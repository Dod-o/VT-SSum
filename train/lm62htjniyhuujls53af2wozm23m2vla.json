{
    "id": "lm62htjniyhuujls53af2wozm23m2vla",
    "title": "Online Multiple Kernel Regression",
    "info": {
        "author": [
            "Steven C.H. Hoi, School of Information Systems, Singapore Management University"
        ],
        "published": "Oct. 8, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_hoi_kernel_regression/",
    "segmentation": [
        [
            "My name is Steven- Singapore Management University this genre, with my student doing shuffle and Beanie from SMU."
        ],
        [
            "So big data now is really.",
            "Big Data is a very hot topic in this data mining community.",
            "As we all know.",
            "Major research challenges that we face in big data analytics is that Commission must measure are too limited not just because of data is not in size, but more important because of data arriving in dreaming, high velocity and also data is a very high variety.",
            "So our research agenda is motivated to develop new machine learning method that can address this limitation for big data analytics.",
            "In particular, we want to invest new machine measure that can handle high velocity and high variety challenges.",
            "On one hand, we want the machine in my server that can handle the data stream as efficient as possible.",
            "We want to go beyond the conventional best measure that have to suffer very expensive retraining costs, and therefore we invest our online learning method.",
            "On the other hand, we want to handle high variety of data and we want the machine method that able to incorporate different sorts of data.",
            "One of scenario requires a multi model learning and we investigate the learning method with multiple kernel method to handle these challenges."
        ],
        [
            "To this end, in this world we investigate online.",
            "Multiple kernel learning is one of the promising direction to address big data analytics challenges.",
            "So the major contribution of this work is that we study online learning with multiple kernel for regression and Time series prediction task.",
            "In this work with proposed and you an online model kernel learning framework that simultaneously learn the multiple kernel regression and the best combination in online learning process.",
            "Finally, we conduct extensive empirical study and apply the measure for time series prediction test."
        ],
        [
            "So rest of my talk is always followed.",
            "First, introduce a background on some related methods.",
            "Then I will present the purpose online.",
            "Multiple kernel regression, famous and then we will talk about some.",
            "Extension which scale the algorithm for last year data analytics.",
            "Finally talk about experiment."
        ],
        [
            "So let me give you a very brief overview.",
            "For some measurements, personal method we want to explore komasa for data analytics, but you get for regression tests.",
            "So kernel method represent a family of machine learning method that can handle some complicated data.",
            "Analytics are particularly to learn nonlinear hyperplane, conventional bash kernel method limited for big data and index for a few reasons.",
            "The first important reason is this method usually batch learning, for example, support random seen it.",
            "Typical batch learning measure.",
            "There are usually slow, especially when you use in a corner an user.",
            "You have to suffer with high retraining costs when you have a new training data coming and visit.",
            "This cannot handle the high velocity challenges.",
            "Another major issue for regular komasa is you have to determine appropriate kernel on behind before you Start learning task, and normally you need a domain knowledge to design A proper kernel or you need to.",
            "I'll probably choose the right parameter for countermeasure, and these are all the practical issue which made kernel method may not be practical for big data analytics in this world.",
            "We want to answer this question, but very more automatic learning methods.",
            "Now let me first introduce what is on our learning and why we need to study this methodology."
        ],
        [
            "So under was in a fairly simple way.",
            "We want to train some predictor that can learn from the data stream.",
            "So typically when you see the data instance .5 on the environment and we want to make a prediction, is accurate as possible and basically learn are you trying to for other each prediction learner received feedback on environment and you can measure with the prediction is correct or incorrect.",
            "Learners suffer from effort.",
            "We're going to make update to ensure that the particular could become more and more accurate.",
            "So why we need online learning?",
            "Because online learning is very fast, is very efficient and highly scalable and you don't have to do any training when you have a new training data.",
            "Just need to perform the update when able necessary and normally this method of reasonable yet guarantees that some theoretical bounds in theory."
        ],
        [
            "Now why we want to consider the comas are because we want to automatically choose the right kernel for the machine learning tasks.",
            "We don't have one too many issues and we can have different methods to address this issue.",
            "For example, we can explore some kernel learning to focus on one particular domain while in this world we may be considered a combination of multiple kernel and this actually related to one of the popular error most known so called multiple kernel learning method and people in this area usually formulate this as a batch learning.",
            "Is a convex concave bottom isation task in a limitation for Commission work is you have to solve this batch learning batch optimization time in quite complicated way.",
            "Although there are many efficient algorithm purpose.",
            "But if you really want to apply to a large scale scenario it remains to be an open challenges.",
            "So we want to develop only measure that can go beyond conventional batch optimization solution."
        ],
        [
            "So next I would like to present our purpose online.",
            "Multiple kernel learning framework for regression tasks and I will talk about some extension."
        ],
        [
            "So this Rico gives the overview for the purpose online multiple kernel learning framework for regression.",
            "So typically we receive the data stream from environment.",
            "So this data can consist of multiple diversity or multiple types of representation and we can contract kernel for each types of data or each type of representation and we can learn a kernel regression for each kernel of each individual modality.",
            "At the end we assign an appropriate color combination way for each modality and then combine them.",
            "To the final prediction and at the end, if the final prediction suffer mistake, we will update the model.",
            "Basically there are two major update.",
            "One is we need to update each individual kernel regression for each kernel and the 2nd is we need to update the optimal combination for all the kernel in these two are the main research engine for this framework."
        ],
        [
            "So first we will look at the first challenging is given a specific kernel.",
            "How can we learn the optimal kernel regression?",
            "So in this way we applied a typical online learning framework for kernel based on learning.",
            "In particular, we use the online gradient decent to update the model.",
            "So so for online.",
            "With this and the first thing is you need to specify what is the loss function.",
            "Worse objective function you want to optimize.",
            "So one typical solution you can consider for regression is a square loss, which in literature requires which of.",
            "Are we done so?",
            "The problem with this square losses that is quite sensitive to noise and the 2nd is that it will actually produce a known sparser so far vector.",
            "In particular if we try to look at this final prediction.",
            "A cell phone.",
            "If you try to look at this final prediction function or this Alpha will be non zero.",
            "In other word is that all the incoming incident will be treated as support vector and therefore you cannot produce a sparse vector.",
            "And you can imagine this would not be efficient in online learning process.",
            "An improvement that we can do is we can export if incentive loss function and therefore we can produce a sparse vector and also less insensitive to noise in this data streams."
        ],
        [
            "The second major issue is how do we update the kernel combination way in online learning process and this essentially is the final prediction function that we combine multiple modality and WT represent the weights assigned to each individual kernel.",
            "So we actually explore two types of online learning algorithm to address these challenges.",
            "The first algorithm we call is the hedging algorithm, which is one of the best on one of the.",
            "We will know online learning our technique based on the frame of the prediction with expert was so the basic idea for this algorithm is we want to track the best corner that can give you the best performance in the online learning process and the update is fairly simple.",
            "That is, whenever corner suffer mistake we try to multiply by a factor that is more than one and the value of this vector isn't depends on the loss as you suffer the other ways.",
            "We can also consider online quiz and decent.",
            "Basically for the online convex optimization.",
            "That we're trying to update based on the Lausanne using the gradient decent solution, so these are two very different update one is based on more on the multiplicative update manner and the other based on addictive applicated manner and they have a different property.",
            "An advantage for different scenarios, for example for hedging algorithm is actually converge faster in order to track the best corner is more probably for nonstationary data and maybe for sequence.",
            "While only within this and is able to find the optimal combination in sub tracking of individual best corner or it is more popular if you have a long sequence with more stationary data will try to see some experience or later."
        ],
        [
            "So these are the major framework is we propose for this regression and well, the problem is this kind of failure may have some limitation when you scale up to the big data.",
            "Now we're trying to."
        ],
        [
            "Get some extension that we can improve the scalability.",
            "So first major so bad for this method is that in this online multiple cleaning process for every single step we have to do the kernel update whenever the final prediction suffer loss.",
            "In other words, we have to update all the kernel when we have a mistakes and this could be very expensive and not efficient if you have a large number of corner.",
            "A second limitation is that it does not guarantee abundant support vector when you have a large number of sequence long sequence, you may have the support of growth overtime even though we use the, it's it's an incentive loss.",
            "We can make a supporter somehow sparse, but eventually the support vector is not guaranteed to be bounded, so we want to improve this to limitation by some extension.",
            "So first extension is we make is using a stochastic update solution.",
            "In other words, is that we don't have the update.",
            "All the corner.",
            "We only did update those most important, most effective corner.",
            "While we can skip the update for those poor corner, so that's a basic idea, and more specifically we can determine the sampling probability which is proportional to the importance or effectiveness of this kernel.",
            "And then we also trying to trade off between this exploration exploitation.",
            "In other word is we don't want to lose the update for those poor corner.",
            "We want to give them some opportunity whenever they may become.",
            "Our effective for some.",
            "For example, concentrating when you have certain strange, maybe this set of kernel.",
            "They are not good for previous sequence, but maybe they could be better for the future sequence and we want to trade all this between exploration, exploitation."
        ],
        [
            "The second updates to address abundance of poverty issue.",
            "We consider, but budget online learning which we can try to guarantee the lumbar support vector in every single step is bounded.",
            "So the basic idea is very simple.",
            "We using a sliding window solution that is whenever support vector size is reached the budget we trying to discover the oldest perfect whenever we LU1 and this also known as a vocation algorithm in budget online learning literature.",
            "Of course we can explore more effective solution for example projection or stochastic updating solution.",
            "But we really have to trade up between the efficiency and effectiveness.",
            "So we can have some discussion.",
            "In fact, for this two extension, because they actually address some of the important issue when we handle time series prediction.",
            "That is the pattern changing order concept reading issue, which very welcome in time series error.",
            "So the first scenario that we use in a stochastic update which is basically OK.",
            "So in case some chance to other kernel that may may work better for future Bob may not work as good as path and this kind of stochastic days is able to address this issue in a second.",
            "Is the budget online learning essentially give more important to the data stater?",
            "Because we always forget the oldest data and this also can somehow to handle on the concept in a more effective way."
        ],
        [
            "The last I just briefly mentioned that we can actually directly apply this framework to time series prediction scenario using the multiple kernel learning idea.",
            "So if we recall most Costco method that we can do for time series prediction is based on the order regression model.",
            "An auto regression basically defined in this way which we have a linear model and we have to specify the window size which is based on the prediction based on combination of this time series data in this window.",
            "And this is basically linear model.",
            "The limitation for this model cost versus linear second is that you have to specify window size and in many scenario we don't know the optimal windows.",
            "I'd go today to the pattern can always change overtime.",
            "So how can we overcome these two limitation?",
            "So we try to apply online multiple kernel learning math.",
            "First we try to kernel this method such that it can handle on linear pattern.",
            "Second is we want to automatically choose the window size.",
            "In other words we wanted Windows site insensitive.",
            "We trying to do this by space or a large number of Windows side.",
            "For given range, for example, P can start from one to 10 and we want to create a cell corner which each corner is designed with respect to one of the particular P value and then we can apply the online model kernel method for this time series prediction in a straightforward way."
        ],
        [
            "Now these are the method and application.",
            "The legs will look at the experiment."
        ],
        [
            "So we try to apply online multiple currently question for both the regular regression tests in terms of prediction tasks, we choose data set, which is some form regular regression and far from time series data and we decide to pull up 24 diverse abnormal function and we compare with active and algorithm including the best color selected by cross validation and the best corner which is now inside and we compare with the algorithm as one is by hedging our William the others by only.",
            "We did decent.",
            "So."
        ],
        [
            "This is our first experiment result that we compare with a single kernel and multiple corner.",
            "So for each of these are the two different types of regression algorithm and the last two can't represent the online multiple kernel regression function.",
            "So from this result we can see that the proposed online multiple kernel regression they perform at least as good as the best kernel in inside and actually perform better in many others in error or in other words, is that using the multiple learning we are able to significantly improve the performance.",
            "It is it's compatible to the best kernel in King size."
        ],
        [
            "So the second issue is that we need to compare between these two algorithm.",
            "Understand in what's another the hedging algorithm, maybe better emotional and maybe on language and this thing can be better.",
            "So we did some experiment to export these two issue.",
            "So first we try to look at one scenario which will have a shorter sequence and in this case the bottom one, the curve which shows the hitting the hedging algorithm and this pink color represent this.",
            "Language and dissent.",
            "As we see that this hedging algorithm can converge much faster than own language and decent for this short sequence for on the right side for long sequence we see that when we give us enough time when the data is stationary, we see that the only reason can perform better than the hedging algorithms and this actually that in certain scenario we had to determine appropriate rate or others using the heading out with them or using an algorithm decent."
        ],
        [
            "Right so far?"
        ],
        [
            "Conclude this talks so in this paper we invest a new machine family online, multiple kernel learning for regression tests.",
            "There are two major research issues.",
            "One is how you can decide the best online method for each individual corner and the 2nd is how can you determine an online color combination in efficient and scalable ways.",
            "And we also make some extension to scale the method for large scale data analytics.",
            "In particular, we study too easy one is budget online.",
            "Learning about the numbers support in online learning process and 2nd is stochastic kernel updating that we only sample the most important kernel for updating.",
            "We applied this too assumptive prediction.",
            "You know fairly later ways and there's some feature work that we have to address.",
            "First, we still have no very good theoretical answer for what scenario we should use the.",
            "Hitting out with them or worse now is to use an online within this and also we do have some NPC observation, but how can we give more regular answer to this strategy selection remain an open issue and also we want to export different types of parallelization or distributed only measure such that we can handle big data.",
            "Really, you know last year."
        ],
        [
            "For this.",
            "So if you have interesting, we will try to put some code available on that."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Steven- Singapore Management University this genre, with my student doing shuffle and Beanie from SMU.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So big data now is really.",
                    "label": 0
                },
                {
                    "sent": "Big Data is a very hot topic in this data mining community.",
                    "label": 0
                },
                {
                    "sent": "As we all know.",
                    "label": 0
                },
                {
                    "sent": "Major research challenges that we face in big data analytics is that Commission must measure are too limited not just because of data is not in size, but more important because of data arriving in dreaming, high velocity and also data is a very high variety.",
                    "label": 0
                },
                {
                    "sent": "So our research agenda is motivated to develop new machine learning method that can address this limitation for big data analytics.",
                    "label": 1
                },
                {
                    "sent": "In particular, we want to invest new machine measure that can handle high velocity and high variety challenges.",
                    "label": 0
                },
                {
                    "sent": "On one hand, we want the machine in my server that can handle the data stream as efficient as possible.",
                    "label": 0
                },
                {
                    "sent": "We want to go beyond the conventional best measure that have to suffer very expensive retraining costs, and therefore we invest our online learning method.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we want to handle high variety of data and we want the machine method that able to incorporate different sorts of data.",
                    "label": 1
                },
                {
                    "sent": "One of scenario requires a multi model learning and we investigate the learning method with multiple kernel method to handle these challenges.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To this end, in this world we investigate online.",
                    "label": 0
                },
                {
                    "sent": "Multiple kernel learning is one of the promising direction to address big data analytics challenges.",
                    "label": 0
                },
                {
                    "sent": "So the major contribution of this work is that we study online learning with multiple kernel for regression and Time series prediction task.",
                    "label": 1
                },
                {
                    "sent": "In this work with proposed and you an online model kernel learning framework that simultaneously learn the multiple kernel regression and the best combination in online learning process.",
                    "label": 1
                },
                {
                    "sent": "Finally, we conduct extensive empirical study and apply the measure for time series prediction test.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So rest of my talk is always followed.",
                    "label": 0
                },
                {
                    "sent": "First, introduce a background on some related methods.",
                    "label": 0
                },
                {
                    "sent": "Then I will present the purpose online.",
                    "label": 0
                },
                {
                    "sent": "Multiple kernel regression, famous and then we will talk about some.",
                    "label": 1
                },
                {
                    "sent": "Extension which scale the algorithm for last year data analytics.",
                    "label": 0
                },
                {
                    "sent": "Finally talk about experiment.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me give you a very brief overview.",
                    "label": 0
                },
                {
                    "sent": "For some measurements, personal method we want to explore komasa for data analytics, but you get for regression tests.",
                    "label": 0
                },
                {
                    "sent": "So kernel method represent a family of machine learning method that can handle some complicated data.",
                    "label": 0
                },
                {
                    "sent": "Analytics are particularly to learn nonlinear hyperplane, conventional bash kernel method limited for big data and index for a few reasons.",
                    "label": 0
                },
                {
                    "sent": "The first important reason is this method usually batch learning, for example, support random seen it.",
                    "label": 0
                },
                {
                    "sent": "Typical batch learning measure.",
                    "label": 0
                },
                {
                    "sent": "There are usually slow, especially when you use in a corner an user.",
                    "label": 0
                },
                {
                    "sent": "You have to suffer with high retraining costs when you have a new training data coming and visit.",
                    "label": 0
                },
                {
                    "sent": "This cannot handle the high velocity challenges.",
                    "label": 0
                },
                {
                    "sent": "Another major issue for regular komasa is you have to determine appropriate kernel on behind before you Start learning task, and normally you need a domain knowledge to design A proper kernel or you need to.",
                    "label": 0
                },
                {
                    "sent": "I'll probably choose the right parameter for countermeasure, and these are all the practical issue which made kernel method may not be practical for big data analytics in this world.",
                    "label": 0
                },
                {
                    "sent": "We want to answer this question, but very more automatic learning methods.",
                    "label": 0
                },
                {
                    "sent": "Now let me first introduce what is on our learning and why we need to study this methodology.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So under was in a fairly simple way.",
                    "label": 0
                },
                {
                    "sent": "We want to train some predictor that can learn from the data stream.",
                    "label": 0
                },
                {
                    "sent": "So typically when you see the data instance .5 on the environment and we want to make a prediction, is accurate as possible and basically learn are you trying to for other each prediction learner received feedback on environment and you can measure with the prediction is correct or incorrect.",
                    "label": 0
                },
                {
                    "sent": "Learners suffer from effort.",
                    "label": 0
                },
                {
                    "sent": "We're going to make update to ensure that the particular could become more and more accurate.",
                    "label": 0
                },
                {
                    "sent": "So why we need online learning?",
                    "label": 1
                },
                {
                    "sent": "Because online learning is very fast, is very efficient and highly scalable and you don't have to do any training when you have a new training data.",
                    "label": 0
                },
                {
                    "sent": "Just need to perform the update when able necessary and normally this method of reasonable yet guarantees that some theoretical bounds in theory.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now why we want to consider the comas are because we want to automatically choose the right kernel for the machine learning tasks.",
                    "label": 0
                },
                {
                    "sent": "We don't have one too many issues and we can have different methods to address this issue.",
                    "label": 0
                },
                {
                    "sent": "For example, we can explore some kernel learning to focus on one particular domain while in this world we may be considered a combination of multiple kernel and this actually related to one of the popular error most known so called multiple kernel learning method and people in this area usually formulate this as a batch learning.",
                    "label": 1
                },
                {
                    "sent": "Is a convex concave bottom isation task in a limitation for Commission work is you have to solve this batch learning batch optimization time in quite complicated way.",
                    "label": 0
                },
                {
                    "sent": "Although there are many efficient algorithm purpose.",
                    "label": 0
                },
                {
                    "sent": "But if you really want to apply to a large scale scenario it remains to be an open challenges.",
                    "label": 0
                },
                {
                    "sent": "So we want to develop only measure that can go beyond conventional batch optimization solution.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So next I would like to present our purpose online.",
                    "label": 0
                },
                {
                    "sent": "Multiple kernel learning framework for regression tasks and I will talk about some extension.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this Rico gives the overview for the purpose online multiple kernel learning framework for regression.",
                    "label": 1
                },
                {
                    "sent": "So typically we receive the data stream from environment.",
                    "label": 0
                },
                {
                    "sent": "So this data can consist of multiple diversity or multiple types of representation and we can contract kernel for each types of data or each type of representation and we can learn a kernel regression for each kernel of each individual modality.",
                    "label": 0
                },
                {
                    "sent": "At the end we assign an appropriate color combination way for each modality and then combine them.",
                    "label": 0
                },
                {
                    "sent": "To the final prediction and at the end, if the final prediction suffer mistake, we will update the model.",
                    "label": 0
                },
                {
                    "sent": "Basically there are two major update.",
                    "label": 0
                },
                {
                    "sent": "One is we need to update each individual kernel regression for each kernel and the 2nd is we need to update the optimal combination for all the kernel in these two are the main research engine for this framework.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first we will look at the first challenging is given a specific kernel.",
                    "label": 0
                },
                {
                    "sent": "How can we learn the optimal kernel regression?",
                    "label": 1
                },
                {
                    "sent": "So in this way we applied a typical online learning framework for kernel based on learning.",
                    "label": 0
                },
                {
                    "sent": "In particular, we use the online gradient decent to update the model.",
                    "label": 0
                },
                {
                    "sent": "So so for online.",
                    "label": 0
                },
                {
                    "sent": "With this and the first thing is you need to specify what is the loss function.",
                    "label": 0
                },
                {
                    "sent": "Worse objective function you want to optimize.",
                    "label": 0
                },
                {
                    "sent": "So one typical solution you can consider for regression is a square loss, which in literature requires which of.",
                    "label": 0
                },
                {
                    "sent": "Are we done so?",
                    "label": 0
                },
                {
                    "sent": "The problem with this square losses that is quite sensitive to noise and the 2nd is that it will actually produce a known sparser so far vector.",
                    "label": 0
                },
                {
                    "sent": "In particular if we try to look at this final prediction.",
                    "label": 0
                },
                {
                    "sent": "A cell phone.",
                    "label": 1
                },
                {
                    "sent": "If you try to look at this final prediction function or this Alpha will be non zero.",
                    "label": 0
                },
                {
                    "sent": "In other word is that all the incoming incident will be treated as support vector and therefore you cannot produce a sparse vector.",
                    "label": 1
                },
                {
                    "sent": "And you can imagine this would not be efficient in online learning process.",
                    "label": 0
                },
                {
                    "sent": "An improvement that we can do is we can export if incentive loss function and therefore we can produce a sparse vector and also less insensitive to noise in this data streams.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second major issue is how do we update the kernel combination way in online learning process and this essentially is the final prediction function that we combine multiple modality and WT represent the weights assigned to each individual kernel.",
                    "label": 1
                },
                {
                    "sent": "So we actually explore two types of online learning algorithm to address these challenges.",
                    "label": 0
                },
                {
                    "sent": "The first algorithm we call is the hedging algorithm, which is one of the best on one of the.",
                    "label": 0
                },
                {
                    "sent": "We will know online learning our technique based on the frame of the prediction with expert was so the basic idea for this algorithm is we want to track the best corner that can give you the best performance in the online learning process and the update is fairly simple.",
                    "label": 0
                },
                {
                    "sent": "That is, whenever corner suffer mistake we try to multiply by a factor that is more than one and the value of this vector isn't depends on the loss as you suffer the other ways.",
                    "label": 0
                },
                {
                    "sent": "We can also consider online quiz and decent.",
                    "label": 0
                },
                {
                    "sent": "Basically for the online convex optimization.",
                    "label": 1
                },
                {
                    "sent": "That we're trying to update based on the Lausanne using the gradient decent solution, so these are two very different update one is based on more on the multiplicative update manner and the other based on addictive applicated manner and they have a different property.",
                    "label": 0
                },
                {
                    "sent": "An advantage for different scenarios, for example for hedging algorithm is actually converge faster in order to track the best corner is more probably for nonstationary data and maybe for sequence.",
                    "label": 0
                },
                {
                    "sent": "While only within this and is able to find the optimal combination in sub tracking of individual best corner or it is more popular if you have a long sequence with more stationary data will try to see some experience or later.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are the major framework is we propose for this regression and well, the problem is this kind of failure may have some limitation when you scale up to the big data.",
                    "label": 0
                },
                {
                    "sent": "Now we're trying to.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Get some extension that we can improve the scalability.",
                    "label": 0
                },
                {
                    "sent": "So first major so bad for this method is that in this online multiple cleaning process for every single step we have to do the kernel update whenever the final prediction suffer loss.",
                    "label": 0
                },
                {
                    "sent": "In other words, we have to update all the kernel when we have a mistakes and this could be very expensive and not efficient if you have a large number of corner.",
                    "label": 1
                },
                {
                    "sent": "A second limitation is that it does not guarantee abundant support vector when you have a large number of sequence long sequence, you may have the support of growth overtime even though we use the, it's it's an incentive loss.",
                    "label": 0
                },
                {
                    "sent": "We can make a supporter somehow sparse, but eventually the support vector is not guaranteed to be bounded, so we want to improve this to limitation by some extension.",
                    "label": 1
                },
                {
                    "sent": "So first extension is we make is using a stochastic update solution.",
                    "label": 0
                },
                {
                    "sent": "In other words, is that we don't have the update.",
                    "label": 0
                },
                {
                    "sent": "All the corner.",
                    "label": 0
                },
                {
                    "sent": "We only did update those most important, most effective corner.",
                    "label": 0
                },
                {
                    "sent": "While we can skip the update for those poor corner, so that's a basic idea, and more specifically we can determine the sampling probability which is proportional to the importance or effectiveness of this kernel.",
                    "label": 0
                },
                {
                    "sent": "And then we also trying to trade off between this exploration exploitation.",
                    "label": 0
                },
                {
                    "sent": "In other word is we don't want to lose the update for those poor corner.",
                    "label": 0
                },
                {
                    "sent": "We want to give them some opportunity whenever they may become.",
                    "label": 0
                },
                {
                    "sent": "Our effective for some.",
                    "label": 0
                },
                {
                    "sent": "For example, concentrating when you have certain strange, maybe this set of kernel.",
                    "label": 0
                },
                {
                    "sent": "They are not good for previous sequence, but maybe they could be better for the future sequence and we want to trade all this between exploration, exploitation.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second updates to address abundance of poverty issue.",
                    "label": 0
                },
                {
                    "sent": "We consider, but budget online learning which we can try to guarantee the lumbar support vector in every single step is bounded.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea is very simple.",
                    "label": 0
                },
                {
                    "sent": "We using a sliding window solution that is whenever support vector size is reached the budget we trying to discover the oldest perfect whenever we LU1 and this also known as a vocation algorithm in budget online learning literature.",
                    "label": 0
                },
                {
                    "sent": "Of course we can explore more effective solution for example projection or stochastic updating solution.",
                    "label": 0
                },
                {
                    "sent": "But we really have to trade up between the efficiency and effectiveness.",
                    "label": 0
                },
                {
                    "sent": "So we can have some discussion.",
                    "label": 0
                },
                {
                    "sent": "In fact, for this two extension, because they actually address some of the important issue when we handle time series prediction.",
                    "label": 0
                },
                {
                    "sent": "That is the pattern changing order concept reading issue, which very welcome in time series error.",
                    "label": 1
                },
                {
                    "sent": "So the first scenario that we use in a stochastic update which is basically OK.",
                    "label": 0
                },
                {
                    "sent": "So in case some chance to other kernel that may may work better for future Bob may not work as good as path and this kind of stochastic days is able to address this issue in a second.",
                    "label": 1
                },
                {
                    "sent": "Is the budget online learning essentially give more important to the data stater?",
                    "label": 0
                },
                {
                    "sent": "Because we always forget the oldest data and this also can somehow to handle on the concept in a more effective way.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The last I just briefly mentioned that we can actually directly apply this framework to time series prediction scenario using the multiple kernel learning idea.",
                    "label": 1
                },
                {
                    "sent": "So if we recall most Costco method that we can do for time series prediction is based on the order regression model.",
                    "label": 0
                },
                {
                    "sent": "An auto regression basically defined in this way which we have a linear model and we have to specify the window size which is based on the prediction based on combination of this time series data in this window.",
                    "label": 0
                },
                {
                    "sent": "And this is basically linear model.",
                    "label": 0
                },
                {
                    "sent": "The limitation for this model cost versus linear second is that you have to specify window size and in many scenario we don't know the optimal windows.",
                    "label": 0
                },
                {
                    "sent": "I'd go today to the pattern can always change overtime.",
                    "label": 0
                },
                {
                    "sent": "So how can we overcome these two limitation?",
                    "label": 1
                },
                {
                    "sent": "So we try to apply online multiple kernel learning math.",
                    "label": 1
                },
                {
                    "sent": "First we try to kernel this method such that it can handle on linear pattern.",
                    "label": 0
                },
                {
                    "sent": "Second is we want to automatically choose the window size.",
                    "label": 0
                },
                {
                    "sent": "In other words we wanted Windows site insensitive.",
                    "label": 0
                },
                {
                    "sent": "We trying to do this by space or a large number of Windows side.",
                    "label": 0
                },
                {
                    "sent": "For given range, for example, P can start from one to 10 and we want to create a cell corner which each corner is designed with respect to one of the particular P value and then we can apply the online model kernel method for this time series prediction in a straightforward way.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now these are the method and application.",
                    "label": 0
                },
                {
                    "sent": "The legs will look at the experiment.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we try to apply online multiple currently question for both the regular regression tests in terms of prediction tasks, we choose data set, which is some form regular regression and far from time series data and we decide to pull up 24 diverse abnormal function and we compare with active and algorithm including the best color selected by cross validation and the best corner which is now inside and we compare with the algorithm as one is by hedging our William the others by only.",
                    "label": 0
                },
                {
                    "sent": "We did decent.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is our first experiment result that we compare with a single kernel and multiple corner.",
                    "label": 0
                },
                {
                    "sent": "So for each of these are the two different types of regression algorithm and the last two can't represent the online multiple kernel regression function.",
                    "label": 1
                },
                {
                    "sent": "So from this result we can see that the proposed online multiple kernel regression they perform at least as good as the best kernel in inside and actually perform better in many others in error or in other words, is that using the multiple learning we are able to significantly improve the performance.",
                    "label": 1
                },
                {
                    "sent": "It is it's compatible to the best kernel in King size.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the second issue is that we need to compare between these two algorithm.",
                    "label": 0
                },
                {
                    "sent": "Understand in what's another the hedging algorithm, maybe better emotional and maybe on language and this thing can be better.",
                    "label": 0
                },
                {
                    "sent": "So we did some experiment to export these two issue.",
                    "label": 0
                },
                {
                    "sent": "So first we try to look at one scenario which will have a shorter sequence and in this case the bottom one, the curve which shows the hitting the hedging algorithm and this pink color represent this.",
                    "label": 0
                },
                {
                    "sent": "Language and dissent.",
                    "label": 0
                },
                {
                    "sent": "As we see that this hedging algorithm can converge much faster than own language and decent for this short sequence for on the right side for long sequence we see that when we give us enough time when the data is stationary, we see that the only reason can perform better than the hedging algorithms and this actually that in certain scenario we had to determine appropriate rate or others using the heading out with them or using an algorithm decent.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right so far?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Conclude this talks so in this paper we invest a new machine family online, multiple kernel learning for regression tests.",
                    "label": 1
                },
                {
                    "sent": "There are two major research issues.",
                    "label": 0
                },
                {
                    "sent": "One is how you can decide the best online method for each individual corner and the 2nd is how can you determine an online color combination in efficient and scalable ways.",
                    "label": 0
                },
                {
                    "sent": "And we also make some extension to scale the method for large scale data analytics.",
                    "label": 1
                },
                {
                    "sent": "In particular, we study too easy one is budget online.",
                    "label": 0
                },
                {
                    "sent": "Learning about the numbers support in online learning process and 2nd is stochastic kernel updating that we only sample the most important kernel for updating.",
                    "label": 1
                },
                {
                    "sent": "We applied this too assumptive prediction.",
                    "label": 0
                },
                {
                    "sent": "You know fairly later ways and there's some feature work that we have to address.",
                    "label": 0
                },
                {
                    "sent": "First, we still have no very good theoretical answer for what scenario we should use the.",
                    "label": 0
                },
                {
                    "sent": "Hitting out with them or worse now is to use an online within this and also we do have some NPC observation, but how can we give more regular answer to this strategy selection remain an open issue and also we want to export different types of parallelization or distributed only measure such that we can handle big data.",
                    "label": 0
                },
                {
                    "sent": "Really, you know last year.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this.",
                    "label": 0
                },
                {
                    "sent": "So if you have interesting, we will try to put some code available on that.",
                    "label": 0
                }
            ]
        }
    }
}