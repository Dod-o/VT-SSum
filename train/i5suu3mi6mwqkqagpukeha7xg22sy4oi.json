{
    "id": "i5suu3mi6mwqkqagpukeha7xg22sy4oi",
    "title": "Person detection and recognition, tracking and analysis",
    "info": {
        "author": [
            "Montse Pard\u00e0s, GREC - Knowledge Engineering Research Group, Technical University of Catalonia"
        ],
        "published": "Feb. 14, 2008",
        "recorded": "February 2008",
        "category": [
            "Top->Computer Science"
        ]
    },
    "url": "http://videolectures.net/mcvc08_pardas_pdct/",
    "segmentation": [
        [
            "Once you've heard us from UPC.",
            "And if you like to look at this.",
            "Semi automatic segmentation tool.",
            "She's the person to talk to.",
            "But what she's going to talk about now is person detection and recognition tracking and analysis.",
            "OK, so this is a presentation of the team which is a person, detection tracking and human body analysis.",
            "But we have focused on part of it of all the work that we have done during this idiom.",
            "And for this, uh, focused representation on multi camera scenarios because it's somewhat different of what I have presented in previous meetings, so I thought this would be different.",
            "So these are all the groups that have participated in the team.",
            "And I will show some of the."
        ],
        [
            "Ah.",
            "Works with the have been done in multi camera and also some example results of other parts of the work done in the team which are not in this area, but I will just show the results, not the technical detail.",
            "So the summary, if the following first I will explain what are the multicamera scenarios an which are the applications.",
            "Afterwards, I will present a new technique that we have developed during the last year for multi level for grossing meditation and tracking.",
            "Then I will just play one of the applications of Multicamera which are 3D person tracking with practical filters.",
            "Also the some examples of human motion capture and finally this were results of works of other groups in dating.",
            "But just the results are not the technical detail."
        ],
        [
            "OK, so these are.",
            "And many of it wow.",
            "So the videos will not work.",
            "OK, so this is the.",
            "OK, so it doesn't work because I wanted to show all the line, not just this, But anyway, this is one of the views of room which is overlooked by different cameras and the idea that I wanted to give is that you have different views and when you have crowded the scenes or like more than four or five peoples or people around to the capture that this is just far from 1 camera, it's sometimes not enough because you have too many occlusions.",
            "Also, that objects which include the people in the room, like here the table, and so having multiple cameras, it's better for this.",
            "I wanted to show.",
            "OK, let's see if this goes back.",
            "This was going to be a disaster because they have many videos an.",
            "Never test, stop here.",
            "I see it correctly, but then OK, I saw this is working.",
            "So the idea is that we have these four sequences from 4 different cameras, different corners of the room, an.",
            "The process that we know it's the one that is explaining this is like we get the original video sequences from each camera.",
            "You think it's?",
            "I'm not sure.",
            "Now it's working, but the other one was not.",
            "OK, so.",
            "What are showing here and just showing from for one of the sequences in order not to create more problems?",
            "It's the foreground extraction from one of the cameras.",
            "We do this for all the four cameras and the second the next step is what I show in the several, which is the extraction of the binary volume that is occupied in the scene that is.",
            "Extract the volumes which belong to active entities in the scene.",
            "To do this what we do is to create.",
            "This is shown in the first image.",
            "Made the last roll.",
            "Switch to intersect the visual counts which are obtained by back projecting the silhouettes to each of the camera.",
            "So if we get the intersection of these visual cones, we obtain the volume which is occupied by an active entity an what we obtain.",
            "Is the mouse now?",
            "Well.",
            "My wife lost the mouse.",
            "This is the projection of the 10 volumes, so we see for instance that the legs of the person who are which are behind the table are still reconstructed because they are seen from other cameras.",
            "In this.",
            "Video all the volumes are labeled with the same label because they are still not tracked along time that this there is no an identification of the different volumes along the time.",
            "This is just the reconstruction of the occupied volumes.",
            "This is obtained doesn't mention here with a shape from Silhouette algorithm.",
            "And also we can use some other information for some applications with just the coloring of the of these volumes in the last image, what we see is that this volumes get the color of the pixels where they project and this is useful also for some applications that I will see next."
        ],
        [
            "OK, so this is how it works in a multi camera scenario an.",
            "I'll show.",
            "I will show now what are the applications of of this so God can we do with this data which is labeled data colored little data?",
            "So one of the applications is multi person tracking.",
            "Which can be useful, for instance an.",
            "For higher semantic level.",
            "For activity recognition.",
            "So here we have this still blue labels, but now they are tracked with crosses.",
            "Every person is being drug, so this allows us to reconstruct for instance the trajectory of all the people who is moving in the room and we can extract from this.",
            "Higher level information like activity recognition.",
            "So this is one of the applications.",
            "Sing now.",
            "OK, so the next application is head orientation estimation.",
            "Staining from this volumes those boxes which have a skin color.",
            "We can do a 3 dimensional estimation of the head orientation.",
            "I'll try to see that video here.",
            "Here we see how we extract the focus of attention of the person.",
            "By using this colored box cells.",
            "And finally.",
            "Another application.",
            "It's for human motion capture.",
            "Let's see if this works the same, so using these volumes.",
            "We construct the human body body model.",
            "How it moves, that is, what's the motion or for human body model, by using this label boxers and this can be used for gesture or gait recognition for instance.",
            "So the idea is to.",
            "Use those 3D entities for all these kind of applications which allow us to extract some semantic information from the scene."
        ],
        [
            "OK, so.",
            "This is a general overview of what we can do in multi camera an.",
            "Now I will focus on some of the steps of this and also on some of the applications.",
            "So the first one that I will explain with a little bit more of detail, it's a work that we have done during the last year for forum detection.",
            "This problem detection it's the first step of the scene reconstruction, but can also be used into the applications for forward on detection.",
            "So what we have developed, it's a multi level forum segmentation.",
            "This means that we differentiate between the background model, moving forward model and static forum model.",
            "This is useful for instance in the application that I have shown where there is a person.",
            "OK there's people and people usually don't move all the time in the scene.",
            "For instance they sit and they are staying there for awhile.",
            "In this situation the question comes.",
            "What should we do?",
            "Should we integrate this person into the background?",
            "Or should we keep it as a negative entity?",
            "If we keep it as an active entity, which actually is because at some time the person is going to move again.",
            "The problem is that we will not be able to detect in this camera the persons which are passing in front of it because they are already fallen, so we cannot detect another program.",
            "So what we have done is to develop the multi level forum segmentation.",
            "Which distinguishes this moving forward from the static program for this application.",
            "What we use is a simple model for the background and moving forward on the starting.",
            "It's typical Goshen model with just one Goshen.",
            "And the idea that it is based on is the fact that.",
            "We OK we learn the background model and when we detect foreground because the model the pixel value doesn't fit with the alarm background model.",
            "We initialize moving foreground model.",
            "If the person is moving this moving foreground model will keep on changing.",
            "Otherwise, when the person stays still.",
            "We will observe the same model for a long time, so when.",
            "We observe a moving forward model for a certain amount of time.",
            "We transfer this model to the static program model."
        ],
        [
            "OK, so this is an example.",
            "For instance, the person on the right has a status still, so we label it with a different value, which means that we have identified that this is a steal person.",
            "But this is working still without tracking.",
            "So we just identify for every single frame if we have background foreground or static program."
        ],
        [
            "We have also developed.",
            "A tracking system for a.",
            "Each of the cameras at this photo for today tracking.",
            "Using this multi level information for this what we do is to keep a double register, one for moving objects and one for static objects.",
            "OK, here are the details.",
            "So they will be published soon.",
            "I won't go through it."
        ],
        [
            "Mention that for the moving objects, what we use is a mean shift tracking adapted to the program detection."
        ],
        [
            "I'll show here an example if it's possible.",
            "This is a.",
            "Example, in a room what we have with the different person people entering the room.",
            "And we will see that one of them stays still.",
            "So it changed its label to a static object.",
            "But it doesn't interfere with other person passing in front of it.",
            "This is important in this kind of scenes, which are small and this crowded since there is a lot of occlusions between people, so we see that there's some #2 is a stainless steel, so it goes to a different level and it's not mixed with the people are closing it.",
            "OK.",
            "So this is a work that we have done for actually for."
        ],
        [
            "Audi what do we do in multi camera scenarios for tracking as I have shown before?",
            "We have the 3D reconstructed entities and we have to establish the temporal correspondence is of these objects.",
            "Um?",
            "So what we have developed it's multi person tracking.",
            "Which words with like before crowded since that we have?",
            "Quite a lot of people in the same scene, but multicamera information allows us to solve.",
            "Occlusions.",
            "And we have used the particle filter solution and we have evaluated this technique with standardize database, which is clear to 1007.",
            "OK, so the idea of the particle filters it's as most of you know, it's that we will represent we have a state vector, which in our case is for instance the centroid of the person being tracked.",
            "And we have another set of observations which in our case are the volumes that they have represented in the first slide.",
            "And we want to know the posterior of.",
            "This is state vector with the observations and for this what we created a set of random samples.",
            "We just made this posterior in this particle filters algorithm, there are typically four steps which are the resampling of the particles.",
            "The propagation, evaluation and estimation.",
            "So what we have to answer when designing this particle filters is how to compute the likelihood evaluation.",
            "That is, how to assign the wakes to the particles and what is the propagation model years that it's hard to move the particles to efficiently sample the state."
        ],
        [
            "Space.",
            "So for this 3D taxes for this multi person suite at 3D tracking what we have is that every particle as I mentioned defines a possible location of the person and represented by a very simple model, which is an ellipsoid.",
            "We compute the reference color histogram for each person and awake that are assigned to a particles are a function of the overlap of the binary 3D reconstruction that they have shown in the first slide.",
            "So it's the intersection of this binary theory 3D reconstruction with the ellipsoid that represents the particle.",
            "And we also use the color similarity between the reference histogram and the color of the box cells which are inside this."
        ],
        [
            "Ellipsoid.",
            "We in order to deal with multiple people, what we do is to initialize particle filter for every one of the trucks that are started.",
            "We also need to assign them an interaction model in order to be able not to mix different tracks of different people when they come too close, because the... will intersect.",
            "So we have to.",
            "Avoid the merging of this ellipsoid, so we create an interaction model which forbids this.",
            "So in this case, this would be the Tulip source representing the two particles an there is a zone where we don't allow.",
            "The samples to be measured in order not to mix."
        ],
        [
            "So these are some results.",
            "We won't be able to see them.",
            "See if I can.",
            "Put just one of the videos.",
            "They are in different Roma scenarios.",
            "What I want to show here is that the problem is not so easy because you see that the reconstructed volumes are very noisy.",
            "There are the blue things are the projections of the 3D volumes and they are very noisy, so we obtain.",
            "Voxels are which are not representing really the person, but sometimes the chair has moved to reconstruct.",
            "This is volume, but using this particle filter strategy we are able to obtain just one track for person and not being confused by this noise.",
            "OK."
        ],
        [
            "The results of this.",
            "Have you measured in terms of accuracy and precision, with different voxel sizes?",
            "Of course, the smaller the voxel size the the best accuracy and precision, but longer reach the computational time needed.",
            "This algorithm was performing as the best algorithm in a clear 2007 evaluation campaign which measured different algorithms for the for 3D tracking."
        ],
        [
            "OK, so we also did some combination of without the information for the tracking, but in a very basic level just combining kind of results and we want to work on Fusion at that."
        ],
        [
            "OK, so the next application that I want to show.",
            "It's human motion capture.",
            "As I mentioned, this means to have articulated body model an extracting the motion of this articulated body.",
            "There are two approaches which are possible market or market layers or market list.",
            "We have worked on both of them.",
            "And we have oriented these also using particle filters.",
            "But in this case, the state of space it's formed by the.",
            "The link the links between the different limbs, so we measured the orientation and both of these different links, so it usually has around 22 degrees of freedom, so it's a.",
            "Much more complex problem and the problem is that if you have so many degrees of freedom, you need a lot of particles for the system to work.",
            "So you have to find strategies to make the algorithm faster, because otherwise it's too slow."
        ],
        [
            "OK, so this is an example of.",
            "What can be done with markers just go.",
            "Quickly through through this, but in this case you have labels in marks.",
            "In some parts of the body, which of course help you with the result, but I."
        ],
        [
            "Weather focus on the market less capture which uses the 3D reconstructed volumes that I show in the first slide.",
            "Um?",
            "So as I mentioned, if it's a particle filter strategy, we need to define the likelihood evaluation.",
            "And we have to find it.",
            "Is a function which matches the input data against the particle posts, taking into account again the 3D."
        ],
        [
            "Turn on the color so we have the original image.",
            "The box of reconstruction.",
            "And this would be a particle defines a given position of the body model like the one.",
            "In the future or the second one would be another particle.",
            "So what we will do is to simulate the volume for each of the limbs and we intersect.",
            "This volume created by every particle with the volume that we have reconstructed.",
            "That's the one in blue and for instance, in this case the 2nd.",
            "RAW has an error in the position of the leg, so the intersection with that volume is smaller, so the weight of this particle would be smaller."
        ],
        [
            "We have developed this annealing particle.",
            "This particle filter with annealing in order to be faster because we need so many particles otherwise and we also do it in a logical way.",
            "And discuss two advantages.",
            "One, it's you're still need less particles if you do it in archical, and also when some of the parts of the body become covered, you can.",
            "Use a simple model that, for instance in this the last one you could use the model without the Max."
        ],
        [
            "OK, have video here to show this tracking, but it's outside presentation.",
            "OK.",
            "So this is the optical model.",
            "The lines in the first, the red, blue and green lines are the axis of orientation, and yellow lines are the defining the particles in every year artikkel step.",
            "So the first one we just have the trunk.",
            "So we just fit the trunk with an ellipsoid.",
            "In the second one we have legs and arms, but we don't have the joint.",
            "Of the legs and arms, and in the third one we have all the motion possible, so we see that so this is carried out in these three steps.",
            "So in this way we can minimize the number of particles used.",
            "And in the last one we see the result of the tracking.",
            "OK, so."
        ],
        [
            "This work has been done in cooperation with Technion University and UPC, an attendee and they are taking a slightly different approach, which is training the different possible poses that are used.",
            "For instance, they train, walking, running."
        ],
        [
            "Pushing kicking."
        ],
        [
            "And this also allows to reduce the dimensionality of the particle filters."
        ],
        [
            "OK, I'm going to it that we have this presented this in other works and this is a result of data tracking which is in this case let my limited to a different sense of actions.",
            "We see here to different actions.",
            "OK, so this is basically the work that has been done in multi camera.",
            "A sense, and as I."
        ],
        [
            "Mention I also want to show some other works that have been developed within the context of the team, but without going into details.",
            "One of the works is discussed in this case in.",
            "Today it's for moving object detection and classification.",
            "This is results from Bilkent University.",
            "So in this case, apart from detecting the foreground of the scene, they classify in this case between human or human group.",
            "They can also classify vehicles if there are vehicles around.",
            "It's based on the contour of the forum, detected an.",
            "Vector machines."
        ],
        [
            "And another of the work that has been done.",
            "It's 'cause I have focused the presentation on the."
        ],
        [
            "On person, but we have also a part of the team on phase analysis and this is a work from University of Amsterdam for eye tracking and this is a video showing the eye tracking results in different situations.",
            "The green dot marked the center of the detected eyes.",
            "We'll see it different.",
            "So as I mentioned, these are other parts of the team.",
            "Just wanted to show some videos.",
            "Not to focus only on this multi camera part.",
            "It's it's robust or cushions, and there's also a part which is showing with different people.",
            "And or fast movements.",
            "The motion is faster.",
            "So Nicole can give you more details about this.",
            "Notes above the algorithm.",
            "Finally, with multiple subjects and changing the illumination.",
            "Still works with three or four people.",
            "OK, so this is the end of the presentation.",
            "Is there any questions?",
            "Quite a wide range.",
            "We could see some foreground background segmentation, but these people walking around the table.",
            "We've seen quite some holes in the people standing for nationwide.",
            "Otherwise.",
            "Yeah, and the reason is that we use very simple models for modeling the background.",
            "One Goshen, so we just model the mean and the volumes of discussion.",
            "So when, for instance there is a OK, you move around here and there are these black lines on the background and your dresser in dark color.",
            "So when you move in front of this dark lines this will be detected as background because your model for the bathroom is very simple, right?",
            "So?",
            "Why we use this simple model?",
            "Because we want it to work in real time.",
            "We still need one computer for every camera, but otherwise we can not run real time for this.",
            "The idea is that then we when we combine the multiple cameras, this kind of effects are solved.",
            "We also developed the tracking.",
            "'cause this is only the forum detection, then we have the tracking part.",
            "So we developed the tracking in order to be robust to this kind of effects.",
            "Compromise always.",
            "Basement.",
            "I just wondered if you're multiple person particle filtering.",
            "Do you do automatic initiation and deletion of targets?",
            "Yes, in Java, target is initialized when a volume of size compatible with a person is found.",
            "As we have the 3D information because we have calibrated cameras and so on, we know which is the size of a person in the room.",
            "So when a person of sorry when a volume of this size is detected, we initialize the track.",
            "We also then remove tracks which just appear for a few frames or things like that.",
            "OK, and do you do the tracking separately with a separate particle filter for each person?",
            "Sorry, sorry.",
            "Do you do the tracking independently for each person or do you have a joint stacked particle filter?",
            "No no no.",
            "In order to keep the complexity of the problem smaller we have a truck, so that's a particle filter for every person.",
            "So we initialize a particle filter every time that we detect the volume of the right size.",
            "But then what we define is interaction models between particle filters so.",
            "Yeah, so when waiting the.",
            "The particles are to know the weight of a given particle when we have OK particle for us we find center and size.",
            "Which is defined by an ellipsoid.",
            "So when these two ellipsoids intersect.",
            "We don't compute the contribution of the boxes which are in the intersection.",
            "So that we don't, because otherwise at the end we would merge the tool attraction so we don't allow them to merge.",
            "OK, thanks.",
            "Further questions.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Once you've heard us from UPC.",
                    "label": 0
                },
                {
                    "sent": "And if you like to look at this.",
                    "label": 0
                },
                {
                    "sent": "Semi automatic segmentation tool.",
                    "label": 0
                },
                {
                    "sent": "She's the person to talk to.",
                    "label": 0
                },
                {
                    "sent": "But what she's going to talk about now is person detection and recognition tracking and analysis.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is a presentation of the team which is a person, detection tracking and human body analysis.",
                    "label": 1
                },
                {
                    "sent": "But we have focused on part of it of all the work that we have done during this idiom.",
                    "label": 0
                },
                {
                    "sent": "And for this, uh, focused representation on multi camera scenarios because it's somewhat different of what I have presented in previous meetings, so I thought this would be different.",
                    "label": 0
                },
                {
                    "sent": "So these are all the groups that have participated in the team.",
                    "label": 0
                },
                {
                    "sent": "And I will show some of the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ah.",
                    "label": 0
                },
                {
                    "sent": "Works with the have been done in multi camera and also some example results of other parts of the work done in the team which are not in this area, but I will just show the results, not the technical detail.",
                    "label": 0
                },
                {
                    "sent": "So the summary, if the following first I will explain what are the multicamera scenarios an which are the applications.",
                    "label": 0
                },
                {
                    "sent": "Afterwards, I will present a new technique that we have developed during the last year for multi level for grossing meditation and tracking.",
                    "label": 0
                },
                {
                    "sent": "Then I will just play one of the applications of Multicamera which are 3D person tracking with practical filters.",
                    "label": 1
                },
                {
                    "sent": "Also the some examples of human motion capture and finally this were results of works of other groups in dating.",
                    "label": 1
                },
                {
                    "sent": "But just the results are not the technical detail.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so these are.",
                    "label": 0
                },
                {
                    "sent": "And many of it wow.",
                    "label": 0
                },
                {
                    "sent": "So the videos will not work.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the.",
                    "label": 0
                },
                {
                    "sent": "OK, so it doesn't work because I wanted to show all the line, not just this, But anyway, this is one of the views of room which is overlooked by different cameras and the idea that I wanted to give is that you have different views and when you have crowded the scenes or like more than four or five peoples or people around to the capture that this is just far from 1 camera, it's sometimes not enough because you have too many occlusions.",
                    "label": 0
                },
                {
                    "sent": "Also, that objects which include the people in the room, like here the table, and so having multiple cameras, it's better for this.",
                    "label": 0
                },
                {
                    "sent": "I wanted to show.",
                    "label": 0
                },
                {
                    "sent": "OK, let's see if this goes back.",
                    "label": 0
                },
                {
                    "sent": "This was going to be a disaster because they have many videos an.",
                    "label": 0
                },
                {
                    "sent": "Never test, stop here.",
                    "label": 0
                },
                {
                    "sent": "I see it correctly, but then OK, I saw this is working.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that we have these four sequences from 4 different cameras, different corners of the room, an.",
                    "label": 0
                },
                {
                    "sent": "The process that we know it's the one that is explaining this is like we get the original video sequences from each camera.",
                    "label": 0
                },
                {
                    "sent": "You think it's?",
                    "label": 0
                },
                {
                    "sent": "I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "Now it's working, but the other one was not.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "What are showing here and just showing from for one of the sequences in order not to create more problems?",
                    "label": 0
                },
                {
                    "sent": "It's the foreground extraction from one of the cameras.",
                    "label": 0
                },
                {
                    "sent": "We do this for all the four cameras and the second the next step is what I show in the several, which is the extraction of the binary volume that is occupied in the scene that is.",
                    "label": 0
                },
                {
                    "sent": "Extract the volumes which belong to active entities in the scene.",
                    "label": 0
                },
                {
                    "sent": "To do this what we do is to create.",
                    "label": 0
                },
                {
                    "sent": "This is shown in the first image.",
                    "label": 0
                },
                {
                    "sent": "Made the last roll.",
                    "label": 0
                },
                {
                    "sent": "Switch to intersect the visual counts which are obtained by back projecting the silhouettes to each of the camera.",
                    "label": 0
                },
                {
                    "sent": "So if we get the intersection of these visual cones, we obtain the volume which is occupied by an active entity an what we obtain.",
                    "label": 0
                },
                {
                    "sent": "Is the mouse now?",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "My wife lost the mouse.",
                    "label": 0
                },
                {
                    "sent": "This is the projection of the 10 volumes, so we see for instance that the legs of the person who are which are behind the table are still reconstructed because they are seen from other cameras.",
                    "label": 0
                },
                {
                    "sent": "In this.",
                    "label": 0
                },
                {
                    "sent": "Video all the volumes are labeled with the same label because they are still not tracked along time that this there is no an identification of the different volumes along the time.",
                    "label": 0
                },
                {
                    "sent": "This is just the reconstruction of the occupied volumes.",
                    "label": 0
                },
                {
                    "sent": "This is obtained doesn't mention here with a shape from Silhouette algorithm.",
                    "label": 0
                },
                {
                    "sent": "And also we can use some other information for some applications with just the coloring of the of these volumes in the last image, what we see is that this volumes get the color of the pixels where they project and this is useful also for some applications that I will see next.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is how it works in a multi camera scenario an.",
                    "label": 0
                },
                {
                    "sent": "I'll show.",
                    "label": 0
                },
                {
                    "sent": "I will show now what are the applications of of this so God can we do with this data which is labeled data colored little data?",
                    "label": 0
                },
                {
                    "sent": "So one of the applications is multi person tracking.",
                    "label": 1
                },
                {
                    "sent": "Which can be useful, for instance an.",
                    "label": 0
                },
                {
                    "sent": "For higher semantic level.",
                    "label": 0
                },
                {
                    "sent": "For activity recognition.",
                    "label": 0
                },
                {
                    "sent": "So here we have this still blue labels, but now they are tracked with crosses.",
                    "label": 0
                },
                {
                    "sent": "Every person is being drug, so this allows us to reconstruct for instance the trajectory of all the people who is moving in the room and we can extract from this.",
                    "label": 0
                },
                {
                    "sent": "Higher level information like activity recognition.",
                    "label": 1
                },
                {
                    "sent": "So this is one of the applications.",
                    "label": 1
                },
                {
                    "sent": "Sing now.",
                    "label": 1
                },
                {
                    "sent": "OK, so the next application is head orientation estimation.",
                    "label": 0
                },
                {
                    "sent": "Staining from this volumes those boxes which have a skin color.",
                    "label": 0
                },
                {
                    "sent": "We can do a 3 dimensional estimation of the head orientation.",
                    "label": 0
                },
                {
                    "sent": "I'll try to see that video here.",
                    "label": 0
                },
                {
                    "sent": "Here we see how we extract the focus of attention of the person.",
                    "label": 1
                },
                {
                    "sent": "By using this colored box cells.",
                    "label": 0
                },
                {
                    "sent": "And finally.",
                    "label": 0
                },
                {
                    "sent": "Another application.",
                    "label": 0
                },
                {
                    "sent": "It's for human motion capture.",
                    "label": 1
                },
                {
                    "sent": "Let's see if this works the same, so using these volumes.",
                    "label": 0
                },
                {
                    "sent": "We construct the human body body model.",
                    "label": 0
                },
                {
                    "sent": "How it moves, that is, what's the motion or for human body model, by using this label boxers and this can be used for gesture or gait recognition for instance.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to.",
                    "label": 0
                },
                {
                    "sent": "Use those 3D entities for all these kind of applications which allow us to extract some semantic information from the scene.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "This is a general overview of what we can do in multi camera an.",
                    "label": 0
                },
                {
                    "sent": "Now I will focus on some of the steps of this and also on some of the applications.",
                    "label": 1
                },
                {
                    "sent": "So the first one that I will explain with a little bit more of detail, it's a work that we have done during the last year for forum detection.",
                    "label": 0
                },
                {
                    "sent": "This problem detection it's the first step of the scene reconstruction, but can also be used into the applications for forward on detection.",
                    "label": 0
                },
                {
                    "sent": "So what we have developed, it's a multi level forum segmentation.",
                    "label": 1
                },
                {
                    "sent": "This means that we differentiate between the background model, moving forward model and static forum model.",
                    "label": 0
                },
                {
                    "sent": "This is useful for instance in the application that I have shown where there is a person.",
                    "label": 1
                },
                {
                    "sent": "OK there's people and people usually don't move all the time in the scene.",
                    "label": 0
                },
                {
                    "sent": "For instance they sit and they are staying there for awhile.",
                    "label": 0
                },
                {
                    "sent": "In this situation the question comes.",
                    "label": 0
                },
                {
                    "sent": "What should we do?",
                    "label": 0
                },
                {
                    "sent": "Should we integrate this person into the background?",
                    "label": 0
                },
                {
                    "sent": "Or should we keep it as a negative entity?",
                    "label": 0
                },
                {
                    "sent": "If we keep it as an active entity, which actually is because at some time the person is going to move again.",
                    "label": 0
                },
                {
                    "sent": "The problem is that we will not be able to detect in this camera the persons which are passing in front of it because they are already fallen, so we cannot detect another program.",
                    "label": 0
                },
                {
                    "sent": "So what we have done is to develop the multi level forum segmentation.",
                    "label": 0
                },
                {
                    "sent": "Which distinguishes this moving forward from the static program for this application.",
                    "label": 0
                },
                {
                    "sent": "What we use is a simple model for the background and moving forward on the starting.",
                    "label": 0
                },
                {
                    "sent": "It's typical Goshen model with just one Goshen.",
                    "label": 0
                },
                {
                    "sent": "And the idea that it is based on is the fact that.",
                    "label": 1
                },
                {
                    "sent": "We OK we learn the background model and when we detect foreground because the model the pixel value doesn't fit with the alarm background model.",
                    "label": 1
                },
                {
                    "sent": "We initialize moving foreground model.",
                    "label": 0
                },
                {
                    "sent": "If the person is moving this moving foreground model will keep on changing.",
                    "label": 1
                },
                {
                    "sent": "Otherwise, when the person stays still.",
                    "label": 0
                },
                {
                    "sent": "We will observe the same model for a long time, so when.",
                    "label": 0
                },
                {
                    "sent": "We observe a moving forward model for a certain amount of time.",
                    "label": 0
                },
                {
                    "sent": "We transfer this model to the static program model.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is an example.",
                    "label": 0
                },
                {
                    "sent": "For instance, the person on the right has a status still, so we label it with a different value, which means that we have identified that this is a steal person.",
                    "label": 0
                },
                {
                    "sent": "But this is working still without tracking.",
                    "label": 0
                },
                {
                    "sent": "So we just identify for every single frame if we have background foreground or static program.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have also developed.",
                    "label": 0
                },
                {
                    "sent": "A tracking system for a.",
                    "label": 0
                },
                {
                    "sent": "Each of the cameras at this photo for today tracking.",
                    "label": 0
                },
                {
                    "sent": "Using this multi level information for this what we do is to keep a double register, one for moving objects and one for static objects.",
                    "label": 0
                },
                {
                    "sent": "OK, here are the details.",
                    "label": 0
                },
                {
                    "sent": "So they will be published soon.",
                    "label": 0
                },
                {
                    "sent": "I won't go through it.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mention that for the moving objects, what we use is a mean shift tracking adapted to the program detection.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll show here an example if it's possible.",
                    "label": 0
                },
                {
                    "sent": "This is a.",
                    "label": 0
                },
                {
                    "sent": "Example, in a room what we have with the different person people entering the room.",
                    "label": 0
                },
                {
                    "sent": "And we will see that one of them stays still.",
                    "label": 0
                },
                {
                    "sent": "So it changed its label to a static object.",
                    "label": 0
                },
                {
                    "sent": "But it doesn't interfere with other person passing in front of it.",
                    "label": 0
                },
                {
                    "sent": "This is important in this kind of scenes, which are small and this crowded since there is a lot of occlusions between people, so we see that there's some #2 is a stainless steel, so it goes to a different level and it's not mixed with the people are closing it.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is a work that we have done for actually for.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Audi what do we do in multi camera scenarios for tracking as I have shown before?",
                    "label": 1
                },
                {
                    "sent": "We have the 3D reconstructed entities and we have to establish the temporal correspondence is of these objects.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "So what we have developed it's multi person tracking.",
                    "label": 0
                },
                {
                    "sent": "Which words with like before crowded since that we have?",
                    "label": 0
                },
                {
                    "sent": "Quite a lot of people in the same scene, but multicamera information allows us to solve.",
                    "label": 0
                },
                {
                    "sent": "Occlusions.",
                    "label": 0
                },
                {
                    "sent": "And we have used the particle filter solution and we have evaluated this technique with standardize database, which is clear to 1007.",
                    "label": 0
                },
                {
                    "sent": "OK, so the idea of the particle filters it's as most of you know, it's that we will represent we have a state vector, which in our case is for instance the centroid of the person being tracked.",
                    "label": 0
                },
                {
                    "sent": "And we have another set of observations which in our case are the volumes that they have represented in the first slide.",
                    "label": 1
                },
                {
                    "sent": "And we want to know the posterior of.",
                    "label": 0
                },
                {
                    "sent": "This is state vector with the observations and for this what we created a set of random samples.",
                    "label": 1
                },
                {
                    "sent": "We just made this posterior in this particle filters algorithm, there are typically four steps which are the resampling of the particles.",
                    "label": 0
                },
                {
                    "sent": "The propagation, evaluation and estimation.",
                    "label": 1
                },
                {
                    "sent": "So what we have to answer when designing this particle filters is how to compute the likelihood evaluation.",
                    "label": 0
                },
                {
                    "sent": "That is, how to assign the wakes to the particles and what is the propagation model years that it's hard to move the particles to efficiently sample the state.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Space.",
                    "label": 0
                },
                {
                    "sent": "So for this 3D taxes for this multi person suite at 3D tracking what we have is that every particle as I mentioned defines a possible location of the person and represented by a very simple model, which is an ellipsoid.",
                    "label": 1
                },
                {
                    "sent": "We compute the reference color histogram for each person and awake that are assigned to a particles are a function of the overlap of the binary 3D reconstruction that they have shown in the first slide.",
                    "label": 1
                },
                {
                    "sent": "So it's the intersection of this binary theory 3D reconstruction with the ellipsoid that represents the particle.",
                    "label": 0
                },
                {
                    "sent": "And we also use the color similarity between the reference histogram and the color of the box cells which are inside this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ellipsoid.",
                    "label": 0
                },
                {
                    "sent": "We in order to deal with multiple people, what we do is to initialize particle filter for every one of the trucks that are started.",
                    "label": 0
                },
                {
                    "sent": "We also need to assign them an interaction model in order to be able not to mix different tracks of different people when they come too close, because the... will intersect.",
                    "label": 0
                },
                {
                    "sent": "So we have to.",
                    "label": 0
                },
                {
                    "sent": "Avoid the merging of this ellipsoid, so we create an interaction model which forbids this.",
                    "label": 1
                },
                {
                    "sent": "So in this case, this would be the Tulip source representing the two particles an there is a zone where we don't allow.",
                    "label": 0
                },
                {
                    "sent": "The samples to be measured in order not to mix.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are some results.",
                    "label": 0
                },
                {
                    "sent": "We won't be able to see them.",
                    "label": 0
                },
                {
                    "sent": "See if I can.",
                    "label": 0
                },
                {
                    "sent": "Put just one of the videos.",
                    "label": 0
                },
                {
                    "sent": "They are in different Roma scenarios.",
                    "label": 0
                },
                {
                    "sent": "What I want to show here is that the problem is not so easy because you see that the reconstructed volumes are very noisy.",
                    "label": 0
                },
                {
                    "sent": "There are the blue things are the projections of the 3D volumes and they are very noisy, so we obtain.",
                    "label": 0
                },
                {
                    "sent": "Voxels are which are not representing really the person, but sometimes the chair has moved to reconstruct.",
                    "label": 0
                },
                {
                    "sent": "This is volume, but using this particle filter strategy we are able to obtain just one track for person and not being confused by this noise.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The results of this.",
                    "label": 0
                },
                {
                    "sent": "Have you measured in terms of accuracy and precision, with different voxel sizes?",
                    "label": 0
                },
                {
                    "sent": "Of course, the smaller the voxel size the the best accuracy and precision, but longer reach the computational time needed.",
                    "label": 0
                },
                {
                    "sent": "This algorithm was performing as the best algorithm in a clear 2007 evaluation campaign which measured different algorithms for the for 3D tracking.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we also did some combination of without the information for the tracking, but in a very basic level just combining kind of results and we want to work on Fusion at that.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the next application that I want to show.",
                    "label": 0
                },
                {
                    "sent": "It's human motion capture.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned, this means to have articulated body model an extracting the motion of this articulated body.",
                    "label": 1
                },
                {
                    "sent": "There are two approaches which are possible market or market layers or market list.",
                    "label": 1
                },
                {
                    "sent": "We have worked on both of them.",
                    "label": 0
                },
                {
                    "sent": "And we have oriented these also using particle filters.",
                    "label": 0
                },
                {
                    "sent": "But in this case, the state of space it's formed by the.",
                    "label": 1
                },
                {
                    "sent": "The link the links between the different limbs, so we measured the orientation and both of these different links, so it usually has around 22 degrees of freedom, so it's a.",
                    "label": 0
                },
                {
                    "sent": "Much more complex problem and the problem is that if you have so many degrees of freedom, you need a lot of particles for the system to work.",
                    "label": 0
                },
                {
                    "sent": "So you have to find strategies to make the algorithm faster, because otherwise it's too slow.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is an example of.",
                    "label": 0
                },
                {
                    "sent": "What can be done with markers just go.",
                    "label": 0
                },
                {
                    "sent": "Quickly through through this, but in this case you have labels in marks.",
                    "label": 0
                },
                {
                    "sent": "In some parts of the body, which of course help you with the result, but I.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Weather focus on the market less capture which uses the 3D reconstructed volumes that I show in the first slide.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So as I mentioned, if it's a particle filter strategy, we need to define the likelihood evaluation.",
                    "label": 0
                },
                {
                    "sent": "And we have to find it.",
                    "label": 0
                },
                {
                    "sent": "Is a function which matches the input data against the particle posts, taking into account again the 3D.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Turn on the color so we have the original image.",
                    "label": 0
                },
                {
                    "sent": "The box of reconstruction.",
                    "label": 0
                },
                {
                    "sent": "And this would be a particle defines a given position of the body model like the one.",
                    "label": 0
                },
                {
                    "sent": "In the future or the second one would be another particle.",
                    "label": 0
                },
                {
                    "sent": "So what we will do is to simulate the volume for each of the limbs and we intersect.",
                    "label": 0
                },
                {
                    "sent": "This volume created by every particle with the volume that we have reconstructed.",
                    "label": 0
                },
                {
                    "sent": "That's the one in blue and for instance, in this case the 2nd.",
                    "label": 0
                },
                {
                    "sent": "RAW has an error in the position of the leg, so the intersection with that volume is smaller, so the weight of this particle would be smaller.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have developed this annealing particle.",
                    "label": 0
                },
                {
                    "sent": "This particle filter with annealing in order to be faster because we need so many particles otherwise and we also do it in a logical way.",
                    "label": 0
                },
                {
                    "sent": "And discuss two advantages.",
                    "label": 0
                },
                {
                    "sent": "One, it's you're still need less particles if you do it in archical, and also when some of the parts of the body become covered, you can.",
                    "label": 0
                },
                {
                    "sent": "Use a simple model that, for instance in this the last one you could use the model without the Max.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, have video here to show this tracking, but it's outside presentation.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is the optical model.",
                    "label": 0
                },
                {
                    "sent": "The lines in the first, the red, blue and green lines are the axis of orientation, and yellow lines are the defining the particles in every year artikkel step.",
                    "label": 0
                },
                {
                    "sent": "So the first one we just have the trunk.",
                    "label": 0
                },
                {
                    "sent": "So we just fit the trunk with an ellipsoid.",
                    "label": 0
                },
                {
                    "sent": "In the second one we have legs and arms, but we don't have the joint.",
                    "label": 0
                },
                {
                    "sent": "Of the legs and arms, and in the third one we have all the motion possible, so we see that so this is carried out in these three steps.",
                    "label": 0
                },
                {
                    "sent": "So in this way we can minimize the number of particles used.",
                    "label": 0
                },
                {
                    "sent": "And in the last one we see the result of the tracking.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This work has been done in cooperation with Technion University and UPC, an attendee and they are taking a slightly different approach, which is training the different possible poses that are used.",
                    "label": 0
                },
                {
                    "sent": "For instance, they train, walking, running.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pushing kicking.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this also allows to reduce the dimensionality of the particle filters.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I'm going to it that we have this presented this in other works and this is a result of data tracking which is in this case let my limited to a different sense of actions.",
                    "label": 0
                },
                {
                    "sent": "We see here to different actions.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is basically the work that has been done in multi camera.",
                    "label": 0
                },
                {
                    "sent": "A sense, and as I.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mention I also want to show some other works that have been developed within the context of the team, but without going into details.",
                    "label": 0
                },
                {
                    "sent": "One of the works is discussed in this case in.",
                    "label": 0
                },
                {
                    "sent": "Today it's for moving object detection and classification.",
                    "label": 1
                },
                {
                    "sent": "This is results from Bilkent University.",
                    "label": 0
                },
                {
                    "sent": "So in this case, apart from detecting the foreground of the scene, they classify in this case between human or human group.",
                    "label": 0
                },
                {
                    "sent": "They can also classify vehicles if there are vehicles around.",
                    "label": 0
                },
                {
                    "sent": "It's based on the contour of the forum, detected an.",
                    "label": 0
                },
                {
                    "sent": "Vector machines.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And another of the work that has been done.",
                    "label": 0
                },
                {
                    "sent": "It's 'cause I have focused the presentation on the.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On person, but we have also a part of the team on phase analysis and this is a work from University of Amsterdam for eye tracking and this is a video showing the eye tracking results in different situations.",
                    "label": 0
                },
                {
                    "sent": "The green dot marked the center of the detected eyes.",
                    "label": 0
                },
                {
                    "sent": "We'll see it different.",
                    "label": 0
                },
                {
                    "sent": "So as I mentioned, these are other parts of the team.",
                    "label": 0
                },
                {
                    "sent": "Just wanted to show some videos.",
                    "label": 0
                },
                {
                    "sent": "Not to focus only on this multi camera part.",
                    "label": 0
                },
                {
                    "sent": "It's it's robust or cushions, and there's also a part which is showing with different people.",
                    "label": 0
                },
                {
                    "sent": "And or fast movements.",
                    "label": 0
                },
                {
                    "sent": "The motion is faster.",
                    "label": 0
                },
                {
                    "sent": "So Nicole can give you more details about this.",
                    "label": 0
                },
                {
                    "sent": "Notes above the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Finally, with multiple subjects and changing the illumination.",
                    "label": 0
                },
                {
                    "sent": "Still works with three or four people.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the end of the presentation.",
                    "label": 0
                },
                {
                    "sent": "Is there any questions?",
                    "label": 0
                },
                {
                    "sent": "Quite a wide range.",
                    "label": 0
                },
                {
                    "sent": "We could see some foreground background segmentation, but these people walking around the table.",
                    "label": 0
                },
                {
                    "sent": "We've seen quite some holes in the people standing for nationwide.",
                    "label": 0
                },
                {
                    "sent": "Otherwise.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and the reason is that we use very simple models for modeling the background.",
                    "label": 0
                },
                {
                    "sent": "One Goshen, so we just model the mean and the volumes of discussion.",
                    "label": 0
                },
                {
                    "sent": "So when, for instance there is a OK, you move around here and there are these black lines on the background and your dresser in dark color.",
                    "label": 0
                },
                {
                    "sent": "So when you move in front of this dark lines this will be detected as background because your model for the bathroom is very simple, right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "Why we use this simple model?",
                    "label": 0
                },
                {
                    "sent": "Because we want it to work in real time.",
                    "label": 0
                },
                {
                    "sent": "We still need one computer for every camera, but otherwise we can not run real time for this.",
                    "label": 0
                },
                {
                    "sent": "The idea is that then we when we combine the multiple cameras, this kind of effects are solved.",
                    "label": 0
                },
                {
                    "sent": "We also developed the tracking.",
                    "label": 0
                },
                {
                    "sent": "'cause this is only the forum detection, then we have the tracking part.",
                    "label": 0
                },
                {
                    "sent": "So we developed the tracking in order to be robust to this kind of effects.",
                    "label": 0
                },
                {
                    "sent": "Compromise always.",
                    "label": 0
                },
                {
                    "sent": "Basement.",
                    "label": 0
                },
                {
                    "sent": "I just wondered if you're multiple person particle filtering.",
                    "label": 0
                },
                {
                    "sent": "Do you do automatic initiation and deletion of targets?",
                    "label": 0
                },
                {
                    "sent": "Yes, in Java, target is initialized when a volume of size compatible with a person is found.",
                    "label": 0
                },
                {
                    "sent": "As we have the 3D information because we have calibrated cameras and so on, we know which is the size of a person in the room.",
                    "label": 0
                },
                {
                    "sent": "So when a person of sorry when a volume of this size is detected, we initialize the track.",
                    "label": 0
                },
                {
                    "sent": "We also then remove tracks which just appear for a few frames or things like that.",
                    "label": 0
                },
                {
                    "sent": "OK, and do you do the tracking separately with a separate particle filter for each person?",
                    "label": 0
                },
                {
                    "sent": "Sorry, sorry.",
                    "label": 0
                },
                {
                    "sent": "Do you do the tracking independently for each person or do you have a joint stacked particle filter?",
                    "label": 0
                },
                {
                    "sent": "No no no.",
                    "label": 0
                },
                {
                    "sent": "In order to keep the complexity of the problem smaller we have a truck, so that's a particle filter for every person.",
                    "label": 0
                },
                {
                    "sent": "So we initialize a particle filter every time that we detect the volume of the right size.",
                    "label": 0
                },
                {
                    "sent": "But then what we define is interaction models between particle filters so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so when waiting the.",
                    "label": 0
                },
                {
                    "sent": "The particles are to know the weight of a given particle when we have OK particle for us we find center and size.",
                    "label": 0
                },
                {
                    "sent": "Which is defined by an ellipsoid.",
                    "label": 0
                },
                {
                    "sent": "So when these two ellipsoids intersect.",
                    "label": 0
                },
                {
                    "sent": "We don't compute the contribution of the boxes which are in the intersection.",
                    "label": 0
                },
                {
                    "sent": "So that we don't, because otherwise at the end we would merge the tool attraction so we don't allow them to merge.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks.",
                    "label": 0
                },
                {
                    "sent": "Further questions.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}