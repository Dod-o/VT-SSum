{
    "id": "t6aiqja7umdsfbkrwrrh3v3oks6dlrvr",
    "title": "An Integrated Machine Learning Approach to Stroke Prediction",
    "info": {
        "author": [
            "Honglak Lee, Department of Electrical Engineering and Computer Science, University of Michigan"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Artificial Intelligence",
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/kdd2010_lee_imla/",
    "segmentation": [
        [
            "OK, good morning.",
            "Thank you for coming to this talk.",
            "I'm home lately from Stanford University.",
            "Today I'm going to talk about an integrated machine learning approach for stroke prediction and this is joint work with Aditya Khosla, Hucow, Cliffline Sequential and joining."
        ],
        [
            "Oh so here is a brief loud outline of this talk, so I'll first talk about the motivation of this research and present our algorithm and experimental results and finish."
        ],
        [
            "Summary"
        ],
        [
            "So the problem that we're interested is stroke prediction and stroke prediction is a very important problem.",
            "Cause stroke is actually the third leading cause of death in the United States.",
            "And also it's a leading cause of long-term disability.",
            "In order to tackle this problem, it is very important to identify and discover risk factors and also we need to discover good prediction algorithms.",
            "However, current research on stroke is mostly based on simple statistical models, so the goal of this work is to bring machine learning methods to stroke prediction and improve its performance."
        ],
        [
            "First, I would like to talk about risk factors.",
            "So risk factors are traditionally discovered by just clinical studies, for example, doctors and medical researchers have found that there are many risk factors for stroke.",
            "For example, age, prior stroke, blood pressure, hypertension, and cigarette smoking, and so on."
        ],
        [
            "The second aspect of this problem is prediction algorithm, and most researchers in this field have relied on model called Cox proportional Hazard model, and this is actually one of the most widely used statistical method method in medical research applied to many.",
            "Apply to predicting many various diseases.",
            "The main idea of this model is to model the hazard function at time T as a function of time, and also as a function of some feature values."
        ],
        [
            "So there are a number of research that does stroke prediction.",
            "An most of this research relies on basically a small number of features, essentially just using manually selected features and also these are very small in terms of numbers.",
            "Also, the prediction method is somewhat limited because they just use Cox proportional hazard regression model so they don't take advantage of other powerful machine learning methods."
        ],
        [
            "So compared to previous approaches.",
            "We are trying to enlarge the scope of this problem to up by applying other machine learning methods.",
            "For example, we instead of using just 20 features, we are going to just use 1000 features that are features that are available to us.",
            "However, not all of these thousand features will be useful for predicting stroke, so we will do automatic feature selection.",
            "And then we are based on this selected features.",
            "We will apply some other machine learning methods.",
            "For example, using support vector machines."
        ],
        [
            "So here is just a cartoon overview about our approach.",
            "So first, in order to deal with the missing data we will evaluate different methods for data imputation and then we will use feature selection to select useful features and then finally apply prediction algorithm."
        ],
        [
            "So in more detail.",
            "We we used several several missing value imputation algorithms.",
            "For example, just simply using mean or median values of the missing feature.",
            "Missing feature values, median values of the observed feature values to replace the missing values or just using linear regression or M for inferring these missing values.",
            "For feature selection, we also used several algorithms, for example forward feature selection, L1 regularised logistic regression, which is actually one of the most widely used feature selection algorithm.",
            "And also we used conservative mean feature selection which is a new algorithm that is developed in our paper.",
            "Finally, we also evaluate different prediction algorithms.",
            "For example, support vector machines and also margin based sensor regression, which is a new method that we developed in this paper.",
            "So."
        ],
        [
            "I will give you a very brief explanation about the first algorithm, which is called conservative mean feature selection.",
            "The main idea of this.",
            "This algorithm is actually very simple.",
            "Essentially, we want to.",
            "Learn we want to measure the discriminant power of each individual feature.",
            "So what we will typically do is just pick one feature and then run some classifier and then compute the area under the RC curve and average over 10 volts.",
            "However, what we found is that in the in the problem of stroke prediction the number of positive example is very small.",
            "For example, it's only about 6% of the entire training data is, so it's very skewed and also the positive examples are fairly heterogeneous, which means that if we split depending on how we split randomly, actually the this RC curve area may fluctuate a lot.",
            "So the intuition here is that instead of just using the mean value.",
            "We just take account into this fluctuation, so we basically subtract the standard deviation of these fluctuations over the folds and then use this as a estimate of these discriminative power and then we use these to rank the feature and then select the appropriate number of features and the more details are in the paper."
        ],
        [
            "Next I'm going to describe about a new algorithm called margin based sensor regression.",
            "So here the idea is that we have some information about timing of stroke and the problem is that whether it's this person have a stroke within the next five years or not.",
            "So when the stroke happens we want to predict it as accurately as possible with the timing as well.",
            "But when the stroke doesn't happen, we just want to predict it as a negative.",
            "So here is the formulation.",
            "So given the timing T We convert this timing.",
            "Through our new variable Z, which is essentially just taking our inverse and map it to some values such that positive values means stroke and negative values means non stroke and we want to predict these values as a function of features.",
            "So first idea is that we want to predict these positive examples as closely as possible, but only if the stroke happens.",
            "And then we also want to classify the negative examples as negative.",
            "So ideally we just want these prediction output to be negative for the negative non stroke examples.",
            "However, a nice concept from machine learning is basically adding a concept of margin.",
            "So instead of just pushing it below 0 we want to.",
            "We may want to push it actually a little bit further from further from zero and actually it turns out that improves the performance quite a bit."
        ],
        [
            "And the formulation can be written as a convex optimization, which is essentially just a combination for tradeoff between the regression error, 4 stroke events and we want to predict the timing as accurately as possible.",
            "And also we want to classify the non stroke or.",
            "Negative examples with some soft margin constraints."
        ],
        [
            "OK, so I'm going to talk about it."
        ],
        [
            "Our mental setup and results.",
            "So we used cardiovascular heart study data, which is one of the most widely used benchmark for stroke prediction.",
            "So this is the annual examination for elderly people which was conducted more than 10 years.",
            "So after preprocessing we have about eight 800 features and 5000 examples and the task here is to use the first year measurement as features and predict whether this person will have a stroke in next five years or not."
        ],
        [
            "So here is a summary result.",
            "So we first evaluated different data imputation method and it actually turned out that just simply using the median value.",
            "So substituting the median value for.",
            "Medium value of the absurd feature values as work just the best."
        ],
        [
            "And here is the result evaluating different or feature selection algorithms and also different prediction algorithms.",
            "And we found that combining the conservative mean, feature selection and margin buying sensor regression gave the best performance.",
            "And compared to the traditional method, using Cox proportional hazard model and just manually selected 16 feature, our algorithm gives about 15% reduction in error."
        ],
        [
            "And similar results holds for another measure called concordance index, but.",
            "The details are in the paper, so I will skip the explain."
        ],
        [
            "Awesome.",
            "And finally we are using our algorithm.",
            "We found some potential risk factors which are not previously covered in in the literature, so this might be useful for further investigation and may turn out to be.",
            "Actually."
        ],
        [
            "Inspectors, so in summary, we presented an integrated approach for stroke prediction by combining imputation, feature selection and prediction.",
            "And we presented a new algorithms for feature selection and prediction an which outperforms the existing method and also we discussed how this method can be used for discovering new potential respecters.",
            "Thank you very."
        ],
        [
            "It's an like to take any questions.",
            "Questions.",
            "One question, what did you do to ensure that you weren't overfitting?",
            "So we used cross validation so this the parameters were.",
            "And as a cross validation an we measure the test data test error and it's repeated over many times to make it more statically significant.",
            "Thank you very much, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, good morning.",
                    "label": 0
                },
                {
                    "sent": "Thank you for coming to this talk.",
                    "label": 0
                },
                {
                    "sent": "I'm home lately from Stanford University.",
                    "label": 0
                },
                {
                    "sent": "Today I'm going to talk about an integrated machine learning approach for stroke prediction and this is joint work with Aditya Khosla, Hucow, Cliffline Sequential and joining.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh so here is a brief loud outline of this talk, so I'll first talk about the motivation of this research and present our algorithm and experimental results and finish.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Summary",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the problem that we're interested is stroke prediction and stroke prediction is a very important problem.",
                    "label": 0
                },
                {
                    "sent": "Cause stroke is actually the third leading cause of death in the United States.",
                    "label": 1
                },
                {
                    "sent": "And also it's a leading cause of long-term disability.",
                    "label": 0
                },
                {
                    "sent": "In order to tackle this problem, it is very important to identify and discover risk factors and also we need to discover good prediction algorithms.",
                    "label": 0
                },
                {
                    "sent": "However, current research on stroke is mostly based on simple statistical models, so the goal of this work is to bring machine learning methods to stroke prediction and improve its performance.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First, I would like to talk about risk factors.",
                    "label": 0
                },
                {
                    "sent": "So risk factors are traditionally discovered by just clinical studies, for example, doctors and medical researchers have found that there are many risk factors for stroke.",
                    "label": 1
                },
                {
                    "sent": "For example, age, prior stroke, blood pressure, hypertension, and cigarette smoking, and so on.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second aspect of this problem is prediction algorithm, and most researchers in this field have relied on model called Cox proportional Hazard model, and this is actually one of the most widely used statistical method method in medical research applied to many.",
                    "label": 1
                },
                {
                    "sent": "Apply to predicting many various diseases.",
                    "label": 1
                },
                {
                    "sent": "The main idea of this model is to model the hazard function at time T as a function of time, and also as a function of some feature values.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are a number of research that does stroke prediction.",
                    "label": 1
                },
                {
                    "sent": "An most of this research relies on basically a small number of features, essentially just using manually selected features and also these are very small in terms of numbers.",
                    "label": 1
                },
                {
                    "sent": "Also, the prediction method is somewhat limited because they just use Cox proportional hazard regression model so they don't take advantage of other powerful machine learning methods.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So compared to previous approaches.",
                    "label": 0
                },
                {
                    "sent": "We are trying to enlarge the scope of this problem to up by applying other machine learning methods.",
                    "label": 0
                },
                {
                    "sent": "For example, we instead of using just 20 features, we are going to just use 1000 features that are features that are available to us.",
                    "label": 0
                },
                {
                    "sent": "However, not all of these thousand features will be useful for predicting stroke, so we will do automatic feature selection.",
                    "label": 1
                },
                {
                    "sent": "And then we are based on this selected features.",
                    "label": 0
                },
                {
                    "sent": "We will apply some other machine learning methods.",
                    "label": 1
                },
                {
                    "sent": "For example, using support vector machines.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is just a cartoon overview about our approach.",
                    "label": 0
                },
                {
                    "sent": "So first, in order to deal with the missing data we will evaluate different methods for data imputation and then we will use feature selection to select useful features and then finally apply prediction algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in more detail.",
                    "label": 0
                },
                {
                    "sent": "We we used several several missing value imputation algorithms.",
                    "label": 1
                },
                {
                    "sent": "For example, just simply using mean or median values of the missing feature.",
                    "label": 0
                },
                {
                    "sent": "Missing feature values, median values of the observed feature values to replace the missing values or just using linear regression or M for inferring these missing values.",
                    "label": 1
                },
                {
                    "sent": "For feature selection, we also used several algorithms, for example forward feature selection, L1 regularised logistic regression, which is actually one of the most widely used feature selection algorithm.",
                    "label": 1
                },
                {
                    "sent": "And also we used conservative mean feature selection which is a new algorithm that is developed in our paper.",
                    "label": 0
                },
                {
                    "sent": "Finally, we also evaluate different prediction algorithms.",
                    "label": 0
                },
                {
                    "sent": "For example, support vector machines and also margin based sensor regression, which is a new method that we developed in this paper.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will give you a very brief explanation about the first algorithm, which is called conservative mean feature selection.",
                    "label": 1
                },
                {
                    "sent": "The main idea of this.",
                    "label": 0
                },
                {
                    "sent": "This algorithm is actually very simple.",
                    "label": 0
                },
                {
                    "sent": "Essentially, we want to.",
                    "label": 0
                },
                {
                    "sent": "Learn we want to measure the discriminant power of each individual feature.",
                    "label": 1
                },
                {
                    "sent": "So what we will typically do is just pick one feature and then run some classifier and then compute the area under the RC curve and average over 10 volts.",
                    "label": 0
                },
                {
                    "sent": "However, what we found is that in the in the problem of stroke prediction the number of positive example is very small.",
                    "label": 0
                },
                {
                    "sent": "For example, it's only about 6% of the entire training data is, so it's very skewed and also the positive examples are fairly heterogeneous, which means that if we split depending on how we split randomly, actually the this RC curve area may fluctuate a lot.",
                    "label": 0
                },
                {
                    "sent": "So the intuition here is that instead of just using the mean value.",
                    "label": 0
                },
                {
                    "sent": "We just take account into this fluctuation, so we basically subtract the standard deviation of these fluctuations over the folds and then use this as a estimate of these discriminative power and then we use these to rank the feature and then select the appropriate number of features and the more details are in the paper.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next I'm going to describe about a new algorithm called margin based sensor regression.",
                    "label": 0
                },
                {
                    "sent": "So here the idea is that we have some information about timing of stroke and the problem is that whether it's this person have a stroke within the next five years or not.",
                    "label": 0
                },
                {
                    "sent": "So when the stroke happens we want to predict it as accurately as possible with the timing as well.",
                    "label": 0
                },
                {
                    "sent": "But when the stroke doesn't happen, we just want to predict it as a negative.",
                    "label": 1
                },
                {
                    "sent": "So here is the formulation.",
                    "label": 1
                },
                {
                    "sent": "So given the timing T We convert this timing.",
                    "label": 0
                },
                {
                    "sent": "Through our new variable Z, which is essentially just taking our inverse and map it to some values such that positive values means stroke and negative values means non stroke and we want to predict these values as a function of features.",
                    "label": 1
                },
                {
                    "sent": "So first idea is that we want to predict these positive examples as closely as possible, but only if the stroke happens.",
                    "label": 0
                },
                {
                    "sent": "And then we also want to classify the negative examples as negative.",
                    "label": 0
                },
                {
                    "sent": "So ideally we just want these prediction output to be negative for the negative non stroke examples.",
                    "label": 0
                },
                {
                    "sent": "However, a nice concept from machine learning is basically adding a concept of margin.",
                    "label": 0
                },
                {
                    "sent": "So instead of just pushing it below 0 we want to.",
                    "label": 0
                },
                {
                    "sent": "We may want to push it actually a little bit further from further from zero and actually it turns out that improves the performance quite a bit.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the formulation can be written as a convex optimization, which is essentially just a combination for tradeoff between the regression error, 4 stroke events and we want to predict the timing as accurately as possible.",
                    "label": 1
                },
                {
                    "sent": "And also we want to classify the non stroke or.",
                    "label": 0
                },
                {
                    "sent": "Negative examples with some soft margin constraints.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm going to talk about it.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our mental setup and results.",
                    "label": 0
                },
                {
                    "sent": "So we used cardiovascular heart study data, which is one of the most widely used benchmark for stroke prediction.",
                    "label": 1
                },
                {
                    "sent": "So this is the annual examination for elderly people which was conducted more than 10 years.",
                    "label": 1
                },
                {
                    "sent": "So after preprocessing we have about eight 800 features and 5000 examples and the task here is to use the first year measurement as features and predict whether this person will have a stroke in next five years or not.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is a summary result.",
                    "label": 0
                },
                {
                    "sent": "So we first evaluated different data imputation method and it actually turned out that just simply using the median value.",
                    "label": 1
                },
                {
                    "sent": "So substituting the median value for.",
                    "label": 1
                },
                {
                    "sent": "Medium value of the absurd feature values as work just the best.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here is the result evaluating different or feature selection algorithms and also different prediction algorithms.",
                    "label": 0
                },
                {
                    "sent": "And we found that combining the conservative mean, feature selection and margin buying sensor regression gave the best performance.",
                    "label": 1
                },
                {
                    "sent": "And compared to the traditional method, using Cox proportional hazard model and just manually selected 16 feature, our algorithm gives about 15% reduction in error.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And similar results holds for another measure called concordance index, but.",
                    "label": 0
                },
                {
                    "sent": "The details are in the paper, so I will skip the explain.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Awesome.",
                    "label": 0
                },
                {
                    "sent": "And finally we are using our algorithm.",
                    "label": 1
                },
                {
                    "sent": "We found some potential risk factors which are not previously covered in in the literature, so this might be useful for further investigation and may turn out to be.",
                    "label": 1
                },
                {
                    "sent": "Actually.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Inspectors, so in summary, we presented an integrated approach for stroke prediction by combining imputation, feature selection and prediction.",
                    "label": 1
                },
                {
                    "sent": "And we presented a new algorithms for feature selection and prediction an which outperforms the existing method and also we discussed how this method can be used for discovering new potential respecters.",
                    "label": 0
                },
                {
                    "sent": "Thank you very.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's an like to take any questions.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "One question, what did you do to ensure that you weren't overfitting?",
                    "label": 0
                },
                {
                    "sent": "So we used cross validation so this the parameters were.",
                    "label": 0
                },
                {
                    "sent": "And as a cross validation an we measure the test data test error and it's repeated over many times to make it more statically significant.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much, thank you.",
                    "label": 0
                }
            ]
        }
    }
}