{
    "id": "fev44idmgdlxchvkvudjl4b7cini3brj",
    "title": "Mind the (Language) Gap- Generation of Multilingual Wikipedia Summaries from Wikidata for ArticlePlaceholders",
    "info": {
        "author": [
            "Lucie-Aim\u00e9e Kaffee, University of Southampton"
        ],
        "published": "July 10, 2018",
        "recorded": "June 2018",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2018_kaffee_wikipedia_summaries/",
    "segmentation": [
        [
            "Yeah hi, I'm Lucy.",
            "I'm in the University of Southampton and together with Pavlos who's also in Southampton and Hardy from the language Laboratoire Uber Korea.",
            "We worked on newer generation of multilingual Wikipedia summaries from wiki data for article placeholders.",
            "If you don't know those words, I'll explain them in a."
        ],
        [
            "So the idea came up that we have this problem in Wikipedia, especially that in English Wikipedia we have almost 6 million articles at the moment, but Arabic Wikipedia, which is the fifth most spoken language in the world with a low percentage of bilingual speakers, we have only around 600,000 articles, right?",
            "And you have this problem in Wikipedia.",
            "If you have low content, you don't get readers, and if you don't have readers you don't have editors that can create those.",
            "Articles that would attract more readers and you're stuck.",
            "Basically in a vicious cycle.",
            "So what can you do to break this cycle?",
            "We thought well, if we need more content we would get those readers, which could be the editors and so on.",
            "So why not generate content?"
        ],
        [
            "Uh, while we have little content on Wikipedia in different languages, we have a lot of resources in wiki data.",
            "Wiki data is a knowledge base, maintain and edited by community of users and we have around 48 million items on wiki data and each item can be labeled and over 400 languages.",
            "And as we showed in a previous study, the varieties of languages covered by wiki data is pretty high."
        ],
        [
            "So that is what items in Wiki data look like.",
            "Their RDF representation of how the multilinguality looked like.",
            "So basically each entity has a unique identifier.",
            "That's language independent.",
            "Items have QID's properties of pid's and their connected via their triples, or they are connected with.",
            "The RDF is labeled property.",
            "Two different language labels."
        ],
        [
            "So now the question is."
        ],
        [
            "How do we get this content from Wiki data that is multilingual and that's very various an already existing into Wikipedia where we looked at her into a project that already is."
        ],
        [
            "Exists, which is the article placeholder.",
            "Those article placeholders display triples on Wikipedia and a tabular form and they are dynamically generated, meaning if something is updated on wiki data, it is automatically updated in Wikipedia as well.",
            "So it has a huge advantage over the creation of Subparticles, which except for example happens in Cebuano, Wikipedia and a big style where someone just imports a lot of information and it's just static and the community is overwhelmed and cannot update it.",
            "Those article placeholders are currently deployed in 14 underresourced.",
            "Wikipedia's including Esperanto, but also Gujarati, Haitian, Creole and auto for example."
        ],
        [
            "This is what an Arctic place order looks like, so it's structured data.",
            "As I said on an entity, so it's literally the triples of the entity.",
            "Pulls into Wikipedia."
        ],
        [
            "What we want to do now is enriching those article placeholders with sexual summaries generated from the wiki data triple.",
            "So basically summarizing a triple, making it, making the whole set up a lot more user friendly and also a good starting point for editors because just seeing pure facts on a Wikipedia page is not really engaging, nor is it a good starting point for someone to actually write content from it.",
            "We tested it on Arabic and Esperanto, but in theory it is.",
            "Usable on any small language that has wiki data items and Wikipedia articles existing."
        ],
        [
            "We chose Esperanto in this case because so it's an artificially made language.",
            "It is really easy to learn for humans as well.",
            "There for us for machines and, but we have an engaged Wikipedia community.",
            "We could reach out to, and it's just a good starting point to see if what we want to do is possible at the same time we chose Arabic as I said, because it's severely underserved.",
            "It's widely spoken, but not really well covered and.",
            "It's a morphologically, really rich language, so it not only has a different script, but it has a huge vocabulary compared to Esperanto anyway.",
            "But even compared to English."
        ],
        [
            "So this is how the input to our system looks like.",
            "We get from the article placeholder that ripples from Ricky data in our case, for example for media, and we take all the triples where the main entity we want to generate a sentence for is either the subject or the object of the triple."
        ],
        [
            "And we give this to our model.",
            "So as I said, we take the triples from the Arctic, a placeholder set up, and we generate for the article place order sentence.",
            "We use a feedforward architecture that encodes the triple from the article placeholder in a vector of fixed dimensionality and the decoders RNN based and it generates summaries one token at a time.",
            "We based the system on previous work of hours, which was state of the art.",
            "One sentence in the biography domain in English."
        ],
        [
            "So now compared to English especially, we have one very severe problem.",
            "We have a lack of data, so we have a lot of out of vocabulary words meaning on training time.",
            "Though our system did not see those words yet.",
            "So to overcome this technical problem, we introduced something called property placeholder."
        ],
        [
            "So in our case, for example, if we have those entities from wiki data, we have triples.",
            "We have the properties.",
            "As I said before, everything has a unique identifier on wiki data, and we built a training data set."
        ],
        [
            "We're relying those triples to the first sentence Wikipedia for to the first sentence of a Wikipedia article.",
            "And now, for example, Calesita is a word that is most likely not been seen on training time because it's very specific for our main entity here."
        ],
        [
            "So what we do instead of just letting the network generate garbage or an unknown token, we introduce a new set of special tokens, which are those property placeholders, meaning we align the objects and replace the obj."
        ],
        [
            "Note in the sentence with the properties to which point to the object.",
            "So after the decoding step of the network we can replace them with appropriate noun from the triple.",
            "Yeah, so the network now is able instead of generating out of vocabulary words to when it want to say is something is ataxia taxonomia normal, it can just put those special tokens instead of having to know the word.",
            "So those are a few examples of what we generate, as I said."
        ],
        [
            "We generate in Arabic and in Esperanto, because Esperanto is easier to learn.",
            "Arabic is a bit more complex."
        ],
        [
            "We do two types of evaluation.",
            "The first one, the first type to see if our network works, and as a good starting point is we use automatic evaluation.",
            "We compared to two baselines.",
            "The first one is machine translation, something that is already used to an extent in Wikipedia, and the second one is temperate retrieval.",
            "As it's like widely used already for text generation, those baselines in our system we compare on three different of automatic evaluation metrics.",
            "One is blue, one to four mature and druschel."
        ],
        [
            "And we can say that on all metrics we could outperform our base."
        ],
        [
            "Science.",
            "And as a second step, then so in the energy community.",
            "It's very known that those automatic evaluation metrics are very limited, so meaning.",
            "Yes, meaning that.",
            "It does not necessarily expect it does not express what a user would say.",
            "What a reader an actual reader would say.",
            "Oh, that's embarrassing.",
            "So what we do is we actually test with the real communities we are trying to address and we're trying to serve.",
            "So we did two 215 days online service aimed one at readers and one at editors in Esperanto and Arabic respectively.",
            "And yeah, as I said, we tried to aim at testing with the actual communities were trying to serve and therefore reach out on their platforms and trying to engage them.",
            "Yes, I said we have two groups, the readers."
        ],
        [
            "And the editors we recruited on different forums.",
            "So first of all we recruited on social media for the readers.",
            "So anyone that would speak the language fluently in a rabbit case, native speakers in Esperanto case, we don't have native speakers, so we look for any kind of fluent speakers, will reach out on Reddit for Esperanto and Twitter and Facebook and two researchers.",
            "We know that our RBC speaking.",
            "In the second step, we reached out on the editors mailing lists and the community pages on Wikipedia, Wikipedia themselves.",
            "For the editors, this was a really interesting experience, and I think one of the coolest experience I had so far in the research world.",
            "Because Wikipedia communities, especially for underserved languages, get so excited if you show them what you want to do.",
            "So, for example, we sent out this email to the editing list and we were not very involved with the rabbit community.",
            "I don't speak Arabic at all, but the Arabic Wikipedia community decided to.",
            "Put our survey link too."
        ],
        [
            "With the opening remarks of the Ricky Arabia, which is the Arabic speaking community event?",
            "For editors of Wikipedia."
        ],
        [
            "So first we work on the reader evaluation.",
            "The first thing we ask, which is pretty standard as the fluency, so it's the text understandable and grammatically correct with scores from zero to 6, and then the appropriateness which, so which is focused on our task, does the summary feel like a Wikipedia article?",
            "We use three different sources to compare to first of all our own generated sentences.",
            "Obviously the set of original Wikipedia sentences and a set of new sentences.",
            "The participation was OK."
        ],
        [
            "Not better than we expected, but what we learned from this especially was we gave the readers as well as the editors.",
            "As you will see later, much too many sentences because it's not a crowdsourcing experiment as people that actually get involved with us.",
            "So as you can see, we have a very low rate of participants that actually contributed to over 50% of the sentences, which was OK. We told them you could stop the experiment at anytime, and anything annotated would go in two hours."
        ],
        [
            "Survey and of course, this is basically what it looks like for the rabbit community, so the upper one is the instructions for the fluency.",
            "The lower one is for.",
            "The lower one was for the appropriateness, so we have the scores from zero to six.",
            "We have the sentence they should evaluate, and the instructions respectively."
        ],
        [
            "And what we can see is we scored relatively well.",
            "We have very high percentage of people thinking that our sentences would fit into Wikipedia.",
            "They clearly can differentiate them from the news as well as the fluency of our sentences is surprisingly high as well.",
            "So we score in orebic better than the actual Wikipedia summaries, which is kind of surprising.",
            "And in Esperanto we score better than the new sentences, where we assume that that's probably because the news in Esperanto.",
            "Even though it's a big news outlet, they use some form of translation tools as well."
        ],
        [
            "In the second step, we."
        ],
        [
            "Work with the editor.",
            "So this was really important to us because the article placeholders not only there to give new information, but what we want in the end is to prepare for people to actually come and make real articles of what we give them as a first step, right?",
            "So editors were asked to edit the article starting from our summary and the corresponding triple.",
            "So basically the layout as we would have it in Artica place order later on and give us two to three sentences.",
            "Basically an introduction of a real Wikipedia article and we measured how much."
        ],
        [
            "Text was reused.",
            "The participation was not too bad, not too high, and as I said, what we really learned was 30 sentences to start with is much too much content.",
            "I was actually surprised that we had two people that went the whole way and annotated, which started writing articles for over 30s of over 15 sentences."
        ],
        [
            "So this is what our setup would look like.",
            "It's our University and sternal system, that's why it looks a bit chunky, but we have an instruction in the on the top we have the generated summary.",
            "We have regulator triples and editing field that's sadly left aligned because you know, right aligning computers.",
            "Not that nice yet."
        ],
        [
            "So we measured how much text was we used by editors.",
            "We used the greedy string tiling algorithm for that, which is actually derived from plagiarism detection.",
            "That's where it's mainly used.",
            "It's the advantage over the Levenshtein distance.",
            "If you look at editing distances that you can detect, black hole blocks moved and you have this minimum match length factor to ignore copying off so small Subs, subsequences in the text.",
            "We divided this our results into three parts wholly derived, partially derived, non derived to say how much of our sentences were reused actually."
        ],
        [
            "And we can see that in Esperanto, alot of sentences were wholly or partially derived.",
            "A huge chunk of text or just left as it is, especially in Esperanto in Arabic, is still a high percentage of wholly and partially derived, however wholly derived us a lot smaller.",
            "We can actually explain this by the fact that, as I said, has parent has a much smaller vocabulary, meaning that we have a lot less out of vocabulary words.",
            "So what we can see in Arabic, especially what users do to get from Holy Direct impact to partially derived.",
            "Is they will replace the special token unknown words which we still have another text, which is something very interesting for us to learn from.",
            "So we really have to take care of how can we cover better underserved languages and how can we make our network generate the text comprehensive."
        ],
        [
            "Clean.",
            "Conclusively, we can say that Wikipedia's article place order is a very good case use case for those energy tasks we can, and generally catering for readers and editors knees needs is the way to go.",
            "When we work on energy tasks and especially in the case of Wikipedia working with the community is really important rather than just doing automatic evaluation because it tells us a lot less of the story of what we want to know and experience than the actual evaluation with the communities."
        ],
        [
            "Yeah, so we can say that our encoder decoder model is able to generate high quality summaries and underserved languages.",
            "And our approach works in multiple languages and was tested for languages with very different properties.",
            "So Arabic, which is very hard and morphologically rich but has a lot of articles compared to Esperanto which has less articles but isn't a lot easier to acquire language.",
            "And we can say that our generated summary seem useful as a starting point for article creation.",
            "Thank you very much.",
            "Yeah, so that's that's another point.",
            "I wanted to make in this slide.",
            "Sorry that the the community was quite happy about it, so we got invited to the Celtic Knot conference which is the Wikimedia Conference for Small Languages as well as we're going to be featured on the Wikimedia Research Showcase, 'cause they thought it was quite interesting.",
            "Thank you Lucy.",
            "I think we have quite some time for questions."
        ],
        [
            "Hi, thanks for the nice talk.",
            "I have a question like are you aware of this tool by Magnus Man Scale?",
            "It is called Autodesk like Auto description.",
            "Yeah did you think you also generates it in multiple language?",
            "Those automatic descriptions?",
            "Wouldn't that have been a good baseline for you?",
            "Also like to compare two.",
            "Yeah so basically what he does is template based descriptions right?",
            "So what we said?",
            "Well we don't go with template based and we we have this template based its information retrieval based.",
            "Originally, templates retrieval baseline to find out how it works well, we said, well, we don't want to have template based generation is that we would have the property problem that the Community would focus on creating those templates instead of the actual work which is creating articles right?",
            "So, especially when we talk about very small communities are cases, Orebic is still a relatively big community, right?",
            "But if we talk for example about Haitian Creole, they have two active editors.",
            "I would prefer that those two active editors go around and actually create the articles and the other advantage of newer network generations.",
            "Obviously the text is less repetitive, right?",
            "So you don't just have a template that always says the same, but the network can adjust to the content of the triples.",
            "But that doesn't.",
            "Yeah like.",
            "But why didn't you compare it?",
            "I saw it too to the actual scores you mean like?",
            "Yeah, like you had a really nice setup, user evaluation and everything and that would have been like just like another system to compare to.",
            "It's true.",
            "It's a very good point.",
            "I'm not aware of how many domains the the Autodesk can cover in Esperanto and Arabic.",
            "That's one of the limitations obviously of template base, so I will have to look into that.",
            "OK, thanks, thank you.",
            "I'm wondering whether the algorithm can go wrong sometimes.",
            "And produce a sentence that is factually wrong by.",
            "Interpolating something wrong?",
            "Yeah, so so this could actually happen.",
            "What we found is this happens mostly because of out of vocabulary words.",
            "So we tested the system in English too.",
            "It's with the crowd experiment in the previous work to how much factually wrong sentences does generate.",
            "It's relatively low, but if we look at our system it's usually generates factually wrong things because it doesn't know the word.",
            "So we had one example where it generates the wrong country, not because it doesn't know it.",
            "Country has to go in there, but it didn't learn the word for the country yet, so just use the word for different country that it's all very often.",
            "So it's mainly a problem of lack of data basically.",
            "Did you also get comments about the amount of content that is that is available there?",
            "So when I looked at these, I think Autodesk they're called descriptions.",
            "They're usually very very, very, very short, so this is partly due to the fact that it's template based and it only represents what is their representable by the templates.",
            "But probably it also reflects a shortage of information, so that is something we didn't specifically ask for.",
            "A good question though.",
            "The thing is, as we learn on those, Wikipedia's are sentences.",
            "LR as long usually as average sentence in that domain.",
            "In that, Wikipedia would be.",
            "It ends.",
            "For example in Esperanto, especially to be relatively short, as the examples I showed earlier are relatively long, because in that in the chemical domain editors just tended to make longer sentences as introductionary sentence.",
            "But we have a lot of sentences generated that are just city.",
            "Is a city in country right?",
            "So it is a lot of those are relatively short to this point, which is something we cannot influence because we said we really want to learn how the Wikipedia community is right in this domain, right?",
            "So in the different domain.",
            "So it really depends on them.",
            "In the end you are a general question about your opinion on why the participation.",
            "OK, you said you were surprised it was there were maybe more people than you expected, but they were still very few.",
            "Just in case is related to the fact that these languages actually, well Arabic is prettier, there's less content there is because the people in the end they're not going to use it.",
            "So.",
            "Well from here.",
            "So I think the participation is multiple problems, so I think 15 days was relatively short, even though we kept it rolling.",
            "So we send the announcement out multiple times to over different times and different basically for rooms or different places where we could send it to the community.",
            "But yes, one of the important factors here is obviously if you have low editing participation in Wikipedia in the 1st place, it is harder to find people to participate, which was interesting because.",
            "So for example, Esperanto, we had almost as much we had as much contributors to our service as in Arabic, while the community is half the size maximum, which was quite interesting.",
            "I think it says more about how different communities interact differently with outsiders.",
            "How surveys will set up, and you're generally just about how different communities are.",
            "Esperanto community.",
            "This parameter community.",
            "Generally, I would say is relatively entered the astic because.",
            "It's bit of an outside language, so it's not something that typically gets attention, particularly from researchers.",
            "Yes.",
            "There may be one very very far away, so I didn't really get how the system is trained from the start.",
            "I mean the actual generator, what we use for training.",
            "So we built 2 new datasets that something I forgot to mention.",
            "I guess we build 2 new datasets that are aligned.",
            "Between Wikipedia triples and the actual text OK. And we give the network those first sentences and the triples where the main entity is either the subject or the object which I mentioned before.",
            "And yeah, that's why we train on base size, and I think 250,000 summaries for aerobic and 221 hundred 25,000 for Esperanto.",
            "So this is one of the problems.",
            "Why, for example, what I said earlier that we when we make mistakes, factual mistakes, it's usually without a vocabulary words.",
            "This happens a lot more in Esperanto than in Arabic, which was to us odd because Esperanto so much easier to learn.",
            "But it's actually just a lack of data."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah hi, I'm Lucy.",
                    "label": 0
                },
                {
                    "sent": "I'm in the University of Southampton and together with Pavlos who's also in Southampton and Hardy from the language Laboratoire Uber Korea.",
                    "label": 0
                },
                {
                    "sent": "We worked on newer generation of multilingual Wikipedia summaries from wiki data for article placeholders.",
                    "label": 1
                },
                {
                    "sent": "If you don't know those words, I'll explain them in a.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the idea came up that we have this problem in Wikipedia, especially that in English Wikipedia we have almost 6 million articles at the moment, but Arabic Wikipedia, which is the fifth most spoken language in the world with a low percentage of bilingual speakers, we have only around 600,000 articles, right?",
                    "label": 0
                },
                {
                    "sent": "And you have this problem in Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "If you have low content, you don't get readers, and if you don't have readers you don't have editors that can create those.",
                    "label": 0
                },
                {
                    "sent": "Articles that would attract more readers and you're stuck.",
                    "label": 0
                },
                {
                    "sent": "Basically in a vicious cycle.",
                    "label": 0
                },
                {
                    "sent": "So what can you do to break this cycle?",
                    "label": 0
                },
                {
                    "sent": "We thought well, if we need more content we would get those readers, which could be the editors and so on.",
                    "label": 0
                },
                {
                    "sent": "So why not generate content?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Uh, while we have little content on Wikipedia in different languages, we have a lot of resources in wiki data.",
                    "label": 0
                },
                {
                    "sent": "Wiki data is a knowledge base, maintain and edited by community of users and we have around 48 million items on wiki data and each item can be labeled and over 400 languages.",
                    "label": 1
                },
                {
                    "sent": "And as we showed in a previous study, the varieties of languages covered by wiki data is pretty high.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that is what items in Wiki data look like.",
                    "label": 0
                },
                {
                    "sent": "Their RDF representation of how the multilinguality looked like.",
                    "label": 0
                },
                {
                    "sent": "So basically each entity has a unique identifier.",
                    "label": 0
                },
                {
                    "sent": "That's language independent.",
                    "label": 0
                },
                {
                    "sent": "Items have QID's properties of pid's and their connected via their triples, or they are connected with.",
                    "label": 0
                },
                {
                    "sent": "The RDF is labeled property.",
                    "label": 0
                },
                {
                    "sent": "Two different language labels.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now the question is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do we get this content from Wiki data that is multilingual and that's very various an already existing into Wikipedia where we looked at her into a project that already is.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Exists, which is the article placeholder.",
                    "label": 0
                },
                {
                    "sent": "Those article placeholders display triples on Wikipedia and a tabular form and they are dynamically generated, meaning if something is updated on wiki data, it is automatically updated in Wikipedia as well.",
                    "label": 0
                },
                {
                    "sent": "So it has a huge advantage over the creation of Subparticles, which except for example happens in Cebuano, Wikipedia and a big style where someone just imports a lot of information and it's just static and the community is overwhelmed and cannot update it.",
                    "label": 0
                },
                {
                    "sent": "Those article placeholders are currently deployed in 14 underresourced.",
                    "label": 1
                },
                {
                    "sent": "Wikipedia's including Esperanto, but also Gujarati, Haitian, Creole and auto for example.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is what an Arctic place order looks like, so it's structured data.",
                    "label": 0
                },
                {
                    "sent": "As I said on an entity, so it's literally the triples of the entity.",
                    "label": 0
                },
                {
                    "sent": "Pulls into Wikipedia.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we want to do now is enriching those article placeholders with sexual summaries generated from the wiki data triple.",
                    "label": 0
                },
                {
                    "sent": "So basically summarizing a triple, making it, making the whole set up a lot more user friendly and also a good starting point for editors because just seeing pure facts on a Wikipedia page is not really engaging, nor is it a good starting point for someone to actually write content from it.",
                    "label": 0
                },
                {
                    "sent": "We tested it on Arabic and Esperanto, but in theory it is.",
                    "label": 1
                },
                {
                    "sent": "Usable on any small language that has wiki data items and Wikipedia articles existing.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We chose Esperanto in this case because so it's an artificially made language.",
                    "label": 0
                },
                {
                    "sent": "It is really easy to learn for humans as well.",
                    "label": 1
                },
                {
                    "sent": "There for us for machines and, but we have an engaged Wikipedia community.",
                    "label": 0
                },
                {
                    "sent": "We could reach out to, and it's just a good starting point to see if what we want to do is possible at the same time we chose Arabic as I said, because it's severely underserved.",
                    "label": 1
                },
                {
                    "sent": "It's widely spoken, but not really well covered and.",
                    "label": 0
                },
                {
                    "sent": "It's a morphologically, really rich language, so it not only has a different script, but it has a huge vocabulary compared to Esperanto anyway.",
                    "label": 0
                },
                {
                    "sent": "But even compared to English.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is how the input to our system looks like.",
                    "label": 0
                },
                {
                    "sent": "We get from the article placeholder that ripples from Ricky data in our case, for example for media, and we take all the triples where the main entity we want to generate a sentence for is either the subject or the object of the triple.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we give this to our model.",
                    "label": 0
                },
                {
                    "sent": "So as I said, we take the triples from the Arctic, a placeholder set up, and we generate for the article place order sentence.",
                    "label": 0
                },
                {
                    "sent": "We use a feedforward architecture that encodes the triple from the article placeholder in a vector of fixed dimensionality and the decoders RNN based and it generates summaries one token at a time.",
                    "label": 1
                },
                {
                    "sent": "We based the system on previous work of hours, which was state of the art.",
                    "label": 0
                },
                {
                    "sent": "One sentence in the biography domain in English.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now compared to English especially, we have one very severe problem.",
                    "label": 0
                },
                {
                    "sent": "We have a lack of data, so we have a lot of out of vocabulary words meaning on training time.",
                    "label": 1
                },
                {
                    "sent": "Though our system did not see those words yet.",
                    "label": 0
                },
                {
                    "sent": "So to overcome this technical problem, we introduced something called property placeholder.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in our case, for example, if we have those entities from wiki data, we have triples.",
                    "label": 0
                },
                {
                    "sent": "We have the properties.",
                    "label": 0
                },
                {
                    "sent": "As I said before, everything has a unique identifier on wiki data, and we built a training data set.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're relying those triples to the first sentence Wikipedia for to the first sentence of a Wikipedia article.",
                    "label": 0
                },
                {
                    "sent": "And now, for example, Calesita is a word that is most likely not been seen on training time because it's very specific for our main entity here.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we do instead of just letting the network generate garbage or an unknown token, we introduce a new set of special tokens, which are those property placeholders, meaning we align the objects and replace the obj.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Note in the sentence with the properties to which point to the object.",
                    "label": 0
                },
                {
                    "sent": "So after the decoding step of the network we can replace them with appropriate noun from the triple.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the network now is able instead of generating out of vocabulary words to when it want to say is something is ataxia taxonomia normal, it can just put those special tokens instead of having to know the word.",
                    "label": 0
                },
                {
                    "sent": "So those are a few examples of what we generate, as I said.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We generate in Arabic and in Esperanto, because Esperanto is easier to learn.",
                    "label": 0
                },
                {
                    "sent": "Arabic is a bit more complex.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We do two types of evaluation.",
                    "label": 0
                },
                {
                    "sent": "The first one, the first type to see if our network works, and as a good starting point is we use automatic evaluation.",
                    "label": 0
                },
                {
                    "sent": "We compared to two baselines.",
                    "label": 0
                },
                {
                    "sent": "The first one is machine translation, something that is already used to an extent in Wikipedia, and the second one is temperate retrieval.",
                    "label": 1
                },
                {
                    "sent": "As it's like widely used already for text generation, those baselines in our system we compare on three different of automatic evaluation metrics.",
                    "label": 1
                },
                {
                    "sent": "One is blue, one to four mature and druschel.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can say that on all metrics we could outperform our base.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Science.",
                    "label": 0
                },
                {
                    "sent": "And as a second step, then so in the energy community.",
                    "label": 0
                },
                {
                    "sent": "It's very known that those automatic evaluation metrics are very limited, so meaning.",
                    "label": 0
                },
                {
                    "sent": "Yes, meaning that.",
                    "label": 0
                },
                {
                    "sent": "It does not necessarily expect it does not express what a user would say.",
                    "label": 0
                },
                {
                    "sent": "What a reader an actual reader would say.",
                    "label": 0
                },
                {
                    "sent": "Oh, that's embarrassing.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we actually test with the real communities we are trying to address and we're trying to serve.",
                    "label": 0
                },
                {
                    "sent": "So we did two 215 days online service aimed one at readers and one at editors in Esperanto and Arabic respectively.",
                    "label": 1
                },
                {
                    "sent": "And yeah, as I said, we tried to aim at testing with the actual communities were trying to serve and therefore reach out on their platforms and trying to engage them.",
                    "label": 0
                },
                {
                    "sent": "Yes, I said we have two groups, the readers.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the editors we recruited on different forums.",
                    "label": 0
                },
                {
                    "sent": "So first of all we recruited on social media for the readers.",
                    "label": 1
                },
                {
                    "sent": "So anyone that would speak the language fluently in a rabbit case, native speakers in Esperanto case, we don't have native speakers, so we look for any kind of fluent speakers, will reach out on Reddit for Esperanto and Twitter and Facebook and two researchers.",
                    "label": 0
                },
                {
                    "sent": "We know that our RBC speaking.",
                    "label": 0
                },
                {
                    "sent": "In the second step, we reached out on the editors mailing lists and the community pages on Wikipedia, Wikipedia themselves.",
                    "label": 1
                },
                {
                    "sent": "For the editors, this was a really interesting experience, and I think one of the coolest experience I had so far in the research world.",
                    "label": 0
                },
                {
                    "sent": "Because Wikipedia communities, especially for underserved languages, get so excited if you show them what you want to do.",
                    "label": 1
                },
                {
                    "sent": "So, for example, we sent out this email to the editing list and we were not very involved with the rabbit community.",
                    "label": 0
                },
                {
                    "sent": "I don't speak Arabic at all, but the Arabic Wikipedia community decided to.",
                    "label": 0
                },
                {
                    "sent": "Put our survey link too.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the opening remarks of the Ricky Arabia, which is the Arabic speaking community event?",
                    "label": 0
                },
                {
                    "sent": "For editors of Wikipedia.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first we work on the reader evaluation.",
                    "label": 0
                },
                {
                    "sent": "The first thing we ask, which is pretty standard as the fluency, so it's the text understandable and grammatically correct with scores from zero to 6, and then the appropriateness which, so which is focused on our task, does the summary feel like a Wikipedia article?",
                    "label": 1
                },
                {
                    "sent": "We use three different sources to compare to first of all our own generated sentences.",
                    "label": 0
                },
                {
                    "sent": "Obviously the set of original Wikipedia sentences and a set of new sentences.",
                    "label": 0
                },
                {
                    "sent": "The participation was OK.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not better than we expected, but what we learned from this especially was we gave the readers as well as the editors.",
                    "label": 0
                },
                {
                    "sent": "As you will see later, much too many sentences because it's not a crowdsourcing experiment as people that actually get involved with us.",
                    "label": 0
                },
                {
                    "sent": "So as you can see, we have a very low rate of participants that actually contributed to over 50% of the sentences, which was OK. We told them you could stop the experiment at anytime, and anything annotated would go in two hours.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Survey and of course, this is basically what it looks like for the rabbit community, so the upper one is the instructions for the fluency.",
                    "label": 0
                },
                {
                    "sent": "The lower one is for.",
                    "label": 0
                },
                {
                    "sent": "The lower one was for the appropriateness, so we have the scores from zero to six.",
                    "label": 0
                },
                {
                    "sent": "We have the sentence they should evaluate, and the instructions respectively.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what we can see is we scored relatively well.",
                    "label": 0
                },
                {
                    "sent": "We have very high percentage of people thinking that our sentences would fit into Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "They clearly can differentiate them from the news as well as the fluency of our sentences is surprisingly high as well.",
                    "label": 0
                },
                {
                    "sent": "So we score in orebic better than the actual Wikipedia summaries, which is kind of surprising.",
                    "label": 1
                },
                {
                    "sent": "And in Esperanto we score better than the new sentences, where we assume that that's probably because the news in Esperanto.",
                    "label": 0
                },
                {
                    "sent": "Even though it's a big news outlet, they use some form of translation tools as well.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the second step, we.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work with the editor.",
                    "label": 0
                },
                {
                    "sent": "So this was really important to us because the article placeholders not only there to give new information, but what we want in the end is to prepare for people to actually come and make real articles of what we give them as a first step, right?",
                    "label": 0
                },
                {
                    "sent": "So editors were asked to edit the article starting from our summary and the corresponding triple.",
                    "label": 1
                },
                {
                    "sent": "So basically the layout as we would have it in Artica place order later on and give us two to three sentences.",
                    "label": 0
                },
                {
                    "sent": "Basically an introduction of a real Wikipedia article and we measured how much.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Text was reused.",
                    "label": 0
                },
                {
                    "sent": "The participation was not too bad, not too high, and as I said, what we really learned was 30 sentences to start with is much too much content.",
                    "label": 0
                },
                {
                    "sent": "I was actually surprised that we had two people that went the whole way and annotated, which started writing articles for over 30s of over 15 sentences.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is what our setup would look like.",
                    "label": 0
                },
                {
                    "sent": "It's our University and sternal system, that's why it looks a bit chunky, but we have an instruction in the on the top we have the generated summary.",
                    "label": 0
                },
                {
                    "sent": "We have regulator triples and editing field that's sadly left aligned because you know, right aligning computers.",
                    "label": 1
                },
                {
                    "sent": "Not that nice yet.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we measured how much text was we used by editors.",
                    "label": 0
                },
                {
                    "sent": "We used the greedy string tiling algorithm for that, which is actually derived from plagiarism detection.",
                    "label": 0
                },
                {
                    "sent": "That's where it's mainly used.",
                    "label": 1
                },
                {
                    "sent": "It's the advantage over the Levenshtein distance.",
                    "label": 0
                },
                {
                    "sent": "If you look at editing distances that you can detect, black hole blocks moved and you have this minimum match length factor to ignore copying off so small Subs, subsequences in the text.",
                    "label": 1
                },
                {
                    "sent": "We divided this our results into three parts wholly derived, partially derived, non derived to say how much of our sentences were reused actually.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can see that in Esperanto, alot of sentences were wholly or partially derived.",
                    "label": 0
                },
                {
                    "sent": "A huge chunk of text or just left as it is, especially in Esperanto in Arabic, is still a high percentage of wholly and partially derived, however wholly derived us a lot smaller.",
                    "label": 0
                },
                {
                    "sent": "We can actually explain this by the fact that, as I said, has parent has a much smaller vocabulary, meaning that we have a lot less out of vocabulary words.",
                    "label": 0
                },
                {
                    "sent": "So what we can see in Arabic, especially what users do to get from Holy Direct impact to partially derived.",
                    "label": 0
                },
                {
                    "sent": "Is they will replace the special token unknown words which we still have another text, which is something very interesting for us to learn from.",
                    "label": 0
                },
                {
                    "sent": "So we really have to take care of how can we cover better underserved languages and how can we make our network generate the text comprehensive.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Clean.",
                    "label": 0
                },
                {
                    "sent": "Conclusively, we can say that Wikipedia's article place order is a very good case use case for those energy tasks we can, and generally catering for readers and editors knees needs is the way to go.",
                    "label": 1
                },
                {
                    "sent": "When we work on energy tasks and especially in the case of Wikipedia working with the community is really important rather than just doing automatic evaluation because it tells us a lot less of the story of what we want to know and experience than the actual evaluation with the communities.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so we can say that our encoder decoder model is able to generate high quality summaries and underserved languages.",
                    "label": 1
                },
                {
                    "sent": "And our approach works in multiple languages and was tested for languages with very different properties.",
                    "label": 1
                },
                {
                    "sent": "So Arabic, which is very hard and morphologically rich but has a lot of articles compared to Esperanto which has less articles but isn't a lot easier to acquire language.",
                    "label": 0
                },
                {
                    "sent": "And we can say that our generated summary seem useful as a starting point for article creation.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's that's another point.",
                    "label": 0
                },
                {
                    "sent": "I wanted to make in this slide.",
                    "label": 0
                },
                {
                    "sent": "Sorry that the the community was quite happy about it, so we got invited to the Celtic Knot conference which is the Wikimedia Conference for Small Languages as well as we're going to be featured on the Wikimedia Research Showcase, 'cause they thought it was quite interesting.",
                    "label": 0
                },
                {
                    "sent": "Thank you Lucy.",
                    "label": 0
                },
                {
                    "sent": "I think we have quite some time for questions.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, thanks for the nice talk.",
                    "label": 0
                },
                {
                    "sent": "I have a question like are you aware of this tool by Magnus Man Scale?",
                    "label": 0
                },
                {
                    "sent": "It is called Autodesk like Auto description.",
                    "label": 0
                },
                {
                    "sent": "Yeah did you think you also generates it in multiple language?",
                    "label": 0
                },
                {
                    "sent": "Those automatic descriptions?",
                    "label": 0
                },
                {
                    "sent": "Wouldn't that have been a good baseline for you?",
                    "label": 0
                },
                {
                    "sent": "Also like to compare two.",
                    "label": 0
                },
                {
                    "sent": "Yeah so basically what he does is template based descriptions right?",
                    "label": 0
                },
                {
                    "sent": "So what we said?",
                    "label": 0
                },
                {
                    "sent": "Well we don't go with template based and we we have this template based its information retrieval based.",
                    "label": 0
                },
                {
                    "sent": "Originally, templates retrieval baseline to find out how it works well, we said, well, we don't want to have template based generation is that we would have the property problem that the Community would focus on creating those templates instead of the actual work which is creating articles right?",
                    "label": 0
                },
                {
                    "sent": "So, especially when we talk about very small communities are cases, Orebic is still a relatively big community, right?",
                    "label": 0
                },
                {
                    "sent": "But if we talk for example about Haitian Creole, they have two active editors.",
                    "label": 0
                },
                {
                    "sent": "I would prefer that those two active editors go around and actually create the articles and the other advantage of newer network generations.",
                    "label": 0
                },
                {
                    "sent": "Obviously the text is less repetitive, right?",
                    "label": 0
                },
                {
                    "sent": "So you don't just have a template that always says the same, but the network can adjust to the content of the triples.",
                    "label": 0
                },
                {
                    "sent": "But that doesn't.",
                    "label": 0
                },
                {
                    "sent": "Yeah like.",
                    "label": 0
                },
                {
                    "sent": "But why didn't you compare it?",
                    "label": 0
                },
                {
                    "sent": "I saw it too to the actual scores you mean like?",
                    "label": 0
                },
                {
                    "sent": "Yeah, like you had a really nice setup, user evaluation and everything and that would have been like just like another system to compare to.",
                    "label": 0
                },
                {
                    "sent": "It's true.",
                    "label": 0
                },
                {
                    "sent": "It's a very good point.",
                    "label": 0
                },
                {
                    "sent": "I'm not aware of how many domains the the Autodesk can cover in Esperanto and Arabic.",
                    "label": 0
                },
                {
                    "sent": "That's one of the limitations obviously of template base, so I will have to look into that.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks, thank you.",
                    "label": 0
                },
                {
                    "sent": "I'm wondering whether the algorithm can go wrong sometimes.",
                    "label": 0
                },
                {
                    "sent": "And produce a sentence that is factually wrong by.",
                    "label": 0
                },
                {
                    "sent": "Interpolating something wrong?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so this could actually happen.",
                    "label": 0
                },
                {
                    "sent": "What we found is this happens mostly because of out of vocabulary words.",
                    "label": 0
                },
                {
                    "sent": "So we tested the system in English too.",
                    "label": 0
                },
                {
                    "sent": "It's with the crowd experiment in the previous work to how much factually wrong sentences does generate.",
                    "label": 0
                },
                {
                    "sent": "It's relatively low, but if we look at our system it's usually generates factually wrong things because it doesn't know the word.",
                    "label": 0
                },
                {
                    "sent": "So we had one example where it generates the wrong country, not because it doesn't know it.",
                    "label": 0
                },
                {
                    "sent": "Country has to go in there, but it didn't learn the word for the country yet, so just use the word for different country that it's all very often.",
                    "label": 0
                },
                {
                    "sent": "So it's mainly a problem of lack of data basically.",
                    "label": 0
                },
                {
                    "sent": "Did you also get comments about the amount of content that is that is available there?",
                    "label": 0
                },
                {
                    "sent": "So when I looked at these, I think Autodesk they're called descriptions.",
                    "label": 0
                },
                {
                    "sent": "They're usually very very, very, very short, so this is partly due to the fact that it's template based and it only represents what is their representable by the templates.",
                    "label": 0
                },
                {
                    "sent": "But probably it also reflects a shortage of information, so that is something we didn't specifically ask for.",
                    "label": 0
                },
                {
                    "sent": "A good question though.",
                    "label": 0
                },
                {
                    "sent": "The thing is, as we learn on those, Wikipedia's are sentences.",
                    "label": 0
                },
                {
                    "sent": "LR as long usually as average sentence in that domain.",
                    "label": 0
                },
                {
                    "sent": "In that, Wikipedia would be.",
                    "label": 0
                },
                {
                    "sent": "It ends.",
                    "label": 0
                },
                {
                    "sent": "For example in Esperanto, especially to be relatively short, as the examples I showed earlier are relatively long, because in that in the chemical domain editors just tended to make longer sentences as introductionary sentence.",
                    "label": 0
                },
                {
                    "sent": "But we have a lot of sentences generated that are just city.",
                    "label": 0
                },
                {
                    "sent": "Is a city in country right?",
                    "label": 0
                },
                {
                    "sent": "So it is a lot of those are relatively short to this point, which is something we cannot influence because we said we really want to learn how the Wikipedia community is right in this domain, right?",
                    "label": 0
                },
                {
                    "sent": "So in the different domain.",
                    "label": 0
                },
                {
                    "sent": "So it really depends on them.",
                    "label": 0
                },
                {
                    "sent": "In the end you are a general question about your opinion on why the participation.",
                    "label": 0
                },
                {
                    "sent": "OK, you said you were surprised it was there were maybe more people than you expected, but they were still very few.",
                    "label": 0
                },
                {
                    "sent": "Just in case is related to the fact that these languages actually, well Arabic is prettier, there's less content there is because the people in the end they're not going to use it.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Well from here.",
                    "label": 0
                },
                {
                    "sent": "So I think the participation is multiple problems, so I think 15 days was relatively short, even though we kept it rolling.",
                    "label": 0
                },
                {
                    "sent": "So we send the announcement out multiple times to over different times and different basically for rooms or different places where we could send it to the community.",
                    "label": 0
                },
                {
                    "sent": "But yes, one of the important factors here is obviously if you have low editing participation in Wikipedia in the 1st place, it is harder to find people to participate, which was interesting because.",
                    "label": 0
                },
                {
                    "sent": "So for example, Esperanto, we had almost as much we had as much contributors to our service as in Arabic, while the community is half the size maximum, which was quite interesting.",
                    "label": 0
                },
                {
                    "sent": "I think it says more about how different communities interact differently with outsiders.",
                    "label": 0
                },
                {
                    "sent": "How surveys will set up, and you're generally just about how different communities are.",
                    "label": 0
                },
                {
                    "sent": "Esperanto community.",
                    "label": 0
                },
                {
                    "sent": "This parameter community.",
                    "label": 0
                },
                {
                    "sent": "Generally, I would say is relatively entered the astic because.",
                    "label": 0
                },
                {
                    "sent": "It's bit of an outside language, so it's not something that typically gets attention, particularly from researchers.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "There may be one very very far away, so I didn't really get how the system is trained from the start.",
                    "label": 0
                },
                {
                    "sent": "I mean the actual generator, what we use for training.",
                    "label": 0
                },
                {
                    "sent": "So we built 2 new datasets that something I forgot to mention.",
                    "label": 0
                },
                {
                    "sent": "I guess we build 2 new datasets that are aligned.",
                    "label": 0
                },
                {
                    "sent": "Between Wikipedia triples and the actual text OK. And we give the network those first sentences and the triples where the main entity is either the subject or the object which I mentioned before.",
                    "label": 0
                },
                {
                    "sent": "And yeah, that's why we train on base size, and I think 250,000 summaries for aerobic and 221 hundred 25,000 for Esperanto.",
                    "label": 0
                },
                {
                    "sent": "So this is one of the problems.",
                    "label": 0
                },
                {
                    "sent": "Why, for example, what I said earlier that we when we make mistakes, factual mistakes, it's usually without a vocabulary words.",
                    "label": 0
                },
                {
                    "sent": "This happens a lot more in Esperanto than in Arabic, which was to us odd because Esperanto so much easier to learn.",
                    "label": 0
                },
                {
                    "sent": "But it's actually just a lack of data.",
                    "label": 0
                }
            ]
        }
    }
}