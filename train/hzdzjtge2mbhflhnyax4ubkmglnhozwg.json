{
    "id": "hzdzjtge2mbhflhnyax4ubkmglnhozwg",
    "title": "The price of bandit information in multiclass online classification",
    "info": {
        "author": [
            "Amit Daniely, Einstein Institute of Mathematics, The Hebrew University of Jerusalem"
        ],
        "published": "Aug. 9, 2013",
        "recorded": "June 2013",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/colt2013_daniely_price/",
    "segmentation": [
        [
            "Thank you so in this world work we considered multiclass online classification.",
            "And we compare the full information scenario and."
        ],
        [
            "Bandit scenario, so let us quickly recall the setting.",
            "So multiclass online classification can be fought as again between an adversary and algorithm.",
            "That was our chooses an instance XD and label Whitey which is a number between one 2K in particular.",
            "There are K levels and exposes the instance X D2 algorithm algorithm.",
            "Try to predict the correct label Whitey and then it feels a feedback in the full information.",
            "The standard scenario is the true label white is revealed while in the bandit scenario only an indication whether the algorithm prediction was correct.",
            "What is revealed and the goal, of course, is to minimize the number of errors.",
            "So today the motivation behind the bandit scenario is clear.",
            "It's include Internet advertising, recommendation systems and many more, and it has been quite extensively studied in the last seven several years.",
            "And in this work we consider the following basic question.",
            "How harder is to predict in the bandit scenario?",
            "And I emphasize that this work is purely information theoretic.",
            "We consider all kinds of algorithm, also known efficient ones, and indeed the algorithm that will show will be highly inefficient."
        ],
        [
            "OK, so.",
            "I would start by stating the previous questions precisely and stating the main result, and then I'll try to give a sketch of the proof."
        ],
        [
            "OK, so first it is clear that in order to obtain a meaningful scenario we must do somehow restrict the adversary, because otherwise it could easily enforce the algorithm to means to make an error at each step.",
            "So we will use the good and old work off of hypothesis paths.",
            "We will fix some hypothesis class H and we will restrict the adversary to.",
            "To produce a realizable sequence, and as you can see here, we consider the realizable case.",
            "Or we also have similar results for the non realizable case which I want to talk about it in the talk.",
            "OK, so."
        ],
        [
            "The definition we define the full information error rate of H. Also, the mistake one of H to be the number of errors can be forced by a full information adversary which also equals to the minimum number Y such that there exists some algorithm that is guaranteed to make at most fear of when it runs on a sequence that is realized by H. Similarly we define.",
            "The bandit mistake bound or the bandit error rate of H to be the number of errors can be forced by a bandit adversary.",
            "And they make question, we ask, is how large can be the ratio between the bandit error rates and the full information error rate?",
            "We call this ratio of the price of bandit in formation of H. OK."
        ],
        [
            "Before stating the main result that is considered a nice toy example.",
            "Here we take the instance SpaceX to be some finite set and they posses class H to be all functions from X to the labels.",
            "So let's make a quick full info analysis.",
            "So for the upper bound, if you're playing the role of the algorithm, there is no reason to her twice in the same instance, because after we've seen some instance we know it's correct label.",
            "Therefore, the full information error rate is upper bounded by the cardinality of X.",
            "And if we're playing the role of that website, we can force a mistake on every instance.",
            "Because it can show the algorithm, the instance it will say some label and we will tell him that the correct label is some other label, therefore the.",
            "Full information error rate is exactly the cardinality of X.",
            "So let's make a quick budget analysis of this class.",
            "So again, if you're playing the role of the algorithm, there is no reason to more than K -- 1 times on the same instance, because after we guessed K -- 1 labels, we know the correct label, so the budget error rate is upper bounded by K -- 1 times regarding guarantee of X and similarly bandit adversary can force came with one errors on each instance and therefore the bandit error rate equal exactly 2K minus one times the entire cardinality of X and hear the ratio.",
            "Exactly the price of my information is exactly K -- 1."
        ],
        [
            "So our main.",
            "During states that for every hypothesis Class H, the price of bandit information, the ratio between the bandit error rate and the full information error, it is upper bounded by 4K times OK. And by example we have just seen.",
            "This is tight up to the local factor.",
            "OK, so before."
        ],
        [
            "Launching into the proof let's me quickly survey some relevant previous results.",
            "So here we wish to upper bound the ratio between the bandit error rate and the full information error rate, so the relevant results are upper bounds on the bandit error rates and lower bound on the standard error rate.",
            "So we start with lower bound on the error rate.",
            "Real there aren't.",
            "Too many results in 89 Littlestown prove that.",
            "In the binary case.",
            "The error rate is lower bounded by a complexity measure called the Little Stone dimension of H, and it extended by nearly two years ago to the multiclass case, with a generalization of the Little stone dimension for upper bounds.",
            "Will not you know little bit more for upper bounds on the monitor, right?",
            "So then I have an algorithm achieves an.",
            "Upper bound of the bandit error rate of K. The number of labels times the log of the cardinality of H, and this can be extended to the non realizable case.",
            "Also, we know that for halfspaces.",
            "With Mountain Gamma, the bandit error rate is upper bounded by K squared over gamma.",
            "And we also know that the bandit error rate is upper bounded, in fact equal to the bandit Littlestown dimension of H. This is another capacity measure of complexity of edge, and I emphasize that none of the above yells a general upper bound on.",
            "The price of bandit information of H."
        ],
        [
            "OK so I will describe the proof will start with."
        ],
        [
            "A little snow dimension.",
            "The latest dimension is a measure of capacity associated associated with every hypothesis class.",
            "It is similar to the VC Dimension an IT measure how complex is to learn the Class H in.",
            "In the online scenario, so this is the definition.",
            "Let me be rooted, full binary tree, whose internal nodes are labeled by the instances an whose edges are labeled by the labels and we say that root leaf path is realizable.",
            "If the following holds, for example, this path is realizable if there exists some function H&H, such that H of X1 equal to two H of X2 and H of X2X1213, and we say that the Treaty is shattered if all its root leaf path are shattered.",
            "And finally we define the Little stone dimension of H to be the maximal depth of.",
            "Officially and.",
            "So just one note, this is a general generalization of the original definition of littlestone.",
            "He defined it for the binary case and this is a generalization to the.",
            "A multiclass case?"
        ],
        [
            "OK, so the main theorem afflatus on test that the error rate of a full information error rate of H equals exactly to the little store dimension of Edge, which I will denote by the letter L. OK, so I'll show you the proof 'cause our."
        ],
        [
            "Proof is.",
            "Have the same spirit of little soundproof, so we'll start with the easier part of the lower bound.",
            "So here I should show you that the adversary can enforce errors if we have a.",
            "Shadow Tree of Death L So the artillery can simply proceed as follows.",
            "If this is the tree."
        ],
        [
            "We start with the route you will show.",
            "The algorithm the instance X1.",
            "The algorithm will predict some labeled algorithm can predict both the labels two and seven.",
            "So suppose it didn't predict the label to the adversary telling that the correct label two label is 2 and."
        ],
        [
            "Will proceed to this node now will show in the instance X2.",
            "Again, the algorithm will predict only one label.",
            "Say it didn't predict one.",
            "The adversary will tell him that the correct label is 1 and will."
        ],
        [
            "Afraid to hear this way, it caused the algorithm to make errors, and by the definition of stuttering the sequence it reduced is realisable.",
            "OK, this is stab Lish.",
            "The lower bound for."
        ],
        [
            "Upper bound I should show you that there is some algorithm that is guaranteed to make at most errors when it runs on the sequence that is realizable by H. So the algorithm will proceed as follows."
        ],
        [
            "In an instance X chosen by the adversary.",
            "It will split the Class H into K classes according to the label of X.",
            "So we define H of XY to be all the function in H such that that Maps X to Y.",
            "So this party."
        ],
        [
            "And H in 2K classes.",
            "And the crucial point."
        ],
        [
            "And if that there exists at most single class out of this K classes whose little dimension equal to Ellen for the rest of the class is the little celebration is strictly smaller.",
            "And the algorithm will choose the label corresponding to.",
            "This class and."
        ],
        [
            "If it's worth the class of consistent hypothesis is one of the other classes, and it says it's little mention is strictly smaller."
        ],
        [
            "Therefore, after each elderly still standing mention decreases and after LL the little celebration will be zero, which means that we have only single consistent hypothesis and from that point we will make no further else.",
            "And establish the upper bound.",
            "OK."
        ],
        [
            "So let's proceed to the proof of our theorem.",
            "So it's a reminder that it said that for every Class H, the ratio between the monetary rate and the error rate is upper bounded by 4K LO K, and since.",
            "The air light equal to the latest on dimension.",
            "Equivalently, we should show that.",
            "The bandit error rate is upper bounded by 4K locate times.",
            "The Little stone dimension of H. So before the 4th, let's try to see what happens if I try to use the same algorithm and imitate the analysis of the previous theorem.",
            "So the problem is that after the algorithm Earth, the set of consistent hypothesis is union of K -- 1 classes of little dimension strictly smaller.",
            "However, this union might be of Littlestown Dimension L. So then the analysis don't work.",
            "Nevertheless."
        ],
        [
            "I claim that in some sense, K -- 1 classes of little stone dimension, smaller indeed smaller than a single class of Littlestown dimension L. Because we can proceed as follows in the next K -- 1 else we can split each one of these classes so we can split this one."
        ],
        [
            "And then that."
        ],
        [
            "One and then."
        ],
        [
            "That one and continue doing so and split the little classes and."
        ],
        [
            "If you continue, continue doing so.",
            "We will get some algorithm with finite mistake bound.",
            "Unfortunately, it will be exponential in the littlest dimension, which is not good enough."
        ],
        [
            "But nevertheless, the idea of the algorithm will be to partition H and somewhat more clever way, so that size at each step we have a partition of the set of consistent hypothesis an at each.",
            "After each error will split some of these classes.",
            "We will delete some others and that of will.",
            "We remain unchanged and we will be doing so, aiming to minimize a measure of capacity which we define next."
        ],
        [
            "So we start with a single subclass.",
            "We defined capacity of the Subclass V to be K2.",
            "The two times the Little Stone dimension of V, and we accept extended this definition to a collection sigh of subclasses by summing over the different subclasses.",
            "We also define splitting operator.",
            "We define the split of V of XY to be set.",
            "So this is a partition of the hypothesis in the that are consistent with the path after we have seen the instance X predicted Y and we were wrong and again we extend the definition to a collection type by taking a union over different subclasses.",
            "So that we."
        ],
        [
            "We simply posted a false start with the collection consisting only of the Class H itself and at each step you will receive some instance and we predict the label that maximum that minimizes the capacity of splitting according to this level, and if it's worth it, will split according to that label.",
            "OK, so that is the algorithm and let me tell you a few words about the analysis so."
        ],
        [
            "The crucial point is that if a subclass V is splitted in 2K minus one of classes of strictly strictly smaller than dimension, then its capacity shrinks by a factor of 1 / K and sense for every subclass we we have at least a single label that split it in this way by simple averaging argument, we conclude that there exists somewhere some level that shrink the total capacity by a factor of 1.",
            "Minus 1 / 2 K Therefore."
        ],
        [
            "After MLF the capacity shrinks by a factor of 1 -- 1 / 2 K to them.",
            "And since the initial capacity is K to the two times.",
            "After the correct number for Kelo case, time L Mistakes the capacity, shrinks to one, which means that we have only a single consistent hypothesis left, and from that point on, we will make no further else.",
            "So that stab Lish is the proof.",
            "OK, so let."
        ],
        [
            "Summarize the main theorem tells us that the price of bandit information, the ratio between the bandit error rate, and the full info error rate is upper bounded by 4K OK and this is tight up to the local factor.",
            "And if I told you assuming similar results holds also for the non realizable case, and you're welcome to come to the poster, I will tell me tell you a little bit more about it, and we also have an application to.",
            "Large mountain half basis.",
            "Using these two theorems, we can calculate almost exactly up to log factors.",
            "The bandit error rate of large margin half passes to soldier.",
            "General generalization of it to the multiclass scenario.",
            "And let me conclude with two open questions.",
            "The first immediate often open question is whether we can get rid of this.",
            "Going low K factor and the second question is what happens if we restrict ourselves to efficient algorithms.",
            "So I remind you that this work is information theoretic.",
            "The algorithm we just so so with clearly inefficient.",
            "And for example, we can ask the following question.",
            "Suppose that I have some algorithm that is guaranteed to make at most M errors when it runs on a sequence that is realizable by edge.",
            "So do I have an algorithm that is guaranteed to make at most, say K squared time, and else when it runs on such sequence in the bandit scenario?",
            "And with that I conclude."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you so in this world work we considered multiclass online classification.",
                    "label": 0
                },
                {
                    "sent": "And we compare the full information scenario and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bandit scenario, so let us quickly recall the setting.",
                    "label": 0
                },
                {
                    "sent": "So multiclass online classification can be fought as again between an adversary and algorithm.",
                    "label": 0
                },
                {
                    "sent": "That was our chooses an instance XD and label Whitey which is a number between one 2K in particular.",
                    "label": 0
                },
                {
                    "sent": "There are K levels and exposes the instance X D2 algorithm algorithm.",
                    "label": 0
                },
                {
                    "sent": "Try to predict the correct label Whitey and then it feels a feedback in the full information.",
                    "label": 0
                },
                {
                    "sent": "The standard scenario is the true label white is revealed while in the bandit scenario only an indication whether the algorithm prediction was correct.",
                    "label": 1
                },
                {
                    "sent": "What is revealed and the goal, of course, is to minimize the number of errors.",
                    "label": 0
                },
                {
                    "sent": "So today the motivation behind the bandit scenario is clear.",
                    "label": 0
                },
                {
                    "sent": "It's include Internet advertising, recommendation systems and many more, and it has been quite extensively studied in the last seven several years.",
                    "label": 0
                },
                {
                    "sent": "And in this work we consider the following basic question.",
                    "label": 1
                },
                {
                    "sent": "How harder is to predict in the bandit scenario?",
                    "label": 0
                },
                {
                    "sent": "And I emphasize that this work is purely information theoretic.",
                    "label": 0
                },
                {
                    "sent": "We consider all kinds of algorithm, also known efficient ones, and indeed the algorithm that will show will be highly inefficient.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I would start by stating the previous questions precisely and stating the main result, and then I'll try to give a sketch of the proof.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so first it is clear that in order to obtain a meaningful scenario we must do somehow restrict the adversary, because otherwise it could easily enforce the algorithm to means to make an error at each step.",
                    "label": 0
                },
                {
                    "sent": "So we will use the good and old work off of hypothesis paths.",
                    "label": 0
                },
                {
                    "sent": "We will fix some hypothesis class H and we will restrict the adversary to.",
                    "label": 1
                },
                {
                    "sent": "To produce a realizable sequence, and as you can see here, we consider the realizable case.",
                    "label": 0
                },
                {
                    "sent": "Or we also have similar results for the non realizable case which I want to talk about it in the talk.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The definition we define the full information error rate of H. Also, the mistake one of H to be the number of errors can be forced by a full information adversary which also equals to the minimum number Y such that there exists some algorithm that is guaranteed to make at most fear of when it runs on a sequence that is realized by H. Similarly we define.",
                    "label": 0
                },
                {
                    "sent": "The bandit mistake bound or the bandit error rate of H to be the number of errors can be forced by a bandit adversary.",
                    "label": 1
                },
                {
                    "sent": "And they make question, we ask, is how large can be the ratio between the bandit error rates and the full information error rate?",
                    "label": 0
                },
                {
                    "sent": "We call this ratio of the price of bandit in formation of H. OK.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Before stating the main result that is considered a nice toy example.",
                    "label": 0
                },
                {
                    "sent": "Here we take the instance SpaceX to be some finite set and they posses class H to be all functions from X to the labels.",
                    "label": 0
                },
                {
                    "sent": "So let's make a quick full info analysis.",
                    "label": 0
                },
                {
                    "sent": "So for the upper bound, if you're playing the role of the algorithm, there is no reason to her twice in the same instance, because after we've seen some instance we know it's correct label.",
                    "label": 0
                },
                {
                    "sent": "Therefore, the full information error rate is upper bounded by the cardinality of X.",
                    "label": 0
                },
                {
                    "sent": "And if we're playing the role of that website, we can force a mistake on every instance.",
                    "label": 0
                },
                {
                    "sent": "Because it can show the algorithm, the instance it will say some label and we will tell him that the correct label is some other label, therefore the.",
                    "label": 0
                },
                {
                    "sent": "Full information error rate is exactly the cardinality of X.",
                    "label": 0
                },
                {
                    "sent": "So let's make a quick budget analysis of this class.",
                    "label": 0
                },
                {
                    "sent": "So again, if you're playing the role of the algorithm, there is no reason to more than K -- 1 times on the same instance, because after we guessed K -- 1 labels, we know the correct label, so the budget error rate is upper bounded by K -- 1 times regarding guarantee of X and similarly bandit adversary can force came with one errors on each instance and therefore the bandit error rate equal exactly 2K minus one times the entire cardinality of X and hear the ratio.",
                    "label": 1
                },
                {
                    "sent": "Exactly the price of my information is exactly K -- 1.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our main.",
                    "label": 0
                },
                {
                    "sent": "During states that for every hypothesis Class H, the price of bandit information, the ratio between the bandit error rate and the full information error, it is upper bounded by 4K times OK. And by example we have just seen.",
                    "label": 0
                },
                {
                    "sent": "This is tight up to the local factor.",
                    "label": 1
                },
                {
                    "sent": "OK, so before.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Launching into the proof let's me quickly survey some relevant previous results.",
                    "label": 1
                },
                {
                    "sent": "So here we wish to upper bound the ratio between the bandit error rate and the full information error rate, so the relevant results are upper bounds on the bandit error rates and lower bound on the standard error rate.",
                    "label": 0
                },
                {
                    "sent": "So we start with lower bound on the error rate.",
                    "label": 0
                },
                {
                    "sent": "Real there aren't.",
                    "label": 0
                },
                {
                    "sent": "Too many results in 89 Littlestown prove that.",
                    "label": 0
                },
                {
                    "sent": "In the binary case.",
                    "label": 0
                },
                {
                    "sent": "The error rate is lower bounded by a complexity measure called the Little Stone dimension of H, and it extended by nearly two years ago to the multiclass case, with a generalization of the Little stone dimension for upper bounds.",
                    "label": 0
                },
                {
                    "sent": "Will not you know little bit more for upper bounds on the monitor, right?",
                    "label": 1
                },
                {
                    "sent": "So then I have an algorithm achieves an.",
                    "label": 0
                },
                {
                    "sent": "Upper bound of the bandit error rate of K. The number of labels times the log of the cardinality of H, and this can be extended to the non realizable case.",
                    "label": 0
                },
                {
                    "sent": "Also, we know that for halfspaces.",
                    "label": 0
                },
                {
                    "sent": "With Mountain Gamma, the bandit error rate is upper bounded by K squared over gamma.",
                    "label": 0
                },
                {
                    "sent": "And we also know that the bandit error rate is upper bounded, in fact equal to the bandit Littlestown dimension of H. This is another capacity measure of complexity of edge, and I emphasize that none of the above yells a general upper bound on.",
                    "label": 0
                },
                {
                    "sent": "The price of bandit information of H.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so I will describe the proof will start with.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A little snow dimension.",
                    "label": 0
                },
                {
                    "sent": "The latest dimension is a measure of capacity associated associated with every hypothesis class.",
                    "label": 0
                },
                {
                    "sent": "It is similar to the VC Dimension an IT measure how complex is to learn the Class H in.",
                    "label": 0
                },
                {
                    "sent": "In the online scenario, so this is the definition.",
                    "label": 0
                },
                {
                    "sent": "Let me be rooted, full binary tree, whose internal nodes are labeled by the instances an whose edges are labeled by the labels and we say that root leaf path is realizable.",
                    "label": 1
                },
                {
                    "sent": "If the following holds, for example, this path is realizable if there exists some function H&H, such that H of X1 equal to two H of X2 and H of X2X1213, and we say that the Treaty is shattered if all its root leaf path are shattered.",
                    "label": 1
                },
                {
                    "sent": "And finally we define the Little stone dimension of H to be the maximal depth of.",
                    "label": 0
                },
                {
                    "sent": "Officially and.",
                    "label": 0
                },
                {
                    "sent": "So just one note, this is a general generalization of the original definition of littlestone.",
                    "label": 0
                },
                {
                    "sent": "He defined it for the binary case and this is a generalization to the.",
                    "label": 0
                },
                {
                    "sent": "A multiclass case?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the main theorem afflatus on test that the error rate of a full information error rate of H equals exactly to the little store dimension of Edge, which I will denote by the letter L. OK, so I'll show you the proof 'cause our.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Proof is.",
                    "label": 0
                },
                {
                    "sent": "Have the same spirit of little soundproof, so we'll start with the easier part of the lower bound.",
                    "label": 0
                },
                {
                    "sent": "So here I should show you that the adversary can enforce errors if we have a.",
                    "label": 1
                },
                {
                    "sent": "Shadow Tree of Death L So the artillery can simply proceed as follows.",
                    "label": 0
                },
                {
                    "sent": "If this is the tree.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We start with the route you will show.",
                    "label": 0
                },
                {
                    "sent": "The algorithm the instance X1.",
                    "label": 0
                },
                {
                    "sent": "The algorithm will predict some labeled algorithm can predict both the labels two and seven.",
                    "label": 0
                },
                {
                    "sent": "So suppose it didn't predict the label to the adversary telling that the correct label two label is 2 and.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Will proceed to this node now will show in the instance X2.",
                    "label": 0
                },
                {
                    "sent": "Again, the algorithm will predict only one label.",
                    "label": 0
                },
                {
                    "sent": "Say it didn't predict one.",
                    "label": 0
                },
                {
                    "sent": "The adversary will tell him that the correct label is 1 and will.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Afraid to hear this way, it caused the algorithm to make errors, and by the definition of stuttering the sequence it reduced is realisable.",
                    "label": 0
                },
                {
                    "sent": "OK, this is stab Lish.",
                    "label": 0
                },
                {
                    "sent": "The lower bound for.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Upper bound I should show you that there is some algorithm that is guaranteed to make at most errors when it runs on the sequence that is realizable by H. So the algorithm will proceed as follows.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In an instance X chosen by the adversary.",
                    "label": 1
                },
                {
                    "sent": "It will split the Class H into K classes according to the label of X.",
                    "label": 0
                },
                {
                    "sent": "So we define H of XY to be all the function in H such that that Maps X to Y.",
                    "label": 0
                },
                {
                    "sent": "So this party.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And H in 2K classes.",
                    "label": 0
                },
                {
                    "sent": "And the crucial point.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if that there exists at most single class out of this K classes whose little dimension equal to Ellen for the rest of the class is the little celebration is strictly smaller.",
                    "label": 0
                },
                {
                    "sent": "And the algorithm will choose the label corresponding to.",
                    "label": 1
                },
                {
                    "sent": "This class and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If it's worth the class of consistent hypothesis is one of the other classes, and it says it's little mention is strictly smaller.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Therefore, after each elderly still standing mention decreases and after LL the little celebration will be zero, which means that we have only single consistent hypothesis and from that point we will make no further else.",
                    "label": 0
                },
                {
                    "sent": "And establish the upper bound.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's proceed to the proof of our theorem.",
                    "label": 0
                },
                {
                    "sent": "So it's a reminder that it said that for every Class H, the ratio between the monetary rate and the error rate is upper bounded by 4K LO K, and since.",
                    "label": 1
                },
                {
                    "sent": "The air light equal to the latest on dimension.",
                    "label": 0
                },
                {
                    "sent": "Equivalently, we should show that.",
                    "label": 0
                },
                {
                    "sent": "The bandit error rate is upper bounded by 4K locate times.",
                    "label": 0
                },
                {
                    "sent": "The Little stone dimension of H. So before the 4th, let's try to see what happens if I try to use the same algorithm and imitate the analysis of the previous theorem.",
                    "label": 0
                },
                {
                    "sent": "So the problem is that after the algorithm Earth, the set of consistent hypothesis is union of K -- 1 classes of little dimension strictly smaller.",
                    "label": 1
                },
                {
                    "sent": "However, this union might be of Littlestown Dimension L. So then the analysis don't work.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I claim that in some sense, K -- 1 classes of little stone dimension, smaller indeed smaller than a single class of Littlestown dimension L. Because we can proceed as follows in the next K -- 1 else we can split each one of these classes so we can split this one.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then that.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One and then.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That one and continue doing so and split the little classes and.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you continue, continue doing so.",
                    "label": 0
                },
                {
                    "sent": "We will get some algorithm with finite mistake bound.",
                    "label": 1
                },
                {
                    "sent": "Unfortunately, it will be exponential in the littlest dimension, which is not good enough.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But nevertheless, the idea of the algorithm will be to partition H and somewhat more clever way, so that size at each step we have a partition of the set of consistent hypothesis an at each.",
                    "label": 1
                },
                {
                    "sent": "After each error will split some of these classes.",
                    "label": 0
                },
                {
                    "sent": "We will delete some others and that of will.",
                    "label": 0
                },
                {
                    "sent": "We remain unchanged and we will be doing so, aiming to minimize a measure of capacity which we define next.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we start with a single subclass.",
                    "label": 0
                },
                {
                    "sent": "We defined capacity of the Subclass V to be K2.",
                    "label": 1
                },
                {
                    "sent": "The two times the Little Stone dimension of V, and we accept extended this definition to a collection sigh of subclasses by summing over the different subclasses.",
                    "label": 1
                },
                {
                    "sent": "We also define splitting operator.",
                    "label": 0
                },
                {
                    "sent": "We define the split of V of XY to be set.",
                    "label": 0
                },
                {
                    "sent": "So this is a partition of the hypothesis in the that are consistent with the path after we have seen the instance X predicted Y and we were wrong and again we extend the definition to a collection type by taking a union over different subclasses.",
                    "label": 0
                },
                {
                    "sent": "So that we.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We simply posted a false start with the collection consisting only of the Class H itself and at each step you will receive some instance and we predict the label that maximum that minimizes the capacity of splitting according to this level, and if it's worth it, will split according to that label.",
                    "label": 0
                },
                {
                    "sent": "OK, so that is the algorithm and let me tell you a few words about the analysis so.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The crucial point is that if a subclass V is splitted in 2K minus one of classes of strictly strictly smaller than dimension, then its capacity shrinks by a factor of 1 / K and sense for every subclass we we have at least a single label that split it in this way by simple averaging argument, we conclude that there exists somewhere some level that shrink the total capacity by a factor of 1.",
                    "label": 0
                },
                {
                    "sent": "Minus 1 / 2 K Therefore.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After MLF the capacity shrinks by a factor of 1 -- 1 / 2 K to them.",
                    "label": 1
                },
                {
                    "sent": "And since the initial capacity is K to the two times.",
                    "label": 0
                },
                {
                    "sent": "After the correct number for Kelo case, time L Mistakes the capacity, shrinks to one, which means that we have only a single consistent hypothesis left, and from that point on, we will make no further else.",
                    "label": 1
                },
                {
                    "sent": "So that stab Lish is the proof.",
                    "label": 0
                },
                {
                    "sent": "OK, so let.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Summarize the main theorem tells us that the price of bandit information, the ratio between the bandit error rate, and the full info error rate is upper bounded by 4K OK and this is tight up to the local factor.",
                    "label": 1
                },
                {
                    "sent": "And if I told you assuming similar results holds also for the non realizable case, and you're welcome to come to the poster, I will tell me tell you a little bit more about it, and we also have an application to.",
                    "label": 1
                },
                {
                    "sent": "Large mountain half basis.",
                    "label": 0
                },
                {
                    "sent": "Using these two theorems, we can calculate almost exactly up to log factors.",
                    "label": 1
                },
                {
                    "sent": "The bandit error rate of large margin half passes to soldier.",
                    "label": 1
                },
                {
                    "sent": "General generalization of it to the multiclass scenario.",
                    "label": 0
                },
                {
                    "sent": "And let me conclude with two open questions.",
                    "label": 1
                },
                {
                    "sent": "The first immediate often open question is whether we can get rid of this.",
                    "label": 0
                },
                {
                    "sent": "Going low K factor and the second question is what happens if we restrict ourselves to efficient algorithms.",
                    "label": 0
                },
                {
                    "sent": "So I remind you that this work is information theoretic.",
                    "label": 0
                },
                {
                    "sent": "The algorithm we just so so with clearly inefficient.",
                    "label": 0
                },
                {
                    "sent": "And for example, we can ask the following question.",
                    "label": 0
                },
                {
                    "sent": "Suppose that I have some algorithm that is guaranteed to make at most M errors when it runs on a sequence that is realizable by edge.",
                    "label": 0
                },
                {
                    "sent": "So do I have an algorithm that is guaranteed to make at most, say K squared time, and else when it runs on such sequence in the bandit scenario?",
                    "label": 0
                },
                {
                    "sent": "And with that I conclude.",
                    "label": 0
                }
            ]
        }
    }
}