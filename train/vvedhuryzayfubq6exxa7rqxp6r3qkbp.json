{
    "id": "vvedhuryzayfubq6exxa7rqxp6r3qkbp",
    "title": "Exploratory Learning of Grasp Affordances",
    "info": {
        "author": [
            "Justus H. Piater, Institut f\u00fcr Informatik, University of Innsbruck"
        ],
        "published": "Nov. 8, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Robotics"
        ]
    },
    "url": "http://videolectures.net/rss2010_piater_elg/",
    "segmentation": [
        [
            "This will be very brief because I have exactly 2 minutes left or there's going to be a fairly short talk.",
            "Thank you very much.",
            "OK, you can have the microphone back.",
            "So the initial the first challenge of today's talk, the second challenge is that you've all eaten an I have also all eaten, so we all would like to take a nap now, but you can't because the organizers said you have to ask questions afterwards.",
            "So unfortunately you will have to follow my presentation.",
            "And ask some questions afterwards.",
            "Yes, yeah, that's the great challenge that I'm facing.",
            "OK, so I'm talking about exploratory learning of grasp affordances.",
            "Here's a little motivational."
        ],
        [
            "Lights, I'm also surprised nobody has shown motivated motivating an introduction from iRobot yet, but if we want to build autonomous artificial systems like from like we see in this movie.",
            "How how would you do that?",
            "What are key ingredients to four working for coping with a complex, unpredictable world and one key ingredient here is of course by equipping them with sufficient means of online learning, which is what part of this workshop is."
        ],
        [
            "About and what I'm going to talk about here is focus on is learning to do skillful grasping.",
            "So this is only a coarse approximation to the real colors, but I think you see.",
            "What this is supposed to mean?",
            "So what I'm going to talk about is our way of doing up learning how to grasp, using exploration and demonstration.",
            "This exploration can be totally random, can be biased, or it could be goal directed or active.",
            "Our representations involve specialized object models into which the grasp representations integrate seamlessly and this will play a particular role and the section when I'm going to talk about generalizing graph performances across objects.",
            "So in principle, these graphs performance learning is about known objects in specific objects, and then finally, I'll briefly talk about active.",
            "Knowning so this is."
        ],
        [
            "What the?",
            "Presentation is going to be about.",
            "I'm systematically missing the part bottom part of the screen, so I'm going to try.",
            "To resize and hope that this will improve the situation.",
            "That's better.",
            "OK now I'm missing part on the left, but I think that's less critical.",
            "OK, so this talk is going to be separated for sections.",
            "One brief section about learning these 3D specialized representations.",
            "Secondly, I'll talk about grasp density grasp densities, which is what we call our grass performance representations.",
            "Then I'll talk about how to generalize those between.",
            "Objects, and finally, I'll briefly talk about some recent work on active learning.",
            "So first about 3D."
        ],
        [
            "Object models, so here's an overview of of the idea.",
            "So first of all, we have through a project partner.",
            "We have a system that extracts 3D primitives such as store, so these are really primitives that live in 3D from a scene using stereo methods.",
            "And from those we construct object models in the form of Markov networks.",
            "So that we can formulate formulate the problem of recognizing, locating and estimating the pose of objects and scenes as inference on Markov networks.",
            "So once we have followed this dream here and have learned such representations, when we get a new scene, maybe cluttered scene that contains.",
            "A known object.",
            "Then we can locate that known object using probabilistic inference and recover its 3D pose, and then it's available for whatever we want to do with that problem solving interaction."
        ],
        [
            "Just one more illustration about these visual features, so this is essentially the.",
            "This is the input that we receive from the system that contains that consists of oriented three patches.",
            "That contains some color information, so we have different Patch types.",
            "And we have a 3D position and only a 2 dimensional orientational pose of each of these patches."
        ],
        [
            "Now I want to say a little more about how these representations work, because that will become important later on, so this is a well.",
            "This is also 3D example, except that this scene happens to be flat, but it makes it easier to describe.",
            "So in this case we have three different feature types that encode different color contrast, so we have this red black contrast.",
            "This black white contrast in this red white contrast.",
            "So these are three different feature types that are observed in this scene.",
            "And now from this, we hierarchically composed by automatic methods this Markov network that represents this object.",
            "So what we intuitively one resent is mutual geometric relations between pairs of features, and we do that by postulating sort of virtual virtual feature.",
            "Um?",
            "For example, at a.",
            "Position that we can choose essentially arbitrarily and re encode the relative position of that virtual feature to the actual features as potentials in this network.",
            "So what's labeled X4 up here X4 bridge pattern?",
            "That's a virtual feature that represents this bridge pattern and that's.",
            "That's a random variable that contains that will eventually, when the objects located contain the.",
            "The 60 pose of that bridge pattern in the scene.",
            "And these binary potentials represent relative locations, so we can think about this as this representing if X4 is located at a specific pose in 3D, then by virtue of these two potential side one forum site 2 four it knows where to look for features X1 and X2 and X1 and X2 are not located.",
            "One specific place in the scene, but in many different places.",
            "So this feature X1 occurs all around these.",
            "Red Black contrasts at this black white.",
            "Is arranged in the way this bridge pattern is arranged, so these potentials are actually spatial potential that can represent the entire spatial distribution of these underlying features everywhere in the scene.",
            "So similarly for the triangular frame which contains only a single feature type, and then again these two.",
            "Composed together to form a representation of the entire traffic sign.",
            "So vertices are random variables that contain the position or pose 60 pose of a feature in the scene, and the potentials the edges in this Markov network represent spatial relations.",
            "And how to infer the pose of a traffic sign and seen what we do is we.",
            "Look at the actual object future observations in the scene and.",
            "Instantiate the corresponding nodes in the network.",
            "Turn the probabilistic inference crank and come up with a posterior distribution in every node that represents the pose of that feature on the scene.",
            "And since there is one top level feature X6, we can take that to be the pose of the traffic sign in a scene.",
            "So."
        ],
        [
            "Brief shortcuts to move ahead here.",
            "Some results that you published to illustrate the kinds of performance we get out of this, so these are pose estimation results superimposed onto photographs of cluttered scenes and.",
            "Basically what we can say is that this works about as well as we can expect in the sense that if we look at the raw data and for in the form of the extracted 3D patches and we see some object structure in that reconstruction, then our system will be able to pull it out and whenever our pose estimator fails, then when we look at the data, most of the time.",
            "We don't see the object there either, so there's something else that's wrong, so this works fairly reliably."
        ],
        [
            "This basic machinery is not limited to these 3D patches.",
            "But we can also work with other types of data, so in this case this is depth data from for example, the laser Range Finder.",
            "Which is different in the sense that this is not sparse but dense, but mathematically it turns out to be exactly the same for each Patch.",
            "We also have a 5 depots where one orientation degree of freedom is missing.",
            "In this case, it's the orientation around the Patch normal, which is meaningless in this case, and in the case of the 3D patches, it's the orientation around the axis.",
            "Demarcating the boundary between the two colors that is essentially meaningless.",
            "So mathematically, it turns out to be exactly the same.",
            "And I'm showing you this because it will become important later on.",
            "We're going to use this kind of representation.",
            "So this is all I want to say about the object reference."
        ],
        [
            "Patients that we use.",
            "Now I want to move on to talk about learning to grasp objects.",
            "So the motivation is if I see an object such as this, how do I grasp it?",
            "Is my visual system going to reconstruct?",
            "The precise dramatic shape of this bottle and then my brain will compute optimal contact points taking.",
            "Slip it into account for example, and then compute optimal grasp that she's forced closure.",
            "I don't think that's going to happen.",
            "I think it's rather going to happen is that I have graphed such a bottle many times before, so when I see one even without any 3D information or explicitly information, I know how to do it, I move my hand to the position where always move it tool to grasp it.",
            "Bottle because I know it I've I've done that many times before and this worked, and this is the same intuition they want to apply here as well.",
            "You want to grasp objects many times, figure out remember what grasps.",
            "Work well in practice, and then associate those with the object models."
        ],
        [
            "So the immediate idea that we're following is.",
            "To just associate grasps into the same Markov network.",
            "So this is the same picture that we saw before, except that we now have this topmost block that says grasps.",
            "That also feeds into the learning part, and the crucial observation here is that a grasp is essentially an entity in the same space as all the other features.",
            "It's a it's a 60 feature if you will.",
            "A 60 virtual feature that describes the object relative pose of a gripper.",
            "Such that if the fingers are closed, the object is graphed, so that would be a successful grasp.",
            "So we're going to integrate them into the same model mathematically, there's no difference to between grasps and visual features or these higher level virtual features, and they all fit nicely together into the same representation.",
            "So when we then instantiate.",
            "An object in a scene based on the visual observations.",
            "Then we don't have a grasp.",
            "We cannot observe this grasp, but we can infer the grass just through the learned potentials.",
            "So the net effect of this is once you have learned such representation, when we see an object in the scene, we recognize it an estimate.",
            "It's posed by virtual inference within the network, then automatically at the end.",
            "We also have the group oppose in order to grasp it.",
            "Or an entire posterior distribution over group opposes useful for grasping that object, so in other words, when I see a bottle and I can't help but to know how to grasp it, it's the same thing.",
            "The bottle is characterized as much by its visual appearance as by.",
            "The types of grasps it affords.",
            "Yeah."
        ],
        [
            "An illustration of what I just said.",
            "So in addition to the visual features.",
            "Tripping over my own cable.",
            "In addition to that, to the visual features here we just have this graph feature, and that's an entire distribution or probabilistic density, which is why we call this a grasp density."
        ],
        [
            "Just to formalize that a little more grasp density is defined in terms of object relative group opposes.",
            "Um?",
            "Under the condition that the grasp succeeds, this is what we represent.",
            "This is the way to visualize graphs grasp.",
            "So if this is a, this is a gripper.",
            "Then if you want to draw grasp densities then drawing groups over the place would be what I did.",
            "Everything right, your group is fairly clunky thing, so we summarize this entire group by this little paddle.",
            "And so if you see in a subsequent picture such a paddle, you really have to think this is the pose of the gripper with respect to the object.",
            "And then since since we use nonparametric representations to kernel density estimation to turn these particles into continuous densities, you also think have to think about these in terms of carrying a 60 pose kernel around them, which for us is a separable kernel into a Gaussian.",
            "Isotropic position Colonel and an orientation Colonel.",
            "So here we use a demo slots and Colonel.",
            "We've also used to anti portal from Jesus Fisher Kernels in Quaternion space."
        ],
        [
            "So here, for example, is an example of a graph density associated with this model of a table tennis bat.",
            "So if you think of the.",
            "Grippers associated with these little paddles.",
            "Then these would all be plausable grasps and the right.",
            "It's just a different way of visualizing this.",
            "We're just the position of the gripper around the edges, visualized as a.",
            "As a shade of green that's proportional to the graph density at those positions.",
            "How do we?"
        ],
        [
            "One such graft densities is just a brief overview over the basic idea, so in principle what we have to do is we have to take the object and then try to grasp in all different ways, but in all different ways would mean to to sample sufficiently densely 6 dimensional pose space.",
            "That's not feasible.",
            "The chance of success would be way too low, so we have Tobias that sampling procedure somehow.",
            "What we do is we use we draw these graphs that we try out from.",
            "What we call grasp hypothesis density and these can come from various sources and with two basic sources, one of them is grasp hypothesis.",
            "Indicated by or derived from these visual features directly.",
            "Because there where you want to draft this, gotta be something visible.",
            "An example of resulting density is on the top right where I can't see anything because it's fairly dense sampling.",
            "We just see that the.",
            "Tips of these little paddles?",
            "This is much more structured already than just a random collection of pedals pointing all over the place.",
            "Or they could come from human demonstration.",
            "Human knows how to grasp them, and there's also different experiment that we've done.",
            "We can play save icon markers on a human hand, have a human grasp this bottle multiple times.",
            "I have 5 minutes left.",
            "I started at quarter past five and half.",
            "It's only halftime now.",
            "OK oh boy.",
            "Alright, so you draw these.",
            "This graph that you want to try out from this hypothesis density and you add it to empirical density.",
            "If it is successful.",
            "Essentially.",
            "Um?",
            "Where you make sure that by dividing by the corresponding hypothesis density.",
            "As an importance value, the empirical density converges to something that in theory at least, is independent.",
            "On the hypothesis density."
        ],
        [
            "So here's an example.",
            "On the left we have brass hypothesis and on the right we have some samples drawn from the resulting in pro density."
        ],
        [
            "Again, same thing visualized slightly differently in this case.",
            "So in the previous case we used visually encourage hypothesis dense the visually impaired hypothese density.",
            "In here we used human demonstration.",
            "So all of these graphs that we see on the left here are graphs demonstrate by human and on the right we see those that that some samples from the resulting empirical density and you'll see that there are much more focused.",
            "So this means that.",
            "Humans can grasp a bottle many or this teapot and much more flexible way than the kinetically limited.",
            "Three finger shrunk hands that we used for this.",
            "Only a subset of those glasses actually work for the robot.",
            "Now I'm going to skip the movie because I'm running out of time.",
            "I want to talk a little bit about part based.",
            "Generalization."
        ],
        [
            "So here the idea is.",
            "So all we've done so far is object specific, right?",
            "We have an object, we learn how to grasp it and we associate the grasp answer to that object model.",
            "Now in practice we would learn want to learn something more generic about the objects that we grab, so that if we learn how to grasp the handle.",
            "For example, if next time I had an object with the handle comes around then you want to be able to say oh here's the handle that's grasping at the handle.",
            "So now our method is not capable of doing that, but this is some extremely recent work.",
            "That I'm briefly going to touch upon in the minutes that rests on the idea is.",
            "To identify object parts.",
            "And associated local sections of grass density that are predictive of grass.",
            "Benefits of other objects.",
            "So if we can extract a part part such as a handle from one object, and it happens to match onto a different object, then the corresponding part of the graph density should also apply to the new object.",
            "That's the idea."
        ],
        [
            "So to simplify things, we use with the user reduced object model here.",
            "So this is all it boils down to.",
            "This is the same hierarchy that I showed you before now except that there is no hierarchy here, that's just object pose an two types of feature poses.",
            "There's only one type of feature.",
            "There's no color or nothing, is just pose.",
            "And on the other hand we have the grass density.",
            "So if you're going to be strict with me timing wise, then I think I'm going to skip the math slides that I so carefully prepared and."
        ],
        [
            "Skip right to some illustrative results.",
            "So on the left we have two objects of pan and a toy panda toy knife, and this is grasp density.",
            "Don't for a for this toy pan.",
            "Alright, and then we ran this algorithm that identifies parts.",
            "That are predictive of grasp densities of other objects, and if you want to know more details then I can't show them because I just skip the details.",
            "But here are two of these parts.",
            "That were found by this algorithm and one is really small and the other one looks like the handle of the pan.",
            "It actually is the hand of the pan, and this is an interesting part because it also happens to match the handle of the knife.",
            "So here we have a successful example of transfer.",
            "By virtue of this handle."
        ],
        [
            "Um?",
            "These crosses are barely visible.",
            "They still show an interesting.",
            "Affect here so on the.",
            "On the abscissa we have size of the extract parts.",
            "And on the vertical axis we have generalization measure that intuitively represents the usefulness of the of the part in terms of its generalization capabilities and what you see is that large, very large parts are not very useful, and that's simply because large parts tend not to fit onto other objects, right?",
            "There are two objects specific extremely small parts are useless as well because they fit everywhere and they are absolutely unpredictive of grasping properties.",
            "So the maximum in both of these cases is somewhere somewhere around here and in the.",
            "In a region where all the parts are relatively small."
        ],
        [
            "We ran a bunch of simulated experiments on these four objects.",
            "I'm going to move ahead fast to save some time.",
            "Here's here's another part extracted on these simulated objects.",
            "So what this part represents is around it surface shape.",
            "That fits these different objects.",
            "That we see here, right?",
            "All of these have this kind of rounded surface and they are afford similar types of grasps around the entire object, so the system manage."
        ],
        [
            "To pull that out.",
            "This is the visual part of the visual feature.",
            "Part of that part, and this is the grass density part of the extracted part.",
            "This is just a more dense sampling that illustrates that there is some degree of freedom around that part that correlates with the grasp ability."
        ],
        [
            "To quantify that a little bit here, the percentage of success of the grasps during learning and so the.",
            "This learning was used hypothesis densities derived either from basic visual features, or from this generalization mechanism that I briefly touched upon.",
            "And if you use this generalization mechanism, then essentially three times more of your grasp attempts during the learning phase succeed.",
            "How much time do you give me?",
            "2 minutes.",
            "OK, so that means I can spend.",
            "One minute on the paper that you wanted me."
        ],
        [
            "Talk about.",
            "So what we've talked about so far is in terms of these graphs.",
            "Densities grasp densities are generative model of grasps, and they seem to characterize an entire grass performance all around the object.",
            "And they said they integrate seamlessly with our specific visual models, which comes in handy for this generalization procedure.",
            "However, you can do things differently if you want to.",
            "So, for example, what what we did at the Max Planck Institute was to say OK, instead of learning the entire graph, performs all around the object.",
            "Let's focus on just the few best grasping positions, and then you have a different learning problem where you can learn these specific parts with.",
            "In a much more efficient way than if you try to characterize the whole thing.",
            "And this is set up such that can work with any pose estimator.",
            "They just have.",
            "We just happen to use the same pose estimator as we use here and we can learn more than just gripper."
        ],
        [
            "Pose.",
            "Here's the basic architecture.",
            "I don't want to go into all that detail.",
            "The main distinction here is that we have a two level system on the upper level.",
            "We have a reinforcement learning system that.",
            "Tries to identify the best 660 object relative pose is useful for grasping and at the bottom we have a reactive lower level that implements the actual detail to make it happen, including the approach of the hand to the object and pre shaping the hand using visual features as attractors and other visual features as distractors such that you don't collide with the object in unexpected unintended ways.",
            "Um?",
            "Well, since I'm running out of time."
        ],
        [
            "I'm just going to show you an example of final pre shapes learned in this way so.",
            "Depending on the type of object we have to do with, they work very differently.",
            "If you want to see the details, there's publication coming up in robotics in the systems.",
            "But now I'm running out of time, I'm told."
        ],
        [
            "So I just want to give credit where credit is due.",
            "The bottom is cut off so Giannis without a name here.",
            "This is not a krugerrand.",
            "This is John Peters on the bottom right.",
            "Except for this this final part that I showed you this essentially the work of the Notrees dissertation.",
            "We should just handed in a few days ago.",
            "And much of the robotics experiments and the visual low level features are the work of these two people at the University of Southern Denmark.",
            "And the reinforcement learning two level system is part of the doctoral studies of Oliver Chroma.",
            "Turn time."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This will be very brief because I have exactly 2 minutes left or there's going to be a fairly short talk.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "OK, you can have the microphone back.",
                    "label": 0
                },
                {
                    "sent": "So the initial the first challenge of today's talk, the second challenge is that you've all eaten an I have also all eaten, so we all would like to take a nap now, but you can't because the organizers said you have to ask questions afterwards.",
                    "label": 0
                },
                {
                    "sent": "So unfortunately you will have to follow my presentation.",
                    "label": 0
                },
                {
                    "sent": "And ask some questions afterwards.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah, that's the great challenge that I'm facing.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm talking about exploratory learning of grasp affordances.",
                    "label": 1
                },
                {
                    "sent": "Here's a little motivational.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lights, I'm also surprised nobody has shown motivated motivating an introduction from iRobot yet, but if we want to build autonomous artificial systems like from like we see in this movie.",
                    "label": 1
                },
                {
                    "sent": "How how would you do that?",
                    "label": 0
                },
                {
                    "sent": "What are key ingredients to four working for coping with a complex, unpredictable world and one key ingredient here is of course by equipping them with sufficient means of online learning, which is what part of this workshop is.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About and what I'm going to talk about here is focus on is learning to do skillful grasping.",
                    "label": 1
                },
                {
                    "sent": "So this is only a coarse approximation to the real colors, but I think you see.",
                    "label": 0
                },
                {
                    "sent": "What this is supposed to mean?",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to talk about is our way of doing up learning how to grasp, using exploration and demonstration.",
                    "label": 0
                },
                {
                    "sent": "This exploration can be totally random, can be biased, or it could be goal directed or active.",
                    "label": 0
                },
                {
                    "sent": "Our representations involve specialized object models into which the grasp representations integrate seamlessly and this will play a particular role and the section when I'm going to talk about generalizing graph performances across objects.",
                    "label": 1
                },
                {
                    "sent": "So in principle, these graphs performance learning is about known objects in specific objects, and then finally, I'll briefly talk about active.",
                    "label": 0
                },
                {
                    "sent": "Knowning so this is.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What the?",
                    "label": 0
                },
                {
                    "sent": "Presentation is going to be about.",
                    "label": 0
                },
                {
                    "sent": "I'm systematically missing the part bottom part of the screen, so I'm going to try.",
                    "label": 0
                },
                {
                    "sent": "To resize and hope that this will improve the situation.",
                    "label": 0
                },
                {
                    "sent": "That's better.",
                    "label": 0
                },
                {
                    "sent": "OK now I'm missing part on the left, but I think that's less critical.",
                    "label": 0
                },
                {
                    "sent": "OK, so this talk is going to be separated for sections.",
                    "label": 0
                },
                {
                    "sent": "One brief section about learning these 3D specialized representations.",
                    "label": 0
                },
                {
                    "sent": "Secondly, I'll talk about grasp density grasp densities, which is what we call our grass performance representations.",
                    "label": 1
                },
                {
                    "sent": "Then I'll talk about how to generalize those between.",
                    "label": 0
                },
                {
                    "sent": "Objects, and finally, I'll briefly talk about some recent work on active learning.",
                    "label": 1
                },
                {
                    "sent": "So first about 3D.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Object models, so here's an overview of of the idea.",
                    "label": 0
                },
                {
                    "sent": "So first of all, we have through a project partner.",
                    "label": 0
                },
                {
                    "sent": "We have a system that extracts 3D primitives such as store, so these are really primitives that live in 3D from a scene using stereo methods.",
                    "label": 0
                },
                {
                    "sent": "And from those we construct object models in the form of Markov networks.",
                    "label": 0
                },
                {
                    "sent": "So that we can formulate formulate the problem of recognizing, locating and estimating the pose of objects and scenes as inference on Markov networks.",
                    "label": 0
                },
                {
                    "sent": "So once we have followed this dream here and have learned such representations, when we get a new scene, maybe cluttered scene that contains.",
                    "label": 0
                },
                {
                    "sent": "A known object.",
                    "label": 0
                },
                {
                    "sent": "Then we can locate that known object using probabilistic inference and recover its 3D pose, and then it's available for whatever we want to do with that problem solving interaction.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just one more illustration about these visual features, so this is essentially the.",
                    "label": 1
                },
                {
                    "sent": "This is the input that we receive from the system that contains that consists of oriented three patches.",
                    "label": 0
                },
                {
                    "sent": "That contains some color information, so we have different Patch types.",
                    "label": 0
                },
                {
                    "sent": "And we have a 3D position and only a 2 dimensional orientational pose of each of these patches.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I want to say a little more about how these representations work, because that will become important later on, so this is a well.",
                    "label": 0
                },
                {
                    "sent": "This is also 3D example, except that this scene happens to be flat, but it makes it easier to describe.",
                    "label": 0
                },
                {
                    "sent": "So in this case we have three different feature types that encode different color contrast, so we have this red black contrast.",
                    "label": 0
                },
                {
                    "sent": "This black white contrast in this red white contrast.",
                    "label": 0
                },
                {
                    "sent": "So these are three different feature types that are observed in this scene.",
                    "label": 0
                },
                {
                    "sent": "And now from this, we hierarchically composed by automatic methods this Markov network that represents this object.",
                    "label": 0
                },
                {
                    "sent": "So what we intuitively one resent is mutual geometric relations between pairs of features, and we do that by postulating sort of virtual virtual feature.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "For example, at a.",
                    "label": 0
                },
                {
                    "sent": "Position that we can choose essentially arbitrarily and re encode the relative position of that virtual feature to the actual features as potentials in this network.",
                    "label": 0
                },
                {
                    "sent": "So what's labeled X4 up here X4 bridge pattern?",
                    "label": 0
                },
                {
                    "sent": "That's a virtual feature that represents this bridge pattern and that's.",
                    "label": 0
                },
                {
                    "sent": "That's a random variable that contains that will eventually, when the objects located contain the.",
                    "label": 0
                },
                {
                    "sent": "The 60 pose of that bridge pattern in the scene.",
                    "label": 0
                },
                {
                    "sent": "And these binary potentials represent relative locations, so we can think about this as this representing if X4 is located at a specific pose in 3D, then by virtue of these two potential side one forum site 2 four it knows where to look for features X1 and X2 and X1 and X2 are not located.",
                    "label": 0
                },
                {
                    "sent": "One specific place in the scene, but in many different places.",
                    "label": 0
                },
                {
                    "sent": "So this feature X1 occurs all around these.",
                    "label": 0
                },
                {
                    "sent": "Red Black contrasts at this black white.",
                    "label": 0
                },
                {
                    "sent": "Is arranged in the way this bridge pattern is arranged, so these potentials are actually spatial potential that can represent the entire spatial distribution of these underlying features everywhere in the scene.",
                    "label": 0
                },
                {
                    "sent": "So similarly for the triangular frame which contains only a single feature type, and then again these two.",
                    "label": 0
                },
                {
                    "sent": "Composed together to form a representation of the entire traffic sign.",
                    "label": 0
                },
                {
                    "sent": "So vertices are random variables that contain the position or pose 60 pose of a feature in the scene, and the potentials the edges in this Markov network represent spatial relations.",
                    "label": 0
                },
                {
                    "sent": "And how to infer the pose of a traffic sign and seen what we do is we.",
                    "label": 0
                },
                {
                    "sent": "Look at the actual object future observations in the scene and.",
                    "label": 0
                },
                {
                    "sent": "Instantiate the corresponding nodes in the network.",
                    "label": 0
                },
                {
                    "sent": "Turn the probabilistic inference crank and come up with a posterior distribution in every node that represents the pose of that feature on the scene.",
                    "label": 0
                },
                {
                    "sent": "And since there is one top level feature X6, we can take that to be the pose of the traffic sign in a scene.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Brief shortcuts to move ahead here.",
                    "label": 0
                },
                {
                    "sent": "Some results that you published to illustrate the kinds of performance we get out of this, so these are pose estimation results superimposed onto photographs of cluttered scenes and.",
                    "label": 1
                },
                {
                    "sent": "Basically what we can say is that this works about as well as we can expect in the sense that if we look at the raw data and for in the form of the extracted 3D patches and we see some object structure in that reconstruction, then our system will be able to pull it out and whenever our pose estimator fails, then when we look at the data, most of the time.",
                    "label": 0
                },
                {
                    "sent": "We don't see the object there either, so there's something else that's wrong, so this works fairly reliably.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This basic machinery is not limited to these 3D patches.",
                    "label": 0
                },
                {
                    "sent": "But we can also work with other types of data, so in this case this is depth data from for example, the laser Range Finder.",
                    "label": 0
                },
                {
                    "sent": "Which is different in the sense that this is not sparse but dense, but mathematically it turns out to be exactly the same for each Patch.",
                    "label": 0
                },
                {
                    "sent": "We also have a 5 depots where one orientation degree of freedom is missing.",
                    "label": 0
                },
                {
                    "sent": "In this case, it's the orientation around the Patch normal, which is meaningless in this case, and in the case of the 3D patches, it's the orientation around the axis.",
                    "label": 0
                },
                {
                    "sent": "Demarcating the boundary between the two colors that is essentially meaningless.",
                    "label": 0
                },
                {
                    "sent": "So mathematically, it turns out to be exactly the same.",
                    "label": 0
                },
                {
                    "sent": "And I'm showing you this because it will become important later on.",
                    "label": 0
                },
                {
                    "sent": "We're going to use this kind of representation.",
                    "label": 0
                },
                {
                    "sent": "So this is all I want to say about the object reference.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Patients that we use.",
                    "label": 0
                },
                {
                    "sent": "Now I want to move on to talk about learning to grasp objects.",
                    "label": 1
                },
                {
                    "sent": "So the motivation is if I see an object such as this, how do I grasp it?",
                    "label": 0
                },
                {
                    "sent": "Is my visual system going to reconstruct?",
                    "label": 0
                },
                {
                    "sent": "The precise dramatic shape of this bottle and then my brain will compute optimal contact points taking.",
                    "label": 0
                },
                {
                    "sent": "Slip it into account for example, and then compute optimal grasp that she's forced closure.",
                    "label": 0
                },
                {
                    "sent": "I don't think that's going to happen.",
                    "label": 0
                },
                {
                    "sent": "I think it's rather going to happen is that I have graphed such a bottle many times before, so when I see one even without any 3D information or explicitly information, I know how to do it, I move my hand to the position where always move it tool to grasp it.",
                    "label": 0
                },
                {
                    "sent": "Bottle because I know it I've I've done that many times before and this worked, and this is the same intuition they want to apply here as well.",
                    "label": 0
                },
                {
                    "sent": "You want to grasp objects many times, figure out remember what grasps.",
                    "label": 0
                },
                {
                    "sent": "Work well in practice, and then associate those with the object models.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the immediate idea that we're following is.",
                    "label": 0
                },
                {
                    "sent": "To just associate grasps into the same Markov network.",
                    "label": 0
                },
                {
                    "sent": "So this is the same picture that we saw before, except that we now have this topmost block that says grasps.",
                    "label": 0
                },
                {
                    "sent": "That also feeds into the learning part, and the crucial observation here is that a grasp is essentially an entity in the same space as all the other features.",
                    "label": 0
                },
                {
                    "sent": "It's a it's a 60 feature if you will.",
                    "label": 0
                },
                {
                    "sent": "A 60 virtual feature that describes the object relative pose of a gripper.",
                    "label": 0
                },
                {
                    "sent": "Such that if the fingers are closed, the object is graphed, so that would be a successful grasp.",
                    "label": 0
                },
                {
                    "sent": "So we're going to integrate them into the same model mathematically, there's no difference to between grasps and visual features or these higher level virtual features, and they all fit nicely together into the same representation.",
                    "label": 0
                },
                {
                    "sent": "So when we then instantiate.",
                    "label": 0
                },
                {
                    "sent": "An object in a scene based on the visual observations.",
                    "label": 0
                },
                {
                    "sent": "Then we don't have a grasp.",
                    "label": 0
                },
                {
                    "sent": "We cannot observe this grasp, but we can infer the grass just through the learned potentials.",
                    "label": 0
                },
                {
                    "sent": "So the net effect of this is once you have learned such representation, when we see an object in the scene, we recognize it an estimate.",
                    "label": 0
                },
                {
                    "sent": "It's posed by virtual inference within the network, then automatically at the end.",
                    "label": 0
                },
                {
                    "sent": "We also have the group oppose in order to grasp it.",
                    "label": 0
                },
                {
                    "sent": "Or an entire posterior distribution over group opposes useful for grasping that object, so in other words, when I see a bottle and I can't help but to know how to grasp it, it's the same thing.",
                    "label": 0
                },
                {
                    "sent": "The bottle is characterized as much by its visual appearance as by.",
                    "label": 0
                },
                {
                    "sent": "The types of grasps it affords.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An illustration of what I just said.",
                    "label": 0
                },
                {
                    "sent": "So in addition to the visual features.",
                    "label": 0
                },
                {
                    "sent": "Tripping over my own cable.",
                    "label": 0
                },
                {
                    "sent": "In addition to that, to the visual features here we just have this graph feature, and that's an entire distribution or probabilistic density, which is why we call this a grasp density.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just to formalize that a little more grasp density is defined in terms of object relative group opposes.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Under the condition that the grasp succeeds, this is what we represent.",
                    "label": 0
                },
                {
                    "sent": "This is the way to visualize graphs grasp.",
                    "label": 0
                },
                {
                    "sent": "So if this is a, this is a gripper.",
                    "label": 1
                },
                {
                    "sent": "Then if you want to draw grasp densities then drawing groups over the place would be what I did.",
                    "label": 0
                },
                {
                    "sent": "Everything right, your group is fairly clunky thing, so we summarize this entire group by this little paddle.",
                    "label": 0
                },
                {
                    "sent": "And so if you see in a subsequent picture such a paddle, you really have to think this is the pose of the gripper with respect to the object.",
                    "label": 0
                },
                {
                    "sent": "And then since since we use nonparametric representations to kernel density estimation to turn these particles into continuous densities, you also think have to think about these in terms of carrying a 60 pose kernel around them, which for us is a separable kernel into a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Isotropic position Colonel and an orientation Colonel.",
                    "label": 0
                },
                {
                    "sent": "So here we use a demo slots and Colonel.",
                    "label": 0
                },
                {
                    "sent": "We've also used to anti portal from Jesus Fisher Kernels in Quaternion space.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here, for example, is an example of a graph density associated with this model of a table tennis bat.",
                    "label": 0
                },
                {
                    "sent": "So if you think of the.",
                    "label": 0
                },
                {
                    "sent": "Grippers associated with these little paddles.",
                    "label": 0
                },
                {
                    "sent": "Then these would all be plausable grasps and the right.",
                    "label": 0
                },
                {
                    "sent": "It's just a different way of visualizing this.",
                    "label": 0
                },
                {
                    "sent": "We're just the position of the gripper around the edges, visualized as a.",
                    "label": 0
                },
                {
                    "sent": "As a shade of green that's proportional to the graph density at those positions.",
                    "label": 0
                },
                {
                    "sent": "How do we?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One such graft densities is just a brief overview over the basic idea, so in principle what we have to do is we have to take the object and then try to grasp in all different ways, but in all different ways would mean to to sample sufficiently densely 6 dimensional pose space.",
                    "label": 0
                },
                {
                    "sent": "That's not feasible.",
                    "label": 0
                },
                {
                    "sent": "The chance of success would be way too low, so we have Tobias that sampling procedure somehow.",
                    "label": 0
                },
                {
                    "sent": "What we do is we use we draw these graphs that we try out from.",
                    "label": 0
                },
                {
                    "sent": "What we call grasp hypothesis density and these can come from various sources and with two basic sources, one of them is grasp hypothesis.",
                    "label": 1
                },
                {
                    "sent": "Indicated by or derived from these visual features directly.",
                    "label": 0
                },
                {
                    "sent": "Because there where you want to draft this, gotta be something visible.",
                    "label": 0
                },
                {
                    "sent": "An example of resulting density is on the top right where I can't see anything because it's fairly dense sampling.",
                    "label": 0
                },
                {
                    "sent": "We just see that the.",
                    "label": 0
                },
                {
                    "sent": "Tips of these little paddles?",
                    "label": 0
                },
                {
                    "sent": "This is much more structured already than just a random collection of pedals pointing all over the place.",
                    "label": 0
                },
                {
                    "sent": "Or they could come from human demonstration.",
                    "label": 0
                },
                {
                    "sent": "Human knows how to grasp them, and there's also different experiment that we've done.",
                    "label": 0
                },
                {
                    "sent": "We can play save icon markers on a human hand, have a human grasp this bottle multiple times.",
                    "label": 0
                },
                {
                    "sent": "I have 5 minutes left.",
                    "label": 0
                },
                {
                    "sent": "I started at quarter past five and half.",
                    "label": 0
                },
                {
                    "sent": "It's only halftime now.",
                    "label": 0
                },
                {
                    "sent": "OK oh boy.",
                    "label": 0
                },
                {
                    "sent": "Alright, so you draw these.",
                    "label": 0
                },
                {
                    "sent": "This graph that you want to try out from this hypothesis density and you add it to empirical density.",
                    "label": 0
                },
                {
                    "sent": "If it is successful.",
                    "label": 0
                },
                {
                    "sent": "Essentially.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Where you make sure that by dividing by the corresponding hypothesis density.",
                    "label": 0
                },
                {
                    "sent": "As an importance value, the empirical density converges to something that in theory at least, is independent.",
                    "label": 1
                },
                {
                    "sent": "On the hypothesis density.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "On the left we have brass hypothesis and on the right we have some samples drawn from the resulting in pro density.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, same thing visualized slightly differently in this case.",
                    "label": 0
                },
                {
                    "sent": "So in the previous case we used visually encourage hypothesis dense the visually impaired hypothese density.",
                    "label": 0
                },
                {
                    "sent": "In here we used human demonstration.",
                    "label": 0
                },
                {
                    "sent": "So all of these graphs that we see on the left here are graphs demonstrate by human and on the right we see those that that some samples from the resulting empirical density and you'll see that there are much more focused.",
                    "label": 0
                },
                {
                    "sent": "So this means that.",
                    "label": 0
                },
                {
                    "sent": "Humans can grasp a bottle many or this teapot and much more flexible way than the kinetically limited.",
                    "label": 0
                },
                {
                    "sent": "Three finger shrunk hands that we used for this.",
                    "label": 0
                },
                {
                    "sent": "Only a subset of those glasses actually work for the robot.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to skip the movie because I'm running out of time.",
                    "label": 0
                },
                {
                    "sent": "I want to talk a little bit about part based.",
                    "label": 0
                },
                {
                    "sent": "Generalization.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here the idea is.",
                    "label": 0
                },
                {
                    "sent": "So all we've done so far is object specific, right?",
                    "label": 0
                },
                {
                    "sent": "We have an object, we learn how to grasp it and we associate the grasp answer to that object model.",
                    "label": 0
                },
                {
                    "sent": "Now in practice we would learn want to learn something more generic about the objects that we grab, so that if we learn how to grasp the handle.",
                    "label": 0
                },
                {
                    "sent": "For example, if next time I had an object with the handle comes around then you want to be able to say oh here's the handle that's grasping at the handle.",
                    "label": 0
                },
                {
                    "sent": "So now our method is not capable of doing that, but this is some extremely recent work.",
                    "label": 0
                },
                {
                    "sent": "That I'm briefly going to touch upon in the minutes that rests on the idea is.",
                    "label": 0
                },
                {
                    "sent": "To identify object parts.",
                    "label": 0
                },
                {
                    "sent": "And associated local sections of grass density that are predictive of grass.",
                    "label": 0
                },
                {
                    "sent": "Benefits of other objects.",
                    "label": 0
                },
                {
                    "sent": "So if we can extract a part part such as a handle from one object, and it happens to match onto a different object, then the corresponding part of the graph density should also apply to the new object.",
                    "label": 0
                },
                {
                    "sent": "That's the idea.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to simplify things, we use with the user reduced object model here.",
                    "label": 1
                },
                {
                    "sent": "So this is all it boils down to.",
                    "label": 1
                },
                {
                    "sent": "This is the same hierarchy that I showed you before now except that there is no hierarchy here, that's just object pose an two types of feature poses.",
                    "label": 0
                },
                {
                    "sent": "There's only one type of feature.",
                    "label": 0
                },
                {
                    "sent": "There's no color or nothing, is just pose.",
                    "label": 0
                },
                {
                    "sent": "And on the other hand we have the grass density.",
                    "label": 0
                },
                {
                    "sent": "So if you're going to be strict with me timing wise, then I think I'm going to skip the math slides that I so carefully prepared and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Skip right to some illustrative results.",
                    "label": 0
                },
                {
                    "sent": "So on the left we have two objects of pan and a toy panda toy knife, and this is grasp density.",
                    "label": 0
                },
                {
                    "sent": "Don't for a for this toy pan.",
                    "label": 0
                },
                {
                    "sent": "Alright, and then we ran this algorithm that identifies parts.",
                    "label": 0
                },
                {
                    "sent": "That are predictive of grasp densities of other objects, and if you want to know more details then I can't show them because I just skip the details.",
                    "label": 1
                },
                {
                    "sent": "But here are two of these parts.",
                    "label": 0
                },
                {
                    "sent": "That were found by this algorithm and one is really small and the other one looks like the handle of the pan.",
                    "label": 0
                },
                {
                    "sent": "It actually is the hand of the pan, and this is an interesting part because it also happens to match the handle of the knife.",
                    "label": 0
                },
                {
                    "sent": "So here we have a successful example of transfer.",
                    "label": 0
                },
                {
                    "sent": "By virtue of this handle.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "These crosses are barely visible.",
                    "label": 0
                },
                {
                    "sent": "They still show an interesting.",
                    "label": 0
                },
                {
                    "sent": "Affect here so on the.",
                    "label": 0
                },
                {
                    "sent": "On the abscissa we have size of the extract parts.",
                    "label": 0
                },
                {
                    "sent": "And on the vertical axis we have generalization measure that intuitively represents the usefulness of the of the part in terms of its generalization capabilities and what you see is that large, very large parts are not very useful, and that's simply because large parts tend not to fit onto other objects, right?",
                    "label": 0
                },
                {
                    "sent": "There are two objects specific extremely small parts are useless as well because they fit everywhere and they are absolutely unpredictive of grasping properties.",
                    "label": 0
                },
                {
                    "sent": "So the maximum in both of these cases is somewhere somewhere around here and in the.",
                    "label": 0
                },
                {
                    "sent": "In a region where all the parts are relatively small.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We ran a bunch of simulated experiments on these four objects.",
                    "label": 1
                },
                {
                    "sent": "I'm going to move ahead fast to save some time.",
                    "label": 0
                },
                {
                    "sent": "Here's here's another part extracted on these simulated objects.",
                    "label": 0
                },
                {
                    "sent": "So what this part represents is around it surface shape.",
                    "label": 0
                },
                {
                    "sent": "That fits these different objects.",
                    "label": 0
                },
                {
                    "sent": "That we see here, right?",
                    "label": 0
                },
                {
                    "sent": "All of these have this kind of rounded surface and they are afford similar types of grasps around the entire object, so the system manage.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To pull that out.",
                    "label": 0
                },
                {
                    "sent": "This is the visual part of the visual feature.",
                    "label": 0
                },
                {
                    "sent": "Part of that part, and this is the grass density part of the extracted part.",
                    "label": 0
                },
                {
                    "sent": "This is just a more dense sampling that illustrates that there is some degree of freedom around that part that correlates with the grasp ability.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To quantify that a little bit here, the percentage of success of the grasps during learning and so the.",
                    "label": 0
                },
                {
                    "sent": "This learning was used hypothesis densities derived either from basic visual features, or from this generalization mechanism that I briefly touched upon.",
                    "label": 0
                },
                {
                    "sent": "And if you use this generalization mechanism, then essentially three times more of your grasp attempts during the learning phase succeed.",
                    "label": 0
                },
                {
                    "sent": "How much time do you give me?",
                    "label": 0
                },
                {
                    "sent": "2 minutes.",
                    "label": 0
                },
                {
                    "sent": "OK, so that means I can spend.",
                    "label": 0
                },
                {
                    "sent": "One minute on the paper that you wanted me.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Talk about.",
                    "label": 0
                },
                {
                    "sent": "So what we've talked about so far is in terms of these graphs.",
                    "label": 0
                },
                {
                    "sent": "Densities grasp densities are generative model of grasps, and they seem to characterize an entire grass performance all around the object.",
                    "label": 0
                },
                {
                    "sent": "And they said they integrate seamlessly with our specific visual models, which comes in handy for this generalization procedure.",
                    "label": 1
                },
                {
                    "sent": "However, you can do things differently if you want to.",
                    "label": 0
                },
                {
                    "sent": "So, for example, what what we did at the Max Planck Institute was to say OK, instead of learning the entire graph, performs all around the object.",
                    "label": 0
                },
                {
                    "sent": "Let's focus on just the few best grasping positions, and then you have a different learning problem where you can learn these specific parts with.",
                    "label": 0
                },
                {
                    "sent": "In a much more efficient way than if you try to characterize the whole thing.",
                    "label": 0
                },
                {
                    "sent": "And this is set up such that can work with any pose estimator.",
                    "label": 1
                },
                {
                    "sent": "They just have.",
                    "label": 0
                },
                {
                    "sent": "We just happen to use the same pose estimator as we use here and we can learn more than just gripper.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pose.",
                    "label": 0
                },
                {
                    "sent": "Here's the basic architecture.",
                    "label": 0
                },
                {
                    "sent": "I don't want to go into all that detail.",
                    "label": 0
                },
                {
                    "sent": "The main distinction here is that we have a two level system on the upper level.",
                    "label": 0
                },
                {
                    "sent": "We have a reinforcement learning system that.",
                    "label": 0
                },
                {
                    "sent": "Tries to identify the best 660 object relative pose is useful for grasping and at the bottom we have a reactive lower level that implements the actual detail to make it happen, including the approach of the hand to the object and pre shaping the hand using visual features as attractors and other visual features as distractors such that you don't collide with the object in unexpected unintended ways.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Well, since I'm running out of time.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm just going to show you an example of final pre shapes learned in this way so.",
                    "label": 0
                },
                {
                    "sent": "Depending on the type of object we have to do with, they work very differently.",
                    "label": 0
                },
                {
                    "sent": "If you want to see the details, there's publication coming up in robotics in the systems.",
                    "label": 0
                },
                {
                    "sent": "But now I'm running out of time, I'm told.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I just want to give credit where credit is due.",
                    "label": 0
                },
                {
                    "sent": "The bottom is cut off so Giannis without a name here.",
                    "label": 0
                },
                {
                    "sent": "This is not a krugerrand.",
                    "label": 0
                },
                {
                    "sent": "This is John Peters on the bottom right.",
                    "label": 0
                },
                {
                    "sent": "Except for this this final part that I showed you this essentially the work of the Notrees dissertation.",
                    "label": 0
                },
                {
                    "sent": "We should just handed in a few days ago.",
                    "label": 0
                },
                {
                    "sent": "And much of the robotics experiments and the visual low level features are the work of these two people at the University of Southern Denmark.",
                    "label": 0
                },
                {
                    "sent": "And the reinforcement learning two level system is part of the doctoral studies of Oliver Chroma.",
                    "label": 0
                },
                {
                    "sent": "Turn time.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}