{
    "id": "5dsonpacxhhjrwnypab2lfuhptcvzjxp",
    "title": "Hierarchical Multi-Stream Posterior Based Speech Recognition System",
    "info": {
        "author": [
            "Hamed Ketabdar, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "June 2005",
        "category": [
            "Top->Computer Science->Speech Analysis"
        ]
    },
    "url": "http://videolectures.net/mlmi04uk_ketabdar_hmspb/",
    "segmentation": [
        [
            "These are the longest range exterior based speech recognition system.",
            "Hello everybody, I will talk about the hierarchical multi stream posterior based speech recognition system."
        ],
        [
            "Actually, there are two main messages in this time, so the first main message in this talk is to propose an utility pole framework for getting more informative posteriors by taking into account some extra knowledge about the problem, so we expect, so we expect to have more informative procedures comparing to the usual way of posterior estimations, which we use neural network, or specifically MLP, well based on this.",
            "To discuss framework, we will be able to introduce prior knowledge about the problem and contextual information and we can get estimate of posteriors out of multiple stream of features which can have complementary information.",
            "So if we for example focus to the case of a speech recognition problem, we can introduce information about phoneme duration or phoning transition probabilities in the posterior estimation.",
            "OK."
        ],
        [
            "Second message will be to use this posterior estimation idea in designing hierarchical structure for processing the sequences.",
            "So we divide the problem in different levels of hierarchy and then we integrate proper prior knowledge contextual information at the proper level and we can combine different evidences we have about the problem at the proper level.",
            "This diagram shows just one example.",
            "For the case of the speech recognition.",
            "So as you see, the first layer gets some do some feature extraction or posterior estimation.",
            "Both of their speech signal.",
            "Then in the second layer we can somehow start introducing prior knowledge about the problem and combine different evidences we have and this will give us more informative features or posteriors.",
            "And finally we use this more informative features or posterior in the last.",
            "Layer for training and inference.",
            "So dividing the problem like this will let us to find the proper level or layer and the proper knowledge which we can use to get better features or better posterior estimates specifically."
        ],
        [
            "Well, OK, so let's start with the very brief review office using posteriors and estimating posteriors in speech recognition systems.",
            "So normally we get a very time limited window of his speech signal and represented by some caps roll or spectral feature.",
            "Then this feature vector is processed by neural network to get some phony evidence is in the form of posterior and then this.",
            "Phone posteriors are used as featured or as local scores for doing training and inference, or just doing the decoding, but the main point is it should be.",
            "Notice that usually we just see very time limited window of the speech signal.",
            "I mean the MLP sees very time limited window for speech signal and well there is no way to introduce information about.",
            "Some kind of prior information, like finding minimum duration, like if a phoneme can appear after another phone or things like this when we use the MLP to get the posterior estimates."
        ],
        [
            "But we always know that there is a.",
            "Information about funding is completely extended overtime and there is no such kind of hard boundaries between phonemes, and obviously there is always some prior knowledge and assumptions about the problem, so the main question and the main motivation in this talk is is there any way to introduce this kind of posterior in formation?",
            "Prior information and contextual information in the posterior estimation to have more informative posteriors.",
            "So."
        ],
        [
            "So here we propose the idea which we call it gamma posterior estimation.",
            "So based on this idea we get the estimated posterior out of.",
            "Hidden Markov model and based on state, posterior definition.",
            "So as you probably know, the day state, is the probability of being in a specific HMM state at time T having the.",
            "Having the model M introducing some prior knowledge about the problem and the whole observation sequence.",
            "So by defining a posterior like peace and estimating the posterior like this, we expect to end up with more informative posteriors than the usual way of posterior summation because it will let us to introduce these two more knowledge.",
            "The prior knowledge about the problem and complete contextual information.",
            "And here we see just."
        ],
        [
            "Rabbit details about how this compensate, posterior can be estimated so it is written in terms of forward and backward hmm recursions, and then this forward and backward hmm.",
            "Recursions are written in terms of emission likelihoods or emission state.",
            "Likelihoods and state transition probabilities."
        ],
        [
            "Just to have some feeling about how this idea works, this isn't a slide showing some visualizing, so the figure under left shows the form posterior estimation by MLP for an utterance speech utterance.",
            "The exact axis shows the time our samples and Y axis shows the phone index and the intensity level shows the value of posterior so.",
            "More dark means higher value for the posterior and the one on the left shows the same story, but this time phone posteriors are estimated by, estimation method and we actually introduced a priority very simple prior knowledge about the problem, so we assume that phoning duration, minimum phone duration is at least three, and as you can compare figures, the second one looks to be more informative.",
            "This is well.",
            "This is just to be visualized the case, and I'm not going to make a well conclusion.",
            "You will see the results after.",
            "OK, well now knowing this gamma posterior."
        ],
        [
            "Estimation method, let's do one more step and get the estimate of posterior out of multiple stream of features.",
            "So it's the same as before, but this time we have multiple stream of features which can have some complementary information.",
            "So we define multistream state, as the probability of being in a specific HMM state.",
            "Or, well, let's say a specific phoneme at time T having their model M, including prior knowledge about the problem.",
            "And having multiple stream of features which can have complementary information and also whole observation sequence, which means blank contextual information for each.",
            "So we even get more informative posteriors because now in addition to the features we had before, we can combine the different evidences we have.",
            "And this is mainly the idea in which we use after to make a hierarchical speech recognition system."
        ],
        [
            "OK, in this slide you should you see just some details about how we can get this multi stream estate, So we define you forward and backward multistream recursions and it can be shown that based on some independence assumptions they can be written in terms of single stream forward and backward recursion.",
            "And finally, it can be shown that multi stream state Commerce can be written in terms of multi stream forward and backward recursion.",
            "We"
        ],
        [
            "We know we know about the story and how it works and what is the main idea.",
            "So the main idea was to combine multiple stream of features and also introduced contextual information and prior knowledge about the problem.",
            "So I will show you some initial experiments and results.",
            "The first question regarding the experiments which streams to combine.",
            "So obviously the streams which."
        ],
        [
            "Will be combined.",
            "Should have some kind of complementary information, well concerning this.",
            "For example, we can combine PLP, capsule features and trap features.",
            "One have capsular spectral feature and the other one temporal features, or we can combine static or dynamic features like PLP's or Delta PLP, but for experiment we combined these two features."
        ],
        [
            "OK, so well, here we.",
            "We wish to reach to the second idea of this talk while designing the hierarchical system well.",
            "Specifically in this talk for the speech recognition problem.",
            "Based on this idea, which is, as you see, is conceptually similar to what I talked about in the first slide.",
            "So we get some initial phone posteriors out of PLP and trap features by using MLP or a hierarchy of MLP.",
            "Then we turn it to phone a scale likelihoods and be used.",
            "This phone is scale likelihoods in the.",
            "Monte Spring forward and backward occasions to get estimate of multi stream commas, which band?",
            "Because here I assume a phoneme is represented by one state.",
            "I can say multi stream formed posterior and then after some transformation I will use this schedule as features for a standard HMM GMM train inference system like the random system similar to turn off system.",
            "We have divided the problem into different subproblems and at each step we can do the proper processing.",
            "So initial posterior estimation, then combination, and here is the point that we can also introduce the prior knowledge of our problem or take more contextual information and finally doing the.",
            "Train and influence at the last player, but by the features which are more informative than the initial features.",
            "And for the experiment I will show, I assume ergotic model with uniform transition for probability for this state, just for the initial experiments.",
            "So here we."
        ],
        [
            "See some initial results.",
            "I used two different databases to test the method.",
            "So or GI database or GI digits database and they are plastic.",
            "Is database the tables are showing the same result for the same experiments but for different databases?",
            "So first column is showing the features which then used in standard HMM GMM train different system well so they're all features and then.",
            "The same thing happens for all of them using as using in a standard HMM GMM train inference system.",
            "So first row is Pierre.",
            "People stereos getting summative, Posterio sort of PLP features by MLP and then feeding it to the next layer.",
            "The 2nd row is trapped posterior so the same story and the third row is the combination of these PLP and trapper stereos by inverse entropy combination method and the last row is our method which combines PLP and track posteriors by.",
            "Team, posterior idea and then feeding this posteriors to standard HMM human train you print system as you see our method performs better than the inverse entropy combination and also the single stream which are used for the combination.",
            "Well."
        ],
        [
            "I want to make 2 conclusions out of the stack, so here we propose a new touristical framework and we show just some initial results for a new kind of posterior estimation which will let us to get estimate of posteriors out of multiple stream of features.",
            "We can say this is also a way to combine different stream of features and in the same time we can introduce prior knowledge about the problem like phoneme durations.",
            "And lexical information in the posterior estimation and take long contextual information for the posterior estimation.",
            "The second conclusion is to use this to use this posterior estimation idea to design hierarchical speech, speech recognition system and divide the problem in the different levels.",
            "Well, I showed this case for in this slide I was presenting their hierarchical speech recognition system.",
            "OK, thank you very much.",
            "Using more constraints to computer.",
            "Yes, but it is not represented in this talk well.",
            "I just used a complete constrained model like the configuration we use for stereo estimation.",
            "So let's say I get estimates of grandmas out of the complete network.",
            "We normally run to get the result for speech recognition system and then we observe that in this case, well, we didn't do the experiment like explained here.",
            "We didn't use this.",
            "Plus they use as features, but we then did recording using this gammas coming from a complete network and then we observe that there is also a property which was not shown here and based on this posterior estimation via the system will be less sensitive to the tuning factors.",
            "For example, you know that we have we have to tune something like word insertion penalties normally to get the.",
            "Highest performance possible, but it was shown that in this case we don't need to tune.",
            "It immediately gives us the highest performance possible without any tuning.",
            "OK. Alright well thanks everybody for."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are the longest range exterior based speech recognition system.",
                    "label": 0
                },
                {
                    "sent": "Hello everybody, I will talk about the hierarchical multi stream posterior based speech recognition system.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, there are two main messages in this time, so the first main message in this talk is to propose an utility pole framework for getting more informative posteriors by taking into account some extra knowledge about the problem, so we expect, so we expect to have more informative procedures comparing to the usual way of posterior estimations, which we use neural network, or specifically MLP, well based on this.",
                    "label": 0
                },
                {
                    "sent": "To discuss framework, we will be able to introduce prior knowledge about the problem and contextual information and we can get estimate of posteriors out of multiple stream of features which can have complementary information.",
                    "label": 1
                },
                {
                    "sent": "So if we for example focus to the case of a speech recognition problem, we can introduce information about phoneme duration or phoning transition probabilities in the posterior estimation.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Second message will be to use this posterior estimation idea in designing hierarchical structure for processing the sequences.",
                    "label": 0
                },
                {
                    "sent": "So we divide the problem in different levels of hierarchy and then we integrate proper prior knowledge contextual information at the proper level and we can combine different evidences we have about the problem at the proper level.",
                    "label": 0
                },
                {
                    "sent": "This diagram shows just one example.",
                    "label": 0
                },
                {
                    "sent": "For the case of the speech recognition.",
                    "label": 1
                },
                {
                    "sent": "So as you see, the first layer gets some do some feature extraction or posterior estimation.",
                    "label": 0
                },
                {
                    "sent": "Both of their speech signal.",
                    "label": 0
                },
                {
                    "sent": "Then in the second layer we can somehow start introducing prior knowledge about the problem and combine different evidences we have and this will give us more informative features or posteriors.",
                    "label": 0
                },
                {
                    "sent": "And finally we use this more informative features or posterior in the last.",
                    "label": 0
                },
                {
                    "sent": "Layer for training and inference.",
                    "label": 0
                },
                {
                    "sent": "So dividing the problem like this will let us to find the proper level or layer and the proper knowledge which we can use to get better features or better posterior estimates specifically.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, OK, so let's start with the very brief review office using posteriors and estimating posteriors in speech recognition systems.",
                    "label": 1
                },
                {
                    "sent": "So normally we get a very time limited window of his speech signal and represented by some caps roll or spectral feature.",
                    "label": 0
                },
                {
                    "sent": "Then this feature vector is processed by neural network to get some phony evidence is in the form of posterior and then this.",
                    "label": 0
                },
                {
                    "sent": "Phone posteriors are used as featured or as local scores for doing training and inference, or just doing the decoding, but the main point is it should be.",
                    "label": 1
                },
                {
                    "sent": "Notice that usually we just see very time limited window of the speech signal.",
                    "label": 0
                },
                {
                    "sent": "I mean the MLP sees very time limited window for speech signal and well there is no way to introduce information about.",
                    "label": 0
                },
                {
                    "sent": "Some kind of prior information, like finding minimum duration, like if a phoneme can appear after another phone or things like this when we use the MLP to get the posterior estimates.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But we always know that there is a.",
                    "label": 0
                },
                {
                    "sent": "Information about funding is completely extended overtime and there is no such kind of hard boundaries between phonemes, and obviously there is always some prior knowledge and assumptions about the problem, so the main question and the main motivation in this talk is is there any way to introduce this kind of posterior in formation?",
                    "label": 1
                },
                {
                    "sent": "Prior information and contextual information in the posterior estimation to have more informative posteriors.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here we propose the idea which we call it gamma posterior estimation.",
                    "label": 1
                },
                {
                    "sent": "So based on this idea we get the estimated posterior out of.",
                    "label": 1
                },
                {
                    "sent": "Hidden Markov model and based on state, posterior definition.",
                    "label": 0
                },
                {
                    "sent": "So as you probably know, the day state, is the probability of being in a specific HMM state at time T having the.",
                    "label": 0
                },
                {
                    "sent": "Having the model M introducing some prior knowledge about the problem and the whole observation sequence.",
                    "label": 0
                },
                {
                    "sent": "So by defining a posterior like peace and estimating the posterior like this, we expect to end up with more informative posteriors than the usual way of posterior summation because it will let us to introduce these two more knowledge.",
                    "label": 0
                },
                {
                    "sent": "The prior knowledge about the problem and complete contextual information.",
                    "label": 0
                },
                {
                    "sent": "And here we see just.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rabbit details about how this compensate, posterior can be estimated so it is written in terms of forward and backward hmm recursions, and then this forward and backward hmm.",
                    "label": 1
                },
                {
                    "sent": "Recursions are written in terms of emission likelihoods or emission state.",
                    "label": 1
                },
                {
                    "sent": "Likelihoods and state transition probabilities.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just to have some feeling about how this idea works, this isn't a slide showing some visualizing, so the figure under left shows the form posterior estimation by MLP for an utterance speech utterance.",
                    "label": 0
                },
                {
                    "sent": "The exact axis shows the time our samples and Y axis shows the phone index and the intensity level shows the value of posterior so.",
                    "label": 0
                },
                {
                    "sent": "More dark means higher value for the posterior and the one on the left shows the same story, but this time phone posteriors are estimated by, estimation method and we actually introduced a priority very simple prior knowledge about the problem, so we assume that phoning duration, minimum phone duration is at least three, and as you can compare figures, the second one looks to be more informative.",
                    "label": 1
                },
                {
                    "sent": "This is well.",
                    "label": 0
                },
                {
                    "sent": "This is just to be visualized the case, and I'm not going to make a well conclusion.",
                    "label": 0
                },
                {
                    "sent": "You will see the results after.",
                    "label": 0
                },
                {
                    "sent": "OK, well now knowing this gamma posterior.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Estimation method, let's do one more step and get the estimate of posterior out of multiple stream of features.",
                    "label": 0
                },
                {
                    "sent": "So it's the same as before, but this time we have multiple stream of features which can have some complementary information.",
                    "label": 0
                },
                {
                    "sent": "So we define multistream state, as the probability of being in a specific HMM state.",
                    "label": 0
                },
                {
                    "sent": "Or, well, let's say a specific phoneme at time T having their model M, including prior knowledge about the problem.",
                    "label": 1
                },
                {
                    "sent": "And having multiple stream of features which can have complementary information and also whole observation sequence, which means blank contextual information for each.",
                    "label": 1
                },
                {
                    "sent": "So we even get more informative posteriors because now in addition to the features we had before, we can combine the different evidences we have.",
                    "label": 0
                },
                {
                    "sent": "And this is mainly the idea in which we use after to make a hierarchical speech recognition system.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, in this slide you should you see just some details about how we can get this multi stream estate, So we define you forward and backward multistream recursions and it can be shown that based on some independence assumptions they can be written in terms of single stream forward and backward recursion.",
                    "label": 1
                },
                {
                    "sent": "And finally, it can be shown that multi stream state Commerce can be written in terms of multi stream forward and backward recursion.",
                    "label": 0
                },
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We know we know about the story and how it works and what is the main idea.",
                    "label": 0
                },
                {
                    "sent": "So the main idea was to combine multiple stream of features and also introduced contextual information and prior knowledge about the problem.",
                    "label": 0
                },
                {
                    "sent": "So I will show you some initial experiments and results.",
                    "label": 0
                },
                {
                    "sent": "The first question regarding the experiments which streams to combine.",
                    "label": 1
                },
                {
                    "sent": "So obviously the streams which.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Will be combined.",
                    "label": 0
                },
                {
                    "sent": "Should have some kind of complementary information, well concerning this.",
                    "label": 0
                },
                {
                    "sent": "For example, we can combine PLP, capsule features and trap features.",
                    "label": 0
                },
                {
                    "sent": "One have capsular spectral feature and the other one temporal features, or we can combine static or dynamic features like PLP's or Delta PLP, but for experiment we combined these two features.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so well, here we.",
                    "label": 0
                },
                {
                    "sent": "We wish to reach to the second idea of this talk while designing the hierarchical system well.",
                    "label": 0
                },
                {
                    "sent": "Specifically in this talk for the speech recognition problem.",
                    "label": 1
                },
                {
                    "sent": "Based on this idea, which is, as you see, is conceptually similar to what I talked about in the first slide.",
                    "label": 0
                },
                {
                    "sent": "So we get some initial phone posteriors out of PLP and trap features by using MLP or a hierarchy of MLP.",
                    "label": 0
                },
                {
                    "sent": "Then we turn it to phone a scale likelihoods and be used.",
                    "label": 0
                },
                {
                    "sent": "This phone is scale likelihoods in the.",
                    "label": 0
                },
                {
                    "sent": "Monte Spring forward and backward occasions to get estimate of multi stream commas, which band?",
                    "label": 0
                },
                {
                    "sent": "Because here I assume a phoneme is represented by one state.",
                    "label": 0
                },
                {
                    "sent": "I can say multi stream formed posterior and then after some transformation I will use this schedule as features for a standard HMM GMM train inference system like the random system similar to turn off system.",
                    "label": 0
                },
                {
                    "sent": "We have divided the problem into different subproblems and at each step we can do the proper processing.",
                    "label": 0
                },
                {
                    "sent": "So initial posterior estimation, then combination, and here is the point that we can also introduce the prior knowledge of our problem or take more contextual information and finally doing the.",
                    "label": 0
                },
                {
                    "sent": "Train and influence at the last player, but by the features which are more informative than the initial features.",
                    "label": 0
                },
                {
                    "sent": "And for the experiment I will show, I assume ergotic model with uniform transition for probability for this state, just for the initial experiments.",
                    "label": 0
                },
                {
                    "sent": "So here we.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See some initial results.",
                    "label": 0
                },
                {
                    "sent": "I used two different databases to test the method.",
                    "label": 0
                },
                {
                    "sent": "So or GI database or GI digits database and they are plastic.",
                    "label": 1
                },
                {
                    "sent": "Is database the tables are showing the same result for the same experiments but for different databases?",
                    "label": 0
                },
                {
                    "sent": "So first column is showing the features which then used in standard HMM GMM train different system well so they're all features and then.",
                    "label": 0
                },
                {
                    "sent": "The same thing happens for all of them using as using in a standard HMM GMM train inference system.",
                    "label": 0
                },
                {
                    "sent": "So first row is Pierre.",
                    "label": 0
                },
                {
                    "sent": "People stereos getting summative, Posterio sort of PLP features by MLP and then feeding it to the next layer.",
                    "label": 0
                },
                {
                    "sent": "The 2nd row is trapped posterior so the same story and the third row is the combination of these PLP and trapper stereos by inverse entropy combination method and the last row is our method which combines PLP and track posteriors by.",
                    "label": 1
                },
                {
                    "sent": "Team, posterior idea and then feeding this posteriors to standard HMM human train you print system as you see our method performs better than the inverse entropy combination and also the single stream which are used for the combination.",
                    "label": 1
                },
                {
                    "sent": "Well.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I want to make 2 conclusions out of the stack, so here we propose a new touristical framework and we show just some initial results for a new kind of posterior estimation which will let us to get estimate of posteriors out of multiple stream of features.",
                    "label": 0
                },
                {
                    "sent": "We can say this is also a way to combine different stream of features and in the same time we can introduce prior knowledge about the problem like phoneme durations.",
                    "label": 0
                },
                {
                    "sent": "And lexical information in the posterior estimation and take long contextual information for the posterior estimation.",
                    "label": 1
                },
                {
                    "sent": "The second conclusion is to use this to use this posterior estimation idea to design hierarchical speech, speech recognition system and divide the problem in the different levels.",
                    "label": 1
                },
                {
                    "sent": "Well, I showed this case for in this slide I was presenting their hierarchical speech recognition system.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Using more constraints to computer.",
                    "label": 0
                },
                {
                    "sent": "Yes, but it is not represented in this talk well.",
                    "label": 0
                },
                {
                    "sent": "I just used a complete constrained model like the configuration we use for stereo estimation.",
                    "label": 0
                },
                {
                    "sent": "So let's say I get estimates of grandmas out of the complete network.",
                    "label": 0
                },
                {
                    "sent": "We normally run to get the result for speech recognition system and then we observe that in this case, well, we didn't do the experiment like explained here.",
                    "label": 0
                },
                {
                    "sent": "We didn't use this.",
                    "label": 0
                },
                {
                    "sent": "Plus they use as features, but we then did recording using this gammas coming from a complete network and then we observe that there is also a property which was not shown here and based on this posterior estimation via the system will be less sensitive to the tuning factors.",
                    "label": 0
                },
                {
                    "sent": "For example, you know that we have we have to tune something like word insertion penalties normally to get the.",
                    "label": 0
                },
                {
                    "sent": "Highest performance possible, but it was shown that in this case we don't need to tune.",
                    "label": 0
                },
                {
                    "sent": "It immediately gives us the highest performance possible without any tuning.",
                    "label": 0
                },
                {
                    "sent": "OK. Alright well thanks everybody for.",
                    "label": 0
                }
            ]
        }
    }
}