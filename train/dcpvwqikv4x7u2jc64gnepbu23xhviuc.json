{
    "id": "dcpvwqikv4x7u2jc64gnepbu23xhviuc",
    "title": "Operator-aware approach for boosting performance in RDF stream processing",
    "info": {
        "author": [
            "Danh Le Phuoc, TU Berlin"
        ],
        "published": "Nov. 10, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2016_le_phuoc_stream_processing/",
    "segmentation": [
        [
            "OK, my name down at work.",
            "I'm from Technical University of Berlin, Germany.",
            "Did see actually the work from the continuation from where I work with in Ireland for my PhD thesis on SQL Engine that some of you might know.",
            "So during the World Cup building the engine we find out that some behavior of the query operator that we have to look really in the bottom 2.",
            "See how to boosting up the performance so this article is about sharing what did I file and it was slowing down.",
            "The process in intuitive, sly and some other technical detail like algorithms.",
            "You can find out in the paper."
        ],
        [
            "So the agenda just to give brief overview and go direct to the challenge that we face and then and how we solve that and some share some experiment result that I have during the process of.",
            "Up and running the engine."
        ],
        [
            "So what I just bring back the overview of idea of stream processing is my not my scene necessary for some people in the room because.",
            "You know what our audio stream processing is, but I want to just focus on the sample.",
            "So like we have, so we had the idea stream data had with the stream with timestamp and we have 3 Steam link.",
            "Here we I get a sample that the taxi data from New York that you have the taxi number when it picked up when it drop off when they start computing the fair and this very sample that."
        ],
        [
            "It's really often if you see with Uber another thing they want to compute the active taxi to computing grades.",
            "So we asking how in Gray or active taxi in Lot 1000 payment transaction and then it will require the continued computation that mean."
        ],
        [
            "Normally.",
            "The data coming in and you have to update the query and in our perspective idea is the way for you to do interoperability and other things.",
            "I think I don't have to sell the.",
            "Why do you sad yet?",
            "But when you come out, other people expected to express things similar to Sparkle.",
            "So basic.",
            "Wanna sample that you correlate freestream within in Windows and you do aggregation so how?"
        ],
        [
            "Does it work in the engine as normally?",
            "You construct the dataflow like that's extracting data from stream with Windows daemon like this and you had window buffer.",
            "You do the donana you do aggregation.",
            "This is the normal query stream, so I will use this assemble a lot to slowing down how it the data flowing here how the processing stay will be maintained in processing."
        ],
        [
            "So basically when during the process process ID's SQL Engine an with a lot of project.",
            "Basically SQL Engine now pop them license in one in Industrial Park.",
            "Now that they bought the engine.",
            "So some of the work here is.",
            "Hear that now we cannot open source.",
            "It was licensed, so we see that all the cell data structure and algorithm is not enough for to achieve some execution free throughput for sample.",
            "I'm using Berkeley data DB and some of the sale data structure, relational database or even relational stream or esperan something is really hard to get some 10,000 operator execution with window around 100K.",
            "A million entries in the windows and another thing which I saw a lot overhead using roadways data structure like you have a hit or you have some other us our salary data to put there.",
            "We come back to the challenge why it doesn't fit with our pro base, so I took the bottom over's perspective.",
            "Why look into really bottom that what data structure, how the data struggle affect the way you maintaining the processing stay an.",
            "Can we build a sophisticated, more sophisticated incremental evaluating evaluating algorithm to make it faster?",
            "So to do that I."
        ],
        [
            "I just want to I don't know whether people had in here the background in the database, but I just want to slow down a bit.",
            "Is the normal way that people expecting doing stream processing a incremental computing because the process of computing data is continuously, you can reduce a lot of computing stay in previous stay for supper.",
            "In here you have.",
            "One John operator you normally went up there in the book for you just have to look up the state you already indexed.",
            "Or for example you computing this thing.",
            "You just look at the buffer that you index and you prop if there's a thing in the buffer yet to output or cow you just had a book bookkeeping, stay here or you do another minus like.",
            "Eating too fast.",
            "For example, you have to look at things they hear it normally with stateful with sliding videos for something like projection at Hunter is pretty straightforward.",
            "I wouldn't mention that easy as you can try then data stream management work.",
            "Some definition here, but this is the focus of maintaining processing stay in equivalent to evaluation data purpose to market faster."
        ],
        [
            "But when we come to doubt do incremental evaluation is our argument that drove a datastore structure is not suitable because we have very small RDF data elements because when RDF triple going to the stream or through other processes that you will see RDF node and normally you encode with fixed size integer or viable Len byte or something is really small processing state.",
            "Normally we had.",
            "Window with million entries and then would be very unusually large.",
            "Row and table if you use the robata date structures.",
            "Other things that in the state of the art stream processing.",
            "Incremental computing for continuous query in sliding Windows 2 halves.",
            "A lot of challenges use there.",
            "You can look up in a state of the art or in the paper.",
            "So two main thing is if you maintain an auxiliary data Stage 4.",
            "For computing for previous day, normally you have two of common approach.",
            "Adding more time stamp for checking it's pining or you negative tuple in another way to signal when the data inspired to re computing normally because we see one added note or one binding with fixing one integer in here if you put one time stem or some other object here it may be bigger than origonal data.",
            "You want to process in the pipeline.",
            "Another thing, there's a lot of stadia like they propose some solution, but they still suffer some problem with call double computation.",
            "I will illustrate it in a sample I have been following.",
            "So."
        ],
        [
            "This is the query you have.",
            "This is the data flow you have.",
            "This is for example this window that I'm pro."
        ],
        [
            "It's so enforceable in here.",
            "You have three stream going to that and you have three window here, huge on and normally you don't have the data to other empty and when the time proceed here and you had the data coming to two window so you had the matching data here.",
            "Here and here, and you had better in John.",
            "And then we'll follow up into the aggregation that you have the average from the John here.",
            "I.",
            "So in here in the data sliding window you see this thing you can encode.",
            "But integers, so we come back how we presented in Rahway is not efficient in our argument on that.",
            "Another thing a when you generate.",
            "Processing stage you see when the time precedes you generate, you have the data adding here a lot of processing the intermediary here before joining the final result, and normally the latter mild process they generate in here, but you see it is here is normally is the copy or generate from processing state in here for example, this one is.",
            "You can find it here in here.",
            "Another thing is in the processing fly we have observation that if you track back in here you can get this binding value from this so you don't need really to copy or store the state in the intermediate operator."
        ],
        [
            "Another thing is more real important in evaluation is.",
            "When the time come and you will see the day that is spy.",
            "For salmon, this when you proceed with Rand Window 5.",
            "So with that type on 11 you have one as spy entry."
        ],
        [
            "Not my problem.",
            "You have to invent this from the output and."
        ],
        [
            "Validate this one, but you don't know whether this one will contribute to this one.",
            "This one, this one or not."
        ],
        [
            "Normally you had to rejoin this buffer so it's the same effort when you join from previous step.",
            "So it call DOPA computation problem and evaluate incremental evaluation.",
            "So to be able to do that you have to find efficient way is like it already add a pop of the computation effort already."
        ],
        [
            "So this is all the issue that we found and then we got little decision we.",
            "Provide operator aware approach that we designed the data structure that work friendly with the behavioral operator, including how to bookkeeping, processing state, how to index them, an associated with algorithm that actually tailored to how operator work to make it faster."
        ],
        [
            "So the first thing we see."
        ],
        [
            "See that previously you see when you generate the John for samples, so you had a two day to match.",
            "Here you you had the intermediate John and then."
        ],
        [
            "I had another joint ahead of final states, so."
        ],
        [
            "See here the data generated from the flow so.",
            "We say that."
        ],
        [
            "In here we call intermediate mapping, so this thing we don't need to store data, we just saw the pointer to Arduino to recall that rebase.",
            "So when the data generate, we just maintain the trail for this so far assembled this data how the data created trail back to the store.",
            "So we already saw that and the link to the data."
        ],
        [
            "And then that come to another good things when we convicting the data we just."
        ],
        [
            "Follow this thing."
        ],
        [
            "Here.",
            "Defy the spy data, for example, in this, when this one is by and follow the link and go ahead.",
            "I know this one is right, I don't have to look at the buffer or pre computing the previous day from this well for to get this part and that lead to double computation is real heavy with John later.",
            "As you can see that we can follow the link here and defined as spy.",
            "Anne."
        ],
        [
            "Man with that rebate.",
            "Structures of data that we have and other things we call ring by index.",
            "Actually when you have that rebate mapping in here where I create index instead I create index on the data item.",
            "I actually only indexing on the key and I create the circling around this because normally you only add up the data in the end of the list.",
            "So it really 0014.",
            "So the case is what you delete it and you spend less effort into ring an.",
            "We had another ring that you can refer back this data.",
            "When you want to look up.",
            "The data entry backs.",
            "They say we use for the job that normally we use of aggregation and other operators so.",
            "With this we only need two data structure with the treeby that will help to boost up info.",
            "The performance evaluation for incremental evaluation and we saw most of the problem of double computation an overhead of the data structure with audit data."
        ],
        [
            "So some experiment that we say.",
            "See for example, we implemented our ring index and we see that we.",
            "That's different option for implementing decks.",
            "You house you tree, you're like tree and we see that has can deliver.",
            "Best performance."
        ],
        [
            "So with that, when we put in our system implementation, we see that we can reach the insert throughput around 900K or when we start we can redo a million search operation that will help to implement."
        ],
        [
            "The query operator faster, so in most of the cases that we compare with relational SQL, even with experts.",
            "So we outperform and magnitude better than relational approach an.",
            "We also most of the case manager, the better than expert if we called it at hopefully with Java data structure."
        ],
        [
            "Another thing that we compare with real data set an we see that in performance that we still far 5 to 12 pipe faster than relational approach or data data structure.",
            "Wanting in here, you see that you don't receive as like the big gap between relational and.",
            "Our implementation because in here there's some overhead add up.",
            "Between in the processing is the encoding process and our data passing as well because we do with real time data set.",
            "Another side effect because I side effect we got a major is not the major target when we start with this, the memory consumption that we can consume less.",
            "Twice less memory than with relational based approach, and we also still save around 20 to 50% to Esper.",
            "That the the achievement we."
        ],
        [
            "So in summary that we look down to the query operator an maximum change in data structure and query operator and we achieved this result with the query processing that we have at and just ahead of like.",
            "I'm trying to release the open source version in December for people to test because there's a lot of requirement for requests from from from some people around here via email.",
            "That's it.",
            "OK, let's thank the speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, my name down at work.",
                    "label": 0
                },
                {
                    "sent": "I'm from Technical University of Berlin, Germany.",
                    "label": 1
                },
                {
                    "sent": "Did see actually the work from the continuation from where I work with in Ireland for my PhD thesis on SQL Engine that some of you might know.",
                    "label": 0
                },
                {
                    "sent": "So during the World Cup building the engine we find out that some behavior of the query operator that we have to look really in the bottom 2.",
                    "label": 0
                },
                {
                    "sent": "See how to boosting up the performance so this article is about sharing what did I file and it was slowing down.",
                    "label": 0
                },
                {
                    "sent": "The process in intuitive, sly and some other technical detail like algorithms.",
                    "label": 0
                },
                {
                    "sent": "You can find out in the paper.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the agenda just to give brief overview and go direct to the challenge that we face and then and how we solve that and some share some experiment result that I have during the process of.",
                    "label": 0
                },
                {
                    "sent": "Up and running the engine.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I just bring back the overview of idea of stream processing is my not my scene necessary for some people in the room because.",
                    "label": 1
                },
                {
                    "sent": "You know what our audio stream processing is, but I want to just focus on the sample.",
                    "label": 0
                },
                {
                    "sent": "So like we have, so we had the idea stream data had with the stream with timestamp and we have 3 Steam link.",
                    "label": 1
                },
                {
                    "sent": "Here we I get a sample that the taxi data from New York that you have the taxi number when it picked up when it drop off when they start computing the fair and this very sample that.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's really often if you see with Uber another thing they want to compute the active taxi to computing grades.",
                    "label": 0
                },
                {
                    "sent": "So we asking how in Gray or active taxi in Lot 1000 payment transaction and then it will require the continued computation that mean.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Normally.",
                    "label": 0
                },
                {
                    "sent": "The data coming in and you have to update the query and in our perspective idea is the way for you to do interoperability and other things.",
                    "label": 0
                },
                {
                    "sent": "I think I don't have to sell the.",
                    "label": 0
                },
                {
                    "sent": "Why do you sad yet?",
                    "label": 0
                },
                {
                    "sent": "But when you come out, other people expected to express things similar to Sparkle.",
                    "label": 0
                },
                {
                    "sent": "So basic.",
                    "label": 0
                },
                {
                    "sent": "Wanna sample that you correlate freestream within in Windows and you do aggregation so how?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Does it work in the engine as normally?",
                    "label": 0
                },
                {
                    "sent": "You construct the dataflow like that's extracting data from stream with Windows daemon like this and you had window buffer.",
                    "label": 0
                },
                {
                    "sent": "You do the donana you do aggregation.",
                    "label": 0
                },
                {
                    "sent": "This is the normal query stream, so I will use this assemble a lot to slowing down how it the data flowing here how the processing stay will be maintained in processing.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So basically when during the process process ID's SQL Engine an with a lot of project.",
                    "label": 0
                },
                {
                    "sent": "Basically SQL Engine now pop them license in one in Industrial Park.",
                    "label": 0
                },
                {
                    "sent": "Now that they bought the engine.",
                    "label": 0
                },
                {
                    "sent": "So some of the work here is.",
                    "label": 0
                },
                {
                    "sent": "Hear that now we cannot open source.",
                    "label": 0
                },
                {
                    "sent": "It was licensed, so we see that all the cell data structure and algorithm is not enough for to achieve some execution free throughput for sample.",
                    "label": 0
                },
                {
                    "sent": "I'm using Berkeley data DB and some of the sale data structure, relational database or even relational stream or esperan something is really hard to get some 10,000 operator execution with window around 100K.",
                    "label": 0
                },
                {
                    "sent": "A million entries in the windows and another thing which I saw a lot overhead using roadways data structure like you have a hit or you have some other us our salary data to put there.",
                    "label": 0
                },
                {
                    "sent": "We come back to the challenge why it doesn't fit with our pro base, so I took the bottom over's perspective.",
                    "label": 0
                },
                {
                    "sent": "Why look into really bottom that what data structure, how the data struggle affect the way you maintaining the processing stay an.",
                    "label": 0
                },
                {
                    "sent": "Can we build a sophisticated, more sophisticated incremental evaluating evaluating algorithm to make it faster?",
                    "label": 0
                },
                {
                    "sent": "So to do that I.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I just want to I don't know whether people had in here the background in the database, but I just want to slow down a bit.",
                    "label": 0
                },
                {
                    "sent": "Is the normal way that people expecting doing stream processing a incremental computing because the process of computing data is continuously, you can reduce a lot of computing stay in previous stay for supper.",
                    "label": 0
                },
                {
                    "sent": "In here you have.",
                    "label": 0
                },
                {
                    "sent": "One John operator you normally went up there in the book for you just have to look up the state you already indexed.",
                    "label": 0
                },
                {
                    "sent": "Or for example you computing this thing.",
                    "label": 0
                },
                {
                    "sent": "You just look at the buffer that you index and you prop if there's a thing in the buffer yet to output or cow you just had a book bookkeeping, stay here or you do another minus like.",
                    "label": 0
                },
                {
                    "sent": "Eating too fast.",
                    "label": 0
                },
                {
                    "sent": "For example, you have to look at things they hear it normally with stateful with sliding videos for something like projection at Hunter is pretty straightforward.",
                    "label": 0
                },
                {
                    "sent": "I wouldn't mention that easy as you can try then data stream management work.",
                    "label": 1
                },
                {
                    "sent": "Some definition here, but this is the focus of maintaining processing stay in equivalent to evaluation data purpose to market faster.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But when we come to doubt do incremental evaluation is our argument that drove a datastore structure is not suitable because we have very small RDF data elements because when RDF triple going to the stream or through other processes that you will see RDF node and normally you encode with fixed size integer or viable Len byte or something is really small processing state.",
                    "label": 1
                },
                {
                    "sent": "Normally we had.",
                    "label": 0
                },
                {
                    "sent": "Window with million entries and then would be very unusually large.",
                    "label": 0
                },
                {
                    "sent": "Row and table if you use the robata date structures.",
                    "label": 0
                },
                {
                    "sent": "Other things that in the state of the art stream processing.",
                    "label": 0
                },
                {
                    "sent": "Incremental computing for continuous query in sliding Windows 2 halves.",
                    "label": 0
                },
                {
                    "sent": "A lot of challenges use there.",
                    "label": 0
                },
                {
                    "sent": "You can look up in a state of the art or in the paper.",
                    "label": 0
                },
                {
                    "sent": "So two main thing is if you maintain an auxiliary data Stage 4.",
                    "label": 0
                },
                {
                    "sent": "For computing for previous day, normally you have two of common approach.",
                    "label": 0
                },
                {
                    "sent": "Adding more time stamp for checking it's pining or you negative tuple in another way to signal when the data inspired to re computing normally because we see one added note or one binding with fixing one integer in here if you put one time stem or some other object here it may be bigger than origonal data.",
                    "label": 0
                },
                {
                    "sent": "You want to process in the pipeline.",
                    "label": 0
                },
                {
                    "sent": "Another thing, there's a lot of stadia like they propose some solution, but they still suffer some problem with call double computation.",
                    "label": 0
                },
                {
                    "sent": "I will illustrate it in a sample I have been following.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the query you have.",
                    "label": 0
                },
                {
                    "sent": "This is the data flow you have.",
                    "label": 0
                },
                {
                    "sent": "This is for example this window that I'm pro.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's so enforceable in here.",
                    "label": 0
                },
                {
                    "sent": "You have three stream going to that and you have three window here, huge on and normally you don't have the data to other empty and when the time proceed here and you had the data coming to two window so you had the matching data here.",
                    "label": 0
                },
                {
                    "sent": "Here and here, and you had better in John.",
                    "label": 0
                },
                {
                    "sent": "And then we'll follow up into the aggregation that you have the average from the John here.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "So in here in the data sliding window you see this thing you can encode.",
                    "label": 0
                },
                {
                    "sent": "But integers, so we come back how we presented in Rahway is not efficient in our argument on that.",
                    "label": 0
                },
                {
                    "sent": "Another thing a when you generate.",
                    "label": 0
                },
                {
                    "sent": "Processing stage you see when the time precedes you generate, you have the data adding here a lot of processing the intermediary here before joining the final result, and normally the latter mild process they generate in here, but you see it is here is normally is the copy or generate from processing state in here for example, this one is.",
                    "label": 0
                },
                {
                    "sent": "You can find it here in here.",
                    "label": 0
                },
                {
                    "sent": "Another thing is in the processing fly we have observation that if you track back in here you can get this binding value from this so you don't need really to copy or store the state in the intermediate operator.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another thing is more real important in evaluation is.",
                    "label": 0
                },
                {
                    "sent": "When the time come and you will see the day that is spy.",
                    "label": 0
                },
                {
                    "sent": "For salmon, this when you proceed with Rand Window 5.",
                    "label": 0
                },
                {
                    "sent": "So with that type on 11 you have one as spy entry.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not my problem.",
                    "label": 0
                },
                {
                    "sent": "You have to invent this from the output and.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Validate this one, but you don't know whether this one will contribute to this one.",
                    "label": 0
                },
                {
                    "sent": "This one, this one or not.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Normally you had to rejoin this buffer so it's the same effort when you join from previous step.",
                    "label": 0
                },
                {
                    "sent": "So it call DOPA computation problem and evaluate incremental evaluation.",
                    "label": 0
                },
                {
                    "sent": "So to be able to do that you have to find efficient way is like it already add a pop of the computation effort already.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is all the issue that we found and then we got little decision we.",
                    "label": 0
                },
                {
                    "sent": "Provide operator aware approach that we designed the data structure that work friendly with the behavioral operator, including how to bookkeeping, processing state, how to index them, an associated with algorithm that actually tailored to how operator work to make it faster.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first thing we see.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See that previously you see when you generate the John for samples, so you had a two day to match.",
                    "label": 0
                },
                {
                    "sent": "Here you you had the intermediate John and then.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I had another joint ahead of final states, so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See here the data generated from the flow so.",
                    "label": 0
                },
                {
                    "sent": "We say that.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In here we call intermediate mapping, so this thing we don't need to store data, we just saw the pointer to Arduino to recall that rebase.",
                    "label": 0
                },
                {
                    "sent": "So when the data generate, we just maintain the trail for this so far assembled this data how the data created trail back to the store.",
                    "label": 0
                },
                {
                    "sent": "So we already saw that and the link to the data.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then that come to another good things when we convicting the data we just.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Follow this thing.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "Defy the spy data, for example, in this, when this one is by and follow the link and go ahead.",
                    "label": 0
                },
                {
                    "sent": "I know this one is right, I don't have to look at the buffer or pre computing the previous day from this well for to get this part and that lead to double computation is real heavy with John later.",
                    "label": 0
                },
                {
                    "sent": "As you can see that we can follow the link here and defined as spy.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Man with that rebate.",
                    "label": 0
                },
                {
                    "sent": "Structures of data that we have and other things we call ring by index.",
                    "label": 0
                },
                {
                    "sent": "Actually when you have that rebate mapping in here where I create index instead I create index on the data item.",
                    "label": 0
                },
                {
                    "sent": "I actually only indexing on the key and I create the circling around this because normally you only add up the data in the end of the list.",
                    "label": 0
                },
                {
                    "sent": "So it really 0014.",
                    "label": 0
                },
                {
                    "sent": "So the case is what you delete it and you spend less effort into ring an.",
                    "label": 0
                },
                {
                    "sent": "We had another ring that you can refer back this data.",
                    "label": 0
                },
                {
                    "sent": "When you want to look up.",
                    "label": 0
                },
                {
                    "sent": "The data entry backs.",
                    "label": 0
                },
                {
                    "sent": "They say we use for the job that normally we use of aggregation and other operators so.",
                    "label": 0
                },
                {
                    "sent": "With this we only need two data structure with the treeby that will help to boost up info.",
                    "label": 0
                },
                {
                    "sent": "The performance evaluation for incremental evaluation and we saw most of the problem of double computation an overhead of the data structure with audit data.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So some experiment that we say.",
                    "label": 0
                },
                {
                    "sent": "See for example, we implemented our ring index and we see that we.",
                    "label": 0
                },
                {
                    "sent": "That's different option for implementing decks.",
                    "label": 0
                },
                {
                    "sent": "You house you tree, you're like tree and we see that has can deliver.",
                    "label": 0
                },
                {
                    "sent": "Best performance.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with that, when we put in our system implementation, we see that we can reach the insert throughput around 900K or when we start we can redo a million search operation that will help to implement.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The query operator faster, so in most of the cases that we compare with relational SQL, even with experts.",
                    "label": 0
                },
                {
                    "sent": "So we outperform and magnitude better than relational approach an.",
                    "label": 0
                },
                {
                    "sent": "We also most of the case manager, the better than expert if we called it at hopefully with Java data structure.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another thing that we compare with real data set an we see that in performance that we still far 5 to 12 pipe faster than relational approach or data data structure.",
                    "label": 0
                },
                {
                    "sent": "Wanting in here, you see that you don't receive as like the big gap between relational and.",
                    "label": 0
                },
                {
                    "sent": "Our implementation because in here there's some overhead add up.",
                    "label": 0
                },
                {
                    "sent": "Between in the processing is the encoding process and our data passing as well because we do with real time data set.",
                    "label": 0
                },
                {
                    "sent": "Another side effect because I side effect we got a major is not the major target when we start with this, the memory consumption that we can consume less.",
                    "label": 0
                },
                {
                    "sent": "Twice less memory than with relational based approach, and we also still save around 20 to 50% to Esper.",
                    "label": 0
                },
                {
                    "sent": "That the the achievement we.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in summary that we look down to the query operator an maximum change in data structure and query operator and we achieved this result with the query processing that we have at and just ahead of like.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to release the open source version in December for people to test because there's a lot of requirement for requests from from from some people around here via email.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank the speaker.",
                    "label": 0
                }
            ]
        }
    }
}