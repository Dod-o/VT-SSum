{
    "id": "v3jblot46fqyskfojbz2sjy4xooccjof",
    "title": "Matching Web Tables with Knowledge Base Entities: From Entity Lookups to Entity Embeddings",
    "info": {
        "author": [
            "Vasilis Efthymiou, Foundation for Research and Technology - Hellas (FORTH)"
        ],
        "published": "Nov. 28, 2017",
        "recorded": "October 2017",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2017_efthymiou_web_tables/",
    "segmentation": [
        [
            "So this is a work that we did while I was an intern at IBM Research with Oktay hasn't gotten Mariana Rodriguez Morrow and also with my PC advisor, Vassilis Crystal, Phyllis."
        ],
        [
            "So I'm going first to say what is the problem of web table annotation.",
            "The model that we used an then list of family of algorithms that we used to solve this problem.",
            "For example, we used Vlookups entity embeddings and ontology matching tools, as well as a hybrid method, which is a combination of them, and then we're going to see the evaluation, so I'm going to."
        ],
        [
            "Keep the definition of a knowledge graph.",
            "I assume everyone knows what it is.",
            "I'm only going to say that we see entities as sets of attribute value pairs."
        ],
        [
            "And we had our own knowledge graph with.",
            "In IBM, that was actually a combination of DB pedia, YAGO wiki data, and Freebase and it offers an API for AI applications.",
            "So this is the target of her annotations."
        ],
        [
            "And the problem of web table annotation is given a web table, we want to annotate each row of this table with an entity that we know that we have in our knowledge graph.",
            "So for example, the first row with the entity China in fact base.",
            "The."
        ],
        [
            "That we use is that each row is an entity.",
            "Its column is an attribute of this entity.",
            "There are some special columns, for example this label column that contains the names of the entities.",
            "We identify it as the leftmost column with higher the most number of higher number of.",
            "Non numeric values.",
            "Distinct values and another kind of special column is the one that contains relations to other entities.",
            "We assume also that all the entities of the same column correspond to the same conceptual type, so those are more or less are the limitations of our model or the assumptions that we make."
        ],
        [
            "The main challenge is for web table annotation.",
            "Of course we don't know from the beginning what types of entities are contained in a web table.",
            "For example, when we looked up for China in our knowledge Graph, the 1st result that came up was that China is a city in Japan, so obviously that was not very correct.",
            "Not not what was we were looking for.",
            "We don't know which columns we should use in order to annotate web tables, so in some cases if we just use.",
            "One of the one of the columns like this country column label column.",
            "We might end up having different entities in our knowledge graph with very similar names, so we also need to exploit other columns of this table.",
            "The names used in the web table and the Knowledge Graph may be very different.",
            "For example, we may have the name Bulma in the web Table and Myanmar in the Knowledge Graph, which are two different names.",
            "One is the oldest and one is the newer for the same country."
        ],
        [
            "And.",
            "So the line of research that the first line of research that we tried was entity lookups, vlookups, our search service over offered by a knowledge graph, and this is the state of the art.",
            "So this was a work by the Manheim Group called T 2K, and it is an iterative approach that does skymind instant level instance level mappings and the first step is to look up its cell of the label column using the.",
            "Look up service off the target knowledge graph.",
            "For example DB pedia or fact base.",
            "We call this a simple look up and we use it as a baseline and then this works.",
            "Use an iterative step, finding more mappings or refining the mappings between schema and instances until they converge."
        ],
        [
            "Another line of research that was interesting and that's why we are in this session was that we could maybe use entity embeddings for the problem of web table annotation, and we mostly rely this work.",
            "This approach on the on the work proposed last year in SWC and it's called Dozer.",
            "The idea is that we can first index and create embeddings from the target knowledge graph and in this index we can have information about the labels of the entities.",
            "The embeddings, which are vectorial representations of those entities and some prior probabilities, which is actually the frequency how many times we how likely it is to meet this entity.",
            "So how popular it is, let's say, and on the other hand, there is a text, so we want to with entity mentions and we this work tries to find mappings between the text and the Knowledge Graph.",
            "So instead of text we used web tables and then after they generate candidates based on the similarity of the labels from the text and knowledge graph they try, they build a graph of candidates that we will see later."
        ],
        [
            "And then we said, OK, the ontology matching tools are quite mature.",
            "They are in this field for a lot many years.",
            "So we could also try to use some of the most popular ones like log map, Paris or more.",
            "So we first tried those two to see how well those tools could work in this problem.",
            "So the contributions of the work of."
        ],
        [
            "This work is that we introduced a new look up based method that outperforms state of the art.",
            "Look at based methods and we also added a new approach.",
            "Hybrid methods which combines two different approaches for this problem we introduce and you called standard based on Wikipedia tables that we publicly that we offer publicly and then we evaluated those different methods and see and so which ones work better in under which circumstances.",
            "So the."
        ],
        [
            "Approach that we introduces a look up based method of from our Knowledge graph.",
            "The idea is that we first detect the label column and then we run a search for its cells of itself.",
            "This label column.",
            "So we get the results for China in the USA etc.",
            "Now we also get some statistics from those lookups, so we get the most frequent types that appears as the 1st result and the most frequent words that appears in those descriptions of the entities in the results.",
            "And now we have three cases.",
            "Those searches may end up with one result more than one result, or 0 results.",
            "If you have one result in ourselves, we assume that this is the correct result.",
            "So if we have only one result for China, we assume that this is the one we are looking for.",
            "And in this case we also look for if.",
            "The other if if this unique result contains the value, for example Beijing for one of its attributes, and if it does, we say that this attribute is a candidate relation to map to map to this column to the last column capital.",
            "Now if we have more than one result, we have to refine ourselves.",
            "So we had some restrictions, for example that the search results should be in.",
            "One of should belong to the one of the most frequent types.",
            "So for example.",
            "We have many results for China.",
            "We say that OK there show me only the results that belong to the type country or have one of the most popular words from the previous searches.",
            "And if we have 0 results, this means that we are we do a more very strict search so we have to loosen up our search and say that OK if we have no results for China just get me all the entities that have a capital called Beijing.",
            "And if we have many results for that, just get me the one that has a closer named to this string, China.",
            "For the."
        ],
        [
            "Embeddings approach instead of using a text, we just use the cells of the leg label column as an entity mentions an, we assume that the rest of the arrow is just the context of an entity mention."
        ],
        [
            "And from for this approach, the graph of candidates that is generated is the following.",
            "So for its entity mention.",
            "That we have in our web table.",
            "We have some candidate mappings from the Knowledge Graph and we want to find which one of them is the correct one.",
            "So we also have the same nodes for other rows of the same table.",
            "And the idea is that we create a K partite complete K partite graph.",
            "So K is the number of entity mentions that we want to find the correct mappings.",
            "In this case, 3 and the edges of this graph are weighted based on the similarity.",
            "So the cosine similarity, which is actually the similarity of the vectors of the embeddings created for the Knowledge graph entities.",
            "After we build this graph."
        ],
        [
            "Again, this is based on on this work.",
            "So after we build this graph.",
            "We run page rank and after 50 iterations of page rank it's noticed is assigned a score.",
            "This is the relevant score, so the higher the score the more coherent results are to each other.",
            "OK, I have to."
        ],
        [
            "It up so then the third approach is to use ontology matching tools.",
            "The basic idea is that we create one ontology.",
            "One very simple ontology from the web tables, one very simple ontology.",
            "Or we already have the ontology from a knowledge graph.",
            "So we only prune it using the blocking step, and then we run any of the ontology matching tools that have been proposed.",
            "I am going to skip the details like log map on Paris and get the results as the annotations."
        ],
        [
            "And we also introduced a hybrid approach.",
            "The idea is that we can combine the two best performing methods.",
            "In our case we tried vlookups and embeddings.",
            "So when the look ups fail to identify mappings from some of the rows, we can use the results that we get from the embeddings.",
            "And if we use this order, look up first and embedding second, we call it hybrid one.",
            "If we use the other, if we order is.",
            "And the opposite, we call it hybrid 2."
        ],
        [
            "For the experimental evaluation, we used to popular the gold standard still today only may, and we also introduce our own gold standard Wikipedia.",
            "It's three orders of magnitude larger than existing knowledge and gold standards, and this last row also here corresponds to how many of the cells in the web tables are filled and not empty, with one corresponding to the case that no cells are empty."
        ],
        [
            "OK, to create the gold standard from Wikipedia, we took Wikipedia tables.",
            "Those are already annotated, and it's straightforward to move from Wikipedia to DB Pedia, as you know."
        ],
        [
            "There were some issues, so it was not an easy task, so many tables could have missing links or multiple values per cell or it would be difficult to identify which row and column we are currently."
        ],
        [
            "For the evaluation, first we used for the first gold standard introduced by the 2K Group, we see that fact based look up is the overall winner and the almost perfect structure Ness of this gold standard, so it doesn't have many missing values, provides the ideal conditions for methods that exploit all the columns of a table, like the two K ontology matching tools exhibit the worst results, mainly in recall.",
            "But to be fair, we also.",
            "Keep the results of our blocking our indexing, which is already worse than the other methods, but still the difference between blocking and log log map or Paris is significant.",
            "And finally we also see that the hybrid methods perform better than the rest."
        ],
        [
            "In the Second World, styled on gold Standard, which has many missing values, we see that again fact based look up outperforms other approaches by even 8% higher F measure.",
            "From the second best, an 15% better F measure than state of the art to K. But to be fair to 2K in this case because it has this call center has many missing rows, many empty rows.",
            "It discards many of the tables of very low quality, so we didn't find tune to for this case we just use the default settings and again hybrid approaches are best."
        ],
        [
            "And in our own gold standard, what we saw in this case is that the embeddings approach works better than the rest, so this is the more noisy gold standard because it's not easy to the cells have because of the issues that I showed you before ontology matching against again is the worst approach, even from the step of blocking.",
            "So we can do things to improve our own indexing to be more fair with those with this approach.",
            "We see that we have much worse results in this.",
            "Can standard at the previous ones, and this is mostly because of the noise and in this case the hybrid approaches are much much better than the constituent methods and this is big cause this is the ideal case for our hybrid approach when we both of the constituent methods have modest recall and very good precision."
        ],
        [
            "The lessons learned is that are that fact based look up and embeddings work better with bigger tables with many rows in smaller tables the embeddings work better than fact based look up when we have relations fact based look up works better because it exploits those relations when we have noise in our data the embeddings work better and the ideal case for the hybrid method is when we have good recall and modest recalling good precision in both methods so."
        ],
        [
            "Come up, we have seen three different ways to annotate web tables using vlookups embeddings or ontology matching, and we have introduced a new gold standard that is publicly available and you look up method that outperforms state of the art and and you.",
            "Approach that combines the previous approaches, so that's yeah, that's all, thank you.",
            "Thank you very much.",
            "Comparison, so I'm kind of surprised that you were operating just with vlookups mostly right?",
            "Let's see if you would use one of these several wiki fires, which have pretty sophisticated machinery behind for disembarkation and everything else.",
            "So this would give you a little bit better baseline for comparisons.",
            "I mean their fasts, strong contextual machinery to disambiguate, and so on, so.",
            "Then a good reason why you didn't use, let's say this wiki fires or this annotation machine is.",
            "We tried to find different approaches to this problem, so whenever we discussed with people they said that OK, you should definitely try my tool to for your problem.",
            "It perfectly fits, so that's why we have so many different approaches.",
            "To be fair, we could not try everything, but of course your suggestion is very good, so we didn't consider this option, but of course we could do that.",
            "We are not.",
            "Mostly based based on our results on vlookups, we also tried the embeddings on the matching and combination, but as a simple baseline we tried to see the simplest thing that we could do so just.",
            "Just search for the entity in the label column and get the results.",
            "And it's quite surprising that it provides very good results.",
            "Very competitive results to state of the art and to us.",
            "Yeah, the question is where the problem gets hard, right?",
            "So this is where yes starts mattering.",
            "So there the look up just cannot do it anymore, right?",
            "Yes, that's right.",
            "So we have to exploit more things than just, but this is a very valid suggestion.",
            "So thank you.",
            "OK, thank you for the lies but intention and I have one question.",
            "For the third method, you'll transform your table to.",
            "I cannot hear you very well.",
            "I'm sorry for the third method, you transform your whip table into ontology and then match such ontology with the your Knowledge Graph.",
            "So how you transform this web table to ontology and then when you transform it to ontology, it becomes.",
            "It's not simple ontology matching, but in balance ontology matching problem.",
            "Since the size of the whip table or the number of concept in the transform Ontology is not compatible to the original knowledge Graph you match with, so using such system like look map or the other system, I do not exactly if it is effective matching system you use to deal with such imbalance.",
            "Matching into our intelligence metric exactly.",
            "So this is not very quite fair for those tools, so we're not trying to criticize those tools for not performing.",
            "Well, to answer the second part of your question, we just wanted to explore different ways to solve this problem and maybe see how well different tools work for this to this direction.",
            "So what you say is correct, we have on the one side very rich ontology containing many classes and types, and on the other side we have a very flat ontology built only from a very small table with very few attributes and value.",
            "So the way we created this ontology you can find more details in our.",
            "College matching the paper last years, but the way that we do it, we assume that there is a header row which contains the names of the columns and the the cell of the header.",
            "All that is in the label column.",
            "We use it as the name of the root class.",
            "Let's say a very shallow ontology and the rest of the cells in the header row are the attribute names of the entities and its role is an instance of this this.",
            "My class and we have some sampling to detect if column is a data type, corresponds to data type or an object property.",
            "So to relations with other entities.",
            "But still this is very flat ontology and very shallow and it's it's not why those systems were built.",
            "So for example, Paris explicitly states that we cannot handle at Regina's data, so it's not very fair to say that they're not performing well because they do not.",
            "Do well in our use case."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a work that we did while I was an intern at IBM Research with Oktay hasn't gotten Mariana Rodriguez Morrow and also with my PC advisor, Vassilis Crystal, Phyllis.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going first to say what is the problem of web table annotation.",
                    "label": 1
                },
                {
                    "sent": "The model that we used an then list of family of algorithms that we used to solve this problem.",
                    "label": 1
                },
                {
                    "sent": "For example, we used Vlookups entity embeddings and ontology matching tools, as well as a hybrid method, which is a combination of them, and then we're going to see the evaluation, so I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Keep the definition of a knowledge graph.",
                    "label": 1
                },
                {
                    "sent": "I assume everyone knows what it is.",
                    "label": 0
                },
                {
                    "sent": "I'm only going to say that we see entities as sets of attribute value pairs.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we had our own knowledge graph with.",
                    "label": 0
                },
                {
                    "sent": "In IBM, that was actually a combination of DB pedia, YAGO wiki data, and Freebase and it offers an API for AI applications.",
                    "label": 1
                },
                {
                    "sent": "So this is the target of her annotations.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the problem of web table annotation is given a web table, we want to annotate each row of this table with an entity that we know that we have in our knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "So for example, the first row with the entity China in fact base.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we use is that each row is an entity.",
                    "label": 0
                },
                {
                    "sent": "Its column is an attribute of this entity.",
                    "label": 0
                },
                {
                    "sent": "There are some special columns, for example this label column that contains the names of the entities.",
                    "label": 1
                },
                {
                    "sent": "We identify it as the leftmost column with higher the most number of higher number of.",
                    "label": 0
                },
                {
                    "sent": "Non numeric values.",
                    "label": 0
                },
                {
                    "sent": "Distinct values and another kind of special column is the one that contains relations to other entities.",
                    "label": 0
                },
                {
                    "sent": "We assume also that all the entities of the same column correspond to the same conceptual type, so those are more or less are the limitations of our model or the assumptions that we make.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The main challenge is for web table annotation.",
                    "label": 0
                },
                {
                    "sent": "Of course we don't know from the beginning what types of entities are contained in a web table.",
                    "label": 0
                },
                {
                    "sent": "For example, when we looked up for China in our knowledge Graph, the 1st result that came up was that China is a city in Japan, so obviously that was not very correct.",
                    "label": 0
                },
                {
                    "sent": "Not not what was we were looking for.",
                    "label": 0
                },
                {
                    "sent": "We don't know which columns we should use in order to annotate web tables, so in some cases if we just use.",
                    "label": 0
                },
                {
                    "sent": "One of the one of the columns like this country column label column.",
                    "label": 0
                },
                {
                    "sent": "We might end up having different entities in our knowledge graph with very similar names, so we also need to exploit other columns of this table.",
                    "label": 0
                },
                {
                    "sent": "The names used in the web table and the Knowledge Graph may be very different.",
                    "label": 0
                },
                {
                    "sent": "For example, we may have the name Bulma in the web Table and Myanmar in the Knowledge Graph, which are two different names.",
                    "label": 0
                },
                {
                    "sent": "One is the oldest and one is the newer for the same country.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So the line of research that the first line of research that we tried was entity lookups, vlookups, our search service over offered by a knowledge graph, and this is the state of the art.",
                    "label": 1
                },
                {
                    "sent": "So this was a work by the Manheim Group called T 2K, and it is an iterative approach that does skymind instant level instance level mappings and the first step is to look up its cell of the label column using the.",
                    "label": 1
                },
                {
                    "sent": "Look up service off the target knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "For example DB pedia or fact base.",
                    "label": 0
                },
                {
                    "sent": "We call this a simple look up and we use it as a baseline and then this works.",
                    "label": 1
                },
                {
                    "sent": "Use an iterative step, finding more mappings or refining the mappings between schema and instances until they converge.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another line of research that was interesting and that's why we are in this session was that we could maybe use entity embeddings for the problem of web table annotation, and we mostly rely this work.",
                    "label": 0
                },
                {
                    "sent": "This approach on the on the work proposed last year in SWC and it's called Dozer.",
                    "label": 0
                },
                {
                    "sent": "The idea is that we can first index and create embeddings from the target knowledge graph and in this index we can have information about the labels of the entities.",
                    "label": 0
                },
                {
                    "sent": "The embeddings, which are vectorial representations of those entities and some prior probabilities, which is actually the frequency how many times we how likely it is to meet this entity.",
                    "label": 0
                },
                {
                    "sent": "So how popular it is, let's say, and on the other hand, there is a text, so we want to with entity mentions and we this work tries to find mappings between the text and the Knowledge Graph.",
                    "label": 0
                },
                {
                    "sent": "So instead of text we used web tables and then after they generate candidates based on the similarity of the labels from the text and knowledge graph they try, they build a graph of candidates that we will see later.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we said, OK, the ontology matching tools are quite mature.",
                    "label": 1
                },
                {
                    "sent": "They are in this field for a lot many years.",
                    "label": 0
                },
                {
                    "sent": "So we could also try to use some of the most popular ones like log map, Paris or more.",
                    "label": 1
                },
                {
                    "sent": "So we first tried those two to see how well those tools could work in this problem.",
                    "label": 0
                },
                {
                    "sent": "So the contributions of the work of.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This work is that we introduced a new look up based method that outperforms state of the art.",
                    "label": 0
                },
                {
                    "sent": "Look at based methods and we also added a new approach.",
                    "label": 0
                },
                {
                    "sent": "Hybrid methods which combines two different approaches for this problem we introduce and you called standard based on Wikipedia tables that we publicly that we offer publicly and then we evaluated those different methods and see and so which ones work better in under which circumstances.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Approach that we introduces a look up based method of from our Knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "The idea is that we first detect the label column and then we run a search for its cells of itself.",
                    "label": 1
                },
                {
                    "sent": "This label column.",
                    "label": 1
                },
                {
                    "sent": "So we get the results for China in the USA etc.",
                    "label": 0
                },
                {
                    "sent": "Now we also get some statistics from those lookups, so we get the most frequent types that appears as the 1st result and the most frequent words that appears in those descriptions of the entities in the results.",
                    "label": 1
                },
                {
                    "sent": "And now we have three cases.",
                    "label": 0
                },
                {
                    "sent": "Those searches may end up with one result more than one result, or 0 results.",
                    "label": 0
                },
                {
                    "sent": "If you have one result in ourselves, we assume that this is the correct result.",
                    "label": 0
                },
                {
                    "sent": "So if we have only one result for China, we assume that this is the one we are looking for.",
                    "label": 0
                },
                {
                    "sent": "And in this case we also look for if.",
                    "label": 1
                },
                {
                    "sent": "The other if if this unique result contains the value, for example Beijing for one of its attributes, and if it does, we say that this attribute is a candidate relation to map to map to this column to the last column capital.",
                    "label": 0
                },
                {
                    "sent": "Now if we have more than one result, we have to refine ourselves.",
                    "label": 0
                },
                {
                    "sent": "So we had some restrictions, for example that the search results should be in.",
                    "label": 0
                },
                {
                    "sent": "One of should belong to the one of the most frequent types.",
                    "label": 1
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "We have many results for China.",
                    "label": 0
                },
                {
                    "sent": "We say that OK there show me only the results that belong to the type country or have one of the most popular words from the previous searches.",
                    "label": 0
                },
                {
                    "sent": "And if we have 0 results, this means that we are we do a more very strict search so we have to loosen up our search and say that OK if we have no results for China just get me all the entities that have a capital called Beijing.",
                    "label": 0
                },
                {
                    "sent": "And if we have many results for that, just get me the one that has a closer named to this string, China.",
                    "label": 0
                },
                {
                    "sent": "For the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Embeddings approach instead of using a text, we just use the cells of the leg label column as an entity mentions an, we assume that the rest of the arrow is just the context of an entity mention.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And from for this approach, the graph of candidates that is generated is the following.",
                    "label": 1
                },
                {
                    "sent": "So for its entity mention.",
                    "label": 0
                },
                {
                    "sent": "That we have in our web table.",
                    "label": 0
                },
                {
                    "sent": "We have some candidate mappings from the Knowledge Graph and we want to find which one of them is the correct one.",
                    "label": 0
                },
                {
                    "sent": "So we also have the same nodes for other rows of the same table.",
                    "label": 0
                },
                {
                    "sent": "And the idea is that we create a K partite complete K partite graph.",
                    "label": 0
                },
                {
                    "sent": "So K is the number of entity mentions that we want to find the correct mappings.",
                    "label": 0
                },
                {
                    "sent": "In this case, 3 and the edges of this graph are weighted based on the similarity.",
                    "label": 0
                },
                {
                    "sent": "So the cosine similarity, which is actually the similarity of the vectors of the embeddings created for the Knowledge graph entities.",
                    "label": 0
                },
                {
                    "sent": "After we build this graph.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again, this is based on on this work.",
                    "label": 0
                },
                {
                    "sent": "So after we build this graph.",
                    "label": 0
                },
                {
                    "sent": "We run page rank and after 50 iterations of page rank it's noticed is assigned a score.",
                    "label": 1
                },
                {
                    "sent": "This is the relevant score, so the higher the score the more coherent results are to each other.",
                    "label": 0
                },
                {
                    "sent": "OK, I have to.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It up so then the third approach is to use ontology matching tools.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is that we create one ontology.",
                    "label": 0
                },
                {
                    "sent": "One very simple ontology from the web tables, one very simple ontology.",
                    "label": 0
                },
                {
                    "sent": "Or we already have the ontology from a knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "So we only prune it using the blocking step, and then we run any of the ontology matching tools that have been proposed.",
                    "label": 0
                },
                {
                    "sent": "I am going to skip the details like log map on Paris and get the results as the annotations.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also introduced a hybrid approach.",
                    "label": 0
                },
                {
                    "sent": "The idea is that we can combine the two best performing methods.",
                    "label": 0
                },
                {
                    "sent": "In our case we tried vlookups and embeddings.",
                    "label": 0
                },
                {
                    "sent": "So when the look ups fail to identify mappings from some of the rows, we can use the results that we get from the embeddings.",
                    "label": 0
                },
                {
                    "sent": "And if we use this order, look up first and embedding second, we call it hybrid one.",
                    "label": 0
                },
                {
                    "sent": "If we use the other, if we order is.",
                    "label": 0
                },
                {
                    "sent": "And the opposite, we call it hybrid 2.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the experimental evaluation, we used to popular the gold standard still today only may, and we also introduce our own gold standard Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "It's three orders of magnitude larger than existing knowledge and gold standards, and this last row also here corresponds to how many of the cells in the web tables are filled and not empty, with one corresponding to the case that no cells are empty.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, to create the gold standard from Wikipedia, we took Wikipedia tables.",
                    "label": 0
                },
                {
                    "sent": "Those are already annotated, and it's straightforward to move from Wikipedia to DB Pedia, as you know.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There were some issues, so it was not an easy task, so many tables could have missing links or multiple values per cell or it would be difficult to identify which row and column we are currently.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the evaluation, first we used for the first gold standard introduced by the 2K Group, we see that fact based look up is the overall winner and the almost perfect structure Ness of this gold standard, so it doesn't have many missing values, provides the ideal conditions for methods that exploit all the columns of a table, like the two K ontology matching tools exhibit the worst results, mainly in recall.",
                    "label": 0
                },
                {
                    "sent": "But to be fair, we also.",
                    "label": 0
                },
                {
                    "sent": "Keep the results of our blocking our indexing, which is already worse than the other methods, but still the difference between blocking and log log map or Paris is significant.",
                    "label": 0
                },
                {
                    "sent": "And finally we also see that the hybrid methods perform better than the rest.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the Second World, styled on gold Standard, which has many missing values, we see that again fact based look up outperforms other approaches by even 8% higher F measure.",
                    "label": 1
                },
                {
                    "sent": "From the second best, an 15% better F measure than state of the art to K. But to be fair to 2K in this case because it has this call center has many missing rows, many empty rows.",
                    "label": 1
                },
                {
                    "sent": "It discards many of the tables of very low quality, so we didn't find tune to for this case we just use the default settings and again hybrid approaches are best.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in our own gold standard, what we saw in this case is that the embeddings approach works better than the rest, so this is the more noisy gold standard because it's not easy to the cells have because of the issues that I showed you before ontology matching against again is the worst approach, even from the step of blocking.",
                    "label": 1
                },
                {
                    "sent": "So we can do things to improve our own indexing to be more fair with those with this approach.",
                    "label": 0
                },
                {
                    "sent": "We see that we have much worse results in this.",
                    "label": 0
                },
                {
                    "sent": "Can standard at the previous ones, and this is mostly because of the noise and in this case the hybrid approaches are much much better than the constituent methods and this is big cause this is the ideal case for our hybrid approach when we both of the constituent methods have modest recall and very good precision.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The lessons learned is that are that fact based look up and embeddings work better with bigger tables with many rows in smaller tables the embeddings work better than fact based look up when we have relations fact based look up works better because it exploits those relations when we have noise in our data the embeddings work better and the ideal case for the hybrid method is when we have good recall and modest recalling good precision in both methods so.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Come up, we have seen three different ways to annotate web tables using vlookups embeddings or ontology matching, and we have introduced a new gold standard that is publicly available and you look up method that outperforms state of the art and and you.",
                    "label": 0
                },
                {
                    "sent": "Approach that combines the previous approaches, so that's yeah, that's all, thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Comparison, so I'm kind of surprised that you were operating just with vlookups mostly right?",
                    "label": 0
                },
                {
                    "sent": "Let's see if you would use one of these several wiki fires, which have pretty sophisticated machinery behind for disembarkation and everything else.",
                    "label": 0
                },
                {
                    "sent": "So this would give you a little bit better baseline for comparisons.",
                    "label": 0
                },
                {
                    "sent": "I mean their fasts, strong contextual machinery to disambiguate, and so on, so.",
                    "label": 0
                },
                {
                    "sent": "Then a good reason why you didn't use, let's say this wiki fires or this annotation machine is.",
                    "label": 0
                },
                {
                    "sent": "We tried to find different approaches to this problem, so whenever we discussed with people they said that OK, you should definitely try my tool to for your problem.",
                    "label": 0
                },
                {
                    "sent": "It perfectly fits, so that's why we have so many different approaches.",
                    "label": 0
                },
                {
                    "sent": "To be fair, we could not try everything, but of course your suggestion is very good, so we didn't consider this option, but of course we could do that.",
                    "label": 0
                },
                {
                    "sent": "We are not.",
                    "label": 0
                },
                {
                    "sent": "Mostly based based on our results on vlookups, we also tried the embeddings on the matching and combination, but as a simple baseline we tried to see the simplest thing that we could do so just.",
                    "label": 0
                },
                {
                    "sent": "Just search for the entity in the label column and get the results.",
                    "label": 0
                },
                {
                    "sent": "And it's quite surprising that it provides very good results.",
                    "label": 0
                },
                {
                    "sent": "Very competitive results to state of the art and to us.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the question is where the problem gets hard, right?",
                    "label": 0
                },
                {
                    "sent": "So this is where yes starts mattering.",
                    "label": 0
                },
                {
                    "sent": "So there the look up just cannot do it anymore, right?",
                    "label": 0
                },
                {
                    "sent": "Yes, that's right.",
                    "label": 0
                },
                {
                    "sent": "So we have to exploit more things than just, but this is a very valid suggestion.",
                    "label": 0
                },
                {
                    "sent": "So thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you for the lies but intention and I have one question.",
                    "label": 0
                },
                {
                    "sent": "For the third method, you'll transform your table to.",
                    "label": 0
                },
                {
                    "sent": "I cannot hear you very well.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry for the third method, you transform your whip table into ontology and then match such ontology with the your Knowledge Graph.",
                    "label": 0
                },
                {
                    "sent": "So how you transform this web table to ontology and then when you transform it to ontology, it becomes.",
                    "label": 0
                },
                {
                    "sent": "It's not simple ontology matching, but in balance ontology matching problem.",
                    "label": 0
                },
                {
                    "sent": "Since the size of the whip table or the number of concept in the transform Ontology is not compatible to the original knowledge Graph you match with, so using such system like look map or the other system, I do not exactly if it is effective matching system you use to deal with such imbalance.",
                    "label": 0
                },
                {
                    "sent": "Matching into our intelligence metric exactly.",
                    "label": 0
                },
                {
                    "sent": "So this is not very quite fair for those tools, so we're not trying to criticize those tools for not performing.",
                    "label": 0
                },
                {
                    "sent": "Well, to answer the second part of your question, we just wanted to explore different ways to solve this problem and maybe see how well different tools work for this to this direction.",
                    "label": 0
                },
                {
                    "sent": "So what you say is correct, we have on the one side very rich ontology containing many classes and types, and on the other side we have a very flat ontology built only from a very small table with very few attributes and value.",
                    "label": 0
                },
                {
                    "sent": "So the way we created this ontology you can find more details in our.",
                    "label": 0
                },
                {
                    "sent": "College matching the paper last years, but the way that we do it, we assume that there is a header row which contains the names of the columns and the the cell of the header.",
                    "label": 0
                },
                {
                    "sent": "All that is in the label column.",
                    "label": 0
                },
                {
                    "sent": "We use it as the name of the root class.",
                    "label": 0
                },
                {
                    "sent": "Let's say a very shallow ontology and the rest of the cells in the header row are the attribute names of the entities and its role is an instance of this this.",
                    "label": 0
                },
                {
                    "sent": "My class and we have some sampling to detect if column is a data type, corresponds to data type or an object property.",
                    "label": 0
                },
                {
                    "sent": "So to relations with other entities.",
                    "label": 0
                },
                {
                    "sent": "But still this is very flat ontology and very shallow and it's it's not why those systems were built.",
                    "label": 0
                },
                {
                    "sent": "So for example, Paris explicitly states that we cannot handle at Regina's data, so it's not very fair to say that they're not performing well because they do not.",
                    "label": 0
                },
                {
                    "sent": "Do well in our use case.",
                    "label": 0
                }
            ]
        }
    }
}