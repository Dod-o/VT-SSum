{
    "id": "hlf44k5gt5q3c56yudgce524cedjok2b",
    "title": "Quality Assessment of Linked Datasets using Probabilistic Approximations",
    "info": {
        "author": [
            "Jeremy Debattista, Department of Enterprise Information Systems (EIS), University of Bonn"
        ],
        "published": "July 15, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2015_debattista_linked_datasets/",
    "segmentation": [
        [
            "Good afternoon everyone.",
            "I am Jeremy.",
            "I'm a PhD student at the University of Bonn, and during this 20 minutes or so I will be presenting our work titled quality assessment offering datasets using probabilistic approximation.",
            "So let's first start with the."
        ],
        [
            "Actual problem.",
            "So the problem was that we were assessing a number of datasets to try to detect duplicate instance, but it was taking."
        ],
        [
            "Quite a lot of time to finish.",
            "I."
        ],
        [
            "That means that I couldn't use my laptop for a lot of time.",
            "And of course, when it's time for deadlines, I cannot just wait and look at my monitor for a lot of time.",
            "And therefore we had to do some kind of so we have to find some kind of solution.",
            "Although we know that naive approaches for calculating quality metrics would give us more accurate results.",
            "It was clearly not time efficient.",
            "And obviously, we don't want to wait a lot of time to assess the link data quality."
        ],
        [
            "Therefore, our hypothesis was that probabilistic approximation techniques would, first of all drastically improve the computational time when compared with the more naive and traditional approaches, and second of all, they would give us.",
            "They will still give us close to accurate results.",
            "OK, so."
        ],
        [
            "In this presentation we will discuss three probabilistic techniques which which can be applied to four quality metrics in this case.",
            "So why did we choose these four quality metrics?",
            "So first of all, these four metrics are quite important for assessing linked data.",
            "For deference ability, for example, we don't really need to assess each and every resource to check if the resource is the reference data set has a high amount of the reference ability or not.",
            "So a sample would be good.",
            "Similar for the link to external data providers, which I will explain later.",
            "For extension of conciseness, we had to find some way which we can identify the public.",
            "It's in the datasets quickly without having to go through all datasets more than once or all the resources more than once.",
            "And finally, everyone knows that clustering coefficient clustering coefficient of a network traditional takes a lot of time to solve and compute."
        ],
        [
            "So each metric was evaluated with four different parameters and over over 6 datasets ranging from \u20b975,000 to 100 million triples.",
            "All evaluation was done actually on my notebook.",
            "The.",
            "The datasets were chosen from data hub and we make sure that the domains the domains of the datasets are different and in the last load."
        ],
        [
            "OK, so the first technique will discuss is the reservoir sampling technique, which will be used on the dereference ability metric and the links to data providers metric."
        ],
        [
            "So what's reservoir sampling?",
            "Reservoir sampling is a statistical based technique facilitating the sampling of evenly distributed items by either adding items to the reservoir if it's not full or generating some probability to replace an item in the reservoir."
        ],
        [
            "The first metric we will discuss this, the dereference ability metric.",
            "So basically this metric is the process that retrieves representation of the requested resource.",
            "So in semantic web times we have some UI and it gives us at 303.",
            "See other which will direct us to the actual resource on the web."
        ],
        [
            "So how are we doing the dereference ability and the naive way so?"
        ],
        [
            "Are taking this object and this object resource and pass it to the referencer."
        ],
        [
            "Under the reference cell would say if it is OK or not."
        ],
        [
            "I will take the object given that the object is a UI resource, pass it to the referencer."
        ],
        [
            "And again it would save it this dereferenceable or not."
        ],
        [
            "And we do this for all triples in the data set."
        ],
        [
            "So the naive approach was taking a lot of time due to the network overhead.",
            "Therefore we decided to see how we can do sampling.",
            "Therefore I will show you how we did the reservoir sampling using 11 resource."
        ],
        [
            "So we first take the top level domain and for the sake of this example, let's assume that the the top level domain is not in the reservoir."
        ],
        [
            "Therefore, the first thing we have to check is if it's reservoir full."
        ],
        [
            "If it's not full, great, we just edited in our reservoir."
        ],
        [
            "But what if it's?"
        ],
        [
            "So."
        ],
        [
            "Is this a bit?"
        ],
        [
            "The tricky part."
        ],
        [
            "Sophie."
        ],
        [
            "First we generate the probability from zero to 1, where N is the number of the items attempted to be to be added."
        ],
        [
            "Have the generated number lies between zero and the size of the reservoir.",
            "Then we just replace the current item."
        ],
        [
            "Each item is also expected.",
            "The reservoir is also errors, therefore itself and the second reservoir."
        ],
        [
            "We start the second part of the UI and the reservoir in the same manner.",
            "How we start the top level domains?"
        ],
        [
            "So the tradeoff for reservoir sampling is actually the size of the reservoir, which could fit in the memory.",
            "As we can see from 6 datasets for did not compute on the knife, or at least they did not compute inacceptable time.",
            "For the naive implementation.",
            "And for two of them we have some results for the second data set, no resource was actually the dereferenceable and we were wondering if this is true.",
            "So we went and checked some resources manually and it seemed that no resources was actually no resource was actually references references."
        ],
        [
            "So.",
            "The approximate technique, so it's the red bar there takes considerably less time than the knife technique, and in fact we managed to compute time for all the datasets.",
            "Our."
        ],
        [
            "The reference are such as resource is using HTTP gets, so the time is affected by the size of the resource and the network latency.",
            "Of course, an extra step ahead would be more ideal, but not all servers allow this feature, so we had to use HTTP get in this case."
        ],
        [
            "So the second metric is the links to external data providers which measures the degree of linkage with external data sources."
        ],
        [
            "So the naive approach is quite simple, so."
        ],
        [
            "First take the.",
            "Top level domain of this subject resource will check with the base UI and if they are not the same then it's not an external resource.",
            "We do the same for the object.",
            "Object resource will check the top level domain and it's not the same as the base you arrive.",
            "So that means it is a.",
            "An external resource."
        ],
        [
            "We then check if the external resource is a semantic resource or not, because we don't want to.",
            "I mean, if we have a UI which is an image, then it's not a link to an external resource for our case.",
            "And.",
            "If it is an extension, extended resource and semantic resource, then we store in set on disk."
        ],
        [
            "So the approximate approach is quite."
        ],
        [
            "So if I check this subject.",
            "The top level domain and we check it with the base you arrive."
        ],
        [
            "We do the same for the object.",
            "And."
        ],
        [
            "We store it in our CFR.",
            "We do not check beforehand.",
            "Finally, when all the strippers are are parsed and we have a reservoir full of external resources.",
            "Then we check each item in the reservoir is if it is a semantic resource or not."
        ],
        [
            "So I'm here.",
            "We had a bit more results than the previous one and we realized that the precision was actually 100%, so both deny even the estimation.",
            "I gotta Tim gave us the same results.",
            "One possible reason about this is the fact that the.",
            "The reservoir was too big in such a way that all extended resources could fit in the in the.",
            "In memory.",
            "Therefore."
        ],
        [
            "Um?",
            "We can look also into the time.",
            "So here we also see that the approximate technique.",
            "Outperformed the more naive one."
        ],
        [
            "And the knife metric we know that took more time since this set had to be stored in on disk.",
            "Therefore we will have some disk latency time as well."
        ],
        [
            "OK, so to sum up, the reservoir sampling techniques, the reference ability metric gave us around 75% precision and the order of magnitude could go up easily over two with small datasets having 1 million triples.",
            "And the external the link to external data providers gave us 100% precision and the time difference could also be notice be noticeable when the datasets were growing larger."
        ],
        [
            "OK, so the next technique I will discuss is the Bloom filter technique, which will be used in the extensional conciseness metric."
        ],
        [
            "So Bloom filters are a fast and space efficient vector data structure commonly used to query for elements in set.",
            "So."
        ],
        [
            "So imagine we have this word and we want to check if it is like if it exists in the English dictionary, so we can do three ways, either do it manually, go go through the dictionary word by word.",
            "Or else you some index and then still go word by word or else encoded dictionary in a bit vector data structures and use bloom filters.",
            "So if we go for the last approach, the blue filter will tell me, will tell us that the idea."
        ],
        [
            "Definitely does not exist in the dictionary."
        ],
        [
            "Or it's probably exists in the dictionary, but it will never tell us that it definitely exists in dictionary."
        ],
        [
            "So the idea behind Bloom filters is quite simple.",
            "We have a word and it is hashed by a number of functions."
        ],
        [
            "When if we are, I think they were to the Bloom filter, then the bits corresponding to the hash function values are set to 1.",
            "On the other hand, if.",
            "If we are searching for a word, the algorithm which will check if the bits are set to one or read."
        ],
        [
            "And then it will reply OK. Then the word probably exists in the set."
        ],
        [
            "Extension of Conciseness is a metric which consider an instance to be unique if no other instance in datasets exist with the same set of properties and corresponding values."
        ],
        [
            "So then I have approaches.",
            "As I said earlier, takes all resources and compare each of them with every other resource in the data set.",
            "So this is Dennis following."
        ],
        [
            "Just ordered triples by property and then by value.",
            "After ordering the properties and values, we convert them into some string representation, removing some punctuation and white spaces.",
            "The whole string is."
        ],
        [
            "Then compared with the rest of the resources whose properties and values are also ordered in the same manner.",
            "So."
        ],
        [
            "Yeah, that took a lot of time and we decided to use the Bloom filter approach.",
            "More specifically, we didn't use the traditional Bloom filter, but we used an adaptation of this technique which is used in data streams to detect that."
        ],
        [
            "Instances, so one of the main properties in this adaptation is that.",
            "Once the all Bloom filters are having their bit set to one before adding a new item, random bit is reset to 0.",
            "So this process of checking evap at resource exists already or not is done as follows.",
            "So first we take the distributors of a resource converted to a string representation as described below with past."
        ],
        [
            "2K hash functions which would give us K positions.",
            "Do."
        ],
        [
            "Escape positions will be used in one 2K Bloom filters."
        ],
        [
            "And we set all those weather direct boxes 2 to one.",
            "Can we also check when before adding?",
            "We also check if a random bit needs to be reset and this is done by a time cost."
        ],
        [
            "So the tradeoff for Bloom filters is that.",
            "Face off between the first computational resources is the number of filters and the size of the factors.",
            "Of course, all these approximation techniques should fit in memory.",
            "As we can see, for for these results we had a nice precision and the parameter settings used pair of 10 filters and the size was over 100,000."
        ],
        [
            "So the time here, the approximate algorithm outperformed.",
            "The nyva approximation.",
            "By by a large scale.",
            "And here we can say that the bloom filters really work for for this case."
        ],
        [
            "So to sum up the this this technique we saw that the precision was on average 1997%, while the computational time takes more or less three orders of magnitude.",
            "Less than the than the.",
            "Actual actual implementation."
        ],
        [
            "OK, so the last technique is the clustering coefficient estimation technique which will be used on the clustering coefficient C to check the clustering coefficient C of our network."
        ],
        [
            "So clustering coefficient estimation measures the neighborhood of neighborhoods density of an old using random walks on a graph."
        ],
        [
            "So the clustering coefficient of a network metric is as part of a set of network measures which is used to assess the quality of data mappings in linked datasets.",
            "The aim of this metric is actually two identifier to identify how how well resources are connected to each other by measuring the density of the resource neighborhood."
        ],
        [
            "So the traditional way of.",
            "Calculating clustering coefficient is as follows so."
        ],
        [
            "We first take aranaut and we get."
        ],
        [
            "The neighbor count if the neighbor count is less than two, then the clustering coefficient will automatically be 0."
        ],
        [
            "S We check how many of the neighbors are connected to each other.",
            "In this case one."
        ],
        [
            "And then we check the number of possible edges between nodes.",
            "These two numbers are divided and will give us the clustering coefficient value for that particular node.",
            "The right note.",
            "So this procedure is repeated for all nodes in a network and of course this will take a lot of time to compute."
        ],
        [
            "So how do we do the estimated way so?",
            "Assuming that we have a graph, we."
        ],
        [
            "Form a random walk moving from one note to another, backwards and forward."
        ],
        [
            "Untilled"
        ],
        [
            "The mixing time is rich, so mixing time is the time taken until a random work converges to a steady state."
        ],
        [
            "While we're doing this, this random walk, we are collecting information of the neighbors of the node and this information is then used by the estimator to call to calculate the clustering coefficient value.",
            "This function just calculates the weighted clustering coefficient for each node in the random random walk park.",
            "Divided by the reciprocal degree of the sample nodes."
        ],
        [
            "So.",
            "OK, so the mixing time chosen for this experiment was lock lock square then which is similar to the mixing time for small networks.",
            "Multiplied by a variable which we were actually using and testing to see what is the best mixing time for linked open data.",
            "Closely linked open data set.",
            "Since we have no idea of this mixing time yet.",
            "So as we can see, this mixing time gave us 98 and 99% precision on the 1st two datasets, but it was declining on the on bigger data set.",
            "Therefore it means that we still need to evaluate better the.",
            "The mixing time of of such a such an approach."
        ],
        [
            "Having said that, having said that the approximation approach still took less time to compute.",
            "One reason for having for having a lot of time during computation is that we are building the graph on disk, so that is something that we have to see in the future.",
            "How we can actually reduce this computation time as well."
        ],
        [
            "So to sum up this approach, we found out that the position was approximate 95% and the time saved was a bit more than one order of magnitude."
        ],
        [
            "Therefore, to conclude, let's just revisit the hypothesis.",
            "We first said that we want to drastically improve the computational."
        ],
        [
            "Time and we have designed this these experiments.",
            "We did decrease the computational time considerably.",
            "Anne."
        ],
        [
            "And the second one was to give close to accurate results.",
            "And we can say that the loss of precision was acceptable in most of the cases and so.",
            "We were happy to say that these hypothesis and and our.",
            "Our goal was met."
        ],
        [
            "Finally, data quality can, largely.",
            "Datasets can also be assessed for quality using very limited computational capabilities, such as a personal notebook.",
            "Therefore, no one, all publishers who are actually not publishing datasets, have no excuse not to calculate and assess their datasets for quality before actually publishing them on the web."
        ],
        [
            "OK, and finally all tests were all tests were conducted on our quality assessment framework look, so which is available online?",
            "These metrics metrics which I discussed are also available online amongst with others.",
            "OK, so thank you for your time and any questions please."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "I am Jeremy.",
                    "label": 0
                },
                {
                    "sent": "I'm a PhD student at the University of Bonn, and during this 20 minutes or so I will be presenting our work titled quality assessment offering datasets using probabilistic approximation.",
                    "label": 1
                },
                {
                    "sent": "So let's first start with the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actual problem.",
                    "label": 0
                },
                {
                    "sent": "So the problem was that we were assessing a number of datasets to try to detect duplicate instance, but it was taking.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quite a lot of time to finish.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That means that I couldn't use my laptop for a lot of time.",
                    "label": 0
                },
                {
                    "sent": "And of course, when it's time for deadlines, I cannot just wait and look at my monitor for a lot of time.",
                    "label": 0
                },
                {
                    "sent": "And therefore we had to do some kind of so we have to find some kind of solution.",
                    "label": 0
                },
                {
                    "sent": "Although we know that naive approaches for calculating quality metrics would give us more accurate results.",
                    "label": 0
                },
                {
                    "sent": "It was clearly not time efficient.",
                    "label": 0
                },
                {
                    "sent": "And obviously, we don't want to wait a lot of time to assess the link data quality.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Therefore, our hypothesis was that probabilistic approximation techniques would, first of all drastically improve the computational time when compared with the more naive and traditional approaches, and second of all, they would give us.",
                    "label": 1
                },
                {
                    "sent": "They will still give us close to accurate results.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this presentation we will discuss three probabilistic techniques which which can be applied to four quality metrics in this case.",
                    "label": 0
                },
                {
                    "sent": "So why did we choose these four quality metrics?",
                    "label": 0
                },
                {
                    "sent": "So first of all, these four metrics are quite important for assessing linked data.",
                    "label": 0
                },
                {
                    "sent": "For deference ability, for example, we don't really need to assess each and every resource to check if the resource is the reference data set has a high amount of the reference ability or not.",
                    "label": 0
                },
                {
                    "sent": "So a sample would be good.",
                    "label": 0
                },
                {
                    "sent": "Similar for the link to external data providers, which I will explain later.",
                    "label": 1
                },
                {
                    "sent": "For extension of conciseness, we had to find some way which we can identify the public.",
                    "label": 0
                },
                {
                    "sent": "It's in the datasets quickly without having to go through all datasets more than once or all the resources more than once.",
                    "label": 0
                },
                {
                    "sent": "And finally, everyone knows that clustering coefficient clustering coefficient of a network traditional takes a lot of time to solve and compute.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So each metric was evaluated with four different parameters and over over 6 datasets ranging from \u20b975,000 to 100 million triples.",
                    "label": 1
                },
                {
                    "sent": "All evaluation was done actually on my notebook.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The datasets were chosen from data hub and we make sure that the domains the domains of the datasets are different and in the last load.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the first technique will discuss is the reservoir sampling technique, which will be used on the dereference ability metric and the links to data providers metric.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what's reservoir sampling?",
                    "label": 0
                },
                {
                    "sent": "Reservoir sampling is a statistical based technique facilitating the sampling of evenly distributed items by either adding items to the reservoir if it's not full or generating some probability to replace an item in the reservoir.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first metric we will discuss this, the dereference ability metric.",
                    "label": 0
                },
                {
                    "sent": "So basically this metric is the process that retrieves representation of the requested resource.",
                    "label": 1
                },
                {
                    "sent": "So in semantic web times we have some UI and it gives us at 303.",
                    "label": 0
                },
                {
                    "sent": "See other which will direct us to the actual resource on the web.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how are we doing the dereference ability and the naive way so?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are taking this object and this object resource and pass it to the referencer.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Under the reference cell would say if it is OK or not.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will take the object given that the object is a UI resource, pass it to the referencer.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again it would save it this dereferenceable or not.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we do this for all triples in the data set.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the naive approach was taking a lot of time due to the network overhead.",
                    "label": 0
                },
                {
                    "sent": "Therefore we decided to see how we can do sampling.",
                    "label": 0
                },
                {
                    "sent": "Therefore I will show you how we did the reservoir sampling using 11 resource.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we first take the top level domain and for the sake of this example, let's assume that the the top level domain is not in the reservoir.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Therefore, the first thing we have to check is if it's reservoir full.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If it's not full, great, we just edited in our reservoir.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But what if it's?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is this a bit?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The tricky part.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sophie.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First we generate the probability from zero to 1, where N is the number of the items attempted to be to be added.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have the generated number lies between zero and the size of the reservoir.",
                    "label": 0
                },
                {
                    "sent": "Then we just replace the current item.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each item is also expected.",
                    "label": 0
                },
                {
                    "sent": "The reservoir is also errors, therefore itself and the second reservoir.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We start the second part of the UI and the reservoir in the same manner.",
                    "label": 0
                },
                {
                    "sent": "How we start the top level domains?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the tradeoff for reservoir sampling is actually the size of the reservoir, which could fit in the memory.",
                    "label": 0
                },
                {
                    "sent": "As we can see from 6 datasets for did not compute on the knife, or at least they did not compute inacceptable time.",
                    "label": 0
                },
                {
                    "sent": "For the naive implementation.",
                    "label": 0
                },
                {
                    "sent": "And for two of them we have some results for the second data set, no resource was actually the dereferenceable and we were wondering if this is true.",
                    "label": 0
                },
                {
                    "sent": "So we went and checked some resources manually and it seemed that no resources was actually no resource was actually references references.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The approximate technique, so it's the red bar there takes considerably less time than the knife technique, and in fact we managed to compute time for all the datasets.",
                    "label": 0
                },
                {
                    "sent": "Our.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The reference are such as resource is using HTTP gets, so the time is affected by the size of the resource and the network latency.",
                    "label": 0
                },
                {
                    "sent": "Of course, an extra step ahead would be more ideal, but not all servers allow this feature, so we had to use HTTP get in this case.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the second metric is the links to external data providers which measures the degree of linkage with external data sources.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the naive approach is quite simple, so.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First take the.",
                    "label": 0
                },
                {
                    "sent": "Top level domain of this subject resource will check with the base UI and if they are not the same then it's not an external resource.",
                    "label": 0
                },
                {
                    "sent": "We do the same for the object.",
                    "label": 0
                },
                {
                    "sent": "Object resource will check the top level domain and it's not the same as the base you arrive.",
                    "label": 0
                },
                {
                    "sent": "So that means it is a.",
                    "label": 0
                },
                {
                    "sent": "An external resource.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We then check if the external resource is a semantic resource or not, because we don't want to.",
                    "label": 0
                },
                {
                    "sent": "I mean, if we have a UI which is an image, then it's not a link to an external resource for our case.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "If it is an extension, extended resource and semantic resource, then we store in set on disk.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the approximate approach is quite.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if I check this subject.",
                    "label": 0
                },
                {
                    "sent": "The top level domain and we check it with the base you arrive.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do the same for the object.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We store it in our CFR.",
                    "label": 0
                },
                {
                    "sent": "We do not check beforehand.",
                    "label": 0
                },
                {
                    "sent": "Finally, when all the strippers are are parsed and we have a reservoir full of external resources.",
                    "label": 0
                },
                {
                    "sent": "Then we check each item in the reservoir is if it is a semantic resource or not.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm here.",
                    "label": 0
                },
                {
                    "sent": "We had a bit more results than the previous one and we realized that the precision was actually 100%, so both deny even the estimation.",
                    "label": 0
                },
                {
                    "sent": "I gotta Tim gave us the same results.",
                    "label": 0
                },
                {
                    "sent": "One possible reason about this is the fact that the.",
                    "label": 0
                },
                {
                    "sent": "The reservoir was too big in such a way that all extended resources could fit in the in the.",
                    "label": 0
                },
                {
                    "sent": "In memory.",
                    "label": 0
                },
                {
                    "sent": "Therefore.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We can look also into the time.",
                    "label": 0
                },
                {
                    "sent": "So here we also see that the approximate technique.",
                    "label": 0
                },
                {
                    "sent": "Outperformed the more naive one.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the knife metric we know that took more time since this set had to be stored in on disk.",
                    "label": 0
                },
                {
                    "sent": "Therefore we will have some disk latency time as well.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so to sum up, the reservoir sampling techniques, the reference ability metric gave us around 75% precision and the order of magnitude could go up easily over two with small datasets having 1 million triples.",
                    "label": 0
                },
                {
                    "sent": "And the external the link to external data providers gave us 100% precision and the time difference could also be notice be noticeable when the datasets were growing larger.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the next technique I will discuss is the Bloom filter technique, which will be used in the extensional conciseness metric.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Bloom filters are a fast and space efficient vector data structure commonly used to query for elements in set.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So imagine we have this word and we want to check if it is like if it exists in the English dictionary, so we can do three ways, either do it manually, go go through the dictionary word by word.",
                    "label": 0
                },
                {
                    "sent": "Or else you some index and then still go word by word or else encoded dictionary in a bit vector data structures and use bloom filters.",
                    "label": 1
                },
                {
                    "sent": "So if we go for the last approach, the blue filter will tell me, will tell us that the idea.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Definitely does not exist in the dictionary.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or it's probably exists in the dictionary, but it will never tell us that it definitely exists in dictionary.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the idea behind Bloom filters is quite simple.",
                    "label": 0
                },
                {
                    "sent": "We have a word and it is hashed by a number of functions.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When if we are, I think they were to the Bloom filter, then the bits corresponding to the hash function values are set to 1.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if.",
                    "label": 0
                },
                {
                    "sent": "If we are searching for a word, the algorithm which will check if the bits are set to one or read.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then it will reply OK. Then the word probably exists in the set.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Extension of Conciseness is a metric which consider an instance to be unique if no other instance in datasets exist with the same set of properties and corresponding values.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then I have approaches.",
                    "label": 0
                },
                {
                    "sent": "As I said earlier, takes all resources and compare each of them with every other resource in the data set.",
                    "label": 0
                },
                {
                    "sent": "So this is Dennis following.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just ordered triples by property and then by value.",
                    "label": 0
                },
                {
                    "sent": "After ordering the properties and values, we convert them into some string representation, removing some punctuation and white spaces.",
                    "label": 0
                },
                {
                    "sent": "The whole string is.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then compared with the rest of the resources whose properties and values are also ordered in the same manner.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, that took a lot of time and we decided to use the Bloom filter approach.",
                    "label": 0
                },
                {
                    "sent": "More specifically, we didn't use the traditional Bloom filter, but we used an adaptation of this technique which is used in data streams to detect that.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Instances, so one of the main properties in this adaptation is that.",
                    "label": 0
                },
                {
                    "sent": "Once the all Bloom filters are having their bit set to one before adding a new item, random bit is reset to 0.",
                    "label": 0
                },
                {
                    "sent": "So this process of checking evap at resource exists already or not is done as follows.",
                    "label": 0
                },
                {
                    "sent": "So first we take the distributors of a resource converted to a string representation as described below with past.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2K hash functions which would give us K positions.",
                    "label": 0
                },
                {
                    "sent": "Do.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Escape positions will be used in one 2K Bloom filters.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we set all those weather direct boxes 2 to one.",
                    "label": 0
                },
                {
                    "sent": "Can we also check when before adding?",
                    "label": 0
                },
                {
                    "sent": "We also check if a random bit needs to be reset and this is done by a time cost.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the tradeoff for Bloom filters is that.",
                    "label": 0
                },
                {
                    "sent": "Face off between the first computational resources is the number of filters and the size of the factors.",
                    "label": 0
                },
                {
                    "sent": "Of course, all these approximation techniques should fit in memory.",
                    "label": 0
                },
                {
                    "sent": "As we can see, for for these results we had a nice precision and the parameter settings used pair of 10 filters and the size was over 100,000.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the time here, the approximate algorithm outperformed.",
                    "label": 0
                },
                {
                    "sent": "The nyva approximation.",
                    "label": 0
                },
                {
                    "sent": "By by a large scale.",
                    "label": 0
                },
                {
                    "sent": "And here we can say that the bloom filters really work for for this case.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to sum up the this this technique we saw that the precision was on average 1997%, while the computational time takes more or less three orders of magnitude.",
                    "label": 0
                },
                {
                    "sent": "Less than the than the.",
                    "label": 0
                },
                {
                    "sent": "Actual actual implementation.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the last technique is the clustering coefficient estimation technique which will be used on the clustering coefficient C to check the clustering coefficient C of our network.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So clustering coefficient estimation measures the neighborhood of neighborhoods density of an old using random walks on a graph.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the clustering coefficient of a network metric is as part of a set of network measures which is used to assess the quality of data mappings in linked datasets.",
                    "label": 0
                },
                {
                    "sent": "The aim of this metric is actually two identifier to identify how how well resources are connected to each other by measuring the density of the resource neighborhood.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the traditional way of.",
                    "label": 0
                },
                {
                    "sent": "Calculating clustering coefficient is as follows so.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We first take aranaut and we get.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The neighbor count if the neighbor count is less than two, then the clustering coefficient will automatically be 0.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "S We check how many of the neighbors are connected to each other.",
                    "label": 0
                },
                {
                    "sent": "In this case one.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we check the number of possible edges between nodes.",
                    "label": 0
                },
                {
                    "sent": "These two numbers are divided and will give us the clustering coefficient value for that particular node.",
                    "label": 1
                },
                {
                    "sent": "The right note.",
                    "label": 0
                },
                {
                    "sent": "So this procedure is repeated for all nodes in a network and of course this will take a lot of time to compute.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we do the estimated way so?",
                    "label": 0
                },
                {
                    "sent": "Assuming that we have a graph, we.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Form a random walk moving from one note to another, backwards and forward.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Untilled",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The mixing time is rich, so mixing time is the time taken until a random work converges to a steady state.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "While we're doing this, this random walk, we are collecting information of the neighbors of the node and this information is then used by the estimator to call to calculate the clustering coefficient value.",
                    "label": 0
                },
                {
                    "sent": "This function just calculates the weighted clustering coefficient for each node in the random random walk park.",
                    "label": 1
                },
                {
                    "sent": "Divided by the reciprocal degree of the sample nodes.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, so the mixing time chosen for this experiment was lock lock square then which is similar to the mixing time for small networks.",
                    "label": 0
                },
                {
                    "sent": "Multiplied by a variable which we were actually using and testing to see what is the best mixing time for linked open data.",
                    "label": 1
                },
                {
                    "sent": "Closely linked open data set.",
                    "label": 0
                },
                {
                    "sent": "Since we have no idea of this mixing time yet.",
                    "label": 0
                },
                {
                    "sent": "So as we can see, this mixing time gave us 98 and 99% precision on the 1st two datasets, but it was declining on the on bigger data set.",
                    "label": 0
                },
                {
                    "sent": "Therefore it means that we still need to evaluate better the.",
                    "label": 0
                },
                {
                    "sent": "The mixing time of of such a such an approach.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Having said that, having said that the approximation approach still took less time to compute.",
                    "label": 0
                },
                {
                    "sent": "One reason for having for having a lot of time during computation is that we are building the graph on disk, so that is something that we have to see in the future.",
                    "label": 0
                },
                {
                    "sent": "How we can actually reduce this computation time as well.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to sum up this approach, we found out that the position was approximate 95% and the time saved was a bit more than one order of magnitude.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Therefore, to conclude, let's just revisit the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "We first said that we want to drastically improve the computational.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time and we have designed this these experiments.",
                    "label": 0
                },
                {
                    "sent": "We did decrease the computational time considerably.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the second one was to give close to accurate results.",
                    "label": 1
                },
                {
                    "sent": "And we can say that the loss of precision was acceptable in most of the cases and so.",
                    "label": 0
                },
                {
                    "sent": "We were happy to say that these hypothesis and and our.",
                    "label": 0
                },
                {
                    "sent": "Our goal was met.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, data quality can, largely.",
                    "label": 0
                },
                {
                    "sent": "Datasets can also be assessed for quality using very limited computational capabilities, such as a personal notebook.",
                    "label": 0
                },
                {
                    "sent": "Therefore, no one, all publishers who are actually not publishing datasets, have no excuse not to calculate and assess their datasets for quality before actually publishing them on the web.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and finally all tests were all tests were conducted on our quality assessment framework look, so which is available online?",
                    "label": 0
                },
                {
                    "sent": "These metrics metrics which I discussed are also available online amongst with others.",
                    "label": 0
                },
                {
                    "sent": "OK, so thank you for your time and any questions please.",
                    "label": 0
                }
            ]
        }
    }
}