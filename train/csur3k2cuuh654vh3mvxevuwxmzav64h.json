{
    "id": "csur3k2cuuh654vh3mvxevuwxmzav64h",
    "title": "Scaling Up Multiagent Planning: A Best-Response Approach",
    "info": {
        "author": [
            "Anders Jonsson, Artificial Intelligence Group, Pompeu Fabra University"
        ],
        "published": "July 21, 2011",
        "recorded": "June 2011",
        "category": [
            "Top->Computer Science->Artificial Intelligence->Planning and Scheduling"
        ]
    },
    "url": "http://videolectures.net/icaps2011_jonsson_planning/",
    "segmentation": [
        [
            "So this is joint work with Michael Robot, Sis of University of Edenburg.",
            "So we're going to look at planning with multiple agents.",
            "So as as most of you know, it's a hard problem because the joint action space is exponential in the number of agents, and also agents might be be self interested in might not care so much about what other agents are doing, but be more concerned about their own goals.",
            "So our proposed solution is to let each agent compute its best response to the other agents actions.",
            "By best response, we mean a plan that minimizes the cost to the agent, while while still achieving its goals.",
            "And, well, a major motivation for this work, of course, is that if we plan for one agent at a time, we can use single agent planners, which we know are quite."
        ],
        [
            "Efficient, we're going to look at planning with multiple agents, which we know is a hard problem.",
            "The Joint Action space is exponential in the number of agents.",
            "And agents maybe feel self interested."
        ],
        [
            "So our proposed solution is to let each agent compute its best response to the other agents plans."
        ],
        [
            "By best response, we mean a plan that minimizes the cost to that agent, while while achieving."
        ],
        [
            "Its goals.",
            "And part of the motivation for doing this is when when we plan for a single agent, we can use single agent planner planners which we know are quite."
        ],
        [
            "Efficient.",
            "So the notation is we define the multi agent problem as tuple, where N is the set of agents.",
            "We have a set of fluents an initial state.",
            "Gold states for each agent, so the overall goal is to to to achieve the goals of all agents in the action.",
            "Space is the cross product of the individual actions.",
            "Sets of each agent a novel element?",
            "Here is what we call an admissibility function, which I'll describe on another slide.",
            "And each agent also has a cost function, which is a function from the Joint action space to the reels.",
            "So I think to note here is that the cost to an agent might depend on what other agents are doing, not just what the what the agent itself is doing."
        ],
        [
            "And the goal, as usual, is to find a plan, which here is a sequence of joint actions to that takes you from initial state to."
        ],
        [
            "Allstate.",
            "The Fluence can be partitioned into private set for each agent which we call F1 to FN plus a set of public influence that we called F Pub.",
            "So the idea is that the the fluids that are private to an agent are those that can only be affected by that agent while the set of public fluents are those that can be changed by all agents."
        ],
        [
            "So if we do this, each action of an agent.",
            "Anne has preconditions and effects only on the private Fluence of that agents and the set of public fluents.",
            "And well, this can trivially be extended to to negative preconditions and effects."
        ],
        [
            "And the same thing is true about the goal.",
            "The goal state of an agent is only defined on the on the private influence of that agent and the set of public."
        ],
        [
            "Fluents and the cost of a plan is just the sum of the costs of the of the joint actions of the the joint actions of the of the plan."
        ],
        [
            "The admissibility function represents concurrency constraints between individual actions, so that for example in."
        ],
        [
            "So so we just say that a joint action A is part of the plan if it Maps to 1 using the admissibility function.",
            "If it Maps to zero, it's not part of the of the problem.",
            "So for example, in logistics you know 22 agents could not pick up the the same package at the same time, so we can just prohibit that those joint actions by by this function."
        ],
        [
            "So there are two reasons for doing this.",
            "One is that even though the Joint action space is exponential in and, we can usually represent this function PSI in in a more compact way an."
        ],
        [
            "And another motivation is that our approach requires quickly checking whether a joint action is part of the of the problem or not, which we can then do with this function."
        ],
        [
            "So just a quick example of what a multiagent planning problem looks like here.",
            "There are three agents represent and they are in a network, so the network nodes are here.",
            "The intersections of the lines we have to send some package across this network, so there the initial states are represented by the numbers of the agents and the gold states are represented by the symbols that match each agent."
        ],
        [
            "So a joint action is consists of each agent taking one of its actions.",
            "In this example, we take the cost of an action to an agent to be the number of other agents that send the package across the same link at the same time."
        ],
        [
            "And eventually, well, the agents will find the joint plan.",
            "This these circles here highlights links where the cost is suboptimal in the sense that more than one agent is sending a package across that link at the same time step.",
            "It's not just that they send it, send the the package through that link, they have to do it at the same time step as well for the cost to increase.",
            "OK, so."
        ],
        [
            "So now I'm going to define the best response planning problem.",
            "So so our approach assumes that there already exists a joint plan for solving the problem of length."
        ],
        [
            "Day.",
            "So what we will do is give an agent.",
            "I will define a single agent planning problem with costs where the Fluence of that problem is just the private Fluence of that agent.",
            "Plus while union the public fluents union set of time fluens that will just be kept.",
            "We used to keep track of the position we are in the plan.",
            "The initial state is the the the original initial state projected onto the new set of fluents Union and Time Zero, and the goal state is the individual goal of that agent.",
            "Union time K. So we have to take the.",
            "Then the additional fluents here require us to to move from time zero to time."
        ],
        [
            "Kate.",
            "So what?",
            "How do we define actions of our problem?",
            "Well, each joint action of the of the existing plan.",
            "Can be written as a pair where the first element of the pair is the reaction of Agent I and the 2nd the 2nd element is the action of all other agents except I."
        ],
        [
            "And what we will do is for each possible action of Agent I we will replace the agent ice action in the joint action with that that new action."
        ],
        [
            "If that action is, if that's new, joint action is is admissible, it is part of the problem.",
            "We add a new action to the action space where the preconditions and effects are just projected onto the new set of fluents.",
            "And the the the time, the way that I'm fluents are added here is to show to simulate that we move one time step forward when we when we take an action.",
            "So the idea here is that by enforcing this we we assure that the position of the actions of other agents in the plan remain the same because the first joint action has to happen from time zero to time one, the second one from time one to time two etc until we reach time K. And finally, the cost of the action.",
            "Here is the cost of the action to Agent I, because Agent I is trying to to minimize it its own."
        ],
        [
            "So it might happen that after this K time, after executing this K actions agent, I might still not have achieved its goal.",
            "So to take this into account, we also add know up actions for each agent that can be applied when the agent is done with all."
        ],
        [
            "Other actions.",
            "So for each possible action of Agent I, we add joint actions that are basically that action for Agent I and nothing, no up action for all other."
        ],
        [
            "Guidance and we add the uh, corresponding action to our new action space.",
            "In the exact same way as before, the only difference now is that the precondition is that all the other key actions have to have already been been applied, so we can only take these actions once.",
            "The other actions are done."
        ],
        [
            "OK, so now once we have set this up now the process of doing best response planning is very simple.",
            "We just solve this this BRP problem using an optimal planner.",
            "We replaced the actions for Agent I with the new actions with the actions of the new plan and we iterate over all agents until no agent can can improve its cost anymore."
        ],
        [
            "OK, so so just in the in the example, well too.",
            "Resolve these these suboptimal cases.",
            "We now let Agent one plan while keeping the actions of agents two and three fixed so it."
        ],
        [
            "One might come up with a plan that looks like this.",
            "So now the at no point does Agent I, agent one send a package across a link that coincides with another agent, and then we do the same thing for ages."
        ],
        [
            "Two and and eventually no agent can improve its cost by by choosing a cheaper plan."
        ],
        [
            "OK, so in general what the process we have described is not guaranteed to converge, but we will define a subclass of multi agent problems for which it does converge.",
            "So to do this will borrow some concepts from game theory.",
            "In particular, there's something in game theory called the Congestion Games where.",
            "Just as before, we have a set of agents.",
            "We have a set of resources.",
            "And actions consist in selecting a nonempty subset of the resources, so it's there's no planning here.",
            "This is the one shot action.",
            "You just select a nonempty subset of the resources and there's a cost function associated with each resource."
        ],
        [
            "And the utility of an agent depends on for each resource that it chose, how many other agents shows that same resource and weighted by this.",
            "This cost function for that resource."
        ],
        [
            "So just to make this idea a little more interesting from a planning perspective, we decided to extend this idea of congestion game just by.",
            "Sorry, I'm I'm already on the next slide, so so first of all, I'm just going to describe why this is interesting from our perspective.",
            "Well, given the congestion game, you can define a potential function.",
            "It does not really matter here what the potential function is.",
            "What does matter is that the potential function has the following property given 2 joint actions and that only differ in the.",
            "Action choice of Agent I.",
            "The difference in the difference in utility to Agent I is the same as the difference in potential.",
            "So if an agent chooses another action that increases its utility by some amount, the potential increases by an equivalent amount."
        ],
        [
            "So it's very so, so games that satisfy this property are called potential games, and it's very easy to prove that this type of iterative best response convert this in this case to Nash equilibrium."
        ],
        [
            "So, so like I already said, we decided to extend this idea to to make it a bit more interesting from a planning perspective.",
            "The only thing we did that was that to introduce an extra term in the utility function of an agent that only depends on the action choice of that agent.",
            "So so so the UI prime here.",
            "The new term DI AI only depends on AI.",
            "In other words, the action shows that agent I made.",
            "And well, if you make this extension, you can just define a new."
        ],
        [
            "Central function and you can show that the the potential game property still holds.",
            "Yes, just by doing the the map."
        ],
        [
            "So so now, given this we we define a class of of multiagent planning problems that we call congestion planning problems.",
            "First, let R be a set of resources, each with an associated cost function."
        ],
        [
            "A congestion planning problem is simply a standard multiagent planning problem, as as we defined before augmented with this set of resources and the cost function for each resource.",
            "Such that each action of an agent is associated with a possibly empty subset of resources.",
            "And the following additional restric."
        ],
        [
            "Oceans hold the set of public fluences is empty.",
            "The all joint actions are part of the problem.",
            "The cost function of Agent I is some function here which is essentially what it is, is the negation of the utility function of the extended utility function from the previous slide.",
            "So we just sweep.",
            "I mean when to maximize utility you want to minimize cost and no up action uses no resource and incurs no cost."
        ],
        [
            "So so for this new class of problems it's quite easy to prove the following that the best.",
            "I mean this iterative best response planning process that we have described is guaranteed to converge to in this case to the Nash equilibrium.",
            "So to do this the we define a potential function not just for individual actions, but for whole plans.",
            "And we show that the difference in utility between two plans that were the plans only differ on the actions of Agent I.",
            "Is equal exactly to the difference in cost to that agent of that plan.",
            "So that's exactly the same property as we had before.",
            "It's only that now we have a sequence of actions instead of individual actions.",
            "So what we get is in fact that the congestion planning problem is is a planning is a potential game where actions can change their plans to improve their costs, and this potential will increase by an equivalent amount.",
            "So, so this is guaranteed to converge."
        ],
        [
            "And in fact, the example I have been showing you is an example of such a planning problem where there are no.",
            "The only fluids are the fluids describing the current position of a package.",
            "And the resources are the links in the network and the costs associated with the link is the number of agents sending packages across that link simultaneously."
        ],
        [
            "So just to to test this idea, we we ran two sets of experiments.",
            "In the first set of experiments we used the network example from the that I have been showing you just varying the number of nodes and agents.",
            "In the second set, we run experiments in problems from the the planning competition with multi agent flavor.",
            "For each.",
            "Best response planning problem.",
            "We generate the corresponding problem in PDL which involves some technical details which I will not get into here and we used a HSP to to solve these these problems optimally."
        ],
        [
            "In the network example, we have already seen that it's an example of a congestion planning problem, so finding the initial plan here is easy.",
            "We can just let each individual agent plan as if no other agents are using links simultaneously.",
            "And by the previous theorem here, the best response planning process is guaranteed to converge.",
            "I'm not going to.",
            "Well, the results are fairly as expected, just to give an idea of how large problems we can solve if we have a network with 100 nodes in 100 agents, the best response planning converges in 10 minutes, so we can scale.",
            "2 problems that are significantly larger than than than what have been done so far in multiagent planning.",
            "Of course, that that the reason we can do this is that these problems are very weakly coupled, that there are no fluents that shared by agents.",
            "The only interaction between agents is the cost that depends on other agents doing something simelton."
        ],
        [
            "Leslie in the IPC domains.",
            "We used multi agent problems from from.",
            "From logistics Rovers and satellite.",
            "And to generate an initial plan, we used the this ESP planner by Nissim ET al.",
            "And in Rovers, HSP failed to solve our beer VRP problems.",
            "So we also use Llama to to to generate suboptimal plans.",
            "So even though La Maison is a satisficing planner, we wanted to see what.",
            "Whether in fact the whole process would converge in this case, so the motivation for these experiments were not really too.",
            "UH-2 as to to test whether sorry the motivation for this was basically to test whether beer P would converge at all, in spite of lack of such guarantees, and to see what how long it would take, what it will converge to it."
        ],
        [
            "Cetera.",
            "So so the result.",
            "Here are the results for for for the problems in in a few of the logistics Rovers and satellite problems.",
            "The Thi columnist this that I'm the the C columnists.",
            "The cost the total cost where we just defined cost as the total number of of actions of each of the agents, non idle actions and M Mr is the makespan.",
            "And for the VR, optimal is VR using HSP and VR.",
            "Satisficing is VR using Llama and the I column is the number of iterations it took two to converge to two.",
            "To stable equilibrium.",
            "So what we can see is that in logistics VRP is quite fast compared to finding the initial plan.",
            "The reason is that the branching factor is not so large.",
            "But there getting coming up with and there's a lot of interaction between agents because there are lot of of public fluents in terms of packages that are in different locations.",
            "We believe that the recent llama fails here.",
            "Is that the problem is very heavily constrained that the agent might have to satisfy a precondition at a given time that another agent is using.",
            "And basically you have to find an optimal plan to to foreign agents to be able to do that, so so llama in many cases reports that the problem is unsolvable even though it in fact is.",
            "In Rovers I actually discovered yes to couple of days ago that the reason that HSV fails is that for you.",
            "For those of you who are familiar with Rovers, the strips translation introduces some redundant effects such as not Channel 3 and channel free and HSV can't deal with him if you remove those.",
            "Those redundant effects HP can infected with him, but I didn't have time to run experiments using this.",
            "Well, what you can note here in general is that the the cost of the initial plan was already in fact very good, so so it was not improved by appana lot.",
            "Bye bye best response planning.",
            "On the other hand, best response planning in many cases is able to improve on them expand.",
            "In other words, it can find the shorter.",
            "Shorter joint plans than the initial plan."
        ],
        [
            "So to conclude that we have presented a single agent approach to multiagent planning, where each agent optimizes its own cost.",
            "In other words, it acts in a bit in a way in a selfish way to to find its best cost.",
            "For congestion planning problems, this process is guaranteed to converge and and even though there are no convergence guarantees in the IPC domains we tested, in practice the process does converge in these problems too."
        ],
        [
            "For future works.",
            "We'd like to determine convergence guarantees for larger classes of multiagent planning problems.",
            "Also, of course the the main limitation of this work is that you need an initial plan to start, so to find ways to apply single agent planning to come up with with initial plans.",
            "And also to try cases for which public goals are not shared by by agents, which is an assumption we made in this work.",
            "And as any translation based approach basically sit back and roll our thumbs and hope that that single agent planning that that we that other researchers develop better single agent planners.",
            "I mean we might even see such planners now in in the next session.",
            "OK.",
            "In the first problem that you showed, there are many optimal plans, so agents can accommodate other agents and still find an optimal plan in the total cost remains pretty good, but in some problems because of the interaction they may they may not be able to execute optimal plans, and then there may be some nontrivial tradeoffs.",
            "And what can you say about the?",
            "The equilibrium that you find how far it may be from the best quality measured, let's say by some.",
            "So it depends very heavily on the in the network example the there's just one single best equilibrium, so it will always always.",
            "Any congestion planning problem?",
            "There's only one best equilibrium in in a general.",
            "In the general case, it depends heavily on the initial plan, so different initial plans of course will.",
            "Will lead to different equilibrium.",
            "So in most of these, in this approach you you assume that all other agent plans are always successful, 'cause you share costs.",
            "So you must assume that every other agent does exactly what it what he says he wants to do.",
            "So how would you?",
            "I don't know.",
            "Think about uncertainty in this situation.",
            "What kind of approach would you?",
            "Yeah, I think it's best to deal with here.",
            "So it's not really a problem.",
            "We have thought so much about, but.",
            "Yeah, so it's true.",
            "Our approach requires other agents plans to be fixed.",
            "If you cannot trust the other agents then.",
            "Probably it becomes difficult to guarantee that you can even reach your satisfy your own goal, right?",
            "Because so so.",
            "I don't really have a good answer.",
            "Any thoughts of that, how well?",
            "This will be our last question is so why why Nash equilibrium?",
            "Yeah, well, it's a.",
            "It's one well established criteria for equilibrium.",
            "So so to prove here that we converge to something.",
            "It's just a well established criteria that that that.",
            "That we used to to prove convergence, but of course I don't rule out that there are other criteria in fact.",
            "We have already been thinking about trying to prove convergence for for more general classes of planning problems in that case.",
            "And we have some positive results that are not Nash equilibrium, so so I would say that there are we are not restraining ourselves to just magically appear here.",
            "Thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is joint work with Michael Robot, Sis of University of Edenburg.",
                    "label": 1
                },
                {
                    "sent": "So we're going to look at planning with multiple agents.",
                    "label": 0
                },
                {
                    "sent": "So as as most of you know, it's a hard problem because the joint action space is exponential in the number of agents, and also agents might be be self interested in might not care so much about what other agents are doing, but be more concerned about their own goals.",
                    "label": 0
                },
                {
                    "sent": "So our proposed solution is to let each agent compute its best response to the other agents actions.",
                    "label": 0
                },
                {
                    "sent": "By best response, we mean a plan that minimizes the cost to the agent, while while still achieving its goals.",
                    "label": 0
                },
                {
                    "sent": "And, well, a major motivation for this work, of course, is that if we plan for one agent at a time, we can use single agent planners, which we know are quite.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Efficient, we're going to look at planning with multiple agents, which we know is a hard problem.",
                    "label": 0
                },
                {
                    "sent": "The Joint Action space is exponential in the number of agents.",
                    "label": 1
                },
                {
                    "sent": "And agents maybe feel self interested.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our proposed solution is to let each agent compute its best response to the other agents plans.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By best response, we mean a plan that minimizes the cost to that agent, while while achieving.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Its goals.",
                    "label": 0
                },
                {
                    "sent": "And part of the motivation for doing this is when when we plan for a single agent, we can use single agent planner planners which we know are quite.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Efficient.",
                    "label": 0
                },
                {
                    "sent": "So the notation is we define the multi agent problem as tuple, where N is the set of agents.",
                    "label": 1
                },
                {
                    "sent": "We have a set of fluents an initial state.",
                    "label": 0
                },
                {
                    "sent": "Gold states for each agent, so the overall goal is to to to achieve the goals of all agents in the action.",
                    "label": 0
                },
                {
                    "sent": "Space is the cross product of the individual actions.",
                    "label": 1
                },
                {
                    "sent": "Sets of each agent a novel element?",
                    "label": 1
                },
                {
                    "sent": "Here is what we call an admissibility function, which I'll describe on another slide.",
                    "label": 0
                },
                {
                    "sent": "And each agent also has a cost function, which is a function from the Joint action space to the reels.",
                    "label": 0
                },
                {
                    "sent": "So I think to note here is that the cost to an agent might depend on what other agents are doing, not just what the what the agent itself is doing.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the goal, as usual, is to find a plan, which here is a sequence of joint actions to that takes you from initial state to.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Allstate.",
                    "label": 0
                },
                {
                    "sent": "The Fluence can be partitioned into private set for each agent which we call F1 to FN plus a set of public influence that we called F Pub.",
                    "label": 1
                },
                {
                    "sent": "So the idea is that the the fluids that are private to an agent are those that can only be affected by that agent while the set of public fluents are those that can be changed by all agents.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we do this, each action of an agent.",
                    "label": 1
                },
                {
                    "sent": "Anne has preconditions and effects only on the private Fluence of that agents and the set of public fluents.",
                    "label": 0
                },
                {
                    "sent": "And well, this can trivially be extended to to negative preconditions and effects.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the same thing is true about the goal.",
                    "label": 0
                },
                {
                    "sent": "The goal state of an agent is only defined on the on the private influence of that agent and the set of public.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fluents and the cost of a plan is just the sum of the costs of the of the joint actions of the the joint actions of the of the plan.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The admissibility function represents concurrency constraints between individual actions, so that for example in.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so we just say that a joint action A is part of the plan if it Maps to 1 using the admissibility function.",
                    "label": 1
                },
                {
                    "sent": "If it Maps to zero, it's not part of the of the problem.",
                    "label": 0
                },
                {
                    "sent": "So for example, in logistics you know 22 agents could not pick up the the same package at the same time, so we can just prohibit that those joint actions by by this function.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there are two reasons for doing this.",
                    "label": 0
                },
                {
                    "sent": "One is that even though the Joint action space is exponential in and, we can usually represent this function PSI in in a more compact way an.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And another motivation is that our approach requires quickly checking whether a joint action is part of the of the problem or not, which we can then do with this function.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just a quick example of what a multiagent planning problem looks like here.",
                    "label": 0
                },
                {
                    "sent": "There are three agents represent and they are in a network, so the network nodes are here.",
                    "label": 1
                },
                {
                    "sent": "The intersections of the lines we have to send some package across this network, so there the initial states are represented by the numbers of the agents and the gold states are represented by the symbols that match each agent.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So a joint action is consists of each agent taking one of its actions.",
                    "label": 0
                },
                {
                    "sent": "In this example, we take the cost of an action to an agent to be the number of other agents that send the package across the same link at the same time.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And eventually, well, the agents will find the joint plan.",
                    "label": 1
                },
                {
                    "sent": "This these circles here highlights links where the cost is suboptimal in the sense that more than one agent is sending a package across that link at the same time step.",
                    "label": 1
                },
                {
                    "sent": "It's not just that they send it, send the the package through that link, they have to do it at the same time step as well for the cost to increase.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I'm going to define the best response planning problem.",
                    "label": 0
                },
                {
                    "sent": "So so our approach assumes that there already exists a joint plan for solving the problem of length.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Day.",
                    "label": 0
                },
                {
                    "sent": "So what we will do is give an agent.",
                    "label": 1
                },
                {
                    "sent": "I will define a single agent planning problem with costs where the Fluence of that problem is just the private Fluence of that agent.",
                    "label": 0
                },
                {
                    "sent": "Plus while union the public fluents union set of time fluens that will just be kept.",
                    "label": 0
                },
                {
                    "sent": "We used to keep track of the position we are in the plan.",
                    "label": 0
                },
                {
                    "sent": "The initial state is the the the original initial state projected onto the new set of fluents Union and Time Zero, and the goal state is the individual goal of that agent.",
                    "label": 0
                },
                {
                    "sent": "Union time K. So we have to take the.",
                    "label": 0
                },
                {
                    "sent": "Then the additional fluents here require us to to move from time zero to time.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Kate.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                },
                {
                    "sent": "How do we define actions of our problem?",
                    "label": 0
                },
                {
                    "sent": "Well, each joint action of the of the existing plan.",
                    "label": 1
                },
                {
                    "sent": "Can be written as a pair where the first element of the pair is the reaction of Agent I and the 2nd the 2nd element is the action of all other agents except I.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what we will do is for each possible action of Agent I we will replace the agent ice action in the joint action with that that new action.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If that action is, if that's new, joint action is is admissible, it is part of the problem.",
                    "label": 0
                },
                {
                    "sent": "We add a new action to the action space where the preconditions and effects are just projected onto the new set of fluents.",
                    "label": 0
                },
                {
                    "sent": "And the the the time, the way that I'm fluents are added here is to show to simulate that we move one time step forward when we when we take an action.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is that by enforcing this we we assure that the position of the actions of other agents in the plan remain the same because the first joint action has to happen from time zero to time one, the second one from time one to time two etc until we reach time K. And finally, the cost of the action.",
                    "label": 0
                },
                {
                    "sent": "Here is the cost of the action to Agent I, because Agent I is trying to to minimize it its own.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it might happen that after this K time, after executing this K actions agent, I might still not have achieved its goal.",
                    "label": 0
                },
                {
                    "sent": "So to take this into account, we also add know up actions for each agent that can be applied when the agent is done with all.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other actions.",
                    "label": 0
                },
                {
                    "sent": "So for each possible action of Agent I, we add joint actions that are basically that action for Agent I and nothing, no up action for all other.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Guidance and we add the uh, corresponding action to our new action space.",
                    "label": 0
                },
                {
                    "sent": "In the exact same way as before, the only difference now is that the precondition is that all the other key actions have to have already been been applied, so we can only take these actions once.",
                    "label": 0
                },
                {
                    "sent": "The other actions are done.",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now once we have set this up now the process of doing best response planning is very simple.",
                    "label": 0
                },
                {
                    "sent": "We just solve this this BRP problem using an optimal planner.",
                    "label": 1
                },
                {
                    "sent": "We replaced the actions for Agent I with the new actions with the actions of the new plan and we iterate over all agents until no agent can can improve its cost anymore.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so just in the in the example, well too.",
                    "label": 0
                },
                {
                    "sent": "Resolve these these suboptimal cases.",
                    "label": 0
                },
                {
                    "sent": "We now let Agent one plan while keeping the actions of agents two and three fixed so it.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One might come up with a plan that looks like this.",
                    "label": 0
                },
                {
                    "sent": "So now the at no point does Agent I, agent one send a package across a link that coincides with another agent, and then we do the same thing for ages.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two and and eventually no agent can improve its cost by by choosing a cheaper plan.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in general what the process we have described is not guaranteed to converge, but we will define a subclass of multi agent problems for which it does converge.",
                    "label": 0
                },
                {
                    "sent": "So to do this will borrow some concepts from game theory.",
                    "label": 0
                },
                {
                    "sent": "In particular, there's something in game theory called the Congestion Games where.",
                    "label": 1
                },
                {
                    "sent": "Just as before, we have a set of agents.",
                    "label": 1
                },
                {
                    "sent": "We have a set of resources.",
                    "label": 0
                },
                {
                    "sent": "And actions consist in selecting a nonempty subset of the resources, so it's there's no planning here.",
                    "label": 1
                },
                {
                    "sent": "This is the one shot action.",
                    "label": 0
                },
                {
                    "sent": "You just select a nonempty subset of the resources and there's a cost function associated with each resource.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the utility of an agent depends on for each resource that it chose, how many other agents shows that same resource and weighted by this.",
                    "label": 0
                },
                {
                    "sent": "This cost function for that resource.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to make this idea a little more interesting from a planning perspective, we decided to extend this idea of congestion game just by.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I'm I'm already on the next slide, so so first of all, I'm just going to describe why this is interesting from our perspective.",
                    "label": 0
                },
                {
                    "sent": "Well, given the congestion game, you can define a potential function.",
                    "label": 1
                },
                {
                    "sent": "It does not really matter here what the potential function is.",
                    "label": 0
                },
                {
                    "sent": "What does matter is that the potential function has the following property given 2 joint actions and that only differ in the.",
                    "label": 0
                },
                {
                    "sent": "Action choice of Agent I.",
                    "label": 0
                },
                {
                    "sent": "The difference in the difference in utility to Agent I is the same as the difference in potential.",
                    "label": 0
                },
                {
                    "sent": "So if an agent chooses another action that increases its utility by some amount, the potential increases by an equivalent amount.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's very so, so games that satisfy this property are called potential games, and it's very easy to prove that this type of iterative best response convert this in this case to Nash equilibrium.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so like I already said, we decided to extend this idea to to make it a bit more interesting from a planning perspective.",
                    "label": 0
                },
                {
                    "sent": "The only thing we did that was that to introduce an extra term in the utility function of an agent that only depends on the action choice of that agent.",
                    "label": 0
                },
                {
                    "sent": "So so so the UI prime here.",
                    "label": 0
                },
                {
                    "sent": "The new term DI AI only depends on AI.",
                    "label": 0
                },
                {
                    "sent": "In other words, the action shows that agent I made.",
                    "label": 0
                },
                {
                    "sent": "And well, if you make this extension, you can just define a new.",
                    "label": 1
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Central function and you can show that the the potential game property still holds.",
                    "label": 0
                },
                {
                    "sent": "Yes, just by doing the the map.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So so now, given this we we define a class of of multiagent planning problems that we call congestion planning problems.",
                    "label": 0
                },
                {
                    "sent": "First, let R be a set of resources, each with an associated cost function.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A congestion planning problem is simply a standard multiagent planning problem, as as we defined before augmented with this set of resources and the cost function for each resource.",
                    "label": 1
                },
                {
                    "sent": "Such that each action of an agent is associated with a possibly empty subset of resources.",
                    "label": 1
                },
                {
                    "sent": "And the following additional restric.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oceans hold the set of public fluences is empty.",
                    "label": 0
                },
                {
                    "sent": "The all joint actions are part of the problem.",
                    "label": 0
                },
                {
                    "sent": "The cost function of Agent I is some function here which is essentially what it is, is the negation of the utility function of the extended utility function from the previous slide.",
                    "label": 1
                },
                {
                    "sent": "So we just sweep.",
                    "label": 0
                },
                {
                    "sent": "I mean when to maximize utility you want to minimize cost and no up action uses no resource and incurs no cost.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so for this new class of problems it's quite easy to prove the following that the best.",
                    "label": 0
                },
                {
                    "sent": "I mean this iterative best response planning process that we have described is guaranteed to converge to in this case to the Nash equilibrium.",
                    "label": 1
                },
                {
                    "sent": "So to do this the we define a potential function not just for individual actions, but for whole plans.",
                    "label": 0
                },
                {
                    "sent": "And we show that the difference in utility between two plans that were the plans only differ on the actions of Agent I.",
                    "label": 1
                },
                {
                    "sent": "Is equal exactly to the difference in cost to that agent of that plan.",
                    "label": 0
                },
                {
                    "sent": "So that's exactly the same property as we had before.",
                    "label": 0
                },
                {
                    "sent": "It's only that now we have a sequence of actions instead of individual actions.",
                    "label": 0
                },
                {
                    "sent": "So what we get is in fact that the congestion planning problem is is a planning is a potential game where actions can change their plans to improve their costs, and this potential will increase by an equivalent amount.",
                    "label": 0
                },
                {
                    "sent": "So, so this is guaranteed to converge.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in fact, the example I have been showing you is an example of such a planning problem where there are no.",
                    "label": 0
                },
                {
                    "sent": "The only fluids are the fluids describing the current position of a package.",
                    "label": 1
                },
                {
                    "sent": "And the resources are the links in the network and the costs associated with the link is the number of agents sending packages across that link simultaneously.",
                    "label": 1
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to to test this idea, we we ran two sets of experiments.",
                    "label": 1
                },
                {
                    "sent": "In the first set of experiments we used the network example from the that I have been showing you just varying the number of nodes and agents.",
                    "label": 1
                },
                {
                    "sent": "In the second set, we run experiments in problems from the the planning competition with multi agent flavor.",
                    "label": 0
                },
                {
                    "sent": "For each.",
                    "label": 0
                },
                {
                    "sent": "Best response planning problem.",
                    "label": 0
                },
                {
                    "sent": "We generate the corresponding problem in PDL which involves some technical details which I will not get into here and we used a HSP to to solve these these problems optimally.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the network example, we have already seen that it's an example of a congestion planning problem, so finding the initial plan here is easy.",
                    "label": 1
                },
                {
                    "sent": "We can just let each individual agent plan as if no other agents are using links simultaneously.",
                    "label": 1
                },
                {
                    "sent": "And by the previous theorem here, the best response planning process is guaranteed to converge.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to.",
                    "label": 0
                },
                {
                    "sent": "Well, the results are fairly as expected, just to give an idea of how large problems we can solve if we have a network with 100 nodes in 100 agents, the best response planning converges in 10 minutes, so we can scale.",
                    "label": 0
                },
                {
                    "sent": "2 problems that are significantly larger than than than what have been done so far in multiagent planning.",
                    "label": 0
                },
                {
                    "sent": "Of course, that that the reason we can do this is that these problems are very weakly coupled, that there are no fluents that shared by agents.",
                    "label": 0
                },
                {
                    "sent": "The only interaction between agents is the cost that depends on other agents doing something simelton.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Leslie in the IPC domains.",
                    "label": 0
                },
                {
                    "sent": "We used multi agent problems from from.",
                    "label": 0
                },
                {
                    "sent": "From logistics Rovers and satellite.",
                    "label": 1
                },
                {
                    "sent": "And to generate an initial plan, we used the this ESP planner by Nissim ET al.",
                    "label": 1
                },
                {
                    "sent": "And in Rovers, HSP failed to solve our beer VRP problems.",
                    "label": 1
                },
                {
                    "sent": "So we also use Llama to to to generate suboptimal plans.",
                    "label": 0
                },
                {
                    "sent": "So even though La Maison is a satisficing planner, we wanted to see what.",
                    "label": 0
                },
                {
                    "sent": "Whether in fact the whole process would converge in this case, so the motivation for these experiments were not really too.",
                    "label": 0
                },
                {
                    "sent": "UH-2 as to to test whether sorry the motivation for this was basically to test whether beer P would converge at all, in spite of lack of such guarantees, and to see what how long it would take, what it will converge to it.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cetera.",
                    "label": 0
                },
                {
                    "sent": "So so the result.",
                    "label": 0
                },
                {
                    "sent": "Here are the results for for for the problems in in a few of the logistics Rovers and satellite problems.",
                    "label": 0
                },
                {
                    "sent": "The Thi columnist this that I'm the the C columnists.",
                    "label": 0
                },
                {
                    "sent": "The cost the total cost where we just defined cost as the total number of of actions of each of the agents, non idle actions and M Mr is the makespan.",
                    "label": 0
                },
                {
                    "sent": "And for the VR, optimal is VR using HSP and VR.",
                    "label": 0
                },
                {
                    "sent": "Satisficing is VR using Llama and the I column is the number of iterations it took two to converge to two.",
                    "label": 0
                },
                {
                    "sent": "To stable equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So what we can see is that in logistics VRP is quite fast compared to finding the initial plan.",
                    "label": 0
                },
                {
                    "sent": "The reason is that the branching factor is not so large.",
                    "label": 0
                },
                {
                    "sent": "But there getting coming up with and there's a lot of interaction between agents because there are lot of of public fluents in terms of packages that are in different locations.",
                    "label": 0
                },
                {
                    "sent": "We believe that the recent llama fails here.",
                    "label": 0
                },
                {
                    "sent": "Is that the problem is very heavily constrained that the agent might have to satisfy a precondition at a given time that another agent is using.",
                    "label": 0
                },
                {
                    "sent": "And basically you have to find an optimal plan to to foreign agents to be able to do that, so so llama in many cases reports that the problem is unsolvable even though it in fact is.",
                    "label": 0
                },
                {
                    "sent": "In Rovers I actually discovered yes to couple of days ago that the reason that HSV fails is that for you.",
                    "label": 0
                },
                {
                    "sent": "For those of you who are familiar with Rovers, the strips translation introduces some redundant effects such as not Channel 3 and channel free and HSV can't deal with him if you remove those.",
                    "label": 0
                },
                {
                    "sent": "Those redundant effects HP can infected with him, but I didn't have time to run experiments using this.",
                    "label": 0
                },
                {
                    "sent": "Well, what you can note here in general is that the the cost of the initial plan was already in fact very good, so so it was not improved by appana lot.",
                    "label": 0
                },
                {
                    "sent": "Bye bye best response planning.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, best response planning in many cases is able to improve on them expand.",
                    "label": 0
                },
                {
                    "sent": "In other words, it can find the shorter.",
                    "label": 0
                },
                {
                    "sent": "Shorter joint plans than the initial plan.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude that we have presented a single agent approach to multiagent planning, where each agent optimizes its own cost.",
                    "label": 1
                },
                {
                    "sent": "In other words, it acts in a bit in a way in a selfish way to to find its best cost.",
                    "label": 1
                },
                {
                    "sent": "For congestion planning problems, this process is guaranteed to converge and and even though there are no convergence guarantees in the IPC domains we tested, in practice the process does converge in these problems too.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For future works.",
                    "label": 0
                },
                {
                    "sent": "We'd like to determine convergence guarantees for larger classes of multiagent planning problems.",
                    "label": 1
                },
                {
                    "sent": "Also, of course the the main limitation of this work is that you need an initial plan to start, so to find ways to apply single agent planning to come up with with initial plans.",
                    "label": 1
                },
                {
                    "sent": "And also to try cases for which public goals are not shared by by agents, which is an assumption we made in this work.",
                    "label": 0
                },
                {
                    "sent": "And as any translation based approach basically sit back and roll our thumbs and hope that that single agent planning that that we that other researchers develop better single agent planners.",
                    "label": 0
                },
                {
                    "sent": "I mean we might even see such planners now in in the next session.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "In the first problem that you showed, there are many optimal plans, so agents can accommodate other agents and still find an optimal plan in the total cost remains pretty good, but in some problems because of the interaction they may they may not be able to execute optimal plans, and then there may be some nontrivial tradeoffs.",
                    "label": 0
                },
                {
                    "sent": "And what can you say about the?",
                    "label": 0
                },
                {
                    "sent": "The equilibrium that you find how far it may be from the best quality measured, let's say by some.",
                    "label": 0
                },
                {
                    "sent": "So it depends very heavily on the in the network example the there's just one single best equilibrium, so it will always always.",
                    "label": 0
                },
                {
                    "sent": "Any congestion planning problem?",
                    "label": 0
                },
                {
                    "sent": "There's only one best equilibrium in in a general.",
                    "label": 0
                },
                {
                    "sent": "In the general case, it depends heavily on the initial plan, so different initial plans of course will.",
                    "label": 0
                },
                {
                    "sent": "Will lead to different equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So in most of these, in this approach you you assume that all other agent plans are always successful, 'cause you share costs.",
                    "label": 0
                },
                {
                    "sent": "So you must assume that every other agent does exactly what it what he says he wants to do.",
                    "label": 0
                },
                {
                    "sent": "So how would you?",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "Think about uncertainty in this situation.",
                    "label": 0
                },
                {
                    "sent": "What kind of approach would you?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think it's best to deal with here.",
                    "label": 0
                },
                {
                    "sent": "So it's not really a problem.",
                    "label": 0
                },
                {
                    "sent": "We have thought so much about, but.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's true.",
                    "label": 0
                },
                {
                    "sent": "Our approach requires other agents plans to be fixed.",
                    "label": 0
                },
                {
                    "sent": "If you cannot trust the other agents then.",
                    "label": 0
                },
                {
                    "sent": "Probably it becomes difficult to guarantee that you can even reach your satisfy your own goal, right?",
                    "label": 0
                },
                {
                    "sent": "Because so so.",
                    "label": 0
                },
                {
                    "sent": "I don't really have a good answer.",
                    "label": 0
                },
                {
                    "sent": "Any thoughts of that, how well?",
                    "label": 0
                },
                {
                    "sent": "This will be our last question is so why why Nash equilibrium?",
                    "label": 0
                },
                {
                    "sent": "Yeah, well, it's a.",
                    "label": 0
                },
                {
                    "sent": "It's one well established criteria for equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So so to prove here that we converge to something.",
                    "label": 0
                },
                {
                    "sent": "It's just a well established criteria that that that.",
                    "label": 0
                },
                {
                    "sent": "That we used to to prove convergence, but of course I don't rule out that there are other criteria in fact.",
                    "label": 0
                },
                {
                    "sent": "We have already been thinking about trying to prove convergence for for more general classes of planning problems in that case.",
                    "label": 0
                },
                {
                    "sent": "And we have some positive results that are not Nash equilibrium, so so I would say that there are we are not restraining ourselves to just magically appear here.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        }
    }
}