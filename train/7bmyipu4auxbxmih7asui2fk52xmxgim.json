{
    "id": "7bmyipu4auxbxmih7asui2fk52xmxgim",
    "title": "Learning relational bayesian classifiers from RDF data",
    "info": {
        "author": [
            "Harris Lin, Iowa State University"
        ],
        "published": "Nov. 25, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Semantic Web->RDF - Resource Description Framework",
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/iswc2011_lin_rdfdata/",
    "segmentation": [
        [
            "So like to also thank our sponsors.",
            "Set in safe and I will stay in University.",
            "The Graduate College for sponsoring this group.",
            "OK, so first of all let let me allow me to be a little brave and start with."
        ],
        [
            "Some grand vision of what we share.",
            "So suppose you have some.",
            "Your company have some data, so your patient health records and you manage to make some links to this down linking open data codes and you might want to ask the question of what's the probability of this patient getting Alzheimer's disease within the next 10 years.",
            "So what you can do with this is like if this probability is high from the prediction.",
            "You might want to monitor start monitoring this patients in what what often happens is that the prevention of this disease is much more cost effective than than."
        ],
        [
            "The treatment of disease.",
            "So this is an area of disease prevention of far more example.",
            "You might also have some customer purchase history.",
            "Say and you want to ask the question with the customer.",
            "See will buy this product.",
            "So this is kind of a link prediction which is similar to our previous talk as well.",
            "So we can also we call it a product recommendation.",
            "So we are working with this kind of prediction tasks.",
            "Building predictive model from."
        ],
        [
            "An RDF data.",
            "You might also have for like government data.",
            "For example, you want to predict the crime rates in some particular region and not might help with absolutely planning.",
            "So if you know that certain region has a higher crime rate, you might locate more police resources to to that region.",
            "OK. You never hear me now.",
            "Dismissed.",
            "Like this?",
            "OK, thank you."
        ],
        [
            "OK, so with this I prepare to 1 slide executive summary of what what's coming up in my talk so we don't have to understand everything here is just to get you an idea of what being covered in in this work.",
            "So we show how to learn a relational Bayesian classifiers from RDF data.",
            "So in a setting where the data can be accessed only through statistical queries against the sparkle endpoint and also demonstrated advantages of this query approach.",
            "Against the one that requires direct access to RDF data anyway, so it is stab.",
            "Lish is common conditions under where the model can be updated incrementally in response to the underlying data, and also show settings where the attributes of interest are normal priority.",
            "So we do some calling and selections on top of this RDF data."
        ],
        [
            "So.",
            "I already started with some."
        ],
        [
            "Motivations here, so I continue the motivation so we you know, we have a rapidly growing RDF data that so that officer opportunity for this learning and predictive models.",
            "So what we're looking at in our work is a classifier.",
            "So building classifiers on RDF data and we want to use this resulting models to guide for the decisions for the application domains so.",
            "So the machine learning here offers one of the most cost effective approaches to building this prediction models.",
            "So in a very higher level we have data and we have this machine learning algorithm and we produced this learning model and we will use this learning model to make further decisions in applications.",
            "So with RDF data the this area, called US statistical relational learning, which over certain very natural starting point for designing algorithms for this RDF data.",
            "Because RDF data which this links.",
            "Have this relational nature, so we chose one of the simple models in this area and try to.",
            "Build."
        ],
        [
            "Modeling in our setting.",
            "So, um.",
            "There's still the work that boots models multi if data is still relatively sparse.",
            "One of the top, perhaps the most closest, somewhere in spirit.",
            "If ours is work by Kiefer, and it's covering in 2008, so they extended the sparkle query with with more construct that builds try to pull that data mining model so they have like a create mining model statement and also predict statements so they extended the sparkle query just like what Microsoft has in there.",
            "SQL Database and they also used the relational Bayesian classifiers in other work by transferring without online.",
            "So they represent a tripling RDF.",
            "Data is 1 one value in the Boolean matrix and they used techniques such as LDA to complete the metrics there for the prediction.",
            "Another worker, recent work in 2011 Yummy SWC so Paisa and his Co authors.",
            "They used kernel based support vector machines, so it's also part of the relational learning literature, so they used kernel based support vector machines to build a kernel machine.",
            "Over this RDF data.",
            "OK, so having a."
        ],
        [
            "That we observe some current limitations or existing works.",
            "Basically the current method.",
            "Assume that the learning algorithm assume that direct access to the underlying data.",
            "OK, so this learning algorithm has direct access, usually in the on the same local machine and we ask the question."
        ],
        [
            "Um?",
            "Weather this this assumption does not monopoly hold off during practice.",
            "So first of all, the idea of stores may not always provide data dumps, so one example might be coming from US streaming social network data where they only provide updates of their data in in form in the form of like a sparkle query interface.",
            "Also, there might be access constraints that prevent the access student direct this underlying RDF data.",
            "For example, the patient health records I showed you earlier and also Doctor Penland's keynote speaker highlight this this problem as well, and there's also a vision called Linked Coast data we did in the code workshops on Sunday, which also has highlighted this access constraints.",
            "OK, so.",
            "In here we cannot access the underlying data, but we may be able to access some of the statistics of this RDF data of the query, so I'll show you later what I mean by that.",
            "We also have an automotive version where there might be a bandwidth constraints that limits the ability to transfer data from a remote RDF store to local site.",
            "One example is censored data, so sensitive data we have.",
            "Device that usually works on battery, so it's it's it consumes a lot less electricity for the local computations, but it costs a lot of electricity to transmit their data to some hub.",
            "So this is the case in the sensor data and possibly in the case for the linked sensor data, and this is in workshop as well.",
            "This I'm not too sure about this, but this is possible that may happen here.",
            "So.",
            "Again, even if we have to direct access to RDF data, the learning algorithms that resumes in memory access to the data may not cope with these huge message datasets.",
            "Datasets that are too large to fit in memory.",
            "So against this background, we want to have some approaches for learning from RDF data without direct access to RDF data in settings like with, the data can be accessed only through statistical queries.",
            "For example an here.",
            "We want to say like, for example against a sparkle carry endpoint or in general it can be provide any kind of query interface.",
            "OK, so this is the the main problems we want to address here."
        ],
        [
            "Now I will show you a brief overview of our approach of how to edges."
        ],
        [
            "This problems now we have used kind of extended this this approach from one of operators is courage and discovered this in our group.",
            "So we used statistical query based learning framework.",
            "So here we are learning algorithm only interacts with this inquiry interface and the current interface works with the RDF data on the remote machine.",
            "So the local local machine learning algorithms.",
            "Has been separated into two components, one that poses this statistical query to the query interface and then gathers the results and use the result to build predictive model and the output is the still the classifier here.",
            "So this is a general approach we want to follow that address this problem of learning learning predictive models without directly access to data.",
            "But we still allow like.",
            "Terry interface.",
            "So we see this work.",
            "We built our relational learning classifier that interacts with Sparkle 1.1 access point here, so I'll show you in the following slides."
        ],
        [
            "So just to to over an overview of what a relational Bayesian classifier is.",
            "It's one of the relational variant of simple Bayesian classifiers.",
            "There's a good book by Little Tool in 2007 and 9 statistical relational learning that covers the on this area.",
            "So a simple classifiers the recap.",
            "This issue, like each attribute in the data instance.",
            "It has a single value from the domain of corresponding random variable and also they assume that the data attributes are conditionally independent given the class label.",
            "So relational Bayesian classifier X extension of that.",
            "So now each data attribute text value that could be a multi sets of elements chosen former domain of the random variable and now it still assume that the multi sets that notice setting is independent given the cost label.",
            "So I won't go into the details, but this is the formula that our PC trying to boot.",
            "So in the learning phase.",
            "That obviously will estimate the probabilities here.",
            "And, um, to classify.",
            "And you label that use this formula that maximizes the likelihood of the class."
        ],
        [
            "Thanks so I'll go through a quick example.",
            "So suppose we take an example from a movie domain.",
            "So this RDF schema.",
            "Here we have movie costs.",
            "An extra costs an agenda cause Anna movie has a property opening receipts of integer and so on and so forth.",
            "And we our goal say we want to predict whether the movie receives more than like $2,000,000 in its opening week.",
            "So it's the opening recap.",
            "Opening receipts property and will specify a target class in this case is the cost of movies and we also specify our target attributes.",
            "In this case, is the opening receipts with the integer property and say we have two attributes.",
            "The first one would be like, for example in his actor and the year of birth.",
            "The number to integer of the airports and say we have a second attributes like in his actor, any gender there so long to build an RBC from given this inputs."
        ],
        [
            "Anne, given that if schema suppose we have, this instance is supposed to have two movies inception in Titanic they have an exception.",
            "Have two actors, Ellen and Leonardo.",
            "And so this is an instance.",
            "An example instance we want to learn a PC from.",
            "So what obviously this is first of all, influence this RDF data into a table which contains this multi sets of attributes.",
            "So if you see an exception you get the opening receipts as one column and so on.",
            "Target attributes and heck sector.",
            "Your processor boots will contain the sets of two years.",
            "And has actually gender would contain a set of two.",
            "Gingers to female and male, so that reduces in down into a table of multisets, column in from there.",
            "Obviously it does the aggregation and counts an estimates the parameters from there.",
            "OK, so in our work we have kind of doing this flattening on the fly so we post the sparkle queries that directly gets our accounts and aggregations from the RDF data.",
            "So we are not going through this writing approach which is post it's able to be able to post a sparkle queries that estimates our parameters.",
            "So this is the general overview of what's what's the solution is look like."
        ],
        [
            "OK.",
            "So again, we have obviously learned here that only interacts with Sparkle 1.1.",
            "An unknown here is that we are using the aggregate function in down cycle 1.1 a lot.",
            "We rely heavily on the aggregate queries support by Sparkle 1.1 there so that was impossible.",
            "You know, Sparkle 1.0.",
            "OK, so this is a.",
            "Implementation of that IBC using following our approach of.",
            "Learning project models through statistical queries OK?"
        ],
        [
            "So I'll show."
        ],
        [
            "First of all, the first experiments that some conference we found intuition of why this is better.",
            "So we compare the we color communication complexity.",
            "So we compared the.",
            "The size of the Curry.",
            "Posting the results against one that would require direct access to data.",
            "In that case I'm learning algorithm will need to download retrieve the entire datasets too, it's it's it's local machine, so with this with this blue blue line it does not depend the query approach our query approaches does not depends on the size of the data data set, so that stays constant, whereas the.",
            "When we want to download all the RDF datasets, that's increases overtime.",
            "So in this case we measure the size.",
            "Data dumping RDF XML format in that already exists exceeds the size when there are more than three movies thing that it says so in the conference with our intuition that the cost of retrieving the stats statistiques needed for learning is much smaller than the console.",
            "Retrieving the entire data set.",
            "So we only know that Model T details of this data set preparation.",
            "You can have a look at our paper."
        ],
        [
            "OK. No, I present you some extensions of this basic approach to this settings.",
            "So the 1st of."
        ],
        [
            "All is extension of how we handle that.",
            "Order Wonder RDF stores updated overtime in the second second level is when the attributes of interest is not normal priority.",
            "OK, so we will do some crawling."
        ],
        [
            "Selection, so first of all very quickly.",
            "What here idea is that when the underlying data is updated overtime, so the question is, can we update the learner by only querying querying the data that's being updated?",
            "So can we update it?",
            "Can we update the model without working through all the entire datasets before?",
            "OK, so in this case the learner will get previously constructed RPC learner an you want to query only the updated portion of the datasets and it will update or update sooner so that we were using a definition updatable definitions that say that.",
            "And that's that's that says whether this.",
            "This is even possible in this case.",
            "So in the paper was shown that in general this is not possible, but in some restricted cases we can update when the we say that every update is we updated the underlying data sets are clean sewer cleaning senses.",
            "When when the New Triples has very minimal connection, swift.",
            "Old data set so you can see it in the paper for the precise definition.",
            "I won't go through the details here so."
        ],
        [
            "Want to spend some time on the other extension?",
            "We did so in here.",
            "We have to analyze the problem where to actually build something of interest are not known a priori.",
            "So in this case the learner is going only given the target class and target attributes.",
            "Launch would predict and the learner would need to interact with the query interface to crawl and select the attribute of interest here."
        ],
        [
            "So we use the census data in our experiments to show you.",
            "So this is a schema of the US Census by October in this top state region and uses a property to subdivide population stats democratics.",
            "So if you follow the path here, population male and age 20 to 29, four thousand.",
            "That means there are 4000 people.",
            "That satisfies the conditions on the path, so we are using this this.",
            "Since its data converted it to RDF.",
            "Typeerror"
        ],
        [
            "So we combined with one of the data golf datasets that records the violent crime rates for each state.",
            "So our question in this case is we want to ask whether the States violent crime rate is over 400 per 100,000 population and we did a cross validation of 52 US states into 13 folds an we.",
            "Compare the two approaches of how we have different strategy of how to crawl in selects features.",
            "So this is just a result of accuracy of classifier over the number of attributes the crawler is allowed to grow.",
            "So if we go the crawlers vary from 5 attribute to GND attributes and you see the accuracy gets higher if you get more attribute.",
            "So one of the interesting things in this experiment is actually we don't know we're not.",
            "We don't give the the attribute of interest a priority to."
        ],
        [
            "So we can get we treat from the learner actually the top attribute selected by by this strategy.",
            "So this is the top six attribute selected pilot strategy in predicting weather states violent crime rate.",
            "So the 1st three are kind of obvious with the number of weapon families or number of household.",
            "If you have more population than you have generally have more customers.",
            "But if you get lower you get to see a more finer.",
            "Um, knowledge there.",
            "So if you have a one person household, we've female householder that has a higher correlation with the crime rate and also you get down there.",
            "You could you have two or more person households with family house order with no husband present.",
            "You can also a high correlation.",
            "So this is just attributes found out by this crawling and selecting from distances."
        ],
        [
            "In our city.",
            "OK, and to conclude we have almost conclusion we have to provide their open source implementation.",
            "So welcome to download an inode experiment.",
            "State assets are online as well.",
            "So."
        ],
        [
            "So."
        ],
        [
            "Just um, just to summarize with the contributions.",
            "So we proposed a statistical query based approach to learning relational classifiers from RDF data, and this is applicable to settings where the data making access through our status will query through this sparkle endpoint and this is confirmed by the experiment that is far more bandwidth efficient than the alternative style.",
            "Assume direct access to data where in this case you need to download or the entire data set and it's possible to generalize this to other statistical relational learning algorithm as well.",
            "So we have just chosen a very simple, very end of this stage relational learning algorithm.",
            "And we also extended the settings to where the RDF store is updated.",
            "Overtime we provide some theoretical updatable results there, and we also did generalize the problem to where the attributes of interest unknown powdery."
        ],
        [
            "Ken and some future work involves looking at whether we can adapt other learning algorithms to boots in this settings.",
            "And also we can consider extending extensions to approach where we learn models from multiple distributed RDF data stores.",
            "So what we have shown you only assumes we're learning from a single or RDF data, so this remote, but it's only from a single data source, so.",
            "What's going on in the daddy of create multiple sources sessions right now?",
            "In other thing, other room is some really closely related to this extension, OK?",
            "And.",
            "So."
        ],
        [
            "So.",
            "That will conclude my talk.",
            "Thank you very much.",
            "Couple of questions.",
            "One is do you see many?",
            "RDF status stores that have only statistical access but not full access.",
            "So I can.",
            "I certainly understand the possibility about it, but even it's unlikely to.",
            "I mean that a hospital or clinical care would make even the statistical access available to data.",
            "Just a question.",
            "If you know anything.",
            "I just like to know, right?",
            "So one of one of the possibilities here is the social network data.",
            "With update I keep updating overtime so they might not provide the data dumps OK.",
            "So in case of the patients health records, that might be more motivated from this privacy constraints.",
            "So because of privacy then the Lord says we cannot release the data right?",
            "But then to overcome these problems, we may guarantee privacy through this statistical query.",
            "So because the statistics are, I would say less sensitive than I understand the possibilities.",
            "I just want to know whether in reality there's something like that or not.",
            "There, no, not yet.",
            "Not anymore miss offline.",
            "Practical challenges the question other question was in your census experiments.",
            "I saw the results being 4055 to 7580 unless it is really about 75 or 7050 doesn't mean anything right?",
            "That the accuracy of 50% doesn't mean anything.",
            "That means it's a random thing, right?",
            "So only when you are going about 7580 that accuracy is meaningful, right?",
            "Is my understanding correct?",
            "Well, it's my might be correct, yes, but it's going."
        ],
        [
            "She.",
            "It's going close to 80 in telling the truth, but the idea of this experiment is actually to show that you can do this crawling a selection.",
            "Unless RDF data, so the lower accuracies might be attributed to the simple simplicity assumption by this relational Bayesian classifier.",
            "So we are not.",
            "We are not.",
            "Claiming that these are busy is good for everybody because we chose this just because it's a simple one to formulate and to see how it's going on with this settings.",
            "So as I said in the future, we may consider other more services.",
            "I think.",
            "I think it's an important question.",
            "Obviously doesn't seem at this point all that great here.",
            "I mean 50% is even meaning there's actually random, so.",
            "Uh.",
            "That said, do you expect others to really be better, or is just guesswork?",
            "I respect other that that looks at this.",
            "The other models that looks at this census datasets that may that may look at you may look at more finer regions other than a state.",
            "So in here we consider like 52 states so that instances are not not really not much to hear.",
            "OK, so not not be positive interests but good talk, thank you.",
            "Did question on this so the Accuracy Cove right is not monotonically increasing.",
            "It varies quite a bit up and down.",
            "Do you have a sense?",
            "Any comments on how you can find the optimal accuracy?",
            "Because intuitively as you add more attributes and your selection for attributes is based on information gain or something, it should help, so that's not the case here.",
            "In principle you should help, but the thing with this simple two strategies is that.",
            "Many attributes may provide the same information to to with respect to our target attributes.",
            "So if you, if it chooses many of the attributes that have the same that contributes the same for measuring that we actually degrades the accuracy.",
            "So that might be a reason of why it's going up and down.",
            "Well, you just answered actually my question, but I have another question.",
            "Since you know you know if more attributes selected but there there sort of dependent with each other, right?",
            "So quality will be radios.",
            "Have you thought of choosing a different classifier such as conditional random field CRF?",
            "That's you know that doesn't require other features to be independent.",
            "I will sort of doing something like right now.",
            "We haven't looked at that here, but.",
            "That might be a good option to to to look at this and actually the other.",
            "Approach to solving this is actually to to use the classifier built to actually to to judge whether this attributes is meaningful to your car.",
            "Safer, so you actually actually use your current existing classifier to see whether this attributes count contributes more information into your existing one.",
            "So we have tried.",
            "We tried that here, so that's another option to to look at this, But again, this is a really.",
            "The examiner here the main purpose of this actually to show you can do this to select selection and crawling, so of course they're mushrooms to expand here.",
            "Yes, I have a question or a couple of questions related to the way you compare this to just working on the raw data you have to measure.",
            "I think it's called communication complexity or something like that.",
            "Yes, right?",
            "And it was interesting that you only looked at the size on disk as opposed to actually anytime, so there might be communication, latency's, query processing, latency's and things.",
            "Did you consider that at all?",
            "Uh."
        ],
        [
            "We look at that in one time, but we've got datasets we are using here that the query processing is actually very fast, so we didn't actually compare that with the time, time, dimensions and one related query, or one question is how many queries do you need?",
            "Typically, given a particular intelligence and tell you some size in would require how many of these aggregation queries to do that, because obviously the more queries you have to issue the longer time it will take to.",
            "Gathered statistics, yes, so the number of queries thank you.",
            "Better question.",
            "So the number of queries depends on."
        ],
        [
            "Several things.",
            "If one of the key things is actually the number of attributes you specify, so the more attributes we have, the more queries we need to fire.",
            "And also it depends on the number of values.",
            "In a domain of available of how much, how much their gender has 2 two value in so many, it depends on how much.",
            "A number of domestic.",
            "So if you want to see I have some pickup slide of kind of queries we are."
        ],
        [
            "Closing so this is the kind of fun sparkle queries about posing.",
            "So in the first of all, in the first one it says you want to its account of the cost of some costs with some certain attributes.",
            "And here with the next one we have aggregation with some min Max on average and which aggregates this with some certain costs and we have some certain actions so.",
            "So we have analyzed complexity in terms of mass in public counters complicity in that paper.",
            "So can we get that in detail?",
            "OK, thank you.",
            "I'm afraid we don't have time for more questions.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So like to also thank our sponsors.",
                    "label": 0
                },
                {
                    "sent": "Set in safe and I will stay in University.",
                    "label": 0
                },
                {
                    "sent": "The Graduate College for sponsoring this group.",
                    "label": 0
                },
                {
                    "sent": "OK, so first of all let let me allow me to be a little brave and start with.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some grand vision of what we share.",
                    "label": 0
                },
                {
                    "sent": "So suppose you have some.",
                    "label": 0
                },
                {
                    "sent": "Your company have some data, so your patient health records and you manage to make some links to this down linking open data codes and you might want to ask the question of what's the probability of this patient getting Alzheimer's disease within the next 10 years.",
                    "label": 1
                },
                {
                    "sent": "So what you can do with this is like if this probability is high from the prediction.",
                    "label": 0
                },
                {
                    "sent": "You might want to monitor start monitoring this patients in what what often happens is that the prevention of this disease is much more cost effective than than.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The treatment of disease.",
                    "label": 0
                },
                {
                    "sent": "So this is an area of disease prevention of far more example.",
                    "label": 0
                },
                {
                    "sent": "You might also have some customer purchase history.",
                    "label": 1
                },
                {
                    "sent": "Say and you want to ask the question with the customer.",
                    "label": 0
                },
                {
                    "sent": "See will buy this product.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of a link prediction which is similar to our previous talk as well.",
                    "label": 1
                },
                {
                    "sent": "So we can also we call it a product recommendation.",
                    "label": 0
                },
                {
                    "sent": "So we are working with this kind of prediction tasks.",
                    "label": 0
                },
                {
                    "sent": "Building predictive model from.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An RDF data.",
                    "label": 0
                },
                {
                    "sent": "You might also have for like government data.",
                    "label": 0
                },
                {
                    "sent": "For example, you want to predict the crime rates in some particular region and not might help with absolutely planning.",
                    "label": 0
                },
                {
                    "sent": "So if you know that certain region has a higher crime rate, you might locate more police resources to to that region.",
                    "label": 0
                },
                {
                    "sent": "OK. You never hear me now.",
                    "label": 0
                },
                {
                    "sent": "Dismissed.",
                    "label": 0
                },
                {
                    "sent": "Like this?",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so with this I prepare to 1 slide executive summary of what what's coming up in my talk so we don't have to understand everything here is just to get you an idea of what being covered in in this work.",
                    "label": 0
                },
                {
                    "sent": "So we show how to learn a relational Bayesian classifiers from RDF data.",
                    "label": 1
                },
                {
                    "sent": "So in a setting where the data can be accessed only through statistical queries against the sparkle endpoint and also demonstrated advantages of this query approach.",
                    "label": 1
                },
                {
                    "sent": "Against the one that requires direct access to RDF data anyway, so it is stab.",
                    "label": 1
                },
                {
                    "sent": "Lish is common conditions under where the model can be updated incrementally in response to the underlying data, and also show settings where the attributes of interest are normal priority.",
                    "label": 0
                },
                {
                    "sent": "So we do some calling and selections on top of this RDF data.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I already started with some.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Motivations here, so I continue the motivation so we you know, we have a rapidly growing RDF data that so that officer opportunity for this learning and predictive models.",
                    "label": 0
                },
                {
                    "sent": "So what we're looking at in our work is a classifier.",
                    "label": 0
                },
                {
                    "sent": "So building classifiers on RDF data and we want to use this resulting models to guide for the decisions for the application domains so.",
                    "label": 1
                },
                {
                    "sent": "So the machine learning here offers one of the most cost effective approaches to building this prediction models.",
                    "label": 1
                },
                {
                    "sent": "So in a very higher level we have data and we have this machine learning algorithm and we produced this learning model and we will use this learning model to make further decisions in applications.",
                    "label": 0
                },
                {
                    "sent": "So with RDF data the this area, called US statistical relational learning, which over certain very natural starting point for designing algorithms for this RDF data.",
                    "label": 1
                },
                {
                    "sent": "Because RDF data which this links.",
                    "label": 0
                },
                {
                    "sent": "Have this relational nature, so we chose one of the simple models in this area and try to.",
                    "label": 0
                },
                {
                    "sent": "Build.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Modeling in our setting.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "There's still the work that boots models multi if data is still relatively sparse.",
                    "label": 0
                },
                {
                    "sent": "One of the top, perhaps the most closest, somewhere in spirit.",
                    "label": 0
                },
                {
                    "sent": "If ours is work by Kiefer, and it's covering in 2008, so they extended the sparkle query with with more construct that builds try to pull that data mining model so they have like a create mining model statement and also predict statements so they extended the sparkle query just like what Microsoft has in there.",
                    "label": 1
                },
                {
                    "sent": "SQL Database and they also used the relational Bayesian classifiers in other work by transferring without online.",
                    "label": 0
                },
                {
                    "sent": "So they represent a tripling RDF.",
                    "label": 1
                },
                {
                    "sent": "Data is 1 one value in the Boolean matrix and they used techniques such as LDA to complete the metrics there for the prediction.",
                    "label": 0
                },
                {
                    "sent": "Another worker, recent work in 2011 Yummy SWC so Paisa and his Co authors.",
                    "label": 1
                },
                {
                    "sent": "They used kernel based support vector machines, so it's also part of the relational learning literature, so they used kernel based support vector machines to build a kernel machine.",
                    "label": 0
                },
                {
                    "sent": "Over this RDF data.",
                    "label": 0
                },
                {
                    "sent": "OK, so having a.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we observe some current limitations or existing works.",
                    "label": 0
                },
                {
                    "sent": "Basically the current method.",
                    "label": 0
                },
                {
                    "sent": "Assume that the learning algorithm assume that direct access to the underlying data.",
                    "label": 1
                },
                {
                    "sent": "OK, so this learning algorithm has direct access, usually in the on the same local machine and we ask the question.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Weather this this assumption does not monopoly hold off during practice.",
                    "label": 0
                },
                {
                    "sent": "So first of all, the idea of stores may not always provide data dumps, so one example might be coming from US streaming social network data where they only provide updates of their data in in form in the form of like a sparkle query interface.",
                    "label": 0
                },
                {
                    "sent": "Also, there might be access constraints that prevent the access student direct this underlying RDF data.",
                    "label": 0
                },
                {
                    "sent": "For example, the patient health records I showed you earlier and also Doctor Penland's keynote speaker highlight this this problem as well, and there's also a vision called Linked Coast data we did in the code workshops on Sunday, which also has highlighted this access constraints.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "In here we cannot access the underlying data, but we may be able to access some of the statistics of this RDF data of the query, so I'll show you later what I mean by that.",
                    "label": 0
                },
                {
                    "sent": "We also have an automotive version where there might be a bandwidth constraints that limits the ability to transfer data from a remote RDF store to local site.",
                    "label": 1
                },
                {
                    "sent": "One example is censored data, so sensitive data we have.",
                    "label": 0
                },
                {
                    "sent": "Device that usually works on battery, so it's it's it consumes a lot less electricity for the local computations, but it costs a lot of electricity to transmit their data to some hub.",
                    "label": 0
                },
                {
                    "sent": "So this is the case in the sensor data and possibly in the case for the linked sensor data, and this is in workshop as well.",
                    "label": 0
                },
                {
                    "sent": "This I'm not too sure about this, but this is possible that may happen here.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "Again, even if we have to direct access to RDF data, the learning algorithms that resumes in memory access to the data may not cope with these huge message datasets.",
                    "label": 1
                },
                {
                    "sent": "Datasets that are too large to fit in memory.",
                    "label": 0
                },
                {
                    "sent": "So against this background, we want to have some approaches for learning from RDF data without direct access to RDF data in settings like with, the data can be accessed only through statistical queries.",
                    "label": 1
                },
                {
                    "sent": "For example an here.",
                    "label": 0
                },
                {
                    "sent": "We want to say like, for example against a sparkle carry endpoint or in general it can be provide any kind of query interface.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the the main problems we want to address here.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I will show you a brief overview of our approach of how to edges.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This problems now we have used kind of extended this this approach from one of operators is courage and discovered this in our group.",
                    "label": 0
                },
                {
                    "sent": "So we used statistical query based learning framework.",
                    "label": 1
                },
                {
                    "sent": "So here we are learning algorithm only interacts with this inquiry interface and the current interface works with the RDF data on the remote machine.",
                    "label": 1
                },
                {
                    "sent": "So the local local machine learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "Has been separated into two components, one that poses this statistical query to the query interface and then gathers the results and use the result to build predictive model and the output is the still the classifier here.",
                    "label": 0
                },
                {
                    "sent": "So this is a general approach we want to follow that address this problem of learning learning predictive models without directly access to data.",
                    "label": 0
                },
                {
                    "sent": "But we still allow like.",
                    "label": 0
                },
                {
                    "sent": "Terry interface.",
                    "label": 0
                },
                {
                    "sent": "So we see this work.",
                    "label": 0
                },
                {
                    "sent": "We built our relational learning classifier that interacts with Sparkle 1.1 access point here, so I'll show you in the following slides.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to to over an overview of what a relational Bayesian classifier is.",
                    "label": 1
                },
                {
                    "sent": "It's one of the relational variant of simple Bayesian classifiers.",
                    "label": 1
                },
                {
                    "sent": "There's a good book by Little Tool in 2007 and 9 statistical relational learning that covers the on this area.",
                    "label": 0
                },
                {
                    "sent": "So a simple classifiers the recap.",
                    "label": 1
                },
                {
                    "sent": "This issue, like each attribute in the data instance.",
                    "label": 0
                },
                {
                    "sent": "It has a single value from the domain of corresponding random variable and also they assume that the data attributes are conditionally independent given the class label.",
                    "label": 1
                },
                {
                    "sent": "So relational Bayesian classifier X extension of that.",
                    "label": 0
                },
                {
                    "sent": "So now each data attribute text value that could be a multi sets of elements chosen former domain of the random variable and now it still assume that the multi sets that notice setting is independent given the cost label.",
                    "label": 0
                },
                {
                    "sent": "So I won't go into the details, but this is the formula that our PC trying to boot.",
                    "label": 0
                },
                {
                    "sent": "So in the learning phase.",
                    "label": 0
                },
                {
                    "sent": "That obviously will estimate the probabilities here.",
                    "label": 0
                },
                {
                    "sent": "And, um, to classify.",
                    "label": 0
                },
                {
                    "sent": "And you label that use this formula that maximizes the likelihood of the class.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thanks so I'll go through a quick example.",
                    "label": 0
                },
                {
                    "sent": "So suppose we take an example from a movie domain.",
                    "label": 1
                },
                {
                    "sent": "So this RDF schema.",
                    "label": 0
                },
                {
                    "sent": "Here we have movie costs.",
                    "label": 0
                },
                {
                    "sent": "An extra costs an agenda cause Anna movie has a property opening receipts of integer and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "And we our goal say we want to predict whether the movie receives more than like $2,000,000 in its opening week.",
                    "label": 1
                },
                {
                    "sent": "So it's the opening recap.",
                    "label": 0
                },
                {
                    "sent": "Opening receipts property and will specify a target class in this case is the cost of movies and we also specify our target attributes.",
                    "label": 0
                },
                {
                    "sent": "In this case, is the opening receipts with the integer property and say we have two attributes.",
                    "label": 0
                },
                {
                    "sent": "The first one would be like, for example in his actor and the year of birth.",
                    "label": 0
                },
                {
                    "sent": "The number to integer of the airports and say we have a second attributes like in his actor, any gender there so long to build an RBC from given this inputs.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne, given that if schema suppose we have, this instance is supposed to have two movies inception in Titanic they have an exception.",
                    "label": 0
                },
                {
                    "sent": "Have two actors, Ellen and Leonardo.",
                    "label": 0
                },
                {
                    "sent": "And so this is an instance.",
                    "label": 0
                },
                {
                    "sent": "An example instance we want to learn a PC from.",
                    "label": 0
                },
                {
                    "sent": "So what obviously this is first of all, influence this RDF data into a table which contains this multi sets of attributes.",
                    "label": 0
                },
                {
                    "sent": "So if you see an exception you get the opening receipts as one column and so on.",
                    "label": 0
                },
                {
                    "sent": "Target attributes and heck sector.",
                    "label": 0
                },
                {
                    "sent": "Your processor boots will contain the sets of two years.",
                    "label": 0
                },
                {
                    "sent": "And has actually gender would contain a set of two.",
                    "label": 0
                },
                {
                    "sent": "Gingers to female and male, so that reduces in down into a table of multisets, column in from there.",
                    "label": 0
                },
                {
                    "sent": "Obviously it does the aggregation and counts an estimates the parameters from there.",
                    "label": 0
                },
                {
                    "sent": "OK, so in our work we have kind of doing this flattening on the fly so we post the sparkle queries that directly gets our accounts and aggregations from the RDF data.",
                    "label": 0
                },
                {
                    "sent": "So we are not going through this writing approach which is post it's able to be able to post a sparkle queries that estimates our parameters.",
                    "label": 0
                },
                {
                    "sent": "So this is the general overview of what's what's the solution is look like.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So again, we have obviously learned here that only interacts with Sparkle 1.1.",
                    "label": 0
                },
                {
                    "sent": "An unknown here is that we are using the aggregate function in down cycle 1.1 a lot.",
                    "label": 0
                },
                {
                    "sent": "We rely heavily on the aggregate queries support by Sparkle 1.1 there so that was impossible.",
                    "label": 1
                },
                {
                    "sent": "You know, Sparkle 1.0.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a.",
                    "label": 0
                },
                {
                    "sent": "Implementation of that IBC using following our approach of.",
                    "label": 1
                },
                {
                    "sent": "Learning project models through statistical queries OK?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll show.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First of all, the first experiments that some conference we found intuition of why this is better.",
                    "label": 0
                },
                {
                    "sent": "So we compare the we color communication complexity.",
                    "label": 0
                },
                {
                    "sent": "So we compared the.",
                    "label": 0
                },
                {
                    "sent": "The size of the Curry.",
                    "label": 0
                },
                {
                    "sent": "Posting the results against one that would require direct access to data.",
                    "label": 1
                },
                {
                    "sent": "In that case I'm learning algorithm will need to download retrieve the entire datasets too, it's it's it's local machine, so with this with this blue blue line it does not depend the query approach our query approaches does not depends on the size of the data data set, so that stays constant, whereas the.",
                    "label": 0
                },
                {
                    "sent": "When we want to download all the RDF datasets, that's increases overtime.",
                    "label": 0
                },
                {
                    "sent": "So in this case we measure the size.",
                    "label": 1
                },
                {
                    "sent": "Data dumping RDF XML format in that already exists exceeds the size when there are more than three movies thing that it says so in the conference with our intuition that the cost of retrieving the stats statistiques needed for learning is much smaller than the console.",
                    "label": 1
                },
                {
                    "sent": "Retrieving the entire data set.",
                    "label": 0
                },
                {
                    "sent": "So we only know that Model T details of this data set preparation.",
                    "label": 0
                },
                {
                    "sent": "You can have a look at our paper.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. No, I present you some extensions of this basic approach to this settings.",
                    "label": 0
                },
                {
                    "sent": "So the 1st of.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All is extension of how we handle that.",
                    "label": 0
                },
                {
                    "sent": "Order Wonder RDF stores updated overtime in the second second level is when the attributes of interest is not normal priority.",
                    "label": 1
                },
                {
                    "sent": "OK, so we will do some crawling.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Selection, so first of all very quickly.",
                    "label": 0
                },
                {
                    "sent": "What here idea is that when the underlying data is updated overtime, so the question is, can we update the learner by only querying querying the data that's being updated?",
                    "label": 1
                },
                {
                    "sent": "So can we update it?",
                    "label": 0
                },
                {
                    "sent": "Can we update the model without working through all the entire datasets before?",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case the learner will get previously constructed RPC learner an you want to query only the updated portion of the datasets and it will update or update sooner so that we were using a definition updatable definitions that say that.",
                    "label": 1
                },
                {
                    "sent": "And that's that's that says whether this.",
                    "label": 0
                },
                {
                    "sent": "This is even possible in this case.",
                    "label": 0
                },
                {
                    "sent": "So in the paper was shown that in general this is not possible, but in some restricted cases we can update when the we say that every update is we updated the underlying data sets are clean sewer cleaning senses.",
                    "label": 1
                },
                {
                    "sent": "When when the New Triples has very minimal connection, swift.",
                    "label": 1
                },
                {
                    "sent": "Old data set so you can see it in the paper for the precise definition.",
                    "label": 0
                },
                {
                    "sent": "I won't go through the details here so.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Want to spend some time on the other extension?",
                    "label": 0
                },
                {
                    "sent": "We did so in here.",
                    "label": 1
                },
                {
                    "sent": "We have to analyze the problem where to actually build something of interest are not known a priori.",
                    "label": 1
                },
                {
                    "sent": "So in this case the learner is going only given the target class and target attributes.",
                    "label": 0
                },
                {
                    "sent": "Launch would predict and the learner would need to interact with the query interface to crawl and select the attribute of interest here.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we use the census data in our experiments to show you.",
                    "label": 0
                },
                {
                    "sent": "So this is a schema of the US Census by October in this top state region and uses a property to subdivide population stats democratics.",
                    "label": 0
                },
                {
                    "sent": "So if you follow the path here, population male and age 20 to 29, four thousand.",
                    "label": 0
                },
                {
                    "sent": "That means there are 4000 people.",
                    "label": 0
                },
                {
                    "sent": "That satisfies the conditions on the path, so we are using this this.",
                    "label": 0
                },
                {
                    "sent": "Since its data converted it to RDF.",
                    "label": 0
                },
                {
                    "sent": "Typeerror",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we combined with one of the data golf datasets that records the violent crime rates for each state.",
                    "label": 0
                },
                {
                    "sent": "So our question in this case is we want to ask whether the States violent crime rate is over 400 per 100,000 population and we did a cross validation of 52 US states into 13 folds an we.",
                    "label": 1
                },
                {
                    "sent": "Compare the two approaches of how we have different strategy of how to crawl in selects features.",
                    "label": 0
                },
                {
                    "sent": "So this is just a result of accuracy of classifier over the number of attributes the crawler is allowed to grow.",
                    "label": 0
                },
                {
                    "sent": "So if we go the crawlers vary from 5 attribute to GND attributes and you see the accuracy gets higher if you get more attribute.",
                    "label": 0
                },
                {
                    "sent": "So one of the interesting things in this experiment is actually we don't know we're not.",
                    "label": 0
                },
                {
                    "sent": "We don't give the the attribute of interest a priority to.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can get we treat from the learner actually the top attribute selected by by this strategy.",
                    "label": 0
                },
                {
                    "sent": "So this is the top six attribute selected pilot strategy in predicting weather states violent crime rate.",
                    "label": 0
                },
                {
                    "sent": "So the 1st three are kind of obvious with the number of weapon families or number of household.",
                    "label": 0
                },
                {
                    "sent": "If you have more population than you have generally have more customers.",
                    "label": 0
                },
                {
                    "sent": "But if you get lower you get to see a more finer.",
                    "label": 0
                },
                {
                    "sent": "Um, knowledge there.",
                    "label": 0
                },
                {
                    "sent": "So if you have a one person household, we've female householder that has a higher correlation with the crime rate and also you get down there.",
                    "label": 0
                },
                {
                    "sent": "You could you have two or more person households with family house order with no husband present.",
                    "label": 0
                },
                {
                    "sent": "You can also a high correlation.",
                    "label": 0
                },
                {
                    "sent": "So this is just attributes found out by this crawling and selecting from distances.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In our city.",
                    "label": 0
                },
                {
                    "sent": "OK, and to conclude we have almost conclusion we have to provide their open source implementation.",
                    "label": 1
                },
                {
                    "sent": "So welcome to download an inode experiment.",
                    "label": 0
                },
                {
                    "sent": "State assets are online as well.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just um, just to summarize with the contributions.",
                    "label": 0
                },
                {
                    "sent": "So we proposed a statistical query based approach to learning relational classifiers from RDF data, and this is applicable to settings where the data making access through our status will query through this sparkle endpoint and this is confirmed by the experiment that is far more bandwidth efficient than the alternative style.",
                    "label": 1
                },
                {
                    "sent": "Assume direct access to data where in this case you need to download or the entire data set and it's possible to generalize this to other statistical relational learning algorithm as well.",
                    "label": 1
                },
                {
                    "sent": "So we have just chosen a very simple, very end of this stage relational learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "And we also extended the settings to where the RDF store is updated.",
                    "label": 0
                },
                {
                    "sent": "Overtime we provide some theoretical updatable results there, and we also did generalize the problem to where the attributes of interest unknown powdery.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ken and some future work involves looking at whether we can adapt other learning algorithms to boots in this settings.",
                    "label": 0
                },
                {
                    "sent": "And also we can consider extending extensions to approach where we learn models from multiple distributed RDF data stores.",
                    "label": 1
                },
                {
                    "sent": "So what we have shown you only assumes we're learning from a single or RDF data, so this remote, but it's only from a single data source, so.",
                    "label": 0
                },
                {
                    "sent": "What's going on in the daddy of create multiple sources sessions right now?",
                    "label": 0
                },
                {
                    "sent": "In other thing, other room is some really closely related to this extension, OK?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That will conclude my talk.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Couple of questions.",
                    "label": 0
                },
                {
                    "sent": "One is do you see many?",
                    "label": 0
                },
                {
                    "sent": "RDF status stores that have only statistical access but not full access.",
                    "label": 0
                },
                {
                    "sent": "So I can.",
                    "label": 0
                },
                {
                    "sent": "I certainly understand the possibility about it, but even it's unlikely to.",
                    "label": 0
                },
                {
                    "sent": "I mean that a hospital or clinical care would make even the statistical access available to data.",
                    "label": 0
                },
                {
                    "sent": "Just a question.",
                    "label": 0
                },
                {
                    "sent": "If you know anything.",
                    "label": 0
                },
                {
                    "sent": "I just like to know, right?",
                    "label": 0
                },
                {
                    "sent": "So one of one of the possibilities here is the social network data.",
                    "label": 0
                },
                {
                    "sent": "With update I keep updating overtime so they might not provide the data dumps OK.",
                    "label": 0
                },
                {
                    "sent": "So in case of the patients health records, that might be more motivated from this privacy constraints.",
                    "label": 0
                },
                {
                    "sent": "So because of privacy then the Lord says we cannot release the data right?",
                    "label": 0
                },
                {
                    "sent": "But then to overcome these problems, we may guarantee privacy through this statistical query.",
                    "label": 0
                },
                {
                    "sent": "So because the statistics are, I would say less sensitive than I understand the possibilities.",
                    "label": 0
                },
                {
                    "sent": "I just want to know whether in reality there's something like that or not.",
                    "label": 0
                },
                {
                    "sent": "There, no, not yet.",
                    "label": 0
                },
                {
                    "sent": "Not anymore miss offline.",
                    "label": 0
                },
                {
                    "sent": "Practical challenges the question other question was in your census experiments.",
                    "label": 0
                },
                {
                    "sent": "I saw the results being 4055 to 7580 unless it is really about 75 or 7050 doesn't mean anything right?",
                    "label": 0
                },
                {
                    "sent": "That the accuracy of 50% doesn't mean anything.",
                    "label": 0
                },
                {
                    "sent": "That means it's a random thing, right?",
                    "label": 0
                },
                {
                    "sent": "So only when you are going about 7580 that accuracy is meaningful, right?",
                    "label": 0
                },
                {
                    "sent": "Is my understanding correct?",
                    "label": 0
                },
                {
                    "sent": "Well, it's my might be correct, yes, but it's going.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "She.",
                    "label": 0
                },
                {
                    "sent": "It's going close to 80 in telling the truth, but the idea of this experiment is actually to show that you can do this crawling a selection.",
                    "label": 0
                },
                {
                    "sent": "Unless RDF data, so the lower accuracies might be attributed to the simple simplicity assumption by this relational Bayesian classifier.",
                    "label": 0
                },
                {
                    "sent": "So we are not.",
                    "label": 0
                },
                {
                    "sent": "We are not.",
                    "label": 0
                },
                {
                    "sent": "Claiming that these are busy is good for everybody because we chose this just because it's a simple one to formulate and to see how it's going on with this settings.",
                    "label": 0
                },
                {
                    "sent": "So as I said in the future, we may consider other more services.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "I think it's an important question.",
                    "label": 0
                },
                {
                    "sent": "Obviously doesn't seem at this point all that great here.",
                    "label": 0
                },
                {
                    "sent": "I mean 50% is even meaning there's actually random, so.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "That said, do you expect others to really be better, or is just guesswork?",
                    "label": 0
                },
                {
                    "sent": "I respect other that that looks at this.",
                    "label": 0
                },
                {
                    "sent": "The other models that looks at this census datasets that may that may look at you may look at more finer regions other than a state.",
                    "label": 0
                },
                {
                    "sent": "So in here we consider like 52 states so that instances are not not really not much to hear.",
                    "label": 0
                },
                {
                    "sent": "OK, so not not be positive interests but good talk, thank you.",
                    "label": 0
                },
                {
                    "sent": "Did question on this so the Accuracy Cove right is not monotonically increasing.",
                    "label": 0
                },
                {
                    "sent": "It varies quite a bit up and down.",
                    "label": 0
                },
                {
                    "sent": "Do you have a sense?",
                    "label": 0
                },
                {
                    "sent": "Any comments on how you can find the optimal accuracy?",
                    "label": 0
                },
                {
                    "sent": "Because intuitively as you add more attributes and your selection for attributes is based on information gain or something, it should help, so that's not the case here.",
                    "label": 0
                },
                {
                    "sent": "In principle you should help, but the thing with this simple two strategies is that.",
                    "label": 0
                },
                {
                    "sent": "Many attributes may provide the same information to to with respect to our target attributes.",
                    "label": 0
                },
                {
                    "sent": "So if you, if it chooses many of the attributes that have the same that contributes the same for measuring that we actually degrades the accuracy.",
                    "label": 0
                },
                {
                    "sent": "So that might be a reason of why it's going up and down.",
                    "label": 0
                },
                {
                    "sent": "Well, you just answered actually my question, but I have another question.",
                    "label": 0
                },
                {
                    "sent": "Since you know you know if more attributes selected but there there sort of dependent with each other, right?",
                    "label": 0
                },
                {
                    "sent": "So quality will be radios.",
                    "label": 0
                },
                {
                    "sent": "Have you thought of choosing a different classifier such as conditional random field CRF?",
                    "label": 0
                },
                {
                    "sent": "That's you know that doesn't require other features to be independent.",
                    "label": 0
                },
                {
                    "sent": "I will sort of doing something like right now.",
                    "label": 0
                },
                {
                    "sent": "We haven't looked at that here, but.",
                    "label": 0
                },
                {
                    "sent": "That might be a good option to to to look at this and actually the other.",
                    "label": 0
                },
                {
                    "sent": "Approach to solving this is actually to to use the classifier built to actually to to judge whether this attributes is meaningful to your car.",
                    "label": 0
                },
                {
                    "sent": "Safer, so you actually actually use your current existing classifier to see whether this attributes count contributes more information into your existing one.",
                    "label": 0
                },
                {
                    "sent": "So we have tried.",
                    "label": 0
                },
                {
                    "sent": "We tried that here, so that's another option to to look at this, But again, this is a really.",
                    "label": 0
                },
                {
                    "sent": "The examiner here the main purpose of this actually to show you can do this to select selection and crawling, so of course they're mushrooms to expand here.",
                    "label": 0
                },
                {
                    "sent": "Yes, I have a question or a couple of questions related to the way you compare this to just working on the raw data you have to measure.",
                    "label": 0
                },
                {
                    "sent": "I think it's called communication complexity or something like that.",
                    "label": 0
                },
                {
                    "sent": "Yes, right?",
                    "label": 0
                },
                {
                    "sent": "And it was interesting that you only looked at the size on disk as opposed to actually anytime, so there might be communication, latency's, query processing, latency's and things.",
                    "label": 0
                },
                {
                    "sent": "Did you consider that at all?",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We look at that in one time, but we've got datasets we are using here that the query processing is actually very fast, so we didn't actually compare that with the time, time, dimensions and one related query, or one question is how many queries do you need?",
                    "label": 0
                },
                {
                    "sent": "Typically, given a particular intelligence and tell you some size in would require how many of these aggregation queries to do that, because obviously the more queries you have to issue the longer time it will take to.",
                    "label": 0
                },
                {
                    "sent": "Gathered statistics, yes, so the number of queries thank you.",
                    "label": 0
                },
                {
                    "sent": "Better question.",
                    "label": 0
                },
                {
                    "sent": "So the number of queries depends on.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Several things.",
                    "label": 0
                },
                {
                    "sent": "If one of the key things is actually the number of attributes you specify, so the more attributes we have, the more queries we need to fire.",
                    "label": 0
                },
                {
                    "sent": "And also it depends on the number of values.",
                    "label": 0
                },
                {
                    "sent": "In a domain of available of how much, how much their gender has 2 two value in so many, it depends on how much.",
                    "label": 0
                },
                {
                    "sent": "A number of domestic.",
                    "label": 0
                },
                {
                    "sent": "So if you want to see I have some pickup slide of kind of queries we are.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Closing so this is the kind of fun sparkle queries about posing.",
                    "label": 0
                },
                {
                    "sent": "So in the first of all, in the first one it says you want to its account of the cost of some costs with some certain attributes.",
                    "label": 0
                },
                {
                    "sent": "And here with the next one we have aggregation with some min Max on average and which aggregates this with some certain costs and we have some certain actions so.",
                    "label": 0
                },
                {
                    "sent": "So we have analyzed complexity in terms of mass in public counters complicity in that paper.",
                    "label": 0
                },
                {
                    "sent": "So can we get that in detail?",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "I'm afraid we don't have time for more questions.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}