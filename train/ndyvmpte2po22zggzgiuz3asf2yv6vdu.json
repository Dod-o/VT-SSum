{
    "id": "ndyvmpte2po22zggzgiuz3asf2yv6vdu",
    "title": "Querying Factorized Probabilistic Triple Databases",
    "info": {
        "author": [
            "Denis Krompa\u00df, LMU Institut f\u00fcr Informatik, Ludwig-Maximilians Universit\u00e4t"
        ],
        "published": "Dec. 19, 2014",
        "recorded": "October 2014",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2014_krompass_querying_factorized/",
    "segmentation": [
        [
            "So here a brief outline of my talk.",
            "So first I will give a short introduction."
        ],
        [
            "Move to talk to our topic and motivate our work.",
            "After that I will present how we actually construct apolistic knowledge basis or as a factorized holistic knowledge basis with rescar rescar, the 3rd order tensor factorization method especially developed for multi relational learning task on RDF triplestores.",
            "And after that I will present our major contribution, that is that you can actually do complex querying on the factorized representation.",
            "That goes clearly beyond just querying for ground triples."
        ],
        [
            "So while knowledge basis as contained in the linked open data cloud like DB Pedia, Freebase or Jago or commercial knowledge basis like knowledge graphs are actually large triple stores, you all know that they represent facts of the world in machine readable form and the triples.",
            "I have a subject predicate object structure which can be exploited in various applications as background knowledge or in search engine to provide.",
            "Additional information to the user, like as is done at Google.",
            "So on the other side, this knowledge base is not complete.",
            "In addition, they contain many false facts and most of the times we also don't have any information about uncertainty of triples.",
            "So there are only a few attempts that actually try to describe triple uncertainty, like Jago."
        ],
        [
            "Well, this is just a simple made up example graph I constructed consisting of two relation.",
            "It's deterministic and this somehow represents the situation in most of the cases.",
            "So in knowledge base is like a DB pedia and no information about uncertainty is available and we only see what is left after some pruning step.",
            "But of course we would like to remind the valuable information that is hidden in the uncertainties.",
            "So we can exploit it for example in querying with uncertainties.",
            "Where we can actually represent this holistic representation of a knowledge base As for example progress tick tuple, independent database?",
            "And for example, just taking this simple query on this example graph where we want to know if Jack knows someone who is a friend of Lucy and in the deterministic world we successfully pruned out all this information that could somehow give us an answer to this query, but in the holistic world we actually see that there is such a relation with quite high probability."
        ],
        [
            "So unfortunately we are confronted with situations that no information is present in the knowledge base and so we want somehow reintroduce the uncertainty in the into the knowledge base.",
            "Here we run into another problem 'cause if we approximate this probabilities with some model, we cannot explicitly represent all the uncertainty values or probabilities for every possible triple in the knowledge base.",
            "Since this knowledge base are.",
            "Quite large, so they contain millions of entities, thousands of relation and therefore we have interacted many possible triples for which we would have to represent uncertainty values.",
            "We solve this issue using this rescaled tensor factorization method, which actually with rescue we can actually construct compressed representation of this probabilistic representation, and given this compressed representation, we can simply reconstruct all this uncertainty values as needed.",
            "And then we can further exploit it for complex querying, so probabilistic complex querying.",
            "So there are two kinds of queries, unsafe queries which have mostly exponential time complexity and safe queries.",
            "On this work we only concentrate on safe queering which in theory has polynomial time complexity.",
            "But in combination that we have we're dealing now with a compressed representation.",
            "This can still lead to very long processing times and we will tackle this in our work."
        ],
        [
            "So here we show how we actually construct a probabilistic knowledge based out of a deterministic model one or the other factorized representation.",
            "So we are given some deterministic multi relational graph.",
            "We put it in an adjacency tensor in this attention to 10s or each frontal slice.",
            "Extra represents an adjacency matrix for each relation type.",
            "Then we factorize it in latent representation of entities which is represented by the effect on matrix A and.",
            "Latent representation of relation types, which is represented by the court ends, or are we usually gotten likelihood function for this.",
            "Of course, Bernoulli likelihood function would be much more appropriate, but the Gaussian likelihood function has much higher scalability properties than using the Mendeley one and two in order to get valid probabilities, we actually approximate proper Bernoulli probabilities with a signature transfer function.",
            "And at this point we are already able to policy query just foreground triples.",
            "So we could ask for example it's Jack, a friend of Lucy and we actually asking for a single edge in this graph and we simply take the latent representation of Jack out of the vector matrix.",
            "A is a latent representation of friend of relation type into latent presentation of Lucy.",
            "Do a vector matrix vector product then apply the signal transfer function to this value and get the probability.",
            "And."
        ],
        [
            "Just to give you some numbers who wears this?",
            "Compression works in a recent work of us.",
            "We showed that we were able to factorize type constraint DB pedia with only 225 million parameters and were able to successfully represent 1.6 billion 160 billion triples.",
            "So."
        ],
        [
            "So of course, then the approach would be now so we can reconstruct the probability values for each possible triple in the in the knowledge base, and native approach would be just, you know, construct probabilities as we need it and apply extension query relation Woods.",
            "These are rules that are used to evaluate a safe queries in the probabilistic database world, and then in this case we would just apply the independent project tool to resolve this extension quantifier.",
            "But when we have more complex queries like this one where we actually have two existential quantifiers which are nested, we run into a problem.",
            "Here we cause here we have nested loops and so quadratic runtime already.",
            "So and if you just imagine that we want to actually perform ranking task and we want to know this have an answer for every person in the database and then this complexity rises already to cubic.",
            "So what does it mean and?"
        ],
        [
            "So how fast is it?",
            "Just the naive approach here we used in extraction of DB pedia regarding the music domain and we actually ask what songs arrivals from the pop rock genre musical artists at half at contractors Solantic Records.",
            "And this query takes on the naive approach already 5 minutes.",
            "And in the second example, we actually have a nested extensional quantifier.",
            "Since we are asking for three record labels, not just one, and the runtime already rises to 10 minutes Annina following, I will show how we tackle this problem, and we actually able to bring this response time down to seconds.",
            "So how we?"
        ],
        [
            "With that so at this point I have to mention that we have already factorized deterministic knowledge base in the past and we are given the latent representation of entities and relation types and what we actually want to do is to avoid evaluating independent project words.",
            "So just a query before we have a nested independent project.",
            "He ran two existential quantifier which are nested.",
            "So first we exploit the initial deterministic knowledge base.",
            "So what we try to do is to construct a deterministic compound relation first.",
            "So from the deterministic knowledge base we extract the data for the relation nodes and soccer.",
            "In this example and construct a compound relation.",
            "No soccer player of.",
            "Then we exploit the latent representation of entities and from this we are able to request to construct a latent representation.",
            "Of the compound relation no soccer off, so that's how it works for you.",
            "For those that are familiar with the rest, can model.",
            "It will recognize the update here of the of the algorithm.",
            "So given the the latent representation of the compound relation, we actually able to derive uncertainty values for every possible triple in this compound relation.",
            "We plug this in the initial evaluation formula and therefore resolved the outer existential quantifier in this example."
        ],
        [
            "So how well is the quality of this approximation?",
            "So the good news is it works comparably well.",
            "Then the naive approach so green is compound relations and the blue one is the naive approach on both queries and.",
            "Here I have a more complex case where we."
        ],
        [
            "We have a more dramatic effect of this nested loop, and here we actually.",
            "This is a composition of the previous two queries, but instead of asking for record labels, we ask here for albums that start with T and of course in the DB Pedia knowledge base.",
            "There are a lot of albums that start with T and using the naive approach I actually stopped waiting after six hours for an answer, but using the compound relation I get a very good answer.",
            "After less than 4 seconds."
        ],
        [
            "So in summary, we showed that we can reintroduce uncertainty into a deterministic knowledge base using the reske tensor factorization model.",
            "Then we showed this was a major contribution that we, besides just reconstructing ground triples.",
            "We can go further and actually exploit this factorization for further querying.",
            "So in this case safe querying.",
            "And we also tackled the problem of independent project words, which often well if we have nested extension quantifiers which can lead to very long run times of the evaluation.",
            "And we showed that we can resolve this problem by exploiting instrinsic features of Rascal and by constructing compound relations.",
            "So thank you for attention and happy to ask you questions."
        ],
        [
            "Are you are you doing this for everything or you have a given query workload and then you know that you can create these compositions for given the query workload.",
            "So I mean the question is if?",
            "So we assume that we have given the query and we know of course which will so for which relations we are involved in the query.",
            "And based on this knowledge we select whether the relation types that we want to somehow combine in the.",
            "Well, in the compound relation and then use the deterministic knowledge base to do that, it answer your question, I'm not sure.",
            "How do you determine the optimal rank of the the matrix?",
            "How to factorization?",
            "Well.",
            "So, um.",
            "When we saw the factorization is done before hand, so this is nothing to do with the query itself.",
            "So for that we just do it as I would say.",
            "Usually we do it so we have given the deterministic knowledge base.",
            "We extract some subsample of this knowledge base, then do for example cross cross validation and then try to get the rank and of course the regularization parameters.",
            "And then after that we know the parameters we would vectorized complete knowledge base.",
            "Further questions.",
            "Let's thank the speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here a brief outline of my talk.",
                    "label": 0
                },
                {
                    "sent": "So first I will give a short introduction.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Move to talk to our topic and motivate our work.",
                    "label": 0
                },
                {
                    "sent": "After that I will present how we actually construct apolistic knowledge basis or as a factorized holistic knowledge basis with rescar rescar, the 3rd order tensor factorization method especially developed for multi relational learning task on RDF triplestores.",
                    "label": 0
                },
                {
                    "sent": "And after that I will present our major contribution, that is that you can actually do complex querying on the factorized representation.",
                    "label": 0
                },
                {
                    "sent": "That goes clearly beyond just querying for ground triples.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So while knowledge basis as contained in the linked open data cloud like DB Pedia, Freebase or Jago or commercial knowledge basis like knowledge graphs are actually large triple stores, you all know that they represent facts of the world in machine readable form and the triples.",
                    "label": 1
                },
                {
                    "sent": "I have a subject predicate object structure which can be exploited in various applications as background knowledge or in search engine to provide.",
                    "label": 0
                },
                {
                    "sent": "Additional information to the user, like as is done at Google.",
                    "label": 0
                },
                {
                    "sent": "So on the other side, this knowledge base is not complete.",
                    "label": 0
                },
                {
                    "sent": "In addition, they contain many false facts and most of the times we also don't have any information about uncertainty of triples.",
                    "label": 0
                },
                {
                    "sent": "So there are only a few attempts that actually try to describe triple uncertainty, like Jago.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, this is just a simple made up example graph I constructed consisting of two relation.",
                    "label": 0
                },
                {
                    "sent": "It's deterministic and this somehow represents the situation in most of the cases.",
                    "label": 0
                },
                {
                    "sent": "So in knowledge base is like a DB pedia and no information about uncertainty is available and we only see what is left after some pruning step.",
                    "label": 0
                },
                {
                    "sent": "But of course we would like to remind the valuable information that is hidden in the uncertainties.",
                    "label": 0
                },
                {
                    "sent": "So we can exploit it for example in querying with uncertainties.",
                    "label": 0
                },
                {
                    "sent": "Where we can actually represent this holistic representation of a knowledge base As for example progress tick tuple, independent database?",
                    "label": 0
                },
                {
                    "sent": "And for example, just taking this simple query on this example graph where we want to know if Jack knows someone who is a friend of Lucy and in the deterministic world we successfully pruned out all this information that could somehow give us an answer to this query, but in the holistic world we actually see that there is such a relation with quite high probability.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So unfortunately we are confronted with situations that no information is present in the knowledge base and so we want somehow reintroduce the uncertainty in the into the knowledge base.",
                    "label": 0
                },
                {
                    "sent": "Here we run into another problem 'cause if we approximate this probabilities with some model, we cannot explicitly represent all the uncertainty values or probabilities for every possible triple in the knowledge base.",
                    "label": 0
                },
                {
                    "sent": "Since this knowledge base are.",
                    "label": 0
                },
                {
                    "sent": "Quite large, so they contain millions of entities, thousands of relation and therefore we have interacted many possible triples for which we would have to represent uncertainty values.",
                    "label": 1
                },
                {
                    "sent": "We solve this issue using this rescaled tensor factorization method, which actually with rescue we can actually construct compressed representation of this probabilistic representation, and given this compressed representation, we can simply reconstruct all this uncertainty values as needed.",
                    "label": 1
                },
                {
                    "sent": "And then we can further exploit it for complex querying, so probabilistic complex querying.",
                    "label": 1
                },
                {
                    "sent": "So there are two kinds of queries, unsafe queries which have mostly exponential time complexity and safe queries.",
                    "label": 1
                },
                {
                    "sent": "On this work we only concentrate on safe queering which in theory has polynomial time complexity.",
                    "label": 0
                },
                {
                    "sent": "But in combination that we have we're dealing now with a compressed representation.",
                    "label": 1
                },
                {
                    "sent": "This can still lead to very long processing times and we will tackle this in our work.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here we show how we actually construct a probabilistic knowledge based out of a deterministic model one or the other factorized representation.",
                    "label": 0
                },
                {
                    "sent": "So we are given some deterministic multi relational graph.",
                    "label": 0
                },
                {
                    "sent": "We put it in an adjacency tensor in this attention to 10s or each frontal slice.",
                    "label": 0
                },
                {
                    "sent": "Extra represents an adjacency matrix for each relation type.",
                    "label": 0
                },
                {
                    "sent": "Then we factorize it in latent representation of entities which is represented by the effect on matrix A and.",
                    "label": 0
                },
                {
                    "sent": "Latent representation of relation types, which is represented by the court ends, or are we usually gotten likelihood function for this.",
                    "label": 0
                },
                {
                    "sent": "Of course, Bernoulli likelihood function would be much more appropriate, but the Gaussian likelihood function has much higher scalability properties than using the Mendeley one and two in order to get valid probabilities, we actually approximate proper Bernoulli probabilities with a signature transfer function.",
                    "label": 0
                },
                {
                    "sent": "And at this point we are already able to policy query just foreground triples.",
                    "label": 0
                },
                {
                    "sent": "So we could ask for example it's Jack, a friend of Lucy and we actually asking for a single edge in this graph and we simply take the latent representation of Jack out of the vector matrix.",
                    "label": 1
                },
                {
                    "sent": "A is a latent representation of friend of relation type into latent presentation of Lucy.",
                    "label": 0
                },
                {
                    "sent": "Do a vector matrix vector product then apply the signal transfer function to this value and get the probability.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to give you some numbers who wears this?",
                    "label": 0
                },
                {
                    "sent": "Compression works in a recent work of us.",
                    "label": 0
                },
                {
                    "sent": "We showed that we were able to factorize type constraint DB pedia with only 225 million parameters and were able to successfully represent 1.6 billion 160 billion triples.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So of course, then the approach would be now so we can reconstruct the probability values for each possible triple in the in the knowledge base, and native approach would be just, you know, construct probabilities as we need it and apply extension query relation Woods.",
                    "label": 0
                },
                {
                    "sent": "These are rules that are used to evaluate a safe queries in the probabilistic database world, and then in this case we would just apply the independent project tool to resolve this extension quantifier.",
                    "label": 0
                },
                {
                    "sent": "But when we have more complex queries like this one where we actually have two existential quantifiers which are nested, we run into a problem.",
                    "label": 0
                },
                {
                    "sent": "Here we cause here we have nested loops and so quadratic runtime already.",
                    "label": 0
                },
                {
                    "sent": "So and if you just imagine that we want to actually perform ranking task and we want to know this have an answer for every person in the database and then this complexity rises already to cubic.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean and?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how fast is it?",
                    "label": 0
                },
                {
                    "sent": "Just the naive approach here we used in extraction of DB pedia regarding the music domain and we actually ask what songs arrivals from the pop rock genre musical artists at half at contractors Solantic Records.",
                    "label": 0
                },
                {
                    "sent": "And this query takes on the naive approach already 5 minutes.",
                    "label": 0
                },
                {
                    "sent": "And in the second example, we actually have a nested extensional quantifier.",
                    "label": 0
                },
                {
                    "sent": "Since we are asking for three record labels, not just one, and the runtime already rises to 10 minutes Annina following, I will show how we tackle this problem, and we actually able to bring this response time down to seconds.",
                    "label": 0
                },
                {
                    "sent": "So how we?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With that so at this point I have to mention that we have already factorized deterministic knowledge base in the past and we are given the latent representation of entities and relation types and what we actually want to do is to avoid evaluating independent project words.",
                    "label": 0
                },
                {
                    "sent": "So just a query before we have a nested independent project.",
                    "label": 0
                },
                {
                    "sent": "He ran two existential quantifier which are nested.",
                    "label": 0
                },
                {
                    "sent": "So first we exploit the initial deterministic knowledge base.",
                    "label": 1
                },
                {
                    "sent": "So what we try to do is to construct a deterministic compound relation first.",
                    "label": 0
                },
                {
                    "sent": "So from the deterministic knowledge base we extract the data for the relation nodes and soccer.",
                    "label": 0
                },
                {
                    "sent": "In this example and construct a compound relation.",
                    "label": 0
                },
                {
                    "sent": "No soccer player of.",
                    "label": 0
                },
                {
                    "sent": "Then we exploit the latent representation of entities and from this we are able to request to construct a latent representation.",
                    "label": 0
                },
                {
                    "sent": "Of the compound relation no soccer off, so that's how it works for you.",
                    "label": 0
                },
                {
                    "sent": "For those that are familiar with the rest, can model.",
                    "label": 0
                },
                {
                    "sent": "It will recognize the update here of the of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So given the the latent representation of the compound relation, we actually able to derive uncertainty values for every possible triple in this compound relation.",
                    "label": 1
                },
                {
                    "sent": "We plug this in the initial evaluation formula and therefore resolved the outer existential quantifier in this example.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how well is the quality of this approximation?",
                    "label": 0
                },
                {
                    "sent": "So the good news is it works comparably well.",
                    "label": 0
                },
                {
                    "sent": "Then the naive approach so green is compound relations and the blue one is the naive approach on both queries and.",
                    "label": 0
                },
                {
                    "sent": "Here I have a more complex case where we.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a more dramatic effect of this nested loop, and here we actually.",
                    "label": 0
                },
                {
                    "sent": "This is a composition of the previous two queries, but instead of asking for record labels, we ask here for albums that start with T and of course in the DB Pedia knowledge base.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of albums that start with T and using the naive approach I actually stopped waiting after six hours for an answer, but using the compound relation I get a very good answer.",
                    "label": 0
                },
                {
                    "sent": "After less than 4 seconds.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in summary, we showed that we can reintroduce uncertainty into a deterministic knowledge base using the reske tensor factorization model.",
                    "label": 0
                },
                {
                    "sent": "Then we showed this was a major contribution that we, besides just reconstructing ground triples.",
                    "label": 0
                },
                {
                    "sent": "We can go further and actually exploit this factorization for further querying.",
                    "label": 0
                },
                {
                    "sent": "So in this case safe querying.",
                    "label": 0
                },
                {
                    "sent": "And we also tackled the problem of independent project words, which often well if we have nested extension quantifiers which can lead to very long run times of the evaluation.",
                    "label": 0
                },
                {
                    "sent": "And we showed that we can resolve this problem by exploiting instrinsic features of Rascal and by constructing compound relations.",
                    "label": 1
                },
                {
                    "sent": "So thank you for attention and happy to ask you questions.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are you are you doing this for everything or you have a given query workload and then you know that you can create these compositions for given the query workload.",
                    "label": 0
                },
                {
                    "sent": "So I mean the question is if?",
                    "label": 0
                },
                {
                    "sent": "So we assume that we have given the query and we know of course which will so for which relations we are involved in the query.",
                    "label": 0
                },
                {
                    "sent": "And based on this knowledge we select whether the relation types that we want to somehow combine in the.",
                    "label": 0
                },
                {
                    "sent": "Well, in the compound relation and then use the deterministic knowledge base to do that, it answer your question, I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "How do you determine the optimal rank of the the matrix?",
                    "label": 0
                },
                {
                    "sent": "How to factorization?",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "When we saw the factorization is done before hand, so this is nothing to do with the query itself.",
                    "label": 0
                },
                {
                    "sent": "So for that we just do it as I would say.",
                    "label": 0
                },
                {
                    "sent": "Usually we do it so we have given the deterministic knowledge base.",
                    "label": 0
                },
                {
                    "sent": "We extract some subsample of this knowledge base, then do for example cross cross validation and then try to get the rank and of course the regularization parameters.",
                    "label": 0
                },
                {
                    "sent": "And then after that we know the parameters we would vectorized complete knowledge base.",
                    "label": 0
                },
                {
                    "sent": "Further questions.",
                    "label": 0
                },
                {
                    "sent": "Let's thank the speaker.",
                    "label": 0
                }
            ]
        }
    }
}