{
    "id": "sjgajpxis4spsur6rsc7lsgtejuaw4ll",
    "title": "One Shot Similarity Metric Learning for Action Recognition",
    "info": {
        "author": [
            "Orit Kliper-Gross, Faculty of Mathematics and Computer Science, Weizmann Institute of Science"
        ],
        "published": "Oct. 17, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Supervised Learning"
        ]
    },
    "url": "http://videolectures.net/simbad2011_kliper_gross_recognition/",
    "segmentation": [
        [
            "So hi, my name is Derek little girl.",
            "Anne, I'm going to present this joint work with God, Hosner and your Wolf on one shot, similarity metric.",
            "Learning for action recognition.",
            "So to do some order."
        ],
        [
            "In this pipeline of this work, if not, I'm going to present, so I'm going to start by metric learning.",
            "Then I'm going to present the one shot similarity an in this work, where combining these two into a new method of one shot similarity metric learning in short, or SML.",
            "At the end of the talk I will show an application of this to action recognition, so I'm going to start by a short introduction to metric learning."
        ],
        [
            "So in the general.",
            "The general scenario of metric learning you're giving point you are given points in some space and you don't know the point labels.",
            "You only know similar and not similar constraints.",
            "The distance metric in this in this space is sometimes not relevant or not meaningful and not consistent with the constraints you are having.",
            "In the metric learning scenario, you're learning such projection matrix a such that in the news."
        ],
        [
            "Chase the distance will be meaningful and consistent with the constraints you are having, and you can easily perform tasks such as classification, clustering, retrieval, task, button cognition and more."
        ],
        [
            "The most common approach to metric learning learns the Euclidean distance in the projected space.",
            "It means that it lands a projection matrix a such that the points moved to the projected space there clearing distance will perform better and consistent with the constraint we're talking about.",
            "Um, this is equivalent to learning a melon.",
            "Obvious metrics in the original space, so algorithm usually do either learn a or M, so this is a bunch of work done on this subject.",
            "This is very huge literature on this."
        ],
        [
            "And recently there was a work by Nguan in Bay, which suggested learning cosine similarity, which means they suggest learning a projection matrix a such that the cosine similarity in the projected space will perform better, so they call it cosine similarity metric learning.",
            "In short CSML.",
            "And this is the score they're using into projective space.",
            "This work have inspired our work."
        ],
        [
            "And in this work we're trying to do.",
            "Watch out similarity metric learning, which optimize the one shot similarity score.",
            "In the projected space.",
            "So this will call one shot similarity metric learning ossm and we will also show an application of it to action recognition."
        ],
        [
            "So what is one shot similarity?",
            "So one shot similarity by by Wolf Hosner anti gun from my CV 09.",
            "Is a measure of similarity between two vectors.",
            "The input is the two vectors I&J and you're also given a set of background sample an.",
            "This samples are samples which you don't know the labels of, but you do know that the labels of the point in this set are different from both I&J.",
            "So how you're going to do that?",
            "You use one shot learning, which means classification with one positive example, and I'm now going to demonstrate how you're going to do that."
        ],
        [
            "So.",
            "Here are the two vectors imj which you want to calculate the similarity between them.",
            "You have this negative set an of background sample, and as I said before, you don't know anything about this set except at about the point in this step, except that they have different.",
            "They are labeled differently from both ING, so you do one shot learning twice first."
        ],
        [
            "You are looking at the vector I and the negative set N and you are looking for a model separating between this vector and the negative set.",
            "Then you use this model to classify J and use the score of the classification as score one.",
            "Then you do the opposite."
        ],
        [
            "Which means you are switching rules of ING.",
            "So you're taking J and the negative set you're looking for model separating these two and then he use it to classify."
        ],
        [
            "I.",
            "The classification score of I using this model is called to.",
            "The two side sided one shot similarity.",
            "Is given by an average of these two scores.",
            "Let's see some properties of this similar."
        ],
        [
            "The function.",
            "So first.",
            "One chip similarity is a meta similarity.",
            "It means you can use any classifier as an underlying classifier.",
            "Second, you don't need label training data, which means you don't know the classes labours.",
            "You only know that the classes their labors of the set N are different from boss inj and lost.",
            "It may be efficiently computed since this city.",
            "Statistical properties of the set and can be computed only once for all pairs inj and also when you compare I against many JS you only need to compute the statistical properties of N once."
        ],
        [
            "So once your similarity I've shown to Excel in tasks such as face recognition and document analysis, however, when you try to apply to action recognition, we got answer to spine result.",
            "So I'm now going to show how we applied one shot similarity metric learning."
        ],
        [
            "So what is it?",
            "So wanted similarity metric learning?",
            "You have this setting in the original space where they want your similarity score is gave answer this fine result and you want to find a matrix a such that in the projected space the one shot similarity will perform better.",
            "So let's start of which one shot similarity score we were using.",
            "As I said before, one shot similarity is a meta similarity.",
            "An in this work we used the version of it with Freescale in our discriminate analysis.",
            "This means that the separating the classifier used here is LDA linear discriminant analysis, a good LDA separator.",
            "Will maximize this core, which means it encourage a large variance between the classes and as.",
            "Small variance within classes.",
            "So from the LDA equation you go."
        ],
        [
            "The following one shot similarity score given I JNN so this exact details of the formula are not so important right now, but I just want you to notice that we need only to calculate the mean of the set N and the inverse of the covenant metrics, and we do it once for all pairs inj."
        ],
        [
            "So what is OS?",
            "SM L1 shot similarity metric learning.",
            "This is simply want a similarity in the projected space.",
            "So giving IJN and the projection matrix A you just do OS test after you projecting everything to the new space you get this score, which is exactly the same as before in the projected subspace.",
            "And again you only need to calculate the mean of the set an after the projection and also the inverse of the covariance Matri."
        ],
        [
            "So how are we going to get this a this projection matrix?"
        ],
        [
            "So let's see what is the objective function.",
            "The goal of we have is to find a which optimize the following score.",
            "Let's talk about this Corbett so you have these two terms.",
            "Which encourage last separation between Sam and not same person.",
            "So we want this sum to be high.",
            "The similarity to be high and this score to be low.",
            "And the Alpha term here is for balance between these two terms.",
            "The third term is organization term, which keep a close to some initial matrix AO.",
            "Better, here is a tradeoff between having this encouraging this large separation and keeping a close to this disabled property a 0.",
            "So in the paper, we show that the gradient of this objective function has closed form solution.",
            "And we perform the optimization using gradient distance.",
            "You can refer to our paper for more details of this form.",
            "OK."
        ],
        [
            "I'm now going to show an application of this to action recognition, and for this we use the Ashland set, the action similarity labeling challenge.",
            "This is a new action recognition database we've presented in previous work.",
            "It is available online and is far more challenging than any other existing action recognition set.",
            "It contains over 400 complex action classes.",
            "Which is an order of magnitude, then another existing set.",
            "There their video in this database are required from YouTube, which means they are attacking and the unconstrained, realistic uncontrolled setting.",
            "This set have an attached action permitting protocol, which I'm now going to explain exactly what it means."
        ],
        [
            "So what is action permitting?",
            "So the input are two video pairs.",
            "As you can see here.",
            "And the questions is.",
            "If the actors in these two videos perform the same action or not.",
            "So the output of this should be a binary classification, same or not saying, let's see some of the challenges posed by."
        ],
        [
            "This problem.",
            "So first there is allowed variability within an action.",
            "For example, as you see here, there standing on my leg action.",
            "So here she is doing it on the wall and he's standing with eyes closed.",
            "And here is the explaining the action while doing it.",
            "And here there is a class resolution issue.",
            "You can say this is swimming action or you can say this is backstroke swimming and this is breaststroke swimming.",
            "Last, you have action ambiguity.",
            "For example here you can say it's either high five or walking.",
            "Anna are there challenges such as the quality of the video or an ambiguity of the actor doing the action.",
            "For example, here is this baby or the father holding him.",
            "So this is very high dimensional complicated space."
        ],
        [
            "So the Ashland benchmark setting is as follow.",
            "You are given 6000 video pairs divided into 10 subset which are mutually exclusive in each such subset you have different 40 classes of actions.",
            "This means mutually exclusive and you are required to do 10 fold cross validation on this subset, which means you are using the first set as a test set in the first round and the rest for training.",
            "Then you use this for test and the other for training and so on and so forth."
        ],
        [
            "So the baseline test done on Ashland in previous work is as full.",
            "Taking this time and not same pairs.",
            "You are calculating global video descriptor.",
            "Then you calculate the similarity score between this global descriptor.",
            "Can you put these scores into an SVM classifier, which in this case means just finding an optimal special and he used this threshold to classify the test?"
        ],
        [
            "Moreover, in this previous work we also use multiple descriptors and multiple similarities, so you get a vector of similarity scores, and you put this into an SVM machine to get in a spam classifier, and as before, you use this classifier to classify the test."
        ],
        [
            "So the baseline test on Iceland, which is in different method, which is the 65 or three area under curve score, which is 69 accuracy and also we've shown in this previous work that human can perform 97% on this task.",
            "So this is an satisfying result and we are now going to show how we improve that by one shot similarity metric."
        ],
        [
            "So where do we enter in this pipeline?",
            "So given these two input video pairs.",
            "Calculating the spacetime interest point on this videos.",
            "This is a standard thing in action recognition.",
            "These are features in space time in each of the videos.",
            "This is by software available by laptop here then from."
        ],
        [
            "Is best I'm interested.",
            "You calculate global descriptor three types.",
            "Histogram of oriented gradients, histogram, vertical flow, and the combination of the two which refer to as HNS an you do bag of words to get global descriptors of size 5000 for each of these descriptors.",
            "This is also a standard in action recognition and follow."
        ],
        [
            "This work?",
            "So in this work we enter here and we do PCA plus metric learning.",
            "We do two types of metric learning.",
            "The cosine similarity metric learning of new brennende from 2010.",
            "An hour one shot similarity metric learning, which is this work?",
            "We also do a dimensionality reduction from 5000 to 100 by PCA and then to 5050 by these two types of metric learning."
        ],
        [
            "Then we follow the rest of the pipeline.",
            "We calculate the cosine similarity and the one shot similarity scores and we do it for multiple similarity and we use the multiple similarity and the multiple descriptors into an SVM classifier."
        ],
        [
            "To get to get the same notes and label on it tested, so let's see."
        ],
        [
            "Result.",
            "So the baseline were 65.3 and in this work we managed to get it up to 69.10 area under curve.",
            "So this is the state of the current state of the art result on the Ashland benchmark."
        ],
        [
            "So these are some of the tests we did.",
            "The PCI initialization PSNL alone or SSM after PCN after CSML.",
            "So the best result are 69 and this is 38% of our random classify."
        ],
        [
            "I'm now going to show some qualitative result, so let's look at same pairs which were classified correctly.",
            "This is pairs with the highest confidence we got, and we expect it to be.",
            "So we expect it to be a easy pairs the easiest pair.",
            "So as you see here, this is the same actor just doing the same work.",
            "With different direction and you see it's pretty easy examples."
        ],
        [
            "And so the next slide is not same pair which was classified correctly.",
            "And here again this is with highest confidence, so it's the easiest pair and as expected you can see also completely different scenarios and actions.",
            "Maybe what is more into."
        ],
        [
            "Thing is to look at the mistakes and this is mistakes with highest confidence, which means these are pair that we were most wrong about.",
            "So these are same pairs which were classified wrongly as not saying an as you can see here for example, this is the same swimming action but in completely different position and paste.",
            "And here you can see the punching action where here is eating another guy and here this is punching in the air and also here this is a completely different scenario and completely different backgrounds."
        ],
        [
            "Let's see, some are not same which were classified wrongly.",
            "So again, this is the pairs we were most wrong about, so this is wrong.",
            "Pair with highest confidence classified as saying.",
            "So here you can see what we talked earlier about class resolution.",
            "So this is two different swimming type expected to be classified as not saying.",
            "And here it's the same actor which doing completely different actions an we should have been classified as not same.",
            "And here you see two different kind of sport game."
        ],
        [
            "So let's summarize.",
            "What we showed here is a metric learning method geared toward improve one shot similarity performance.",
            "We formulated the cost function using this time, not same labels.",
            "And we gave a gradient descent solution.",
            "I've also showed an application to action recognition specifically on the action permission.",
            "And we showed the best reported result on the Iceland set."
        ],
        [
            "Thank you very much.",
            "So what is your performance on the grassland data set?",
            "So it's in 97, which is so biased 7 stairway we made on this pairs people were asked to say they showed the pairs and they were asked to say same, not Simon rated on a scale between one and seven and we showed that to reach 97%.",
            "Area under curve performance, which is not perfect because this task is has an ambiguity even for all humans.",
            "That the that the highest potential of improvement for bridging that gap between the OK, so let's.",
            "Where you live is the highest potential for that on the feature side or so.",
            "This is a very new set, so we don't have a lot of experience on it, but you can try different direction here, which shows the to enter in the global after the global descriptors Ann to play with this, but you can try different features.",
            "You can go back and try different features.",
            "And you can do also different classifiers at the end.",
            "But in this work we were entering at the global descriptors side.",
            "But of course there is the maybe potentially better performance if you play also with this with the.",
            "Let's say feature the basic features or the at the end that that the classifier side."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So hi, my name is Derek little girl.",
                    "label": 0
                },
                {
                    "sent": "Anne, I'm going to present this joint work with God, Hosner and your Wolf on one shot, similarity metric.",
                    "label": 0
                },
                {
                    "sent": "Learning for action recognition.",
                    "label": 0
                },
                {
                    "sent": "So to do some order.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this pipeline of this work, if not, I'm going to present, so I'm going to start by metric learning.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to present the one shot similarity an in this work, where combining these two into a new method of one shot similarity metric learning in short, or SML.",
                    "label": 1
                },
                {
                    "sent": "At the end of the talk I will show an application of this to action recognition, so I'm going to start by a short introduction to metric learning.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the general.",
                    "label": 0
                },
                {
                    "sent": "The general scenario of metric learning you're giving point you are given points in some space and you don't know the point labels.",
                    "label": 0
                },
                {
                    "sent": "You only know similar and not similar constraints.",
                    "label": 0
                },
                {
                    "sent": "The distance metric in this in this space is sometimes not relevant or not meaningful and not consistent with the constraints you are having.",
                    "label": 1
                },
                {
                    "sent": "In the metric learning scenario, you're learning such projection matrix a such that in the news.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Chase the distance will be meaningful and consistent with the constraints you are having, and you can easily perform tasks such as classification, clustering, retrieval, task, button cognition and more.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The most common approach to metric learning learns the Euclidean distance in the projected space.",
                    "label": 1
                },
                {
                    "sent": "It means that it lands a projection matrix a such that the points moved to the projected space there clearing distance will perform better and consistent with the constraint we're talking about.",
                    "label": 0
                },
                {
                    "sent": "Um, this is equivalent to learning a melon.",
                    "label": 0
                },
                {
                    "sent": "Obvious metrics in the original space, so algorithm usually do either learn a or M, so this is a bunch of work done on this subject.",
                    "label": 0
                },
                {
                    "sent": "This is very huge literature on this.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And recently there was a work by Nguan in Bay, which suggested learning cosine similarity, which means they suggest learning a projection matrix a such that the cosine similarity in the projected space will perform better, so they call it cosine similarity metric learning.",
                    "label": 1
                },
                {
                    "sent": "In short CSML.",
                    "label": 0
                },
                {
                    "sent": "And this is the score they're using into projective space.",
                    "label": 0
                },
                {
                    "sent": "This work have inspired our work.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in this work we're trying to do.",
                    "label": 1
                },
                {
                    "sent": "Watch out similarity metric learning, which optimize the one shot similarity score.",
                    "label": 0
                },
                {
                    "sent": "In the projected space.",
                    "label": 0
                },
                {
                    "sent": "So this will call one shot similarity metric learning ossm and we will also show an application of it to action recognition.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is one shot similarity?",
                    "label": 0
                },
                {
                    "sent": "So one shot similarity by by Wolf Hosner anti gun from my CV 09.",
                    "label": 0
                },
                {
                    "sent": "Is a measure of similarity between two vectors.",
                    "label": 1
                },
                {
                    "sent": "The input is the two vectors I&J and you're also given a set of background sample an.",
                    "label": 0
                },
                {
                    "sent": "This samples are samples which you don't know the labels of, but you do know that the labels of the point in this set are different from both I&J.",
                    "label": 0
                },
                {
                    "sent": "So how you're going to do that?",
                    "label": 0
                },
                {
                    "sent": "You use one shot learning, which means classification with one positive example, and I'm now going to demonstrate how you're going to do that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here are the two vectors imj which you want to calculate the similarity between them.",
                    "label": 0
                },
                {
                    "sent": "You have this negative set an of background sample, and as I said before, you don't know anything about this set except at about the point in this step, except that they have different.",
                    "label": 0
                },
                {
                    "sent": "They are labeled differently from both ING, so you do one shot learning twice first.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You are looking at the vector I and the negative set N and you are looking for a model separating between this vector and the negative set.",
                    "label": 0
                },
                {
                    "sent": "Then you use this model to classify J and use the score of the classification as score one.",
                    "label": 0
                },
                {
                    "sent": "Then you do the opposite.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which means you are switching rules of ING.",
                    "label": 0
                },
                {
                    "sent": "So you're taking J and the negative set you're looking for model separating these two and then he use it to classify.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "The classification score of I using this model is called to.",
                    "label": 0
                },
                {
                    "sent": "The two side sided one shot similarity.",
                    "label": 0
                },
                {
                    "sent": "Is given by an average of these two scores.",
                    "label": 0
                },
                {
                    "sent": "Let's see some properties of this similar.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The function.",
                    "label": 0
                },
                {
                    "sent": "So first.",
                    "label": 0
                },
                {
                    "sent": "One chip similarity is a meta similarity.",
                    "label": 0
                },
                {
                    "sent": "It means you can use any classifier as an underlying classifier.",
                    "label": 1
                },
                {
                    "sent": "Second, you don't need label training data, which means you don't know the classes labours.",
                    "label": 0
                },
                {
                    "sent": "You only know that the classes their labors of the set N are different from boss inj and lost.",
                    "label": 1
                },
                {
                    "sent": "It may be efficiently computed since this city.",
                    "label": 0
                },
                {
                    "sent": "Statistical properties of the set and can be computed only once for all pairs inj and also when you compare I against many JS you only need to compute the statistical properties of N once.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So once your similarity I've shown to Excel in tasks such as face recognition and document analysis, however, when you try to apply to action recognition, we got answer to spine result.",
                    "label": 0
                },
                {
                    "sent": "So I'm now going to show how we applied one shot similarity metric learning.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is it?",
                    "label": 0
                },
                {
                    "sent": "So wanted similarity metric learning?",
                    "label": 0
                },
                {
                    "sent": "You have this setting in the original space where they want your similarity score is gave answer this fine result and you want to find a matrix a such that in the projected space the one shot similarity will perform better.",
                    "label": 0
                },
                {
                    "sent": "So let's start of which one shot similarity score we were using.",
                    "label": 0
                },
                {
                    "sent": "As I said before, one shot similarity is a meta similarity.",
                    "label": 0
                },
                {
                    "sent": "An in this work we used the version of it with Freescale in our discriminate analysis.",
                    "label": 0
                },
                {
                    "sent": "This means that the separating the classifier used here is LDA linear discriminant analysis, a good LDA separator.",
                    "label": 1
                },
                {
                    "sent": "Will maximize this core, which means it encourage a large variance between the classes and as.",
                    "label": 0
                },
                {
                    "sent": "Small variance within classes.",
                    "label": 0
                },
                {
                    "sent": "So from the LDA equation you go.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The following one shot similarity score given I JNN so this exact details of the formula are not so important right now, but I just want you to notice that we need only to calculate the mean of the set N and the inverse of the covenant metrics, and we do it once for all pairs inj.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is OS?",
                    "label": 0
                },
                {
                    "sent": "SM L1 shot similarity metric learning.",
                    "label": 1
                },
                {
                    "sent": "This is simply want a similarity in the projected space.",
                    "label": 1
                },
                {
                    "sent": "So giving IJN and the projection matrix A you just do OS test after you projecting everything to the new space you get this score, which is exactly the same as before in the projected subspace.",
                    "label": 0
                },
                {
                    "sent": "And again you only need to calculate the mean of the set an after the projection and also the inverse of the covariance Matri.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how are we going to get this a this projection matrix?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's see what is the objective function.",
                    "label": 0
                },
                {
                    "sent": "The goal of we have is to find a which optimize the following score.",
                    "label": 0
                },
                {
                    "sent": "Let's talk about this Corbett so you have these two terms.",
                    "label": 0
                },
                {
                    "sent": "Which encourage last separation between Sam and not same person.",
                    "label": 0
                },
                {
                    "sent": "So we want this sum to be high.",
                    "label": 0
                },
                {
                    "sent": "The similarity to be high and this score to be low.",
                    "label": 0
                },
                {
                    "sent": "And the Alpha term here is for balance between these two terms.",
                    "label": 0
                },
                {
                    "sent": "The third term is organization term, which keep a close to some initial matrix AO.",
                    "label": 0
                },
                {
                    "sent": "Better, here is a tradeoff between having this encouraging this large separation and keeping a close to this disabled property a 0.",
                    "label": 0
                },
                {
                    "sent": "So in the paper, we show that the gradient of this objective function has closed form solution.",
                    "label": 0
                },
                {
                    "sent": "And we perform the optimization using gradient distance.",
                    "label": 1
                },
                {
                    "sent": "You can refer to our paper for more details of this form.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm now going to show an application of this to action recognition, and for this we use the Ashland set, the action similarity labeling challenge.",
                    "label": 1
                },
                {
                    "sent": "This is a new action recognition database we've presented in previous work.",
                    "label": 0
                },
                {
                    "sent": "It is available online and is far more challenging than any other existing action recognition set.",
                    "label": 1
                },
                {
                    "sent": "It contains over 400 complex action classes.",
                    "label": 0
                },
                {
                    "sent": "Which is an order of magnitude, then another existing set.",
                    "label": 0
                },
                {
                    "sent": "There their video in this database are required from YouTube, which means they are attacking and the unconstrained, realistic uncontrolled setting.",
                    "label": 0
                },
                {
                    "sent": "This set have an attached action permitting protocol, which I'm now going to explain exactly what it means.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is action permitting?",
                    "label": 0
                },
                {
                    "sent": "So the input are two video pairs.",
                    "label": 0
                },
                {
                    "sent": "As you can see here.",
                    "label": 0
                },
                {
                    "sent": "And the questions is.",
                    "label": 0
                },
                {
                    "sent": "If the actors in these two videos perform the same action or not.",
                    "label": 0
                },
                {
                    "sent": "So the output of this should be a binary classification, same or not saying, let's see some of the challenges posed by.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This problem.",
                    "label": 0
                },
                {
                    "sent": "So first there is allowed variability within an action.",
                    "label": 0
                },
                {
                    "sent": "For example, as you see here, there standing on my leg action.",
                    "label": 0
                },
                {
                    "sent": "So here she is doing it on the wall and he's standing with eyes closed.",
                    "label": 0
                },
                {
                    "sent": "And here is the explaining the action while doing it.",
                    "label": 0
                },
                {
                    "sent": "And here there is a class resolution issue.",
                    "label": 0
                },
                {
                    "sent": "You can say this is swimming action or you can say this is backstroke swimming and this is breaststroke swimming.",
                    "label": 0
                },
                {
                    "sent": "Last, you have action ambiguity.",
                    "label": 1
                },
                {
                    "sent": "For example here you can say it's either high five or walking.",
                    "label": 0
                },
                {
                    "sent": "Anna are there challenges such as the quality of the video or an ambiguity of the actor doing the action.",
                    "label": 0
                },
                {
                    "sent": "For example, here is this baby or the father holding him.",
                    "label": 1
                },
                {
                    "sent": "So this is very high dimensional complicated space.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the Ashland benchmark setting is as follow.",
                    "label": 1
                },
                {
                    "sent": "You are given 6000 video pairs divided into 10 subset which are mutually exclusive in each such subset you have different 40 classes of actions.",
                    "label": 1
                },
                {
                    "sent": "This means mutually exclusive and you are required to do 10 fold cross validation on this subset, which means you are using the first set as a test set in the first round and the rest for training.",
                    "label": 0
                },
                {
                    "sent": "Then you use this for test and the other for training and so on and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the baseline test done on Ashland in previous work is as full.",
                    "label": 0
                },
                {
                    "sent": "Taking this time and not same pairs.",
                    "label": 1
                },
                {
                    "sent": "You are calculating global video descriptor.",
                    "label": 0
                },
                {
                    "sent": "Then you calculate the similarity score between this global descriptor.",
                    "label": 0
                },
                {
                    "sent": "Can you put these scores into an SVM classifier, which in this case means just finding an optimal special and he used this threshold to classify the test?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Moreover, in this previous work we also use multiple descriptors and multiple similarities, so you get a vector of similarity scores, and you put this into an SVM machine to get in a spam classifier, and as before, you use this classifier to classify the test.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the baseline test on Iceland, which is in different method, which is the 65 or three area under curve score, which is 69 accuracy and also we've shown in this previous work that human can perform 97% on this task.",
                    "label": 0
                },
                {
                    "sent": "So this is an satisfying result and we are now going to show how we improve that by one shot similarity metric.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So where do we enter in this pipeline?",
                    "label": 0
                },
                {
                    "sent": "So given these two input video pairs.",
                    "label": 1
                },
                {
                    "sent": "Calculating the spacetime interest point on this videos.",
                    "label": 0
                },
                {
                    "sent": "This is a standard thing in action recognition.",
                    "label": 1
                },
                {
                    "sent": "These are features in space time in each of the videos.",
                    "label": 0
                },
                {
                    "sent": "This is by software available by laptop here then from.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is best I'm interested.",
                    "label": 0
                },
                {
                    "sent": "You calculate global descriptor three types.",
                    "label": 0
                },
                {
                    "sent": "Histogram of oriented gradients, histogram, vertical flow, and the combination of the two which refer to as HNS an you do bag of words to get global descriptors of size 5000 for each of these descriptors.",
                    "label": 1
                },
                {
                    "sent": "This is also a standard in action recognition and follow.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This work?",
                    "label": 0
                },
                {
                    "sent": "So in this work we enter here and we do PCA plus metric learning.",
                    "label": 1
                },
                {
                    "sent": "We do two types of metric learning.",
                    "label": 0
                },
                {
                    "sent": "The cosine similarity metric learning of new brennende from 2010.",
                    "label": 0
                },
                {
                    "sent": "An hour one shot similarity metric learning, which is this work?",
                    "label": 1
                },
                {
                    "sent": "We also do a dimensionality reduction from 5000 to 100 by PCA and then to 5050 by these two types of metric learning.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we follow the rest of the pipeline.",
                    "label": 0
                },
                {
                    "sent": "We calculate the cosine similarity and the one shot similarity scores and we do it for multiple similarity and we use the multiple similarity and the multiple descriptors into an SVM classifier.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To get to get the same notes and label on it tested, so let's see.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Result.",
                    "label": 0
                },
                {
                    "sent": "So the baseline were 65.3 and in this work we managed to get it up to 69.10 area under curve.",
                    "label": 0
                },
                {
                    "sent": "So this is the state of the current state of the art result on the Ashland benchmark.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are some of the tests we did.",
                    "label": 0
                },
                {
                    "sent": "The PCI initialization PSNL alone or SSM after PCN after CSML.",
                    "label": 0
                },
                {
                    "sent": "So the best result are 69 and this is 38% of our random classify.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm now going to show some qualitative result, so let's look at same pairs which were classified correctly.",
                    "label": 0
                },
                {
                    "sent": "This is pairs with the highest confidence we got, and we expect it to be.",
                    "label": 0
                },
                {
                    "sent": "So we expect it to be a easy pairs the easiest pair.",
                    "label": 0
                },
                {
                    "sent": "So as you see here, this is the same actor just doing the same work.",
                    "label": 0
                },
                {
                    "sent": "With different direction and you see it's pretty easy examples.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the next slide is not same pair which was classified correctly.",
                    "label": 0
                },
                {
                    "sent": "And here again this is with highest confidence, so it's the easiest pair and as expected you can see also completely different scenarios and actions.",
                    "label": 0
                },
                {
                    "sent": "Maybe what is more into.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing is to look at the mistakes and this is mistakes with highest confidence, which means these are pair that we were most wrong about.",
                    "label": 0
                },
                {
                    "sent": "So these are same pairs which were classified wrongly as not saying an as you can see here for example, this is the same swimming action but in completely different position and paste.",
                    "label": 0
                },
                {
                    "sent": "And here you can see the punching action where here is eating another guy and here this is punching in the air and also here this is a completely different scenario and completely different backgrounds.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's see, some are not same which were classified wrongly.",
                    "label": 0
                },
                {
                    "sent": "So again, this is the pairs we were most wrong about, so this is wrong.",
                    "label": 0
                },
                {
                    "sent": "Pair with highest confidence classified as saying.",
                    "label": 1
                },
                {
                    "sent": "So here you can see what we talked earlier about class resolution.",
                    "label": 0
                },
                {
                    "sent": "So this is two different swimming type expected to be classified as not saying.",
                    "label": 0
                },
                {
                    "sent": "And here it's the same actor which doing completely different actions an we should have been classified as not same.",
                    "label": 0
                },
                {
                    "sent": "And here you see two different kind of sport game.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's summarize.",
                    "label": 0
                },
                {
                    "sent": "What we showed here is a metric learning method geared toward improve one shot similarity performance.",
                    "label": 1
                },
                {
                    "sent": "We formulated the cost function using this time, not same labels.",
                    "label": 1
                },
                {
                    "sent": "And we gave a gradient descent solution.",
                    "label": 0
                },
                {
                    "sent": "I've also showed an application to action recognition specifically on the action permission.",
                    "label": 1
                },
                {
                    "sent": "And we showed the best reported result on the Iceland set.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "So what is your performance on the grassland data set?",
                    "label": 0
                },
                {
                    "sent": "So it's in 97, which is so biased 7 stairway we made on this pairs people were asked to say they showed the pairs and they were asked to say same, not Simon rated on a scale between one and seven and we showed that to reach 97%.",
                    "label": 0
                },
                {
                    "sent": "Area under curve performance, which is not perfect because this task is has an ambiguity even for all humans.",
                    "label": 0
                },
                {
                    "sent": "That the that the highest potential of improvement for bridging that gap between the OK, so let's.",
                    "label": 0
                },
                {
                    "sent": "Where you live is the highest potential for that on the feature side or so.",
                    "label": 0
                },
                {
                    "sent": "This is a very new set, so we don't have a lot of experience on it, but you can try different direction here, which shows the to enter in the global after the global descriptors Ann to play with this, but you can try different features.",
                    "label": 0
                },
                {
                    "sent": "You can go back and try different features.",
                    "label": 0
                },
                {
                    "sent": "And you can do also different classifiers at the end.",
                    "label": 0
                },
                {
                    "sent": "But in this work we were entering at the global descriptors side.",
                    "label": 0
                },
                {
                    "sent": "But of course there is the maybe potentially better performance if you play also with this with the.",
                    "label": 0
                },
                {
                    "sent": "Let's say feature the basic features or the at the end that that the classifier side.",
                    "label": 0
                }
            ]
        }
    }
}