{
    "id": "ni55lypar6u55mtcorhbzpxavvnmz6ce",
    "title": "Weighting versus Pruning in Rule Validation for Detecting Network and Host Anomalies",
    "info": {
        "author": [
            "Gaurav Tandon, Florida Institute of Technology"
        ],
        "published": "Sept. 14, 2007",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/kdd07_tandon_wvpirv/",
    "segmentation": [
        [
            "Behavior and try to find significant deviations.",
            "The advantage of such systems is that we can detect novel attacks, but then there's a problem of high false alarm generation because not every alarm that we get is necessarily from an intrusion."
        ],
        [
            "So we can also think of the signature detection problem as a classification problem and anomaly detection being a single class learning problem where we only deal with normal training data.",
            "Weather anomaly detection systems.",
            "It is important that we come up with an easy to understand model because typically such systems will be used by network or system administrators and they have to deal with all the alarms.",
            "So rule learning is one way where we have easy to understand set of rules which the administrator can comprehend.",
            "Unlearned is an algorithm which is used to detect anomalies.",
            "It has been shown to be better than many existing systems and this is just a toy example.",
            "Of the type of rules that letter generates an here.",
            "I have a network rule where I have a given source IP address and a destination IP address and the consequences that given the two the only possible destination ports are 21, which is FTP 25 which is SMTP and 80 which is HTTP.",
            "With every rule, there's a P value associated, which I'll come to in a few slides.",
            "In the detection phase, every data instance is associated with an anomaly score, which is the degree of abnormality and ideally for any normal event.",
            "This anomaly score should be 0 and we hope to have a very high anomaly score for any intrusive act."
        ],
        [
            "Pretty.",
            "So how do we quantify the role quality?",
            "So here we have two different aspects of role quality, the first being the predictiveness, which is the measure of predictive accuracy of the consequent being true, given that the antecedent was true and the other is rule belief.",
            "That is, how much trust do we have on the rule itself?",
            "An ensemble methods boosting use weights, which are typically represent the belief in that particular."
        ],
        [
            "Expert.",
            "So how does the predictiveness and belief aspect of rule quality translate into a lead role?",
            "And so I have the same example.",
            "But now we notice that there's a P value Anna W value associated with every rule, and the P value is basically signifying the predictiveness aspect of rule quality, which is how likely is the rule.",
            "Will the rule be violated so it's the probability of rule violation, and then there's a weight associated which corresponds to the rule belief."
        ],
        [
            "So we've seen in earlier literature that rule pruning is great because it tends to avoid overfitting.",
            "Ann rule waiting has been used to combine prediction from different experts.",
            "And the literature that we've come across generally discusses pruning versus no pruning or wearing versus no waiting.",
            "But we did not come across across any work which was actually comparing pruning with waiting, specially in the field of anomaly detection.",
            "And this is the motivation for our work to see if wearing is able to do better in terms of accuracy."
        ],
        [
            "Done pruning.",
            "This is the four steps that Leonard has for rule generation.",
            "It starts with a very small random training sample from which it generates a candidate set of rules and for any anomaly detection system we need to have a small rule set.",
            "It is imperative because we need to have the system being running for online usage an if the rule set is large, the time requirements in the test phase will be higher.",
            "So what letter does is performs a coverage test to minimize this particular rule set.",
            "Then the rules are updated to cover the entire training data.",
            "And finally, there's a validation step which is a separate held out data set.",
            "And also comprises of normal data."
        ],
        [
            "And this is the P value which is used to signify the predictiveness aspect of rule quality.",
            "It is the probability or the likelihood of the rule being violated and the formula that we use or by N is from Britain and Bell have used it in data compression earlier and the numerator are signifies the number of values, number of distinct values in the consequent an N is the number of data instances which satisfied the consequent in the training data.",
            "That would satisfy the antecedent.",
            "I'm sorry in the training data.",
            "So this is the probability of the rule being violated.",
            "So in essence, if the rule has high probability of being violated when there is a violation, we are not surprised that much.",
            "On the other hand, if the rule of the likelihood of the rule being violated is very low, and this rule is violated.",
            "The surprise element is really high, so the anomaly score is inversely proportional to this predictive value."
        ],
        [
            "So let's revisit the validation set ANSI how rule pruning and rule waiting are applied."
        ],
        [
            "So the idea for rule pruning is we have training data from which layer add learned rule set.",
            "In this case they are trend different rules.",
            "And there's a validation data set which also comprises of normal instances.",
            "So.",
            "The idea is that keep the rules which conform to the validation data.",
            "So in this case R1 is validated to the validation set it conforms, so we keep it.",
            "But we prune the rule which was violated and the idea is simple, because any violation in the validation set is typically a false alarm, since we know that it comprises of normal data.",
            "So at the end of the valuation step we prune all the rules which were violated.",
            "In this case R2R6.",
            "NR 9."
        ],
        [
            "So for a Roulin given data instance, there are three applicable cases.",
            "Either the rule is confirmed it is violated, or it does not apply, and the third case there are no changes that we make, so I will not cover this in."
        ],
        [
            "Talk.",
            "Let's go one by one on the other two cases.",
            "The first one is that of rule conformance.",
            "So we have a data instance which conforms to the rule.",
            "We can see the both the conditions and and in the antecedent match and the consequent is one of the values and the destination port is also valid consequent value.",
            "So the semantics of the rule do not change.",
            "The rule remains intact, but the P value changes because.",
            "If you look at the P value was R by N and now instead of 100 data instances which were satisfying the antecedent, now we have an additional data instance which satisfies, so we increase it from hundred 201."
        ],
        [
            "What about rule violation?",
            "In this case?",
            "We can see even though the conditions and the antecedent match, but there's a new destination port.",
            "In this case telnet, which is 23, so this rule violates the given data instance.",
            "And what role pruning does is just get rid of the rule that eliminates it."
        ],
        [
            "From the rule set.",
            "So what is the limitation of rule pruning an?",
            "For that, let's go back to the coverage test."
        ],
        [
            "Coverage test performs a minimal set of rules and typically each rule has a very large coverage on the training data.",
            "An bruening any of the rules we believe will lead to reducing the coverage significantly and potentially lead to missed detections."
        ],
        [
            "And that is the motivation of rule waiting, for which we go back."
        ],
        [
            "So the 4th step which was validation and now with every rule we associate a weight.",
            "So again, the same example.",
            "We learn 10 rules, each of which has a weight.",
            "An on the validation data.",
            "What we do is if the rule conforms to the validation data set, we simply increase the weight.",
            "But on rule violation, instead of pruning it, we decrease the weight because now our belief or trust in the rule has decreased.",
            "So at the end of the validation step, we still retain the rules, but increase or decrease the weight depending upon whether the rule was confirmed or violated."
        ],
        [
            "So I will quickly go over the two cases of rule conformance and rule violation and see what changes we made.",
            "Four lettered specifically.",
            "The first case is out of rule conformance and now.",
            "And I'm wanting to notice that in addition to the P value which signifies predictiveness, we also have the weight for rule belief.",
            "For rule conformance, the semantics of the rule do not change.",
            "The rules still remains the same.",
            "The P value is updated as in Rule pruning and now we have the additional weight which is increased.",
            "And how do we increase this?",
            "Wait, I'll be discussing a few weight update techniques later in this presentation."
        ],
        [
            "For rule violation.",
            "As we saw before, we had a new destination port which was tell it in this case.",
            "So the semantics of the rule change because we need to update the consequent at the bottom of the screen to have.",
            "The new destination port.",
            "We also changed the.",
            "Probability of the rule being violated because now we have four distinct.",
            "Destination ports instead of three earlier, so the numerator is 4 and now there is an additional data instance which satisfies the antecedent, so the denominator is incremented as well.",
            "And since the rule was violated at decreased, our trust in the role, and so we have a new weight which is weight prime, which is less than the value of W."
        ],
        [
            "So how does the anomaly scoring differ in the two cases?",
            "Well, rule pruning only incorporates the rule predictiveness aspect of rule quality, and so we can see we saw earlier that anomaly score was inversely proportional to P. But now we have an additional T factor which is for creating a non stationary model, which is the time since last anomaly.",
            "For rule waiting, we see that we, in addition to the rule predictiveness, we have the weight for rule belief an it's directly proportional to the weight and the anomaly score is aggregated over all the rules which were violated for the given data test data instance."
        ],
        [
            "We experimented with three different weight update methods.",
            "In this particular paper, the first one using Windows specialist which has been applied successfully in varied domains and the idea is to decrement the weight by a factor Alpha on rule violation and updated by another factor beta.",
            "When the rule is confirmed, an both of these para meters have values between zero and one.",
            "But the problem here is.",
            "That the amount of weight is just a constant factor beta and it does not depend on whether a high belief rule or a low belief rule was why."
        ],
        [
            "Dated.",
            "What is the motivation for the second method which is called equal reward apportioning?",
            "So the rule violation still remains the same, which is decrementing it by a factor Alpha, but now the reward is being accumulated.",
            "As the total penalty and the penalty is equally distributed amongst the rules which conform to the given data instance.",
            "In this case, we get rid of the beta parimeter, but we still have the Alpha pack."
        ],
        [
            "Peter the third is technique weight update method which has been adopted from information theory, which is basically the gain in the mutual information given the consequent was true when the incident was true and the consequent was not true.",
            "With the answer in being true.",
            "And the way it can have any real value.",
            "But we typically want to only have weights which have again in mutual information.",
            "So we actually ignored the rules with negative weights, and there are no para meters."
        ],
        [
            "In this particular case.",
            "We experimented with.",
            "I wear a variety of network and host datasets for network.",
            "We have the ID evaluation, the DARPA data set, where we had extracted incoming TCP streams.",
            "There were packet data that we had, and the combination of the two and the same we did for University Department ULL data set that we gathered.",
            "So that's a TCP packet, and the combination of TCP and packet for host based systems.",
            "We had the DARPA data set which comprise of the BSM logs from Solaris hosts.",
            "We use the University of New Mexico data which comprised of applications running on the Linux platform and the F ID UTK data which comprise of Microsoft Excel macro executions.",
            "So you can see a wide variety of operating systems and applications.",
            "Data sets the evaluation criteria we used was the RC curves, which is the typical norm and we computed the area under the curve where higher value is better.",
            "But in our system we need to restrain the amount of false alarms being generated.",
            "So typically we are only interested in very low false alarm rates.",
            "So for our experiment we only concentrated on false alarm rates at .1 and."
        ],
        [
            "Percent.",
            "So this is a table of area in the curve at point 1%, false alarm rate.",
            "The first column is the data set.",
            "Second as the pruning, and the subsequent three columns are the three weighting schemes that we used.",
            "So generally we can see that weighting techniques did better than pruning an.",
            "If we go to the last roll of this particular table, we have the number of times each weighting strategy was better, same or worse than pruning.",
            "So in general we saw that waiting did better, but we did not find any one particular weighting technique, which rarely outperformed the other."
        ],
        [
            "Try to relax the false alarm rate and we saw that the performance of wearing grew better than it was able to do.",
            "Much better than pruning, but again we did not find any one particular technique with just one."
        ],
        [
            "The best amongst all.",
            "But we were curious as to why waiting was able to do better than pruning.",
            "Anne.",
            "We notice that we are scoring the anomaly, so typically now the intrusive activity has a higher anomaly score and the reason can be attributed to the two factors that I have on the slide.",
            "The first being that now we have increased weights for the rules, which are confirmed and the second being that we are introducing the rules which were earlier being pruned, but they have a lower weight and what we found that the latter was actually contributing more to the anomaly score than the former.",
            "And this actually supports our claim of.",
            "Introducing rule waiting instead of rule pruning."
        ],
        [
            "And we also performed experiments to see whether our technique is good for online purposes.",
            "And we had a."
        ],
        [
            "Very minimal overhead.",
            "And since we're running out of time, I'll just put the summary slide on the screen an I am open for questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Behavior and try to find significant deviations.",
                    "label": 0
                },
                {
                    "sent": "The advantage of such systems is that we can detect novel attacks, but then there's a problem of high false alarm generation because not every alarm that we get is necessarily from an intrusion.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we can also think of the signature detection problem as a classification problem and anomaly detection being a single class learning problem where we only deal with normal training data.",
                    "label": 1
                },
                {
                    "sent": "Weather anomaly detection systems.",
                    "label": 0
                },
                {
                    "sent": "It is important that we come up with an easy to understand model because typically such systems will be used by network or system administrators and they have to deal with all the alarms.",
                    "label": 0
                },
                {
                    "sent": "So rule learning is one way where we have easy to understand set of rules which the administrator can comprehend.",
                    "label": 0
                },
                {
                    "sent": "Unlearned is an algorithm which is used to detect anomalies.",
                    "label": 0
                },
                {
                    "sent": "It has been shown to be better than many existing systems and this is just a toy example.",
                    "label": 0
                },
                {
                    "sent": "Of the type of rules that letter generates an here.",
                    "label": 0
                },
                {
                    "sent": "I have a network rule where I have a given source IP address and a destination IP address and the consequences that given the two the only possible destination ports are 21, which is FTP 25 which is SMTP and 80 which is HTTP.",
                    "label": 0
                },
                {
                    "sent": "With every rule, there's a P value associated, which I'll come to in a few slides.",
                    "label": 0
                },
                {
                    "sent": "In the detection phase, every data instance is associated with an anomaly score, which is the degree of abnormality and ideally for any normal event.",
                    "label": 1
                },
                {
                    "sent": "This anomaly score should be 0 and we hope to have a very high anomaly score for any intrusive act.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pretty.",
                    "label": 0
                },
                {
                    "sent": "So how do we quantify the role quality?",
                    "label": 0
                },
                {
                    "sent": "So here we have two different aspects of role quality, the first being the predictiveness, which is the measure of predictive accuracy of the consequent being true, given that the antecedent was true and the other is rule belief.",
                    "label": 1
                },
                {
                    "sent": "That is, how much trust do we have on the rule itself?",
                    "label": 1
                },
                {
                    "sent": "An ensemble methods boosting use weights, which are typically represent the belief in that particular.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Expert.",
                    "label": 0
                },
                {
                    "sent": "So how does the predictiveness and belief aspect of rule quality translate into a lead role?",
                    "label": 0
                },
                {
                    "sent": "And so I have the same example.",
                    "label": 0
                },
                {
                    "sent": "But now we notice that there's a P value Anna W value associated with every rule, and the P value is basically signifying the predictiveness aspect of rule quality, which is how likely is the rule.",
                    "label": 0
                },
                {
                    "sent": "Will the rule be violated so it's the probability of rule violation, and then there's a weight associated which corresponds to the rule belief.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we've seen in earlier literature that rule pruning is great because it tends to avoid overfitting.",
                    "label": 1
                },
                {
                    "sent": "Ann rule waiting has been used to combine prediction from different experts.",
                    "label": 1
                },
                {
                    "sent": "And the literature that we've come across generally discusses pruning versus no pruning or wearing versus no waiting.",
                    "label": 0
                },
                {
                    "sent": "But we did not come across across any work which was actually comparing pruning with waiting, specially in the field of anomaly detection.",
                    "label": 0
                },
                {
                    "sent": "And this is the motivation for our work to see if wearing is able to do better in terms of accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Done pruning.",
                    "label": 0
                },
                {
                    "sent": "This is the four steps that Leonard has for rule generation.",
                    "label": 0
                },
                {
                    "sent": "It starts with a very small random training sample from which it generates a candidate set of rules and for any anomaly detection system we need to have a small rule set.",
                    "label": 0
                },
                {
                    "sent": "It is imperative because we need to have the system being running for online usage an if the rule set is large, the time requirements in the test phase will be higher.",
                    "label": 0
                },
                {
                    "sent": "So what letter does is performs a coverage test to minimize this particular rule set.",
                    "label": 1
                },
                {
                    "sent": "Then the rules are updated to cover the entire training data.",
                    "label": 0
                },
                {
                    "sent": "And finally, there's a validation step which is a separate held out data set.",
                    "label": 0
                },
                {
                    "sent": "And also comprises of normal data.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the P value which is used to signify the predictiveness aspect of rule quality.",
                    "label": 0
                },
                {
                    "sent": "It is the probability or the likelihood of the rule being violated and the formula that we use or by N is from Britain and Bell have used it in data compression earlier and the numerator are signifies the number of values, number of distinct values in the consequent an N is the number of data instances which satisfied the consequent in the training data.",
                    "label": 0
                },
                {
                    "sent": "That would satisfy the antecedent.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry in the training data.",
                    "label": 0
                },
                {
                    "sent": "So this is the probability of the rule being violated.",
                    "label": 0
                },
                {
                    "sent": "So in essence, if the rule has high probability of being violated when there is a violation, we are not surprised that much.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if the rule of the likelihood of the rule being violated is very low, and this rule is violated.",
                    "label": 0
                },
                {
                    "sent": "The surprise element is really high, so the anomaly score is inversely proportional to this predictive value.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's revisit the validation set ANSI how rule pruning and rule waiting are applied.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the idea for rule pruning is we have training data from which layer add learned rule set.",
                    "label": 1
                },
                {
                    "sent": "In this case they are trend different rules.",
                    "label": 1
                },
                {
                    "sent": "And there's a validation data set which also comprises of normal instances.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The idea is that keep the rules which conform to the validation data.",
                    "label": 0
                },
                {
                    "sent": "So in this case R1 is validated to the validation set it conforms, so we keep it.",
                    "label": 0
                },
                {
                    "sent": "But we prune the rule which was violated and the idea is simple, because any violation in the validation set is typically a false alarm, since we know that it comprises of normal data.",
                    "label": 0
                },
                {
                    "sent": "So at the end of the valuation step we prune all the rules which were violated.",
                    "label": 0
                },
                {
                    "sent": "In this case R2R6.",
                    "label": 0
                },
                {
                    "sent": "NR 9.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for a Roulin given data instance, there are three applicable cases.",
                    "label": 0
                },
                {
                    "sent": "Either the rule is confirmed it is violated, or it does not apply, and the third case there are no changes that we make, so I will not cover this in.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Talk.",
                    "label": 0
                },
                {
                    "sent": "Let's go one by one on the other two cases.",
                    "label": 0
                },
                {
                    "sent": "The first one is that of rule conformance.",
                    "label": 0
                },
                {
                    "sent": "So we have a data instance which conforms to the rule.",
                    "label": 0
                },
                {
                    "sent": "We can see the both the conditions and and in the antecedent match and the consequent is one of the values and the destination port is also valid consequent value.",
                    "label": 0
                },
                {
                    "sent": "So the semantics of the rule do not change.",
                    "label": 0
                },
                {
                    "sent": "The rule remains intact, but the P value changes because.",
                    "label": 0
                },
                {
                    "sent": "If you look at the P value was R by N and now instead of 100 data instances which were satisfying the antecedent, now we have an additional data instance which satisfies, so we increase it from hundred 201.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What about rule violation?",
                    "label": 0
                },
                {
                    "sent": "In this case?",
                    "label": 0
                },
                {
                    "sent": "We can see even though the conditions and the antecedent match, but there's a new destination port.",
                    "label": 0
                },
                {
                    "sent": "In this case telnet, which is 23, so this rule violates the given data instance.",
                    "label": 0
                },
                {
                    "sent": "And what role pruning does is just get rid of the rule that eliminates it.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the rule set.",
                    "label": 0
                },
                {
                    "sent": "So what is the limitation of rule pruning an?",
                    "label": 0
                },
                {
                    "sent": "For that, let's go back to the coverage test.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Coverage test performs a minimal set of rules and typically each rule has a very large coverage on the training data.",
                    "label": 0
                },
                {
                    "sent": "An bruening any of the rules we believe will lead to reducing the coverage significantly and potentially lead to missed detections.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that is the motivation of rule waiting, for which we go back.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the 4th step which was validation and now with every rule we associate a weight.",
                    "label": 0
                },
                {
                    "sent": "So again, the same example.",
                    "label": 0
                },
                {
                    "sent": "We learn 10 rules, each of which has a weight.",
                    "label": 0
                },
                {
                    "sent": "An on the validation data.",
                    "label": 0
                },
                {
                    "sent": "What we do is if the rule conforms to the validation data set, we simply increase the weight.",
                    "label": 0
                },
                {
                    "sent": "But on rule violation, instead of pruning it, we decrease the weight because now our belief or trust in the rule has decreased.",
                    "label": 0
                },
                {
                    "sent": "So at the end of the validation step, we still retain the rules, but increase or decrease the weight depending upon whether the rule was confirmed or violated.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I will quickly go over the two cases of rule conformance and rule violation and see what changes we made.",
                    "label": 0
                },
                {
                    "sent": "Four lettered specifically.",
                    "label": 0
                },
                {
                    "sent": "The first case is out of rule conformance and now.",
                    "label": 0
                },
                {
                    "sent": "And I'm wanting to notice that in addition to the P value which signifies predictiveness, we also have the weight for rule belief.",
                    "label": 0
                },
                {
                    "sent": "For rule conformance, the semantics of the rule do not change.",
                    "label": 0
                },
                {
                    "sent": "The rules still remains the same.",
                    "label": 0
                },
                {
                    "sent": "The P value is updated as in Rule pruning and now we have the additional weight which is increased.",
                    "label": 0
                },
                {
                    "sent": "And how do we increase this?",
                    "label": 0
                },
                {
                    "sent": "Wait, I'll be discussing a few weight update techniques later in this presentation.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For rule violation.",
                    "label": 0
                },
                {
                    "sent": "As we saw before, we had a new destination port which was tell it in this case.",
                    "label": 0
                },
                {
                    "sent": "So the semantics of the rule change because we need to update the consequent at the bottom of the screen to have.",
                    "label": 0
                },
                {
                    "sent": "The new destination port.",
                    "label": 0
                },
                {
                    "sent": "We also changed the.",
                    "label": 0
                },
                {
                    "sent": "Probability of the rule being violated because now we have four distinct.",
                    "label": 0
                },
                {
                    "sent": "Destination ports instead of three earlier, so the numerator is 4 and now there is an additional data instance which satisfies the antecedent, so the denominator is incremented as well.",
                    "label": 0
                },
                {
                    "sent": "And since the rule was violated at decreased, our trust in the role, and so we have a new weight which is weight prime, which is less than the value of W.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how does the anomaly scoring differ in the two cases?",
                    "label": 0
                },
                {
                    "sent": "Well, rule pruning only incorporates the rule predictiveness aspect of rule quality, and so we can see we saw earlier that anomaly score was inversely proportional to P. But now we have an additional T factor which is for creating a non stationary model, which is the time since last anomaly.",
                    "label": 1
                },
                {
                    "sent": "For rule waiting, we see that we, in addition to the rule predictiveness, we have the weight for rule belief an it's directly proportional to the weight and the anomaly score is aggregated over all the rules which were violated for the given data test data instance.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We experimented with three different weight update methods.",
                    "label": 0
                },
                {
                    "sent": "In this particular paper, the first one using Windows specialist which has been applied successfully in varied domains and the idea is to decrement the weight by a factor Alpha on rule violation and updated by another factor beta.",
                    "label": 0
                },
                {
                    "sent": "When the rule is confirmed, an both of these para meters have values between zero and one.",
                    "label": 0
                },
                {
                    "sent": "But the problem here is.",
                    "label": 0
                },
                {
                    "sent": "That the amount of weight is just a constant factor beta and it does not depend on whether a high belief rule or a low belief rule was why.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dated.",
                    "label": 0
                },
                {
                    "sent": "What is the motivation for the second method which is called equal reward apportioning?",
                    "label": 1
                },
                {
                    "sent": "So the rule violation still remains the same, which is decrementing it by a factor Alpha, but now the reward is being accumulated.",
                    "label": 1
                },
                {
                    "sent": "As the total penalty and the penalty is equally distributed amongst the rules which conform to the given data instance.",
                    "label": 0
                },
                {
                    "sent": "In this case, we get rid of the beta parimeter, but we still have the Alpha pack.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Peter the third is technique weight update method which has been adopted from information theory, which is basically the gain in the mutual information given the consequent was true when the incident was true and the consequent was not true.",
                    "label": 0
                },
                {
                    "sent": "With the answer in being true.",
                    "label": 0
                },
                {
                    "sent": "And the way it can have any real value.",
                    "label": 0
                },
                {
                    "sent": "But we typically want to only have weights which have again in mutual information.",
                    "label": 0
                },
                {
                    "sent": "So we actually ignored the rules with negative weights, and there are no para meters.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this particular case.",
                    "label": 0
                },
                {
                    "sent": "We experimented with.",
                    "label": 0
                },
                {
                    "sent": "I wear a variety of network and host datasets for network.",
                    "label": 0
                },
                {
                    "sent": "We have the ID evaluation, the DARPA data set, where we had extracted incoming TCP streams.",
                    "label": 0
                },
                {
                    "sent": "There were packet data that we had, and the combination of the two and the same we did for University Department ULL data set that we gathered.",
                    "label": 0
                },
                {
                    "sent": "So that's a TCP packet, and the combination of TCP and packet for host based systems.",
                    "label": 0
                },
                {
                    "sent": "We had the DARPA data set which comprise of the BSM logs from Solaris hosts.",
                    "label": 0
                },
                {
                    "sent": "We use the University of New Mexico data which comprised of applications running on the Linux platform and the F ID UTK data which comprise of Microsoft Excel macro executions.",
                    "label": 0
                },
                {
                    "sent": "So you can see a wide variety of operating systems and applications.",
                    "label": 0
                },
                {
                    "sent": "Data sets the evaluation criteria we used was the RC curves, which is the typical norm and we computed the area under the curve where higher value is better.",
                    "label": 1
                },
                {
                    "sent": "But in our system we need to restrain the amount of false alarms being generated.",
                    "label": 1
                },
                {
                    "sent": "So typically we are only interested in very low false alarm rates.",
                    "label": 0
                },
                {
                    "sent": "So for our experiment we only concentrated on false alarm rates at .1 and.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Percent.",
                    "label": 0
                },
                {
                    "sent": "So this is a table of area in the curve at point 1%, false alarm rate.",
                    "label": 1
                },
                {
                    "sent": "The first column is the data set.",
                    "label": 0
                },
                {
                    "sent": "Second as the pruning, and the subsequent three columns are the three weighting schemes that we used.",
                    "label": 0
                },
                {
                    "sent": "So generally we can see that weighting techniques did better than pruning an.",
                    "label": 0
                },
                {
                    "sent": "If we go to the last roll of this particular table, we have the number of times each weighting strategy was better, same or worse than pruning.",
                    "label": 0
                },
                {
                    "sent": "So in general we saw that waiting did better, but we did not find any one particular weighting technique, which rarely outperformed the other.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Try to relax the false alarm rate and we saw that the performance of wearing grew better than it was able to do.",
                    "label": 0
                },
                {
                    "sent": "Much better than pruning, but again we did not find any one particular technique with just one.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The best amongst all.",
                    "label": 0
                },
                {
                    "sent": "But we were curious as to why waiting was able to do better than pruning.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "We notice that we are scoring the anomaly, so typically now the intrusive activity has a higher anomaly score and the reason can be attributed to the two factors that I have on the slide.",
                    "label": 0
                },
                {
                    "sent": "The first being that now we have increased weights for the rules, which are confirmed and the second being that we are introducing the rules which were earlier being pruned, but they have a lower weight and what we found that the latter was actually contributing more to the anomaly score than the former.",
                    "label": 0
                },
                {
                    "sent": "And this actually supports our claim of.",
                    "label": 0
                },
                {
                    "sent": "Introducing rule waiting instead of rule pruning.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also performed experiments to see whether our technique is good for online purposes.",
                    "label": 0
                },
                {
                    "sent": "And we had a.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very minimal overhead.",
                    "label": 0
                },
                {
                    "sent": "And since we're running out of time, I'll just put the summary slide on the screen an I am open for questions.",
                    "label": 0
                }
            ]
        }
    }
}