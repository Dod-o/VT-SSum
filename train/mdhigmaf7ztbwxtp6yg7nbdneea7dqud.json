{
    "id": "mdhigmaf7ztbwxtp6yg7nbdneea7dqud",
    "title": "Knows What It Knows: A Framework For Self-Aware Learning",
    "info": {
        "author": [
            "Lihong Li, Microsoft Research"
        ],
        "published": "July 24, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/icml08_li_kwik/",
    "segmentation": [
        [
            "I thought the paper is know what it knows, a framework for self.",
            "Michael Littman and Thomas Wash and let's congratulate them.",
            "Lihong will be giving the talk.",
            "Can you hear me?",
            "OK, not hear me.",
            "OK, now you hear me OK thanks, thanks for introduction.",
            "Cause so the title is knows what he knows is the framework for software learning this joint.",
            "By Michael Lipman.",
            "Tom Wash over there."
        ],
        [
            "So let me give you a quick overview of the quick and quick is an acronym of Four Knows what he knows and what it is, is a learning framework when the learner has to choose samples actively.",
            "For example, in selective sampling, the learner only sees label when it buys are labeled an embedded problems.",
            "The learner can only see the payoff when he chooses the arm, and in more general setting like reinforcement learning, we can only observe the transition or reward of the state when we.",
            "Visit the state takes an action there.",
            "An in this quick setting requires that the learner must be aware of the prediction error so that this is the key to balance exploration exploitation for learner in this unknown environment, and it actually unifies a lot of these recent pack MDP work in reinforcement learning, and I'm."
        ],
        [
            "And they're going to detail about it.",
            "So here's an outline.",
            "First, given motivating example and then define what quick is followed by some very simple quick examples and then I'll show you how we can combine quick learners to produce powerful algorithms for data vision."
        ],
        [
            "I'm learning.",
            "OK, so here's another example is an episodic task, and the task he is to is to find the shortest or the minimum cost path the agent is aware of the topology of the graph.",
            "He knows the vectors associated to each edge and the cause of an edge is linear is linear in the vector, but the agent doesn't know the weight of the other ways.",
            "That gives you the cost.",
            "So in this case the star is 120 but Agent doesn't know that.",
            "Another question is how can agent find is minimum cost path at the beginning?",
            "The agent knows nothing about this edge costs and then he may take a random path.",
            "For example the middle one because as the smallest number of edges.",
            "So maybe this is the best one and these are the rewards you observe.",
            "The cause it observes 33331 OK and if you run the standard square linear regression algorithm it gives a solution.",
            "A prediction over the wait an.",
            "Usually we can make a prediction about the other edge cost.",
            "But it turns out that.",
            "The two ones that up there is wrong and.",
            "And actually, if you look at the optimal weight W star, the edge cost up, there are zero both 0, so the minimum cost path is actually the upper 1 instead of the middle one.",
            "And in this case this algorithm fails to find a minimum."
        ],
        [
            "'cause now OK. Now let's see what a quick agent would do.",
            "So in a quick quick Asian tries to reason about uncertainty in this prediction about as costs for the these two edges below 2 one, I notice that the 01 is quite obvious because the cost vector is zero an for the two one the cost vector is actually a difference between two of the other edges he has visited before and therefore the cost of that edges.",
            "The difference between the two edges cut edge costs because the edge 'cause it's linear in the weights and then he was there for the other two edges.",
            "You would say I don't know about as costs.",
            "An another element of this quick learner is that the agent is encouraged to explore the unknown edges, and so we explore it and take that path and now I can observe the zero 'cause of the graph and then now the agent is able to learn the minimum cost path.",
            "So in this case, which you can see that why is important to for the agent to know whether his fictions right or not.",
            "An also in this case you can see the generalization allows the agent to avoid visiting every edge in this.",
            "While allowing the agent to find."
        ],
        [
            "Minimum cost power.",
            "Alright, so let's make this."
        ],
        [
            "Process more formal.",
            "Here's a little bit notation, actually.",
            "Most of notation we're using this talk so quickest are supervised learning framework, as in other settings we have input set X offset Y and a quick learner tries to find the relation, but Maps inputs X2 output Y.",
            "For example, in a graph problem we saw just now we're trying.",
            "We're trying to predict the S cost given the input vectors of that edge.",
            "OK, and we also have some set called the observation step.",
            "See I'm going to talk about that in the next slide.",
            "So the agent also has hypothesis class which is set of hypothesis or relations between inputs and outputs that agent considers.",
            "For example, the causes the linear inputs.",
            "So this is an example.",
            "Can we assume that the target hypothesis is in this hypothesis class?",
            "In sometimes this is called realized realizable assumption.",
            "And finally we also need a special symbol just assemble.",
            "It says I don't know.",
            "So when you see this symbol in this slide and you know what it means is I don't know."
        ],
        [
            "OK, so this is the product of this learning framework at the beginning.",
            "The learner and the problem or the environment are given parameters epsilon.",
            "The error parameter down to the confidence parameter and H hypothesis class.",
            "And then the environment is allowed to pick some target hypothesis, each star secretly and ever serverly.",
            "And then the environment picks and input and gives it to the learner and learner has two choices.",
            "It can either say I don't know that is output.",
            "Or he can say I know this output and then then I make a prediction.",
            "It is says it says I don't know.",
            "Then the environment will give the target hypothesis value Y which is a star of X in the deterministic case or in the stochastic case this Y is corrupted by white noises.",
            "But on average these expectation of these observations should be the value of the target function.",
            "So when this is done then you will go back to return with the environment, takes a turn and then picks another input and then gives it a learner and the learner has two choices and this repeat forever.",
            "Only succeeds in the quick sense if the two things happens.",
            "The first thing is that with high confidence the operations make by the agent must be correct, meaning that they differ.",
            "The prediction and the true value differ by at most epsilon and the second requirement is that the number of I don't knows sent by the agent must be bounded by a small number, and in this case require that the number is bounded by a polynomial function in the in the parameters and the dimension of their measures.",
            "How complex or how large the hypothesis set is.",
            "For example, in case it might be the size of the hypothesis, or in more complicated cases it could be like a pack, it could be a busy dimension, things like that.",
            "So here's the."
        ],
        [
            "We compare the quick framework to previous to previous to previous Framework, core pack and Mistake bound and be that's really quick.",
            "Combines elements from both frameworks in a quick pack framework, the learner receives ID.",
            "Samples are the inputs and every input has the associated labels and learner is able to learn from a polynomial or small amount of training data.",
            "The purple ones up there an after the training phase it can start making correct predictions.",
            "The green blocks there.",
            "In a mistake that model the learner always make prediction.",
            "There's no distinction between the training phase or testing phase and learning expression all the time.",
            "And when it makes a mistake, the learner tells him the right label.",
            "An requirement in mistake bound is that the number of mistakes made by the agent, the whole run, no matter how long it is, must be bounded by simply normal or small number.",
            "An this mistake model, the inputs can be chosen adversely, Ann.",
            "So in our quick model it combines elements from both models, for example in similar to mistake bound inputs can be chosen obviously and the labels are available when this agent says I don't know instead of when instead of.",
            "Being available all the time are similar to pack when whenever the learner makes a prediction, it must be correct with high probability.",
            "And in the paper we show that show an example that we argue that we have a quick learner.",
            "You can converge the mistake bound learner and is also well known in the field that when you have a mistake now learner, you can turn it into a pack loner.",
            "The other direction doesn't work well.",
            "So which that means what it means is that quick framework is more.",
            "Is stricter than mistake while model which is.",
            "Likely to be stricter than the pack model.",
            "And so it."
        ],
        [
            "Rest of the talk I'm going to go over some basic, quick, learnable classes.",
            "An then describe how we can combine this quick learners to produce more powerful, quick learners to solve interesting problems.",
            "For example in reinforcement learning.",
            "That's an example of picking the factor MVP learning problem."
        ],
        [
            "Yeah."
        ],
        [
            "So here's the first case is probably the simplest case, so here the inputs or hypothesis space or finite and the target function is domestic.",
            "So imagine that you are bar owner and the bar is frequented by N patterns and one of them is the instigator.",
            "Whenever it shows up, there's a fight.",
            "Unless there's another guy called Peacemaker, is there to prevent despite and now your task is that.",
            "Given the subgroup of patterns in the bar you want to predict whether there's a fight or not, so that maybe you can call the 911 beforehand.",
            "OK, since the problem is easy, so in a straightforward algorithm is called memorization.",
            "So basically, the algorithm memorizes the outcome for each of the possible inputs.",
            "OK, so for example, in this case it remembers whether it's applied or not when this subgroup of patterns is in the bar.",
            "Then if it hasn't seen this subgroup of patterns in the bar before, he says I don't know an it's quite.",
            "It's easy to see that the number of I don't know is this bounded by the size of input space which is exponential in.",
            "Number patterns unfortunately better algorithm called enumeration works this way.",
            "Basically, it treats the hypothesis in this hypothesis class as experts an OK. Now, given the input an hour, consult experts and see whether there's there's discrete disagreements among the experts.",
            "If all the experts say the make the same prediction, and since one of them is right, then I can make a safe prediction if they expose this phone disagree with each other, then I'll say I don't know and I use the observed labels too.",
            "Cutie long experts and the number I don't know is.",
            "Here is the most the number of hypothesis in the class minus one in this case is predominant, which is good."
        ],
        [
            "OK, now let's look at another example where is finite, but it's noisy.",
            "Is the coin learning problem you have a biased coin?",
            "You want to predict the probability that you see is ahead when you flip the coin.",
            "And here the observations noisy is sort of observing the probability of coin flip of the head and what you observe is whether it's a head or tail.",
            "And the algorithm simple.",
            "So at the beginning of learning and predict, I don't know for that many of times.",
            "And then it will use the relative frequency and this samples in these observations.",
            "Then as the descriptions afterwards and the correctness of this algorithm is bound, it's guaranteed by the famous hopping bound.",
            "Is this inequality for concentration.",
            "So the number I don't know is this is polynomial in the parameters.",
            "Although this algorithm this problem.",
            "Is very simple.",
            "This algorithm turns out to be a building block for many of the stochastic problems we look at later."
        ],
        [
            "Hey, an actually the quickest not designed for solving simple problems and we can actually use this solve more complicated problems.",
            "For example in the paper we show how to learn how to quick learn the distance to a known point in the D dimensional space in our paper and you AI we show how to quick learn multivariate Gaussian distributions and also some previous work by strong learning Maps.",
            "Last year that shows how we can quickly learn more."
        ],
        [
            "Linear functions.",
            "OK, so we so now we're ready to do more interesting stuffs by combining a quick learners.",
            "And apply it to model based reinforcement learning."
        ],
        [
            "And to do that I need some background rotation information about MPs and motivation reinforcement.",
            "Learning an MVP is a Markov decision process, which is the triple things like that.",
            "An S is the set of states a set of actions.",
            "Auntie Anne are transitions will work functions and gammas discount factor.",
            "The details are not important.",
            "What's important here is that we can assume that only the transitions of this Markov decision process is unknown, and the transition here T of prime given essay means that means the probability of going to the new status prime when the agent takes an action A in the states.",
            "Hey, send an important observation is that when we can quickly learn this transition function or the transition probabilities we can find and beta fish and algorithm similar to our mix of breath and intangibles that.",
            "They can learn this in this environment efficiently.",
            "And the idea is.",
            "I'm not going to in the details, I'm just going to give you some idea what this algorithm does so at any.",
            "Time of decision making.",
            "The agent looks at the space and see whether the samples can allows.",
            "Age allows the agent to give predictions.",
            "Accurate predictions about this transition functions and petition the state space into two parts.",
            "The nonpartisan, unknown parts for the non PTSD agent can make quite accurate predictions, so users empirical predictions.",
            "T hat for the unknown parts.",
            "The agent knows cannot make valid prediction or accurate predictions, and then he assigns.",
            "VMAX which is a which means the region is maximally rewarding.",
            "So the agent either so the agent assumes that when something is unknown there must be something best possible having it there.",
            "But this is called the optimism in the face of uncertainty principle in reinforcement learning and the property of this principle is that the agent can either explore unknown regions because of the Vmax trick over there, or explore the known regions.",
            "By wandering in the green part.",
            "And since the number if we can quickly learn the transition probabilities, meaning that we can.",
            "We will say I don't know for a small amount of times in this MDP and then it means the first step.",
            "The exploration steps is smaller because it's bounded by the number of.",
            "Polynomial function."
        ],
        [
            "The number of I don't knows.",
            "So now I'll show you how we can use the simple algorithm call input partition to learn finite MDP's.",
            "So the problem here is that we have a set of experts that can quickly learn different subsets of inputs.",
            "For example, I have 3 sub learners here.",
            "One can learn the price of fruits, the other can learn kind of learn the price of diamonds the other can quick learn the price of lawyers and as a learner I want to quickly learn the price of.",
            "Something and something could be a fruit or diamond or or oil.",
            "And the algorithm is quite simply, basically consult the appropriate learners to make predictions.",
            "For example, if the morning gives and pineapple and Agent knows that this is a foot and it gives it to the foot learner and the full owner says is $5, then I can safely predict $5 because that's the right quick learner and next time someone own food comes up and quickly and says I don't know about this food, I can predict this price and then the learner can.",
            "Just say I don't know so.",
            "So this algorithm simple.",
            "But how can I use it to solve interesting problems like in front of GPS?",
            "So it turns out that learning the transition probability and fun and DP can be viewed as esquerre a instances of point learning problems in each corner instance is trying to predict this probability.",
            "We can view as reaching as prime in status by applying a as flipping a coin.",
            "If I reach if the agent which is this day as prime, then we interpreter as ahead.",
            "Otherwise we interpret as her tail.",
            "So this is actually a coin learning problem.",
            "And we we can quick learn this final MVP by using input partition over the coin learning algorithm.",
            "And this is actually the key inside shared by many priority algorithms like EQ by current sensing onomics by Fred."
        ],
        [
            "And ten holes.",
            "So here's another algorithm that combines learners.",
            "We have again we have different kinds of learners for different kinds of inputs and outputs, and now we try to combine them.",
            "Learns the cross.",
            "Learn the mapping between the cross part of inputs to the cross part of outputs and again the.",
            "OPS.",
            "So the learner just comes out the appropriate sub learners an it was and then combines the outputs.",
            "Together into vector and return.",
            "Even a scenario where one of the learner says I don't know, then the output of the learners source.",
            "I don't know and the number of total number of I don't know set by the learner is a sum of the I don't know over all these sub learners bother some lawmakers."
        ],
        [
            "This album is sufficient and it turns out that this is a simple algorithm can be used to do a lot of things.",
            "For example in finance tips would have showed it.",
            "We can do quick learner finite MDP by using quite learning with input position.",
            "We can also learn linear MVP where the transitions are governed by system of linear equations.",
            "We can also learn type MPs where the transitions depends on the type of states rather than individual states.",
            "An in factory Q algorithm by currents and color.",
            "They use something similar to quick Learner factor MVP.",
            "When the factorization structure is known, you might wonder what happens if the structure is unknown.",
            "And to do this we need."
        ],
        [
            "Another algorithm called Union.",
            "The algorithm is this.",
            "We have again we have different sets of inputs.",
            "Are there different sets of hypothesis classes?",
            "And then each hypothesis class allows we have an agent to learn each hypothesis class.",
            "Now the question is how can we combine the learners to?",
            "Quick learn to Union of order hypothesis class classes.",
            "So in this cartoon we have three agents.",
            "One can learn C + X function where C is unknown.",
            "An one can learn C * X where C is also known and the third one can quickly and absolute.",
            "Function and in the first case in the first step, when the environment tells that input is 2 and two of the learners as I don't know because seeing there is is unknown, but the absolute function learner says 2 because it is only one function in the hypothesis class.",
            "But then since the outputs are don't disagree with each other, the learner says I don't know.",
            "But then the environments tells the agent was straight output and then you can.",
            "You can realize that the actual output is 4, but that guy there says 2, so it must be a wrong runner.",
            "So we killed a guy and then the next step we have observed input zero and again the two remaining learners predict differently.",
            "We said I don't know.",
            "And then we observed the right output which is 2 and then we killed the green one and now we have the last one which is the right one.",
            "OK. Can this process can actually be gentle?"
        ],
        [
            "Two stochastic case.",
            "And now I will show you the last part of the talk.",
            "I'll show you how we can quick learn factor MPs by using the simple combination algorithms.",
            "So by quick by factor amps it means that the transitions of transitions of the MPs are can be modeled by dynamic base net VPN.",
            "OK, so in this graph an it's every state in this MDP is actually a lecture of state components.",
            "For example, here is the components here.",
            "Anna DPM can tell you the transition probabilities.",
            "So here each each of the sub I prime the next stage component depends on only on this previous a subset of the previous nodes called apparent when the sets of parents is small.",
            "When parents are small and then the number.",
            "The parameters to represent this MD pH much smaller than the original flat MP representation, and this is often used in practice to reduce the size of MVP and to improve learning so the problems in learning effective DPS.",
            "Sure here.",
            "So first thing is, how can we discover the patterns of each nodes?",
            "The second is how can we combine learners for different nodes too quick, learn the whole vector state vector and the third one is.",
            "How can we estimate the next day probability given the power?"
        ],
        [
            "OK. OK, Ann, so here's the here's a Four layer algorithm that can be used to solve the problem by combining the work we have done so far.",
            "So the algorithm has four layers.",
            "The first layer, called it noisy union, is similar to union algorithm.",
            "That show is just now and then it it can be used to discover the parents and then the cross product algorithm can be used to learn the conditional probability table for each of the next nodes and finally the input partition can be used to.",
            "To reduce the entries in this conditional probability table into individual probabilities and then use the client learning to learn the probabilities and this significantly improve on the state of the art result in last year's drought.",
            "Broken Lipman.",
            "An it also solves an important problem.",
            "Important open problem by Carnes and Carter.",
            "When they set the most interesting one is to allow the agent to learn a model structure as well as the parameters.",
            "So structure learning problem and then the second one thing to emphasize.",
            "That integration of these ideas with the problem of exploration exploitation is far from trivial and we show how we can do this by combining very simple routines and this quick frame."
        ],
        [
            "OK."
        ],
        [
            "Kate can conclude the paper and some open a lot of open problems.",
            "In this paper, we like to emphasize this one where.",
            "What's the difference between a deterministic quick setting and stochastic quick setting?",
            "So this table summarizes the differences in the number of.",
            "I don't knows in the plastic case, and a simpler dismissed the case and open question is how is there a systematic way to convert the deterministic quick learner to the stochastic cases?"
        ],
        [
            "So to conclude the talk, we have to find a quick learner with quick framework for self aware learning which is implied by prior reinforcement learning algorithms.",
            "It also has potential application to other learning problems like active learning, anomaly detection etc.",
            "And then we show how we can we can quickly learn some hypothesis classes and how to combine this quick learners to produce powerful algorithms to solve interesting problems in reinforcement learning.",
            "OK thanks, so like to take pictures.",
            "Questions.",
            "Quit.",
            "Right?",
            "OK. Or maybe you mean.",
            "You mean, yes, I'm sorry.",
            "You mean the world has always returned the labels.",
            "Realizable case right?",
            "Something about how to?",
            "As we continue to talk about having framework.",
            "So that's, uh, yeah, that's a quick question.",
            "So we have also considered this problem an with some partial results.",
            "To adjust the problem where it store may not be an issue.",
            "And then I put in general, we don't have a good solution yet and this one is actually one of the open problems.",
            "I have a lost soul.",
            "It's intriguing is the factor than the example, because I think the hard part of learning a structural factors that we need is the part that you might have too many edges, or you don't know the structures because actually the realisable case issue that George is raising, so I'm not sure if that I think that's not addressed.",
            "It's not OK, so in apartment just now we assume that the deep structure it's simple in the sense that the number of parents it's bounded by K some constant.",
            "And this is actually assumption to make many of the structure learning based, net structure, learning literature, including in one the factory Cuban Factor or Max and also out of papers in.",
            "Graphical model running.",
            "And in general this is NP hard, so.",
            "OK thanks.",
            "OK, so."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I thought the paper is know what it knows, a framework for self.",
                    "label": 1
                },
                {
                    "sent": "Michael Littman and Thomas Wash and let's congratulate them.",
                    "label": 0
                },
                {
                    "sent": "Lihong will be giving the talk.",
                    "label": 0
                },
                {
                    "sent": "Can you hear me?",
                    "label": 0
                },
                {
                    "sent": "OK, not hear me.",
                    "label": 0
                },
                {
                    "sent": "OK, now you hear me OK thanks, thanks for introduction.",
                    "label": 0
                },
                {
                    "sent": "Cause so the title is knows what he knows is the framework for software learning this joint.",
                    "label": 0
                },
                {
                    "sent": "By Michael Lipman.",
                    "label": 0
                },
                {
                    "sent": "Tom Wash over there.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me give you a quick overview of the quick and quick is an acronym of Four Knows what he knows and what it is, is a learning framework when the learner has to choose samples actively.",
                    "label": 1
                },
                {
                    "sent": "For example, in selective sampling, the learner only sees label when it buys are labeled an embedded problems.",
                    "label": 0
                },
                {
                    "sent": "The learner can only see the payoff when he chooses the arm, and in more general setting like reinforcement learning, we can only observe the transition or reward of the state when we.",
                    "label": 1
                },
                {
                    "sent": "Visit the state takes an action there.",
                    "label": 0
                },
                {
                    "sent": "An in this quick setting requires that the learner must be aware of the prediction error so that this is the key to balance exploration exploitation for learner in this unknown environment, and it actually unifies a lot of these recent pack MDP work in reinforcement learning, and I'm.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And they're going to detail about it.",
                    "label": 0
                },
                {
                    "sent": "So here's an outline.",
                    "label": 0
                },
                {
                    "sent": "First, given motivating example and then define what quick is followed by some very simple quick examples and then I'll show you how we can combine quick learners to produce powerful algorithms for data vision.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm learning.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's another example is an episodic task, and the task he is to is to find the shortest or the minimum cost path the agent is aware of the topology of the graph.",
                    "label": 1
                },
                {
                    "sent": "He knows the vectors associated to each edge and the cause of an edge is linear is linear in the vector, but the agent doesn't know the weight of the other ways.",
                    "label": 0
                },
                {
                    "sent": "That gives you the cost.",
                    "label": 0
                },
                {
                    "sent": "So in this case the star is 120 but Agent doesn't know that.",
                    "label": 0
                },
                {
                    "sent": "Another question is how can agent find is minimum cost path at the beginning?",
                    "label": 0
                },
                {
                    "sent": "The agent knows nothing about this edge costs and then he may take a random path.",
                    "label": 0
                },
                {
                    "sent": "For example the middle one because as the smallest number of edges.",
                    "label": 0
                },
                {
                    "sent": "So maybe this is the best one and these are the rewards you observe.",
                    "label": 0
                },
                {
                    "sent": "The cause it observes 33331 OK and if you run the standard square linear regression algorithm it gives a solution.",
                    "label": 0
                },
                {
                    "sent": "A prediction over the wait an.",
                    "label": 1
                },
                {
                    "sent": "Usually we can make a prediction about the other edge cost.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that.",
                    "label": 0
                },
                {
                    "sent": "The two ones that up there is wrong and.",
                    "label": 0
                },
                {
                    "sent": "And actually, if you look at the optimal weight W star, the edge cost up, there are zero both 0, so the minimum cost path is actually the upper 1 instead of the middle one.",
                    "label": 1
                },
                {
                    "sent": "And in this case this algorithm fails to find a minimum.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "'cause now OK. Now let's see what a quick agent would do.",
                    "label": 0
                },
                {
                    "sent": "So in a quick quick Asian tries to reason about uncertainty in this prediction about as costs for the these two edges below 2 one, I notice that the 01 is quite obvious because the cost vector is zero an for the two one the cost vector is actually a difference between two of the other edges he has visited before and therefore the cost of that edges.",
                    "label": 0
                },
                {
                    "sent": "The difference between the two edges cut edge costs because the edge 'cause it's linear in the weights and then he was there for the other two edges.",
                    "label": 0
                },
                {
                    "sent": "You would say I don't know about as costs.",
                    "label": 0
                },
                {
                    "sent": "An another element of this quick learner is that the agent is encouraged to explore the unknown edges, and so we explore it and take that path and now I can observe the zero 'cause of the graph and then now the agent is able to learn the minimum cost path.",
                    "label": 1
                },
                {
                    "sent": "So in this case, which you can see that why is important to for the agent to know whether his fictions right or not.",
                    "label": 0
                },
                {
                    "sent": "An also in this case you can see the generalization allows the agent to avoid visiting every edge in this.",
                    "label": 1
                },
                {
                    "sent": "While allowing the agent to find.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Minimum cost power.",
                    "label": 0
                },
                {
                    "sent": "Alright, so let's make this.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Process more formal.",
                    "label": 0
                },
                {
                    "sent": "Here's a little bit notation, actually.",
                    "label": 0
                },
                {
                    "sent": "Most of notation we're using this talk so quickest are supervised learning framework, as in other settings we have input set X offset Y and a quick learner tries to find the relation, but Maps inputs X2 output Y.",
                    "label": 0
                },
                {
                    "sent": "For example, in a graph problem we saw just now we're trying.",
                    "label": 0
                },
                {
                    "sent": "We're trying to predict the S cost given the input vectors of that edge.",
                    "label": 0
                },
                {
                    "sent": "OK, and we also have some set called the observation step.",
                    "label": 0
                },
                {
                    "sent": "See I'm going to talk about that in the next slide.",
                    "label": 0
                },
                {
                    "sent": "So the agent also has hypothesis class which is set of hypothesis or relations between inputs and outputs that agent considers.",
                    "label": 0
                },
                {
                    "sent": "For example, the causes the linear inputs.",
                    "label": 0
                },
                {
                    "sent": "So this is an example.",
                    "label": 0
                },
                {
                    "sent": "Can we assume that the target hypothesis is in this hypothesis class?",
                    "label": 0
                },
                {
                    "sent": "In sometimes this is called realized realizable assumption.",
                    "label": 0
                },
                {
                    "sent": "And finally we also need a special symbol just assemble.",
                    "label": 0
                },
                {
                    "sent": "It says I don't know.",
                    "label": 1
                },
                {
                    "sent": "So when you see this symbol in this slide and you know what it means is I don't know.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is the product of this learning framework at the beginning.",
                    "label": 0
                },
                {
                    "sent": "The learner and the problem or the environment are given parameters epsilon.",
                    "label": 0
                },
                {
                    "sent": "The error parameter down to the confidence parameter and H hypothesis class.",
                    "label": 0
                },
                {
                    "sent": "And then the environment is allowed to pick some target hypothesis, each star secretly and ever serverly.",
                    "label": 0
                },
                {
                    "sent": "And then the environment picks and input and gives it to the learner and learner has two choices.",
                    "label": 0
                },
                {
                    "sent": "It can either say I don't know that is output.",
                    "label": 0
                },
                {
                    "sent": "Or he can say I know this output and then then I make a prediction.",
                    "label": 0
                },
                {
                    "sent": "It is says it says I don't know.",
                    "label": 1
                },
                {
                    "sent": "Then the environment will give the target hypothesis value Y which is a star of X in the deterministic case or in the stochastic case this Y is corrupted by white noises.",
                    "label": 0
                },
                {
                    "sent": "But on average these expectation of these observations should be the value of the target function.",
                    "label": 0
                },
                {
                    "sent": "So when this is done then you will go back to return with the environment, takes a turn and then picks another input and then gives it a learner and the learner has two choices and this repeat forever.",
                    "label": 0
                },
                {
                    "sent": "Only succeeds in the quick sense if the two things happens.",
                    "label": 0
                },
                {
                    "sent": "The first thing is that with high confidence the operations make by the agent must be correct, meaning that they differ.",
                    "label": 0
                },
                {
                    "sent": "The prediction and the true value differ by at most epsilon and the second requirement is that the number of I don't knows sent by the agent must be bounded by a small number, and in this case require that the number is bounded by a polynomial function in the in the parameters and the dimension of their measures.",
                    "label": 0
                },
                {
                    "sent": "How complex or how large the hypothesis set is.",
                    "label": 0
                },
                {
                    "sent": "For example, in case it might be the size of the hypothesis, or in more complicated cases it could be like a pack, it could be a busy dimension, things like that.",
                    "label": 0
                },
                {
                    "sent": "So here's the.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We compare the quick framework to previous to previous to previous Framework, core pack and Mistake bound and be that's really quick.",
                    "label": 0
                },
                {
                    "sent": "Combines elements from both frameworks in a quick pack framework, the learner receives ID.",
                    "label": 0
                },
                {
                    "sent": "Samples are the inputs and every input has the associated labels and learner is able to learn from a polynomial or small amount of training data.",
                    "label": 0
                },
                {
                    "sent": "The purple ones up there an after the training phase it can start making correct predictions.",
                    "label": 0
                },
                {
                    "sent": "The green blocks there.",
                    "label": 0
                },
                {
                    "sent": "In a mistake that model the learner always make prediction.",
                    "label": 0
                },
                {
                    "sent": "There's no distinction between the training phase or testing phase and learning expression all the time.",
                    "label": 0
                },
                {
                    "sent": "And when it makes a mistake, the learner tells him the right label.",
                    "label": 0
                },
                {
                    "sent": "An requirement in mistake bound is that the number of mistakes made by the agent, the whole run, no matter how long it is, must be bounded by simply normal or small number.",
                    "label": 0
                },
                {
                    "sent": "An this mistake model, the inputs can be chosen adversely, Ann.",
                    "label": 0
                },
                {
                    "sent": "So in our quick model it combines elements from both models, for example in similar to mistake bound inputs can be chosen obviously and the labels are available when this agent says I don't know instead of when instead of.",
                    "label": 0
                },
                {
                    "sent": "Being available all the time are similar to pack when whenever the learner makes a prediction, it must be correct with high probability.",
                    "label": 0
                },
                {
                    "sent": "And in the paper we show that show an example that we argue that we have a quick learner.",
                    "label": 0
                },
                {
                    "sent": "You can converge the mistake bound learner and is also well known in the field that when you have a mistake now learner, you can turn it into a pack loner.",
                    "label": 0
                },
                {
                    "sent": "The other direction doesn't work well.",
                    "label": 0
                },
                {
                    "sent": "So which that means what it means is that quick framework is more.",
                    "label": 0
                },
                {
                    "sent": "Is stricter than mistake while model which is.",
                    "label": 0
                },
                {
                    "sent": "Likely to be stricter than the pack model.",
                    "label": 0
                },
                {
                    "sent": "And so it.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rest of the talk I'm going to go over some basic, quick, learnable classes.",
                    "label": 0
                },
                {
                    "sent": "An then describe how we can combine this quick learners to produce more powerful, quick learners to solve interesting problems.",
                    "label": 1
                },
                {
                    "sent": "For example in reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "That's an example of picking the factor MVP learning problem.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the first case is probably the simplest case, so here the inputs or hypothesis space or finite and the target function is domestic.",
                    "label": 0
                },
                {
                    "sent": "So imagine that you are bar owner and the bar is frequented by N patterns and one of them is the instigator.",
                    "label": 1
                },
                {
                    "sent": "Whenever it shows up, there's a fight.",
                    "label": 0
                },
                {
                    "sent": "Unless there's another guy called Peacemaker, is there to prevent despite and now your task is that.",
                    "label": 0
                },
                {
                    "sent": "Given the subgroup of patterns in the bar you want to predict whether there's a fight or not, so that maybe you can call the 911 beforehand.",
                    "label": 1
                },
                {
                    "sent": "OK, since the problem is easy, so in a straightforward algorithm is called memorization.",
                    "label": 1
                },
                {
                    "sent": "So basically, the algorithm memorizes the outcome for each of the possible inputs.",
                    "label": 0
                },
                {
                    "sent": "OK, so for example, in this case it remembers whether it's applied or not when this subgroup of patterns is in the bar.",
                    "label": 0
                },
                {
                    "sent": "Then if it hasn't seen this subgroup of patterns in the bar before, he says I don't know an it's quite.",
                    "label": 0
                },
                {
                    "sent": "It's easy to see that the number of I don't know is this bounded by the size of input space which is exponential in.",
                    "label": 0
                },
                {
                    "sent": "Number patterns unfortunately better algorithm called enumeration works this way.",
                    "label": 0
                },
                {
                    "sent": "Basically, it treats the hypothesis in this hypothesis class as experts an OK. Now, given the input an hour, consult experts and see whether there's there's discrete disagreements among the experts.",
                    "label": 0
                },
                {
                    "sent": "If all the experts say the make the same prediction, and since one of them is right, then I can make a safe prediction if they expose this phone disagree with each other, then I'll say I don't know and I use the observed labels too.",
                    "label": 0
                },
                {
                    "sent": "Cutie long experts and the number I don't know is.",
                    "label": 0
                },
                {
                    "sent": "Here is the most the number of hypothesis in the class minus one in this case is predominant, which is good.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now let's look at another example where is finite, but it's noisy.",
                    "label": 0
                },
                {
                    "sent": "Is the coin learning problem you have a biased coin?",
                    "label": 0
                },
                {
                    "sent": "You want to predict the probability that you see is ahead when you flip the coin.",
                    "label": 1
                },
                {
                    "sent": "And here the observations noisy is sort of observing the probability of coin flip of the head and what you observe is whether it's a head or tail.",
                    "label": 1
                },
                {
                    "sent": "And the algorithm simple.",
                    "label": 0
                },
                {
                    "sent": "So at the beginning of learning and predict, I don't know for that many of times.",
                    "label": 0
                },
                {
                    "sent": "And then it will use the relative frequency and this samples in these observations.",
                    "label": 0
                },
                {
                    "sent": "Then as the descriptions afterwards and the correctness of this algorithm is bound, it's guaranteed by the famous hopping bound.",
                    "label": 0
                },
                {
                    "sent": "Is this inequality for concentration.",
                    "label": 0
                },
                {
                    "sent": "So the number I don't know is this is polynomial in the parameters.",
                    "label": 0
                },
                {
                    "sent": "Although this algorithm this problem.",
                    "label": 0
                },
                {
                    "sent": "Is very simple.",
                    "label": 0
                },
                {
                    "sent": "This algorithm turns out to be a building block for many of the stochastic problems we look at later.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hey, an actually the quickest not designed for solving simple problems and we can actually use this solve more complicated problems.",
                    "label": 0
                },
                {
                    "sent": "For example in the paper we show how to learn how to quick learn the distance to a known point in the D dimensional space in our paper and you AI we show how to quick learn multivariate Gaussian distributions and also some previous work by strong learning Maps.",
                    "label": 1
                },
                {
                    "sent": "Last year that shows how we can quickly learn more.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Linear functions.",
                    "label": 0
                },
                {
                    "sent": "OK, so we so now we're ready to do more interesting stuffs by combining a quick learners.",
                    "label": 0
                },
                {
                    "sent": "And apply it to model based reinforcement learning.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to do that I need some background rotation information about MPs and motivation reinforcement.",
                    "label": 0
                },
                {
                    "sent": "Learning an MVP is a Markov decision process, which is the triple things like that.",
                    "label": 1
                },
                {
                    "sent": "An S is the set of states a set of actions.",
                    "label": 0
                },
                {
                    "sent": "Auntie Anne are transitions will work functions and gammas discount factor.",
                    "label": 0
                },
                {
                    "sent": "The details are not important.",
                    "label": 0
                },
                {
                    "sent": "What's important here is that we can assume that only the transitions of this Markov decision process is unknown, and the transition here T of prime given essay means that means the probability of going to the new status prime when the agent takes an action A in the states.",
                    "label": 0
                },
                {
                    "sent": "Hey, send an important observation is that when we can quickly learn this transition function or the transition probabilities we can find and beta fish and algorithm similar to our mix of breath and intangibles that.",
                    "label": 0
                },
                {
                    "sent": "They can learn this in this environment efficiently.",
                    "label": 0
                },
                {
                    "sent": "And the idea is.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to in the details, I'm just going to give you some idea what this algorithm does so at any.",
                    "label": 0
                },
                {
                    "sent": "Time of decision making.",
                    "label": 0
                },
                {
                    "sent": "The agent looks at the space and see whether the samples can allows.",
                    "label": 0
                },
                {
                    "sent": "Age allows the agent to give predictions.",
                    "label": 0
                },
                {
                    "sent": "Accurate predictions about this transition functions and petition the state space into two parts.",
                    "label": 0
                },
                {
                    "sent": "The nonpartisan, unknown parts for the non PTSD agent can make quite accurate predictions, so users empirical predictions.",
                    "label": 0
                },
                {
                    "sent": "T hat for the unknown parts.",
                    "label": 0
                },
                {
                    "sent": "The agent knows cannot make valid prediction or accurate predictions, and then he assigns.",
                    "label": 0
                },
                {
                    "sent": "VMAX which is a which means the region is maximally rewarding.",
                    "label": 0
                },
                {
                    "sent": "So the agent either so the agent assumes that when something is unknown there must be something best possible having it there.",
                    "label": 0
                },
                {
                    "sent": "But this is called the optimism in the face of uncertainty principle in reinforcement learning and the property of this principle is that the agent can either explore unknown regions because of the Vmax trick over there, or explore the known regions.",
                    "label": 1
                },
                {
                    "sent": "By wandering in the green part.",
                    "label": 0
                },
                {
                    "sent": "And since the number if we can quickly learn the transition probabilities, meaning that we can.",
                    "label": 0
                },
                {
                    "sent": "We will say I don't know for a small amount of times in this MDP and then it means the first step.",
                    "label": 0
                },
                {
                    "sent": "The exploration steps is smaller because it's bounded by the number of.",
                    "label": 0
                },
                {
                    "sent": "Polynomial function.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The number of I don't knows.",
                    "label": 0
                },
                {
                    "sent": "So now I'll show you how we can use the simple algorithm call input partition to learn finite MDP's.",
                    "label": 0
                },
                {
                    "sent": "So the problem here is that we have a set of experts that can quickly learn different subsets of inputs.",
                    "label": 0
                },
                {
                    "sent": "For example, I have 3 sub learners here.",
                    "label": 0
                },
                {
                    "sent": "One can learn the price of fruits, the other can learn kind of learn the price of diamonds the other can quick learn the price of lawyers and as a learner I want to quickly learn the price of.",
                    "label": 0
                },
                {
                    "sent": "Something and something could be a fruit or diamond or or oil.",
                    "label": 0
                },
                {
                    "sent": "And the algorithm is quite simply, basically consult the appropriate learners to make predictions.",
                    "label": 0
                },
                {
                    "sent": "For example, if the morning gives and pineapple and Agent knows that this is a foot and it gives it to the foot learner and the full owner says is $5, then I can safely predict $5 because that's the right quick learner and next time someone own food comes up and quickly and says I don't know about this food, I can predict this price and then the learner can.",
                    "label": 0
                },
                {
                    "sent": "Just say I don't know so.",
                    "label": 0
                },
                {
                    "sent": "So this algorithm simple.",
                    "label": 0
                },
                {
                    "sent": "But how can I use it to solve interesting problems like in front of GPS?",
                    "label": 0
                },
                {
                    "sent": "So it turns out that learning the transition probability and fun and DP can be viewed as esquerre a instances of point learning problems in each corner instance is trying to predict this probability.",
                    "label": 0
                },
                {
                    "sent": "We can view as reaching as prime in status by applying a as flipping a coin.",
                    "label": 0
                },
                {
                    "sent": "If I reach if the agent which is this day as prime, then we interpreter as ahead.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we interpret as her tail.",
                    "label": 0
                },
                {
                    "sent": "So this is actually a coin learning problem.",
                    "label": 0
                },
                {
                    "sent": "And we we can quick learn this final MVP by using input partition over the coin learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "And this is actually the key inside shared by many priority algorithms like EQ by current sensing onomics by Fred.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And ten holes.",
                    "label": 0
                },
                {
                    "sent": "So here's another algorithm that combines learners.",
                    "label": 0
                },
                {
                    "sent": "We have again we have different kinds of learners for different kinds of inputs and outputs, and now we try to combine them.",
                    "label": 0
                },
                {
                    "sent": "Learns the cross.",
                    "label": 0
                },
                {
                    "sent": "Learn the mapping between the cross part of inputs to the cross part of outputs and again the.",
                    "label": 0
                },
                {
                    "sent": "OPS.",
                    "label": 0
                },
                {
                    "sent": "So the learner just comes out the appropriate sub learners an it was and then combines the outputs.",
                    "label": 0
                },
                {
                    "sent": "Together into vector and return.",
                    "label": 0
                },
                {
                    "sent": "Even a scenario where one of the learner says I don't know, then the output of the learners source.",
                    "label": 0
                },
                {
                    "sent": "I don't know and the number of total number of I don't know set by the learner is a sum of the I don't know over all these sub learners bother some lawmakers.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This album is sufficient and it turns out that this is a simple algorithm can be used to do a lot of things.",
                    "label": 0
                },
                {
                    "sent": "For example in finance tips would have showed it.",
                    "label": 0
                },
                {
                    "sent": "We can do quick learner finite MDP by using quite learning with input position.",
                    "label": 0
                },
                {
                    "sent": "We can also learn linear MVP where the transitions are governed by system of linear equations.",
                    "label": 0
                },
                {
                    "sent": "We can also learn type MPs where the transitions depends on the type of states rather than individual states.",
                    "label": 0
                },
                {
                    "sent": "An in factory Q algorithm by currents and color.",
                    "label": 0
                },
                {
                    "sent": "They use something similar to quick Learner factor MVP.",
                    "label": 0
                },
                {
                    "sent": "When the factorization structure is known, you might wonder what happens if the structure is unknown.",
                    "label": 0
                },
                {
                    "sent": "And to do this we need.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another algorithm called Union.",
                    "label": 0
                },
                {
                    "sent": "The algorithm is this.",
                    "label": 0
                },
                {
                    "sent": "We have again we have different sets of inputs.",
                    "label": 0
                },
                {
                    "sent": "Are there different sets of hypothesis classes?",
                    "label": 0
                },
                {
                    "sent": "And then each hypothesis class allows we have an agent to learn each hypothesis class.",
                    "label": 0
                },
                {
                    "sent": "Now the question is how can we combine the learners to?",
                    "label": 0
                },
                {
                    "sent": "Quick learn to Union of order hypothesis class classes.",
                    "label": 0
                },
                {
                    "sent": "So in this cartoon we have three agents.",
                    "label": 0
                },
                {
                    "sent": "One can learn C + X function where C is unknown.",
                    "label": 0
                },
                {
                    "sent": "An one can learn C * X where C is also known and the third one can quickly and absolute.",
                    "label": 0
                },
                {
                    "sent": "Function and in the first case in the first step, when the environment tells that input is 2 and two of the learners as I don't know because seeing there is is unknown, but the absolute function learner says 2 because it is only one function in the hypothesis class.",
                    "label": 0
                },
                {
                    "sent": "But then since the outputs are don't disagree with each other, the learner says I don't know.",
                    "label": 0
                },
                {
                    "sent": "But then the environments tells the agent was straight output and then you can.",
                    "label": 0
                },
                {
                    "sent": "You can realize that the actual output is 4, but that guy there says 2, so it must be a wrong runner.",
                    "label": 0
                },
                {
                    "sent": "So we killed a guy and then the next step we have observed input zero and again the two remaining learners predict differently.",
                    "label": 0
                },
                {
                    "sent": "We said I don't know.",
                    "label": 0
                },
                {
                    "sent": "And then we observed the right output which is 2 and then we killed the green one and now we have the last one which is the right one.",
                    "label": 0
                },
                {
                    "sent": "OK. Can this process can actually be gentle?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two stochastic case.",
                    "label": 0
                },
                {
                    "sent": "And now I will show you the last part of the talk.",
                    "label": 0
                },
                {
                    "sent": "I'll show you how we can quick learn factor MPs by using the simple combination algorithms.",
                    "label": 0
                },
                {
                    "sent": "So by quick by factor amps it means that the transitions of transitions of the MPs are can be modeled by dynamic base net VPN.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this graph an it's every state in this MDP is actually a lecture of state components.",
                    "label": 0
                },
                {
                    "sent": "For example, here is the components here.",
                    "label": 0
                },
                {
                    "sent": "Anna DPM can tell you the transition probabilities.",
                    "label": 0
                },
                {
                    "sent": "So here each each of the sub I prime the next stage component depends on only on this previous a subset of the previous nodes called apparent when the sets of parents is small.",
                    "label": 0
                },
                {
                    "sent": "When parents are small and then the number.",
                    "label": 0
                },
                {
                    "sent": "The parameters to represent this MD pH much smaller than the original flat MP representation, and this is often used in practice to reduce the size of MVP and to improve learning so the problems in learning effective DPS.",
                    "label": 0
                },
                {
                    "sent": "Sure here.",
                    "label": 0
                },
                {
                    "sent": "So first thing is, how can we discover the patterns of each nodes?",
                    "label": 0
                },
                {
                    "sent": "The second is how can we combine learners for different nodes too quick, learn the whole vector state vector and the third one is.",
                    "label": 0
                },
                {
                    "sent": "How can we estimate the next day probability given the power?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. OK, Ann, so here's the here's a Four layer algorithm that can be used to solve the problem by combining the work we have done so far.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm has four layers.",
                    "label": 1
                },
                {
                    "sent": "The first layer, called it noisy union, is similar to union algorithm.",
                    "label": 0
                },
                {
                    "sent": "That show is just now and then it it can be used to discover the parents and then the cross product algorithm can be used to learn the conditional probability table for each of the next nodes and finally the input partition can be used to.",
                    "label": 0
                },
                {
                    "sent": "To reduce the entries in this conditional probability table into individual probabilities and then use the client learning to learn the probabilities and this significantly improve on the state of the art result in last year's drought.",
                    "label": 1
                },
                {
                    "sent": "Broken Lipman.",
                    "label": 0
                },
                {
                    "sent": "An it also solves an important problem.",
                    "label": 0
                },
                {
                    "sent": "Important open problem by Carnes and Carter.",
                    "label": 0
                },
                {
                    "sent": "When they set the most interesting one is to allow the agent to learn a model structure as well as the parameters.",
                    "label": 1
                },
                {
                    "sent": "So structure learning problem and then the second one thing to emphasize.",
                    "label": 1
                },
                {
                    "sent": "That integration of these ideas with the problem of exploration exploitation is far from trivial and we show how we can do this by combining very simple routines and this quick frame.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Kate can conclude the paper and some open a lot of open problems.",
                    "label": 1
                },
                {
                    "sent": "In this paper, we like to emphasize this one where.",
                    "label": 1
                },
                {
                    "sent": "What's the difference between a deterministic quick setting and stochastic quick setting?",
                    "label": 0
                },
                {
                    "sent": "So this table summarizes the differences in the number of.",
                    "label": 0
                },
                {
                    "sent": "I don't knows in the plastic case, and a simpler dismissed the case and open question is how is there a systematic way to convert the deterministic quick learner to the stochastic cases?",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude the talk, we have to find a quick learner with quick framework for self aware learning which is implied by prior reinforcement learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "It also has potential application to other learning problems like active learning, anomaly detection etc.",
                    "label": 1
                },
                {
                    "sent": "And then we show how we can we can quickly learn some hypothesis classes and how to combine this quick learners to produce powerful algorithms to solve interesting problems in reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "OK thanks, so like to take pictures.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Quit.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "OK. Or maybe you mean.",
                    "label": 0
                },
                {
                    "sent": "You mean, yes, I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "You mean the world has always returned the labels.",
                    "label": 0
                },
                {
                    "sent": "Realizable case right?",
                    "label": 0
                },
                {
                    "sent": "Something about how to?",
                    "label": 0
                },
                {
                    "sent": "As we continue to talk about having framework.",
                    "label": 0
                },
                {
                    "sent": "So that's, uh, yeah, that's a quick question.",
                    "label": 0
                },
                {
                    "sent": "So we have also considered this problem an with some partial results.",
                    "label": 0
                },
                {
                    "sent": "To adjust the problem where it store may not be an issue.",
                    "label": 0
                },
                {
                    "sent": "And then I put in general, we don't have a good solution yet and this one is actually one of the open problems.",
                    "label": 0
                },
                {
                    "sent": "I have a lost soul.",
                    "label": 0
                },
                {
                    "sent": "It's intriguing is the factor than the example, because I think the hard part of learning a structural factors that we need is the part that you might have too many edges, or you don't know the structures because actually the realisable case issue that George is raising, so I'm not sure if that I think that's not addressed.",
                    "label": 0
                },
                {
                    "sent": "It's not OK, so in apartment just now we assume that the deep structure it's simple in the sense that the number of parents it's bounded by K some constant.",
                    "label": 0
                },
                {
                    "sent": "And this is actually assumption to make many of the structure learning based, net structure, learning literature, including in one the factory Cuban Factor or Max and also out of papers in.",
                    "label": 0
                },
                {
                    "sent": "Graphical model running.",
                    "label": 0
                },
                {
                    "sent": "And in general this is NP hard, so.",
                    "label": 0
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        }
    }
}