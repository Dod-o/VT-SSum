{
    "id": "hpvtlqi2p6nswl2s5qrbbl34kqqg3r76",
    "title": "Protein-protein network inference with regularized output and input kernel methods",
    "info": {
        "author": [
            "Florence d'Alche-Buc, Universit\u00e9 Evry Val d'Essonne"
        ],
        "published": "Nov. 8, 2010",
        "recorded": "October 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines",
            "Top->Computer Science->Machine Learning->Structured Data",
            "Top->Computer Science->Bioinformatics->Computational Systems Biology"
        ]
    },
    "url": "http://videolectures.net/mlsb2010_dalche_buc_ppn/",
    "segmentation": [
        [
            "Thank you very much for the nice introduction and thank you for the invitation.",
            "So I I'm thankful to the organizers to invite me.",
            "It's a pleasure to present your current work on the input and output kernel methods for network inference and not all the network, but protein.",
            "Protein interaction network.",
            "OK, first of all."
        ],
        [
            "I I'd like to say a few words about the place where I am, so maybe you don't know every every.",
            "It's a place in France for Jenna Poles at the city of jeans.",
            "It's a 30 kilometers from Paris.",
            "OK, it's a place where we have the National Center for sequencing.",
            "OK, an University of favorite Sejong University.",
            "It has been.",
            "It was founded in 91.",
            "OK, it has about 10,000 students.",
            "And of course it is German mainly towards biology, bioinformatics and biochemistry, so our lab at Similia lab of computer science on complex Systems, Anile Group as a huge sale.",
            "It's about machine learning with application systems biology, so we're not just only working on protein, protein interaction, network inference, but we are also doing modeling and learning of dynamical systems.",
            "Especially biological systems like gene regulatory networks, signaling networks, and.",
            "Say that we are looking at biological data and try to mine and predict through through data OK."
        ],
        [
            "So today I'm going to talk about this famous for the input induction networks.",
            "I'm sure you have seen this picture a lot of times.",
            "OK, it's a used.",
            "The set of protein protein interactions that you know that we know today.",
            "OK, first at all we have to say something about that.",
            "Each edge here means that you have a physical interaction between two proteins, so not of course are proteins.",
            "I'm here, we do not take into account the fact that you have.",
            "In fact, this interaction take place in space in space and time.",
            "OK, it's not possible now to have to gather all this information, so please consider this graph as convenient representation of set of information.",
            "So for the rest of the talk I will assume that this is not biological system per say.",
            "It's more convenient way to represent information.",
            "OK, contrary to gene regulatory networks or signaling networks where you are really systems behind that."
        ],
        [
            "OK, so just to briefly motivate brief motivation for this work so you know that there exist detection methods, biology codon, experimental methods to detect physical interaction between proteins.",
            "But sometimes these methods.",
            "Hi there, they are small scale and they are very costly and laborious.",
            "Either their large scale OK but they are known to produce iPhones positive rate.",
            "OK, so it's it's a good idea to say OK, we're going to suggest interactions to biologists and then biologists and biochemists will go to the lab and try to validate this suggested interaction.",
            "Of course the biology they don't want, you know a list of a very large list of interaction, but maybe they want.",
            "This list is.",
            "Should be ranked OK and the problem we have we are going to."
        ],
        [
            "Face is how can we represent this information?",
            "How can we build a method that makes its predictions?",
            "So first we can ask what kind information are available here.",
            "So there are lot of way to describe proteins, sequence information, structural information.",
            "You can also represent.",
            "You can also look at the domains and the motives.",
            "You can look at Phil genetic signatures and.",
            "You can also look at jeans that Uncle proteins and you can look at expressing expression of genes, OK?",
            "If you look at the known interaction you have mainly as we said yesterday for the problems, mainly positive examples in the sense that biologists published papers where the proof they show experimentally the presence of physical interaction.",
            "Now is there is really a very few examples that may be considered as negative."
        ],
        [
            "So I'm going to say a word about existing approaches, because this problem has been tackled for why now, about five years.",
            "We mainly have two kind of approaches.",
            "First approach is supervised age influence, so you are going to go back to a classical problem in machine learning like supervised classification or regression, and you're going to use that to predict if two proteins are linked or not OK, please notice that this problem in the domain of social network is called link prediction.",
            "OK, so you have a complete literature in the social social networks.",
            "Web data related to link prediction.",
            "An overview is to say, well, it's more problem of matrix completion.",
            "OK, it's not really a supervised problem."
        ],
        [
            "OK.",
            "So just to introduce you these approaches, the supervise aging firms or link prediction.",
            "OK, you have two proteins.",
            "You imagine that you have some input feature vector that give you an idea of the properties of each of the proteins or prime and you want to learn a decision function.",
            "OK, you want to run a function F from a pair of objects that go towards the set of.",
            "01011 OK, so the training data you have it.",
            "This input feature vectors for each of your proteins?",
            "The metrics, the sub metrics that say that your proteins in the training set are linked or not OK, and usually what you want to do.",
            "You want to use this information.",
            "You want to use this information to learn a function that will be able to predict new links between new proteins and also proteins that you have in your training set and proteins that you have in your test set."
        ],
        [
            "So if you look back to the literature, mainly the the main research group that has worked on this on introduces his setting is banner on Noble in 2005 with pairwise SVM.",
            "So the define SVM with a couple of SVM and kernels on couple of couples of inputs.",
            "OK, you have also a great job with Yamanishi.",
            "Is there an Ann Coulter's about supervised learning of a kernel or similarity?",
            "So you are going to transform your supervised classification problem into a metric learning problem.",
            "OK, I will show you this in a minute and you have also the work we I'm going to present you mainly done with the PR girls with here.",
            "It's an overview.",
            "It's also again a learning method, but but without camera gracian.",
            "I'm going to talk to you to talk about today and we have other.",
            "Recent methods one family of methods by key in 2008 with mutual feature expert on them first or so like us but not exactly same.",
            "Same same context and very interesting approach.",
            "BI Weekly on there who is related to another way of defining a supervised classification.",
            "In this case you don't use pairs of data, but you define a classifier.",
            "For each of you putting in the training set, and this classifier will be able to tell you if one protein will be linked to this protein you're looking at."
        ],
        [
            "But in fact, if we come back to the first euros, is that where people when people were looking at this problem?",
            "I mean first people, the other two cats problem is Koji Tsuda with here and then colleagues because they say, well, this problem is not a supervised problem, it's an unsupervised problem.",
            "Yes, I have some constraints and I'm going to take care of this constraint, but mainly it's metrics completion problem.",
            "OK, so you see you have this adjacency matrix OK, and you want to complete this.",
            "So I."
        ],
        [
            "So Cody was the first to use them and to propose them for such problems and a developer sore.",
            "This this method and this family of methods with with cattle.",
            "And there is also general matrix regression.",
            "Paper by Yemeni Shia man there and very new stuff is now about transductive and semi supervised learning.",
            "So people are saying, OK, I'm going to use unlabeled data.",
            "I know information about my proteins, sequences, everything, everything can be used and I'm going to do link propagation in the case of Cash Manda Manishi, I'm going to use mixture of Wishart matrices.",
            "It's really nice work but by.",
            "And colleagues or training set expansion.",
            "So in the."
        ],
        [
            "In the dog I'm going up to a focus on specific kind of methods.",
            "Starting from supervised learning and towards transductive learning OK, we will do both.",
            "First we're going to say that we are going to try to avoid working on pairs of data.",
            "OK because of operational complexity.",
            "An idea assumption that is not met in that case, and we're going to try to define as realistic as possible.",
            "Different different task OK. And of course as other.",
            "Researcher, we want to allow data integration and structural feature encoding."
        ],
        [
            "OK, so the outline of my talk will be the following.",
            "I'm going to enter into the core subject of this talk and I will describe user framework of output canal regression.",
            "It's really simple ideas.",
            "Basically it's using channel trick in the output space and I will show you 2 examples of regression methods, but really a lot of regression method can be developed in this framework.",
            "Will tell you a little bit about output.",
            "Ventrian previous results we had with with Bear and then I will show you current work on input, output, calibration with the square panelization.",
            "So after that we will switch to a more realistic task where you are going to use unlabeled data and you are going to solve this transcriptive link prediction problem.",
            "And finally I will conclude."
        ],
        [
            "OK, so let's come back to this setting of supervised supervised learning.",
            "OK, now I'm I'm going to use the framework of.",
            "Similarity learning, so I imagine that this classifier, this predictor that tells me if two proteins are linked or not is based on some regulation.",
            "Not any regression sum function here will say which, say that Orono Prime are closed in the sense of metric on a graph.",
            "OK, if you know Prime 2 nodes in the graph which are closed, we have high similarity.",
            "Otherwise I will have a low similarity.",
            "OK, as sorry as everybody, I will use threshold.",
            "OK, I'm learning a proxy.",
            "Of this similarity and learning filter or choosing theater will correspond to learning the classifier."
        ],
        [
            "So the new idea here is that we're going to add some assumption.",
            "OK, she says Sumption.",
            "Is that this similarity will be for us positive definite kernel.",
            "OK, this means that if I still call Ky this positive definite kernel, I call Y the feature map associated with this kernel and Big Y space under with this dot product then the new problem?",
            "Can be set as following if I am able to approximate this feature map OK, it's.",
            "It's OK because I will have an approximation here of this feature map and thus an approximation of his kernel.",
            "OK, so instead of running kernel function defined on pairs, we're going to learn a function defined on single objects.",
            "OK, this is the."
        ],
        [
            "So as I said, what we have to do we have to build a function approximation that outputs in this space.",
            "In this target either space Y.",
            "Then we will ensure that the similarity will be a kernel by construction.",
            "OK, so we are.",
            "It's OK with that.",
            "And the second point is of course that this approach image this approximation of Y.",
            "If it is good enough, then the scalar product will be good enough.",
            "Approximation of K1, OK?"
        ],
        [
            "So just to fix ideas very simple picture.",
            "OK, imagine that our proteins geometry conforms with scorers OK, you have this data set.",
            "You know you know that about your data OK and what you want to learn.",
            "So you could to the set.",
            "Object you have your subset which is which is your training symbol and what you want to do.",
            "You want to build a function H that gods that give you from the geometry.",
            "Confirm the color of object.",
            "OK, this is a way to see the things.",
            "OK, it means that if you have some object or I OK you have a way to uncle this object by these features via this feature vector X. OK and here.",
            "In the output you have a feature vectors, but very specific feature vectors, because you know that they are associated with some Ilbert space on door with some kernels OK, then you want to learn this function.",
            "OK, so it's a very general problem.",
            "It's like extending regression vector regression to.",
            "I would put space which are in their space with some product."
        ],
        [
            "OK.",
            "So another way to see that if I look at the feature map OK?",
            "Here with why what I'm doing, I have some information here about the object.",
            "OK, you have this color and you have this here you have the color still, which in fact is related here to the graph, just a way to represent it.",
            "You have still geometry confirm OK, you have this information and you want to go from this graph to a vectorial representation.",
            "OK so it's really using the kernel trick in the output space.",
            "OK."
        ],
        [
            "OK, so is it possible to do this?",
            "Yes?",
            "Well, as I told you other people like John flip their work worked on on metric learning.",
            "Can LCC and different methods or also yamanishi they use these additional kernel?",
            "It's not the only kernel we can use, but it's one of the best candles that tell you if two nodes are closed in a graph.",
            "OK, we can define other kernel with this one.",
            "It's quite is quite good, so right.",
            "OK, so briefly what you can do?",
            "If you know the adjacency matrix.",
            "Of your known graph W, you define the lab lesson OK, and then you make an exponential of this matrix OK with the smoothing parameter bitter diffusion parameter beta and you get a gram matrix OK, and this diffusion metrics will be used as training input.",
            "You have training output you have."
        ],
        [
            "OK, so now the problem we have.",
            "It's in fact vector regression.",
            "But a bit special.",
            "OK, because we have this output kernel feature space, so you have data.",
            "You have some input representation.",
            "OK, so for the moment I'm talking about occlusion space OK, but in fact.",
            "It could be any can induce labor space.",
            "An output representation.",
            "Here you have just one user gram matrix, not vector representation you have.",
            "You are going to choose some class of function.",
            "OK as usual.",
            "In supervised learning you are going to find a function H from X to Y that minimizes some expectation of some loss.",
            "You are going to choose quite appropriately.",
            "OK, and you want to minimize this expectation, OK?"
        ],
        [
            "So our first idea, of course, is to say OK, which loss.",
            "Let's try square root square off as I did appropriate properties for this problem.",
            "OK, because when you compute this is Norma Square norm.",
            "You only required to compute things with dot products.",
            "OK, so this is a good eligible loss.",
            "And the other thing you have to you have to take into account is the fact that be careful in fact.",
            "We don't know why we just know KYK the gram matrix of the gram deficient matrix.",
            "OK, so in order to have the outputs of H in Big Y, the only thing we have to do we can do in fact is to work in the vector space fine bye.",
            "Y1Y N OK if you have any data, OK so from that we are going to develop different tools.",
            "First we have developed output canal regression trees with P Garcon with angle.",
            "Then we are.",
            "It was quite direct.",
            "Try to extend ensemble methods on this output.",
            "Kernel regression framework, so bagging quite.",
            "Direct boosting through Christ, some work and random first or so quite direct.",
            "Then we we have done very recent work and this work is based on the idea that we'd like to have an input Journal as well as an output kernel.",
            "OK, it's convenient to have to be able to represent complex information data as input.",
            "OK, so will present.",
            "Uses input output canal, organized regression an?",
            "It's a joint work with ceiling.",
            "Or with the PhD student and Marissa Franzke.",
            "And of course muskie benefit from any discussion with spear."
        ],
        [
            "OK, so now let's go for output cameltry 220."
        ],
        [
            "To the subject.",
            "So you know tree regulation traits.",
            "We in fact very rough method.",
            "You are going to say OK, I'm going to ask questions to coordinates of inputs.",
            "Very simple questions, OK?",
            "Sorry and then you will take a look at the leaf.",
            "The average of the outputs that fall into that Cliff.",
            "OK, this can be written as a following.",
            "You have this H tree, so the one of these output kernel function OK and you define it as.",
            "Through regression, but here remember that we are vectors OK?",
            "We have vectors here, and so we have the average."
        ],
        [
            "OK, so very quickly because it's a non non results previous results when you learn a tree you you are doing incrementally.",
            "Greedy algorithm OK. And for the current training set at a given node, you are going to split this training set and to choose this split to choose the questions you have to ask the coordinates of few data you have to maximize the empirical or addiction.",
            "The American violence prediction is means that the score you are looking at is variance of your outputs.",
            "For your training set and the variants of your outputs for the left set for the right set, when you are doing this split OK, everything can be computed with that product.",
            "OK, at any moment you don't need to work on the Big Y."
        ],
        [
            "White space.",
            "OK, so here's nice residents about trees.",
            "This is the results where you have just you're in learning so you have this kind of tree and we have just here.",
            "For instance look at this.",
            "This leave if four OK.",
            "It's interesting to know that.",
            "All this data falling into the same list.",
            "OK, it seems that there is a path from the root to that leaf.",
            "OK, saying that, you can describe this data by some properties of the inputs and you are able from these properties to identify this subgroups.",
            "OK, so it means that you can predict this.",
            "The interaction with in fact input information, as would say we will see later expression of genes.",
            "Fusion 16 actor on a lot of inputs OK."
        ],
        [
            "So very quickly I'm going to use several times this data set.",
            "It's a well known data set, so I think.",
            "Could you Sudan cattle were the first to use it?",
            "It's 984 proteins, 2478 Edge is an input feature.",
            "Gene expression.",
            "Different experiments spend months.",
            "Data isn't data flow.",
            "Genetic profiles across 145 one 145 SPPS.",
            "Presence or absence of an ortholog.",
            "Localization data and also yes to every day to be cheating, but in fact you will see that these large scale data.",
            "Help, but not not so much.",
            "OK and output, of course it's the."
        ],
        [
            "Graph of interaction.",
            "OK so I briefly record this this results.",
            "Just to say that we compare to different.",
            "To different works and we are.",
            "That's at the same level as as the other positive.",
            "OK, just notice that it's not a single tree, but ensemble methods with Singletary especially, it's extra extra trees that we have talked about."
        ],
        [
            "Out yesterday.",
            "Another resource here, what can it be useful for except predict physical interaction?",
            "You can use this to predict function OK in read this the in blue.",
            "This is the training data in red.",
            "This is a completed data OK, and what you see in the graph here?",
            "If you look at this cluster OK in the graph you are going to say OK.",
            "I'm going to infer that the function here, which is known here will be also shared by other genes.",
            "OK, of course, it's it's kind of empirical inference, but it does work for summer summer."
        ],
        [
            "Some of the cheese products.",
            "OK, so now let's take another angle and say OK, this is very nice and very powerful.",
            "But now I like also to use a Colonel in the input space.",
            "OK, so we are quite used to this, so we're going to extend fact existing method to do that.",
            "So now we have this positive definite kernel KX.",
            "OK, that calls for similarities between inputs OK. And what we are going to look we're going to look in fact, that simpler models than than trees, linear models from X to Y."
        ],
        [
            "So in fact, we took some inspiration from support vector machine OK and also for maximum magic robot or maximum magic.",
            "Imagine regulation.",
            "So by sticking and some arcana and housing.",
            "You have here the idea that OK, Now we're going to have the same kind of function that is computed for instance in support vector machine.",
            "But here instead having schara you have a vector OK.",
            "Please note that we are not deriving this form of the function from some cost function in the dual.",
            "OK, we're taking this from an applying some minimization.",
            "OK, so we're all choosing margin here, because really it's it's a regression problem we want to tackle it.",
            "Call it with the square OK, and we're going to try to learn this parameters."
        ],
        [
            "So first of all, it's simpler.",
            "The simplest idea that comes to mind is to say, OK, I'm going to fit the data OK with the square.",
            "I'm going to make some penalization on the parameter vector.",
            "OK, this is nice because when you derive this cost function and I knew the gradient you have across from solution OK like in retrogression.",
            "In fact, it's the same kind of presence.",
            "OK, so of course we have the use of this different kernel matrices, which is completely normal because we have input gain and output kernels."
        ],
        [
            "OK.",
            "But this is very nice.",
            "It's a model quite simple, because what you were just doing, you are doing linear combination of your input output vectors.",
            "OK, if we look back at work that are being done in another context, mapping strings to strings work of Cortez Mori on Western OK.",
            "In fact they've done already the extension of.",
            "Canon, which regression to output can deliver even if they didn't call that like that.",
            "OK, so they propose this kind of model OK. You have to notice that here you have this big matrix A and the dimension is.",
            "You have the dimension of your input and output space.",
            "That might be infinite OK, but who will come later to that?",
            "OK, so they did this fit least square fitting panelization with four business norm, OK. Also fine closed form solution as in canal retrogression OK.",
            "So in their case they wanted to finally predict string, so they have to solve a premich problem.",
            "OK here, it's as as as you see, it's not useful.",
            "We have this foolish solution, OK, but will usually always use the output of this function inside the DOT product OK?",
            "So we won't.",
            "We won't have to suffer preimage problem OK, but so their method here can be applied to the context.",
            "I have defined OK."
        ],
        [
            "OK. Let's say let's try to have maybe a different model.",
            "OK, yeah, we have this, possibly infinite size of the metrics a if the if X&Y as have infinite dimensions, so can we simplify just this?",
            "This function, yes, it's possible.",
            "Going just to."
        ],
        [
            "Come back to the definition definition here.",
            "Oh OK, it's OK. You see here.",
            "Small mistake here.",
            "OK, if you write this in a matrix from OK, you have these metrics and here you have a diagonal matrix with vector A in the diagonal.",
            "OK, so it's looked it looks like very much the Kenner Ridge regression, OK with specific vector."
        ],
        [
            "Something we want to try is to say OK, we're going to define exactly the same model, but here I'm going to restrict these.",
            "The dimension of A to N * N. OK, contrary to the previous model, which were infinite with infinite.",
            "Dimension potential yet at least.",
            "OK, so we can do everything the same.",
            "I put here on propose the foreignness norm of the world matrix.",
            "OK, even if my parameters are just the metrics, a OK and again we find across solution.",
            "So is it a new model?",
            "In fact not.",
            "It's just a way to rewrite things.",
            "OK in this supervised framework, this model and the model."
        ],
        [
            "Are presented by Curtis and all compute the same function.",
            "OK because if you look at this equation OK, you will see that there is just the."
        ],
        [
            "A difference here that comes from the form of your equation, OK.",
            "So is it useless?",
            "No, you will see that.",
            "In fact it will be good to have some finite set of parameters when we will use variance of the link prediction.",
            "So I will keep this for the transductive learning case, but it will be nicer to have a finite."
        ],
        [
            "Parameters.",
            "OK, just some 1st results here.",
            "So it's a supervised setting with then cross validation and it's just to show you an idea of the scaling of of the methods.",
            "If you use only gene expression to predict protein protein interaction, which is in fact the best predictor for this prediction, OK?",
            "You will see this single single output candle tree.",
            "Is not very performant if you look at the.",
            "Round as a rocker.",
            "OK if you now use it in another method such as random price to extra trees, you get a really nice results if you use now our simple model with a vector we have, we get quite nice razors.",
            "Not as good as the ensemble methods and now if you see a model that big a motel so which is again the same quarters models and the older model.",
            "The rewriting we would propose we got this results, so it's it's encouraging for the next step, OK?"
        ],
        [
            "And we're going to make a more serious comparison.",
            "OK, so there is this nice paper of blickle on there and they compare.",
            "Network construction methods will be a large set of larger bunch of methods OK. And So what we did we use their setting to be able to compare with them.",
            "OK so first we have to notice that.",
            "The local methods that is proposing a empirically on Anna at all are only can only be applied to the prediction of interaction between learning and training sets.",
            "This is what this is.",
            "The reason why is that we have to remember that we have a classifier linked one protein OK, and you learn how to classify potential candidates and to say yes this candidate can be linked to the protein.",
            "So it's not exactly the same framework as you or the other methods, but at least we can compare on this prediction OK?",
            "So what we did we use the standard cross validation and has we have hyperparameters.",
            "As you see, we have this number one.",
            "OK, we need to perform some parameter selection OK and to try to be able to get to fit into this setting.",
            "We pair from an internal 5V5 cross validation CV using the area under the.",
            "F dear curve to be able to select the best parameters.",
            "OK, so first I'm going to show you the results for the simpler simple Model H small a OK An here what you?"
        ],
        [
            "OK. You have the results for all the data.",
            "OK, so training test sets, rashes running set.",
            "Test suggests learning set so all the parts of this matrix OK so remaining part of the matrix OK. And of course.",
            "You look at the results as we show before we as we have seen before.",
            "It's OK is that it's rather good, not not very, very exciting.",
            "OK, if we look at the different here, inputs, expression, localization, flow, genetic yes too, I break data integration of everything.",
            "OK, you see that usually you can improve.",
            "OK, that's.",
            "Weather is here to be strange, but OK with the area under the FDR.",
            "OK, we have quite high values, but if we look at all the methods as we will see it's more or less the same."
        ],
        [
            "Now if we look at the H model, which is a more complex model, OK, much more, richer, OK, then you get really nice performance.",
            "OK, nice performance here in you see AUC area under the Roc curve and also area under the FDR graphs.",
            "OK, these are supposed to be as minimal as possible, so it's still big.",
            "OK, it's still large, but.",
            "It's it's it's OK."
        ],
        [
            "Especially if we compare to this big results provided by publicly and I in 2007.",
            "So here this is the.",
            "Five fold cross validation exactly the same, the same.",
            "But anyway, we have used OK.",
            "They compared a lot of methods here and here is the result for protein protein interaction.",
            "So to be honest in the metabolic networks they perform very well, especially the local methods is dramatically is dramatically increasing its performance when integrating information.",
            "It's quite magic in fact, but if you look at protein protein interaction, which is in fact our propose.",
            "We're going to look at this his data.",
            "OK, this results and you will see that.",
            "Sorry."
        ],
        [
            "In the supervised setting where we have very good weather."
        ],
        [
            "That were those methods?",
            "OK, so here is so M of code.",
            "It's true that is performing the best results.",
            "Here we are."
        ],
        [
            "Maybe we're just a little bit.",
            "Just a hug.",
            "OK."
        ],
        [
            "So the message is not, you know, comparing exactly each method that saying OK, this pull of method can solve the problem.",
            "It is at the level of other methods on an sometimes better.",
            "OK.",
            "So this is a good tool to addressing prediction, but the prediction in fact could be could benefit from the use of unlabeled data when you talk to a biology.",
            "So for instance we are working on the cystic fibrosis.",
            "So human protein with biologists so he knows already.",
            "Set of proteins that you want to link.",
            "OK, this big set.",
            "Be changing OK. We know already the protocol.",
            "OK, so you know that and you want to complete this interaction.",
            "This interaction.",
            "OK so."
        ],
        [
            "It's more a transitive problem than a supervised one.",
            "OK, so here remember that in our setting it's quite specific we need this gram matrix as input, so we will be always looking at the problem as a matrix completion.",
            "OK, we need a few examples, few proteins, while you know everything.",
            "OK, this is an important limitation.",
            "I want to not too I this OK, but we're going to try.",
            "To make the set of labeled data as small as possible.",
            "And the idea is we will be to use this input input cannot."
        ],
        [
            "Store to make the.",
            "So prediction OK, so very fast OK?"
        ],
        [
            "I'm going to.",
            "To go a little faster, OK?",
            "If you look at some supervised regression, maybe you know that very common cost function as you try to fit the data with the label data and try to have smoothness assumption.",
            "Something that you can tell about your data even if they are unlabeled, you can always say that the function I want to build must be continuous, must be smooth, and you can say that for any couple of inputs.",
            "So.",
            "Sorry, this smoothness assumption was proposed by many researchers and it's based on the lab Russian operators again.",
            "And of course, if we want to use this.",
            "So this function is better to start with the smooth model.",
            "OK, so trees here are not fully appropriate, while in fact linear combination could be eligible OK.",
            "So."
        ],
        [
            "We are going to use this input output kernel models sort of Model H small A through the HCK OK so now just be careful changed notation so P is a number of labeled proteins OK, and the total number of proteins OK. And here what you see is you see the cost function with classic traditional least square with some penalization.",
            "OK and you just add this constraint saying that.",
            "OK, you have this smoothness assumption OK.",
            "So this move this assumption, you can write it nicely OK as a trace of this lab machine operator.",
            "OK, you have this really nice writing, but the most important is to say, OK, I'm trying to use information about inputs.",
            "If two proteins are closed, the input space, I want the output of my predictor will be closed."
        ],
        [
            "So then I think with the.",
            "An L2 panelization is that you come again for you come again two across from solution OK.",
            "So everything can be rightly if you again if you derive the cost function.",
            "If you knew it, you will find a single solution OK, and again it will be the same for the model HB A and the MPN OK.",
            "Please notice that in this case we have different models.",
            "OK, in the supervised case everything was completely equivalent.",
            "Here you won't choose exactly.",
            "You won't get exactly the same solution, OK?"
        ],
        [
            "So a protocol to test this is the following.",
            "OK, so you have this level data.",
            "OK, we have this.",
            "Yes data and we are going to use this intensively to try to test our methods.",
            "OK, so the idea is first to say OK, I'm going to sample a subset of pea proteins.",
            "OK, and I will do this a lot of times for each sample of people.",
            "10s?",
            "OK, I will be able to.",
            "However, a problem and I we need to select my hyperparameters.",
            "So now the one and longer to OK.",
            "In fact other parameters that are linked with kernels, diffusion, diffusion parameter and parameters for instance, variance in the Goshen OK.",
            "So this election is the following we are going to use for cross validation Y-44.",
            "In fact, as you will see, will take very small amount of data, label data and so we need we need.",
            "We need to make a compromise between data that we need to validate to test and data for learning.",
            "So we use this four fold cross validation here.",
            "So you made in that in this matrix you are leaving some of the.",
            "Example for test.",
            "So you are learning this.",
            "You are testing in the 1/4 of your data.",
            "Do this force and you select your parameters.",
            "OK, so be careful, it's protocol for transductive learning so where we're going.",
            "We're going to predict here all these missing data.",
            "OK, and we will evaluate here the area under the Roc curve and the area, and there's a full discovery rate."
        ],
        [
            "OK.",
            "So just last last results.",
            "OK, it's in fact the 1st results with the model HA, which is not the best OK and just to show you if I take 10% of the data as lab data, 10% of the notes OK, it means in fact 1% of the edges OK.",
            "If you remember that the number of edges if you have any notes, it's end times N -- 1.",
            "Divided by by two.",
            "OK then you have this 1% of edges, so it's very far from other works that take 25% of the data or or things like that.",
            "OK, it's really a small amount of edges, which is known OK, and here you can see the supervised setting and the transitive setting.",
            "And of course adding lab level data, sorry.",
            "If you look here at more data you will see again this this little increasing K of the performance.",
            "OK, we have exactly the same as the same kind of performance in UFOK.",
            "So can we.",
            "Compare with other transductive methods.",
            "OK, it's a bit special because the the other methods they randomly sample some data which they.",
            "Which supposed not to be, not to be known.",
            "OK, here we have a sub matrix which is known.",
            "So the setting is quite different than in fact for other transition methods our setting is quite disadvantageous.",
            "OK, so we have we have to define something that we don't know quite yet.",
            "Well how we're going to compare."
        ],
        [
            "This OK?",
            "OK, so I'm going to yeah I'm going to finish and complete.",
            "OK, the first message I want to tell you is to say please look at the output space in your problem.",
            "Try usually people take a lot of time to define input space which is really important, but output space can really open a larger Ave to new task and maybe to get more information on your problem so user can entry.",
            "Go to space is just an example of doing that, but be careful to the output space.",
            "It's really important to to define that.",
            "OK, I will go through."
        ],
        [
            "This perspective now, so now we are working with a biologist, Alexander Edelman, in Nickell spittle at in Paris, OK. Ann is interesting in the potency eftir, whose mutations are involved in cystic fibrosis OK and what he wants to do.",
            "We want to complete the known.",
            "Interaction network around this protein to be able to to better know partners of these proteins, which is big macromolecule.",
            "OK, so to do that we have to solve?",
            "Send some problem first, as you may be notice that we didn't dealt with the imbalance set of examples.",
            "In fact, in our framework, the fact that you have absence of negatives is not taken into account.",
            "We have made the assumption that the small sub metrics is known, but everything is known for this agent was here submatrix.",
            "OK, so we have to go with that so second.",
            "Point we want to improve is the fact that it's good to just integrate every information by computing the mean of kennel.",
            "But it would be nice to automatically select which kind of input kernel you want to use.",
            "And finally, as I'm also working on graphical pricing model, I'm very attracted by the new direction that could be defined.",
            "A graphical probabilistic model.",
            "So encapsulate all the thing into logistic regression like model, because in that case you can mix local approaches with nature and global approaches as we do here.",
            "OK, and the last point, but not there is.",
            "In fact, I think I would put calibration can be used in many many settings to solve different problems.",
            "So the idea is that if you find the right output space, maybe if you are able to solve some pre image problem then you can do this method.",
            "I thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you very much for the nice introduction and thank you for the invitation.",
                    "label": 0
                },
                {
                    "sent": "So I I'm thankful to the organizers to invite me.",
                    "label": 0
                },
                {
                    "sent": "It's a pleasure to present your current work on the input and output kernel methods for network inference and not all the network, but protein.",
                    "label": 1
                },
                {
                    "sent": "Protein interaction network.",
                    "label": 0
                },
                {
                    "sent": "OK, first of all.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I I'd like to say a few words about the place where I am, so maybe you don't know every every.",
                    "label": 1
                },
                {
                    "sent": "It's a place in France for Jenna Poles at the city of jeans.",
                    "label": 1
                },
                {
                    "sent": "It's a 30 kilometers from Paris.",
                    "label": 0
                },
                {
                    "sent": "OK, it's a place where we have the National Center for sequencing.",
                    "label": 0
                },
                {
                    "sent": "OK, an University of favorite Sejong University.",
                    "label": 0
                },
                {
                    "sent": "It has been.",
                    "label": 0
                },
                {
                    "sent": "It was founded in 91.",
                    "label": 0
                },
                {
                    "sent": "OK, it has about 10,000 students.",
                    "label": 0
                },
                {
                    "sent": "And of course it is German mainly towards biology, bioinformatics and biochemistry, so our lab at Similia lab of computer science on complex Systems, Anile Group as a huge sale.",
                    "label": 0
                },
                {
                    "sent": "It's about machine learning with application systems biology, so we're not just only working on protein, protein interaction, network inference, but we are also doing modeling and learning of dynamical systems.",
                    "label": 1
                },
                {
                    "sent": "Especially biological systems like gene regulatory networks, signaling networks, and.",
                    "label": 0
                },
                {
                    "sent": "Say that we are looking at biological data and try to mine and predict through through data OK.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So today I'm going to talk about this famous for the input induction networks.",
                    "label": 0
                },
                {
                    "sent": "I'm sure you have seen this picture a lot of times.",
                    "label": 0
                },
                {
                    "sent": "OK, it's a used.",
                    "label": 0
                },
                {
                    "sent": "The set of protein protein interactions that you know that we know today.",
                    "label": 0
                },
                {
                    "sent": "OK, first at all we have to say something about that.",
                    "label": 0
                },
                {
                    "sent": "Each edge here means that you have a physical interaction between two proteins, so not of course are proteins.",
                    "label": 0
                },
                {
                    "sent": "I'm here, we do not take into account the fact that you have.",
                    "label": 0
                },
                {
                    "sent": "In fact, this interaction take place in space in space and time.",
                    "label": 0
                },
                {
                    "sent": "OK, it's not possible now to have to gather all this information, so please consider this graph as convenient representation of set of information.",
                    "label": 0
                },
                {
                    "sent": "So for the rest of the talk I will assume that this is not biological system per say.",
                    "label": 0
                },
                {
                    "sent": "It's more convenient way to represent information.",
                    "label": 0
                },
                {
                    "sent": "OK, contrary to gene regulatory networks or signaling networks where you are really systems behind that.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so just to briefly motivate brief motivation for this work so you know that there exist detection methods, biology codon, experimental methods to detect physical interaction between proteins.",
                    "label": 0
                },
                {
                    "sent": "But sometimes these methods.",
                    "label": 0
                },
                {
                    "sent": "Hi there, they are small scale and they are very costly and laborious.",
                    "label": 1
                },
                {
                    "sent": "Either their large scale OK but they are known to produce iPhones positive rate.",
                    "label": 1
                },
                {
                    "sent": "OK, so it's it's a good idea to say OK, we're going to suggest interactions to biologists and then biologists and biochemists will go to the lab and try to validate this suggested interaction.",
                    "label": 0
                },
                {
                    "sent": "Of course the biology they don't want, you know a list of a very large list of interaction, but maybe they want.",
                    "label": 0
                },
                {
                    "sent": "This list is.",
                    "label": 0
                },
                {
                    "sent": "Should be ranked OK and the problem we have we are going to.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Face is how can we represent this information?",
                    "label": 0
                },
                {
                    "sent": "How can we build a method that makes its predictions?",
                    "label": 0
                },
                {
                    "sent": "So first we can ask what kind information are available here.",
                    "label": 0
                },
                {
                    "sent": "So there are lot of way to describe proteins, sequence information, structural information.",
                    "label": 0
                },
                {
                    "sent": "You can also represent.",
                    "label": 0
                },
                {
                    "sent": "You can also look at the domains and the motives.",
                    "label": 0
                },
                {
                    "sent": "You can look at Phil genetic signatures and.",
                    "label": 0
                },
                {
                    "sent": "You can also look at jeans that Uncle proteins and you can look at expressing expression of genes, OK?",
                    "label": 0
                },
                {
                    "sent": "If you look at the known interaction you have mainly as we said yesterday for the problems, mainly positive examples in the sense that biologists published papers where the proof they show experimentally the presence of physical interaction.",
                    "label": 0
                },
                {
                    "sent": "Now is there is really a very few examples that may be considered as negative.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to say a word about existing approaches, because this problem has been tackled for why now, about five years.",
                    "label": 1
                },
                {
                    "sent": "We mainly have two kind of approaches.",
                    "label": 0
                },
                {
                    "sent": "First approach is supervised age influence, so you are going to go back to a classical problem in machine learning like supervised classification or regression, and you're going to use that to predict if two proteins are linked or not OK, please notice that this problem in the domain of social network is called link prediction.",
                    "label": 0
                },
                {
                    "sent": "OK, so you have a complete literature in the social social networks.",
                    "label": 0
                },
                {
                    "sent": "Web data related to link prediction.",
                    "label": 1
                },
                {
                    "sent": "An overview is to say, well, it's more problem of matrix completion.",
                    "label": 0
                },
                {
                    "sent": "OK, it's not really a supervised problem.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So just to introduce you these approaches, the supervise aging firms or link prediction.",
                    "label": 1
                },
                {
                    "sent": "OK, you have two proteins.",
                    "label": 1
                },
                {
                    "sent": "You imagine that you have some input feature vector that give you an idea of the properties of each of the proteins or prime and you want to learn a decision function.",
                    "label": 1
                },
                {
                    "sent": "OK, you want to run a function F from a pair of objects that go towards the set of.",
                    "label": 0
                },
                {
                    "sent": "01011 OK, so the training data you have it.",
                    "label": 0
                },
                {
                    "sent": "This input feature vectors for each of your proteins?",
                    "label": 0
                },
                {
                    "sent": "The metrics, the sub metrics that say that your proteins in the training set are linked or not OK, and usually what you want to do.",
                    "label": 0
                },
                {
                    "sent": "You want to use this information.",
                    "label": 0
                },
                {
                    "sent": "You want to use this information to learn a function that will be able to predict new links between new proteins and also proteins that you have in your training set and proteins that you have in your test set.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you look back to the literature, mainly the the main research group that has worked on this on introduces his setting is banner on Noble in 2005 with pairwise SVM.",
                    "label": 0
                },
                {
                    "sent": "So the define SVM with a couple of SVM and kernels on couple of couples of inputs.",
                    "label": 0
                },
                {
                    "sent": "OK, you have also a great job with Yamanishi.",
                    "label": 0
                },
                {
                    "sent": "Is there an Ann Coulter's about supervised learning of a kernel or similarity?",
                    "label": 1
                },
                {
                    "sent": "So you are going to transform your supervised classification problem into a metric learning problem.",
                    "label": 0
                },
                {
                    "sent": "OK, I will show you this in a minute and you have also the work we I'm going to present you mainly done with the PR girls with here.",
                    "label": 0
                },
                {
                    "sent": "It's an overview.",
                    "label": 0
                },
                {
                    "sent": "It's also again a learning method, but but without camera gracian.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk to you to talk about today and we have other.",
                    "label": 0
                },
                {
                    "sent": "Recent methods one family of methods by key in 2008 with mutual feature expert on them first or so like us but not exactly same.",
                    "label": 0
                },
                {
                    "sent": "Same same context and very interesting approach.",
                    "label": 0
                },
                {
                    "sent": "BI Weekly on there who is related to another way of defining a supervised classification.",
                    "label": 0
                },
                {
                    "sent": "In this case you don't use pairs of data, but you define a classifier.",
                    "label": 0
                },
                {
                    "sent": "For each of you putting in the training set, and this classifier will be able to tell you if one protein will be linked to this protein you're looking at.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But in fact, if we come back to the first euros, is that where people when people were looking at this problem?",
                    "label": 0
                },
                {
                    "sent": "I mean first people, the other two cats problem is Koji Tsuda with here and then colleagues because they say, well, this problem is not a supervised problem, it's an unsupervised problem.",
                    "label": 0
                },
                {
                    "sent": "Yes, I have some constraints and I'm going to take care of this constraint, but mainly it's metrics completion problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so you see you have this adjacency matrix OK, and you want to complete this.",
                    "label": 0
                },
                {
                    "sent": "So I.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Cody was the first to use them and to propose them for such problems and a developer sore.",
                    "label": 0
                },
                {
                    "sent": "This this method and this family of methods with with cattle.",
                    "label": 0
                },
                {
                    "sent": "And there is also general matrix regression.",
                    "label": 0
                },
                {
                    "sent": "Paper by Yemeni Shia man there and very new stuff is now about transductive and semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "So people are saying, OK, I'm going to use unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "I know information about my proteins, sequences, everything, everything can be used and I'm going to do link propagation in the case of Cash Manda Manishi, I'm going to use mixture of Wishart matrices.",
                    "label": 1
                },
                {
                    "sent": "It's really nice work but by.",
                    "label": 0
                },
                {
                    "sent": "And colleagues or training set expansion.",
                    "label": 0
                },
                {
                    "sent": "So in the.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the dog I'm going up to a focus on specific kind of methods.",
                    "label": 0
                },
                {
                    "sent": "Starting from supervised learning and towards transductive learning OK, we will do both.",
                    "label": 0
                },
                {
                    "sent": "First we're going to say that we are going to try to avoid working on pairs of data.",
                    "label": 1
                },
                {
                    "sent": "OK because of operational complexity.",
                    "label": 0
                },
                {
                    "sent": "An idea assumption that is not met in that case, and we're going to try to define as realistic as possible.",
                    "label": 1
                },
                {
                    "sent": "Different different task OK. And of course as other.",
                    "label": 0
                },
                {
                    "sent": "Researcher, we want to allow data integration and structural feature encoding.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the outline of my talk will be the following.",
                    "label": 0
                },
                {
                    "sent": "I'm going to enter into the core subject of this talk and I will describe user framework of output canal regression.",
                    "label": 0
                },
                {
                    "sent": "It's really simple ideas.",
                    "label": 0
                },
                {
                    "sent": "Basically it's using channel trick in the output space and I will show you 2 examples of regression methods, but really a lot of regression method can be developed in this framework.",
                    "label": 0
                },
                {
                    "sent": "Will tell you a little bit about output.",
                    "label": 0
                },
                {
                    "sent": "Ventrian previous results we had with with Bear and then I will show you current work on input, output, calibration with the square panelization.",
                    "label": 0
                },
                {
                    "sent": "So after that we will switch to a more realistic task where you are going to use unlabeled data and you are going to solve this transcriptive link prediction problem.",
                    "label": 1
                },
                {
                    "sent": "And finally I will conclude.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's come back to this setting of supervised supervised learning.",
                    "label": 0
                },
                {
                    "sent": "OK, now I'm I'm going to use the framework of.",
                    "label": 0
                },
                {
                    "sent": "Similarity learning, so I imagine that this classifier, this predictor that tells me if two proteins are linked or not is based on some regulation.",
                    "label": 0
                },
                {
                    "sent": "Not any regression sum function here will say which, say that Orono Prime are closed in the sense of metric on a graph.",
                    "label": 0
                },
                {
                    "sent": "OK, if you know Prime 2 nodes in the graph which are closed, we have high similarity.",
                    "label": 1
                },
                {
                    "sent": "Otherwise I will have a low similarity.",
                    "label": 0
                },
                {
                    "sent": "OK, as sorry as everybody, I will use threshold.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm learning a proxy.",
                    "label": 1
                },
                {
                    "sent": "Of this similarity and learning filter or choosing theater will correspond to learning the classifier.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the new idea here is that we're going to add some assumption.",
                    "label": 0
                },
                {
                    "sent": "OK, she says Sumption.",
                    "label": 0
                },
                {
                    "sent": "Is that this similarity will be for us positive definite kernel.",
                    "label": 0
                },
                {
                    "sent": "OK, this means that if I still call Ky this positive definite kernel, I call Y the feature map associated with this kernel and Big Y space under with this dot product then the new problem?",
                    "label": 1
                },
                {
                    "sent": "Can be set as following if I am able to approximate this feature map OK, it's.",
                    "label": 0
                },
                {
                    "sent": "It's OK because I will have an approximation here of this feature map and thus an approximation of his kernel.",
                    "label": 1
                },
                {
                    "sent": "OK, so instead of running kernel function defined on pairs, we're going to learn a function defined on single objects.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as I said, what we have to do we have to build a function approximation that outputs in this space.",
                    "label": 0
                },
                {
                    "sent": "In this target either space Y.",
                    "label": 0
                },
                {
                    "sent": "Then we will ensure that the similarity will be a kernel by construction.",
                    "label": 0
                },
                {
                    "sent": "OK, so we are.",
                    "label": 0
                },
                {
                    "sent": "It's OK with that.",
                    "label": 0
                },
                {
                    "sent": "And the second point is of course that this approach image this approximation of Y.",
                    "label": 0
                },
                {
                    "sent": "If it is good enough, then the scalar product will be good enough.",
                    "label": 0
                },
                {
                    "sent": "Approximation of K1, OK?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to fix ideas very simple picture.",
                    "label": 0
                },
                {
                    "sent": "OK, imagine that our proteins geometry conforms with scorers OK, you have this data set.",
                    "label": 0
                },
                {
                    "sent": "You know you know that about your data OK and what you want to learn.",
                    "label": 0
                },
                {
                    "sent": "So you could to the set.",
                    "label": 0
                },
                {
                    "sent": "Object you have your subset which is which is your training symbol and what you want to do.",
                    "label": 0
                },
                {
                    "sent": "You want to build a function H that gods that give you from the geometry.",
                    "label": 0
                },
                {
                    "sent": "Confirm the color of object.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a way to see the things.",
                    "label": 0
                },
                {
                    "sent": "OK, it means that if you have some object or I OK you have a way to uncle this object by these features via this feature vector X. OK and here.",
                    "label": 0
                },
                {
                    "sent": "In the output you have a feature vectors, but very specific feature vectors, because you know that they are associated with some Ilbert space on door with some kernels OK, then you want to learn this function.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a very general problem.",
                    "label": 0
                },
                {
                    "sent": "It's like extending regression vector regression to.",
                    "label": 0
                },
                {
                    "sent": "I would put space which are in their space with some product.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So another way to see that if I look at the feature map OK?",
                    "label": 0
                },
                {
                    "sent": "Here with why what I'm doing, I have some information here about the object.",
                    "label": 0
                },
                {
                    "sent": "OK, you have this color and you have this here you have the color still, which in fact is related here to the graph, just a way to represent it.",
                    "label": 0
                },
                {
                    "sent": "You have still geometry confirm OK, you have this information and you want to go from this graph to a vectorial representation.",
                    "label": 0
                },
                {
                    "sent": "OK so it's really using the kernel trick in the output space.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so is it possible to do this?",
                    "label": 0
                },
                {
                    "sent": "Yes?",
                    "label": 0
                },
                {
                    "sent": "Well, as I told you other people like John flip their work worked on on metric learning.",
                    "label": 0
                },
                {
                    "sent": "Can LCC and different methods or also yamanishi they use these additional kernel?",
                    "label": 0
                },
                {
                    "sent": "It's not the only kernel we can use, but it's one of the best candles that tell you if two nodes are closed in a graph.",
                    "label": 0
                },
                {
                    "sent": "OK, we can define other kernel with this one.",
                    "label": 0
                },
                {
                    "sent": "It's quite is quite good, so right.",
                    "label": 0
                },
                {
                    "sent": "OK, so briefly what you can do?",
                    "label": 0
                },
                {
                    "sent": "If you know the adjacency matrix.",
                    "label": 1
                },
                {
                    "sent": "Of your known graph W, you define the lab lesson OK, and then you make an exponential of this matrix OK with the smoothing parameter bitter diffusion parameter beta and you get a gram matrix OK, and this diffusion metrics will be used as training input.",
                    "label": 0
                },
                {
                    "sent": "You have training output you have.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now the problem we have.",
                    "label": 0
                },
                {
                    "sent": "It's in fact vector regression.",
                    "label": 0
                },
                {
                    "sent": "But a bit special.",
                    "label": 0
                },
                {
                    "sent": "OK, because we have this output kernel feature space, so you have data.",
                    "label": 0
                },
                {
                    "sent": "You have some input representation.",
                    "label": 0
                },
                {
                    "sent": "OK, so for the moment I'm talking about occlusion space OK, but in fact.",
                    "label": 0
                },
                {
                    "sent": "It could be any can induce labor space.",
                    "label": 0
                },
                {
                    "sent": "An output representation.",
                    "label": 0
                },
                {
                    "sent": "Here you have just one user gram matrix, not vector representation you have.",
                    "label": 0
                },
                {
                    "sent": "You are going to choose some class of function.",
                    "label": 0
                },
                {
                    "sent": "OK as usual.",
                    "label": 0
                },
                {
                    "sent": "In supervised learning you are going to find a function H from X to Y that minimizes some expectation of some loss.",
                    "label": 1
                },
                {
                    "sent": "You are going to choose quite appropriately.",
                    "label": 0
                },
                {
                    "sent": "OK, and you want to minimize this expectation, OK?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our first idea, of course, is to say OK, which loss.",
                    "label": 0
                },
                {
                    "sent": "Let's try square root square off as I did appropriate properties for this problem.",
                    "label": 0
                },
                {
                    "sent": "OK, because when you compute this is Norma Square norm.",
                    "label": 0
                },
                {
                    "sent": "You only required to compute things with dot products.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a good eligible loss.",
                    "label": 0
                },
                {
                    "sent": "And the other thing you have to you have to take into account is the fact that be careful in fact.",
                    "label": 0
                },
                {
                    "sent": "We don't know why we just know KYK the gram matrix of the gram deficient matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, so in order to have the outputs of H in Big Y, the only thing we have to do we can do in fact is to work in the vector space fine bye.",
                    "label": 0
                },
                {
                    "sent": "Y1Y N OK if you have any data, OK so from that we are going to develop different tools.",
                    "label": 0
                },
                {
                    "sent": "First we have developed output canal regression trees with P Garcon with angle.",
                    "label": 0
                },
                {
                    "sent": "Then we are.",
                    "label": 0
                },
                {
                    "sent": "It was quite direct.",
                    "label": 0
                },
                {
                    "sent": "Try to extend ensemble methods on this output.",
                    "label": 0
                },
                {
                    "sent": "Kernel regression framework, so bagging quite.",
                    "label": 0
                },
                {
                    "sent": "Direct boosting through Christ, some work and random first or so quite direct.",
                    "label": 0
                },
                {
                    "sent": "Then we we have done very recent work and this work is based on the idea that we'd like to have an input Journal as well as an output kernel.",
                    "label": 0
                },
                {
                    "sent": "OK, it's convenient to have to be able to represent complex information data as input.",
                    "label": 0
                },
                {
                    "sent": "OK, so will present.",
                    "label": 0
                },
                {
                    "sent": "Uses input output canal, organized regression an?",
                    "label": 0
                },
                {
                    "sent": "It's a joint work with ceiling.",
                    "label": 1
                },
                {
                    "sent": "Or with the PhD student and Marissa Franzke.",
                    "label": 0
                },
                {
                    "sent": "And of course muskie benefit from any discussion with spear.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now let's go for output cameltry 220.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To the subject.",
                    "label": 0
                },
                {
                    "sent": "So you know tree regulation traits.",
                    "label": 0
                },
                {
                    "sent": "We in fact very rough method.",
                    "label": 0
                },
                {
                    "sent": "You are going to say OK, I'm going to ask questions to coordinates of inputs.",
                    "label": 0
                },
                {
                    "sent": "Very simple questions, OK?",
                    "label": 0
                },
                {
                    "sent": "Sorry and then you will take a look at the leaf.",
                    "label": 1
                },
                {
                    "sent": "The average of the outputs that fall into that Cliff.",
                    "label": 1
                },
                {
                    "sent": "OK, this can be written as a following.",
                    "label": 0
                },
                {
                    "sent": "You have this H tree, so the one of these output kernel function OK and you define it as.",
                    "label": 0
                },
                {
                    "sent": "Through regression, but here remember that we are vectors OK?",
                    "label": 0
                },
                {
                    "sent": "We have vectors here, and so we have the average.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so very quickly because it's a non non results previous results when you learn a tree you you are doing incrementally.",
                    "label": 0
                },
                {
                    "sent": "Greedy algorithm OK. And for the current training set at a given node, you are going to split this training set and to choose this split to choose the questions you have to ask the coordinates of few data you have to maximize the empirical or addiction.",
                    "label": 1
                },
                {
                    "sent": "The American violence prediction is means that the score you are looking at is variance of your outputs.",
                    "label": 0
                },
                {
                    "sent": "For your training set and the variants of your outputs for the left set for the right set, when you are doing this split OK, everything can be computed with that product.",
                    "label": 0
                },
                {
                    "sent": "OK, at any moment you don't need to work on the Big Y.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "White space.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's nice residents about trees.",
                    "label": 0
                },
                {
                    "sent": "This is the results where you have just you're in learning so you have this kind of tree and we have just here.",
                    "label": 0
                },
                {
                    "sent": "For instance look at this.",
                    "label": 0
                },
                {
                    "sent": "This leave if four OK.",
                    "label": 0
                },
                {
                    "sent": "It's interesting to know that.",
                    "label": 0
                },
                {
                    "sent": "All this data falling into the same list.",
                    "label": 0
                },
                {
                    "sent": "OK, it seems that there is a path from the root to that leaf.",
                    "label": 0
                },
                {
                    "sent": "OK, saying that, you can describe this data by some properties of the inputs and you are able from these properties to identify this subgroups.",
                    "label": 0
                },
                {
                    "sent": "OK, so it means that you can predict this.",
                    "label": 0
                },
                {
                    "sent": "The interaction with in fact input information, as would say we will see later expression of genes.",
                    "label": 0
                },
                {
                    "sent": "Fusion 16 actor on a lot of inputs OK.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So very quickly I'm going to use several times this data set.",
                    "label": 0
                },
                {
                    "sent": "It's a well known data set, so I think.",
                    "label": 0
                },
                {
                    "sent": "Could you Sudan cattle were the first to use it?",
                    "label": 0
                },
                {
                    "sent": "It's 984 proteins, 2478 Edge is an input feature.",
                    "label": 1
                },
                {
                    "sent": "Gene expression.",
                    "label": 0
                },
                {
                    "sent": "Different experiments spend months.",
                    "label": 0
                },
                {
                    "sent": "Data isn't data flow.",
                    "label": 0
                },
                {
                    "sent": "Genetic profiles across 145 one 145 SPPS.",
                    "label": 0
                },
                {
                    "sent": "Presence or absence of an ortholog.",
                    "label": 1
                },
                {
                    "sent": "Localization data and also yes to every day to be cheating, but in fact you will see that these large scale data.",
                    "label": 1
                },
                {
                    "sent": "Help, but not not so much.",
                    "label": 0
                },
                {
                    "sent": "OK and output, of course it's the.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graph of interaction.",
                    "label": 0
                },
                {
                    "sent": "OK so I briefly record this this results.",
                    "label": 0
                },
                {
                    "sent": "Just to say that we compare to different.",
                    "label": 0
                },
                {
                    "sent": "To different works and we are.",
                    "label": 0
                },
                {
                    "sent": "That's at the same level as as the other positive.",
                    "label": 0
                },
                {
                    "sent": "OK, just notice that it's not a single tree, but ensemble methods with Singletary especially, it's extra extra trees that we have talked about.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Out yesterday.",
                    "label": 0
                },
                {
                    "sent": "Another resource here, what can it be useful for except predict physical interaction?",
                    "label": 0
                },
                {
                    "sent": "You can use this to predict function OK in read this the in blue.",
                    "label": 0
                },
                {
                    "sent": "This is the training data in red.",
                    "label": 0
                },
                {
                    "sent": "This is a completed data OK, and what you see in the graph here?",
                    "label": 0
                },
                {
                    "sent": "If you look at this cluster OK in the graph you are going to say OK.",
                    "label": 0
                },
                {
                    "sent": "I'm going to infer that the function here, which is known here will be also shared by other genes.",
                    "label": 0
                },
                {
                    "sent": "OK, of course, it's it's kind of empirical inference, but it does work for summer summer.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some of the cheese products.",
                    "label": 0
                },
                {
                    "sent": "OK, so now let's take another angle and say OK, this is very nice and very powerful.",
                    "label": 0
                },
                {
                    "sent": "But now I like also to use a Colonel in the input space.",
                    "label": 0
                },
                {
                    "sent": "OK, so we are quite used to this, so we're going to extend fact existing method to do that.",
                    "label": 0
                },
                {
                    "sent": "So now we have this positive definite kernel KX.",
                    "label": 1
                },
                {
                    "sent": "OK, that calls for similarities between inputs OK. And what we are going to look we're going to look in fact, that simpler models than than trees, linear models from X to Y.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in fact, we took some inspiration from support vector machine OK and also for maximum magic robot or maximum magic.",
                    "label": 0
                },
                {
                    "sent": "Imagine regulation.",
                    "label": 0
                },
                {
                    "sent": "So by sticking and some arcana and housing.",
                    "label": 0
                },
                {
                    "sent": "You have here the idea that OK, Now we're going to have the same kind of function that is computed for instance in support vector machine.",
                    "label": 0
                },
                {
                    "sent": "But here instead having schara you have a vector OK.",
                    "label": 0
                },
                {
                    "sent": "Please note that we are not deriving this form of the function from some cost function in the dual.",
                    "label": 0
                },
                {
                    "sent": "OK, we're taking this from an applying some minimization.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're all choosing margin here, because really it's it's a regression problem we want to tackle it.",
                    "label": 0
                },
                {
                    "sent": "Call it with the square OK, and we're going to try to learn this parameters.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first of all, it's simpler.",
                    "label": 0
                },
                {
                    "sent": "The simplest idea that comes to mind is to say, OK, I'm going to fit the data OK with the square.",
                    "label": 0
                },
                {
                    "sent": "I'm going to make some penalization on the parameter vector.",
                    "label": 0
                },
                {
                    "sent": "OK, this is nice because when you derive this cost function and I knew the gradient you have across from solution OK like in retrogression.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's the same kind of presence.",
                    "label": 0
                },
                {
                    "sent": "OK, so of course we have the use of this different kernel matrices, which is completely normal because we have input gain and output kernels.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "But this is very nice.",
                    "label": 0
                },
                {
                    "sent": "It's a model quite simple, because what you were just doing, you are doing linear combination of your input output vectors.",
                    "label": 0
                },
                {
                    "sent": "OK, if we look back at work that are being done in another context, mapping strings to strings work of Cortez Mori on Western OK.",
                    "label": 1
                },
                {
                    "sent": "In fact they've done already the extension of.",
                    "label": 0
                },
                {
                    "sent": "Canon, which regression to output can deliver even if they didn't call that like that.",
                    "label": 0
                },
                {
                    "sent": "OK, so they propose this kind of model OK. You have to notice that here you have this big matrix A and the dimension is.",
                    "label": 1
                },
                {
                    "sent": "You have the dimension of your input and output space.",
                    "label": 1
                },
                {
                    "sent": "That might be infinite OK, but who will come later to that?",
                    "label": 0
                },
                {
                    "sent": "OK, so they did this fit least square fitting panelization with four business norm, OK. Also fine closed form solution as in canal retrogression OK.",
                    "label": 0
                },
                {
                    "sent": "So in their case they wanted to finally predict string, so they have to solve a premich problem.",
                    "label": 1
                },
                {
                    "sent": "OK here, it's as as as you see, it's not useful.",
                    "label": 0
                },
                {
                    "sent": "We have this foolish solution, OK, but will usually always use the output of this function inside the DOT product OK?",
                    "label": 1
                },
                {
                    "sent": "So we won't.",
                    "label": 0
                },
                {
                    "sent": "We won't have to suffer preimage problem OK, but so their method here can be applied to the context.",
                    "label": 0
                },
                {
                    "sent": "I have defined OK.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. Let's say let's try to have maybe a different model.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah, we have this, possibly infinite size of the metrics a if the if X&Y as have infinite dimensions, so can we simplify just this?",
                    "label": 1
                },
                {
                    "sent": "This function, yes, it's possible.",
                    "label": 0
                },
                {
                    "sent": "Going just to.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Come back to the definition definition here.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, it's OK. You see here.",
                    "label": 0
                },
                {
                    "sent": "Small mistake here.",
                    "label": 0
                },
                {
                    "sent": "OK, if you write this in a matrix from OK, you have these metrics and here you have a diagonal matrix with vector A in the diagonal.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's looked it looks like very much the Kenner Ridge regression, OK with specific vector.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Something we want to try is to say OK, we're going to define exactly the same model, but here I'm going to restrict these.",
                    "label": 0
                },
                {
                    "sent": "The dimension of A to N * N. OK, contrary to the previous model, which were infinite with infinite.",
                    "label": 1
                },
                {
                    "sent": "Dimension potential yet at least.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can do everything the same.",
                    "label": 1
                },
                {
                    "sent": "I put here on propose the foreignness norm of the world matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, even if my parameters are just the metrics, a OK and again we find across solution.",
                    "label": 0
                },
                {
                    "sent": "So is it a new model?",
                    "label": 1
                },
                {
                    "sent": "In fact not.",
                    "label": 0
                },
                {
                    "sent": "It's just a way to rewrite things.",
                    "label": 0
                },
                {
                    "sent": "OK in this supervised framework, this model and the model.",
                    "label": 1
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are presented by Curtis and all compute the same function.",
                    "label": 0
                },
                {
                    "sent": "OK because if you look at this equation OK, you will see that there is just the.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A difference here that comes from the form of your equation, OK.",
                    "label": 0
                },
                {
                    "sent": "So is it useless?",
                    "label": 0
                },
                {
                    "sent": "No, you will see that.",
                    "label": 0
                },
                {
                    "sent": "In fact it will be good to have some finite set of parameters when we will use variance of the link prediction.",
                    "label": 0
                },
                {
                    "sent": "So I will keep this for the transductive learning case, but it will be nicer to have a finite.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Parameters.",
                    "label": 0
                },
                {
                    "sent": "OK, just some 1st results here.",
                    "label": 0
                },
                {
                    "sent": "So it's a supervised setting with then cross validation and it's just to show you an idea of the scaling of of the methods.",
                    "label": 1
                },
                {
                    "sent": "If you use only gene expression to predict protein protein interaction, which is in fact the best predictor for this prediction, OK?",
                    "label": 1
                },
                {
                    "sent": "You will see this single single output candle tree.",
                    "label": 0
                },
                {
                    "sent": "Is not very performant if you look at the.",
                    "label": 0
                },
                {
                    "sent": "Round as a rocker.",
                    "label": 0
                },
                {
                    "sent": "OK if you now use it in another method such as random price to extra trees, you get a really nice results if you use now our simple model with a vector we have, we get quite nice razors.",
                    "label": 0
                },
                {
                    "sent": "Not as good as the ensemble methods and now if you see a model that big a motel so which is again the same quarters models and the older model.",
                    "label": 0
                },
                {
                    "sent": "The rewriting we would propose we got this results, so it's it's encouraging for the next step, OK?",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we're going to make a more serious comparison.",
                    "label": 0
                },
                {
                    "sent": "OK, so there is this nice paper of blickle on there and they compare.",
                    "label": 0
                },
                {
                    "sent": "Network construction methods will be a large set of larger bunch of methods OK. And So what we did we use their setting to be able to compare with them.",
                    "label": 1
                },
                {
                    "sent": "OK so first we have to notice that.",
                    "label": 0
                },
                {
                    "sent": "The local methods that is proposing a empirically on Anna at all are only can only be applied to the prediction of interaction between learning and training sets.",
                    "label": 1
                },
                {
                    "sent": "This is what this is.",
                    "label": 0
                },
                {
                    "sent": "The reason why is that we have to remember that we have a classifier linked one protein OK, and you learn how to classify potential candidates and to say yes this candidate can be linked to the protein.",
                    "label": 1
                },
                {
                    "sent": "So it's not exactly the same framework as you or the other methods, but at least we can compare on this prediction OK?",
                    "label": 0
                },
                {
                    "sent": "So what we did we use the standard cross validation and has we have hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "As you see, we have this number one.",
                    "label": 0
                },
                {
                    "sent": "OK, we need to perform some parameter selection OK and to try to be able to get to fit into this setting.",
                    "label": 0
                },
                {
                    "sent": "We pair from an internal 5V5 cross validation CV using the area under the.",
                    "label": 0
                },
                {
                    "sent": "F dear curve to be able to select the best parameters.",
                    "label": 0
                },
                {
                    "sent": "OK, so first I'm going to show you the results for the simpler simple Model H small a OK An here what you?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. You have the results for all the data.",
                    "label": 0
                },
                {
                    "sent": "OK, so training test sets, rashes running set.",
                    "label": 0
                },
                {
                    "sent": "Test suggests learning set so all the parts of this matrix OK so remaining part of the matrix OK. And of course.",
                    "label": 0
                },
                {
                    "sent": "You look at the results as we show before we as we have seen before.",
                    "label": 0
                },
                {
                    "sent": "It's OK is that it's rather good, not not very, very exciting.",
                    "label": 0
                },
                {
                    "sent": "OK, if we look at the different here, inputs, expression, localization, flow, genetic yes too, I break data integration of everything.",
                    "label": 0
                },
                {
                    "sent": "OK, you see that usually you can improve.",
                    "label": 0
                },
                {
                    "sent": "OK, that's.",
                    "label": 0
                },
                {
                    "sent": "Weather is here to be strange, but OK with the area under the FDR.",
                    "label": 0
                },
                {
                    "sent": "OK, we have quite high values, but if we look at all the methods as we will see it's more or less the same.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now if we look at the H model, which is a more complex model, OK, much more, richer, OK, then you get really nice performance.",
                    "label": 0
                },
                {
                    "sent": "OK, nice performance here in you see AUC area under the Roc curve and also area under the FDR graphs.",
                    "label": 0
                },
                {
                    "sent": "OK, these are supposed to be as minimal as possible, so it's still big.",
                    "label": 0
                },
                {
                    "sent": "OK, it's still large, but.",
                    "label": 0
                },
                {
                    "sent": "It's it's it's OK.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Especially if we compare to this big results provided by publicly and I in 2007.",
                    "label": 0
                },
                {
                    "sent": "So here this is the.",
                    "label": 0
                },
                {
                    "sent": "Five fold cross validation exactly the same, the same.",
                    "label": 0
                },
                {
                    "sent": "But anyway, we have used OK.",
                    "label": 0
                },
                {
                    "sent": "They compared a lot of methods here and here is the result for protein protein interaction.",
                    "label": 0
                },
                {
                    "sent": "So to be honest in the metabolic networks they perform very well, especially the local methods is dramatically is dramatically increasing its performance when integrating information.",
                    "label": 0
                },
                {
                    "sent": "It's quite magic in fact, but if you look at protein protein interaction, which is in fact our propose.",
                    "label": 0
                },
                {
                    "sent": "We're going to look at this his data.",
                    "label": 0
                },
                {
                    "sent": "OK, this results and you will see that.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the supervised setting where we have very good weather.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That were those methods?",
                    "label": 0
                },
                {
                    "sent": "OK, so here is so M of code.",
                    "label": 0
                },
                {
                    "sent": "It's true that is performing the best results.",
                    "label": 0
                },
                {
                    "sent": "Here we are.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe we're just a little bit.",
                    "label": 0
                },
                {
                    "sent": "Just a hug.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the message is not, you know, comparing exactly each method that saying OK, this pull of method can solve the problem.",
                    "label": 0
                },
                {
                    "sent": "It is at the level of other methods on an sometimes better.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is a good tool to addressing prediction, but the prediction in fact could be could benefit from the use of unlabeled data when you talk to a biology.",
                    "label": 0
                },
                {
                    "sent": "So for instance we are working on the cystic fibrosis.",
                    "label": 0
                },
                {
                    "sent": "So human protein with biologists so he knows already.",
                    "label": 0
                },
                {
                    "sent": "Set of proteins that you want to link.",
                    "label": 0
                },
                {
                    "sent": "OK, this big set.",
                    "label": 0
                },
                {
                    "sent": "Be changing OK. We know already the protocol.",
                    "label": 0
                },
                {
                    "sent": "OK, so you know that and you want to complete this interaction.",
                    "label": 0
                },
                {
                    "sent": "This interaction.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's more a transitive problem than a supervised one.",
                    "label": 0
                },
                {
                    "sent": "OK, so here remember that in our setting it's quite specific we need this gram matrix as input, so we will be always looking at the problem as a matrix completion.",
                    "label": 0
                },
                {
                    "sent": "OK, we need a few examples, few proteins, while you know everything.",
                    "label": 0
                },
                {
                    "sent": "OK, this is an important limitation.",
                    "label": 0
                },
                {
                    "sent": "I want to not too I this OK, but we're going to try.",
                    "label": 0
                },
                {
                    "sent": "To make the set of labeled data as small as possible.",
                    "label": 0
                },
                {
                    "sent": "And the idea is we will be to use this input input cannot.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Store to make the.",
                    "label": 0
                },
                {
                    "sent": "So prediction OK, so very fast OK?",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to.",
                    "label": 0
                },
                {
                    "sent": "To go a little faster, OK?",
                    "label": 0
                },
                {
                    "sent": "If you look at some supervised regression, maybe you know that very common cost function as you try to fit the data with the label data and try to have smoothness assumption.",
                    "label": 0
                },
                {
                    "sent": "Something that you can tell about your data even if they are unlabeled, you can always say that the function I want to build must be continuous, must be smooth, and you can say that for any couple of inputs.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Sorry, this smoothness assumption was proposed by many researchers and it's based on the lab Russian operators again.",
                    "label": 1
                },
                {
                    "sent": "And of course, if we want to use this.",
                    "label": 1
                },
                {
                    "sent": "So this function is better to start with the smooth model.",
                    "label": 0
                },
                {
                    "sent": "OK, so trees here are not fully appropriate, while in fact linear combination could be eligible OK.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We are going to use this input output kernel models sort of Model H small A through the HCK OK so now just be careful changed notation so P is a number of labeled proteins OK, and the total number of proteins OK. And here what you see is you see the cost function with classic traditional least square with some penalization.",
                    "label": 1
                },
                {
                    "sent": "OK and you just add this constraint saying that.",
                    "label": 0
                },
                {
                    "sent": "OK, you have this smoothness assumption OK.",
                    "label": 0
                },
                {
                    "sent": "So this move this assumption, you can write it nicely OK as a trace of this lab machine operator.",
                    "label": 0
                },
                {
                    "sent": "OK, you have this really nice writing, but the most important is to say, OK, I'm trying to use information about inputs.",
                    "label": 0
                },
                {
                    "sent": "If two proteins are closed, the input space, I want the output of my predictor will be closed.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then I think with the.",
                    "label": 0
                },
                {
                    "sent": "An L2 panelization is that you come again for you come again two across from solution OK.",
                    "label": 0
                },
                {
                    "sent": "So everything can be rightly if you again if you derive the cost function.",
                    "label": 0
                },
                {
                    "sent": "If you knew it, you will find a single solution OK, and again it will be the same for the model HB A and the MPN OK.",
                    "label": 0
                },
                {
                    "sent": "Please notice that in this case we have different models.",
                    "label": 0
                },
                {
                    "sent": "OK, in the supervised case everything was completely equivalent.",
                    "label": 0
                },
                {
                    "sent": "Here you won't choose exactly.",
                    "label": 0
                },
                {
                    "sent": "You won't get exactly the same solution, OK?",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So a protocol to test this is the following.",
                    "label": 0
                },
                {
                    "sent": "OK, so you have this level data.",
                    "label": 0
                },
                {
                    "sent": "OK, we have this.",
                    "label": 0
                },
                {
                    "sent": "Yes data and we are going to use this intensively to try to test our methods.",
                    "label": 0
                },
                {
                    "sent": "OK, so the idea is first to say OK, I'm going to sample a subset of pea proteins.",
                    "label": 0
                },
                {
                    "sent": "OK, and I will do this a lot of times for each sample of people.",
                    "label": 0
                },
                {
                    "sent": "10s?",
                    "label": 0
                },
                {
                    "sent": "OK, I will be able to.",
                    "label": 0
                },
                {
                    "sent": "However, a problem and I we need to select my hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "So now the one and longer to OK.",
                    "label": 0
                },
                {
                    "sent": "In fact other parameters that are linked with kernels, diffusion, diffusion parameter and parameters for instance, variance in the Goshen OK.",
                    "label": 0
                },
                {
                    "sent": "So this election is the following we are going to use for cross validation Y-44.",
                    "label": 0
                },
                {
                    "sent": "In fact, as you will see, will take very small amount of data, label data and so we need we need.",
                    "label": 0
                },
                {
                    "sent": "We need to make a compromise between data that we need to validate to test and data for learning.",
                    "label": 0
                },
                {
                    "sent": "So we use this four fold cross validation here.",
                    "label": 0
                },
                {
                    "sent": "So you made in that in this matrix you are leaving some of the.",
                    "label": 0
                },
                {
                    "sent": "Example for test.",
                    "label": 0
                },
                {
                    "sent": "So you are learning this.",
                    "label": 0
                },
                {
                    "sent": "You are testing in the 1/4 of your data.",
                    "label": 0
                },
                {
                    "sent": "Do this force and you select your parameters.",
                    "label": 0
                },
                {
                    "sent": "OK, so be careful, it's protocol for transductive learning so where we're going.",
                    "label": 0
                },
                {
                    "sent": "We're going to predict here all these missing data.",
                    "label": 0
                },
                {
                    "sent": "OK, and we will evaluate here the area under the Roc curve and the area, and there's a full discovery rate.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So just last last results.",
                    "label": 0
                },
                {
                    "sent": "OK, it's in fact the 1st results with the model HA, which is not the best OK and just to show you if I take 10% of the data as lab data, 10% of the notes OK, it means in fact 1% of the edges OK.",
                    "label": 1
                },
                {
                    "sent": "If you remember that the number of edges if you have any notes, it's end times N -- 1.",
                    "label": 0
                },
                {
                    "sent": "Divided by by two.",
                    "label": 0
                },
                {
                    "sent": "OK then you have this 1% of edges, so it's very far from other works that take 25% of the data or or things like that.",
                    "label": 1
                },
                {
                    "sent": "OK, it's really a small amount of edges, which is known OK, and here you can see the supervised setting and the transitive setting.",
                    "label": 0
                },
                {
                    "sent": "And of course adding lab level data, sorry.",
                    "label": 0
                },
                {
                    "sent": "If you look here at more data you will see again this this little increasing K of the performance.",
                    "label": 0
                },
                {
                    "sent": "OK, we have exactly the same as the same kind of performance in UFOK.",
                    "label": 0
                },
                {
                    "sent": "So can we.",
                    "label": 1
                },
                {
                    "sent": "Compare with other transductive methods.",
                    "label": 0
                },
                {
                    "sent": "OK, it's a bit special because the the other methods they randomly sample some data which they.",
                    "label": 0
                },
                {
                    "sent": "Which supposed not to be, not to be known.",
                    "label": 1
                },
                {
                    "sent": "OK, here we have a sub matrix which is known.",
                    "label": 0
                },
                {
                    "sent": "So the setting is quite different than in fact for other transition methods our setting is quite disadvantageous.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have we have to define something that we don't know quite yet.",
                    "label": 0
                },
                {
                    "sent": "Well how we're going to compare.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This OK?",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to yeah I'm going to finish and complete.",
                    "label": 0
                },
                {
                    "sent": "OK, the first message I want to tell you is to say please look at the output space in your problem.",
                    "label": 0
                },
                {
                    "sent": "Try usually people take a lot of time to define input space which is really important, but output space can really open a larger Ave to new task and maybe to get more information on your problem so user can entry.",
                    "label": 1
                },
                {
                    "sent": "Go to space is just an example of doing that, but be careful to the output space.",
                    "label": 0
                },
                {
                    "sent": "It's really important to to define that.",
                    "label": 0
                },
                {
                    "sent": "OK, I will go through.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This perspective now, so now we are working with a biologist, Alexander Edelman, in Nickell spittle at in Paris, OK. Ann is interesting in the potency eftir, whose mutations are involved in cystic fibrosis OK and what he wants to do.",
                    "label": 1
                },
                {
                    "sent": "We want to complete the known.",
                    "label": 0
                },
                {
                    "sent": "Interaction network around this protein to be able to to better know partners of these proteins, which is big macromolecule.",
                    "label": 0
                },
                {
                    "sent": "OK, so to do that we have to solve?",
                    "label": 0
                },
                {
                    "sent": "Send some problem first, as you may be notice that we didn't dealt with the imbalance set of examples.",
                    "label": 1
                },
                {
                    "sent": "In fact, in our framework, the fact that you have absence of negatives is not taken into account.",
                    "label": 1
                },
                {
                    "sent": "We have made the assumption that the small sub metrics is known, but everything is known for this agent was here submatrix.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have to go with that so second.",
                    "label": 0
                },
                {
                    "sent": "Point we want to improve is the fact that it's good to just integrate every information by computing the mean of kennel.",
                    "label": 0
                },
                {
                    "sent": "But it would be nice to automatically select which kind of input kernel you want to use.",
                    "label": 0
                },
                {
                    "sent": "And finally, as I'm also working on graphical pricing model, I'm very attracted by the new direction that could be defined.",
                    "label": 0
                },
                {
                    "sent": "A graphical probabilistic model.",
                    "label": 0
                },
                {
                    "sent": "So encapsulate all the thing into logistic regression like model, because in that case you can mix local approaches with nature and global approaches as we do here.",
                    "label": 0
                },
                {
                    "sent": "OK, and the last point, but not there is.",
                    "label": 0
                },
                {
                    "sent": "In fact, I think I would put calibration can be used in many many settings to solve different problems.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that if you find the right output space, maybe if you are able to solve some pre image problem then you can do this method.",
                    "label": 1
                },
                {
                    "sent": "I thank you.",
                    "label": 0
                }
            ]
        }
    }
}