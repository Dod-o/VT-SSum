{
    "id": "f5sdevjkd43xrpxivp6pbtdhtt2yi6es",
    "title": "Graph Embedding using an Edge-Based Wave Kernel",
    "info": {
        "author": [
            "Edwin Hancock, Department of Computer Science, University of York"
        ],
        "published": "Sept. 13, 2010",
        "recorded": "August 2010",
        "category": [
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/ssspr2010_hancock_geu/",
    "segmentation": [
        [
            "So let me."
        ],
        [
            "Begin by motivating this work.",
            "For number of years what we've been doing in New York is trying to study the problem."
        ],
        [
            "Of learning with graph data, and in particular what we've been attempting to do is to is to determine characterizations of graphs that can be used to learn properties of sets of graphs.",
            "So, for instance, these graphs might be delivered by processing problems in natural language processing.",
            "Proteomics coming from attics, data mining, computer vision, which is really the application I'm going to be talking about today, or complex."
        ],
        [
            "Items now if you look at the literature, there's relatively little methodology available, and Victoria methods from statistical machine learning are not easily applied to problems involving graphs.",
            "Since there is no Canonical ordering of the nodes of the graph."
        ],
        [
            "Of however, the observation that we've come up with in this work is that you can make considerable progress if you can develop methods for extracting permutation invariant characterizations for the very for variations in graph structure."
        ],
        [
            "So to give you an example, here's a sequence of data that is extracted from a an image processing problem.",
            "Here we have an example of a.",
            "Select sequence of images of the house as a camera pans around the object.",
            "What we've done is we've extracted corner features from the images and then we've constructed graph representations by building Delaunay Triangulation's on the point features in the graphs and the thing to note about this data is that as you pan through the motion sequence, the.",
            "So where's the pointer?",
            "Has appointed OK.",
            "Thank you as you pass through the sequence, then the overall node structure varies relatively gradually, but as we go from view to view then the edge structure within the graph varies and would like to capture the way in which this varies through the motion sequence."
        ],
        [
            "Now there's a problem with doing this and that is as follows.",
            "In computer vision, graph structures are frequently used to abstract image structure.",
            "However, the algorithms that we use to segment the image primitives are not rely."
        ],
        [
            "Bible.",
            "And so as a result, we have both additional missing nodes due to segmentation error and variations."
        ],
        [
            "Head structure.",
            "So if we were to attempt image matching and recognition using graph representations than these, generally speaking could not easily be reduced to graph isomorphism or even subgraph isomorphism problems.",
            "Instead, we have to use in."
        ],
        [
            "Zach graph matching techniques.",
            "So learning with graph CS is generally a difficult problem, and what I've done here is to summarize the technical problems that arise.",
            "First of all, graphs are not vectors, so there's no natural ordering the nodes and edges in the graph.",
            "If we want to establish such an ordering, then we need to establish correspondences between nodes and that establishing correspondence matches, as pointed out in renders talk earlier is a computationally expensive task.",
            "If we want to capture structural variations.",
            "In a sequence of graph, then we have to be able to deal with the problems that number of nodes and edges not fixed and they can vary due to segmentation error.",
            "So if you put these two problems together, what it means is that graphs are not easily summarized and since they don't reside in a vector space, quantities such as mean and covariance are hard to character."
        ],
        [
            "Rise.",
            "So if we were to attempt to.",
            "Characterize the problems which are involved in learning with graphs.",
            "We could go from the sort of easy to the difficult as you go through the points on this list.",
            "So the simplest problem over graph learning might be to work with the similarities.",
            "If we're able to measure distances between graphs or similarities between graphs, then what we can do is to use pairwise clustering methods to assess.",
            "Attempt to learn the class structure.",
            "Of next next sort of more complicated problem might be to involve involve embedding individual graphs into a low dimensional space, and if we can do this then we can characterize structural variations in terms of, uh, statistical variation in the point pattern, which results from the embedding, and so these methods are really fairly straightforward.",
            "But if we would try to do something more ambitious, that is to try to learn a generative model of graphs, then we have sort of two more complicated steps that we have to perform.",
            "The first is we need to learn the modes of structural variation in a set of graphs, and this means we need to understand how edge connectivity structure varies for grass belong to the same class.",
            "And generally speaking, this problem requires correspondences between the raw structure and is a computationally demanding problem.",
            "However, one way around this might be to try to characterize the properties of graphs using permutation invariant characteristics.",
            "And so, for instance, properties such as path length, commute time, or cycle frequencies might prove to be useful.",
            "And then once we have such a characterization of variation in hand, what we want to do is to put a probability distribution on top of it, and then to construct a generative model which would be capable of describing the distribution of variations with parameters of edge and node structure variation."
        ],
        [
            "So if we will try to try to simplify the learning problem, this would be a sort of a strategy you might adopt, and it's something that we've done in the past which is proved to be a reasonably successful.",
            "What we want to do is to find an efficient means of characterizing graph structure which is not involved with exhaustive, exhaustive search or correspondence, and So what we want to do is to be able to enumerate graph structure without explicit search.",
            "For instance, to determining cycle counts, path link frequencies, and so on and so forth, and so can we compute these things without actually solving the graph matching problem and the answer to this is yes, if you try to analyze a graph using a random walk or diffusion process using the heat equation, then many of these quantities here come about naturally without actually having to perform.",
            "Exhaustive search, so the question I want to to ask him this.",
            "This talk is as follows.",
            "Since the heat equation and the diffusion on the graph that proved to be a very relatively powerful technique for trying to analyze graph structure without actually performing search and without actually computing correspondences, are there alternatives that we could use which give Richard description?"
        ],
        [
            "Characterizations?",
            "So why is it?",
            "Is this interesting?",
            "Why such a topical problem?",
            "Well, it's that the reasons are summarized on this slide here.",
            "Recently, the notion of performing calculus on graphs have become a popular one in the mathematics literature, particularly through the work of Friedman, and this is meant that a richer family of physical operators can be extended from the continuous domain to the graph domain.",
            "And the particular relevance to the talk here is that it's possible to now to be able to define a wave equation on a graph using these.",
            "These notions of calculus on graphs, and this is done through introducing the concept of an edge based Laplacian.",
            "I'll explain a little bit later on what the vertex based Laplacian is and with this edge based Laplacian at hand, what we can do is we can try to analyze a graph in terms of its vibrational modes.",
            "And try to use these vibrational modes as a characterization.",
            "And really the question is, I'm trying to explore in this talk is it can this kind of analysis based on physical operators on graphs?",
            "In particular, the wave equation leads to interesting characterizations and new types of embeddings."
        ],
        [
            "OK, so let me talk a little bit now about the technical background to the talk before I go into some of the details of what we've done.",
            "So what I want to do?"
        ],
        [
            "This is to introduce you to the concept that Friedman developed in his work on calculus on graphs, particularly the idea of an edge based wave equation.",
            "So we have done.",
            "Here is, I've really given you an idea of what the process does.",
            "According to Friedman, we could think of the edges of a graph is taut strings that are joined at the vertices or nodes of a graph, and if we if we want to characterize.",
            "Characterize this behavior.",
            "Then what we need to do is to define a Laplacian operator that operates on the edges of the graph rather than on the the nodes of the graph, and what Friedman has shown is that if we, if we have the familiar the policy and based on the nodes of the graph and I'll define in some detail what this has, this is computed in a few moments.",
            "Then this is related to the policy and which is computed on the edge edges of the graph.",
            "Via the following formula and so with this edge based the plastic in hand.",
            "What we can now do is to try to analyze the vibrational modes that exist using this model of the graph where the edges are taught strings and we have fixed nodes and try to examine this.",
            "The solutions of this wave equation to see whether they give us an interesting characterization which we can use to study the properties of sets of graphs.",
            "So this is the wave equation just to to remind you what is the 2nd order differential equation and the second the second time derivative of the wave.",
            "Wave equation is just equal the edge by fashion times the the wave operator."
        ],
        [
            "So this is the outline following trying to do in this talk.",
            "What I want to do is to describe a new approach for embedding graphs in a in a vector space based on the wave kernel, what we're going to do is to try to have a look at the wave equation and what I'll do is to show you how the solution of the wave equation or the wave kernel has an eigensystem which is determined by the eigenvalues and eigenfunctions of normalized adjacency matrix.",
            "So we don't actually have to compute explicitly.",
            "The edge based class Chen.",
            "It's implicitly determined by the Laplacian the vertex the passing of the graph, and then what I'll do is describer and embedding of the wave kernel of a graph into a vector space based on the gram matrix factorization.",
            "And then I'll just provide some very preliminary results at the end on how we've used this embedding in order to generate point characterizations of graphs and how this has led to different clusters clusters.",
            "Of graphs representing different type."
        ],
        [
            "Of objects.",
            "OK.",
            "So this is the approach we're going to do is to treat the normalized dissimilarity matrix for a set of data as a way of kernel compute the spectrum of the edge based applausi, and using the analysis given by Friedman.",
            "And then we're going to embed the.",
            "The graphs into a vector space using an embedding which deals with."
        ],
        [
            "Potential complex eigenvalues.",
            "So let's just talk a little bit about the theory which underpins this, particularly the relationship between the vertex, the plastic in the heat equation, which is really now."
        ],
        [
            "Familiar stuff?",
            "Then I'll show you how this extends to the wave kernel and the wave equation on a graph.",
            "So here is the sum of the formulas."
        ],
        [
            "What we're going to be dealing with is a weighted adjacency matrix where the elements of the adjacent sides weighted adjacency matrix of weights.",
            "Provided that though the corresponding pair of nodes are connected by edges from the other weighted adjacency matrix, we compute degree matrix and then the vertex Laplacian is just the degree matrix minus adjacency matrix.",
            "The what it's normal to do is to work in terms of the eigen decomposition over Laplacian matrix.",
            "So what I've done is I've written this down here in terms of an eigenvector matrix Phi which has the ordered eigen vectors as columns and an eigenvalue matrix Lambda which has the ordered eigenvalues as diagonal elements and so this is the eigen decomposition of the Laplacian matrix in terms of the eigenvalue and eigenvector matrices.",
            "And then we note some of the properties of the eigenvalues of the plus here."
        ],
        [
            "That is to say that they are always greater than or equal to 0 multiplicity of zero eigenvalue gives a number of key components in the graph, and the eigenvector associated with the second smallest eigen value is the Fiedler vector that's been extensively used in clustering problems in Patton analysis machine and intelligence."
        ],
        [
            "So how does the heat kernel come about?",
            "Well, it's a solution of this simple 1st order differential equation.",
            "The heat kernel satisfies the following relationship is derivative is just minus its time, derivative is just minus to plus Ian times the heat kernel itself.",
            "You'll recognize this as being a differential equation that has an exponential solution, and it turns out that if we have the spectrum of the placinta hand.",
            "Then the heat kernel can be found by pre and post multiplying the time exponential of the eigen.",
            "Eigenvalue diagonal eigenvalue matrix by the eigenvector matrix and its transpose."
        ],
        [
            "And it turns out that the kernel is particularly important in analyzing the properties of continuous time random walks, so continuous time random walk has a state vector P of T. That's the probability of of.",
            "A vector that contains the probability of visiting each of the nodes.",
            "The graph at time T. It solves the following first order differential equation and it turns out that the state vector at time T is just given by the heat kernel at time T times initial state vector.",
            "Analysis of this kind of continuous time random walk leads to a number of characterizations of graph structure, particular the heat kernel turns out to encode information.",
            "About things such."
        ],
        [
            "Is the path length distribution on the graph number of spanning trees in a graph and also it's commute the distribution of commute times?",
            "So we've explored these ideas fairly thoroughly in a series of papers aimed at graph characterization, but now what I want to do is to see whether alternative operators, differential operators on graphs, alternatives to the heat equation yield other interesting characterizations.",
            "So what I want."
        ],
        [
            "To do is just to spend a little bit of time talking about what the wave equation is and how it's linked to the edge based applausi and and how the study of the vertex Laplacian gives US solutions to the wave equation.",
            "So what I've done here is I've written down the heat equation on the wave equation next to each other so you can compare and contrast the different differential operators involved.",
            "The heat kernel is a solution of the equation H = -- L A v * H where LV is the vertex Laplacian which I've defined few slides ago.",
            "The wave equation, on the other hand, is a second order differential equation and.",
            "The Wave kernel is W is a solution of www.double.orthesecond derivative of the wave kernel equals minus the edge Laplacian now times the wave kernel."
        ],
        [
            "So you can you can solve this second order differential equation fairly easily.",
            "What I've done is I've I've given the solution here, so here I've just switched the notation from notation www.two WT to mean the second derivative, so this is the wave equation.",
            "Now impose some boundary conditions on it, and so the solution T = 0 is F and the velocity.",
            "Or the first derivative of the wave kernel at time T = 0 is given by G. So with the initial conditions and the velocity, the solution of the wave equation is given by this sinusoidal form and it's determined by the square root of the edge based Laplacian and the time at which we evaluate the kernel."
        ],
        [
            "And of course you can simplify this to give different forms, and so here's a simplification.",
            "When we take, we set the function F to be 0 everywhere and we take the unit velocity everywhere.",
            "And if you do that then the solution of the wave equation is given here and you can analyze this operator for small values of time and this gives an expansion of the wave wave, kernel Mclaurin expansion for small time values in terms of the edge based Laplacian."
        ],
        [
            "No, what we'd like to be able to do is in order to find the wave kernel, we need to construct the edge based applausi and and it turns out to be natural in this case.",
            "To work with the normalized adjacency matrix.",
            "So what I've done here is written down the definition of normalized weighted adjacency matrix and that's just the inverse of the square root of the degree matrix times the original adjacency matrix.",
            "Post multiplied by one over the square root of the degree matrix.",
            "So what I want to do is to show you that the construction of the edge based occlusion is effectively an implicit problem, since it's determined by the computer spectrum of the vertex deploy."
        ],
        [
            "See EN.",
            "So here's some analysis.",
            "This is taken directly from Friedman's paper.",
            "The relationship between the vertex capacity and and the Angel passion is given by the following is just the vertex.",
            "Laplacian is just one minus the cosine of the square root of the edge Laplacian.",
            "So we can now reorganize this.",
            "It turns out that the cosine of the square root of the edge Laplacian is just going to be 1 minus the normalized vertex Laplacian or the normalized adjacency matrix.",
            "So now we can.",
            "Now we know this relationship between the normalized adjacency matrix and the edge based Laplacian.",
            "We can determine the spectrum of the edge based applausi and and so if the if the cosine of the square root of Lambda belongs to the spectrum of the adjacency matrix, that means that Lambda belongs to the spectrum of the edge based Laplacian.",
            "So this gives the spectrum of the edge based the policy and we want to compute its eigen functions.",
            "Then we need to use the following.",
            "Are relationships so if F is an eigenfunction of the normalized adjacency matrix, cosine and square root of Lambda, thrive Mr. Square root out there is an eigenvalue of normalized adjacency matrix.",
            "Then this means that F is an eigenfunction of the edge based blasian and Lambda is an eigenvalue of the edge base Laplacian and the other the other condition applies.",
            "Is this one here?",
            "Which is that the we take the eigen functions F. Then when we operate on those with the vertex Laplacian then we get 0."
        ],
        [
            "So what does this mean?",
            "Well, here's what the spectrum of the edge based of classy and that comes out of that analysis.",
            "And so you see, the number of harmonics corresponding to the harmonic frequencies of vibration of the edges on the graph.",
            "And if we want to make a physical interpretation."
        ],
        [
            "Of the process, then what we've just done is described the vibrational modes associated with taut strings on each edge.",
            "These are joined together at the vertex.",
            "If we excite or pluck the system, then it produced tones with frequencies whose spectrum ranges over the edge based eigen values and their harmonics."
        ],
        [
            "And if we try to sort of think about it and sort of more computational sense, well the if we if we project the nodes of the graph onto the eigenspace occurrence corresponds to harmonic frequencies of the corresponds to the eigen functions.",
            "And what we're doing is we're projecting onto a space spanned by the harmonic frequencies of the graph because of the second condition that I showed you here on the eigenfunctions.",
            "What this means is that the nodes are stationary under and vibration.",
            "So you can think of them as being the nodes on a constraint as a string and negative eigen space resulting from analysis constant response to non physical vibration modes."
        ],
        [
            "So I think I mean I don't want to to go into any more depth because I think I'm running short of time, but what we've done is we've taken this this analysis and we've done."
        ],
        [
            "An embedding based on it.",
            "The details are on the paper, so I'll just skip through that section of the analysis and come on to some experiments that we've done to show you the kind of embeddings that we get on the basis of the wave kernel analysis.",
            "So what we've done is we've used two datasets.",
            "These have been well explored in our own work and other people's work.",
            "The first is the data set of three sequences of images of model houses.",
            "Here we have Delaunay graphs for each of the points sets in each of the images, and there are three different classes of object corresponding to the different views of the three different houses.",
            "But then we've also used the coil database.",
            "We've taken 45 objects from that, and what we've done is we for each object there are 72 views, and we've extracted the Delaunay graphs.",
            "Of SIFT features extracted from from these images."
        ],
        [
            "So this just runs through the the computational steps that we've adopted.",
            "What we do is we compute the eigensystem of normalized adjacency matrix.",
            "This allows us to construct the edge based the classy and we then computed the edge kernel with different time values and use these to construct embedding matrices.",
            "And then we've developed a procedure here to catch the negative eigen space associated with negative eigenvalues."
        ],
        [
            "So here are the embeddings that we get from the analysis.",
            "The wave kernel analysis of the graphs.",
            "So what in these images what we've done is we've taken the House data point in each in these plots represents a an image and what we've done is we have for each image we've computed the wave kernel embedding and then once we have the embedding points, what we've done is we've computed the distance.",
            "Between pairs of images using a Hausdorff distance, and so with that distance we can perform multidimensional scaling to embed the individual graphs.",
            "That sort of family of graphs into it into an eigenspace for different values of the two parameter of the wave kernel.",
            "What you see is that this gives reasonable separation of the House data."
        ],
        [
            "If we look at what we got with the heat kernel, these are similar results and there's some suggestion that the data here is a little bit more overlapped.",
            "And then what we've done is we have repeated this analysis for the coil data and again we get reasonable separation, reasonable visual separation of the different object classes, and then what I've"
        ],
        [
            "And here is, I've given the Rand index, so this is here.",
            "The smaller the index, the better of the classification we had because we have a number of incorrect's divided by number of incorrect plus correct classifications.",
            "Notice that we can get.",
            "Of clusterings with pretty low values of the Rand index for the House data not so impressive for the for the coil data.",
            "OK, so just to conclude."
        ],
        [
            "What we've done is develop a new approach for embedding."
        ],
        [
            "Ralphs based on the Wave kernel.",
            "I haven't really talked about how we deal with net the negative eigen space in this analysis due to shortage of time.",
            "But based on the experiments that we get reasonable results from this from this approach and although this is now fairly preliminary, work suggests that there might be characterizations that you can extract from the wave kernel that can lead to interesting graph clustering results.",
            "So thank you very much indeed."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Begin by motivating this work.",
                    "label": 0
                },
                {
                    "sent": "For number of years what we've been doing in New York is trying to study the problem.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of learning with graph data, and in particular what we've been attempting to do is to is to determine characterizations of graphs that can be used to learn properties of sets of graphs.",
                    "label": 1
                },
                {
                    "sent": "So, for instance, these graphs might be delivered by processing problems in natural language processing.",
                    "label": 0
                },
                {
                    "sent": "Proteomics coming from attics, data mining, computer vision, which is really the application I'm going to be talking about today, or complex.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Items now if you look at the literature, there's relatively little methodology available, and Victoria methods from statistical machine learning are not easily applied to problems involving graphs.",
                    "label": 0
                },
                {
                    "sent": "Since there is no Canonical ordering of the nodes of the graph.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of however, the observation that we've come up with in this work is that you can make considerable progress if you can develop methods for extracting permutation invariant characterizations for the very for variations in graph structure.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to give you an example, here's a sequence of data that is extracted from a an image processing problem.",
                    "label": 0
                },
                {
                    "sent": "Here we have an example of a.",
                    "label": 0
                },
                {
                    "sent": "Select sequence of images of the house as a camera pans around the object.",
                    "label": 0
                },
                {
                    "sent": "What we've done is we've extracted corner features from the images and then we've constructed graph representations by building Delaunay Triangulation's on the point features in the graphs and the thing to note about this data is that as you pan through the motion sequence, the.",
                    "label": 0
                },
                {
                    "sent": "So where's the pointer?",
                    "label": 0
                },
                {
                    "sent": "Has appointed OK.",
                    "label": 0
                },
                {
                    "sent": "Thank you as you pass through the sequence, then the overall node structure varies relatively gradually, but as we go from view to view then the edge structure within the graph varies and would like to capture the way in which this varies through the motion sequence.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now there's a problem with doing this and that is as follows.",
                    "label": 0
                },
                {
                    "sent": "In computer vision, graph structures are frequently used to abstract image structure.",
                    "label": 1
                },
                {
                    "sent": "However, the algorithms that we use to segment the image primitives are not rely.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bible.",
                    "label": 0
                },
                {
                    "sent": "And so as a result, we have both additional missing nodes due to segmentation error and variations.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Head structure.",
                    "label": 0
                },
                {
                    "sent": "So if we were to attempt image matching and recognition using graph representations than these, generally speaking could not easily be reduced to graph isomorphism or even subgraph isomorphism problems.",
                    "label": 1
                },
                {
                    "sent": "Instead, we have to use in.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Zach graph matching techniques.",
                    "label": 0
                },
                {
                    "sent": "So learning with graph CS is generally a difficult problem, and what I've done here is to summarize the technical problems that arise.",
                    "label": 0
                },
                {
                    "sent": "First of all, graphs are not vectors, so there's no natural ordering the nodes and edges in the graph.",
                    "label": 1
                },
                {
                    "sent": "If we want to establish such an ordering, then we need to establish correspondences between nodes and that establishing correspondence matches, as pointed out in renders talk earlier is a computationally expensive task.",
                    "label": 0
                },
                {
                    "sent": "If we want to capture structural variations.",
                    "label": 0
                },
                {
                    "sent": "In a sequence of graph, then we have to be able to deal with the problems that number of nodes and edges not fixed and they can vary due to segmentation error.",
                    "label": 1
                },
                {
                    "sent": "So if you put these two problems together, what it means is that graphs are not easily summarized and since they don't reside in a vector space, quantities such as mean and covariance are hard to character.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rise.",
                    "label": 0
                },
                {
                    "sent": "So if we were to attempt to.",
                    "label": 0
                },
                {
                    "sent": "Characterize the problems which are involved in learning with graphs.",
                    "label": 1
                },
                {
                    "sent": "We could go from the sort of easy to the difficult as you go through the points on this list.",
                    "label": 0
                },
                {
                    "sent": "So the simplest problem over graph learning might be to work with the similarities.",
                    "label": 0
                },
                {
                    "sent": "If we're able to measure distances between graphs or similarities between graphs, then what we can do is to use pairwise clustering methods to assess.",
                    "label": 0
                },
                {
                    "sent": "Attempt to learn the class structure.",
                    "label": 0
                },
                {
                    "sent": "Of next next sort of more complicated problem might be to involve involve embedding individual graphs into a low dimensional space, and if we can do this then we can characterize structural variations in terms of, uh, statistical variation in the point pattern, which results from the embedding, and so these methods are really fairly straightforward.",
                    "label": 1
                },
                {
                    "sent": "But if we would try to do something more ambitious, that is to try to learn a generative model of graphs, then we have sort of two more complicated steps that we have to perform.",
                    "label": 1
                },
                {
                    "sent": "The first is we need to learn the modes of structural variation in a set of graphs, and this means we need to understand how edge connectivity structure varies for grass belong to the same class.",
                    "label": 1
                },
                {
                    "sent": "And generally speaking, this problem requires correspondences between the raw structure and is a computationally demanding problem.",
                    "label": 0
                },
                {
                    "sent": "However, one way around this might be to try to characterize the properties of graphs using permutation invariant characteristics.",
                    "label": 0
                },
                {
                    "sent": "And so, for instance, properties such as path length, commute time, or cycle frequencies might prove to be useful.",
                    "label": 0
                },
                {
                    "sent": "And then once we have such a characterization of variation in hand, what we want to do is to put a probability distribution on top of it, and then to construct a generative model which would be capable of describing the distribution of variations with parameters of edge and node structure variation.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we will try to try to simplify the learning problem, this would be a sort of a strategy you might adopt, and it's something that we've done in the past which is proved to be a reasonably successful.",
                    "label": 0
                },
                {
                    "sent": "What we want to do is to find an efficient means of characterizing graph structure which is not involved with exhaustive, exhaustive search or correspondence, and So what we want to do is to be able to enumerate graph structure without explicit search.",
                    "label": 1
                },
                {
                    "sent": "For instance, to determining cycle counts, path link frequencies, and so on and so forth, and so can we compute these things without actually solving the graph matching problem and the answer to this is yes, if you try to analyze a graph using a random walk or diffusion process using the heat equation, then many of these quantities here come about naturally without actually having to perform.",
                    "label": 0
                },
                {
                    "sent": "Exhaustive search, so the question I want to to ask him this.",
                    "label": 0
                },
                {
                    "sent": "This talk is as follows.",
                    "label": 0
                },
                {
                    "sent": "Since the heat equation and the diffusion on the graph that proved to be a very relatively powerful technique for trying to analyze graph structure without actually performing search and without actually computing correspondences, are there alternatives that we could use which give Richard description?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Characterizations?",
                    "label": 0
                },
                {
                    "sent": "So why is it?",
                    "label": 0
                },
                {
                    "sent": "Is this interesting?",
                    "label": 0
                },
                {
                    "sent": "Why such a topical problem?",
                    "label": 0
                },
                {
                    "sent": "Well, it's that the reasons are summarized on this slide here.",
                    "label": 0
                },
                {
                    "sent": "Recently, the notion of performing calculus on graphs have become a popular one in the mathematics literature, particularly through the work of Friedman, and this is meant that a richer family of physical operators can be extended from the continuous domain to the graph domain.",
                    "label": 1
                },
                {
                    "sent": "And the particular relevance to the talk here is that it's possible to now to be able to define a wave equation on a graph using these.",
                    "label": 0
                },
                {
                    "sent": "These notions of calculus on graphs, and this is done through introducing the concept of an edge based Laplacian.",
                    "label": 0
                },
                {
                    "sent": "I'll explain a little bit later on what the vertex based Laplacian is and with this edge based Laplacian at hand, what we can do is we can try to analyze a graph in terms of its vibrational modes.",
                    "label": 0
                },
                {
                    "sent": "And try to use these vibrational modes as a characterization.",
                    "label": 0
                },
                {
                    "sent": "And really the question is, I'm trying to explore in this talk is it can this kind of analysis based on physical operators on graphs?",
                    "label": 1
                },
                {
                    "sent": "In particular, the wave equation leads to interesting characterizations and new types of embeddings.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me talk a little bit now about the technical background to the talk before I go into some of the details of what we've done.",
                    "label": 0
                },
                {
                    "sent": "So what I want to do?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is to introduce you to the concept that Friedman developed in his work on calculus on graphs, particularly the idea of an edge based wave equation.",
                    "label": 0
                },
                {
                    "sent": "So we have done.",
                    "label": 0
                },
                {
                    "sent": "Here is, I've really given you an idea of what the process does.",
                    "label": 0
                },
                {
                    "sent": "According to Friedman, we could think of the edges of a graph is taut strings that are joined at the vertices or nodes of a graph, and if we if we want to characterize.",
                    "label": 1
                },
                {
                    "sent": "Characterize this behavior.",
                    "label": 0
                },
                {
                    "sent": "Then what we need to do is to define a Laplacian operator that operates on the edges of the graph rather than on the the nodes of the graph, and what Friedman has shown is that if we, if we have the familiar the policy and based on the nodes of the graph and I'll define in some detail what this has, this is computed in a few moments.",
                    "label": 0
                },
                {
                    "sent": "Then this is related to the policy and which is computed on the edge edges of the graph.",
                    "label": 0
                },
                {
                    "sent": "Via the following formula and so with this edge based the plastic in hand.",
                    "label": 0
                },
                {
                    "sent": "What we can now do is to try to analyze the vibrational modes that exist using this model of the graph where the edges are taught strings and we have fixed nodes and try to examine this.",
                    "label": 0
                },
                {
                    "sent": "The solutions of this wave equation to see whether they give us an interesting characterization which we can use to study the properties of sets of graphs.",
                    "label": 0
                },
                {
                    "sent": "So this is the wave equation just to to remind you what is the 2nd order differential equation and the second the second time derivative of the wave.",
                    "label": 1
                },
                {
                    "sent": "Wave equation is just equal the edge by fashion times the the wave operator.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the outline following trying to do in this talk.",
                    "label": 0
                },
                {
                    "sent": "What I want to do is to describe a new approach for embedding graphs in a in a vector space based on the wave kernel, what we're going to do is to try to have a look at the wave equation and what I'll do is to show you how the solution of the wave equation or the wave kernel has an eigensystem which is determined by the eigenvalues and eigenfunctions of normalized adjacency matrix.",
                    "label": 1
                },
                {
                    "sent": "So we don't actually have to compute explicitly.",
                    "label": 0
                },
                {
                    "sent": "The edge based class Chen.",
                    "label": 0
                },
                {
                    "sent": "It's implicitly determined by the Laplacian the vertex the passing of the graph, and then what I'll do is describer and embedding of the wave kernel of a graph into a vector space based on the gram matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "And then I'll just provide some very preliminary results at the end on how we've used this embedding in order to generate point characterizations of graphs and how this has led to different clusters clusters.",
                    "label": 0
                },
                {
                    "sent": "Of graphs representing different type.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of objects.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is the approach we're going to do is to treat the normalized dissimilarity matrix for a set of data as a way of kernel compute the spectrum of the edge based applausi, and using the analysis given by Friedman.",
                    "label": 1
                },
                {
                    "sent": "And then we're going to embed the.",
                    "label": 0
                },
                {
                    "sent": "The graphs into a vector space using an embedding which deals with.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Potential complex eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "So let's just talk a little bit about the theory which underpins this, particularly the relationship between the vertex, the plastic in the heat equation, which is really now.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Familiar stuff?",
                    "label": 0
                },
                {
                    "sent": "Then I'll show you how this extends to the wave kernel and the wave equation on a graph.",
                    "label": 0
                },
                {
                    "sent": "So here is the sum of the formulas.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we're going to be dealing with is a weighted adjacency matrix where the elements of the adjacent sides weighted adjacency matrix of weights.",
                    "label": 0
                },
                {
                    "sent": "Provided that though the corresponding pair of nodes are connected by edges from the other weighted adjacency matrix, we compute degree matrix and then the vertex Laplacian is just the degree matrix minus adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "The what it's normal to do is to work in terms of the eigen decomposition over Laplacian matrix.",
                    "label": 0
                },
                {
                    "sent": "So what I've done is I've written this down here in terms of an eigenvector matrix Phi which has the ordered eigen vectors as columns and an eigenvalue matrix Lambda which has the ordered eigenvalues as diagonal elements and so this is the eigen decomposition of the Laplacian matrix in terms of the eigenvalue and eigenvector matrices.",
                    "label": 0
                },
                {
                    "sent": "And then we note some of the properties of the eigenvalues of the plus here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That is to say that they are always greater than or equal to 0 multiplicity of zero eigenvalue gives a number of key components in the graph, and the eigenvector associated with the second smallest eigen value is the Fiedler vector that's been extensively used in clustering problems in Patton analysis machine and intelligence.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how does the heat kernel come about?",
                    "label": 0
                },
                {
                    "sent": "Well, it's a solution of this simple 1st order differential equation.",
                    "label": 1
                },
                {
                    "sent": "The heat kernel satisfies the following relationship is derivative is just minus its time, derivative is just minus to plus Ian times the heat kernel itself.",
                    "label": 0
                },
                {
                    "sent": "You'll recognize this as being a differential equation that has an exponential solution, and it turns out that if we have the spectrum of the placinta hand.",
                    "label": 1
                },
                {
                    "sent": "Then the heat kernel can be found by pre and post multiplying the time exponential of the eigen.",
                    "label": 0
                },
                {
                    "sent": "Eigenvalue diagonal eigenvalue matrix by the eigenvector matrix and its transpose.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it turns out that the kernel is particularly important in analyzing the properties of continuous time random walks, so continuous time random walk has a state vector P of T. That's the probability of of.",
                    "label": 0
                },
                {
                    "sent": "A vector that contains the probability of visiting each of the nodes.",
                    "label": 0
                },
                {
                    "sent": "The graph at time T. It solves the following first order differential equation and it turns out that the state vector at time T is just given by the heat kernel at time T times initial state vector.",
                    "label": 0
                },
                {
                    "sent": "Analysis of this kind of continuous time random walk leads to a number of characterizations of graph structure, particular the heat kernel turns out to encode information.",
                    "label": 1
                },
                {
                    "sent": "About things such.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the path length distribution on the graph number of spanning trees in a graph and also it's commute the distribution of commute times?",
                    "label": 0
                },
                {
                    "sent": "So we've explored these ideas fairly thoroughly in a series of papers aimed at graph characterization, but now what I want to do is to see whether alternative operators, differential operators on graphs, alternatives to the heat equation yield other interesting characterizations.",
                    "label": 0
                },
                {
                    "sent": "So what I want.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To do is just to spend a little bit of time talking about what the wave equation is and how it's linked to the edge based applausi and and how the study of the vertex Laplacian gives US solutions to the wave equation.",
                    "label": 0
                },
                {
                    "sent": "So what I've done here is I've written down the heat equation on the wave equation next to each other so you can compare and contrast the different differential operators involved.",
                    "label": 1
                },
                {
                    "sent": "The heat kernel is a solution of the equation H = -- L A v * H where LV is the vertex Laplacian which I've defined few slides ago.",
                    "label": 0
                },
                {
                    "sent": "The wave equation, on the other hand, is a second order differential equation and.",
                    "label": 1
                },
                {
                    "sent": "The Wave kernel is W is a solution of www.double.orthesecond derivative of the wave kernel equals minus the edge Laplacian now times the wave kernel.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can you can solve this second order differential equation fairly easily.",
                    "label": 0
                },
                {
                    "sent": "What I've done is I've I've given the solution here, so here I've just switched the notation from notation www.two WT to mean the second derivative, so this is the wave equation.",
                    "label": 0
                },
                {
                    "sent": "Now impose some boundary conditions on it, and so the solution T = 0 is F and the velocity.",
                    "label": 0
                },
                {
                    "sent": "Or the first derivative of the wave kernel at time T = 0 is given by G. So with the initial conditions and the velocity, the solution of the wave equation is given by this sinusoidal form and it's determined by the square root of the edge based Laplacian and the time at which we evaluate the kernel.",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of course you can simplify this to give different forms, and so here's a simplification.",
                    "label": 0
                },
                {
                    "sent": "When we take, we set the function F to be 0 everywhere and we take the unit velocity everywhere.",
                    "label": 0
                },
                {
                    "sent": "And if you do that then the solution of the wave equation is given here and you can analyze this operator for small values of time and this gives an expansion of the wave wave, kernel Mclaurin expansion for small time values in terms of the edge based Laplacian.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, what we'd like to be able to do is in order to find the wave kernel, we need to construct the edge based applausi and and it turns out to be natural in this case.",
                    "label": 0
                },
                {
                    "sent": "To work with the normalized adjacency matrix.",
                    "label": 1
                },
                {
                    "sent": "So what I've done here is written down the definition of normalized weighted adjacency matrix and that's just the inverse of the square root of the degree matrix times the original adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "Post multiplied by one over the square root of the degree matrix.",
                    "label": 1
                },
                {
                    "sent": "So what I want to do is to show you that the construction of the edge based occlusion is effectively an implicit problem, since it's determined by the computer spectrum of the vertex deploy.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See EN.",
                    "label": 0
                },
                {
                    "sent": "So here's some analysis.",
                    "label": 0
                },
                {
                    "sent": "This is taken directly from Friedman's paper.",
                    "label": 0
                },
                {
                    "sent": "The relationship between the vertex capacity and and the Angel passion is given by the following is just the vertex.",
                    "label": 0
                },
                {
                    "sent": "Laplacian is just one minus the cosine of the square root of the edge Laplacian.",
                    "label": 0
                },
                {
                    "sent": "So we can now reorganize this.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the cosine of the square root of the edge Laplacian is just going to be 1 minus the normalized vertex Laplacian or the normalized adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "So now we can.",
                    "label": 0
                },
                {
                    "sent": "Now we know this relationship between the normalized adjacency matrix and the edge based Laplacian.",
                    "label": 0
                },
                {
                    "sent": "We can determine the spectrum of the edge based applausi and and so if the if the cosine of the square root of Lambda belongs to the spectrum of the adjacency matrix, that means that Lambda belongs to the spectrum of the edge based Laplacian.",
                    "label": 0
                },
                {
                    "sent": "So this gives the spectrum of the edge based the policy and we want to compute its eigen functions.",
                    "label": 0
                },
                {
                    "sent": "Then we need to use the following.",
                    "label": 0
                },
                {
                    "sent": "Are relationships so if F is an eigenfunction of the normalized adjacency matrix, cosine and square root of Lambda, thrive Mr. Square root out there is an eigenvalue of normalized adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "Then this means that F is an eigenfunction of the edge based blasian and Lambda is an eigenvalue of the edge base Laplacian and the other the other condition applies.",
                    "label": 0
                },
                {
                    "sent": "Is this one here?",
                    "label": 0
                },
                {
                    "sent": "Which is that the we take the eigen functions F. Then when we operate on those with the vertex Laplacian then we get 0.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what does this mean?",
                    "label": 0
                },
                {
                    "sent": "Well, here's what the spectrum of the edge based of classy and that comes out of that analysis.",
                    "label": 1
                },
                {
                    "sent": "And so you see, the number of harmonics corresponding to the harmonic frequencies of vibration of the edges on the graph.",
                    "label": 0
                },
                {
                    "sent": "And if we want to make a physical interpretation.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the process, then what we've just done is described the vibrational modes associated with taut strings on each edge.",
                    "label": 1
                },
                {
                    "sent": "These are joined together at the vertex.",
                    "label": 0
                },
                {
                    "sent": "If we excite or pluck the system, then it produced tones with frequencies whose spectrum ranges over the edge based eigen values and their harmonics.",
                    "label": 1
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if we try to sort of think about it and sort of more computational sense, well the if we if we project the nodes of the graph onto the eigenspace occurrence corresponds to harmonic frequencies of the corresponds to the eigen functions.",
                    "label": 1
                },
                {
                    "sent": "And what we're doing is we're projecting onto a space spanned by the harmonic frequencies of the graph because of the second condition that I showed you here on the eigenfunctions.",
                    "label": 1
                },
                {
                    "sent": "What this means is that the nodes are stationary under and vibration.",
                    "label": 0
                },
                {
                    "sent": "So you can think of them as being the nodes on a constraint as a string and negative eigen space resulting from analysis constant response to non physical vibration modes.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I think I mean I don't want to to go into any more depth because I think I'm running short of time, but what we've done is we've taken this this analysis and we've done.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An embedding based on it.",
                    "label": 0
                },
                {
                    "sent": "The details are on the paper, so I'll just skip through that section of the analysis and come on to some experiments that we've done to show you the kind of embeddings that we get on the basis of the wave kernel analysis.",
                    "label": 0
                },
                {
                    "sent": "So what we've done is we've used two datasets.",
                    "label": 0
                },
                {
                    "sent": "These have been well explored in our own work and other people's work.",
                    "label": 0
                },
                {
                    "sent": "The first is the data set of three sequences of images of model houses.",
                    "label": 1
                },
                {
                    "sent": "Here we have Delaunay graphs for each of the points sets in each of the images, and there are three different classes of object corresponding to the different views of the three different houses.",
                    "label": 1
                },
                {
                    "sent": "But then we've also used the coil database.",
                    "label": 0
                },
                {
                    "sent": "We've taken 45 objects from that, and what we've done is we for each object there are 72 views, and we've extracted the Delaunay graphs.",
                    "label": 0
                },
                {
                    "sent": "Of SIFT features extracted from from these images.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this just runs through the the computational steps that we've adopted.",
                    "label": 0
                },
                {
                    "sent": "What we do is we compute the eigensystem of normalized adjacency matrix.",
                    "label": 1
                },
                {
                    "sent": "This allows us to construct the edge based the classy and we then computed the edge kernel with different time values and use these to construct embedding matrices.",
                    "label": 0
                },
                {
                    "sent": "And then we've developed a procedure here to catch the negative eigen space associated with negative eigenvalues.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are the embeddings that we get from the analysis.",
                    "label": 0
                },
                {
                    "sent": "The wave kernel analysis of the graphs.",
                    "label": 1
                },
                {
                    "sent": "So what in these images what we've done is we've taken the House data point in each in these plots represents a an image and what we've done is we have for each image we've computed the wave kernel embedding and then once we have the embedding points, what we've done is we've computed the distance.",
                    "label": 0
                },
                {
                    "sent": "Between pairs of images using a Hausdorff distance, and so with that distance we can perform multidimensional scaling to embed the individual graphs.",
                    "label": 0
                },
                {
                    "sent": "That sort of family of graphs into it into an eigenspace for different values of the two parameter of the wave kernel.",
                    "label": 0
                },
                {
                    "sent": "What you see is that this gives reasonable separation of the House data.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we look at what we got with the heat kernel, these are similar results and there's some suggestion that the data here is a little bit more overlapped.",
                    "label": 0
                },
                {
                    "sent": "And then what we've done is we have repeated this analysis for the coil data and again we get reasonable separation, reasonable visual separation of the different object classes, and then what I've",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is, I've given the Rand index, so this is here.",
                    "label": 0
                },
                {
                    "sent": "The smaller the index, the better of the classification we had because we have a number of incorrect's divided by number of incorrect plus correct classifications.",
                    "label": 0
                },
                {
                    "sent": "Notice that we can get.",
                    "label": 0
                },
                {
                    "sent": "Of clusterings with pretty low values of the Rand index for the House data not so impressive for the for the coil data.",
                    "label": 0
                },
                {
                    "sent": "OK, so just to conclude.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we've done is develop a new approach for embedding.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ralphs based on the Wave kernel.",
                    "label": 1
                },
                {
                    "sent": "I haven't really talked about how we deal with net the negative eigen space in this analysis due to shortage of time.",
                    "label": 0
                },
                {
                    "sent": "But based on the experiments that we get reasonable results from this from this approach and although this is now fairly preliminary, work suggests that there might be characterizations that you can extract from the wave kernel that can lead to interesting graph clustering results.",
                    "label": 0
                },
                {
                    "sent": "So thank you very much indeed.",
                    "label": 0
                }
            ]
        }
    }
}