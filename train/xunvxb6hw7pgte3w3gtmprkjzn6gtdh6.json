{
    "id": "xunvxb6hw7pgte3w3gtmprkjzn6gtdh6",
    "title": "Graph kernels and applications in chemoinformatics",
    "info": {
        "author": [
            "Jean-Philippe Vert, MINES ParisTech"
        ],
        "published": "July 12, 2007",
        "recorded": "June 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods",
            "Top->Computer Science->Machine Learning->Structured Data",
            "Top->Computer Science->Chemoinformatics"
        ]
    },
    "url": "http://videolectures.net/gbr07_vert_ckac/",
    "segmentation": [
        [
            "Thank you.",
            "OK, good morning of course.",
            "First of all, I'd like to thank a lot the Committee for giving me this opportunity and the organization.",
            "It was very perfect and also to thank you for being here.",
            "I mean, I will be surprised the last day of the workshop after the dinner and sunny weather you still here.",
            "So it's quite impressive.",
            "Socially before coming here, I was not really sure about what you know.",
            "What familiarity you you have with Canon methods, but hearing many talks, I think that at least for some of you are quite familiar.",
            "If not expressing currently kernels and kernel felt.",
            "So I apologize because my goal here is to present a bit.",
            "Of course, the state of the art, but a bit review what has been done in the.",
            "Field of kernels.",
            "Positive definite kernels for graphs.",
            "Presents some applications in chem informatics where I've been working on.",
            "And so try to convey you the the main ideas of how the candles appeared, how they are developed, how to make them work, and highlight a few open issues that need to be solved in the future if you want them to work even better."
        ],
        [
            "So I have quite a lot of styles, probably will.",
            "I might skip some of them given the time constraint and the late hour, but I would like at least two after a brief introduction to Colonel scanner methods, which is a kernel to review.",
            "Some work that has been done about one of the main issue in Calendar tells, which is a very common issue in graph algorithms.",
            "In fact, is to find a tradeoff between what you want to express, what we incurred in algorithm, and the complexity of the algorithm itself.",
            "So we see that in practice when we want to design graphic.",
            "Also want to be able to compute them efficiently and want them to represent things an obviously you cannot do all.",
            "OK, so I'll review the results we have about that and as a result, how graph can also introduce to to have efficient algorithms.",
            "This is the so they were most graph kernels that work nowadays are called walk kernels.",
            "I will develop what is explain how it works.",
            "I present a few extensions to make them work in practical applications because we see that the basic definitions often does not do not give very good results.",
            "And finally present some experimental results to highlight the what's good and bad about graph kernels."
        ],
        [
            "So let's start with."
        ],
        [
            "With some motivation.",
            "So in our lab work on computational biology and computational chemistry, and one of the big issues, it's not a new one in computational chemistry or chem informatics is to develop models predictive models to predict when you have a molecule.",
            "So we work with small molecules, so this is typically a small molecule.",
            "See these are three representations of smaller equals.",
            "We want to predict properties of these molecules, and there are many properties we would like to be able to predict typical properties.",
            "So the whole idea in many applications is to develop new drugs.",
            "And most of the drugs are small molecules, so before developing a new drugs who let you know, in an ideal world to be able to design in silico molecule by first predicting if the molecule be toxic.",
            "Arnold because you don't want to drive to be toxic, whether the molecule will be absorbed or not in the correct rate in your in your Organism this is called pharmacokinetics.",
            "Whether it will be active so typically an active drug is a small molecule that can bind to a target target protein.",
            "So you want to be able to predict that and many more properties.",
            "So there is a model that there is a general.",
            "Modeling, which is to say that we want to build models that take US input a molecule and you need to choose a bit how you describe the molecule and that from this molecule will predict the property.",
            "And it turns out that.",
            "We have more and more experimental data about toxic molecules or active molecules or molecules that are well with good pharmacokinetic properties, so more and more we want to develop statistical models that, given a set of molecules with known properties, can find a function to relate the structure of the molecule to this to its activity or toxicity.",
            "What we talk about is is is to build models for molecules where you represent America by your graph.",
            "So I must say that this is not the only way to do, and once again molecule is not a graph graph is just an abstraction of a molecule, but the graphs are quite reasonable representations.",
            "Becausw molecule is made of atoms with covalent bonds, and it's quite natural to represent America by a graph where the vertices are terms and the edges are present covalent bonds.",
            "But once again I would say that the state of the art in.",
            "In this field can use more and more features of molecules OK. For instance, you can use the three dimensional structure of Dominica, which brings a lot of information.",
            "You can use the electrostatic potentials etc.",
            "So here I will just talk about some basic representation which is quite useful, but to develop a real state of the arts program you probably need to take into account other features of medicals.",
            "OK so."
        ],
        [
            "Either the first motivation and here is a natural example.",
            "If you want to develop new drugs for AIDS, you can download other web database of molecules called the encia screen results where you have like 50,000 molecules that I mean tested experimentally to test whether they are active to bind versus target, which is one of the proteins of the HIV virus and therefore you can download the set of graphs and some are so the simplest quantification of them.",
            "Some are active, so these are the blue ones, summer electives and the gold is given this database of active and inactive Nichols.",
            "Build a model that will take when you take.",
            "When you go to a pharmaceutical company, they have huge databases there on molecules, typically millions 10s of millions of molecules and you would like to do screening, which means that among the molecules in the databases of the company to find the ones that are likely to be active so that you can test them and perhaps develop metrics.",
            "So this is a natural example that we would like to solve."
        ],
        [
            "Of course I could mention other applications of graph kennels and we have seen many of them this week.",
            "One of this one is to use graphic and also for image processing.",
            "So typically there are examples of tasks in processing which are classification or clustering or low dimensional representation of molecules and sort of images and we have we have heard talks about that one way to represent an image could be to 1st segment 8 picture using segmentation algorithms and then represent the picture.",
            "As a graph where the uniform regions would be vertices and where you put some edge between adjacent regions and where practical way the edges depending on the similarity between the regions if you wish.",
            "But so when you do that to represent an image paragraph, and then you might want to develop algorithms to do pattern recognition or regression or classifications of of features based on the graph graphic representation."
        ],
        [
            "So in our case is at least in both cases are presented are other examples that of course you know we can formulate the problem as follows.",
            "We have a set of graphs I will call the graphs X, XI, so we have a set of X1 X 2X N graphs.",
            "We have a set of corresponding variables to predict.",
            "I will call them Y1Y2Y N. This could be discrete or continuous depending on what you want to do.",
            "Then you called that either a regression or supervised classification pattern recognition and the goal is, given a database of.",
            "Labeled examples to learn a function F that will predict the Y variable from X&X is a graph I will talk about labeled graph, so I will assume that we have graphs that are that can be directed or undirected.",
            "I will not make a big difference.",
            "I mean they can be handled the same way in this framework and we assume that you have labels on the vertices and edges.",
            "This is quite general presentation of graphs.",
            "OK, so the question is can we adapt classical classical tools of statistical learning to work with graphs?"
        ],
        [
            "Uh, actually it's not difficult to imagine how to apply classical tools to this.",
            "This framework and the last talk was an example.",
            "One idea is to say that we start from a graph which is not obvious to handle in order to when you want to do least square regression, you don't know how to do the square regression and graphs, but wanted to say I will first represent my graph by your vector, and to do that I need to find a mapping from a graph to a vector or fixed dimension by extracting features.",
            "So we heard the talk reference.",
            "You can use some.",
            "Some other we talk about edit distance.",
            "Can you compare you graph to a Dictionary of graphs and then you can represent a graph by a vector.",
            "In chemistry in chemoinformatics."
        ],
        [
            "There are classical representations of molecules as vectors, typically by extracting relevant substructures.",
            "So when you start from molecule that has, let's take this molecule here.",
            "That is made.",
            "I mean, it's really cool, but you can extract from this Microsoft parts which you know can be kind of called meanings like you have a benzene and stuff here.",
            "This can be a few choices etc.",
            "So in this case you need before hand to define a Dictionary of features and then when you have a new molecule, you for instance you can just count how many times it's each sub structure appears.",
            "So you can count it.",
            "Or you can have a binary representation saying it occurs or not and then this allows you to represent your graph.",
            "As a Victor and once you have it, or you can apply for instance you own networks partially square, which is quite popular in coming from Dicks decision trees, support vector machines.",
            "This collaboration whatever you want.",
            "OK, so this is the first way to do some explicit representation of graphs as vectors."
        ],
        [
            "The difficulties with this approach, which which is encountered in practice in chemical Mattis.",
            "The following well first is not obvious how to choose the features OK?",
            "So there is some prior knowledge.",
            "It has to be put in the features.",
            "For instance, if you want to use this feature representation for patterning conditional regression, you would like the features somehow to be relevant for the prediction task.",
            "OK, if you want to predict toxicity and you go to a features which are related to toxicity, which is not always obvious to design.",
            "One approach would be to say, well, let's take as many features as we can.",
            "We take all possible subgraphs.",
            "Then we have a big big vector presentation, but then you have other issues because first, if you do that explicitly, you need to store to store vectors representation, which can be large.",
            "And when you have databases of millions of molecules, if each molecule by vector of millions of dimensions, it becomes a problem.",
            "Then you have from your speed of course, and you have of course statistical issues because if you have too many dimensions, most algorithms, more static algorithms are not designed to work in very, very large dimensions.",
            "OK, some R and I will talk about them, but they basically square regression will not work if you have more dimensions than example.",
            "OK, so you have a trade off to find between which feature to choose and is related to the previous talk about how to find relevant features like revenue graphs represent a graph by the vector of edit distances.",
            "But this is an open issue."
        ],
        [
            "So the approach I will present is to use a trick which is not a new trick.",
            "It's called the kernel trick.",
            "It has been used a lot in kernel methods, public machines, which is to say that there is a class and a class of many algorithms that don't need to have the explicit representation of patterns of objects of graphs as vectors cause.",
            "Because you can use something else which is the inner product between vectors, so these are following.",
            "This is a definition.",
            "Suppose you have graphs which I call X that you represent as feature vectors.",
            "Fire fix.",
            "This can be of any dimension.",
            "Then what we call the kernel in this talk is simply the inner product between the images of two graphs.",
            "After mapping by fire.",
            "The idea is that once you have the kernel you can apply."
        ],
        [
            "The algorithms that instead that do not explicitly where the fireplace, but instead require the kernel.",
            "OK, so the good thing I mean I will develop, it'll be later, but the the main motivation behind this is that first, if you have a way to compute the kernel faster than the fire season five is prime.",
            "You have some speedup of course of the algorithm.",
            "Then you might have some some advantage in terms of memory storage cause instead of representing a graph by your large vector, you can just compute the inner product between your graph, another graphs which can be faster.",
            "And then we will see that some algorithms can deal with high dimension which allow you to not hesitate to have like initial vectors.",
            "So let me just."
        ],
        [
            "Be concrete for those of you who have never seen kennels.",
            "If some I don't know, this is an example of a kernel method, which is how to compute the distance between two objects.",
            "So suppose you start from a set of objects which could be graphs.",
            "And suppose you have a mapping from your set of graphs to a feature presentation.",
            "So here is just two dimensions that images can be 10,000 dimensions or infinite dimensional.",
            "How can you define a distance between two graphs based on file?",
            "Well, one idea would be to say when you take 2 graphs.",
            "It's one X2.",
            "They are mapped to two objects, fire.",
            "This one 5 issue.",
            "So these are two vectors which can be large and you could say well if I can define a distance metric between the two, the two the two graphs as the Euclidean distance between the images.",
            "So one way to do with say I compute fireworks one I compute fireworks 2.",
            "I made the difference and I take the Euclidean norm of the difference.",
            "This is the distance.",
            "Now if you expand it with two lines of simple computations, we can see that the computation of the distance between X1 and X2.",
            "As the Euclidean distance in this space can be expanded as a sum of inner products, it's equal to the inner product between 5X1X1 plus 5X2 X 2 -- 2 * 5 = 2.",
            "So now remember that we defined inner product as a kernel, so this."
        ],
        [
            "We computed from the cannot only OK, so if you have a kernel K, when you compute CRV Sonics 1 + K of Easter is 2 -- 2 carriers phonics two?",
            "This gives you a number which is exactly the distance the square Euclidean distance after mapping to the future space.",
            "So this is a trivial example, but still which explains the the kernel trick which is that to compute the distance in this space, you don't need to compute the two vectors, you just need to be able to compute their inner product.",
            "Supply this and it works.",
            "Now it turns out that this cannot trick and can be used for many other things than computing distances.",
            "This can be useful.",
            "You know if you want to use.",
            "Distance is what you can do.",
            "This would be called Colonel Cannulas.",
            "Neighbors, which is that you can apply Ken Research both without having vector representations.",
            "OK, you can use the hidden distance defined this way, but more Interestingly you have many other algorithms and I'm sure you've heard about them at least like support vector machines or kernel perceptron or kernel.",
            "This square or kernel PCA.",
            "There are many algorithms that can work in this space.",
            "OK so for instance cannot PCI those some principle component analysis this space?",
            "Without completing the vectors, because we can express principle component of this in terms of inner product's similarities, support vector machine is the one we will use is some algorithm for supervised classification where you have two sets of graphs like active and inactive graphs.",
            "If you map them to a space and if you are able to compute the inner product there then you can learn a function that will discriminate between positive and negative ones."
        ],
        [
            "Using the kernel trick.",
            "So a few more words which are once again very classical about Colonel.",
            "So here I said once you have a mapping file, you can define a kernel as inner product between fire base in five is prime.",
            "Now it fights.",
            "There are also cases where you want directly to define the kernel you want to say.",
            "Well, so intuitively know Colonel is like a measure of similarity between the two graphs.",
            "You could say, give me a similarity measure.",
            "Is it a kennel or not?",
            "For instance, give me the edit distance.",
            "Which graphs is it related to?",
            "A kernel?",
            "Is it a Hilbert distance between points?",
            "In this case the answer is no.",
            "But how can you make sure that given security measure is again or not?",
            "Well there is a general property which is the following.",
            "So this is a definition cannot is called positive definite.",
            "So cannot cannot now is just a function that takes 2 objects.",
            "Is pragmatism number.",
            "We say that is positive definite if it's symmetric and if it satisfies this tricky condition, which simply means that when you take a set of North graphs, you compute the matrix of pairwise kernel values.",
            "It has to be this metric has to be positive semidefinite if it's always the case, then you said that the kernel."
        ],
        [
            "We've submitted in it and you have a famous theorem that that stays the equivalence between positive positive definite kernels.",
            "On the one hand and inner product on the other hand.",
            "So this theorem says that.",
            "Account all K is positive definite given the previous definition if and only if there exists some space inner product space and a mapping from your original space to this space such that the kernel K is equal to the inner product after mappings of the points.",
            "OK, so this means that you might want to directly design kernel between graphs and use them with support vector machines if you are able to show that your kernel functions are positive definite."
        ],
        [
            "So now what is a graph can?",
            "Oh well, Grafton is simply the applications of these tree.",
            "Can this ID to the set of graphs?",
            "OK, so the graph cannot simply function K that take two graphs as input outputs and numbers.",
            "I will just talk about real valued kernel, but you could extend it too complex very kernel, but at least for real valued journalism, function of comparison between two graphs.",
            "Search that this function should be equal to some inner product in some space and the space could be abstract.",
            "I mean this is an inner product space Hilbert space.",
            "But this could be infinite dimensional, so you want to define a positive definite functions over the set of graphs.",
            "And when you do, that implicitly means that you are able to embed the set of graphs to help your space.",
            "And when I'll call by embedding, here is is a mapping to Hilbert space, or is that the distance in this Hilbert space is equal to the distance that used by the camel?",
            "It's an exact embedding is not approximate embedding, so it's equivalent to say, am I able to embed the set of graphs in the hyperspace or unable to define a positive definite kernel?"
        ],
        [
            "About the set of graphs.",
            "So this is what we want to do."
        ],
        [
            "A short summary of discern this short introduction.",
            "The problem we have is we want to design general tools to solve problems of regression or pattern recognition, supervised classification of other set of graphs.",
            "What one approach is to represent graphs as vectors, but it's not always easy to do for different reasons, and they can approach would be to say, well, we will directly define a graph kernel to compare two graphs.",
            "The advantages that we can expect the following.",
            "First, we might be able to consider a large number of potential features who are not limited by the number of features we want to use.",
            "Saigon we don't need to store explicitly the vector representations.",
            "If we define the RPD inner product discount correspond to very large dimensional vectors.",
            "But we don't compute them, and 3rd, this is something I didn't say in detail, but we will be able to afford working in high dimensions because we will use algorithms that are dedicated to working large dimensions, 'cause they use regularization techniques.",
            "So support vector machines is an example of algorithm that can work in larger missions because you control something else which is not the dimension which is.",
            "Some other."
        ],
        [
            "Complete measures OK, so so at this point now I will talk more precisely of how to design care, not for graphs.",
            "So historically the first graph kernels were presented in 2003 by two groups in the same times, and I will explain some of the reason."
        ],
        [
            "That have been found and how to design them.",
            "So first of all there is this question of can we.",
            "I mean we want to embed the set of graphs in Hebrew space.",
            "So first of all, can we make an embedding such that we can describe in detail all the variations among graphs and if you walk in graph theory you know that isomorphism is 1 basic thing that you would like to be concerned saying that you want to embed the graph such that two different graphs in the sense that two non isomorphic graphs should be mapped to different points.",
            "If you don't do that then you know that.",
            "If you use a kernel which doesn't follow this property, then you will never be able to learn a function that differentiates non isomorphic graphs.",
            "OK, so this is what we call a complete kernel.",
            "Complete kernel would be a kernel that separates noise amorphic graphs.",
            "Very simple definitions."
        ],
        [
            "So obviously I mean it's not difficult to show and probably you you know it if you are able to.",
            "The next slide that.",
            "There is obviously a tradeoff between having some expressive Cannon said that might be complete kernel and being able to compute."
        ],
        [
            "Because you know that solving the graph isomorphism problem is difficult.",
            "OK, it's between P and NP.",
            "I mean there is no known polynomial time algorithm to solve the to say whether two graphs are isomorphic or not.",
            "And here I said if I have a complete kernel then I am able to solve the problem 'cause if I have a kernel I can compute the distance in the feature space given the equation I gave a few slides the goal and if you compute this distance, if you see that the distance is 0, this would mean that the canola, as an official not OK.",
            "So obviously the computing any complete graph kernel is at least as hard as solving the."
        ],
        [
            "Rough isomorphism problem, which means it's difficult.",
            "The previous, once again trivially if you have.",
            "If you know how to compute the kernel, you have a test to check whether two graphs are symmetric or not, so you know it's hard to do.",
            "Therefore you know that computing the kernel, computing a graph, complete graph kernel cannot be done in polynomial time for them."
        ],
        [
            "So one idea would be to say perhaps so, so now we talk about some ideas on how to design graph kernels, and we said that historically, before graph, cannot the string kernels like one year before the 1st graph kernels, they were substring kernels, and the instance there is something called.",
            "The spectrum can only industries.",
            "The idea was quite quite simple and quite efficient.",
            "Practices were to say when you have a string, you can represent it as a vector by extracting all comers.",
            "Overlapping cameras so you expect the blocks of length K you count the number of occurrences of each block and then this is a vector representation of a string and then you can compute the inner product efficiently.",
            "OK, you don't need to explicitly write it, so he's right here.",
            "Well, when people thought can we do the same on graphs and for instance, if I have a graph, this is a graph.",
            "The natural correspondence to the cameras would be to say, yeah, we expect the subgraphs and you could say, well, given these graphs, I can extract all the subgraphs and build a feature representation of my graph by counting how many times each possible subgraphs occurs in my graph.",
            "And then perhaps I will be able to move the inner product between these two things.",
            "So this is a graph, and this is the list of subgraphs here."
        ],
        [
            "And so you could say, well, can I make?",
            "So let's call that a subgraph candlewood say if I formally you can write it down.",
            "You can say given a graph represented as a vector of large dimensions, it would be infinite dimension in this case, but most coordinates would be 0.",
            "The dimensions correspond to possible subgraphs and the value is the number of times a subgraph occurs.",
            "So this is what we called family.",
            "5H of Jissoji would be a candidate graph.",
            "Edge will be a candidate sub graph and five H of G would be the number of times.",
            "You have a subgraph of G that is unfit to edge.",
            "OK, so you count how many times each subgraph occurs.",
            "This is a feature an you could make an inner product in the space of subgraphs, which would result in a kernel with the following expression.",
            "So the inner product will be the sum of other features, which means the sum of other possible subgraphs, which are graphs of some way to kind of for some nonnegative weights corresponding to sub graph times 5H of G 1 * 5 H of G2 when compared to 1MG two.",
            "This is simply the inner product in this space.",
            "When you present a graph by the number of subgraphs, number of occurrences of different subgraphs."
        ],
        [
            "Well.",
            "These are so you can we compute this channel where you can show that these are this kernel is NP hard, which means that it is at least as hard as NP complete problems.",
            "So this was proven by Thomas Gagnon colleagues in 2003."
        ],
        [
            "There is a nice demonstration.",
            "I will quickly quickly.",
            "Quickly show it because it is quite interesting to show how you can.",
            "You can combine properties of kernels with know how to prove competitive algorithm.",
            "So there is the following.",
            "Suppose you consider PN the path graph.",
            "So the linear graph with N vertices.",
            "When you map this graph to the feature space, you need to explore the subgraphs.",
            "OK, So what are the subgraphs of the linear graph with N vertices?",
            "Well, the subgraphs are just linear subgraphs, OK of length 123, and you can count how many times there occurs.",
            "So for instance.",
            "For Europeans, the image of the linear graphs in the feature space of subgraphs.",
            "If you call EP1 for instance, the coordinate corresponding to the linear sub graph of length one, you know that this one occurs N times it PN OK.",
            "So you can't end times.",
            "This is the first coordinate.",
            "Then you know that the sub graph of length two occurs and minus one times in your chain and etc.",
            "So this is the expectation of five PN in the feature space of subgraphs.",
            "Now once you have that, it turns out that.",
            "If you're interested in this in this dimension in the feature space, so the dimension corresponding to the sub graph PN.",
            "Just by inverting a triangular system you can compute EPN from 5.",
            "P. 152535 PNB cause in fact of the one you just have EP1 in five P2, you have EP1 and EP2 etc.",
            "In 5:00 PM you have if you want in P2P N so you can invert the system.",
            "An right that EPN itself is a linear combination of the file of peas.",
            "For I = 1 two N with Alpha that can be computed in polynomial time.",
            "Just solving a triangle system OK?",
            "So you can formally compute this vector as a linear combination of the five peas with Alpha computed in polynomial time, and if you have this vector then you are able to solve a classical problem in graph theory, which is called."
        ],
        [
            "Instant pot problem.",
            "So this problem is simply to say if you have a graph, can you find a path that goes through all vertices of your graph exactly once?",
            "OK, well, you can see that this problem is really saying is the path of length NA sub graph of my graph.",
            "This is the same thing.",
            "OK so if you are able to say if you have a graph with N vertices, if you have if you are able to say whether the path the path graph of Lexan is a graph or not, then you have solved Hamilton problem.",
            "And here how would you do that?",
            "Well the.",
            "The test is simply to say is the coordinate.",
            "So if I have a graph G with vertices, when I map it to the feature space of subgraphs, is the coordinate corresponding to EPS or sorry EPN 0 or not?",
            "If it's zero, it means that PN is not a sub graph.",
            "If it's one, it means that pieces will graph.",
            "So you need to say whether Fire OG scholar N is positive or not.",
            "And because we say that EPN is a sum of Alpha Phi Phi of peas, you just need to compute.",
            "For any given graph, 5G times the vector, so this is APN which is the sum of Alpha Phi of peas.",
            "And because by definition five G * 5 P is a kernel between G&P, this value is equal to the sum of Alpha times K sub graph of GPI.",
            "OK, So what we have said that here is that.",
            "If we are able to compute the kernel sub graph then we are able to solve the Hamiltonian.",
            "But the problem with the polynomial time operation, which is computing this Alpha is which is easy inverter system?",
            "And then you compute the sum.",
            "If it's zero, then there is no Hamilton path.",
            "If it's nonzero, then there is a Hamilton path.",
            "So this implies that computing this case of graph must be at least as hard as solving the Hamilton path problem, and this one is NP complete.",
            "OK, so this shows that the sub graph kernel cannot be computed."
        ],
        [
            "Efficiently.",
            "So some variance maybe to say, well perhaps some graphs out there are too many subgraphs.",
            "I could perhaps is a bit of the task by considering considering only path.",
            "So path is simply a linear sub graph.",
            "OK, and you could say given given a graph, I will extract all in our sub graphs.",
            "So this is an exhaustive list of linear subgraphs of this graph.",
            "And you could imagine that processes one is easier to compute.",
            "However, if you do exactly the same proof, the proof, I just see the replies here OK, because it only used linear path, so you can show that if you define the."
        ],
        [
            "Anyway, the past kernel as some inner product in the space of counts of paths in your graph, then you cannot compute this kernel efficiently, because this would also allow you to."
        ],
        [
            "Solve the Hamiltonian path problem, which means that computing the past cannot is also NP hard.",
            "OK, so this is a series of bad news.",
            "You know you try to say well, can I cannot make any."
        ],
        [
            "Complete kernel."
        ],
        [
            "That is, let's go to summary, so I cannot make any complete graph kernel.",
            "I cannot compute a subgraph channel that you could expect a bit simpler.",
            "You cannot even compute the path Colonel know extracting path and computing is not possible in practice, so so the idea that has been found was to go a step further in simplicity and considering walks instead of."
        ],
        [
            "Bus.",
            "So This is why we now present works."
        ],
        [
            "Notes.",
            "So I walk, walk is a bit like a party said that work is simply a set of vertices.",
            "So if you have a graph here at work, is a set of adjacent vertices.",
            "But the difference with the path is that you don't put any condition on the fact that versus has been encountered or not in the path.",
            "OK, so let's take a."
        ],
        [
            "A simple example of difference between the path in the walk.",
            "This is a walk, but this is not a bath OK, because what we call the path is a sub graph, so you cannot.",
            "One vertex can occur only once in a path.",
            "OK, so this is a path, but then you are stuck here because we cannot go here, it would not be apart anymore.",
            "Work is a sequence of vertices.",
            "You still follow the edges, but you can walk again on where you have worked already."
        ],
        [
            "Turns out that now you could say well, instead of extracting the path, I can extract the walks so you start from a graph.",
            "You can make the list of works.",
            "Of course there is an infinite number of works where there is a finite number of paths.",
            "Here you have an infinite number of folks because you can.",
            "You can continue working, and if in number of times, but this is not really a problem you define, you can define some infinite dimensional space and say, well, I start from a graph and I compute how many times each work occurs in the in the graph.",
            "This could be a feature representation, so.",
            "At the graph by the set of 5S of G where phase of G is the number of times there is a work isomorphic 22S.",
            "Then probably you need to wait the work to make sure that you embed your graph in a finite vector and you're here."
        ],
        [
            "Space and you can define work kernel between two graphs, one SG-2 as the inner product in India space.",
            "So this would be the sum over all possible paths of the weight of the sorry of the linear path of the weight of the linear linear graph.",
            "Here times number of times there is a work that occurs in the first graph and number of times there is a log data crossing the second graph.",
            "This is definition of graph kernel."
        ],
        [
            "Sorry for what candle so in fact these there are several values Now you can play on the weight you need to put some weight on the works OK because if you put no way then once again because you have an infinite number of works that occurs in each graph, the normal of your vector would be infinite so it would not be an embedding to the Hilbert space.",
            "So there has been at least two famous ways to select weights to put on the set of works, but I will start with the third one, which is even simpler.",
            "Let's call the NTH order Walker null simply the kernel obtained when you extract the walks of length.",
            "OK, so you have a graph and you say I will extract all the walks of length 5.",
            "Which means that in my formalism I will put a weight Lambda G of WW is a candidate linear path that would be a work.",
            "I put this weight equal to 1 if the value's length North and 0 otherwise.",
            "So obviously in this case you have a finite dimensional feature representation and there is no problem of infinite infinite number."
        ],
        [
            "Is the first solution.",
            "A second solution was presented so this was one of the two initial papers and on graph channels by Cashman coworkers.",
            "What to say?",
            "Well, one possibility is to put a weight toward corresponding to its probability, and there are some random walk on the graph.",
            "So which means that you start from a graph from a graph.",
            "You can design a random walk model this random walk that you kill at some points.",
            "Then this defines a probability of other set of works.",
            "And you can use it as a weighting scheme and therefore if you apply this weighting scheme to to this formalism, you attend a graph kernel, that would be the sum of a possible walks of number of times it occurs in each graph, weighted by its probability.",
            "This is equivalent saying this is the probability when you have two independent random walks over to graph.",
            "This will be the probability that the two walks end up with the same labels.",
            "You have labels, so the same labels of vertices and edges, for instance.",
            "So this is 1 possible."
        ],
        [
            "T An another one which is also famous and that ensures convergence of the process instead of having a random walk model to have some weights that only depends on the length of the work.",
            "And then typically two weights work of length by beta to the NV to being a real number smaller than something.",
            "So it has to be smaller than something to make sure that it converges.",
            "OK, there is a, you know if you have a big branching factor then beat us to be small, you need to make sure that when you strike all the walks and USB wait then by beta to the length you have a finite L L2 norm OK, but still possible and this is sometimes also geometric kernels, so these are the.",
            "Probably the most famous and widely used.",
            "What can also random or kernel and the geometric kernel which only differ in the weather.",
            "The weights are set up.",
            "OK, so I must say that I probably there is no reason to choose this one or this one.",
            "The motive, I mean the motivation for you for this weighting schemes is not really.",
            "Triggered by applications is more.",
            "We need something that converges, so when you put the probability not will converge when you when you put some experience or weights it will converge 2 but there is to my knowledge there is no further justification for this.",
            "OK you need something that allows you to have anything number of walks and still."
        ],
        [
            "Being content.",
            "So what's interesting and the reason why there are uses that these three kernels and many other kernels based on walks can be computed in polynomial time.",
            "And I mean it's not gonna search result.",
            "The algorithm is quite simple.",
            "Let"
        ],
        [
            "See how to do well?",
            "The basic results is to make a link between the walks that occurs in two graphs and the works that occur in the product graph.",
            "OK, so first I remind you the definition of product graph when you have two graphs G1 and G2 labeled graph, you can make a graph G 1 * G Two where the vertices are made of pairs of vertices with the same labels and what you put in edge when you have an edge between the two corresponding vertices in the original graphs, classical definition of graph kernel.",
            "Or product graphs.",
            "And the good news?",
            "I mean, the link between these representation and the graph kernels is that you can shake that when you have.",
            "The walk here and work here with the same set of labels.",
            "Then there is a one to one mapping between these pairs of walks and single walks on this product graph.",
            "OK, so for instance, if you take the walk 124 which is yellow, yellow, blue and the work ABC which is also yellow, yellow, blue.",
            "This correspond to the work one A2B3C.",
            "OK, and each time you have a work here that come that can come back, you have across many pairs of works here with the same labels, so you are able to express the set of pairs of works with the same labels as individual walks in this product graph.",
            "So of course this graph is bigger than that.",
            "Once it can be up to the square, I mean the number of vertices can be up to G 1 * G Two of course."
        ],
        [
            "But then you are in good situation 'cause once you have said that pairs of works with similar labels correspond to works and."
        ],
        [
            "Product graph.",
            "Then you with a couple of lines of the question, you can computer.",
            "Graphic analysis follows what you want to do is so the kernel would be the inner product in the space of work, so it will be the sum over all possible works of fires of G1 times phase of G2.",
            "This is definitional.",
            "This could be weighted by some Lambda if you wish.",
            "This is equivalent to saying that you want to extract all pairs of walks W1W2 with the same labels, and so you can wait it as indicator of labels of W 1 equals levels of W2 times some weight, and this thing the set of works of pairs of works with the same label.",
            "As I said, is exactly equal to the set of works of other product graph, so this is simply the set of works about the product product graph of some weight here, which is simply the product of individual weights.",
            "And if you have some additional Lambda, then you can include it here.",
            "OK, so to compute it then you just need to compute over the product graph the sum of other works of something."
        ],
        [
            "So let's take for instance the NTH order work analysis at the end for the worker was simply the way the walks of length with a weight of 1.",
            "So this means that you need to count with some algebra you can see that I said the end product is obtained when you take Lambda G1 of W is equal to 1, fourth or fifth.",
            "Then it means that on the product graph you have the product of 1 which is 1.",
            "So you have to compute the sum over all works on the product graph of indicator or the work is off like.",
            "Of length N, so this means that you just need to compute over the product graph how many walks of length N there are.",
            "This is the only thing, so this is the definition of Colonel Colonel is how many walks of length N are there on the product graph and this is something we know how to do because when you have a graph, you know that if you take the adjustment symmetric of the graph to the power North.",
            "It gives you the number of works, so the IJS entry of the adjusted symmetry to the power N exactly the number of works that start from.",
            "I got to J. OK, so if you want to do the same overall works is simply the sum of the entries of the adjacency matrix to the power North, which can be returned in terms of equation as one transpose A to the N1, and this is what I call my polynomial polynomial time algorithm.",
            "If you're tricky.",
            "I mean this is easy to see how to compute it fast, you know the A is adjusted.",
            "Tricky spa, so you can rephrase it as some dynamic programming like algorithm.",
            "You know you start by doing mattress product vectors and over 2 times.",
            "Then you multiply that by itself and you obtain this thing.",
            "OK so this shows you how to.",
            "So at the end you obtain an algorithm which depends.",
            "Ann is the is the length of the of the works will consider because you want A to the end.",
            "So you need to do over two times the product.",
            "You have the size of product graph that comes into play and this is basically the only two are related to the cost of having the matrix vector multiplication with a sparse matrix D1D12 maximum degrees of the graphs.",
            "So this is this is fast and this is how you compute the NTH order work."
        ],
        [
            "I will I will skip the details, but the other ones can be completed two.",
            "It's a bit less.",
            "I mean just three hours of computation.",
            "So suppose you take for instance the random or kernel or the geometric work Arnold.",
            "Well, for both kernel you need to, you need to check what is the, what is the weight corresponding to work, so need to make the sum of other works of the product graph weighted by something.",
            "And you can check that in both cases the weights corresponding to a work can be.",
            "Expanded as a product of terms that depends on successive pairs OK, and so the question is now, can I compute the sum over all weights that can be of infinite dimensions of this product's and this is easy to do because this is simply a some you can rewrite it as a sum of products and the sum of products is simply the sum of some matches to the power N times the sum of the entries of symmetry super worth so you end up with a normalization where.",
            "You have to take the sun for N = 1 to one of Lambda to the N and this thing is equal to identity minus Lambda inverse.",
            "OK, so this infinite sum can factorize as this equation.",
            "Here you asked the details but you have metric system that I and IT that correspond to the factors of YT schemes.",
            "OK, so we can apply this either to the probabilistic random walk model of this potential decay model is the same is simply the random matrices that change, but you end up with the same results.",
            "And therefore this case, I mean, because you cannot if you directly apply this, we need to invert this matrix so there's metricus size G 1 * G Two.",
            "Then you obtain capacity proportion to the.",
            "G1 Power Three and G2 power three.",
            "In practice, when you compute this, you don't really invert this matrix.",
            "You expand it using the first terms of the power series, and you stop when when you have no time.",
            "I mean, when you have reached a limit of computation time or the precision positioning it.",
            "OK, but at the end this is the target you need to compute this and then find a fast way to approximate this thing."
        ],
        [
            "OK, so conclusion we are able to compute the graph graph kernels however.",
            "So now if you want to apply them in practice.",
            "So we've been working on that.",
            "In practical applications there are a few things that you might want to do to improve the performance into my demo."
        ],
        [
            "Later I would just mention two extensions that are quite obvious but very important in practice.",
            "So the and in all three cases we want to play between the tradeoff between expressiveness and complexity.",
            "So we have seen that we're able to compute the word kernels, and the question is can we increase the bid expressiveness without increasing commercial computation?",
            "Still still saying the space of fast computations?",
            "Can we do more than simply the work kernels?",
            "So first idea is quite obvious, and it's very important in practice is to say that if you start from a graph like in chemistry season molecule, you can try to add labels to your atoms.",
            "Also, you are to be vertices.",
            "So instead of saying that this is just carbon as not an oxygen, you could using different schemes at some information.",
            "For instance regarding the environment of your carbon.",
            "In chemistry found, since there is something well known called the Morgan Index, which is to say this is iterative, you start from ones assigned to all vertices and you say at Step 2 I may just some of the numbers to the vertices.",
            "So this carbon after one Division's number 3 because there are three neighbors and if you apply your graph canal to this graph instead of to the first graph, then when you match the labels you will not only match the carbon with carbon but a cabin with three neighbors with the cabin with three neighbors.",
            "So you had a lot of precision.",
            "You speed up a lot of computation because you will have less matches, so the smaller product graph an we obtain better results at the end.",
            "OK, so the organic it is 1 example, but you can use any coloring scheme.",
            "You know the idea is starting from a graph.",
            "The philosophy is to say that if you add labels then you can add some precision in the descriptions and you can speed up the computation thanks to the product graph stuff that becomes smaller by adding some information environmental information."
        ],
        [
            "SQL Exception is the how to deal with what we call torturing and not ordering works.",
            "So the main difference between walks and path is that a work can work again where it has worked already.",
            "You know you can.",
            "You can turn on, you can go back and among the work.",
            "So in case of chemistry you have, you have cycles in molecules, but you have not so many cycles and you have many path and something that we don't want.",
            "I mean there are some words we don't fight, for instance if you have a linear graph, you have a work that can be start from the blue one, then go to the yellow, then back to the blue.",
            "So which means that you go back directly to a node you just visited.",
            "This is what we call the torturing path train means that you daughter OK. And we want to make a difference between the tottering wants at the notary wants an intuitively.",
            "So this is this one looks like a path.",
            "This was this one is not a bus and the idea is can we without changing many things.",
            "Can we remove this one?",
            "Not count this one in the in the kernel becausw somehow it just add noise no compared to the path."
        ],
        [
            "So it turns out that it's quite easy to do in terms of mathematically speaking.",
            "You could say, well, suppose you have the the random walk model is a first order Markov random walk, so if you just apply the 1st order Markov random walk, you cannot remember what you can from.",
            "Given this position, you need to go somewhere without knowing where you are from.",
            "Well, the idea would be to say just make a second order Markov model.",
            "Given that I am here and that I was here before, what can I go?",
            "You translated the probabilities and retreat to apply here.",
            "To compute it is say well when you have a second order Markov model.",
            "This is equivalent to a first order Markov model on some augmented space.",
            "You know instead of being in a state, you compute pairs of States and you say given these pairs of states or the previous one in Court One.",
            "What is the next pair?",
            "OK, so once you have said that you have broken down the complexity of computing the 2nd order Markov model to a first order Markov model over a bigger space when you applied it to graphs, there is a simple transform you can do.",
            "So when you start from a graph, just perform.",
            "An operation to transform the graph to another directed graphs and you can show that in this graph.",
            "I don't provide these questions, but it's quite common in the works in this graph.",
            "So here in this graph is a graph where you have directions and when you have specific nodes which correspond to starting points of the walks, you can check that the works in this graph that starts in this once exactly the non torturing walks in this graph.",
            "OK, so it corresponds to the augmenting the space of of Markov models have a second order Markov models OK, but this means that if you preprocess your graph starting from this graph to obtain this graph, then you obtain your labeled graph where the walks.",
            "Torturing or not, you cannot have touching works here, in fact, correspond exactly to the non terrain works here.",
            "So if you apply you graph cannot.",
            "To this graph you just do the inner product of other works which are non torturing.",
            "OK so you filter out all the torturing walks.",
            "There is of course which is that you increase the size of the graph.",
            "Some nodes are duplicated but but we are able to.",
            "Filter out the terminal."
        ],
        [
            "Last extension, so it's Extension 3 is to use subtree kernels, so this is an idea that was presented a few hours ago, again by Thomas Gattaran Ramanan, but which was only applied recently last year to my knowledge and practical issues.",
            "That is to say, well you know works correspond to linear path, and you know between subgraphs and in our path, you can think of trees are intermediate level complexity and ideas.",
            "Can you extract subtrees?",
            "And see that something attractable.",
            "So the answer is will be yes.",
            "So the idea would be if you start from your graph, you can describe the linear walks, but you can also extract what are rights here.",
            "If you can see some subgraphs which are three shapes of graphs, OK."
        ],
        [
            "It can be sweets, quite relevant because once again the complexity of molecules.",
            "Can be well approximated by trees you have cycled, but more importantly you have branchings.",
            "So for instance in these molecules you would like to extract graph that subgraph that could be this carbon followed by hazards and then that branches into two different subparts.",
            "So you write in the feature space to have this thing as a feature.",
            "It turns out that this feature is a tree, and it's much simpler to handle that some graphs in general, we said that subgraphs cannot be handled such risk and."
        ],
        [
            "Be handled and if you walk down the equations you obtain.",
            "Once again, you can compute the thing, but with some factorization of the other thing, the idea being to say that you can compute if you call T or V and the number of trees rooted at V with depth, you have a simple relationship between this number and the number of trees will see that the neighbors of your of your vertex of interest of death of death minus one.",
            "So you have an inverse one, so using this worker shown you can compute.",
            "The sum of our all trees, rooted everywhere of depth and weight them if you wish, etc.",
            "So there are a few more questions you can write, but at the end you can you.",
            "Can you increase the complexity but you can extract."
        ],
        [
            "Trees.",
            "OK, so so I can now present some."
        ],
        [
            "Some results of.",
            "So does it work or not?",
            "Well, the good news at the beginning of this of these series of work was was that you know, without putting any prior chemical knowledge, it works quite well.",
            "So for instance, if you if you take the 1st called 2D can also.",
            "This is the graph kernel based on works when you use the non torturing trick to make it work then you can you obtain quite close to state of the art results.",
            "So there is a classical benchmark where the problem is to predict mutagenicity.",
            "So you have some, let's say simplified toxic and non toxic molecules.",
            "You have training set and validation sets.",
            "So this is a classical benchmark.",
            "This model also you can do many things.",
            "And so protocol.",
            "This program one was one is not really state of the art because this is this is 1 which is only based on the graph structure.",
            "It's state of the art we if you just take into account the graph structure.",
            "But to be fair, she said that you have better results if you take into account the graph structure of the miracle plus other chemical features.",
            "OK, the size the log P other things.",
            "But among the algorithms based on the graph only, are you obtain quite quite good result?"
        ],
        [
            "Turn on the camera only.",
            "Another result would be on the study different but related database to check if using subtrees is relevant.",
            "So this picture.",
            "So without many things.",
            "But to summarize on the X axis you have the weight that you give two subtrees with a lot of branches, so this is you can wait a tree based on the branching factor.",
            "If you're here at zero, this column corresponds to the performance of the linear 2D kernel.",
            "OK, on the classical kernel is here, and when you go to the right.",
            "You give more and more ways to trees in the subtree formulation, with many branching factors.",
            "Now you have several curves.",
            "These curves correspond to trees of different depth, so we make your kernel 4 trees of depth 2, which is the blue curve.",
            "Here Updates 3, which is the black curve, etc.",
            "Service that in this case when you start from the work can also just considering linear works in your graph.",
            "These are not ordering in this case.",
            "You obtain your shop increase as soon as you give some ways to the trees.",
            "OK, so in the case of money cuz you really improve the thing.",
            "Once again here you use non torturing walks and non touching trees that you don't see but you can combine all the extensions because they correspond to preprocessing.",
            "So we can first start from your graph then made a graph transform to make sure that you have only non torturing walks and then apply the subtree kernel and you observe that as soon as we give way to the trees at least for the for the the best curve is obtained for H = 3.",
            "So these are simply.",
            "Trees of depth three is rated for molecules.",
            "You jump from some performance.",
            "You see below 80 to 8045, so there is a clear improvement is not always the case.",
            "For instance, if your trees are too deep.",
            "If you have a deep trees, then sometimes you can just degrade the performance by giving the weights.",
            "Probably 'cause you know there are too many features in this case.",
            "So when you have worked on seven, you can expect features.",
            "But if you want to extract resolving seven, there are too many trees compares to the signal.",
            "Innocence, so at least when you have a problem where the decision function might be related to features of small walks or even better, small trees, you might consider using trees and."
        ],
        [
            "The performance and in fact we just present the final result not obtained by myself, but by.",
            "They don't show in France is back at it called them into that work on image classification 'cause he called benchmark.",
            "This is coral databases or supervised classification.",
            "You are 14 classes.",
            "Each class contains 100 pictures, so they did the preprocessing to segment 8 each feature into homogeneous zone.",
            "Then represent each feature biograf and applying graph kernels.",
            "We had to talk this week exactly about the same topic except that.",
            "So what they did is to say, well we can apply.",
            "So this is a performance OK.",
            "This is a test of our so the lower the better the benchmark.",
            "The basic benchmark to say.",
            "Can we just extract histograms for the picture so this is not supposed to be very good, but this is this level.",
            "The second one is the war Colonel, so this is a one where you have a graph.",
            "You extract the walks and you run your stuff.",
            "You optimize the parameters, you obtain some good improvement and then the third one is that reward Colonel.",
            "So this is the one where you add the notion of trees.",
            "You extract nonlinear works, but also 3 three works.",
            "Or the pictures and you once again obtain some improvements.",
            "I will not talk about the later one, but you can still improve the performance by optimizing the weightings of different combinations, because I didn't talk about that, but at the end you obtain many candidate kernels and you could say is there a way to optimally combine the kernels, like doing some linear combinations?",
            "And if you do that, you can.",
            "You can still increase the performance."
        ],
        [
            "OK, I'm basically done so.",
            "Just to summarize what I've said.",
            "Well, the important messages that the graph can also allow you to apply many algorithms.",
            "I just talked about supervised classification, but you can do whatever you want as soon as you have a kernel between graph.",
            "So the idea of having a kernel positive internal between graphs is not only useful for graph classifications, but also for regression.",
            "This is something we use in chemistry when you want to predict the continuous function and also for for a variety of other things.",
            "So the work cannot represent the initially was motivated by chemical applications and at least at the beginning it solves explicit problems that occur in chemistry.",
            "I said that in chemistry you want to have vector presentations, but you cannot have too many too large vectors for storage purposes.",
            "So what they use in chemistry is to use some hash table and there is something called clashes where you have different features that end up in the same bit and then you have problems when you when you use the graph the trick.",
            "You cannot trick then you there is no problem in anymore of clashes 'cause you have different features and you can efficiently compute the inner product correspond to different features and.",
            "Basically, this is what we are able to do.",
            "There are still many open questions, or at least open issues.",
            "First, I said that at the end we have many kernels, so there is a general problem in kernel methods.",
            "Now that we have said that once you have accountabilities represented, many kernels have many parameters, many variants.",
            "A common question is how to choose the best care knowledge.",
            "There is a well know how to optimally combine kernels, how to select channels.",
            "There are some attempts.",
            "It's a hot topic in machine learning will clearly.",
            "The more and more I mean we have more and more kernels for graphs and not only forgot so many things.",
            "So in practice there is a trend nowadays to say, well, let's start with a big variety of Colonel.",
            "So let's say we take all the candles are presented with a family of parameters and then we run an algorithm to optimally combine them or select them etc.",
            "So this is a there is a trend you know to spend less time on this.",
            "Any specific kernels but more time on saying we take all possible kernels and then we design algorithm that can work with many kernels.",
            "So it's still a is still not very satisfactory what we have, but this is a general trend.",
            "Second, there is.",
            "There is clearly a problem of scalability.",
            "OK, so I presented examples where you have a few hundreds few thousands of graphs.",
            "Common metals in general and graph kernels in particular are expensive.",
            "You know, I say we are happy because we have computational times.",
            "But when you want to process ten millions of molecules, you cannot afford computing the 10,000,000 by 10,000,000 metrics.",
            "It would be too long to compute.",
            "You could not be able to store it, and you cannot.",
            "You cannot work with it.",
            "So clearly there are some attempts once again as well in the method.",
            "So more model the kernel methods that support vector machines do not require you to compute all kernel values.",
            "But there is also clearly I mean the bottleneck in the purchase of the computation of the kernel.",
            "So again, the tradeoff there was between.",
            "Expressiveness and complexity is very important.",
            "It's clear that any progress in fast computations of relevant graph kernels can have a big impact on practical applications.",
            "Nowadays it's a bit too slow compared to the size of the primes we have."
        ],
        [
            "Oh yeah, I just mentioned the references that you so you can check.",
            "I mean, these are the main differences are used in this talk.",
            "The first 2 papers by cashing meinel and get another where the first presentations of graph channels in 2003 RAM and got no mention that Ricky Arnold.",
            "Then we have a series of papers about applications of graph kernels on chem informatics.",
            "In particular should acknowledge the work of PMI who defended his PhD recently.",
            "Is now works in France.",
            "Who did most of the experiments and, and more importantly, we have?",
            "We have released an open version of, I mean a software to compute graph can also.",
            "This one is optimized for chemistry and perhaps it will not be very relevant for you because there is a lot of stuff to process.",
            "The format of chemistry, but at least all the algorithms are implemented and can be used if you are able to input your graph in the program.",
            "It reminds me to thank you for your attention.",
            "I'm sorry to be a bit late, but I'm ready to answer any questions.",
            "If you have any.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, good morning of course.",
                    "label": 0
                },
                {
                    "sent": "First of all, I'd like to thank a lot the Committee for giving me this opportunity and the organization.",
                    "label": 0
                },
                {
                    "sent": "It was very perfect and also to thank you for being here.",
                    "label": 0
                },
                {
                    "sent": "I mean, I will be surprised the last day of the workshop after the dinner and sunny weather you still here.",
                    "label": 0
                },
                {
                    "sent": "So it's quite impressive.",
                    "label": 0
                },
                {
                    "sent": "Socially before coming here, I was not really sure about what you know.",
                    "label": 0
                },
                {
                    "sent": "What familiarity you you have with Canon methods, but hearing many talks, I think that at least for some of you are quite familiar.",
                    "label": 0
                },
                {
                    "sent": "If not expressing currently kernels and kernel felt.",
                    "label": 1
                },
                {
                    "sent": "So I apologize because my goal here is to present a bit.",
                    "label": 0
                },
                {
                    "sent": "Of course, the state of the art, but a bit review what has been done in the.",
                    "label": 0
                },
                {
                    "sent": "Field of kernels.",
                    "label": 0
                },
                {
                    "sent": "Positive definite kernels for graphs.",
                    "label": 1
                },
                {
                    "sent": "Presents some applications in chem informatics where I've been working on.",
                    "label": 0
                },
                {
                    "sent": "And so try to convey you the the main ideas of how the candles appeared, how they are developed, how to make them work, and highlight a few open issues that need to be solved in the future if you want them to work even better.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I have quite a lot of styles, probably will.",
                    "label": 0
                },
                {
                    "sent": "I might skip some of them given the time constraint and the late hour, but I would like at least two after a brief introduction to Colonel scanner methods, which is a kernel to review.",
                    "label": 0
                },
                {
                    "sent": "Some work that has been done about one of the main issue in Calendar tells, which is a very common issue in graph algorithms.",
                    "label": 0
                },
                {
                    "sent": "In fact, is to find a tradeoff between what you want to express, what we incurred in algorithm, and the complexity of the algorithm itself.",
                    "label": 0
                },
                {
                    "sent": "So we see that in practice when we want to design graphic.",
                    "label": 0
                },
                {
                    "sent": "Also want to be able to compute them efficiently and want them to represent things an obviously you cannot do all.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'll review the results we have about that and as a result, how graph can also introduce to to have efficient algorithms.",
                    "label": 0
                },
                {
                    "sent": "This is the so they were most graph kernels that work nowadays are called walk kernels.",
                    "label": 1
                },
                {
                    "sent": "I will develop what is explain how it works.",
                    "label": 0
                },
                {
                    "sent": "I present a few extensions to make them work in practical applications because we see that the basic definitions often does not do not give very good results.",
                    "label": 1
                },
                {
                    "sent": "And finally present some experimental results to highlight the what's good and bad about graph kernels.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's start with.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With some motivation.",
                    "label": 0
                },
                {
                    "sent": "So in our lab work on computational biology and computational chemistry, and one of the big issues, it's not a new one in computational chemistry or chem informatics is to develop models predictive models to predict when you have a molecule.",
                    "label": 0
                },
                {
                    "sent": "So we work with small molecules, so this is typically a small molecule.",
                    "label": 1
                },
                {
                    "sent": "See these are three representations of smaller equals.",
                    "label": 0
                },
                {
                    "sent": "We want to predict properties of these molecules, and there are many properties we would like to be able to predict typical properties.",
                    "label": 1
                },
                {
                    "sent": "So the whole idea in many applications is to develop new drugs.",
                    "label": 0
                },
                {
                    "sent": "And most of the drugs are small molecules, so before developing a new drugs who let you know, in an ideal world to be able to design in silico molecule by first predicting if the molecule be toxic.",
                    "label": 1
                },
                {
                    "sent": "Arnold because you don't want to drive to be toxic, whether the molecule will be absorbed or not in the correct rate in your in your Organism this is called pharmacokinetics.",
                    "label": 0
                },
                {
                    "sent": "Whether it will be active so typically an active drug is a small molecule that can bind to a target target protein.",
                    "label": 0
                },
                {
                    "sent": "So you want to be able to predict that and many more properties.",
                    "label": 0
                },
                {
                    "sent": "So there is a model that there is a general.",
                    "label": 0
                },
                {
                    "sent": "Modeling, which is to say that we want to build models that take US input a molecule and you need to choose a bit how you describe the molecule and that from this molecule will predict the property.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that.",
                    "label": 1
                },
                {
                    "sent": "We have more and more experimental data about toxic molecules or active molecules or molecules that are well with good pharmacokinetic properties, so more and more we want to develop statistical models that, given a set of molecules with known properties, can find a function to relate the structure of the molecule to this to its activity or toxicity.",
                    "label": 0
                },
                {
                    "sent": "What we talk about is is is to build models for molecules where you represent America by your graph.",
                    "label": 0
                },
                {
                    "sent": "So I must say that this is not the only way to do, and once again molecule is not a graph graph is just an abstraction of a molecule, but the graphs are quite reasonable representations.",
                    "label": 0
                },
                {
                    "sent": "Becausw molecule is made of atoms with covalent bonds, and it's quite natural to represent America by a graph where the vertices are terms and the edges are present covalent bonds.",
                    "label": 0
                },
                {
                    "sent": "But once again I would say that the state of the art in.",
                    "label": 0
                },
                {
                    "sent": "In this field can use more and more features of molecules OK. For instance, you can use the three dimensional structure of Dominica, which brings a lot of information.",
                    "label": 0
                },
                {
                    "sent": "You can use the electrostatic potentials etc.",
                    "label": 0
                },
                {
                    "sent": "So here I will just talk about some basic representation which is quite useful, but to develop a real state of the arts program you probably need to take into account other features of medicals.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Either the first motivation and here is a natural example.",
                    "label": 0
                },
                {
                    "sent": "If you want to develop new drugs for AIDS, you can download other web database of molecules called the encia screen results where you have like 50,000 molecules that I mean tested experimentally to test whether they are active to bind versus target, which is one of the proteins of the HIV virus and therefore you can download the set of graphs and some are so the simplest quantification of them.",
                    "label": 0
                },
                {
                    "sent": "Some are active, so these are the blue ones, summer electives and the gold is given this database of active and inactive Nichols.",
                    "label": 0
                },
                {
                    "sent": "Build a model that will take when you take.",
                    "label": 0
                },
                {
                    "sent": "When you go to a pharmaceutical company, they have huge databases there on molecules, typically millions 10s of millions of molecules and you would like to do screening, which means that among the molecules in the databases of the company to find the ones that are likely to be active so that you can test them and perhaps develop metrics.",
                    "label": 0
                },
                {
                    "sent": "So this is a natural example that we would like to solve.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course I could mention other applications of graph kennels and we have seen many of them this week.",
                    "label": 0
                },
                {
                    "sent": "One of this one is to use graphic and also for image processing.",
                    "label": 0
                },
                {
                    "sent": "So typically there are examples of tasks in processing which are classification or clustering or low dimensional representation of molecules and sort of images and we have we have heard talks about that one way to represent an image could be to 1st segment 8 picture using segmentation algorithms and then represent the picture.",
                    "label": 0
                },
                {
                    "sent": "As a graph where the uniform regions would be vertices and where you put some edge between adjacent regions and where practical way the edges depending on the similarity between the regions if you wish.",
                    "label": 0
                },
                {
                    "sent": "But so when you do that to represent an image paragraph, and then you might want to develop algorithms to do pattern recognition or regression or classifications of of features based on the graph graphic representation.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in our case is at least in both cases are presented are other examples that of course you know we can formulate the problem as follows.",
                    "label": 0
                },
                {
                    "sent": "We have a set of graphs I will call the graphs X, XI, so we have a set of X1 X 2X N graphs.",
                    "label": 1
                },
                {
                    "sent": "We have a set of corresponding variables to predict.",
                    "label": 0
                },
                {
                    "sent": "I will call them Y1Y2Y N. This could be discrete or continuous depending on what you want to do.",
                    "label": 1
                },
                {
                    "sent": "Then you called that either a regression or supervised classification pattern recognition and the goal is, given a database of.",
                    "label": 0
                },
                {
                    "sent": "Labeled examples to learn a function F that will predict the Y variable from X&X is a graph I will talk about labeled graph, so I will assume that we have graphs that are that can be directed or undirected.",
                    "label": 0
                },
                {
                    "sent": "I will not make a big difference.",
                    "label": 1
                },
                {
                    "sent": "I mean they can be handled the same way in this framework and we assume that you have labels on the vertices and edges.",
                    "label": 0
                },
                {
                    "sent": "This is quite general presentation of graphs.",
                    "label": 0
                },
                {
                    "sent": "OK, so the question is can we adapt classical classical tools of statistical learning to work with graphs?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Uh, actually it's not difficult to imagine how to apply classical tools to this.",
                    "label": 0
                },
                {
                    "sent": "This framework and the last talk was an example.",
                    "label": 0
                },
                {
                    "sent": "One idea is to say that we start from a graph which is not obvious to handle in order to when you want to do least square regression, you don't know how to do the square regression and graphs, but wanted to say I will first represent my graph by your vector, and to do that I need to find a mapping from a graph to a vector or fixed dimension by extracting features.",
                    "label": 0
                },
                {
                    "sent": "So we heard the talk reference.",
                    "label": 0
                },
                {
                    "sent": "You can use some.",
                    "label": 0
                },
                {
                    "sent": "Some other we talk about edit distance.",
                    "label": 0
                },
                {
                    "sent": "Can you compare you graph to a Dictionary of graphs and then you can represent a graph by a vector.",
                    "label": 1
                },
                {
                    "sent": "In chemistry in chemoinformatics.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are classical representations of molecules as vectors, typically by extracting relevant substructures.",
                    "label": 0
                },
                {
                    "sent": "So when you start from molecule that has, let's take this molecule here.",
                    "label": 0
                },
                {
                    "sent": "That is made.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's really cool, but you can extract from this Microsoft parts which you know can be kind of called meanings like you have a benzene and stuff here.",
                    "label": 0
                },
                {
                    "sent": "This can be a few choices etc.",
                    "label": 0
                },
                {
                    "sent": "So in this case you need before hand to define a Dictionary of features and then when you have a new molecule, you for instance you can just count how many times it's each sub structure appears.",
                    "label": 0
                },
                {
                    "sent": "So you can count it.",
                    "label": 0
                },
                {
                    "sent": "Or you can have a binary representation saying it occurs or not and then this allows you to represent your graph.",
                    "label": 0
                },
                {
                    "sent": "As a Victor and once you have it, or you can apply for instance you own networks partially square, which is quite popular in coming from Dicks decision trees, support vector machines.",
                    "label": 0
                },
                {
                    "sent": "This collaboration whatever you want.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the first way to do some explicit representation of graphs as vectors.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The difficulties with this approach, which which is encountered in practice in chemical Mattis.",
                    "label": 0
                },
                {
                    "sent": "The following well first is not obvious how to choose the features OK?",
                    "label": 0
                },
                {
                    "sent": "So there is some prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "It has to be put in the features.",
                    "label": 1
                },
                {
                    "sent": "For instance, if you want to use this feature representation for patterning conditional regression, you would like the features somehow to be relevant for the prediction task.",
                    "label": 1
                },
                {
                    "sent": "OK, if you want to predict toxicity and you go to a features which are related to toxicity, which is not always obvious to design.",
                    "label": 0
                },
                {
                    "sent": "One approach would be to say, well, let's take as many features as we can.",
                    "label": 0
                },
                {
                    "sent": "We take all possible subgraphs.",
                    "label": 0
                },
                {
                    "sent": "Then we have a big big vector presentation, but then you have other issues because first, if you do that explicitly, you need to store to store vectors representation, which can be large.",
                    "label": 0
                },
                {
                    "sent": "And when you have databases of millions of molecules, if each molecule by vector of millions of dimensions, it becomes a problem.",
                    "label": 0
                },
                {
                    "sent": "Then you have from your speed of course, and you have of course statistical issues because if you have too many dimensions, most algorithms, more static algorithms are not designed to work in very, very large dimensions.",
                    "label": 0
                },
                {
                    "sent": "OK, some R and I will talk about them, but they basically square regression will not work if you have more dimensions than example.",
                    "label": 0
                },
                {
                    "sent": "OK, so you have a trade off to find between which feature to choose and is related to the previous talk about how to find relevant features like revenue graphs represent a graph by the vector of edit distances.",
                    "label": 0
                },
                {
                    "sent": "But this is an open issue.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the approach I will present is to use a trick which is not a new trick.",
                    "label": 0
                },
                {
                    "sent": "It's called the kernel trick.",
                    "label": 1
                },
                {
                    "sent": "It has been used a lot in kernel methods, public machines, which is to say that there is a class and a class of many algorithms that don't need to have the explicit representation of patterns of objects of graphs as vectors cause.",
                    "label": 1
                },
                {
                    "sent": "Because you can use something else which is the inner product between vectors, so these are following.",
                    "label": 0
                },
                {
                    "sent": "This is a definition.",
                    "label": 0
                },
                {
                    "sent": "Suppose you have graphs which I call X that you represent as feature vectors.",
                    "label": 0
                },
                {
                    "sent": "Fire fix.",
                    "label": 1
                },
                {
                    "sent": "This can be of any dimension.",
                    "label": 1
                },
                {
                    "sent": "Then what we call the kernel in this talk is simply the inner product between the images of two graphs.",
                    "label": 0
                },
                {
                    "sent": "After mapping by fire.",
                    "label": 0
                },
                {
                    "sent": "The idea is that once you have the kernel you can apply.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The algorithms that instead that do not explicitly where the fireplace, but instead require the kernel.",
                    "label": 1
                },
                {
                    "sent": "OK, so the good thing I mean I will develop, it'll be later, but the the main motivation behind this is that first, if you have a way to compute the kernel faster than the fire season five is prime.",
                    "label": 0
                },
                {
                    "sent": "You have some speedup of course of the algorithm.",
                    "label": 1
                },
                {
                    "sent": "Then you might have some some advantage in terms of memory storage cause instead of representing a graph by your large vector, you can just compute the inner product between your graph, another graphs which can be faster.",
                    "label": 1
                },
                {
                    "sent": "And then we will see that some algorithms can deal with high dimension which allow you to not hesitate to have like initial vectors.",
                    "label": 0
                },
                {
                    "sent": "So let me just.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be concrete for those of you who have never seen kennels.",
                    "label": 0
                },
                {
                    "sent": "If some I don't know, this is an example of a kernel method, which is how to compute the distance between two objects.",
                    "label": 0
                },
                {
                    "sent": "So suppose you start from a set of objects which could be graphs.",
                    "label": 0
                },
                {
                    "sent": "And suppose you have a mapping from your set of graphs to a feature presentation.",
                    "label": 0
                },
                {
                    "sent": "So here is just two dimensions that images can be 10,000 dimensions or infinite dimensional.",
                    "label": 0
                },
                {
                    "sent": "How can you define a distance between two graphs based on file?",
                    "label": 0
                },
                {
                    "sent": "Well, one idea would be to say when you take 2 graphs.",
                    "label": 0
                },
                {
                    "sent": "It's one X2.",
                    "label": 0
                },
                {
                    "sent": "They are mapped to two objects, fire.",
                    "label": 0
                },
                {
                    "sent": "This one 5 issue.",
                    "label": 0
                },
                {
                    "sent": "So these are two vectors which can be large and you could say well if I can define a distance metric between the two, the two the two graphs as the Euclidean distance between the images.",
                    "label": 0
                },
                {
                    "sent": "So one way to do with say I compute fireworks one I compute fireworks 2.",
                    "label": 0
                },
                {
                    "sent": "I made the difference and I take the Euclidean norm of the difference.",
                    "label": 0
                },
                {
                    "sent": "This is the distance.",
                    "label": 0
                },
                {
                    "sent": "Now if you expand it with two lines of simple computations, we can see that the computation of the distance between X1 and X2.",
                    "label": 0
                },
                {
                    "sent": "As the Euclidean distance in this space can be expanded as a sum of inner products, it's equal to the inner product between 5X1X1 plus 5X2 X 2 -- 2 * 5 = 2.",
                    "label": 0
                },
                {
                    "sent": "So now remember that we defined inner product as a kernel, so this.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We computed from the cannot only OK, so if you have a kernel K, when you compute CRV Sonics 1 + K of Easter is 2 -- 2 carriers phonics two?",
                    "label": 0
                },
                {
                    "sent": "This gives you a number which is exactly the distance the square Euclidean distance after mapping to the future space.",
                    "label": 0
                },
                {
                    "sent": "So this is a trivial example, but still which explains the the kernel trick which is that to compute the distance in this space, you don't need to compute the two vectors, you just need to be able to compute their inner product.",
                    "label": 0
                },
                {
                    "sent": "Supply this and it works.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out that this cannot trick and can be used for many other things than computing distances.",
                    "label": 0
                },
                {
                    "sent": "This can be useful.",
                    "label": 0
                },
                {
                    "sent": "You know if you want to use.",
                    "label": 0
                },
                {
                    "sent": "Distance is what you can do.",
                    "label": 0
                },
                {
                    "sent": "This would be called Colonel Cannulas.",
                    "label": 0
                },
                {
                    "sent": "Neighbors, which is that you can apply Ken Research both without having vector representations.",
                    "label": 0
                },
                {
                    "sent": "OK, you can use the hidden distance defined this way, but more Interestingly you have many other algorithms and I'm sure you've heard about them at least like support vector machines or kernel perceptron or kernel.",
                    "label": 0
                },
                {
                    "sent": "This square or kernel PCA.",
                    "label": 0
                },
                {
                    "sent": "There are many algorithms that can work in this space.",
                    "label": 0
                },
                {
                    "sent": "OK so for instance cannot PCI those some principle component analysis this space?",
                    "label": 0
                },
                {
                    "sent": "Without completing the vectors, because we can express principle component of this in terms of inner product's similarities, support vector machine is the one we will use is some algorithm for supervised classification where you have two sets of graphs like active and inactive graphs.",
                    "label": 0
                },
                {
                    "sent": "If you map them to a space and if you are able to compute the inner product there then you can learn a function that will discriminate between positive and negative ones.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Using the kernel trick.",
                    "label": 0
                },
                {
                    "sent": "So a few more words which are once again very classical about Colonel.",
                    "label": 0
                },
                {
                    "sent": "So here I said once you have a mapping file, you can define a kernel as inner product between fire base in five is prime.",
                    "label": 0
                },
                {
                    "sent": "Now it fights.",
                    "label": 0
                },
                {
                    "sent": "There are also cases where you want directly to define the kernel you want to say.",
                    "label": 0
                },
                {
                    "sent": "Well, so intuitively know Colonel is like a measure of similarity between the two graphs.",
                    "label": 0
                },
                {
                    "sent": "You could say, give me a similarity measure.",
                    "label": 0
                },
                {
                    "sent": "Is it a kennel or not?",
                    "label": 0
                },
                {
                    "sent": "For instance, give me the edit distance.",
                    "label": 0
                },
                {
                    "sent": "Which graphs is it related to?",
                    "label": 0
                },
                {
                    "sent": "A kernel?",
                    "label": 0
                },
                {
                    "sent": "Is it a Hilbert distance between points?",
                    "label": 0
                },
                {
                    "sent": "In this case the answer is no.",
                    "label": 0
                },
                {
                    "sent": "But how can you make sure that given security measure is again or not?",
                    "label": 0
                },
                {
                    "sent": "Well there is a general property which is the following.",
                    "label": 0
                },
                {
                    "sent": "So this is a definition cannot is called positive definite.",
                    "label": 1
                },
                {
                    "sent": "So cannot cannot now is just a function that takes 2 objects.",
                    "label": 0
                },
                {
                    "sent": "Is pragmatism number.",
                    "label": 1
                },
                {
                    "sent": "We say that is positive definite if it's symmetric and if it satisfies this tricky condition, which simply means that when you take a set of North graphs, you compute the matrix of pairwise kernel values.",
                    "label": 0
                },
                {
                    "sent": "It has to be this metric has to be positive semidefinite if it's always the case, then you said that the kernel.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We've submitted in it and you have a famous theorem that that stays the equivalence between positive positive definite kernels.",
                    "label": 0
                },
                {
                    "sent": "On the one hand and inner product on the other hand.",
                    "label": 0
                },
                {
                    "sent": "So this theorem says that.",
                    "label": 0
                },
                {
                    "sent": "Account all K is positive definite given the previous definition if and only if there exists some space inner product space and a mapping from your original space to this space such that the kernel K is equal to the inner product after mappings of the points.",
                    "label": 1
                },
                {
                    "sent": "OK, so this means that you might want to directly design kernel between graphs and use them with support vector machines if you are able to show that your kernel functions are positive definite.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now what is a graph can?",
                    "label": 1
                },
                {
                    "sent": "Oh well, Grafton is simply the applications of these tree.",
                    "label": 1
                },
                {
                    "sent": "Can this ID to the set of graphs?",
                    "label": 0
                },
                {
                    "sent": "OK, so the graph cannot simply function K that take two graphs as input outputs and numbers.",
                    "label": 0
                },
                {
                    "sent": "I will just talk about real valued kernel, but you could extend it too complex very kernel, but at least for real valued journalism, function of comparison between two graphs.",
                    "label": 1
                },
                {
                    "sent": "Search that this function should be equal to some inner product in some space and the space could be abstract.",
                    "label": 0
                },
                {
                    "sent": "I mean this is an inner product space Hilbert space.",
                    "label": 0
                },
                {
                    "sent": "But this could be infinite dimensional, so you want to define a positive definite functions over the set of graphs.",
                    "label": 1
                },
                {
                    "sent": "And when you do, that implicitly means that you are able to embed the set of graphs to help your space.",
                    "label": 0
                },
                {
                    "sent": "And when I'll call by embedding, here is is a mapping to Hilbert space, or is that the distance in this Hilbert space is equal to the distance that used by the camel?",
                    "label": 0
                },
                {
                    "sent": "It's an exact embedding is not approximate embedding, so it's equivalent to say, am I able to embed the set of graphs in the hyperspace or unable to define a positive definite kernel?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About the set of graphs.",
                    "label": 0
                },
                {
                    "sent": "So this is what we want to do.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A short summary of discern this short introduction.",
                    "label": 0
                },
                {
                    "sent": "The problem we have is we want to design general tools to solve problems of regression or pattern recognition, supervised classification of other set of graphs.",
                    "label": 1
                },
                {
                    "sent": "What one approach is to represent graphs as vectors, but it's not always easy to do for different reasons, and they can approach would be to say, well, we will directly define a graph kernel to compare two graphs.",
                    "label": 0
                },
                {
                    "sent": "The advantages that we can expect the following.",
                    "label": 0
                },
                {
                    "sent": "First, we might be able to consider a large number of potential features who are not limited by the number of features we want to use.",
                    "label": 1
                },
                {
                    "sent": "Saigon we don't need to store explicitly the vector representations.",
                    "label": 0
                },
                {
                    "sent": "If we define the RPD inner product discount correspond to very large dimensional vectors.",
                    "label": 0
                },
                {
                    "sent": "But we don't compute them, and 3rd, this is something I didn't say in detail, but we will be able to afford working in high dimensions because we will use algorithms that are dedicated to working large dimensions, 'cause they use regularization techniques.",
                    "label": 0
                },
                {
                    "sent": "So support vector machines is an example of algorithm that can work in larger missions because you control something else which is not the dimension which is.",
                    "label": 0
                },
                {
                    "sent": "Some other.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Complete measures OK, so so at this point now I will talk more precisely of how to design care, not for graphs.",
                    "label": 0
                },
                {
                    "sent": "So historically the first graph kernels were presented in 2003 by two groups in the same times, and I will explain some of the reason.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That have been found and how to design them.",
                    "label": 0
                },
                {
                    "sent": "So first of all there is this question of can we.",
                    "label": 0
                },
                {
                    "sent": "I mean we want to embed the set of graphs in Hebrew space.",
                    "label": 0
                },
                {
                    "sent": "So first of all, can we make an embedding such that we can describe in detail all the variations among graphs and if you walk in graph theory you know that isomorphism is 1 basic thing that you would like to be concerned saying that you want to embed the graph such that two different graphs in the sense that two non isomorphic graphs should be mapped to different points.",
                    "label": 0
                },
                {
                    "sent": "If you don't do that then you know that.",
                    "label": 0
                },
                {
                    "sent": "If you use a kernel which doesn't follow this property, then you will never be able to learn a function that differentiates non isomorphic graphs.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is what we call a complete kernel.",
                    "label": 0
                },
                {
                    "sent": "Complete kernel would be a kernel that separates noise amorphic graphs.",
                    "label": 0
                },
                {
                    "sent": "Very simple definitions.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So obviously I mean it's not difficult to show and probably you you know it if you are able to.",
                    "label": 0
                },
                {
                    "sent": "The next slide that.",
                    "label": 0
                },
                {
                    "sent": "There is obviously a tradeoff between having some expressive Cannon said that might be complete kernel and being able to compute.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because you know that solving the graph isomorphism problem is difficult.",
                    "label": 1
                },
                {
                    "sent": "OK, it's between P and NP.",
                    "label": 0
                },
                {
                    "sent": "I mean there is no known polynomial time algorithm to solve the to say whether two graphs are isomorphic or not.",
                    "label": 0
                },
                {
                    "sent": "And here I said if I have a complete kernel then I am able to solve the problem 'cause if I have a kernel I can compute the distance in the feature space given the equation I gave a few slides the goal and if you compute this distance, if you see that the distance is 0, this would mean that the canola, as an official not OK.",
                    "label": 0
                },
                {
                    "sent": "So obviously the computing any complete graph kernel is at least as hard as solving the.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rough isomorphism problem, which means it's difficult.",
                    "label": 1
                },
                {
                    "sent": "The previous, once again trivially if you have.",
                    "label": 0
                },
                {
                    "sent": "If you know how to compute the kernel, you have a test to check whether two graphs are symmetric or not, so you know it's hard to do.",
                    "label": 0
                },
                {
                    "sent": "Therefore you know that computing the kernel, computing a graph, complete graph kernel cannot be done in polynomial time for them.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one idea would be to say perhaps so, so now we talk about some ideas on how to design graph kernels, and we said that historically, before graph, cannot the string kernels like one year before the 1st graph kernels, they were substring kernels, and the instance there is something called.",
                    "label": 0
                },
                {
                    "sent": "The spectrum can only industries.",
                    "label": 0
                },
                {
                    "sent": "The idea was quite quite simple and quite efficient.",
                    "label": 0
                },
                {
                    "sent": "Practices were to say when you have a string, you can represent it as a vector by extracting all comers.",
                    "label": 0
                },
                {
                    "sent": "Overlapping cameras so you expect the blocks of length K you count the number of occurrences of each block and then this is a vector representation of a string and then you can compute the inner product efficiently.",
                    "label": 0
                },
                {
                    "sent": "OK, you don't need to explicitly write it, so he's right here.",
                    "label": 0
                },
                {
                    "sent": "Well, when people thought can we do the same on graphs and for instance, if I have a graph, this is a graph.",
                    "label": 0
                },
                {
                    "sent": "The natural correspondence to the cameras would be to say, yeah, we expect the subgraphs and you could say, well, given these graphs, I can extract all the subgraphs and build a feature representation of my graph by counting how many times each possible subgraphs occurs in my graph.",
                    "label": 0
                },
                {
                    "sent": "And then perhaps I will be able to move the inner product between these two things.",
                    "label": 0
                },
                {
                    "sent": "So this is a graph, and this is the list of subgraphs here.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so you could say, well, can I make?",
                    "label": 0
                },
                {
                    "sent": "So let's call that a subgraph candlewood say if I formally you can write it down.",
                    "label": 0
                },
                {
                    "sent": "You can say given a graph represented as a vector of large dimensions, it would be infinite dimension in this case, but most coordinates would be 0.",
                    "label": 0
                },
                {
                    "sent": "The dimensions correspond to possible subgraphs and the value is the number of times a subgraph occurs.",
                    "label": 0
                },
                {
                    "sent": "So this is what we called family.",
                    "label": 0
                },
                {
                    "sent": "5H of Jissoji would be a candidate graph.",
                    "label": 0
                },
                {
                    "sent": "Edge will be a candidate sub graph and five H of G would be the number of times.",
                    "label": 0
                },
                {
                    "sent": "You have a subgraph of G that is unfit to edge.",
                    "label": 1
                },
                {
                    "sent": "OK, so you count how many times each subgraph occurs.",
                    "label": 0
                },
                {
                    "sent": "This is a feature an you could make an inner product in the space of subgraphs, which would result in a kernel with the following expression.",
                    "label": 0
                },
                {
                    "sent": "So the inner product will be the sum of other features, which means the sum of other possible subgraphs, which are graphs of some way to kind of for some nonnegative weights corresponding to sub graph times 5H of G 1 * 5 H of G2 when compared to 1MG two.",
                    "label": 0
                },
                {
                    "sent": "This is simply the inner product in this space.",
                    "label": 0
                },
                {
                    "sent": "When you present a graph by the number of subgraphs, number of occurrences of different subgraphs.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "These are so you can we compute this channel where you can show that these are this kernel is NP hard, which means that it is at least as hard as NP complete problems.",
                    "label": 0
                },
                {
                    "sent": "So this was proven by Thomas Gagnon colleagues in 2003.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There is a nice demonstration.",
                    "label": 0
                },
                {
                    "sent": "I will quickly quickly.",
                    "label": 0
                },
                {
                    "sent": "Quickly show it because it is quite interesting to show how you can.",
                    "label": 0
                },
                {
                    "sent": "You can combine properties of kernels with know how to prove competitive algorithm.",
                    "label": 0
                },
                {
                    "sent": "So there is the following.",
                    "label": 0
                },
                {
                    "sent": "Suppose you consider PN the path graph.",
                    "label": 1
                },
                {
                    "sent": "So the linear graph with N vertices.",
                    "label": 0
                },
                {
                    "sent": "When you map this graph to the feature space, you need to explore the subgraphs.",
                    "label": 0
                },
                {
                    "sent": "OK, So what are the subgraphs of the linear graph with N vertices?",
                    "label": 1
                },
                {
                    "sent": "Well, the subgraphs are just linear subgraphs, OK of length 123, and you can count how many times there occurs.",
                    "label": 0
                },
                {
                    "sent": "So for instance.",
                    "label": 0
                },
                {
                    "sent": "For Europeans, the image of the linear graphs in the feature space of subgraphs.",
                    "label": 0
                },
                {
                    "sent": "If you call EP1 for instance, the coordinate corresponding to the linear sub graph of length one, you know that this one occurs N times it PN OK.",
                    "label": 0
                },
                {
                    "sent": "So you can't end times.",
                    "label": 0
                },
                {
                    "sent": "This is the first coordinate.",
                    "label": 0
                },
                {
                    "sent": "Then you know that the sub graph of length two occurs and minus one times in your chain and etc.",
                    "label": 0
                },
                {
                    "sent": "So this is the expectation of five PN in the feature space of subgraphs.",
                    "label": 0
                },
                {
                    "sent": "Now once you have that, it turns out that.",
                    "label": 0
                },
                {
                    "sent": "If you're interested in this in this dimension in the feature space, so the dimension corresponding to the sub graph PN.",
                    "label": 0
                },
                {
                    "sent": "Just by inverting a triangular system you can compute EPN from 5.",
                    "label": 0
                },
                {
                    "sent": "P. 152535 PNB cause in fact of the one you just have EP1 in five P2, you have EP1 and EP2 etc.",
                    "label": 0
                },
                {
                    "sent": "In 5:00 PM you have if you want in P2P N so you can invert the system.",
                    "label": 0
                },
                {
                    "sent": "An right that EPN itself is a linear combination of the file of peas.",
                    "label": 1
                },
                {
                    "sent": "For I = 1 two N with Alpha that can be computed in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "Just solving a triangle system OK?",
                    "label": 0
                },
                {
                    "sent": "So you can formally compute this vector as a linear combination of the five peas with Alpha computed in polynomial time, and if you have this vector then you are able to solve a classical problem in graph theory, which is called.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Instant pot problem.",
                    "label": 0
                },
                {
                    "sent": "So this problem is simply to say if you have a graph, can you find a path that goes through all vertices of your graph exactly once?",
                    "label": 0
                },
                {
                    "sent": "OK, well, you can see that this problem is really saying is the path of length NA sub graph of my graph.",
                    "label": 0
                },
                {
                    "sent": "This is the same thing.",
                    "label": 0
                },
                {
                    "sent": "OK so if you are able to say if you have a graph with N vertices, if you have if you are able to say whether the path the path graph of Lexan is a graph or not, then you have solved Hamilton problem.",
                    "label": 1
                },
                {
                    "sent": "And here how would you do that?",
                    "label": 0
                },
                {
                    "sent": "Well the.",
                    "label": 0
                },
                {
                    "sent": "The test is simply to say is the coordinate.",
                    "label": 0
                },
                {
                    "sent": "So if I have a graph G with vertices, when I map it to the feature space of subgraphs, is the coordinate corresponding to EPS or sorry EPN 0 or not?",
                    "label": 0
                },
                {
                    "sent": "If it's zero, it means that PN is not a sub graph.",
                    "label": 0
                },
                {
                    "sent": "If it's one, it means that pieces will graph.",
                    "label": 0
                },
                {
                    "sent": "So you need to say whether Fire OG scholar N is positive or not.",
                    "label": 0
                },
                {
                    "sent": "And because we say that EPN is a sum of Alpha Phi Phi of peas, you just need to compute.",
                    "label": 0
                },
                {
                    "sent": "For any given graph, 5G times the vector, so this is APN which is the sum of Alpha Phi of peas.",
                    "label": 0
                },
                {
                    "sent": "And because by definition five G * 5 P is a kernel between G&P, this value is equal to the sum of Alpha times K sub graph of GPI.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we have said that here is that.",
                    "label": 0
                },
                {
                    "sent": "If we are able to compute the kernel sub graph then we are able to solve the Hamiltonian.",
                    "label": 0
                },
                {
                    "sent": "But the problem with the polynomial time operation, which is computing this Alpha is which is easy inverter system?",
                    "label": 0
                },
                {
                    "sent": "And then you compute the sum.",
                    "label": 0
                },
                {
                    "sent": "If it's zero, then there is no Hamilton path.",
                    "label": 0
                },
                {
                    "sent": "If it's nonzero, then there is a Hamilton path.",
                    "label": 0
                },
                {
                    "sent": "So this implies that computing this case of graph must be at least as hard as solving the Hamilton path problem, and this one is NP complete.",
                    "label": 0
                },
                {
                    "sent": "OK, so this shows that the sub graph kernel cannot be computed.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Efficiently.",
                    "label": 0
                },
                {
                    "sent": "So some variance maybe to say, well perhaps some graphs out there are too many subgraphs.",
                    "label": 0
                },
                {
                    "sent": "I could perhaps is a bit of the task by considering considering only path.",
                    "label": 0
                },
                {
                    "sent": "So path is simply a linear sub graph.",
                    "label": 0
                },
                {
                    "sent": "OK, and you could say given given a graph, I will extract all in our sub graphs.",
                    "label": 1
                },
                {
                    "sent": "So this is an exhaustive list of linear subgraphs of this graph.",
                    "label": 1
                },
                {
                    "sent": "And you could imagine that processes one is easier to compute.",
                    "label": 0
                },
                {
                    "sent": "However, if you do exactly the same proof, the proof, I just see the replies here OK, because it only used linear path, so you can show that if you define the.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anyway, the past kernel as some inner product in the space of counts of paths in your graph, then you cannot compute this kernel efficiently, because this would also allow you to.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Solve the Hamiltonian path problem, which means that computing the past cannot is also NP hard.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a series of bad news.",
                    "label": 0
                },
                {
                    "sent": "You know you try to say well, can I cannot make any.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Complete kernel.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That is, let's go to summary, so I cannot make any complete graph kernel.",
                    "label": 1
                },
                {
                    "sent": "I cannot compute a subgraph channel that you could expect a bit simpler.",
                    "label": 0
                },
                {
                    "sent": "You cannot even compute the path Colonel know extracting path and computing is not possible in practice, so so the idea that has been found was to go a step further in simplicity and considering walks instead of.",
                    "label": 1
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bus.",
                    "label": 0
                },
                {
                    "sent": "So This is why we now present works.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Notes.",
                    "label": 0
                },
                {
                    "sent": "So I walk, walk is a bit like a party said that work is simply a set of vertices.",
                    "label": 1
                },
                {
                    "sent": "So if you have a graph here at work, is a set of adjacent vertices.",
                    "label": 1
                },
                {
                    "sent": "But the difference with the path is that you don't put any condition on the fact that versus has been encountered or not in the path.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's take a.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A simple example of difference between the path in the walk.",
                    "label": 0
                },
                {
                    "sent": "This is a walk, but this is not a bath OK, because what we call the path is a sub graph, so you cannot.",
                    "label": 0
                },
                {
                    "sent": "One vertex can occur only once in a path.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a path, but then you are stuck here because we cannot go here, it would not be apart anymore.",
                    "label": 0
                },
                {
                    "sent": "Work is a sequence of vertices.",
                    "label": 0
                },
                {
                    "sent": "You still follow the edges, but you can walk again on where you have worked already.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Turns out that now you could say well, instead of extracting the path, I can extract the walks so you start from a graph.",
                    "label": 1
                },
                {
                    "sent": "You can make the list of works.",
                    "label": 0
                },
                {
                    "sent": "Of course there is an infinite number of works where there is a finite number of paths.",
                    "label": 0
                },
                {
                    "sent": "Here you have an infinite number of folks because you can.",
                    "label": 0
                },
                {
                    "sent": "You can continue working, and if in number of times, but this is not really a problem you define, you can define some infinite dimensional space and say, well, I start from a graph and I compute how many times each work occurs in the in the graph.",
                    "label": 0
                },
                {
                    "sent": "This could be a feature representation, so.",
                    "label": 0
                },
                {
                    "sent": "At the graph by the set of 5S of G where phase of G is the number of times there is a work isomorphic 22S.",
                    "label": 1
                },
                {
                    "sent": "Then probably you need to wait the work to make sure that you embed your graph in a finite vector and you're here.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Space and you can define work kernel between two graphs, one SG-2 as the inner product in India space.",
                    "label": 0
                },
                {
                    "sent": "So this would be the sum over all possible paths of the weight of the sorry of the linear path of the weight of the linear linear graph.",
                    "label": 0
                },
                {
                    "sent": "Here times number of times there is a work that occurs in the first graph and number of times there is a log data crossing the second graph.",
                    "label": 0
                },
                {
                    "sent": "This is definition of graph kernel.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sorry for what candle so in fact these there are several values Now you can play on the weight you need to put some weight on the works OK because if you put no way then once again because you have an infinite number of works that occurs in each graph, the normal of your vector would be infinite so it would not be an embedding to the Hilbert space.",
                    "label": 0
                },
                {
                    "sent": "So there has been at least two famous ways to select weights to put on the set of works, but I will start with the third one, which is even simpler.",
                    "label": 0
                },
                {
                    "sent": "Let's call the NTH order Walker null simply the kernel obtained when you extract the walks of length.",
                    "label": 1
                },
                {
                    "sent": "OK, so you have a graph and you say I will extract all the walks of length 5.",
                    "label": 0
                },
                {
                    "sent": "Which means that in my formalism I will put a weight Lambda G of WW is a candidate linear path that would be a work.",
                    "label": 1
                },
                {
                    "sent": "I put this weight equal to 1 if the value's length North and 0 otherwise.",
                    "label": 1
                },
                {
                    "sent": "So obviously in this case you have a finite dimensional feature representation and there is no problem of infinite infinite number.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is the first solution.",
                    "label": 0
                },
                {
                    "sent": "A second solution was presented so this was one of the two initial papers and on graph channels by Cashman coworkers.",
                    "label": 0
                },
                {
                    "sent": "What to say?",
                    "label": 0
                },
                {
                    "sent": "Well, one possibility is to put a weight toward corresponding to its probability, and there are some random walk on the graph.",
                    "label": 1
                },
                {
                    "sent": "So which means that you start from a graph from a graph.",
                    "label": 0
                },
                {
                    "sent": "You can design a random walk model this random walk that you kill at some points.",
                    "label": 1
                },
                {
                    "sent": "Then this defines a probability of other set of works.",
                    "label": 0
                },
                {
                    "sent": "And you can use it as a weighting scheme and therefore if you apply this weighting scheme to to this formalism, you attend a graph kernel, that would be the sum of a possible walks of number of times it occurs in each graph, weighted by its probability.",
                    "label": 1
                },
                {
                    "sent": "This is equivalent saying this is the probability when you have two independent random walks over to graph.",
                    "label": 0
                },
                {
                    "sent": "This will be the probability that the two walks end up with the same labels.",
                    "label": 0
                },
                {
                    "sent": "You have labels, so the same labels of vertices and edges, for instance.",
                    "label": 0
                },
                {
                    "sent": "So this is 1 possible.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "T An another one which is also famous and that ensures convergence of the process instead of having a random walk model to have some weights that only depends on the length of the work.",
                    "label": 1
                },
                {
                    "sent": "And then typically two weights work of length by beta to the NV to being a real number smaller than something.",
                    "label": 1
                },
                {
                    "sent": "So it has to be smaller than something to make sure that it converges.",
                    "label": 0
                },
                {
                    "sent": "OK, there is a, you know if you have a big branching factor then beat us to be small, you need to make sure that when you strike all the walks and USB wait then by beta to the length you have a finite L L2 norm OK, but still possible and this is sometimes also geometric kernels, so these are the.",
                    "label": 1
                },
                {
                    "sent": "Probably the most famous and widely used.",
                    "label": 0
                },
                {
                    "sent": "What can also random or kernel and the geometric kernel which only differ in the weather.",
                    "label": 0
                },
                {
                    "sent": "The weights are set up.",
                    "label": 0
                },
                {
                    "sent": "OK, so I must say that I probably there is no reason to choose this one or this one.",
                    "label": 0
                },
                {
                    "sent": "The motive, I mean the motivation for you for this weighting schemes is not really.",
                    "label": 0
                },
                {
                    "sent": "Triggered by applications is more.",
                    "label": 0
                },
                {
                    "sent": "We need something that converges, so when you put the probability not will converge when you when you put some experience or weights it will converge 2 but there is to my knowledge there is no further justification for this.",
                    "label": 0
                },
                {
                    "sent": "OK you need something that allows you to have anything number of walks and still.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Being content.",
                    "label": 0
                },
                {
                    "sent": "So what's interesting and the reason why there are uses that these three kernels and many other kernels based on walks can be computed in polynomial time.",
                    "label": 1
                },
                {
                    "sent": "And I mean it's not gonna search result.",
                    "label": 0
                },
                {
                    "sent": "The algorithm is quite simple.",
                    "label": 0
                },
                {
                    "sent": "Let",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See how to do well?",
                    "label": 0
                },
                {
                    "sent": "The basic results is to make a link between the walks that occurs in two graphs and the works that occur in the product graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so first I remind you the definition of product graph when you have two graphs G1 and G2 labeled graph, you can make a graph G 1 * G Two where the vertices are made of pairs of vertices with the same labels and what you put in edge when you have an edge between the two corresponding vertices in the original graphs, classical definition of graph kernel.",
                    "label": 1
                },
                {
                    "sent": "Or product graphs.",
                    "label": 0
                },
                {
                    "sent": "And the good news?",
                    "label": 0
                },
                {
                    "sent": "I mean, the link between these representation and the graph kernels is that you can shake that when you have.",
                    "label": 0
                },
                {
                    "sent": "The walk here and work here with the same set of labels.",
                    "label": 0
                },
                {
                    "sent": "Then there is a one to one mapping between these pairs of walks and single walks on this product graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so for instance, if you take the walk 124 which is yellow, yellow, blue and the work ABC which is also yellow, yellow, blue.",
                    "label": 0
                },
                {
                    "sent": "This correspond to the work one A2B3C.",
                    "label": 0
                },
                {
                    "sent": "OK, and each time you have a work here that come that can come back, you have across many pairs of works here with the same labels, so you are able to express the set of pairs of works with the same labels as individual walks in this product graph.",
                    "label": 0
                },
                {
                    "sent": "So of course this graph is bigger than that.",
                    "label": 0
                },
                {
                    "sent": "Once it can be up to the square, I mean the number of vertices can be up to G 1 * G Two of course.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But then you are in good situation 'cause once you have said that pairs of works with similar labels correspond to works and.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Product graph.",
                    "label": 0
                },
                {
                    "sent": "Then you with a couple of lines of the question, you can computer.",
                    "label": 0
                },
                {
                    "sent": "Graphic analysis follows what you want to do is so the kernel would be the inner product in the space of work, so it will be the sum over all possible works of fires of G1 times phase of G2.",
                    "label": 0
                },
                {
                    "sent": "This is definitional.",
                    "label": 0
                },
                {
                    "sent": "This could be weighted by some Lambda if you wish.",
                    "label": 0
                },
                {
                    "sent": "This is equivalent to saying that you want to extract all pairs of walks W1W2 with the same labels, and so you can wait it as indicator of labels of W 1 equals levels of W2 times some weight, and this thing the set of works of pairs of works with the same label.",
                    "label": 1
                },
                {
                    "sent": "As I said, is exactly equal to the set of works of other product graph, so this is simply the set of works about the product product graph of some weight here, which is simply the product of individual weights.",
                    "label": 0
                },
                {
                    "sent": "And if you have some additional Lambda, then you can include it here.",
                    "label": 0
                },
                {
                    "sent": "OK, so to compute it then you just need to compute over the product graph the sum of other works of something.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's take for instance the NTH order work analysis at the end for the worker was simply the way the walks of length with a weight of 1.",
                    "label": 0
                },
                {
                    "sent": "So this means that you need to count with some algebra you can see that I said the end product is obtained when you take Lambda G1 of W is equal to 1, fourth or fifth.",
                    "label": 1
                },
                {
                    "sent": "Then it means that on the product graph you have the product of 1 which is 1.",
                    "label": 0
                },
                {
                    "sent": "So you have to compute the sum over all works on the product graph of indicator or the work is off like.",
                    "label": 0
                },
                {
                    "sent": "Of length N, so this means that you just need to compute over the product graph how many walks of length N there are.",
                    "label": 0
                },
                {
                    "sent": "This is the only thing, so this is the definition of Colonel Colonel is how many walks of length N are there on the product graph and this is something we know how to do because when you have a graph, you know that if you take the adjustment symmetric of the graph to the power North.",
                    "label": 0
                },
                {
                    "sent": "It gives you the number of works, so the IJS entry of the adjusted symmetry to the power N exactly the number of works that start from.",
                    "label": 0
                },
                {
                    "sent": "I got to J. OK, so if you want to do the same overall works is simply the sum of the entries of the adjacency matrix to the power North, which can be returned in terms of equation as one transpose A to the N1, and this is what I call my polynomial polynomial time algorithm.",
                    "label": 0
                },
                {
                    "sent": "If you're tricky.",
                    "label": 0
                },
                {
                    "sent": "I mean this is easy to see how to compute it fast, you know the A is adjusted.",
                    "label": 0
                },
                {
                    "sent": "Tricky spa, so you can rephrase it as some dynamic programming like algorithm.",
                    "label": 0
                },
                {
                    "sent": "You know you start by doing mattress product vectors and over 2 times.",
                    "label": 0
                },
                {
                    "sent": "Then you multiply that by itself and you obtain this thing.",
                    "label": 0
                },
                {
                    "sent": "OK so this shows you how to.",
                    "label": 0
                },
                {
                    "sent": "So at the end you obtain an algorithm which depends.",
                    "label": 0
                },
                {
                    "sent": "Ann is the is the length of the of the works will consider because you want A to the end.",
                    "label": 1
                },
                {
                    "sent": "So you need to do over two times the product.",
                    "label": 0
                },
                {
                    "sent": "You have the size of product graph that comes into play and this is basically the only two are related to the cost of having the matrix vector multiplication with a sparse matrix D1D12 maximum degrees of the graphs.",
                    "label": 0
                },
                {
                    "sent": "So this is this is fast and this is how you compute the NTH order work.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will I will skip the details, but the other ones can be completed two.",
                    "label": 0
                },
                {
                    "sent": "It's a bit less.",
                    "label": 0
                },
                {
                    "sent": "I mean just three hours of computation.",
                    "label": 0
                },
                {
                    "sent": "So suppose you take for instance the random or kernel or the geometric work Arnold.",
                    "label": 0
                },
                {
                    "sent": "Well, for both kernel you need to, you need to check what is the, what is the weight corresponding to work, so need to make the sum of other works of the product graph weighted by something.",
                    "label": 0
                },
                {
                    "sent": "And you can check that in both cases the weights corresponding to a work can be.",
                    "label": 1
                },
                {
                    "sent": "Expanded as a product of terms that depends on successive pairs OK, and so the question is now, can I compute the sum over all weights that can be of infinite dimensions of this product's and this is easy to do because this is simply a some you can rewrite it as a sum of products and the sum of products is simply the sum of some matches to the power N times the sum of the entries of symmetry super worth so you end up with a normalization where.",
                    "label": 0
                },
                {
                    "sent": "You have to take the sun for N = 1 to one of Lambda to the N and this thing is equal to identity minus Lambda inverse.",
                    "label": 0
                },
                {
                    "sent": "OK, so this infinite sum can factorize as this equation.",
                    "label": 0
                },
                {
                    "sent": "Here you asked the details but you have metric system that I and IT that correspond to the factors of YT schemes.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can apply this either to the probabilistic random walk model of this potential decay model is the same is simply the random matrices that change, but you end up with the same results.",
                    "label": 0
                },
                {
                    "sent": "And therefore this case, I mean, because you cannot if you directly apply this, we need to invert this matrix so there's metricus size G 1 * G Two.",
                    "label": 0
                },
                {
                    "sent": "Then you obtain capacity proportion to the.",
                    "label": 0
                },
                {
                    "sent": "G1 Power Three and G2 power three.",
                    "label": 0
                },
                {
                    "sent": "In practice, when you compute this, you don't really invert this matrix.",
                    "label": 0
                },
                {
                    "sent": "You expand it using the first terms of the power series, and you stop when when you have no time.",
                    "label": 0
                },
                {
                    "sent": "I mean, when you have reached a limit of computation time or the precision positioning it.",
                    "label": 0
                },
                {
                    "sent": "OK, but at the end this is the target you need to compute this and then find a fast way to approximate this thing.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so conclusion we are able to compute the graph graph kernels however.",
                    "label": 0
                },
                {
                    "sent": "So now if you want to apply them in practice.",
                    "label": 0
                },
                {
                    "sent": "So we've been working on that.",
                    "label": 0
                },
                {
                    "sent": "In practical applications there are a few things that you might want to do to improve the performance into my demo.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Later I would just mention two extensions that are quite obvious but very important in practice.",
                    "label": 0
                },
                {
                    "sent": "So the and in all three cases we want to play between the tradeoff between expressiveness and complexity.",
                    "label": 0
                },
                {
                    "sent": "So we have seen that we're able to compute the word kernels, and the question is can we increase the bid expressiveness without increasing commercial computation?",
                    "label": 0
                },
                {
                    "sent": "Still still saying the space of fast computations?",
                    "label": 0
                },
                {
                    "sent": "Can we do more than simply the work kernels?",
                    "label": 0
                },
                {
                    "sent": "So first idea is quite obvious, and it's very important in practice is to say that if you start from a graph like in chemistry season molecule, you can try to add labels to your atoms.",
                    "label": 0
                },
                {
                    "sent": "Also, you are to be vertices.",
                    "label": 0
                },
                {
                    "sent": "So instead of saying that this is just carbon as not an oxygen, you could using different schemes at some information.",
                    "label": 0
                },
                {
                    "sent": "For instance regarding the environment of your carbon.",
                    "label": 0
                },
                {
                    "sent": "In chemistry found, since there is something well known called the Morgan Index, which is to say this is iterative, you start from ones assigned to all vertices and you say at Step 2 I may just some of the numbers to the vertices.",
                    "label": 1
                },
                {
                    "sent": "So this carbon after one Division's number 3 because there are three neighbors and if you apply your graph canal to this graph instead of to the first graph, then when you match the labels you will not only match the carbon with carbon but a cabin with three neighbors with the cabin with three neighbors.",
                    "label": 0
                },
                {
                    "sent": "So you had a lot of precision.",
                    "label": 0
                },
                {
                    "sent": "You speed up a lot of computation because you will have less matches, so the smaller product graph an we obtain better results at the end.",
                    "label": 1
                },
                {
                    "sent": "OK, so the organic it is 1 example, but you can use any coloring scheme.",
                    "label": 0
                },
                {
                    "sent": "You know the idea is starting from a graph.",
                    "label": 0
                },
                {
                    "sent": "The philosophy is to say that if you add labels then you can add some precision in the descriptions and you can speed up the computation thanks to the product graph stuff that becomes smaller by adding some information environmental information.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "SQL Exception is the how to deal with what we call torturing and not ordering works.",
                    "label": 0
                },
                {
                    "sent": "So the main difference between walks and path is that a work can work again where it has worked already.",
                    "label": 0
                },
                {
                    "sent": "You know you can.",
                    "label": 0
                },
                {
                    "sent": "You can turn on, you can go back and among the work.",
                    "label": 0
                },
                {
                    "sent": "So in case of chemistry you have, you have cycles in molecules, but you have not so many cycles and you have many path and something that we don't want.",
                    "label": 0
                },
                {
                    "sent": "I mean there are some words we don't fight, for instance if you have a linear graph, you have a work that can be start from the blue one, then go to the yellow, then back to the blue.",
                    "label": 0
                },
                {
                    "sent": "So which means that you go back directly to a node you just visited.",
                    "label": 0
                },
                {
                    "sent": "This is what we call the torturing path train means that you daughter OK. And we want to make a difference between the tottering wants at the notary wants an intuitively.",
                    "label": 0
                },
                {
                    "sent": "So this is this one looks like a path.",
                    "label": 0
                },
                {
                    "sent": "This was this one is not a bus and the idea is can we without changing many things.",
                    "label": 0
                },
                {
                    "sent": "Can we remove this one?",
                    "label": 0
                },
                {
                    "sent": "Not count this one in the in the kernel becausw somehow it just add noise no compared to the path.",
                    "label": 1
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it turns out that it's quite easy to do in terms of mathematically speaking.",
                    "label": 0
                },
                {
                    "sent": "You could say, well, suppose you have the the random walk model is a first order Markov random walk, so if you just apply the 1st order Markov random walk, you cannot remember what you can from.",
                    "label": 1
                },
                {
                    "sent": "Given this position, you need to go somewhere without knowing where you are from.",
                    "label": 0
                },
                {
                    "sent": "Well, the idea would be to say just make a second order Markov model.",
                    "label": 0
                },
                {
                    "sent": "Given that I am here and that I was here before, what can I go?",
                    "label": 0
                },
                {
                    "sent": "You translated the probabilities and retreat to apply here.",
                    "label": 0
                },
                {
                    "sent": "To compute it is say well when you have a second order Markov model.",
                    "label": 0
                },
                {
                    "sent": "This is equivalent to a first order Markov model on some augmented space.",
                    "label": 0
                },
                {
                    "sent": "You know instead of being in a state, you compute pairs of States and you say given these pairs of states or the previous one in Court One.",
                    "label": 0
                },
                {
                    "sent": "What is the next pair?",
                    "label": 0
                },
                {
                    "sent": "OK, so once you have said that you have broken down the complexity of computing the 2nd order Markov model to a first order Markov model over a bigger space when you applied it to graphs, there is a simple transform you can do.",
                    "label": 0
                },
                {
                    "sent": "So when you start from a graph, just perform.",
                    "label": 0
                },
                {
                    "sent": "An operation to transform the graph to another directed graphs and you can show that in this graph.",
                    "label": 0
                },
                {
                    "sent": "I don't provide these questions, but it's quite common in the works in this graph.",
                    "label": 0
                },
                {
                    "sent": "So here in this graph is a graph where you have directions and when you have specific nodes which correspond to starting points of the walks, you can check that the works in this graph that starts in this once exactly the non torturing walks in this graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so it corresponds to the augmenting the space of of Markov models have a second order Markov models OK, but this means that if you preprocess your graph starting from this graph to obtain this graph, then you obtain your labeled graph where the walks.",
                    "label": 0
                },
                {
                    "sent": "Torturing or not, you cannot have touching works here, in fact, correspond exactly to the non terrain works here.",
                    "label": 0
                },
                {
                    "sent": "So if you apply you graph cannot.",
                    "label": 0
                },
                {
                    "sent": "To this graph you just do the inner product of other works which are non torturing.",
                    "label": 0
                },
                {
                    "sent": "OK so you filter out all the torturing walks.",
                    "label": 0
                },
                {
                    "sent": "There is of course which is that you increase the size of the graph.",
                    "label": 0
                },
                {
                    "sent": "Some nodes are duplicated but but we are able to.",
                    "label": 0
                },
                {
                    "sent": "Filter out the terminal.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Last extension, so it's Extension 3 is to use subtree kernels, so this is an idea that was presented a few hours ago, again by Thomas Gattaran Ramanan, but which was only applied recently last year to my knowledge and practical issues.",
                    "label": 0
                },
                {
                    "sent": "That is to say, well you know works correspond to linear path, and you know between subgraphs and in our path, you can think of trees are intermediate level complexity and ideas.",
                    "label": 0
                },
                {
                    "sent": "Can you extract subtrees?",
                    "label": 0
                },
                {
                    "sent": "And see that something attractable.",
                    "label": 0
                },
                {
                    "sent": "So the answer is will be yes.",
                    "label": 0
                },
                {
                    "sent": "So the idea would be if you start from your graph, you can describe the linear walks, but you can also extract what are rights here.",
                    "label": 0
                },
                {
                    "sent": "If you can see some subgraphs which are three shapes of graphs, OK.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It can be sweets, quite relevant because once again the complexity of molecules.",
                    "label": 0
                },
                {
                    "sent": "Can be well approximated by trees you have cycled, but more importantly you have branchings.",
                    "label": 0
                },
                {
                    "sent": "So for instance in these molecules you would like to extract graph that subgraph that could be this carbon followed by hazards and then that branches into two different subparts.",
                    "label": 0
                },
                {
                    "sent": "So you write in the feature space to have this thing as a feature.",
                    "label": 0
                },
                {
                    "sent": "It turns out that this feature is a tree, and it's much simpler to handle that some graphs in general, we said that subgraphs cannot be handled such risk and.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Be handled and if you walk down the equations you obtain.",
                    "label": 0
                },
                {
                    "sent": "Once again, you can compute the thing, but with some factorization of the other thing, the idea being to say that you can compute if you call T or V and the number of trees rooted at V with depth, you have a simple relationship between this number and the number of trees will see that the neighbors of your of your vertex of interest of death of death minus one.",
                    "label": 1
                },
                {
                    "sent": "So you have an inverse one, so using this worker shown you can compute.",
                    "label": 1
                },
                {
                    "sent": "The sum of our all trees, rooted everywhere of depth and weight them if you wish, etc.",
                    "label": 0
                },
                {
                    "sent": "So there are a few more questions you can write, but at the end you can you.",
                    "label": 0
                },
                {
                    "sent": "Can you increase the complexity but you can extract.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Trees.",
                    "label": 0
                },
                {
                    "sent": "OK, so so I can now present some.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some results of.",
                    "label": 0
                },
                {
                    "sent": "So does it work or not?",
                    "label": 0
                },
                {
                    "sent": "Well, the good news at the beginning of this of these series of work was was that you know, without putting any prior chemical knowledge, it works quite well.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if you if you take the 1st called 2D can also.",
                    "label": 0
                },
                {
                    "sent": "This is the graph kernel based on works when you use the non torturing trick to make it work then you can you obtain quite close to state of the art results.",
                    "label": 0
                },
                {
                    "sent": "So there is a classical benchmark where the problem is to predict mutagenicity.",
                    "label": 0
                },
                {
                    "sent": "So you have some, let's say simplified toxic and non toxic molecules.",
                    "label": 0
                },
                {
                    "sent": "You have training set and validation sets.",
                    "label": 0
                },
                {
                    "sent": "So this is a classical benchmark.",
                    "label": 0
                },
                {
                    "sent": "This model also you can do many things.",
                    "label": 0
                },
                {
                    "sent": "And so protocol.",
                    "label": 0
                },
                {
                    "sent": "This program one was one is not really state of the art because this is this is 1 which is only based on the graph structure.",
                    "label": 0
                },
                {
                    "sent": "It's state of the art we if you just take into account the graph structure.",
                    "label": 0
                },
                {
                    "sent": "But to be fair, she said that you have better results if you take into account the graph structure of the miracle plus other chemical features.",
                    "label": 0
                },
                {
                    "sent": "OK, the size the log P other things.",
                    "label": 0
                },
                {
                    "sent": "But among the algorithms based on the graph only, are you obtain quite quite good result?",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Turn on the camera only.",
                    "label": 0
                },
                {
                    "sent": "Another result would be on the study different but related database to check if using subtrees is relevant.",
                    "label": 0
                },
                {
                    "sent": "So this picture.",
                    "label": 0
                },
                {
                    "sent": "So without many things.",
                    "label": 0
                },
                {
                    "sent": "But to summarize on the X axis you have the weight that you give two subtrees with a lot of branches, so this is you can wait a tree based on the branching factor.",
                    "label": 0
                },
                {
                    "sent": "If you're here at zero, this column corresponds to the performance of the linear 2D kernel.",
                    "label": 1
                },
                {
                    "sent": "OK, on the classical kernel is here, and when you go to the right.",
                    "label": 1
                },
                {
                    "sent": "You give more and more ways to trees in the subtree formulation, with many branching factors.",
                    "label": 0
                },
                {
                    "sent": "Now you have several curves.",
                    "label": 0
                },
                {
                    "sent": "These curves correspond to trees of different depth, so we make your kernel 4 trees of depth 2, which is the blue curve.",
                    "label": 0
                },
                {
                    "sent": "Here Updates 3, which is the black curve, etc.",
                    "label": 0
                },
                {
                    "sent": "Service that in this case when you start from the work can also just considering linear works in your graph.",
                    "label": 0
                },
                {
                    "sent": "These are not ordering in this case.",
                    "label": 0
                },
                {
                    "sent": "You obtain your shop increase as soon as you give some ways to the trees.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the case of money cuz you really improve the thing.",
                    "label": 0
                },
                {
                    "sent": "Once again here you use non torturing walks and non touching trees that you don't see but you can combine all the extensions because they correspond to preprocessing.",
                    "label": 0
                },
                {
                    "sent": "So we can first start from your graph then made a graph transform to make sure that you have only non torturing walks and then apply the subtree kernel and you observe that as soon as we give way to the trees at least for the for the the best curve is obtained for H = 3.",
                    "label": 0
                },
                {
                    "sent": "So these are simply.",
                    "label": 0
                },
                {
                    "sent": "Trees of depth three is rated for molecules.",
                    "label": 0
                },
                {
                    "sent": "You jump from some performance.",
                    "label": 1
                },
                {
                    "sent": "You see below 80 to 8045, so there is a clear improvement is not always the case.",
                    "label": 0
                },
                {
                    "sent": "For instance, if your trees are too deep.",
                    "label": 0
                },
                {
                    "sent": "If you have a deep trees, then sometimes you can just degrade the performance by giving the weights.",
                    "label": 0
                },
                {
                    "sent": "Probably 'cause you know there are too many features in this case.",
                    "label": 0
                },
                {
                    "sent": "So when you have worked on seven, you can expect features.",
                    "label": 0
                },
                {
                    "sent": "But if you want to extract resolving seven, there are too many trees compares to the signal.",
                    "label": 0
                },
                {
                    "sent": "Innocence, so at least when you have a problem where the decision function might be related to features of small walks or even better, small trees, you might consider using trees and.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The performance and in fact we just present the final result not obtained by myself, but by.",
                    "label": 0
                },
                {
                    "sent": "They don't show in France is back at it called them into that work on image classification 'cause he called benchmark.",
                    "label": 0
                },
                {
                    "sent": "This is coral databases or supervised classification.",
                    "label": 0
                },
                {
                    "sent": "You are 14 classes.",
                    "label": 0
                },
                {
                    "sent": "Each class contains 100 pictures, so they did the preprocessing to segment 8 each feature into homogeneous zone.",
                    "label": 0
                },
                {
                    "sent": "Then represent each feature biograf and applying graph kernels.",
                    "label": 1
                },
                {
                    "sent": "We had to talk this week exactly about the same topic except that.",
                    "label": 0
                },
                {
                    "sent": "So what they did is to say, well we can apply.",
                    "label": 0
                },
                {
                    "sent": "So this is a performance OK.",
                    "label": 0
                },
                {
                    "sent": "This is a test of our so the lower the better the benchmark.",
                    "label": 0
                },
                {
                    "sent": "The basic benchmark to say.",
                    "label": 0
                },
                {
                    "sent": "Can we just extract histograms for the picture so this is not supposed to be very good, but this is this level.",
                    "label": 0
                },
                {
                    "sent": "The second one is the war Colonel, so this is a one where you have a graph.",
                    "label": 0
                },
                {
                    "sent": "You extract the walks and you run your stuff.",
                    "label": 0
                },
                {
                    "sent": "You optimize the parameters, you obtain some good improvement and then the third one is that reward Colonel.",
                    "label": 0
                },
                {
                    "sent": "So this is the one where you add the notion of trees.",
                    "label": 0
                },
                {
                    "sent": "You extract nonlinear works, but also 3 three works.",
                    "label": 0
                },
                {
                    "sent": "Or the pictures and you once again obtain some improvements.",
                    "label": 0
                },
                {
                    "sent": "I will not talk about the later one, but you can still improve the performance by optimizing the weightings of different combinations, because I didn't talk about that, but at the end you obtain many candidate kernels and you could say is there a way to optimally combine the kernels, like doing some linear combinations?",
                    "label": 1
                },
                {
                    "sent": "And if you do that, you can.",
                    "label": 0
                },
                {
                    "sent": "You can still increase the performance.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, I'm basically done so.",
                    "label": 0
                },
                {
                    "sent": "Just to summarize what I've said.",
                    "label": 0
                },
                {
                    "sent": "Well, the important messages that the graph can also allow you to apply many algorithms.",
                    "label": 0
                },
                {
                    "sent": "I just talked about supervised classification, but you can do whatever you want as soon as you have a kernel between graph.",
                    "label": 0
                },
                {
                    "sent": "So the idea of having a kernel positive internal between graphs is not only useful for graph classifications, but also for regression.",
                    "label": 0
                },
                {
                    "sent": "This is something we use in chemistry when you want to predict the continuous function and also for for a variety of other things.",
                    "label": 0
                },
                {
                    "sent": "So the work cannot represent the initially was motivated by chemical applications and at least at the beginning it solves explicit problems that occur in chemistry.",
                    "label": 0
                },
                {
                    "sent": "I said that in chemistry you want to have vector presentations, but you cannot have too many too large vectors for storage purposes.",
                    "label": 0
                },
                {
                    "sent": "So what they use in chemistry is to use some hash table and there is something called clashes where you have different features that end up in the same bit and then you have problems when you when you use the graph the trick.",
                    "label": 0
                },
                {
                    "sent": "You cannot trick then you there is no problem in anymore of clashes 'cause you have different features and you can efficiently compute the inner product correspond to different features and.",
                    "label": 0
                },
                {
                    "sent": "Basically, this is what we are able to do.",
                    "label": 1
                },
                {
                    "sent": "There are still many open questions, or at least open issues.",
                    "label": 0
                },
                {
                    "sent": "First, I said that at the end we have many kernels, so there is a general problem in kernel methods.",
                    "label": 0
                },
                {
                    "sent": "Now that we have said that once you have accountabilities represented, many kernels have many parameters, many variants.",
                    "label": 0
                },
                {
                    "sent": "A common question is how to choose the best care knowledge.",
                    "label": 0
                },
                {
                    "sent": "There is a well know how to optimally combine kernels, how to select channels.",
                    "label": 1
                },
                {
                    "sent": "There are some attempts.",
                    "label": 0
                },
                {
                    "sent": "It's a hot topic in machine learning will clearly.",
                    "label": 1
                },
                {
                    "sent": "The more and more I mean we have more and more kernels for graphs and not only forgot so many things.",
                    "label": 0
                },
                {
                    "sent": "So in practice there is a trend nowadays to say, well, let's start with a big variety of Colonel.",
                    "label": 0
                },
                {
                    "sent": "So let's say we take all the candles are presented with a family of parameters and then we run an algorithm to optimally combine them or select them etc.",
                    "label": 0
                },
                {
                    "sent": "So this is a there is a trend you know to spend less time on this.",
                    "label": 0
                },
                {
                    "sent": "Any specific kernels but more time on saying we take all possible kernels and then we design algorithm that can work with many kernels.",
                    "label": 1
                },
                {
                    "sent": "So it's still a is still not very satisfactory what we have, but this is a general trend.",
                    "label": 1
                },
                {
                    "sent": "Second, there is.",
                    "label": 0
                },
                {
                    "sent": "There is clearly a problem of scalability.",
                    "label": 0
                },
                {
                    "sent": "OK, so I presented examples where you have a few hundreds few thousands of graphs.",
                    "label": 0
                },
                {
                    "sent": "Common metals in general and graph kernels in particular are expensive.",
                    "label": 1
                },
                {
                    "sent": "You know, I say we are happy because we have computational times.",
                    "label": 0
                },
                {
                    "sent": "But when you want to process ten millions of molecules, you cannot afford computing the 10,000,000 by 10,000,000 metrics.",
                    "label": 0
                },
                {
                    "sent": "It would be too long to compute.",
                    "label": 0
                },
                {
                    "sent": "You could not be able to store it, and you cannot.",
                    "label": 0
                },
                {
                    "sent": "You cannot work with it.",
                    "label": 0
                },
                {
                    "sent": "So clearly there are some attempts once again as well in the method.",
                    "label": 0
                },
                {
                    "sent": "So more model the kernel methods that support vector machines do not require you to compute all kernel values.",
                    "label": 0
                },
                {
                    "sent": "But there is also clearly I mean the bottleneck in the purchase of the computation of the kernel.",
                    "label": 0
                },
                {
                    "sent": "So again, the tradeoff there was between.",
                    "label": 0
                },
                {
                    "sent": "Expressiveness and complexity is very important.",
                    "label": 0
                },
                {
                    "sent": "It's clear that any progress in fast computations of relevant graph kernels can have a big impact on practical applications.",
                    "label": 0
                },
                {
                    "sent": "Nowadays it's a bit too slow compared to the size of the primes we have.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh yeah, I just mentioned the references that you so you can check.",
                    "label": 0
                },
                {
                    "sent": "I mean, these are the main differences are used in this talk.",
                    "label": 0
                },
                {
                    "sent": "The first 2 papers by cashing meinel and get another where the first presentations of graph channels in 2003 RAM and got no mention that Ricky Arnold.",
                    "label": 0
                },
                {
                    "sent": "Then we have a series of papers about applications of graph kernels on chem informatics.",
                    "label": 0
                },
                {
                    "sent": "In particular should acknowledge the work of PMI who defended his PhD recently.",
                    "label": 0
                },
                {
                    "sent": "Is now works in France.",
                    "label": 0
                },
                {
                    "sent": "Who did most of the experiments and, and more importantly, we have?",
                    "label": 0
                },
                {
                    "sent": "We have released an open version of, I mean a software to compute graph can also.",
                    "label": 0
                },
                {
                    "sent": "This one is optimized for chemistry and perhaps it will not be very relevant for you because there is a lot of stuff to process.",
                    "label": 0
                },
                {
                    "sent": "The format of chemistry, but at least all the algorithms are implemented and can be used if you are able to input your graph in the program.",
                    "label": 0
                },
                {
                    "sent": "It reminds me to thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry to be a bit late, but I'm ready to answer any questions.",
                    "label": 0
                },
                {
                    "sent": "If you have any.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}