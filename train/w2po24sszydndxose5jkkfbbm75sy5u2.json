{
    "id": "w2po24sszydndxose5jkkfbbm75sy5u2",
    "title": "Introduction To Bayesian Inference",
    "info": {
        "author": [
            "Christopher Bishop, Microsoft Research"
        ],
        "published": "Nov. 2, 2009",
        "recorded": "August 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/mlss09uk_bishop_ibi/",
    "segmentation": [
        [
            "OK well good morning and very warm.",
            "Welcome to Cambridge on this typically sunny day.",
            "Not the note from in here.",
            "I'm.",
            "OK, just kind of here I guess.",
            "So because this is the first talk of the summer school, I thought I'd do something slightly different.",
            "Instead of trying to teach a lot of technical detail, which I think you'll get from a lot of the later talks, I thought I'd give you a sort of a personal perspective on where I think we are in the field of machine learning, and in particular I've come to believe that the next 10 years or so are going to be the most exciting in the entire history of the field of machine learning because we have some very exciting new techniques which allow us to address a whole class of new kinds of applications.",
            "So that's really what I want to talk about.",
            "In this first talk, and it's very much a personal perspective.",
            "And of course other lecturers may have other views on this as well.",
            "Let me begin, though, with perhaps most important slide."
        ],
        [
            "That you'll see, which is this one which is to encourage you to ask questions and to make the summer school interactive.",
            "Now I'm going to be standing here for two lots of 90 minutes that you're going to be sat there for 20 lots of 90 minutes or something.",
            "It's it's a long 2 weeks and you will get a lot more out of it if we if we make it interactive.",
            "So please just interrupt and ask questions as we go through."
        ],
        [
            "Almost as important as this slide, which is just to mention that I'll be taking material.",
            "Typically the second talk from this textbook and there's a copy here if you if you'd like to take."
        ],
        [
            "Look so I'm going to characterize what I think is happening in the field of machine learning as a sort of 3rd generation of machine learning, and so I better explain my terminology by telling you what I mean by by the 1st and 2nd generations, or really the 1st and 2nd generators of machine intelligence I guess.",
            "So what I call the 1st generation is good old fashioned AI, artificial intelligence and there's a nice quote here from Minsky from 1967.",
            "Within a generation.",
            "The problem of creating artificial intelligence will largely be solved and two years later anybody recognize this.",
            "Who knows what this is?",
            "How yes, great this is from the film 2001, so this was I think released in 1968 or there about the same error and it depicted that by the year 2000 would have their super intelligent computer and you can have a conversation that philosophy within all sorts of things.",
            "And the sort of Canonical first generation technique was the expert system based on knowledge extracted from humans.",
            "And.",
            "Had a number of successes, and indeed even today there are some problems where if you want to solve those problems, an expert system is going to be the best way to go.",
            "But in most applications, the technique of expert system suffered from this combinatorial explosion.",
            "There were lots of rules.",
            "There are exceptions to the rules, exceptions to the exceptions, and so on, and so by and large expert systems failed to deliver on Minsky's vision, so I'll characterize this first generation as handcrafted rules.",
            "Everything is built out of rules extracted from humans.",
            "They may be probabilistic rules, but they're all hand."
        ],
        [
            "Crafted so we call the second generation is characterized by things that neural network, support vector machines and then you proved to be much more successful in terms of applications.",
            "So here's an example, handwriting recognition, and there are thousands of other applications now of these techniques, and again, even today they remain extremely valuable from a practical perspective.",
            "One of the difficulties though, is that incorporating what I call complex domain knowledge, and I'm going to give you examples of this as we go through.",
            "So.",
            "I'll characterize the second generation as black box statistical models.",
            "The emphasis very much is on learning from data.",
            "Any prior knowledge that's built in is a rather general nature like continuity or maybe some translation invariants or something, but it's hard to build in this rich."
        ],
        [
            "Domain knowledge.",
            "So the thing that I'm very excited about is what I'm going to call third generation machine intelligence that's characterized by.",
            "A deep integration of rich domain knowledge combined with statistical learning.",
            "And that's really the sort of theme of this of this first talk.",
            "So there are three ingredients to this framework.",
            "The first is that it's based on a Bayesian approach.",
            "The second is that it makes use of probabilistic graphical models in order to describe the approach to the problem.",
            "The modeling of the problem, and it makes use of fast inference techniques which are based on passing local messages around these graphs in order to find tractable solutions, and in a way which is very efficient and scale to very large datasets.",
            "Although we call it third generation, these ideas have their origins going back a very long way in all sorts of fields like statistical physics and electrical engineering, signal processing, and so on.",
            "So these sort of generations of innocence grown up in parallel.",
            "But this, I think, is for me, one of the sort of it's very exciting frontiers of machine learning right now.",
            "OK, let's just begin then with talking a little bit about those three things.",
            "In turn, I'm just going to skim lightly over these topics, and you'll be familiar with some of them, perhaps others less so.",
            "But later talks will drill down into more detail.",
            "I want to give you a flavor for these different topics, and hopefully at least sort of motivate you to be excited about them and to listen to the details in the later lectures."
        ],
        [
            "So this should start with a little problem from probabilities, which is which is the following.",
            "You've got a red box in the blue box and inside each box we've got some apples and oranges depicted by some rather basic graphics I'm afraid.",
            "But on the left box we've got six oranges and two apples in the right box.",
            "We've got three apples and one orange, and will imagine a process by which somebody picks one of these boxes at random with some probability, and then reaches into the box and selects a piece of fruit again at random with equal probability of choosing any of those pieces of fruit.",
            "And we can ask the following question.",
            "Suppose that we don't know which box was chosen, but we do know that the piece of fruits was an orange.",
            "We can ask, what's the probability that the box was blue?",
            "So we're actually doing here is typical of what we're doing in machine learning problems.",
            "We're sort of going in the opposite direction to the physical process.",
            "The physical process is you first will choose the box, and then you choose the piece of fruit, and we want to sort of reverse that process.",
            "We know the piece of fruit, so we want to infer the probability that we chose the blue box.",
            "So of course we do that using the."
        ],
        [
            "The rules of probability and it's very beautiful theory because it just described by these two simple rules.",
            "So really most of what we're going to be talking about is just the consistent application of these.",
            "These two very simple rules.",
            "Does anybody why don't you let me take a minute to derive these rules of probability, or anybody everybody very happy with these.",
            "I imagine from the applicants we have at this summer school that everybody is very comfortable with these OK and probabilities of course satisfy the probability of the properties of being negative."
        ],
        [
            "And something to one.",
            "And from the from the sumrell.",
            "From the product rule of probability, we can write the conditional probability of Y given X in terms of the ratio of the joint to the marginal, and we can write the joint as the product of the conditional and the other marginal.",
            "Which gives us Bayes theorem.",
            "So base here and provides a way of.",
            "Evaluating the conditional probability of Y given X in terms of the reverse conditional P of X given Y and from the product in some rule, we can express the denominator in Bayes theorem in terms of a summation over the terms which appear in the numerator."
        ],
        [
            "So if we look at our apples and oranges, then and let's suppose that the probability of choosing the red box is 2/5.",
            "So it's more likely that we choose the blue box than the red box.",
            "And we somebody shows in the box.",
            "We don't know which one they've chosen a piece of fruit, and it's an orange.",
            "We first of all, compute the denominator and Bayes theorem, which is the probability that the fruit was orange.",
            "So that's probably that fruit is orange.",
            "Given that the box is red, well, that's just the fraction of pieces of fruit in the box, which are oranges times the probability that the box was red, which is 2/5, and then similarly for this term.",
            "In this case, the probability of the box is blue, it's just 1 -- 3/5.",
            "It comes out to be 9 twentieths.",
            "And then we use base theorem to compute the probability that the box is red given that the fruit was an orange and that comes out to be 2/3, which is bigger than 1/2.",
            "So sort of accord with our intuition observing that the piece of fruit is an orange is some evidence that steers more towards the red box than the blue box, because the proportion of oranges is higher in the red box.",
            "That is, in the blue box.",
            "OK, everybody comfortable with that only.",
            "Any questions I'm sure that's all.",
            "Why did I pick 2/5?",
            "It's just a tutorial example, so I just wanted to choose, well, I choose the ace of the numbers.",
            "Cannot simply an.",
            "Also because this is this is less than 1/2, so it's saying that a priority the IT was more likely that it shows the blue box.",
            "But once I saw the piece of fruit was an orange and now becomes more likely that in fact it was a red box, so that's slightly bigger than 1/2 after that, so.",
            "There's nothing, nothing deeper."
        ],
        [
            "Serious about these numbers.",
            "And of course, we can also talk about probabilities with respect to continuous variables.",
            "So X is a continuous variable.",
            "We can define a probability density shown by the red curve P of X.",
            "So the probability that X will lie in this little interval of width Delta X is just equal to that the area which is the product of Delta X times the height of this curve.",
            "And so the probability that X will lie within an interval A to B is the integral of the density over that interval.",
            "And if we integrate from minus Infinity up to a point zed of that density, we get something called the cumulative probability which is shown in that blue curve there.",
            "So it starts at 0 on the left and ends up at 1:00 on the right.",
            "And again these are non negative.",
            "In this case the probability dense."
        ],
        [
            "See integrates to one.",
            "So Bayesian inference, this is what the first of those three ingredients in this sort of 3rd generation framework that I'm talking about and.",
            "The idea of Bayesian inference is really a consistent use of probability to quantify uncertainty, so this is extending probabilities beyond the notion of frequencies of repeatable events and using probability theory anywhere that we have uncertainty.",
            "So if Theta is a quantity of interest and X represents all the things that we know about theater so far, let's say all the data that we've collected and other information we have, then we describe.",
            "Our uncertainty on over theater by this conditional probability P. Theater, given all the things we know so far summarized by X.",
            "And we'll call that the prior probability.",
            "And if we observe some new data X hat, then we can absorb the evidence from X hat by computing this quantity, which is the likelihood function, and we think of this as a function over Theta.",
            "So as PX given Theta.",
            "In which XX hat is set to the observed value and we look at this as a function of Theta, so evaluated for all values theater, we multiply that by the prior and up to normalization constant we get the posterior distribution.",
            "So that's using Bayes theorem to absorb the effect of that new evidence.",
            "So we've gone from the distribution before we observed X at the distribution after we observed X hat, and we'll see lots of examples of that as we go through.",
            "And the other important idea is that to make predictions we marginalise.",
            "So in this simple case we wish to predict a quantity Y, and we'll assume that the Y depends on X only through theater.",
            "So once we know Theta P of Y doesn't depend on X and so from the sum and product rules we want to predict P of Y given X, and that's obtained by taking P of Y given Theta.",
            "You need to give an X and marginalizing, so I'm making predictions using each and every possible value for Theta.",
            "But they waited by the current distribution current posterior distribution.",
            "And the other thing about this, of course, is that this is now effectively, if we observe yet more information.",
            "This is now our prior for the next application of Bayes theorem.",
            "So Bayesian inference is intrinsically a sequential process.",
            "As you observe more information, compute the new new likelihood function multiplied by the current distribution, which is the prior to get the new distribution, which is the posterior."
        ],
        [
            "Why is prior knowledge important?",
            "So I said the interesting thing about the third generation framework is that we can incorporate rich prior knowledge into our machine learning models.",
            "So why is prior knowledge important?",
            "So little cartoon sketch of why it might be important.",
            "So here's a variable X in the variable Y and we have collected some data which pairs of values of X&Y and we want to make a prediction.",
            "We want to know what value is why I'm going to take for this new value of X that's not been observed previously.",
            "And as things stand, it's actually quite quite hard to know what we should say about why.",
            "So not clear what value we should choose.",
            "But if I tell you that the values of Y were generated from the values of X by a straight line with some Gaussian noise added, and I tell you the variance of that noise.",
            "So I give you a lot of prior knowledge about the way that data was generated.",
            "You then, in a much better position to make predictions about the value of Y, and in fact of course without any prior knowledge you can't really say anything.",
            "There are many, many different ways in which why it could have been generated from X is a huge range of possibilities, and the more prior knowledge you have, the more constrained that range of possibilities, and therefore the better the predictions you can make.",
            "So actually prior knowledge is very central to machine learning.",
            "You can't really learn anything just from data alone.",
            "So graphical models can put your hand up if you already use graphical models in your research.",
            "Guessing about half but over half.",
            "OK, great, So what I'm going to do is to, as I said, skim lightly over the topic of graphical models and try to motivate them.",
            "Zubin is going to give two entire talks on the details of graphical models.",
            "So I shall just give a brief introduction for those of you who are not already."
        ],
        [
            "Leave the field.",
            "So the idea of graphical models is to take probability theory.",
            "In other words, the sum and product rule of probability, and to combine them with some diagrams and pictures some graphs.",
            "This brings lots of nice benefits.",
            "It gives us insights into existing models, models which are already just specified mathematically.",
            "We can now see them pictorially and that allows us to understand well for most of us, certainly for me allows us to understand the structure of the models much more clearly.",
            "Many, many people, myself included, find it much easier to look at a picture and see the structure than to look at a big page of mathematics.",
            "But also provides a framework for designing new models.",
            "Once we see the structure of the model graphically, we can alter the model if we wish by adding links to the graph or removing links or adding new nodes and so on.",
            "So we can design our model by designing the diagram.",
            "But it's actually much better than that, because we can also do calculations using using the diagrams we can do things like read off conditional independence properties simply by looking at separation properties directly on the graph.",
            "We could get the same results by grinding through pages of mathematics using the sum and product rule, but it's just much easier to look at the picture and read the results off directly.",
            "I guess a little bit like my background is physics and physics or these things.",
            "Will Feynman diagrams are doing perturbation expansions in field theory and essentially you could do everything without the diagrams, but the diagrams help you set out the calculations are very ordered way and avoid repeating lots of same calculations over and over again, and so that makes the calculations very easy and efficient.",
            "And on such efficiency the diagrams also lead to efficient software implementation.",
            "So we have algorithms for doing inference and learning on the graphs and you'll see these are expressed in terms of message passing algorithms.",
            "We can express them in terms of sending little messages around on the graph, doing lots of local calculations, and we can build software that reflects that structure, and that software will be very efficient.",
            "So I'm going to mention two kinds of graphs I think is even made mention others.",
            "I'm gonna talk about the use of directed graphs in order to design the model and then having designed the model, we can turn it into a different kind of graph called a factor graph, which is convenient for doing inference and learning using."
        ],
        [
            "Model.",
            "Sort of, these graphs all about, well, let's start with an arbitrary distribution of the three variables XY&Z and if we apply the product rule twice.",
            "We can write this symmetrical distribution.",
            "It's rather non symmetric way as a product of a distribution of each of the three variables XY&Z conditioned on other variables.",
            "So to do this we've chosen a particular ordering of those variables.",
            "We cannot represent that biograf.",
            "So each of these variables is represented by a circle in the graph.",
            "And the relationships between the variables are described by links between the between the circles or between the nodes.",
            "And these links carry arrows.",
            "That's why this is for directed graph.",
            "And the interpretation of the graph is that it specifies the way in which the joint distribution decomposes into this product of conditionals.",
            "In particular, there's one factor for each variable, and the conditioning variables are the parents in the graph.",
            "So if there's an arrow from X to Y, then X is said to be the parents of Y.",
            "So this graph says the joint distribution of XY and Z decomposes into P of X given its parents.",
            "Well, it doesn't have any parents.",
            "P of Y given its parents, it has one parent which is X&P of Z given its parents, which are X&Y.",
            "So that graph is equivalent to that decomposition.",
            "And we have a rule about these graphs.",
            "In order for this to to work properly, there must be directed cycles.",
            "That is, if you follow any loops in the graph, it must never be the case that you can go round and loop following the direction of the arrows, just related to this ordering of the variables."
        ],
        [
            "So a directed graph.",
            "More generally, has the property that there are missing links and it's the absence of links in the graph that really conveys information.",
            "So in this example, this is any distribution of the three variables is described by this graph.",
            "This graph is fully connected.",
            "Every variable is connected to every other.",
            "Once we start emitting links.",
            "So here's a graph of a 7.",
            "Variables were not every potential link is present.",
            "Links are missing.",
            "There was missing links tell us about independence properties and.",
            "This graph with missing links therefore describes a more restricted family of distributions.",
            "Therefore, encode some specific knowledge, because instead of looking at all possible distributions, it's looking at a narrow family of distributions.",
            "So we can write down the factorization specified by that graph in the same way as before.",
            "So seven variables with seven nodes for each variable, and so the joint distribution is the product of a conditional one for each variable, and each conditional is conditioned on its parents.",
            "So P of X1 to X7 is written as the product of X1.",
            "Given its parents, there aren't any similar X2 and X3P of X4 given its parents.",
            "The parents of X4 or X1X2X3 have X.",
            "Well given X one X2X3 and so on for the remaining factors.",
            "And notice I haven't said whether these are continuous variables or discrete variables, or whether they are Gaussian, distributed or gamma distributed or whatever.",
            "This is really describing a whole family of distributions, but a family of distributions that have certain independence properties.",
            "So we can use directed graphs to specify models and to capture prior knowledge.",
            "And the other thing that I won't dwell on too long, but the direction of the arrows can be thought of as representing causality.",
            "So if we think of our little boxes of fruit example, we can first of all we in the physical process in the physical world as we first of all, choose a box, then having chosen a box reach inside, we choose a piece of fruit, and that's the sort of ordering relationship we have in the physical process.",
            "But a machine learning we want to go in the opposite direction.",
            "We observe the piece of the identity of the piece of fruit.",
            "We want to infer which box it came from.",
            "And so that's typically true of these graphs, and you see examples later.",
            "The arrow specified the directions of causal physical process in the world, and then we typically observe nodes down here.",
            "We want to infer posterior distributions of nodes higher in the graph.",
            "Yes, question.",
            "Relationship can be include time, information, yes, and you'll see examples of temporal or she'll show you some examples later.",
            "Actually, we have time information.",
            "Yeah, great.",
            "I love questions.",
            "More questions.",
            "Independence.",
            "Necessarily.",
            "Yes, indeed there are other kinds of graphs that don't that there are undirected graph, for example that don't specify sort of soft relationships between variables without giving them the status of 1 being the cause of another.",
            "And also we might introduce variables that don't necessarily have an interpretation in the physical world they run observed variables that are there as part of the modeling process, and we don't necessarily.",
            "We may or may not wish to interpret those as being some actual piece of physics in the real world.",
            "Directed models you can also destroy another bad, which is which is the same independence relationships.",
            "Right so.",
            "Right, so so we're opening up a big discussion there about can we learn causality from the real world?",
            "So can we.",
            "Can we discover whether smoking causes cancer by observing correlations between people who smoke also tend to have cancer?",
            "Because we can't directly infer a causal relationship.",
            "There could be some common cause that causes people to want to smoke and gives them cancer, and the difference is really the interventions.",
            "If you stop smoking, are you less likely to get cancer or not?",
            "And if you make an intervention, then you can discover that causal relationship, but from correlation alone, you can't.",
            "So the big field of research do with discovering causality from statistical data and graphical directed graphs are one of the tools that are used in that field.",
            "I think maybe.",
            "Referencing arrows indicate causal relationships that you say when you design your graphics and inspired from portal relationship to decide the direction of the arrow.",
            "But then the representation itself doesn't really indicate collaboration, because often there's there's a big would you put out power in any direction, absolutely.",
            "So if you have three variables, these variables might be physical processors, and it might be the X causes Y&X&Y together cause Ed and so express your model in terms of that graph.",
            "But you're quite right.",
            "A Markov equivalent graph.",
            "We could reverse the direction of one of those arrows and have all the same statistical properties and be completely equivalent.",
            "Yeah, yeah.",
            "Thank you very much any other.",
            "Any other questions or?"
        ],
        [
            "Points of clarification.",
            "OK, let me give you an example.",
            "Then this is called the Manchester Aspirin Allergy Study and the goal is to discover fundamentally discover the environmental and genetic causes of childhood asthma which is an amazing proportion of children suffer from asthma.",
            "It's a huge a major disease in the Western world.",
            "This study is a birth cohort study just over 1000 children monitored since they were born and we recently collected genetic information.",
            "For for each of the children in the study and alongside the genetic information, we also have.",
            "Over the years we've collected or the study has collected very, very detailed, clean, carefully collected environmental and physiological measurements.",
            "For example, skin tests to determine allergic sensitivity.",
            "Blood tests that measure similar allergic sensitivity notes on whether the child was wheezing or not.",
            "A methacholine response.",
            "The child breeze in a little bit of a substance which induces an artificial asthma attack, and you measure how much of this stuff they have.",
            "Breathe in before they show symptoms of asthma, so these children go through a lot to contribute to this study and the measured at ages 135 and eight.",
            "So we have data through time and lots of other background information about whether their parents smoked and whether they have very petzen."
        ],
        [
            "No.",
            "So this is this is not a director graphical model yet.",
            "This is a sort of block diagram that begins to capture some of the prior knowledge which the clinicians have about the nature of asthma and the things which affect it.",
            "And you may not be able to read from the back.",
            "The details are not important.",
            "The point is, there are lots of different factors here and they connect to each other and fairly specific ways.",
            "So we have asthma, some here in the middle.",
            "We don't actually observe that directly.",
            "What we observe the symptoms of it.",
            "Things like wheezing and so on, and the three major routes to causing asthma.",
            "Inflammation of the Airways.",
            "The overall strength of the airway system measured by or the maximum attainable lung functions.",
            "It's called, and the bronchial hyperresponsiveness how twitchy the system is.",
            "How rapidly the bronchial system responds to external stimuli, such as allergens.",
            "And over here this is the part of the graph which describes allergic response.",
            "Here we have a box labeled genome, but of course the genetic the genetics points and all sorts of aspects on this graph.",
            "This diagram itself is not even completed, just a partial picture.",
            "So I'm going to do is take one little piece of this diagram and expand it up and turn it into a directed graph.",
            "But the point of this is to show that.",
            "Here's an example where we're not simply looking for correlations between genetic variability and a binary disease label asthma.",
            "Not asthma the the real world is much more complex as well as being many genes that affect asthma.",
            "There are many environmental factors.",
            "But rather than just throw them into a big black box statistical model, what we're doing here is capturing all the clinical prior knowledge that we have about the way the variables affect one another.",
            "So."
        ],
        [
            "Let's just take a little piece of this and turn this into a directed graph.",
            "So here are the nodes on the graph.",
            "Here are the arrows.",
            "This is a.",
            "This is a binary variable which says whether or not the child has acquired sensitization to a particular allergen at age 1 and then simply for age 3, five and eight.",
            "So each of these is a binary variable.",
            "These boxes are called plates.",
            "These just mean that what's inside the plate gets replicated a certain number of times, so this is a plate for the children, so down here it says children 1186.",
            "Everything inside here is copied for every child.",
            "Every child has a copy of this variable.",
            "This plate is a plate for allergens, of which there are eight mice, cat, dog, egg, milk, peanut and so on, and so everything inside this plate is replicated 8 times.",
            "So each child has eight variables to do with whether they acquired sensitization age 1 to each of the eight allergens.",
            "And this is correct.",
            "Another question.",
            "This is an example of a directed graph showing.",
            "Variables evolving through time, so we are assuming in this model that these variables form a Markov chain, so the sensitization age 5 depends directly on the sensitization age 3, but it's not depend directly on the sensitization at age 1.",
            "Now these are all things we don't deserve.",
            "We don't, yeah.",
            "Between the different allergies.",
            "I'm.",
            "We yes, yes, these are.",
            "These are independent.",
            "I mean they won't process a posteriori.",
            "They won't be independent.",
            "But yes, we are, so we're making all sorts of assumptions here and the beauty of graphical models is those assumptions are very made very explicit in the graph.",
            "So you can just look at the diagram and see what assumptions you're making.",
            "If you don't like the assumptions, if you'd like to have some dependence, if you think sensitisation age 5 should pen directly on sensitization age one, you can just add in an extra link to your graph.",
            "Yes.",
            "I don't have the same CPU.",
            "I'll come to that in a minute.",
            "The question is whether these share the same probabilities or not OK, so."
        ],
        [
            "We don't deserve these directly.",
            "What we actually observe.",
            "The results of skin tests.",
            "So the child is given a skin prick with these different allergens, cat and peanut, and so on, and see whether the skin goes red.",
            "So we have that data and then related to some immunoglobulin E blood tests where you look for a marker in the blood which says that this child is become sensitized to peanut or whatever and these are measured at age 1, three, five and eight.",
            "So in graphical models, when we observe a variable be shade in the node, so these nodes.",
            "Are the observations for each child and for each allergen.",
            "And now the probability of acquiring.",
            "Sensitization at age 3.",
            "Given your sensitize at age 1 is some variable, and I'll come to that in it, this is the probability of having a positive skin test today three given their sensitized age 3 is some variable and that's described.",
            "That's described down here.",
            "So this is the probability of a positive skin test given they were sensitized and the probability of positive skin testing that we're not sensitized and then similarly for the blood tests.",
            "So these are variables and these are shared.",
            "Across.",
            "All of all of the.",
            "Halogens, and across all of the children and across the different ages.",
            "But they needn't be.",
            "And we explored lots of different variants.",
            "So if you want to allow different set of variables for each allergen, you simply take these nodes and drag them inside the plate and then you get a separate variable for each allergen."
        ],
        [
            "And we also have variables governing the initial probability of sensitization at each at age 1, and then these transition probabilities.",
            "The probability of being sensitized age 3 given that sensitize at age 1 and.",
            "So there's a described by these yellow variables, so these all have prior distributions and then finally we introduce a sensitisation class.",
            "So this is another unobserved variable which has, let's say 5 States and its switches between different choices for these probabilities.",
            "And there's a separate variable foreach children for each child, or 1000 of these variables.",
            "So what this is doing is unsupervised clustering.",
            "Because when we observe, this data will have a posterior distribution over these classes for each child, and so effectively we're softly clustering the children into however many groups it isn't.",
            "So let's say five were softly clustering the children into five groups.",
            "Other things we discover with this model is that within these classes, these soft classes are much stronger indicators of asthma than the raw observed asthma label that's assigned by the GP in the doctors surgery, and so that's a much better variable.",
            "To look for correlations with genetic variability than the simply the presence or absence of asthma.",
            "So the point here is that we are capturing lots of prior knowledge, expressing it as a graph and the structure of the graph tells us about the assumptions we're making.",
            "For example on whether these parameters are shared through time or across children or whatever."
        ],
        [
            "So that's directed graphs for designing the model.",
            "Now we want to do inference on the graph, and for that it's convenient to turn the graph into a different kind of graph, called a factor graph.",
            "You'll be learning a lot more about these later.",
            "The idea is fairly simple, so again, let's consider three variables X one X2X3.",
            "We have a separate node for each variable.",
            "And we also have some square nodes which describe the factors.",
            "So the joint distribution again factorizes into a product of factors, and each factor depends on some subset of the variables.",
            "So the links show the variables that each factor depends on.",
            "So in this case there are four factors and factor FA depends only on X1 and X2.",
            "There are links from FA to X1 and 2X2."
        ],
        [
            "So, given a directed graph, we can then very easily turn it into a factor graph, so here's a directed graph of a three variables.",
            "Here's its factorization of X1, P of X 2 * P of X3.",
            "Given X one X2.",
            "And we can just turn that directly into a factor graph with three factors.",
            "And then by inspection we can read off these three factors.",
            "The first factor P of X1, the second factor.",
            "We have X2 and the third factor is P of X3.",
            "Given X one X2 so FC which depends on the variables X one X2 and X3 is connected to those corresponding nodes in the graph.",
            "So."
        ],
        [
            "It's a factor graph.",
            "Much more of that later in Zubrin's talks.",
            "So let's look at how we do inference on graphs.",
            "And here's the key idea, really.",
            "The expression on the right hand side is algebraically equivalent to the expression on the left hand side, but on the left hand side to evaluate the left hand side we have to perform three operations, two multiplications and additions.",
            "So three numerical operations to evaluate the left hand side.",
            "So computationally the right hand side is not equivalent to the left hand side, because what we've done is to exploit the factorization we've pulled out as a factor and now to evaluate the right hand side, we need 1 addition and one multiplication, so by using the right hand expression.",
            "We can evaluate this quantity computationally more efficiently than by using the left hand side, and in so doing we exploited the factorization of expr."
        ],
        [
            "And on the left.",
            "So that's the idea that we're going to apply, so let's apply that.",
            "Now to factor graph.",
            "Is a factor graph with five variables.",
            "VWXY&Z and four factors.",
            "So the factor graph tells us that the joint distribution factorizes into the product of these factors and it's these factors each of them actually depends on a pair of variables.",
            "So in terms of the potential links which there could be in this graph, many many links are missing for very simple graph.",
            "Actually is just a tree structured graph, no loops.",
            "So let's ask the following question.",
            "Let's ask for the marginal of this particular variable W. Let's compute that well from the sum rule of probability to compute the marginal for W, we take the joint distribution and we sum out the other four variables.",
            "So this is the computation that we have to perform.",
            "Now we perform that computation directly.",
            "Let's see how expensive that would be.",
            "Well, these are discrete variables, and the first thing we have to do is to compute this quantity.",
            "So if we imagine that these were each variable had K different states K different values that it could take, then we would have this big table of.",
            "Of the five variables or 5 dimensional occasion, the power 5th table, it would have to compute and they would have to do K to the power four sums in order to get this K dimensional vector at the end.",
            "The module that we're after, and if we increase the graph in size, you can see that the amount of storage we need, more computation would need to do in that naive approach would grow exponentially with the size of the graph.",
            "But instead we can exploit the factorization by making use of the fact that these factors only depend on a small number of variables.",
            "So in particular.",
            "For looking at the marginal for W, we can notice that the variable V appears only in this factor here, so we can pull that out as a common factor and do the summation over V separately from the remaining summations.",
            "And so this is numerically algebraically equivalent, but numerical numerically computationally is more efficient.",
            "Another elegant thing we can do here is to express this in terms of local messages on the graph.",
            "So this quantity is some function of W and will think of this as a message that's sent from this factor node to this variable node called F1 to W. So function of W. And similarly this remaining object will think of this as a message that sent from here to here.",
            "So each of these are sort of K dimensional vector.",
            "And to compute the marginal we simply have to multiply them pointwise together.",
            "So that's an order K operation.",
            "And computing this involves a little K by K matrix.",
            "That sort of quadratic in K and we have to do K sums for each of the K values of W. So there's a little order K squared calculation to compute that message, so we can do that very efficiently, and then the multiplication again is a little K dimensional multiplication, so again, that's also.",
            "That's also very efficient.",
            "So if we compute this message efficiently, we could do the whole thing in quadratic time instead of exponential time.",
            "So.",
            "Well then.",
            "So yeah.",
            "So I started by talking Bout directed graphs and Maps, multifactor graphs in which each factor is one of those conditional distributions.",
            "But innocence the factor graphs are more general.",
            "They don't have to be conditional distributions in from a director graph.",
            "They could be derived from some undirected graph or any factorization.",
            "Any any situation in which the joint probability distribution over all the variables factorizes, and that's all the factor graph is expressing.",
            "So those factors may have interpretations as conditional distributions, but they may be something else as well.",
            "Is that any other questions?"
        ],
        [
            "OK, so there remains then the issue of computing this message efficiently.",
            "Well, let's look at that message again.",
            "We can do the same thing.",
            "We can reorder the sums and products.",
            "And again, we can interpret.",
            "This quantity now is he is a message from a variable node to factor node.",
            "So if I just go back a second, this says that to compute the marginal at this node we take the product of the two incoming messages at that that variable node.",
            "Well, this is telling us how to compute the message from a factor node to variable node.",
            "It says take the incoming message from the fact all the other variable nodes into that factor node multiplied together.",
            "Anyone here?",
            "So take that incoming message.",
            "Multiplied by the local factor and do a summation again.",
            "This is a K dimensional vector.",
            "This little K by K matrix and there are K terms in that sum, so this is order K squared again.",
            "So we have a case where operation before and I've got another order K squared operation today."
        ],
        [
            "Again, we can take this message and we can reorder it and interpret that as other messages.",
            "So this says that the message that's outgoing from this variable node.",
            "This factor node is just the product of the incoming messages on the other from the other factor nodes, and you'll be seeing a lot more of this.",
            "I think in Tom inkers talk where he talks about various methods for doing inference on graphs using local message passing.",
            "So.",
            "Each of these is a little quadratic operation, and the number of them is just going to grow linearly with the size of the graph.",
            "So now if I make the graph bigger, the computational cost now grows linearly instead of exponentially, so that's a big computational saving.",
            "So you mentioned that you are only using some end product rules, so that kind of property also holds arbitrary ring.",
            "Really, that these I would only relies on the fact that you needed some end product satisfies distributivity conditions and nothing else.",
            "So you can apply to arbitrary structures.",
            "Yes, I mean, it applies to all sorts, gives you insight into the fast Fourier transform and all sorts of other.",
            "Yes, it's a very, very general.",
            "Exploitation of factorization?",
            "Yeah, so it's more general than just machine learning for sure.",
            "Yeah.",
            "The other.",
            "Questions.",
            "Yeah.",
            "If you look at the first expression, the long expression, we could have seen that you know from basics and rules of something that we could extract all the sums on front.",
            "Why do you need a factor graph which is don't see the advantage of my gender factor graph?",
            "You don't.",
            "You can do everything by with a big page of mathematics, right?",
            "So the advantage of the graphs I think we're the ones I described earlier, so the function graph generally is in designing the model in structuring the model and in helping us to set out the calculation.",
            "So yes, I mean you.",
            "You know?",
            "You could just manipulate the mathematics, but by seeing, expressing it as a graph and expresses local message passing, it just makes it a heck of a lot easier to understand the calculations to derive them and to set them out in code.",
            "In principle, you don't ever need to draw the diagram.",
            "There's a wonderful story.",
            "I think I can tell this 'cause the very very smart guy called Steffen Lauritzen who wrote a very famous book or graphical models.",
            "It's quite a theoretical book and somebody know called Joe Whitaker also works in this field.",
            "Was center a draft of this of this book from Stephen.",
            "A draft of the book on graphical models and he read through the draft and wrote back to Steven Stephens.",
            "Quite theoretical sort of guy and he said, you know, Steven, this is a great book on graphical model is fantastic.",
            "It's really going to be a classic.",
            "There's one thing you could do that would improve it and make it easier for the reader, which is to add a few pictures.",
            "So you don't need the graphs, but for the for me and I think for many people they're enormously beneficial.",
            "Many of these factorizations do you still have that direction.",
            "I don't see the direction anymore.",
            "Yes, you can still include directionality.",
            "Factor graphs are going to discuss any of this zuben, so underlying of course, if underlying this was a director graph, then that directionality is still present.",
            "Nothing here.",
            "Specifies anything about any underlying directionality, though, so this is quite general, so this includes.",
            "So I guess I guess what you've lost actually is the following.",
            "If you have two nodes that pointed another know that's gotta head to head knows these two nodes pointing at this node.",
            "Then you have certain conditional independence property.",
            "These guys are independent when you observe this, they become dependent.",
            "That's the explaining away and I guess you lose that when you just express this as a factor.",
            "So on the factor graph you can't see that independence property, but on the original director graph you can.",
            "Any other questions?",
            "OK, so the other property here is.",
            "This was all exact, So what we've actually done here is inference, which is not any linear in the size of the graph at his optimal efficient, but a couple of other, but it's also exact.",
            "And also if you think about it for a moment, let me just go back to the original graph.",
            "To compute this marginal, we sent messages all the way in from the outside to compute that marginal.",
            "If now you said well, now we want this marginal, you do the same thing.",
            "You send messages in from the outside all the way into that node.",
            "But actually all of those messages will be the messages you've already computed.",
            "And in fact, if you let's say you pick a node and you send a message out called at the root, send a message out to all the leaves and then send a message in the leaves back to the roots of each link has had every possible message been sent once in each direction across each link.",
            "Then you have all the messages you need to compute all the marginals on every variable, and if you want the marginal factor, you just take the product of the incoming messages to that factor so it's exact and by just using twice as much computation you can get all the marginals in the graph.",
            "So wonderful stuff."
        ],
        [
            "It does depend on the graph being a tree, though that discussion breaks down if there are loops.",
            "And what do you do if the graph is not a tree?",
            "Well, you can just apply the message passing anyway, this is called loopy belief propagation, and it's rather ad hoc.",
            "Procedure, but it turns out that it works extremely well and it also turns out that it's equivalent to some other techniques.",
            "I don't know if David even be talking about this in your favor.",
            "Will tell you a lot more about why this is actually turns out to be a really, really good thing to do."
        ],
        [
            "The other thing that can go wrong is the marginalization's might not be tractable there.",
            "We just had little summations, but if you have continuous variables and we need to do integrations, we may not be able to do those in closed form.",
            "So what can we do if the marginalization's are not tractable?",
            "So in general, then we've got some complicated distribution and we want to compute marginals and to make predictions using that distribution.",
            "It's not tractable.",
            "Or can we do about it?",
            "One thing we can do about it is Monte Carlo.",
            "We can draw samples from the distribution and we have various going to hold talks about Monte Carlo techniques today and tomorrow I think.",
            "And Monte Carlo techniques are wonderful for couple of reasons.",
            "First of all, they're extremely general.",
            "You can apply into very, very wide range of distributions and also in some sense there there exactly as they would be exact if you had an infinitely powerful computer.",
            "So.",
            "The main limitation that I think is that they can be computationally costly, so scaling up to large datasets can prove to be problematic, so we wanted color methods have a lot of advantages.",
            "The thing that I'm quite excited about it sort of complementary set of techniques which are based on analytical approximations and make use of local message passing on graphs.",
            "I've illustrated that schematically here in Monte Carlo we draw samples which are distributed according to the true posterior distribution.",
            "In these other techniques we approximate.",
            "The the true distribution in red with some family of similar distributions we've shown schematically in green and then we explore that family of distributions to find the Member which is the best representation of the true distribution.",
            "In some sense we have to define mean by the best or the closest match.",
            "There's a whole bunch of these variational message passing, loopy belief propagation of already mentioned expectation propagation and many others very active field of research.",
            "The disadvantage here is that we can only ever find an approximation.",
            "So if we are approximating this complicated distribution by Gaussian, but we can only ever find a Gaussian representation.",
            "On the other hand, it could be very efficient and can scale to large datasets as I'll show you in a minute, and Tom Minka is going to give two whole lectures."
        ],
        [
            "That topic.",
            "So let me give you an illustration.",
            "Of this framework in action.",
            "So this is the problem of ranking and we can think of this in terms of concrete example.",
            "Think of chess.",
            "So imagine that were all members of a chess club and we're going to play games of chess against each other.",
            "So we get together in pairs.",
            "We play a game of chess and one person wins or the other person wins, or it's a draw.",
            "And from all those little pairwise results we want to drop a League table want to put everybody in the room in a sort of big leave.",
            "The example from the best down to the worst at playing chess.",
            "So it's a partial ranking problem.",
            "We have lots of partial rankings.",
            "One person is better than other.",
            "We want to construct the global ranking, but also it's noisy becausw a weaker player will sometimes be to stronger player, and if the strengths are very similar, there's a good chance that they will win.",
            "If there's a big discrepancy in strength, it's very unlikely the weaker player will be to very much stronger player, so that's the goal.",
            "There's a standard approach is called E Lo named after the inventor, and it's used for example in chess or worldwide.",
            "In the worldwide convention in chess is to use E Lo, and it maintains a single strength for each player.",
            "So every chess player in the world has their ELO rating.",
            "They have a number 120 or something.",
            "And what happens in Halo is that, let's say you're 130.",
            "I'm 120.",
            "We play a game chess.",
            "Let's say I managed to win, then my scores increased a little bit and your scores decreased a little bit, and then we often play the next game.",
            "And there are some other limitations as well.",
            "Below.",
            "Can't handle team games."
        ],
        [
            "Can't handle more than two players.",
            "You could, you can invent all sorts of schemes you know, but if you derive the low that if you want a more principled approach then below.",
            "Ito doesn't handle team games, yeah?",
            "OK.",
            "Either can be thought of as a maximum likelihood technique.",
            "I'm describing Bayesian techniques, so in a sense it's a computerized and special case of this, and what I'm going to describe will handle team games.",
            "So this is a generalization of realtime games is one way of thinking of it.",
            "OK, so how does this work?",
            "Let's consider two players, player one player 2 and these players have a strength, so the strength is unknown, so we'll give it a distribution and will make this a Gaussian distribution.",
            "So each player has a prior distribution prior Gaussian distribution of their strength values.",
            "Now they get together and they play a game of chess, and once you use two other variables, which is the performance those apply the performance of player on the performance of Player 2.",
            "On this particular game of chess.",
            "And whichever player has the higher performance will be the winner.",
            "Now the performance is a noisy version of the skill, so this is to allow for the fact that a weaker player can sometimes beat a stronger player.",
            "So this plot shows the performance of player one and the performance of Player 2.",
            "The dotted line shows the skill value, so if this is the skill of player one, this is the skill of player 2.",
            "The performance is again Gaussians or Gaussian.",
            "Noise model is a Gaussian distribution.",
            "In this 2 dimensional space centered on the skill values of the two players.",
            "Now points which the performance of player one is greater than the pump supplier too.",
            "That's the blue region that those are.",
            "The regions where player one wins.",
            "So in this case the strength of Player 2 is actually higher than player one, and so you can see that less than half the probability mass is in this region, so it's more likely that the stronger player will win.",
            "But there is some probability that the weaker player will win, so the observation the observed variable that player one is the winner is just the indicator function, it just set, it's just one in this region.",
            "And zero in that region.",
            "So the effect of multiplying by the factor associated with that observation is to set everything out here to 0.",
            "So observing the result of this game takes this Gaussian distribution and takes a slice through it and sets everything on one side to 0.",
            "So it's a Gaussian with one side cut off and taken away."
        ],
        [
            "What happens if we have teams?",
            "Well, here we have the red team and the blue team.",
            "So now we have a team performance and now the teams play each other and there's a result.",
            "And we have to model how the team performance depends upon the skills of the two players.",
            "So here's a simple example.",
            "In this case, again, it's a Gaussian.",
            "The performance is has some Gaussian distribution.",
            "But it's centered now in this case, on the some of these skills, so that should be S 1 + S two.",
            "So that's the sum of the skills.",
            "That's a game in which the performance of the team is dependent on the some of the skills of the players.",
            "There might be other examples if it's a race and its first past the finishing line that it might be the Max of skills for exam."
        ],
        [
            "And we can have multiple teams.",
            "So again, very easy to express this graphically.",
            "Alright, so that's all directed graph, so let's take that."
        ],
        [
            "To graph and turn it into a factor graph.",
            "So these are the Gaussian prior distributions over the skills, and these are those ranking likelihood factors that we saw in that color diagram earlier.",
            "Those sort of truncated Gaussians.",
            "So now we can apply message passing.",
            "In this case we use expectation propagation and we start by passing messages from these factors, then here.",
            "And at this point we run into.",
            "A problem becausw if we kept the exact factors every time we start off with some giant Gaussian distribution in the 100 dimensional space of the 100 chess players.",
            "But every time we get a game, we keep taking slices out of this.",
            "And after a while it becomes a very complex distribution, very hard to deal with, very hard to compute marginals for players and so on.",
            "So what we're doing in expectation propagation effectively is every time we observe a game outcome.",
            "So we take this Gaussian, we drop a slice off.",
            "We're going to project it back into the space of Gaussian distributions going to find Gaussian distribution which best fits this truncated Gaussian.",
            "And that's done by minimizing something called a kullback Leibler divergent, and the end result of doing that is very simple.",
            "It says that you match the moments of the distribution."
        ],
        [
            "So this is an example from some real data from a game played on a games console and the red and the Blue show two players out of this data set of several hundred players, and on the bottom is the number of games they've played, so you'll see this is over the course of several 100 games.",
            "And this is what happens with the low.",
            "So this is their skill level and you can see as they play games.",
            "Their skill level involves and for these two particular players their skill levels actually been increasing as a result of playing games, or obviously winning quite a lot of games.",
            "This is what happens in the Trueskill system.",
            "The Bayesian ranking system is that it converges very much more quickly about an order of magnitude more quickly, and the intuition for this is the following.",
            "Let's go back to our example.",
            "Yeah, 130 hundred 20 inilah what happens is a little rule which says that if I'm the winner, my score increases a little bit.",
            "Yours decreases a little bit.",
            "But in in the Bayesian approach we have two variables for every person.",
            "We have a mean and variance.",
            "So let's suppose I'm I'm 120, but I'm I'm quite new.",
            "I haven't played many games as a huge uncertainty in my in my skill level, so I'm 120 plus or minus 20 or something.",
            "We don't really know very much about my skill level.",
            "Let's say you've been playing along time, your 1:30, but we've got you nailed down pretty tightly now.",
            "130 plus or minus one.",
            "If I beat you, then kind of in one step.",
            "We could increase my skill up to about 129 'cause we know that I've beaten somebody.",
            "His skill is very definitely up here, so by having the uncertainty as well as the mean, it allows us, when appropriate, to make very big changes.",
            "Which is something we can't do if we just have a single score for each player.",
            "And of course, that all just follows automatically from the rules of probability, we don't have to put that in as some sort of ad hoc factor that just happens when we do the probabilistic inference.",
            "So result is that the we can get good estimates of skill factors in about an order of magnitude fewer games than."
        ],
        [
            "With the low.",
            "And.",
            "We can now extend the model, yeah?",
            "Isn't that an artifact from the very smooth after scheme of the losses that would have a more aggressive update scheme like multiplying something then could not approach also quite fast at home and performance.",
            "We have innovation promote value, estimating the variance you can.",
            "You can certainly make bigger updates if you wish, but then the problem is that those.",
            "The problem is with the big updates.",
            "These systems start or select yes.",
            "I mean, you want to principle approach that's going to do the right thing and you don't know how big to make those updates because you don't have that uncertainty.",
            "So you can make more aggressive updates, but now you won't.",
            "You run the risk of having an unstable.",
            "An unstable system.",
            "Because you don't always want to make a big update, right?",
            "And if our variance is worth very large, there isn't actually much evidence.",
            "If we've got very large, variances are strongly overlapping.",
            "There isn't much evidence make big changes to the means of those distributions.",
            "Correctly, that the eventual feed of the system is our below is that we keep two variables mean like kind of mean and variance and This is why in the lower we we keep just mean.",
            "So that's why we have.",
            "So let's keep that as a key difference.",
            "Yeah, that was a question.",
            "Function keys and this key is constantly clear, but this kid is obviously changing is great.",
            "That's my next view graph.",
            "Great question.",
            "There was another question.",
            "Buy one when you put all the old skills into a vector.",
            "This is basically estimating the mean and diagonal covariance for the augmented vector.",
            "When when the problem is posed like this, do you know whether the problem is solvable when the covariance form is something different than the diagonal itself, we are assuming all the players are independent from each other.",
            "All the signals are independent, but you know when.",
            "Any applications of clicking the make queries other than that?",
            "Sure.",
            "I mean, if you want to introduce if you don't want that.",
            "If you don't want that diagonal assumption, then you effectively putting extra links into the graph.",
            "But now you're dealing with computationally more complex problem.",
            "Yeah, I guess my glib answer is you design the graph and then you run the inference algorithm.",
            "So effectively you're asking to make fewer independent assumptions and therefore to add more links to the graph.",
            "What's up, yeah?",
            "Can you do expectation propagation using Russian distributions to function normally?",
            "Yes, understanding of when that would work well.",
            "Great questions, so when is EP going to work well and when it won't can I redirect that to Tom Minka?",
            "He invented EP and he can talk a lot about situations in which.",
            "I thought I know he's going to discuss that issue in great length as well, because in some situations yes, multimodality P will not work well and use variational message passing instead of the whole suite of these possible algorithms, you need to choose the right one, so I'll leave time to talk about that.",
            "'cause that's really his lecture.",
            "Any other questions?",
            "Alright, so I had a question.",
            "What about skill evolving through time?",
            "So the other thing that can happen?",
            "So what I've described so far is we assume that everybody has a fixed but unknown skill.",
            "What happens, of course, is that if you play lots and lots of chess, your skill improves.",
            "So again we can capture that by just drawing the right graph.",
            "So here's a graph which says players one and two have met and they've had a game and we've got a game outcome.",
            "An hour later they're going to meet and have another game, but in the meantime their skill may have evolved.",
            "So here's a very simple model.",
            "It just says that their skill is just undergoing a sort of Gaussian diffusion, so it says the skill the next time is a Gaussian distribution centered on the skill at the previous time.",
            "And then off we go.",
            "I mean, you need anything more, testing more likely, he just killed them to lose your skills.",
            "Yes.",
            "Not what you really want to shirt.",
            "Well, if you want to skew that distribution, then by all means you go ahead and you put in a skewed distribution.",
            "That's that's great.",
            "Yeah, if you believe if you believe skills should increase steadily with time, I don't know.",
            "My skills have definitely decreased over the years.",
            "Age age should be another variable.",
            "Yep."
        ],
        [
            "I'm OK and the other thing I want to mention about this is that this isn't just an academic study, but it's also been used on online for well since since 2005 where it's processing, these figures are quite out of date actually, so it's really processing millions of game outcomes per day worldwide, 24 hours a day, seven days a week.",
            "So this is a represents an enormous application of Bayesian methods are very large scale application of Bayesian methods, which I don't think we could have contemplated doing.",
            "You know 10 years ago we didn't have this machinery available to do this fast large scale inference.",
            "So is one of the reasons why I think this is a very exciting time for machine learning because the quantity of data in the world is doubling every nine months, is it or something so we live in a world with that's increasingly data rich.",
            "And now we have tools to do inference on very large datasets, so things are exciting juncture.",
            "Actually, I mentioned.",
            "I'll also mention just to prove this wasn't sort of a one off flash in the pan.",
            "There's now another application, again of exactly the same kind of tools.",
            "This time it's to do with selecting advertisements in search.",
            "You'll know about Google.",
            "Well, actually there may not realize this.",
            "There are other search engines are not quite as popular as certain a certain company based in Seattle has one of them.",
            "And just like Google is trying to monitor is paying for it with adverts and so the problem is to pick the pick the right adverts.",
            "You don't bug the user with adverts that are irrelevant, 'cause that's just annoying.",
            "You want to show a few adverts as you can, but ones which the user will actually click on.",
            "So there's a very important inference problem to workout which adverts to show which adverts you should be showing to the user.",
            "And again that's a real time Online Planet scale application involving huge datasets and again also went live a few months ago and now all of the all of the advertisements served up by.",
            "By this particular company on its search engine or all.",
            "Chosen using this method and the performance improvement over the previous method was was enormous, so it's been hugely beneficial in a very."
        ],
        [
            "Single sense.",
            "The thing I want to mention.",
            "Our tools I've talked about this this wonderful framework of graphical models and fast, efficient local message passing algorithms.",
            "So let me mention the work of Jaune win.",
            "This was his PhD work and this was a system called Vibe.",
            "So this is an academic study rather than a fully functional toolkit.",
            "What he did was to say, well, let's really embrace this graphical framework and let's build an inference engine which start by allowing you to draw a graph.",
            "So what you get is a sort of drawing package an by pointing and clicking.",
            "You can construct the graph and this is some some kind of mixture of factor analyzer, some Bayesian mixture factor analyzers.",
            "Each of these nodes available these.",
            "I think you can see these plates here, so this will be the number of data points, and this is the dimensionality of the data space, and I guess that's the number of components in the mixture.",
            "This is the dimensionality of the latent continuous latent space.",
            "We've highlighted one of the nodes here, so we can give it a name.",
            "We can choose what distribution it has this case it's a gamma distribution set its parameters.",
            "This don't know.",
            "This is the observed data.",
            "So tell it where on your hard disk the data lives and you kind of press the go button and it takes the graph and from the graph it compiles into the code and then it executes the code and returns runs variational message passing and returns marginals for those for those variables.",
            "So all that happened automatically starting from the graph and ending up with the solution.",
            "So this avoids the priority.",
            "To this, if you wanted to do you want to apply this framework you first order.",
            "I've all the all the update equations or the variational update equations and then you have to code them all up in in Matlab or whatever.",
            "Both very time consuming steps and both rather error prone.",
            "So this was a nice example of how you could actually."
        ],
        [
            "Automate that.",
            "And.",
            "That was one of the inspirations for more sort of industrial strength.",
            "Very general framework and inference engine called infer.net which supports a will increasingly support a variety of different inference algorithms and many different classes of distribution, and provides very efficient inference and you'll be hearing more.",
            "I think about this a little bit later in the summer school and the beat of this was launched with NIPS last December, so you can download this and try this out for yourselves.",
            "I."
        ],
        [
            "Show me show you a little demonstration."
        ],
        [
            "So I'll show you a little demonstration of info.net.",
            "This is a toy problem you don't need info.net to do this problem, it's just a toy atory problem.",
            "This was put together by John Guiver, one of the developers working on info.net and he put this together in space of few hours and most of the time was spent designing all the graphics and the actual inference code was extremely quick to assemble.",
            "So imagine we've got a drug and we're going to sort of drug trial to see how effective the drug is an.",
            "We've also got a placebo so the people on the top row.",
            "I'm going to give the drug and the people on the bottom row are going to be given the SIBO, and we'd like to know things like if you've got this disease and you take the drug, what's the probability of being cured if you take the procedure?",
            "Watch the probability of being cured would also like to know is the drug doing any good?",
            "Is the drug distinguishable from the placebo in a statistical sense?",
            "So this is a probability scale up here.",
            "They're the same down here they're different and we've just initialized to .5.",
            "So what we can do now in this little demo is we can imagine a bunch of people have taken.",
            "The drug and these are people who've been cured and these are the people who are not cured and over.",
            "Here is the probability distribution over the uncertain value in the probability of being cured.",
            "And you can see as more people get cured it shifts to the right and fewer people get cured and it shifts to the left and the more data we have the narrow it becomes.",
            "And all this inference is all nicely running in real time, and then we can have a placebo, so we can.",
            "Get people to perceive or maybe the procedure isn't working quite so well as the drug.",
            "And sure enough, it tells us that it's almost certain, not quite, but there's a high probability that the drug and the pasivo are acting differently, and the more data we collect, the more sure we can be about that sort of conclusion.",
            "So.",
            "What's going on in that model?",
            "So what we've got is a binary variable which is says whether the drug and the placebo are different.",
            "And then we have another graphical instructions or gates.",
            "I'm sure Tom will be telling you about Gates, but you can think of this as just if if this, this difference variable is true, we select the left half and if it's false, we're going to select the right half.",
            "So let's suppose first of all it's true.",
            "In other words, the drug dealer procedure different than our model is going to be that we have two probabilities.",
            "The probability that you'll be cured if you're treated with the drug, and the probability that you'll be cured if you're treated with the SIBO.",
            "They can be different 'cause these are different.",
            "These are acting differently and now we have some people and each person is given either the drug or the placebo.",
            "So those are those are people and whether you're cured or not, the people who take the drug have a probability of being cured, so they governed by this variable.",
            "So they're connected to this variable, and similarly for the people who take the pasivo.",
            "There probably being cured is governed by this variable.",
            "On the other hand, if this variable is false, then the drug and the pasivo are acting in the same way, so we just have a single probability for being cured that governs all of these observations.",
            "Now we go and collect or data, so we shade in the nodes.",
            "These three people were cured and those people weren't and so now we can run inference and we can pass along messages around this graph and eventually we can compute posterior probabilities for these for these various variables.",
            "And So what you saw on the left hand side of the demo was this variable on the right hand side.",
            "Little histograms for these two and there was just wasn't space to show that one.",
            "But you could imagine what that looked like.",
            "OK, so with the two minutes to go 'cause it was, good luck, wasn't it?",
            "Elements I think for any other questions, yeah.",
            "Bayesian methods have caught on in, say, clinical trials.",
            "I'm a bit worried about the prospect of my health being in the hands of treatments.",
            "Very wise.",
            "Like he passes or whatever for it for deciding whether a drug is actually know, the answer is the answer is no, not at all, and so it's often necessary to take the outputs of the Bayesian model and to express them in in terms of you know, false discovery rates and things that are understood by that community.",
            "So I think there are sort of in parallel with the process of education and enlightenment.",
            "There's also a need, I think, to sort of translate results into a language that's.",
            "Palatable to that to that world.",
            "I actually had quite a similar questions.",
            "If you had this slide on the left side for saying and different so the question is how would you then for example, for medical paper quantify the difference difference between exterior distribution?",
            "So if I ever frequented that would now take the posterior company key value reported and um, so how would you?",
            "How would you do that in an isolation way?",
            "Well, I don't understand the question because that is my answer.",
            "That is my probability.",
            "Of the two being different, and what I now need to do of course, is to take some.",
            "Noted on this slide are on the left side, we just jumped different and the same.",
            "Was that just different in the mean?",
            "All this this is just.",
            "There was a binary variable which if it was true, said these distributions are different.",
            "If it's false, said they were the same and this is the posterior probability of that variable being true.",
            "Given that I guess is upside down.",
            "'cause true is down here, but it's the posterior probability of there being true given given the evidence I have from the data that I've collected.",
            "Is that?",
            "Let me take another question.",
            "Will come back if you're not.",
            "Here's my version so.",
            "I mean looking at those.",
            "One can use it.",
            "So.",
            "Quantified whether there's two distrib.",
            "Just intuitively say something about whether the same difference the sliding scale in relation to Decatur divergent with these two distribution.",
            "There are lots of ways you can solve this problem right, and you could you know all sorts of KL divergences and what I like about this approach is that it's very principled and it's very clear what assumptions you're making.",
            "Make all your assumptions explicit, and then you have fast inference algorithm to compute posterior distributions.",
            "It's not the only way of solving this problem, but it appeals to me because it makes all those assumptions explicit.",
            "And as we had a discussion with the the chest in the ranking example, lots of other things you would think.",
            "So why don't we try better this throw bit of that in?",
            "But then it's not clear what assumptions you're making.",
            "It's not clear when those assumptions are going to breakdown and so on.",
            "So I personally strongly favor this sort of very principled and clear approach.",
            "When you find out when distributions are interactive and upward of.",
            "Samples and found several strategies I could and you have.",
            "Functions is approximately is still non parametric by using a family function underlying distribution.",
            "Everything I've described so far is based on sort of parametric models for those factors, so everything is parametric and there are people looking at how to build the nonparametric factors into these graphs, and I think that's still quite an active research area.",
            "Yeah.",
            "Have maybe time for one.",
            "Yeah.",
            "Crossing from nose to the background and passing back like.",
            "Only two direct messages.",
            "And when I see the graphical model, it looks like a bit like a circuit diagram to me.",
            "They're like conservation of messages along this thing, so there's a question there about the nature of the different messages between variables and factors.",
            "They differ actually between.",
            "Virtual message passing and and EP.",
            "The two sort of main classes.",
            "Our belief propagations like EP in example I showed you was just exact inference, belief propagation the the compute an outgoing message from a variable to factor by multiplying all the incoming messages on that variable and computing outgoing message from factor.",
            "You multiply all the incoming messages by the factor of marginalized.",
            "Compute the outgoing message, VMP turns out to be to be slightly different but.",
            "You're going to get two 290 minute lectures on this stuff from Tom, so I think rather than trying to anticipate Toms talk, perhaps will apps or leave it there and encourage you to listen to Tom Tom Store.",
            "I think Zubin will show we wrap up there.",
            "Just got past.",
            "Yeah alright OK, thanks very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK well good morning and very warm.",
                    "label": 0
                },
                {
                    "sent": "Welcome to Cambridge on this typically sunny day.",
                    "label": 0
                },
                {
                    "sent": "Not the note from in here.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "OK, just kind of here I guess.",
                    "label": 0
                },
                {
                    "sent": "So because this is the first talk of the summer school, I thought I'd do something slightly different.",
                    "label": 0
                },
                {
                    "sent": "Instead of trying to teach a lot of technical detail, which I think you'll get from a lot of the later talks, I thought I'd give you a sort of a personal perspective on where I think we are in the field of machine learning, and in particular I've come to believe that the next 10 years or so are going to be the most exciting in the entire history of the field of machine learning because we have some very exciting new techniques which allow us to address a whole class of new kinds of applications.",
                    "label": 0
                },
                {
                    "sent": "So that's really what I want to talk about.",
                    "label": 0
                },
                {
                    "sent": "In this first talk, and it's very much a personal perspective.",
                    "label": 0
                },
                {
                    "sent": "And of course other lecturers may have other views on this as well.",
                    "label": 0
                },
                {
                    "sent": "Let me begin, though, with perhaps most important slide.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That you'll see, which is this one which is to encourage you to ask questions and to make the summer school interactive.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to be standing here for two lots of 90 minutes that you're going to be sat there for 20 lots of 90 minutes or something.",
                    "label": 0
                },
                {
                    "sent": "It's it's a long 2 weeks and you will get a lot more out of it if we if we make it interactive.",
                    "label": 0
                },
                {
                    "sent": "So please just interrupt and ask questions as we go through.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Almost as important as this slide, which is just to mention that I'll be taking material.",
                    "label": 0
                },
                {
                    "sent": "Typically the second talk from this textbook and there's a copy here if you if you'd like to take.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look so I'm going to characterize what I think is happening in the field of machine learning as a sort of 3rd generation of machine learning, and so I better explain my terminology by telling you what I mean by by the 1st and 2nd generations, or really the 1st and 2nd generators of machine intelligence I guess.",
                    "label": 0
                },
                {
                    "sent": "So what I call the 1st generation is good old fashioned AI, artificial intelligence and there's a nice quote here from Minsky from 1967.",
                    "label": 0
                },
                {
                    "sent": "Within a generation.",
                    "label": 0
                },
                {
                    "sent": "The problem of creating artificial intelligence will largely be solved and two years later anybody recognize this.",
                    "label": 1
                },
                {
                    "sent": "Who knows what this is?",
                    "label": 0
                },
                {
                    "sent": "How yes, great this is from the film 2001, so this was I think released in 1968 or there about the same error and it depicted that by the year 2000 would have their super intelligent computer and you can have a conversation that philosophy within all sorts of things.",
                    "label": 0
                },
                {
                    "sent": "And the sort of Canonical first generation technique was the expert system based on knowledge extracted from humans.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Had a number of successes, and indeed even today there are some problems where if you want to solve those problems, an expert system is going to be the best way to go.",
                    "label": 0
                },
                {
                    "sent": "But in most applications, the technique of expert system suffered from this combinatorial explosion.",
                    "label": 0
                },
                {
                    "sent": "There were lots of rules.",
                    "label": 0
                },
                {
                    "sent": "There are exceptions to the rules, exceptions to the exceptions, and so on, and so by and large expert systems failed to deliver on Minsky's vision, so I'll characterize this first generation as handcrafted rules.",
                    "label": 0
                },
                {
                    "sent": "Everything is built out of rules extracted from humans.",
                    "label": 0
                },
                {
                    "sent": "They may be probabilistic rules, but they're all hand.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Crafted so we call the second generation is characterized by things that neural network, support vector machines and then you proved to be much more successful in terms of applications.",
                    "label": 0
                },
                {
                    "sent": "So here's an example, handwriting recognition, and there are thousands of other applications now of these techniques, and again, even today they remain extremely valuable from a practical perspective.",
                    "label": 0
                },
                {
                    "sent": "One of the difficulties though, is that incorporating what I call complex domain knowledge, and I'm going to give you examples of this as we go through.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I'll characterize the second generation as black box statistical models.",
                    "label": 1
                },
                {
                    "sent": "The emphasis very much is on learning from data.",
                    "label": 0
                },
                {
                    "sent": "Any prior knowledge that's built in is a rather general nature like continuity or maybe some translation invariants or something, but it's hard to build in this rich.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Domain knowledge.",
                    "label": 0
                },
                {
                    "sent": "So the thing that I'm very excited about is what I'm going to call third generation machine intelligence that's characterized by.",
                    "label": 0
                },
                {
                    "sent": "A deep integration of rich domain knowledge combined with statistical learning.",
                    "label": 1
                },
                {
                    "sent": "And that's really the sort of theme of this of this first talk.",
                    "label": 0
                },
                {
                    "sent": "So there are three ingredients to this framework.",
                    "label": 0
                },
                {
                    "sent": "The first is that it's based on a Bayesian approach.",
                    "label": 1
                },
                {
                    "sent": "The second is that it makes use of probabilistic graphical models in order to describe the approach to the problem.",
                    "label": 0
                },
                {
                    "sent": "The modeling of the problem, and it makes use of fast inference techniques which are based on passing local messages around these graphs in order to find tractable solutions, and in a way which is very efficient and scale to very large datasets.",
                    "label": 0
                },
                {
                    "sent": "Although we call it third generation, these ideas have their origins going back a very long way in all sorts of fields like statistical physics and electrical engineering, signal processing, and so on.",
                    "label": 0
                },
                {
                    "sent": "So these sort of generations of innocence grown up in parallel.",
                    "label": 0
                },
                {
                    "sent": "But this, I think, is for me, one of the sort of it's very exciting frontiers of machine learning right now.",
                    "label": 0
                },
                {
                    "sent": "OK, let's just begin then with talking a little bit about those three things.",
                    "label": 0
                },
                {
                    "sent": "In turn, I'm just going to skim lightly over these topics, and you'll be familiar with some of them, perhaps others less so.",
                    "label": 0
                },
                {
                    "sent": "But later talks will drill down into more detail.",
                    "label": 0
                },
                {
                    "sent": "I want to give you a flavor for these different topics, and hopefully at least sort of motivate you to be excited about them and to listen to the details in the later lectures.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this should start with a little problem from probabilities, which is which is the following.",
                    "label": 0
                },
                {
                    "sent": "You've got a red box in the blue box and inside each box we've got some apples and oranges depicted by some rather basic graphics I'm afraid.",
                    "label": 0
                },
                {
                    "sent": "But on the left box we've got six oranges and two apples in the right box.",
                    "label": 0
                },
                {
                    "sent": "We've got three apples and one orange, and will imagine a process by which somebody picks one of these boxes at random with some probability, and then reaches into the box and selects a piece of fruit again at random with equal probability of choosing any of those pieces of fruit.",
                    "label": 0
                },
                {
                    "sent": "And we can ask the following question.",
                    "label": 0
                },
                {
                    "sent": "Suppose that we don't know which box was chosen, but we do know that the piece of fruits was an orange.",
                    "label": 0
                },
                {
                    "sent": "We can ask, what's the probability that the box was blue?",
                    "label": 1
                },
                {
                    "sent": "So we're actually doing here is typical of what we're doing in machine learning problems.",
                    "label": 0
                },
                {
                    "sent": "We're sort of going in the opposite direction to the physical process.",
                    "label": 0
                },
                {
                    "sent": "The physical process is you first will choose the box, and then you choose the piece of fruit, and we want to sort of reverse that process.",
                    "label": 0
                },
                {
                    "sent": "We know the piece of fruit, so we want to infer the probability that we chose the blue box.",
                    "label": 0
                },
                {
                    "sent": "So of course we do that using the.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The rules of probability and it's very beautiful theory because it just described by these two simple rules.",
                    "label": 1
                },
                {
                    "sent": "So really most of what we're going to be talking about is just the consistent application of these.",
                    "label": 0
                },
                {
                    "sent": "These two very simple rules.",
                    "label": 0
                },
                {
                    "sent": "Does anybody why don't you let me take a minute to derive these rules of probability, or anybody everybody very happy with these.",
                    "label": 0
                },
                {
                    "sent": "I imagine from the applicants we have at this summer school that everybody is very comfortable with these OK and probabilities of course satisfy the probability of the properties of being negative.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And something to one.",
                    "label": 0
                },
                {
                    "sent": "And from the from the sumrell.",
                    "label": 0
                },
                {
                    "sent": "From the product rule of probability, we can write the conditional probability of Y given X in terms of the ratio of the joint to the marginal, and we can write the joint as the product of the conditional and the other marginal.",
                    "label": 0
                },
                {
                    "sent": "Which gives us Bayes theorem.",
                    "label": 0
                },
                {
                    "sent": "So base here and provides a way of.",
                    "label": 0
                },
                {
                    "sent": "Evaluating the conditional probability of Y given X in terms of the reverse conditional P of X given Y and from the product in some rule, we can express the denominator in Bayes theorem in terms of a summation over the terms which appear in the numerator.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we look at our apples and oranges, then and let's suppose that the probability of choosing the red box is 2/5.",
                    "label": 1
                },
                {
                    "sent": "So it's more likely that we choose the blue box than the red box.",
                    "label": 0
                },
                {
                    "sent": "And we somebody shows in the box.",
                    "label": 0
                },
                {
                    "sent": "We don't know which one they've chosen a piece of fruit, and it's an orange.",
                    "label": 1
                },
                {
                    "sent": "We first of all, compute the denominator and Bayes theorem, which is the probability that the fruit was orange.",
                    "label": 0
                },
                {
                    "sent": "So that's probably that fruit is orange.",
                    "label": 0
                },
                {
                    "sent": "Given that the box is red, well, that's just the fraction of pieces of fruit in the box, which are oranges times the probability that the box was red, which is 2/5, and then similarly for this term.",
                    "label": 0
                },
                {
                    "sent": "In this case, the probability of the box is blue, it's just 1 -- 3/5.",
                    "label": 0
                },
                {
                    "sent": "It comes out to be 9 twentieths.",
                    "label": 0
                },
                {
                    "sent": "And then we use base theorem to compute the probability that the box is red given that the fruit was an orange and that comes out to be 2/3, which is bigger than 1/2.",
                    "label": 0
                },
                {
                    "sent": "So sort of accord with our intuition observing that the piece of fruit is an orange is some evidence that steers more towards the red box than the blue box, because the proportion of oranges is higher in the red box.",
                    "label": 0
                },
                {
                    "sent": "That is, in the blue box.",
                    "label": 0
                },
                {
                    "sent": "OK, everybody comfortable with that only.",
                    "label": 0
                },
                {
                    "sent": "Any questions I'm sure that's all.",
                    "label": 0
                },
                {
                    "sent": "Why did I pick 2/5?",
                    "label": 0
                },
                {
                    "sent": "It's just a tutorial example, so I just wanted to choose, well, I choose the ace of the numbers.",
                    "label": 0
                },
                {
                    "sent": "Cannot simply an.",
                    "label": 0
                },
                {
                    "sent": "Also because this is this is less than 1/2, so it's saying that a priority the IT was more likely that it shows the blue box.",
                    "label": 0
                },
                {
                    "sent": "But once I saw the piece of fruit was an orange and now becomes more likely that in fact it was a red box, so that's slightly bigger than 1/2 after that, so.",
                    "label": 0
                },
                {
                    "sent": "There's nothing, nothing deeper.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Serious about these numbers.",
                    "label": 0
                },
                {
                    "sent": "And of course, we can also talk about probabilities with respect to continuous variables.",
                    "label": 0
                },
                {
                    "sent": "So X is a continuous variable.",
                    "label": 0
                },
                {
                    "sent": "We can define a probability density shown by the red curve P of X.",
                    "label": 0
                },
                {
                    "sent": "So the probability that X will lie in this little interval of width Delta X is just equal to that the area which is the product of Delta X times the height of this curve.",
                    "label": 0
                },
                {
                    "sent": "And so the probability that X will lie within an interval A to B is the integral of the density over that interval.",
                    "label": 0
                },
                {
                    "sent": "And if we integrate from minus Infinity up to a point zed of that density, we get something called the cumulative probability which is shown in that blue curve there.",
                    "label": 0
                },
                {
                    "sent": "So it starts at 0 on the left and ends up at 1:00 on the right.",
                    "label": 0
                },
                {
                    "sent": "And again these are non negative.",
                    "label": 0
                },
                {
                    "sent": "In this case the probability dense.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See integrates to one.",
                    "label": 0
                },
                {
                    "sent": "So Bayesian inference, this is what the first of those three ingredients in this sort of 3rd generation framework that I'm talking about and.",
                    "label": 0
                },
                {
                    "sent": "The idea of Bayesian inference is really a consistent use of probability to quantify uncertainty, so this is extending probabilities beyond the notion of frequencies of repeatable events and using probability theory anywhere that we have uncertainty.",
                    "label": 1
                },
                {
                    "sent": "So if Theta is a quantity of interest and X represents all the things that we know about theater so far, let's say all the data that we've collected and other information we have, then we describe.",
                    "label": 0
                },
                {
                    "sent": "Our uncertainty on over theater by this conditional probability P. Theater, given all the things we know so far summarized by X.",
                    "label": 0
                },
                {
                    "sent": "And we'll call that the prior probability.",
                    "label": 0
                },
                {
                    "sent": "And if we observe some new data X hat, then we can absorb the evidence from X hat by computing this quantity, which is the likelihood function, and we think of this as a function over Theta.",
                    "label": 0
                },
                {
                    "sent": "So as PX given Theta.",
                    "label": 0
                },
                {
                    "sent": "In which XX hat is set to the observed value and we look at this as a function of Theta, so evaluated for all values theater, we multiply that by the prior and up to normalization constant we get the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "So that's using Bayes theorem to absorb the effect of that new evidence.",
                    "label": 0
                },
                {
                    "sent": "So we've gone from the distribution before we observed X at the distribution after we observed X hat, and we'll see lots of examples of that as we go through.",
                    "label": 0
                },
                {
                    "sent": "And the other important idea is that to make predictions we marginalise.",
                    "label": 0
                },
                {
                    "sent": "So in this simple case we wish to predict a quantity Y, and we'll assume that the Y depends on X only through theater.",
                    "label": 0
                },
                {
                    "sent": "So once we know Theta P of Y doesn't depend on X and so from the sum and product rules we want to predict P of Y given X, and that's obtained by taking P of Y given Theta.",
                    "label": 0
                },
                {
                    "sent": "You need to give an X and marginalizing, so I'm making predictions using each and every possible value for Theta.",
                    "label": 0
                },
                {
                    "sent": "But they waited by the current distribution current posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "And the other thing about this, of course, is that this is now effectively, if we observe yet more information.",
                    "label": 0
                },
                {
                    "sent": "This is now our prior for the next application of Bayes theorem.",
                    "label": 0
                },
                {
                    "sent": "So Bayesian inference is intrinsically a sequential process.",
                    "label": 0
                },
                {
                    "sent": "As you observe more information, compute the new new likelihood function multiplied by the current distribution, which is the prior to get the new distribution, which is the posterior.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why is prior knowledge important?",
                    "label": 1
                },
                {
                    "sent": "So I said the interesting thing about the third generation framework is that we can incorporate rich prior knowledge into our machine learning models.",
                    "label": 0
                },
                {
                    "sent": "So why is prior knowledge important?",
                    "label": 0
                },
                {
                    "sent": "So little cartoon sketch of why it might be important.",
                    "label": 0
                },
                {
                    "sent": "So here's a variable X in the variable Y and we have collected some data which pairs of values of X&Y and we want to make a prediction.",
                    "label": 0
                },
                {
                    "sent": "We want to know what value is why I'm going to take for this new value of X that's not been observed previously.",
                    "label": 0
                },
                {
                    "sent": "And as things stand, it's actually quite quite hard to know what we should say about why.",
                    "label": 0
                },
                {
                    "sent": "So not clear what value we should choose.",
                    "label": 0
                },
                {
                    "sent": "But if I tell you that the values of Y were generated from the values of X by a straight line with some Gaussian noise added, and I tell you the variance of that noise.",
                    "label": 0
                },
                {
                    "sent": "So I give you a lot of prior knowledge about the way that data was generated.",
                    "label": 0
                },
                {
                    "sent": "You then, in a much better position to make predictions about the value of Y, and in fact of course without any prior knowledge you can't really say anything.",
                    "label": 0
                },
                {
                    "sent": "There are many, many different ways in which why it could have been generated from X is a huge range of possibilities, and the more prior knowledge you have, the more constrained that range of possibilities, and therefore the better the predictions you can make.",
                    "label": 0
                },
                {
                    "sent": "So actually prior knowledge is very central to machine learning.",
                    "label": 0
                },
                {
                    "sent": "You can't really learn anything just from data alone.",
                    "label": 0
                },
                {
                    "sent": "So graphical models can put your hand up if you already use graphical models in your research.",
                    "label": 0
                },
                {
                    "sent": "Guessing about half but over half.",
                    "label": 0
                },
                {
                    "sent": "OK, great, So what I'm going to do is to, as I said, skim lightly over the topic of graphical models and try to motivate them.",
                    "label": 0
                },
                {
                    "sent": "Zubin is going to give two entire talks on the details of graphical models.",
                    "label": 0
                },
                {
                    "sent": "So I shall just give a brief introduction for those of you who are not already.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Leave the field.",
                    "label": 0
                },
                {
                    "sent": "So the idea of graphical models is to take probability theory.",
                    "label": 1
                },
                {
                    "sent": "In other words, the sum and product rule of probability, and to combine them with some diagrams and pictures some graphs.",
                    "label": 0
                },
                {
                    "sent": "This brings lots of nice benefits.",
                    "label": 0
                },
                {
                    "sent": "It gives us insights into existing models, models which are already just specified mathematically.",
                    "label": 1
                },
                {
                    "sent": "We can now see them pictorially and that allows us to understand well for most of us, certainly for me allows us to understand the structure of the models much more clearly.",
                    "label": 0
                },
                {
                    "sent": "Many, many people, myself included, find it much easier to look at a picture and see the structure than to look at a big page of mathematics.",
                    "label": 0
                },
                {
                    "sent": "But also provides a framework for designing new models.",
                    "label": 1
                },
                {
                    "sent": "Once we see the structure of the model graphically, we can alter the model if we wish by adding links to the graph or removing links or adding new nodes and so on.",
                    "label": 0
                },
                {
                    "sent": "So we can design our model by designing the diagram.",
                    "label": 0
                },
                {
                    "sent": "But it's actually much better than that, because we can also do calculations using using the diagrams we can do things like read off conditional independence properties simply by looking at separation properties directly on the graph.",
                    "label": 0
                },
                {
                    "sent": "We could get the same results by grinding through pages of mathematics using the sum and product rule, but it's just much easier to look at the picture and read the results off directly.",
                    "label": 1
                },
                {
                    "sent": "I guess a little bit like my background is physics and physics or these things.",
                    "label": 0
                },
                {
                    "sent": "Will Feynman diagrams are doing perturbation expansions in field theory and essentially you could do everything without the diagrams, but the diagrams help you set out the calculations are very ordered way and avoid repeating lots of same calculations over and over again, and so that makes the calculations very easy and efficient.",
                    "label": 0
                },
                {
                    "sent": "And on such efficiency the diagrams also lead to efficient software implementation.",
                    "label": 0
                },
                {
                    "sent": "So we have algorithms for doing inference and learning on the graphs and you'll see these are expressed in terms of message passing algorithms.",
                    "label": 0
                },
                {
                    "sent": "We can express them in terms of sending little messages around on the graph, doing lots of local calculations, and we can build software that reflects that structure, and that software will be very efficient.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to mention two kinds of graphs I think is even made mention others.",
                    "label": 0
                },
                {
                    "sent": "I'm gonna talk about the use of directed graphs in order to design the model and then having designed the model, we can turn it into a different kind of graph called a factor graph, which is convenient for doing inference and learning using.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Model.",
                    "label": 0
                },
                {
                    "sent": "Sort of, these graphs all about, well, let's start with an arbitrary distribution of the three variables XY&Z and if we apply the product rule twice.",
                    "label": 1
                },
                {
                    "sent": "We can write this symmetrical distribution.",
                    "label": 0
                },
                {
                    "sent": "It's rather non symmetric way as a product of a distribution of each of the three variables XY&Z conditioned on other variables.",
                    "label": 0
                },
                {
                    "sent": "So to do this we've chosen a particular ordering of those variables.",
                    "label": 0
                },
                {
                    "sent": "We cannot represent that biograf.",
                    "label": 0
                },
                {
                    "sent": "So each of these variables is represented by a circle in the graph.",
                    "label": 0
                },
                {
                    "sent": "And the relationships between the variables are described by links between the between the circles or between the nodes.",
                    "label": 0
                },
                {
                    "sent": "And these links carry arrows.",
                    "label": 0
                },
                {
                    "sent": "That's why this is for directed graph.",
                    "label": 0
                },
                {
                    "sent": "And the interpretation of the graph is that it specifies the way in which the joint distribution decomposes into this product of conditionals.",
                    "label": 0
                },
                {
                    "sent": "In particular, there's one factor for each variable, and the conditioning variables are the parents in the graph.",
                    "label": 0
                },
                {
                    "sent": "So if there's an arrow from X to Y, then X is said to be the parents of Y.",
                    "label": 0
                },
                {
                    "sent": "So this graph says the joint distribution of XY and Z decomposes into P of X given its parents.",
                    "label": 0
                },
                {
                    "sent": "Well, it doesn't have any parents.",
                    "label": 0
                },
                {
                    "sent": "P of Y given its parents, it has one parent which is X&P of Z given its parents, which are X&Y.",
                    "label": 0
                },
                {
                    "sent": "So that graph is equivalent to that decomposition.",
                    "label": 0
                },
                {
                    "sent": "And we have a rule about these graphs.",
                    "label": 0
                },
                {
                    "sent": "In order for this to to work properly, there must be directed cycles.",
                    "label": 0
                },
                {
                    "sent": "That is, if you follow any loops in the graph, it must never be the case that you can go round and loop following the direction of the arrows, just related to this ordering of the variables.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a directed graph.",
                    "label": 0
                },
                {
                    "sent": "More generally, has the property that there are missing links and it's the absence of links in the graph that really conveys information.",
                    "label": 0
                },
                {
                    "sent": "So in this example, this is any distribution of the three variables is described by this graph.",
                    "label": 0
                },
                {
                    "sent": "This graph is fully connected.",
                    "label": 0
                },
                {
                    "sent": "Every variable is connected to every other.",
                    "label": 0
                },
                {
                    "sent": "Once we start emitting links.",
                    "label": 0
                },
                {
                    "sent": "So here's a graph of a 7.",
                    "label": 0
                },
                {
                    "sent": "Variables were not every potential link is present.",
                    "label": 0
                },
                {
                    "sent": "Links are missing.",
                    "label": 0
                },
                {
                    "sent": "There was missing links tell us about independence properties and.",
                    "label": 0
                },
                {
                    "sent": "This graph with missing links therefore describes a more restricted family of distributions.",
                    "label": 0
                },
                {
                    "sent": "Therefore, encode some specific knowledge, because instead of looking at all possible distributions, it's looking at a narrow family of distributions.",
                    "label": 0
                },
                {
                    "sent": "So we can write down the factorization specified by that graph in the same way as before.",
                    "label": 0
                },
                {
                    "sent": "So seven variables with seven nodes for each variable, and so the joint distribution is the product of a conditional one for each variable, and each conditional is conditioned on its parents.",
                    "label": 0
                },
                {
                    "sent": "So P of X1 to X7 is written as the product of X1.",
                    "label": 0
                },
                {
                    "sent": "Given its parents, there aren't any similar X2 and X3P of X4 given its parents.",
                    "label": 0
                },
                {
                    "sent": "The parents of X4 or X1X2X3 have X.",
                    "label": 0
                },
                {
                    "sent": "Well given X one X2X3 and so on for the remaining factors.",
                    "label": 0
                },
                {
                    "sent": "And notice I haven't said whether these are continuous variables or discrete variables, or whether they are Gaussian, distributed or gamma distributed or whatever.",
                    "label": 0
                },
                {
                    "sent": "This is really describing a whole family of distributions, but a family of distributions that have certain independence properties.",
                    "label": 0
                },
                {
                    "sent": "So we can use directed graphs to specify models and to capture prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "And the other thing that I won't dwell on too long, but the direction of the arrows can be thought of as representing causality.",
                    "label": 0
                },
                {
                    "sent": "So if we think of our little boxes of fruit example, we can first of all we in the physical process in the physical world as we first of all, choose a box, then having chosen a box reach inside, we choose a piece of fruit, and that's the sort of ordering relationship we have in the physical process.",
                    "label": 0
                },
                {
                    "sent": "But a machine learning we want to go in the opposite direction.",
                    "label": 0
                },
                {
                    "sent": "We observe the piece of the identity of the piece of fruit.",
                    "label": 0
                },
                {
                    "sent": "We want to infer which box it came from.",
                    "label": 0
                },
                {
                    "sent": "And so that's typically true of these graphs, and you see examples later.",
                    "label": 0
                },
                {
                    "sent": "The arrow specified the directions of causal physical process in the world, and then we typically observe nodes down here.",
                    "label": 0
                },
                {
                    "sent": "We want to infer posterior distributions of nodes higher in the graph.",
                    "label": 0
                },
                {
                    "sent": "Yes, question.",
                    "label": 0
                },
                {
                    "sent": "Relationship can be include time, information, yes, and you'll see examples of temporal or she'll show you some examples later.",
                    "label": 0
                },
                {
                    "sent": "Actually, we have time information.",
                    "label": 0
                },
                {
                    "sent": "Yeah, great.",
                    "label": 0
                },
                {
                    "sent": "I love questions.",
                    "label": 0
                },
                {
                    "sent": "More questions.",
                    "label": 0
                },
                {
                    "sent": "Independence.",
                    "label": 0
                },
                {
                    "sent": "Necessarily.",
                    "label": 0
                },
                {
                    "sent": "Yes, indeed there are other kinds of graphs that don't that there are undirected graph, for example that don't specify sort of soft relationships between variables without giving them the status of 1 being the cause of another.",
                    "label": 0
                },
                {
                    "sent": "And also we might introduce variables that don't necessarily have an interpretation in the physical world they run observed variables that are there as part of the modeling process, and we don't necessarily.",
                    "label": 0
                },
                {
                    "sent": "We may or may not wish to interpret those as being some actual piece of physics in the real world.",
                    "label": 0
                },
                {
                    "sent": "Directed models you can also destroy another bad, which is which is the same independence relationships.",
                    "label": 0
                },
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "Right, so so we're opening up a big discussion there about can we learn causality from the real world?",
                    "label": 0
                },
                {
                    "sent": "So can we.",
                    "label": 0
                },
                {
                    "sent": "Can we discover whether smoking causes cancer by observing correlations between people who smoke also tend to have cancer?",
                    "label": 0
                },
                {
                    "sent": "Because we can't directly infer a causal relationship.",
                    "label": 0
                },
                {
                    "sent": "There could be some common cause that causes people to want to smoke and gives them cancer, and the difference is really the interventions.",
                    "label": 0
                },
                {
                    "sent": "If you stop smoking, are you less likely to get cancer or not?",
                    "label": 0
                },
                {
                    "sent": "And if you make an intervention, then you can discover that causal relationship, but from correlation alone, you can't.",
                    "label": 0
                },
                {
                    "sent": "So the big field of research do with discovering causality from statistical data and graphical directed graphs are one of the tools that are used in that field.",
                    "label": 0
                },
                {
                    "sent": "I think maybe.",
                    "label": 0
                },
                {
                    "sent": "Referencing arrows indicate causal relationships that you say when you design your graphics and inspired from portal relationship to decide the direction of the arrow.",
                    "label": 1
                },
                {
                    "sent": "But then the representation itself doesn't really indicate collaboration, because often there's there's a big would you put out power in any direction, absolutely.",
                    "label": 0
                },
                {
                    "sent": "So if you have three variables, these variables might be physical processors, and it might be the X causes Y&X&Y together cause Ed and so express your model in terms of that graph.",
                    "label": 0
                },
                {
                    "sent": "But you're quite right.",
                    "label": 0
                },
                {
                    "sent": "A Markov equivalent graph.",
                    "label": 0
                },
                {
                    "sent": "We could reverse the direction of one of those arrows and have all the same statistical properties and be completely equivalent.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much any other.",
                    "label": 0
                },
                {
                    "sent": "Any other questions or?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Points of clarification.",
                    "label": 0
                },
                {
                    "sent": "OK, let me give you an example.",
                    "label": 0
                },
                {
                    "sent": "Then this is called the Manchester Aspirin Allergy Study and the goal is to discover fundamentally discover the environmental and genetic causes of childhood asthma which is an amazing proportion of children suffer from asthma.",
                    "label": 1
                },
                {
                    "sent": "It's a huge a major disease in the Western world.",
                    "label": 1
                },
                {
                    "sent": "This study is a birth cohort study just over 1000 children monitored since they were born and we recently collected genetic information.",
                    "label": 0
                },
                {
                    "sent": "For for each of the children in the study and alongside the genetic information, we also have.",
                    "label": 1
                },
                {
                    "sent": "Over the years we've collected or the study has collected very, very detailed, clean, carefully collected environmental and physiological measurements.",
                    "label": 0
                },
                {
                    "sent": "For example, skin tests to determine allergic sensitivity.",
                    "label": 0
                },
                {
                    "sent": "Blood tests that measure similar allergic sensitivity notes on whether the child was wheezing or not.",
                    "label": 0
                },
                {
                    "sent": "A methacholine response.",
                    "label": 0
                },
                {
                    "sent": "The child breeze in a little bit of a substance which induces an artificial asthma attack, and you measure how much of this stuff they have.",
                    "label": 0
                },
                {
                    "sent": "Breathe in before they show symptoms of asthma, so these children go through a lot to contribute to this study and the measured at ages 135 and eight.",
                    "label": 0
                },
                {
                    "sent": "So we have data through time and lots of other background information about whether their parents smoked and whether they have very petzen.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "So this is this is not a director graphical model yet.",
                    "label": 0
                },
                {
                    "sent": "This is a sort of block diagram that begins to capture some of the prior knowledge which the clinicians have about the nature of asthma and the things which affect it.",
                    "label": 0
                },
                {
                    "sent": "And you may not be able to read from the back.",
                    "label": 0
                },
                {
                    "sent": "The details are not important.",
                    "label": 0
                },
                {
                    "sent": "The point is, there are lots of different factors here and they connect to each other and fairly specific ways.",
                    "label": 0
                },
                {
                    "sent": "So we have asthma, some here in the middle.",
                    "label": 0
                },
                {
                    "sent": "We don't actually observe that directly.",
                    "label": 0
                },
                {
                    "sent": "What we observe the symptoms of it.",
                    "label": 0
                },
                {
                    "sent": "Things like wheezing and so on, and the three major routes to causing asthma.",
                    "label": 0
                },
                {
                    "sent": "Inflammation of the Airways.",
                    "label": 0
                },
                {
                    "sent": "The overall strength of the airway system measured by or the maximum attainable lung functions.",
                    "label": 0
                },
                {
                    "sent": "It's called, and the bronchial hyperresponsiveness how twitchy the system is.",
                    "label": 0
                },
                {
                    "sent": "How rapidly the bronchial system responds to external stimuli, such as allergens.",
                    "label": 0
                },
                {
                    "sent": "And over here this is the part of the graph which describes allergic response.",
                    "label": 0
                },
                {
                    "sent": "Here we have a box labeled genome, but of course the genetic the genetics points and all sorts of aspects on this graph.",
                    "label": 0
                },
                {
                    "sent": "This diagram itself is not even completed, just a partial picture.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to do is take one little piece of this diagram and expand it up and turn it into a directed graph.",
                    "label": 0
                },
                {
                    "sent": "But the point of this is to show that.",
                    "label": 0
                },
                {
                    "sent": "Here's an example where we're not simply looking for correlations between genetic variability and a binary disease label asthma.",
                    "label": 0
                },
                {
                    "sent": "Not asthma the the real world is much more complex as well as being many genes that affect asthma.",
                    "label": 0
                },
                {
                    "sent": "There are many environmental factors.",
                    "label": 0
                },
                {
                    "sent": "But rather than just throw them into a big black box statistical model, what we're doing here is capturing all the clinical prior knowledge that we have about the way the variables affect one another.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's just take a little piece of this and turn this into a directed graph.",
                    "label": 0
                },
                {
                    "sent": "So here are the nodes on the graph.",
                    "label": 0
                },
                {
                    "sent": "Here are the arrows.",
                    "label": 0
                },
                {
                    "sent": "This is a.",
                    "label": 0
                },
                {
                    "sent": "This is a binary variable which says whether or not the child has acquired sensitization to a particular allergen at age 1 and then simply for age 3, five and eight.",
                    "label": 0
                },
                {
                    "sent": "So each of these is a binary variable.",
                    "label": 0
                },
                {
                    "sent": "These boxes are called plates.",
                    "label": 0
                },
                {
                    "sent": "These just mean that what's inside the plate gets replicated a certain number of times, so this is a plate for the children, so down here it says children 1186.",
                    "label": 0
                },
                {
                    "sent": "Everything inside here is copied for every child.",
                    "label": 0
                },
                {
                    "sent": "Every child has a copy of this variable.",
                    "label": 0
                },
                {
                    "sent": "This plate is a plate for allergens, of which there are eight mice, cat, dog, egg, milk, peanut and so on, and so everything inside this plate is replicated 8 times.",
                    "label": 0
                },
                {
                    "sent": "So each child has eight variables to do with whether they acquired sensitization age 1 to each of the eight allergens.",
                    "label": 0
                },
                {
                    "sent": "And this is correct.",
                    "label": 0
                },
                {
                    "sent": "Another question.",
                    "label": 0
                },
                {
                    "sent": "This is an example of a directed graph showing.",
                    "label": 0
                },
                {
                    "sent": "Variables evolving through time, so we are assuming in this model that these variables form a Markov chain, so the sensitization age 5 depends directly on the sensitization age 3, but it's not depend directly on the sensitization at age 1.",
                    "label": 0
                },
                {
                    "sent": "Now these are all things we don't deserve.",
                    "label": 0
                },
                {
                    "sent": "We don't, yeah.",
                    "label": 0
                },
                {
                    "sent": "Between the different allergies.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "We yes, yes, these are.",
                    "label": 0
                },
                {
                    "sent": "These are independent.",
                    "label": 0
                },
                {
                    "sent": "I mean they won't process a posteriori.",
                    "label": 0
                },
                {
                    "sent": "They won't be independent.",
                    "label": 0
                },
                {
                    "sent": "But yes, we are, so we're making all sorts of assumptions here and the beauty of graphical models is those assumptions are very made very explicit in the graph.",
                    "label": 0
                },
                {
                    "sent": "So you can just look at the diagram and see what assumptions you're making.",
                    "label": 0
                },
                {
                    "sent": "If you don't like the assumptions, if you'd like to have some dependence, if you think sensitisation age 5 should pen directly on sensitization age one, you can just add in an extra link to your graph.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "I don't have the same CPU.",
                    "label": 0
                },
                {
                    "sent": "I'll come to that in a minute.",
                    "label": 0
                },
                {
                    "sent": "The question is whether these share the same probabilities or not OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We don't deserve these directly.",
                    "label": 0
                },
                {
                    "sent": "What we actually observe.",
                    "label": 0
                },
                {
                    "sent": "The results of skin tests.",
                    "label": 0
                },
                {
                    "sent": "So the child is given a skin prick with these different allergens, cat and peanut, and so on, and see whether the skin goes red.",
                    "label": 0
                },
                {
                    "sent": "So we have that data and then related to some immunoglobulin E blood tests where you look for a marker in the blood which says that this child is become sensitized to peanut or whatever and these are measured at age 1, three, five and eight.",
                    "label": 0
                },
                {
                    "sent": "So in graphical models, when we observe a variable be shade in the node, so these nodes.",
                    "label": 0
                },
                {
                    "sent": "Are the observations for each child and for each allergen.",
                    "label": 0
                },
                {
                    "sent": "And now the probability of acquiring.",
                    "label": 0
                },
                {
                    "sent": "Sensitization at age 3.",
                    "label": 0
                },
                {
                    "sent": "Given your sensitize at age 1 is some variable, and I'll come to that in it, this is the probability of having a positive skin test today three given their sensitized age 3 is some variable and that's described.",
                    "label": 0
                },
                {
                    "sent": "That's described down here.",
                    "label": 0
                },
                {
                    "sent": "So this is the probability of a positive skin test given they were sensitized and the probability of positive skin testing that we're not sensitized and then similarly for the blood tests.",
                    "label": 0
                },
                {
                    "sent": "So these are variables and these are shared.",
                    "label": 0
                },
                {
                    "sent": "Across.",
                    "label": 0
                },
                {
                    "sent": "All of all of the.",
                    "label": 0
                },
                {
                    "sent": "Halogens, and across all of the children and across the different ages.",
                    "label": 0
                },
                {
                    "sent": "But they needn't be.",
                    "label": 0
                },
                {
                    "sent": "And we explored lots of different variants.",
                    "label": 0
                },
                {
                    "sent": "So if you want to allow different set of variables for each allergen, you simply take these nodes and drag them inside the plate and then you get a separate variable for each allergen.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also have variables governing the initial probability of sensitization at each at age 1, and then these transition probabilities.",
                    "label": 0
                },
                {
                    "sent": "The probability of being sensitized age 3 given that sensitize at age 1 and.",
                    "label": 0
                },
                {
                    "sent": "So there's a described by these yellow variables, so these all have prior distributions and then finally we introduce a sensitisation class.",
                    "label": 0
                },
                {
                    "sent": "So this is another unobserved variable which has, let's say 5 States and its switches between different choices for these probabilities.",
                    "label": 0
                },
                {
                    "sent": "And there's a separate variable foreach children for each child, or 1000 of these variables.",
                    "label": 0
                },
                {
                    "sent": "So what this is doing is unsupervised clustering.",
                    "label": 0
                },
                {
                    "sent": "Because when we observe, this data will have a posterior distribution over these classes for each child, and so effectively we're softly clustering the children into however many groups it isn't.",
                    "label": 0
                },
                {
                    "sent": "So let's say five were softly clustering the children into five groups.",
                    "label": 0
                },
                {
                    "sent": "Other things we discover with this model is that within these classes, these soft classes are much stronger indicators of asthma than the raw observed asthma label that's assigned by the GP in the doctors surgery, and so that's a much better variable.",
                    "label": 0
                },
                {
                    "sent": "To look for correlations with genetic variability than the simply the presence or absence of asthma.",
                    "label": 0
                },
                {
                    "sent": "So the point here is that we are capturing lots of prior knowledge, expressing it as a graph and the structure of the graph tells us about the assumptions we're making.",
                    "label": 0
                },
                {
                    "sent": "For example on whether these parameters are shared through time or across children or whatever.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's directed graphs for designing the model.",
                    "label": 0
                },
                {
                    "sent": "Now we want to do inference on the graph, and for that it's convenient to turn the graph into a different kind of graph, called a factor graph.",
                    "label": 0
                },
                {
                    "sent": "You'll be learning a lot more about these later.",
                    "label": 0
                },
                {
                    "sent": "The idea is fairly simple, so again, let's consider three variables X one X2X3.",
                    "label": 0
                },
                {
                    "sent": "We have a separate node for each variable.",
                    "label": 0
                },
                {
                    "sent": "And we also have some square nodes which describe the factors.",
                    "label": 0
                },
                {
                    "sent": "So the joint distribution again factorizes into a product of factors, and each factor depends on some subset of the variables.",
                    "label": 0
                },
                {
                    "sent": "So the links show the variables that each factor depends on.",
                    "label": 0
                },
                {
                    "sent": "So in this case there are four factors and factor FA depends only on X1 and X2.",
                    "label": 0
                },
                {
                    "sent": "There are links from FA to X1 and 2X2.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, given a directed graph, we can then very easily turn it into a factor graph, so here's a directed graph of a three variables.",
                    "label": 1
                },
                {
                    "sent": "Here's its factorization of X1, P of X 2 * P of X3.",
                    "label": 0
                },
                {
                    "sent": "Given X one X2.",
                    "label": 0
                },
                {
                    "sent": "And we can just turn that directly into a factor graph with three factors.",
                    "label": 0
                },
                {
                    "sent": "And then by inspection we can read off these three factors.",
                    "label": 0
                },
                {
                    "sent": "The first factor P of X1, the second factor.",
                    "label": 0
                },
                {
                    "sent": "We have X2 and the third factor is P of X3.",
                    "label": 0
                },
                {
                    "sent": "Given X one X2 so FC which depends on the variables X one X2 and X3 is connected to those corresponding nodes in the graph.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a factor graph.",
                    "label": 0
                },
                {
                    "sent": "Much more of that later in Zubrin's talks.",
                    "label": 0
                },
                {
                    "sent": "So let's look at how we do inference on graphs.",
                    "label": 0
                },
                {
                    "sent": "And here's the key idea, really.",
                    "label": 0
                },
                {
                    "sent": "The expression on the right hand side is algebraically equivalent to the expression on the left hand side, but on the left hand side to evaluate the left hand side we have to perform three operations, two multiplications and additions.",
                    "label": 0
                },
                {
                    "sent": "So three numerical operations to evaluate the left hand side.",
                    "label": 0
                },
                {
                    "sent": "So computationally the right hand side is not equivalent to the left hand side, because what we've done is to exploit the factorization we've pulled out as a factor and now to evaluate the right hand side, we need 1 addition and one multiplication, so by using the right hand expression.",
                    "label": 0
                },
                {
                    "sent": "We can evaluate this quantity computationally more efficiently than by using the left hand side, and in so doing we exploited the factorization of expr.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And on the left.",
                    "label": 0
                },
                {
                    "sent": "So that's the idea that we're going to apply, so let's apply that.",
                    "label": 0
                },
                {
                    "sent": "Now to factor graph.",
                    "label": 0
                },
                {
                    "sent": "Is a factor graph with five variables.",
                    "label": 0
                },
                {
                    "sent": "VWXY&Z and four factors.",
                    "label": 0
                },
                {
                    "sent": "So the factor graph tells us that the joint distribution factorizes into the product of these factors and it's these factors each of them actually depends on a pair of variables.",
                    "label": 0
                },
                {
                    "sent": "So in terms of the potential links which there could be in this graph, many many links are missing for very simple graph.",
                    "label": 0
                },
                {
                    "sent": "Actually is just a tree structured graph, no loops.",
                    "label": 0
                },
                {
                    "sent": "So let's ask the following question.",
                    "label": 0
                },
                {
                    "sent": "Let's ask for the marginal of this particular variable W. Let's compute that well from the sum rule of probability to compute the marginal for W, we take the joint distribution and we sum out the other four variables.",
                    "label": 0
                },
                {
                    "sent": "So this is the computation that we have to perform.",
                    "label": 0
                },
                {
                    "sent": "Now we perform that computation directly.",
                    "label": 0
                },
                {
                    "sent": "Let's see how expensive that would be.",
                    "label": 0
                },
                {
                    "sent": "Well, these are discrete variables, and the first thing we have to do is to compute this quantity.",
                    "label": 0
                },
                {
                    "sent": "So if we imagine that these were each variable had K different states K different values that it could take, then we would have this big table of.",
                    "label": 0
                },
                {
                    "sent": "Of the five variables or 5 dimensional occasion, the power 5th table, it would have to compute and they would have to do K to the power four sums in order to get this K dimensional vector at the end.",
                    "label": 0
                },
                {
                    "sent": "The module that we're after, and if we increase the graph in size, you can see that the amount of storage we need, more computation would need to do in that naive approach would grow exponentially with the size of the graph.",
                    "label": 0
                },
                {
                    "sent": "But instead we can exploit the factorization by making use of the fact that these factors only depend on a small number of variables.",
                    "label": 0
                },
                {
                    "sent": "So in particular.",
                    "label": 0
                },
                {
                    "sent": "For looking at the marginal for W, we can notice that the variable V appears only in this factor here, so we can pull that out as a common factor and do the summation over V separately from the remaining summations.",
                    "label": 0
                },
                {
                    "sent": "And so this is numerically algebraically equivalent, but numerical numerically computationally is more efficient.",
                    "label": 0
                },
                {
                    "sent": "Another elegant thing we can do here is to express this in terms of local messages on the graph.",
                    "label": 0
                },
                {
                    "sent": "So this quantity is some function of W and will think of this as a message that's sent from this factor node to this variable node called F1 to W. So function of W. And similarly this remaining object will think of this as a message that sent from here to here.",
                    "label": 0
                },
                {
                    "sent": "So each of these are sort of K dimensional vector.",
                    "label": 0
                },
                {
                    "sent": "And to compute the marginal we simply have to multiply them pointwise together.",
                    "label": 0
                },
                {
                    "sent": "So that's an order K operation.",
                    "label": 0
                },
                {
                    "sent": "And computing this involves a little K by K matrix.",
                    "label": 0
                },
                {
                    "sent": "That sort of quadratic in K and we have to do K sums for each of the K values of W. So there's a little order K squared calculation to compute that message, so we can do that very efficiently, and then the multiplication again is a little K dimensional multiplication, so again, that's also.",
                    "label": 0
                },
                {
                    "sent": "That's also very efficient.",
                    "label": 0
                },
                {
                    "sent": "So if we compute this message efficiently, we could do the whole thing in quadratic time instead of exponential time.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Well then.",
                    "label": 0
                },
                {
                    "sent": "So yeah.",
                    "label": 0
                },
                {
                    "sent": "So I started by talking Bout directed graphs and Maps, multifactor graphs in which each factor is one of those conditional distributions.",
                    "label": 0
                },
                {
                    "sent": "But innocence the factor graphs are more general.",
                    "label": 0
                },
                {
                    "sent": "They don't have to be conditional distributions in from a director graph.",
                    "label": 0
                },
                {
                    "sent": "They could be derived from some undirected graph or any factorization.",
                    "label": 0
                },
                {
                    "sent": "Any any situation in which the joint probability distribution over all the variables factorizes, and that's all the factor graph is expressing.",
                    "label": 0
                },
                {
                    "sent": "So those factors may have interpretations as conditional distributions, but they may be something else as well.",
                    "label": 0
                },
                {
                    "sent": "Is that any other questions?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so there remains then the issue of computing this message efficiently.",
                    "label": 0
                },
                {
                    "sent": "Well, let's look at that message again.",
                    "label": 0
                },
                {
                    "sent": "We can do the same thing.",
                    "label": 0
                },
                {
                    "sent": "We can reorder the sums and products.",
                    "label": 0
                },
                {
                    "sent": "And again, we can interpret.",
                    "label": 0
                },
                {
                    "sent": "This quantity now is he is a message from a variable node to factor node.",
                    "label": 0
                },
                {
                    "sent": "So if I just go back a second, this says that to compute the marginal at this node we take the product of the two incoming messages at that that variable node.",
                    "label": 0
                },
                {
                    "sent": "Well, this is telling us how to compute the message from a factor node to variable node.",
                    "label": 0
                },
                {
                    "sent": "It says take the incoming message from the fact all the other variable nodes into that factor node multiplied together.",
                    "label": 0
                },
                {
                    "sent": "Anyone here?",
                    "label": 0
                },
                {
                    "sent": "So take that incoming message.",
                    "label": 0
                },
                {
                    "sent": "Multiplied by the local factor and do a summation again.",
                    "label": 0
                },
                {
                    "sent": "This is a K dimensional vector.",
                    "label": 0
                },
                {
                    "sent": "This little K by K matrix and there are K terms in that sum, so this is order K squared again.",
                    "label": 0
                },
                {
                    "sent": "So we have a case where operation before and I've got another order K squared operation today.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, we can take this message and we can reorder it and interpret that as other messages.",
                    "label": 0
                },
                {
                    "sent": "So this says that the message that's outgoing from this variable node.",
                    "label": 0
                },
                {
                    "sent": "This factor node is just the product of the incoming messages on the other from the other factor nodes, and you'll be seeing a lot more of this.",
                    "label": 0
                },
                {
                    "sent": "I think in Tom inkers talk where he talks about various methods for doing inference on graphs using local message passing.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Each of these is a little quadratic operation, and the number of them is just going to grow linearly with the size of the graph.",
                    "label": 0
                },
                {
                    "sent": "So now if I make the graph bigger, the computational cost now grows linearly instead of exponentially, so that's a big computational saving.",
                    "label": 0
                },
                {
                    "sent": "So you mentioned that you are only using some end product rules, so that kind of property also holds arbitrary ring.",
                    "label": 0
                },
                {
                    "sent": "Really, that these I would only relies on the fact that you needed some end product satisfies distributivity conditions and nothing else.",
                    "label": 0
                },
                {
                    "sent": "So you can apply to arbitrary structures.",
                    "label": 0
                },
                {
                    "sent": "Yes, I mean, it applies to all sorts, gives you insight into the fast Fourier transform and all sorts of other.",
                    "label": 0
                },
                {
                    "sent": "Yes, it's a very, very general.",
                    "label": 0
                },
                {
                    "sent": "Exploitation of factorization?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's more general than just machine learning for sure.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "The other.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "If you look at the first expression, the long expression, we could have seen that you know from basics and rules of something that we could extract all the sums on front.",
                    "label": 0
                },
                {
                    "sent": "Why do you need a factor graph which is don't see the advantage of my gender factor graph?",
                    "label": 0
                },
                {
                    "sent": "You don't.",
                    "label": 0
                },
                {
                    "sent": "You can do everything by with a big page of mathematics, right?",
                    "label": 0
                },
                {
                    "sent": "So the advantage of the graphs I think we're the ones I described earlier, so the function graph generally is in designing the model in structuring the model and in helping us to set out the calculation.",
                    "label": 0
                },
                {
                    "sent": "So yes, I mean you.",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "You could just manipulate the mathematics, but by seeing, expressing it as a graph and expresses local message passing, it just makes it a heck of a lot easier to understand the calculations to derive them and to set them out in code.",
                    "label": 0
                },
                {
                    "sent": "In principle, you don't ever need to draw the diagram.",
                    "label": 0
                },
                {
                    "sent": "There's a wonderful story.",
                    "label": 0
                },
                {
                    "sent": "I think I can tell this 'cause the very very smart guy called Steffen Lauritzen who wrote a very famous book or graphical models.",
                    "label": 0
                },
                {
                    "sent": "It's quite a theoretical book and somebody know called Joe Whitaker also works in this field.",
                    "label": 0
                },
                {
                    "sent": "Was center a draft of this of this book from Stephen.",
                    "label": 0
                },
                {
                    "sent": "A draft of the book on graphical models and he read through the draft and wrote back to Steven Stephens.",
                    "label": 0
                },
                {
                    "sent": "Quite theoretical sort of guy and he said, you know, Steven, this is a great book on graphical model is fantastic.",
                    "label": 0
                },
                {
                    "sent": "It's really going to be a classic.",
                    "label": 0
                },
                {
                    "sent": "There's one thing you could do that would improve it and make it easier for the reader, which is to add a few pictures.",
                    "label": 0
                },
                {
                    "sent": "So you don't need the graphs, but for the for me and I think for many people they're enormously beneficial.",
                    "label": 0
                },
                {
                    "sent": "Many of these factorizations do you still have that direction.",
                    "label": 0
                },
                {
                    "sent": "I don't see the direction anymore.",
                    "label": 0
                },
                {
                    "sent": "Yes, you can still include directionality.",
                    "label": 0
                },
                {
                    "sent": "Factor graphs are going to discuss any of this zuben, so underlying of course, if underlying this was a director graph, then that directionality is still present.",
                    "label": 0
                },
                {
                    "sent": "Nothing here.",
                    "label": 0
                },
                {
                    "sent": "Specifies anything about any underlying directionality, though, so this is quite general, so this includes.",
                    "label": 0
                },
                {
                    "sent": "So I guess I guess what you've lost actually is the following.",
                    "label": 0
                },
                {
                    "sent": "If you have two nodes that pointed another know that's gotta head to head knows these two nodes pointing at this node.",
                    "label": 0
                },
                {
                    "sent": "Then you have certain conditional independence property.",
                    "label": 0
                },
                {
                    "sent": "These guys are independent when you observe this, they become dependent.",
                    "label": 0
                },
                {
                    "sent": "That's the explaining away and I guess you lose that when you just express this as a factor.",
                    "label": 0
                },
                {
                    "sent": "So on the factor graph you can't see that independence property, but on the original director graph you can.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "OK, so the other property here is.",
                    "label": 0
                },
                {
                    "sent": "This was all exact, So what we've actually done here is inference, which is not any linear in the size of the graph at his optimal efficient, but a couple of other, but it's also exact.",
                    "label": 0
                },
                {
                    "sent": "And also if you think about it for a moment, let me just go back to the original graph.",
                    "label": 0
                },
                {
                    "sent": "To compute this marginal, we sent messages all the way in from the outside to compute that marginal.",
                    "label": 0
                },
                {
                    "sent": "If now you said well, now we want this marginal, you do the same thing.",
                    "label": 0
                },
                {
                    "sent": "You send messages in from the outside all the way into that node.",
                    "label": 0
                },
                {
                    "sent": "But actually all of those messages will be the messages you've already computed.",
                    "label": 0
                },
                {
                    "sent": "And in fact, if you let's say you pick a node and you send a message out called at the root, send a message out to all the leaves and then send a message in the leaves back to the roots of each link has had every possible message been sent once in each direction across each link.",
                    "label": 0
                },
                {
                    "sent": "Then you have all the messages you need to compute all the marginals on every variable, and if you want the marginal factor, you just take the product of the incoming messages to that factor so it's exact and by just using twice as much computation you can get all the marginals in the graph.",
                    "label": 0
                },
                {
                    "sent": "So wonderful stuff.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It does depend on the graph being a tree, though that discussion breaks down if there are loops.",
                    "label": 0
                },
                {
                    "sent": "And what do you do if the graph is not a tree?",
                    "label": 1
                },
                {
                    "sent": "Well, you can just apply the message passing anyway, this is called loopy belief propagation, and it's rather ad hoc.",
                    "label": 0
                },
                {
                    "sent": "Procedure, but it turns out that it works extremely well and it also turns out that it's equivalent to some other techniques.",
                    "label": 0
                },
                {
                    "sent": "I don't know if David even be talking about this in your favor.",
                    "label": 0
                },
                {
                    "sent": "Will tell you a lot more about why this is actually turns out to be a really, really good thing to do.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other thing that can go wrong is the marginalization's might not be tractable there.",
                    "label": 0
                },
                {
                    "sent": "We just had little summations, but if you have continuous variables and we need to do integrations, we may not be able to do those in closed form.",
                    "label": 0
                },
                {
                    "sent": "So what can we do if the marginalization's are not tractable?",
                    "label": 1
                },
                {
                    "sent": "So in general, then we've got some complicated distribution and we want to compute marginals and to make predictions using that distribution.",
                    "label": 0
                },
                {
                    "sent": "It's not tractable.",
                    "label": 0
                },
                {
                    "sent": "Or can we do about it?",
                    "label": 1
                },
                {
                    "sent": "One thing we can do about it is Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "We can draw samples from the distribution and we have various going to hold talks about Monte Carlo techniques today and tomorrow I think.",
                    "label": 0
                },
                {
                    "sent": "And Monte Carlo techniques are wonderful for couple of reasons.",
                    "label": 0
                },
                {
                    "sent": "First of all, they're extremely general.",
                    "label": 0
                },
                {
                    "sent": "You can apply into very, very wide range of distributions and also in some sense there there exactly as they would be exact if you had an infinitely powerful computer.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The main limitation that I think is that they can be computationally costly, so scaling up to large datasets can prove to be problematic, so we wanted color methods have a lot of advantages.",
                    "label": 0
                },
                {
                    "sent": "The thing that I'm quite excited about it sort of complementary set of techniques which are based on analytical approximations and make use of local message passing on graphs.",
                    "label": 0
                },
                {
                    "sent": "I've illustrated that schematically here in Monte Carlo we draw samples which are distributed according to the true posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "In these other techniques we approximate.",
                    "label": 0
                },
                {
                    "sent": "The the true distribution in red with some family of similar distributions we've shown schematically in green and then we explore that family of distributions to find the Member which is the best representation of the true distribution.",
                    "label": 0
                },
                {
                    "sent": "In some sense we have to define mean by the best or the closest match.",
                    "label": 0
                },
                {
                    "sent": "There's a whole bunch of these variational message passing, loopy belief propagation of already mentioned expectation propagation and many others very active field of research.",
                    "label": 0
                },
                {
                    "sent": "The disadvantage here is that we can only ever find an approximation.",
                    "label": 0
                },
                {
                    "sent": "So if we are approximating this complicated distribution by Gaussian, but we can only ever find a Gaussian representation.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, it could be very efficient and can scale to large datasets as I'll show you in a minute, and Tom Minka is going to give two whole lectures.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That topic.",
                    "label": 0
                },
                {
                    "sent": "So let me give you an illustration.",
                    "label": 0
                },
                {
                    "sent": "Of this framework in action.",
                    "label": 0
                },
                {
                    "sent": "So this is the problem of ranking and we can think of this in terms of concrete example.",
                    "label": 0
                },
                {
                    "sent": "Think of chess.",
                    "label": 0
                },
                {
                    "sent": "So imagine that were all members of a chess club and we're going to play games of chess against each other.",
                    "label": 0
                },
                {
                    "sent": "So we get together in pairs.",
                    "label": 0
                },
                {
                    "sent": "We play a game of chess and one person wins or the other person wins, or it's a draw.",
                    "label": 0
                },
                {
                    "sent": "And from all those little pairwise results we want to drop a League table want to put everybody in the room in a sort of big leave.",
                    "label": 0
                },
                {
                    "sent": "The example from the best down to the worst at playing chess.",
                    "label": 0
                },
                {
                    "sent": "So it's a partial ranking problem.",
                    "label": 0
                },
                {
                    "sent": "We have lots of partial rankings.",
                    "label": 1
                },
                {
                    "sent": "One person is better than other.",
                    "label": 0
                },
                {
                    "sent": "We want to construct the global ranking, but also it's noisy becausw a weaker player will sometimes be to stronger player, and if the strengths are very similar, there's a good chance that they will win.",
                    "label": 0
                },
                {
                    "sent": "If there's a big discrepancy in strength, it's very unlikely the weaker player will be to very much stronger player, so that's the goal.",
                    "label": 0
                },
                {
                    "sent": "There's a standard approach is called E Lo named after the inventor, and it's used for example in chess or worldwide.",
                    "label": 0
                },
                {
                    "sent": "In the worldwide convention in chess is to use E Lo, and it maintains a single strength for each player.",
                    "label": 1
                },
                {
                    "sent": "So every chess player in the world has their ELO rating.",
                    "label": 0
                },
                {
                    "sent": "They have a number 120 or something.",
                    "label": 0
                },
                {
                    "sent": "And what happens in Halo is that, let's say you're 130.",
                    "label": 0
                },
                {
                    "sent": "I'm 120.",
                    "label": 0
                },
                {
                    "sent": "We play a game chess.",
                    "label": 0
                },
                {
                    "sent": "Let's say I managed to win, then my scores increased a little bit and your scores decreased a little bit, and then we often play the next game.",
                    "label": 0
                },
                {
                    "sent": "And there are some other limitations as well.",
                    "label": 0
                },
                {
                    "sent": "Below.",
                    "label": 0
                },
                {
                    "sent": "Can't handle team games.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can't handle more than two players.",
                    "label": 0
                },
                {
                    "sent": "You could, you can invent all sorts of schemes you know, but if you derive the low that if you want a more principled approach then below.",
                    "label": 0
                },
                {
                    "sent": "Ito doesn't handle team games, yeah?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Either can be thought of as a maximum likelihood technique.",
                    "label": 0
                },
                {
                    "sent": "I'm describing Bayesian techniques, so in a sense it's a computerized and special case of this, and what I'm going to describe will handle team games.",
                    "label": 0
                },
                {
                    "sent": "So this is a generalization of realtime games is one way of thinking of it.",
                    "label": 0
                },
                {
                    "sent": "OK, so how does this work?",
                    "label": 0
                },
                {
                    "sent": "Let's consider two players, player one player 2 and these players have a strength, so the strength is unknown, so we'll give it a distribution and will make this a Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "So each player has a prior distribution prior Gaussian distribution of their strength values.",
                    "label": 0
                },
                {
                    "sent": "Now they get together and they play a game of chess, and once you use two other variables, which is the performance those apply the performance of player on the performance of Player 2.",
                    "label": 0
                },
                {
                    "sent": "On this particular game of chess.",
                    "label": 0
                },
                {
                    "sent": "And whichever player has the higher performance will be the winner.",
                    "label": 0
                },
                {
                    "sent": "Now the performance is a noisy version of the skill, so this is to allow for the fact that a weaker player can sometimes beat a stronger player.",
                    "label": 0
                },
                {
                    "sent": "So this plot shows the performance of player one and the performance of Player 2.",
                    "label": 0
                },
                {
                    "sent": "The dotted line shows the skill value, so if this is the skill of player one, this is the skill of player 2.",
                    "label": 0
                },
                {
                    "sent": "The performance is again Gaussians or Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Noise model is a Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "In this 2 dimensional space centered on the skill values of the two players.",
                    "label": 0
                },
                {
                    "sent": "Now points which the performance of player one is greater than the pump supplier too.",
                    "label": 0
                },
                {
                    "sent": "That's the blue region that those are.",
                    "label": 0
                },
                {
                    "sent": "The regions where player one wins.",
                    "label": 0
                },
                {
                    "sent": "So in this case the strength of Player 2 is actually higher than player one, and so you can see that less than half the probability mass is in this region, so it's more likely that the stronger player will win.",
                    "label": 0
                },
                {
                    "sent": "But there is some probability that the weaker player will win, so the observation the observed variable that player one is the winner is just the indicator function, it just set, it's just one in this region.",
                    "label": 0
                },
                {
                    "sent": "And zero in that region.",
                    "label": 0
                },
                {
                    "sent": "So the effect of multiplying by the factor associated with that observation is to set everything out here to 0.",
                    "label": 0
                },
                {
                    "sent": "So observing the result of this game takes this Gaussian distribution and takes a slice through it and sets everything on one side to 0.",
                    "label": 0
                },
                {
                    "sent": "So it's a Gaussian with one side cut off and taken away.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What happens if we have teams?",
                    "label": 0
                },
                {
                    "sent": "Well, here we have the red team and the blue team.",
                    "label": 0
                },
                {
                    "sent": "So now we have a team performance and now the teams play each other and there's a result.",
                    "label": 0
                },
                {
                    "sent": "And we have to model how the team performance depends upon the skills of the two players.",
                    "label": 0
                },
                {
                    "sent": "So here's a simple example.",
                    "label": 0
                },
                {
                    "sent": "In this case, again, it's a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "The performance is has some Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "But it's centered now in this case, on the some of these skills, so that should be S 1 + S two.",
                    "label": 0
                },
                {
                    "sent": "So that's the sum of the skills.",
                    "label": 0
                },
                {
                    "sent": "That's a game in which the performance of the team is dependent on the some of the skills of the players.",
                    "label": 0
                },
                {
                    "sent": "There might be other examples if it's a race and its first past the finishing line that it might be the Max of skills for exam.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can have multiple teams.",
                    "label": 0
                },
                {
                    "sent": "So again, very easy to express this graphically.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's all directed graph, so let's take that.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To graph and turn it into a factor graph.",
                    "label": 0
                },
                {
                    "sent": "So these are the Gaussian prior distributions over the skills, and these are those ranking likelihood factors that we saw in that color diagram earlier.",
                    "label": 1
                },
                {
                    "sent": "Those sort of truncated Gaussians.",
                    "label": 0
                },
                {
                    "sent": "So now we can apply message passing.",
                    "label": 0
                },
                {
                    "sent": "In this case we use expectation propagation and we start by passing messages from these factors, then here.",
                    "label": 0
                },
                {
                    "sent": "And at this point we run into.",
                    "label": 0
                },
                {
                    "sent": "A problem becausw if we kept the exact factors every time we start off with some giant Gaussian distribution in the 100 dimensional space of the 100 chess players.",
                    "label": 0
                },
                {
                    "sent": "But every time we get a game, we keep taking slices out of this.",
                    "label": 0
                },
                {
                    "sent": "And after a while it becomes a very complex distribution, very hard to deal with, very hard to compute marginals for players and so on.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing in expectation propagation effectively is every time we observe a game outcome.",
                    "label": 0
                },
                {
                    "sent": "So we take this Gaussian, we drop a slice off.",
                    "label": 0
                },
                {
                    "sent": "We're going to project it back into the space of Gaussian distributions going to find Gaussian distribution which best fits this truncated Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And that's done by minimizing something called a kullback Leibler divergent, and the end result of doing that is very simple.",
                    "label": 0
                },
                {
                    "sent": "It says that you match the moments of the distribution.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is an example from some real data from a game played on a games console and the red and the Blue show two players out of this data set of several hundred players, and on the bottom is the number of games they've played, so you'll see this is over the course of several 100 games.",
                    "label": 0
                },
                {
                    "sent": "And this is what happens with the low.",
                    "label": 0
                },
                {
                    "sent": "So this is their skill level and you can see as they play games.",
                    "label": 0
                },
                {
                    "sent": "Their skill level involves and for these two particular players their skill levels actually been increasing as a result of playing games, or obviously winning quite a lot of games.",
                    "label": 0
                },
                {
                    "sent": "This is what happens in the Trueskill system.",
                    "label": 0
                },
                {
                    "sent": "The Bayesian ranking system is that it converges very much more quickly about an order of magnitude more quickly, and the intuition for this is the following.",
                    "label": 0
                },
                {
                    "sent": "Let's go back to our example.",
                    "label": 0
                },
                {
                    "sent": "Yeah, 130 hundred 20 inilah what happens is a little rule which says that if I'm the winner, my score increases a little bit.",
                    "label": 0
                },
                {
                    "sent": "Yours decreases a little bit.",
                    "label": 0
                },
                {
                    "sent": "But in in the Bayesian approach we have two variables for every person.",
                    "label": 0
                },
                {
                    "sent": "We have a mean and variance.",
                    "label": 0
                },
                {
                    "sent": "So let's suppose I'm I'm 120, but I'm I'm quite new.",
                    "label": 0
                },
                {
                    "sent": "I haven't played many games as a huge uncertainty in my in my skill level, so I'm 120 plus or minus 20 or something.",
                    "label": 0
                },
                {
                    "sent": "We don't really know very much about my skill level.",
                    "label": 0
                },
                {
                    "sent": "Let's say you've been playing along time, your 1:30, but we've got you nailed down pretty tightly now.",
                    "label": 0
                },
                {
                    "sent": "130 plus or minus one.",
                    "label": 0
                },
                {
                    "sent": "If I beat you, then kind of in one step.",
                    "label": 0
                },
                {
                    "sent": "We could increase my skill up to about 129 'cause we know that I've beaten somebody.",
                    "label": 0
                },
                {
                    "sent": "His skill is very definitely up here, so by having the uncertainty as well as the mean, it allows us, when appropriate, to make very big changes.",
                    "label": 0
                },
                {
                    "sent": "Which is something we can't do if we just have a single score for each player.",
                    "label": 0
                },
                {
                    "sent": "And of course, that all just follows automatically from the rules of probability, we don't have to put that in as some sort of ad hoc factor that just happens when we do the probabilistic inference.",
                    "label": 0
                },
                {
                    "sent": "So result is that the we can get good estimates of skill factors in about an order of magnitude fewer games than.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the low.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We can now extend the model, yeah?",
                    "label": 0
                },
                {
                    "sent": "Isn't that an artifact from the very smooth after scheme of the losses that would have a more aggressive update scheme like multiplying something then could not approach also quite fast at home and performance.",
                    "label": 0
                },
                {
                    "sent": "We have innovation promote value, estimating the variance you can.",
                    "label": 0
                },
                {
                    "sent": "You can certainly make bigger updates if you wish, but then the problem is that those.",
                    "label": 0
                },
                {
                    "sent": "The problem is with the big updates.",
                    "label": 0
                },
                {
                    "sent": "These systems start or select yes.",
                    "label": 0
                },
                {
                    "sent": "I mean, you want to principle approach that's going to do the right thing and you don't know how big to make those updates because you don't have that uncertainty.",
                    "label": 0
                },
                {
                    "sent": "So you can make more aggressive updates, but now you won't.",
                    "label": 0
                },
                {
                    "sent": "You run the risk of having an unstable.",
                    "label": 0
                },
                {
                    "sent": "An unstable system.",
                    "label": 0
                },
                {
                    "sent": "Because you don't always want to make a big update, right?",
                    "label": 0
                },
                {
                    "sent": "And if our variance is worth very large, there isn't actually much evidence.",
                    "label": 0
                },
                {
                    "sent": "If we've got very large, variances are strongly overlapping.",
                    "label": 0
                },
                {
                    "sent": "There isn't much evidence make big changes to the means of those distributions.",
                    "label": 0
                },
                {
                    "sent": "Correctly, that the eventual feed of the system is our below is that we keep two variables mean like kind of mean and variance and This is why in the lower we we keep just mean.",
                    "label": 0
                },
                {
                    "sent": "So that's why we have.",
                    "label": 0
                },
                {
                    "sent": "So let's keep that as a key difference.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that was a question.",
                    "label": 0
                },
                {
                    "sent": "Function keys and this key is constantly clear, but this kid is obviously changing is great.",
                    "label": 0
                },
                {
                    "sent": "That's my next view graph.",
                    "label": 0
                },
                {
                    "sent": "Great question.",
                    "label": 0
                },
                {
                    "sent": "There was another question.",
                    "label": 0
                },
                {
                    "sent": "Buy one when you put all the old skills into a vector.",
                    "label": 0
                },
                {
                    "sent": "This is basically estimating the mean and diagonal covariance for the augmented vector.",
                    "label": 0
                },
                {
                    "sent": "When when the problem is posed like this, do you know whether the problem is solvable when the covariance form is something different than the diagonal itself, we are assuming all the players are independent from each other.",
                    "label": 0
                },
                {
                    "sent": "All the signals are independent, but you know when.",
                    "label": 0
                },
                {
                    "sent": "Any applications of clicking the make queries other than that?",
                    "label": 0
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you want to introduce if you don't want that.",
                    "label": 0
                },
                {
                    "sent": "If you don't want that diagonal assumption, then you effectively putting extra links into the graph.",
                    "label": 0
                },
                {
                    "sent": "But now you're dealing with computationally more complex problem.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I guess my glib answer is you design the graph and then you run the inference algorithm.",
                    "label": 0
                },
                {
                    "sent": "So effectively you're asking to make fewer independent assumptions and therefore to add more links to the graph.",
                    "label": 0
                },
                {
                    "sent": "What's up, yeah?",
                    "label": 0
                },
                {
                    "sent": "Can you do expectation propagation using Russian distributions to function normally?",
                    "label": 0
                },
                {
                    "sent": "Yes, understanding of when that would work well.",
                    "label": 0
                },
                {
                    "sent": "Great questions, so when is EP going to work well and when it won't can I redirect that to Tom Minka?",
                    "label": 0
                },
                {
                    "sent": "He invented EP and he can talk a lot about situations in which.",
                    "label": 0
                },
                {
                    "sent": "I thought I know he's going to discuss that issue in great length as well, because in some situations yes, multimodality P will not work well and use variational message passing instead of the whole suite of these possible algorithms, you need to choose the right one, so I'll leave time to talk about that.",
                    "label": 0
                },
                {
                    "sent": "'cause that's really his lecture.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "Alright, so I had a question.",
                    "label": 0
                },
                {
                    "sent": "What about skill evolving through time?",
                    "label": 0
                },
                {
                    "sent": "So the other thing that can happen?",
                    "label": 0
                },
                {
                    "sent": "So what I've described so far is we assume that everybody has a fixed but unknown skill.",
                    "label": 0
                },
                {
                    "sent": "What happens, of course, is that if you play lots and lots of chess, your skill improves.",
                    "label": 0
                },
                {
                    "sent": "So again we can capture that by just drawing the right graph.",
                    "label": 0
                },
                {
                    "sent": "So here's a graph which says players one and two have met and they've had a game and we've got a game outcome.",
                    "label": 0
                },
                {
                    "sent": "An hour later they're going to meet and have another game, but in the meantime their skill may have evolved.",
                    "label": 0
                },
                {
                    "sent": "So here's a very simple model.",
                    "label": 0
                },
                {
                    "sent": "It just says that their skill is just undergoing a sort of Gaussian diffusion, so it says the skill the next time is a Gaussian distribution centered on the skill at the previous time.",
                    "label": 0
                },
                {
                    "sent": "And then off we go.",
                    "label": 0
                },
                {
                    "sent": "I mean, you need anything more, testing more likely, he just killed them to lose your skills.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Not what you really want to shirt.",
                    "label": 0
                },
                {
                    "sent": "Well, if you want to skew that distribution, then by all means you go ahead and you put in a skewed distribution.",
                    "label": 0
                },
                {
                    "sent": "That's that's great.",
                    "label": 0
                },
                {
                    "sent": "Yeah, if you believe if you believe skills should increase steadily with time, I don't know.",
                    "label": 0
                },
                {
                    "sent": "My skills have definitely decreased over the years.",
                    "label": 0
                },
                {
                    "sent": "Age age should be another variable.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm OK and the other thing I want to mention about this is that this isn't just an academic study, but it's also been used on online for well since since 2005 where it's processing, these figures are quite out of date actually, so it's really processing millions of game outcomes per day worldwide, 24 hours a day, seven days a week.",
                    "label": 0
                },
                {
                    "sent": "So this is a represents an enormous application of Bayesian methods are very large scale application of Bayesian methods, which I don't think we could have contemplated doing.",
                    "label": 1
                },
                {
                    "sent": "You know 10 years ago we didn't have this machinery available to do this fast large scale inference.",
                    "label": 0
                },
                {
                    "sent": "So is one of the reasons why I think this is a very exciting time for machine learning because the quantity of data in the world is doubling every nine months, is it or something so we live in a world with that's increasingly data rich.",
                    "label": 0
                },
                {
                    "sent": "And now we have tools to do inference on very large datasets, so things are exciting juncture.",
                    "label": 0
                },
                {
                    "sent": "Actually, I mentioned.",
                    "label": 0
                },
                {
                    "sent": "I'll also mention just to prove this wasn't sort of a one off flash in the pan.",
                    "label": 0
                },
                {
                    "sent": "There's now another application, again of exactly the same kind of tools.",
                    "label": 0
                },
                {
                    "sent": "This time it's to do with selecting advertisements in search.",
                    "label": 0
                },
                {
                    "sent": "You'll know about Google.",
                    "label": 0
                },
                {
                    "sent": "Well, actually there may not realize this.",
                    "label": 0
                },
                {
                    "sent": "There are other search engines are not quite as popular as certain a certain company based in Seattle has one of them.",
                    "label": 0
                },
                {
                    "sent": "And just like Google is trying to monitor is paying for it with adverts and so the problem is to pick the pick the right adverts.",
                    "label": 0
                },
                {
                    "sent": "You don't bug the user with adverts that are irrelevant, 'cause that's just annoying.",
                    "label": 0
                },
                {
                    "sent": "You want to show a few adverts as you can, but ones which the user will actually click on.",
                    "label": 0
                },
                {
                    "sent": "So there's a very important inference problem to workout which adverts to show which adverts you should be showing to the user.",
                    "label": 0
                },
                {
                    "sent": "And again that's a real time Online Planet scale application involving huge datasets and again also went live a few months ago and now all of the all of the advertisements served up by.",
                    "label": 0
                },
                {
                    "sent": "By this particular company on its search engine or all.",
                    "label": 0
                },
                {
                    "sent": "Chosen using this method and the performance improvement over the previous method was was enormous, so it's been hugely beneficial in a very.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Single sense.",
                    "label": 0
                },
                {
                    "sent": "The thing I want to mention.",
                    "label": 0
                },
                {
                    "sent": "Our tools I've talked about this this wonderful framework of graphical models and fast, efficient local message passing algorithms.",
                    "label": 0
                },
                {
                    "sent": "So let me mention the work of Jaune win.",
                    "label": 0
                },
                {
                    "sent": "This was his PhD work and this was a system called Vibe.",
                    "label": 0
                },
                {
                    "sent": "So this is an academic study rather than a fully functional toolkit.",
                    "label": 0
                },
                {
                    "sent": "What he did was to say, well, let's really embrace this graphical framework and let's build an inference engine which start by allowing you to draw a graph.",
                    "label": 0
                },
                {
                    "sent": "So what you get is a sort of drawing package an by pointing and clicking.",
                    "label": 0
                },
                {
                    "sent": "You can construct the graph and this is some some kind of mixture of factor analyzer, some Bayesian mixture factor analyzers.",
                    "label": 0
                },
                {
                    "sent": "Each of these nodes available these.",
                    "label": 0
                },
                {
                    "sent": "I think you can see these plates here, so this will be the number of data points, and this is the dimensionality of the data space, and I guess that's the number of components in the mixture.",
                    "label": 0
                },
                {
                    "sent": "This is the dimensionality of the latent continuous latent space.",
                    "label": 0
                },
                {
                    "sent": "We've highlighted one of the nodes here, so we can give it a name.",
                    "label": 0
                },
                {
                    "sent": "We can choose what distribution it has this case it's a gamma distribution set its parameters.",
                    "label": 0
                },
                {
                    "sent": "This don't know.",
                    "label": 0
                },
                {
                    "sent": "This is the observed data.",
                    "label": 0
                },
                {
                    "sent": "So tell it where on your hard disk the data lives and you kind of press the go button and it takes the graph and from the graph it compiles into the code and then it executes the code and returns runs variational message passing and returns marginals for those for those variables.",
                    "label": 0
                },
                {
                    "sent": "So all that happened automatically starting from the graph and ending up with the solution.",
                    "label": 0
                },
                {
                    "sent": "So this avoids the priority.",
                    "label": 0
                },
                {
                    "sent": "To this, if you wanted to do you want to apply this framework you first order.",
                    "label": 0
                },
                {
                    "sent": "I've all the all the update equations or the variational update equations and then you have to code them all up in in Matlab or whatever.",
                    "label": 0
                },
                {
                    "sent": "Both very time consuming steps and both rather error prone.",
                    "label": 0
                },
                {
                    "sent": "So this was a nice example of how you could actually.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Automate that.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "That was one of the inspirations for more sort of industrial strength.",
                    "label": 0
                },
                {
                    "sent": "Very general framework and inference engine called infer.net which supports a will increasingly support a variety of different inference algorithms and many different classes of distribution, and provides very efficient inference and you'll be hearing more.",
                    "label": 0
                },
                {
                    "sent": "I think about this a little bit later in the summer school and the beat of this was launched with NIPS last December, so you can download this and try this out for yourselves.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Show me show you a little demonstration.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll show you a little demonstration of info.net.",
                    "label": 0
                },
                {
                    "sent": "This is a toy problem you don't need info.net to do this problem, it's just a toy atory problem.",
                    "label": 0
                },
                {
                    "sent": "This was put together by John Guiver, one of the developers working on info.net and he put this together in space of few hours and most of the time was spent designing all the graphics and the actual inference code was extremely quick to assemble.",
                    "label": 0
                },
                {
                    "sent": "So imagine we've got a drug and we're going to sort of drug trial to see how effective the drug is an.",
                    "label": 0
                },
                {
                    "sent": "We've also got a placebo so the people on the top row.",
                    "label": 0
                },
                {
                    "sent": "I'm going to give the drug and the people on the bottom row are going to be given the SIBO, and we'd like to know things like if you've got this disease and you take the drug, what's the probability of being cured if you take the procedure?",
                    "label": 0
                },
                {
                    "sent": "Watch the probability of being cured would also like to know is the drug doing any good?",
                    "label": 0
                },
                {
                    "sent": "Is the drug distinguishable from the placebo in a statistical sense?",
                    "label": 0
                },
                {
                    "sent": "So this is a probability scale up here.",
                    "label": 0
                },
                {
                    "sent": "They're the same down here they're different and we've just initialized to .5.",
                    "label": 0
                },
                {
                    "sent": "So what we can do now in this little demo is we can imagine a bunch of people have taken.",
                    "label": 0
                },
                {
                    "sent": "The drug and these are people who've been cured and these are the people who are not cured and over.",
                    "label": 0
                },
                {
                    "sent": "Here is the probability distribution over the uncertain value in the probability of being cured.",
                    "label": 0
                },
                {
                    "sent": "And you can see as more people get cured it shifts to the right and fewer people get cured and it shifts to the left and the more data we have the narrow it becomes.",
                    "label": 0
                },
                {
                    "sent": "And all this inference is all nicely running in real time, and then we can have a placebo, so we can.",
                    "label": 0
                },
                {
                    "sent": "Get people to perceive or maybe the procedure isn't working quite so well as the drug.",
                    "label": 0
                },
                {
                    "sent": "And sure enough, it tells us that it's almost certain, not quite, but there's a high probability that the drug and the pasivo are acting differently, and the more data we collect, the more sure we can be about that sort of conclusion.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What's going on in that model?",
                    "label": 0
                },
                {
                    "sent": "So what we've got is a binary variable which is says whether the drug and the placebo are different.",
                    "label": 0
                },
                {
                    "sent": "And then we have another graphical instructions or gates.",
                    "label": 0
                },
                {
                    "sent": "I'm sure Tom will be telling you about Gates, but you can think of this as just if if this, this difference variable is true, we select the left half and if it's false, we're going to select the right half.",
                    "label": 0
                },
                {
                    "sent": "So let's suppose first of all it's true.",
                    "label": 0
                },
                {
                    "sent": "In other words, the drug dealer procedure different than our model is going to be that we have two probabilities.",
                    "label": 0
                },
                {
                    "sent": "The probability that you'll be cured if you're treated with the drug, and the probability that you'll be cured if you're treated with the SIBO.",
                    "label": 0
                },
                {
                    "sent": "They can be different 'cause these are different.",
                    "label": 0
                },
                {
                    "sent": "These are acting differently and now we have some people and each person is given either the drug or the placebo.",
                    "label": 0
                },
                {
                    "sent": "So those are those are people and whether you're cured or not, the people who take the drug have a probability of being cured, so they governed by this variable.",
                    "label": 0
                },
                {
                    "sent": "So they're connected to this variable, and similarly for the people who take the pasivo.",
                    "label": 0
                },
                {
                    "sent": "There probably being cured is governed by this variable.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if this variable is false, then the drug and the pasivo are acting in the same way, so we just have a single probability for being cured that governs all of these observations.",
                    "label": 0
                },
                {
                    "sent": "Now we go and collect or data, so we shade in the nodes.",
                    "label": 0
                },
                {
                    "sent": "These three people were cured and those people weren't and so now we can run inference and we can pass along messages around this graph and eventually we can compute posterior probabilities for these for these various variables.",
                    "label": 0
                },
                {
                    "sent": "And So what you saw on the left hand side of the demo was this variable on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "Little histograms for these two and there was just wasn't space to show that one.",
                    "label": 0
                },
                {
                    "sent": "But you could imagine what that looked like.",
                    "label": 0
                },
                {
                    "sent": "OK, so with the two minutes to go 'cause it was, good luck, wasn't it?",
                    "label": 0
                },
                {
                    "sent": "Elements I think for any other questions, yeah.",
                    "label": 0
                },
                {
                    "sent": "Bayesian methods have caught on in, say, clinical trials.",
                    "label": 0
                },
                {
                    "sent": "I'm a bit worried about the prospect of my health being in the hands of treatments.",
                    "label": 0
                },
                {
                    "sent": "Very wise.",
                    "label": 0
                },
                {
                    "sent": "Like he passes or whatever for it for deciding whether a drug is actually know, the answer is the answer is no, not at all, and so it's often necessary to take the outputs of the Bayesian model and to express them in in terms of you know, false discovery rates and things that are understood by that community.",
                    "label": 0
                },
                {
                    "sent": "So I think there are sort of in parallel with the process of education and enlightenment.",
                    "label": 0
                },
                {
                    "sent": "There's also a need, I think, to sort of translate results into a language that's.",
                    "label": 0
                },
                {
                    "sent": "Palatable to that to that world.",
                    "label": 0
                },
                {
                    "sent": "I actually had quite a similar questions.",
                    "label": 0
                },
                {
                    "sent": "If you had this slide on the left side for saying and different so the question is how would you then for example, for medical paper quantify the difference difference between exterior distribution?",
                    "label": 0
                },
                {
                    "sent": "So if I ever frequented that would now take the posterior company key value reported and um, so how would you?",
                    "label": 0
                },
                {
                    "sent": "How would you do that in an isolation way?",
                    "label": 0
                },
                {
                    "sent": "Well, I don't understand the question because that is my answer.",
                    "label": 0
                },
                {
                    "sent": "That is my probability.",
                    "label": 0
                },
                {
                    "sent": "Of the two being different, and what I now need to do of course, is to take some.",
                    "label": 0
                },
                {
                    "sent": "Noted on this slide are on the left side, we just jumped different and the same.",
                    "label": 0
                },
                {
                    "sent": "Was that just different in the mean?",
                    "label": 0
                },
                {
                    "sent": "All this this is just.",
                    "label": 0
                },
                {
                    "sent": "There was a binary variable which if it was true, said these distributions are different.",
                    "label": 0
                },
                {
                    "sent": "If it's false, said they were the same and this is the posterior probability of that variable being true.",
                    "label": 0
                },
                {
                    "sent": "Given that I guess is upside down.",
                    "label": 0
                },
                {
                    "sent": "'cause true is down here, but it's the posterior probability of there being true given given the evidence I have from the data that I've collected.",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "Let me take another question.",
                    "label": 0
                },
                {
                    "sent": "Will come back if you're not.",
                    "label": 0
                },
                {
                    "sent": "Here's my version so.",
                    "label": 0
                },
                {
                    "sent": "I mean looking at those.",
                    "label": 0
                },
                {
                    "sent": "One can use it.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Quantified whether there's two distrib.",
                    "label": 0
                },
                {
                    "sent": "Just intuitively say something about whether the same difference the sliding scale in relation to Decatur divergent with these two distribution.",
                    "label": 0
                },
                {
                    "sent": "There are lots of ways you can solve this problem right, and you could you know all sorts of KL divergences and what I like about this approach is that it's very principled and it's very clear what assumptions you're making.",
                    "label": 0
                },
                {
                    "sent": "Make all your assumptions explicit, and then you have fast inference algorithm to compute posterior distributions.",
                    "label": 0
                },
                {
                    "sent": "It's not the only way of solving this problem, but it appeals to me because it makes all those assumptions explicit.",
                    "label": 0
                },
                {
                    "sent": "And as we had a discussion with the the chest in the ranking example, lots of other things you would think.",
                    "label": 0
                },
                {
                    "sent": "So why don't we try better this throw bit of that in?",
                    "label": 0
                },
                {
                    "sent": "But then it's not clear what assumptions you're making.",
                    "label": 0
                },
                {
                    "sent": "It's not clear when those assumptions are going to breakdown and so on.",
                    "label": 0
                },
                {
                    "sent": "So I personally strongly favor this sort of very principled and clear approach.",
                    "label": 0
                },
                {
                    "sent": "When you find out when distributions are interactive and upward of.",
                    "label": 0
                },
                {
                    "sent": "Samples and found several strategies I could and you have.",
                    "label": 0
                },
                {
                    "sent": "Functions is approximately is still non parametric by using a family function underlying distribution.",
                    "label": 0
                },
                {
                    "sent": "Everything I've described so far is based on sort of parametric models for those factors, so everything is parametric and there are people looking at how to build the nonparametric factors into these graphs, and I think that's still quite an active research area.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Have maybe time for one.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Crossing from nose to the background and passing back like.",
                    "label": 0
                },
                {
                    "sent": "Only two direct messages.",
                    "label": 0
                },
                {
                    "sent": "And when I see the graphical model, it looks like a bit like a circuit diagram to me.",
                    "label": 0
                },
                {
                    "sent": "They're like conservation of messages along this thing, so there's a question there about the nature of the different messages between variables and factors.",
                    "label": 0
                },
                {
                    "sent": "They differ actually between.",
                    "label": 0
                },
                {
                    "sent": "Virtual message passing and and EP.",
                    "label": 0
                },
                {
                    "sent": "The two sort of main classes.",
                    "label": 0
                },
                {
                    "sent": "Our belief propagations like EP in example I showed you was just exact inference, belief propagation the the compute an outgoing message from a variable to factor by multiplying all the incoming messages on that variable and computing outgoing message from factor.",
                    "label": 0
                },
                {
                    "sent": "You multiply all the incoming messages by the factor of marginalized.",
                    "label": 0
                },
                {
                    "sent": "Compute the outgoing message, VMP turns out to be to be slightly different but.",
                    "label": 0
                },
                {
                    "sent": "You're going to get two 290 minute lectures on this stuff from Tom, so I think rather than trying to anticipate Toms talk, perhaps will apps or leave it there and encourage you to listen to Tom Tom Store.",
                    "label": 0
                },
                {
                    "sent": "I think Zubin will show we wrap up there.",
                    "label": 0
                },
                {
                    "sent": "Just got past.",
                    "label": 0
                },
                {
                    "sent": "Yeah alright OK, thanks very much.",
                    "label": 0
                }
            ]
        }
    }
}