{
    "id": "vavzf5sjwdbwao5cudu6vncjxtebbd65",
    "title": "Empirical Bernstein Stopping",
    "info": {
        "author": [
            "Volodymyr Mnih, Department of Computer Science, University of Toronto"
        ],
        "published": "Aug. 29, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/icml08_mnih_ebs/",
    "segmentation": [
        [
            "So I'll be talking about how we can design efficient stopping rules.",
            "I'm I'll give two stopping problems.",
            "I'll talk about two inefficient algorithms.",
            "Then I'll present two efficient algorithms and the key will be variance estimation, and I'll give some theoretical and experimental results."
        ],
        [
            "So consider the following problem.",
            "We have two poker players and we'd like to decide which one is better so we can make them play a lot of hands.",
            "But after how many hands can we determine which one is actually the better player?",
            "So there are many similar problems in boosting.",
            "You might want to decide whether a weak learner has error below .5 or not.",
            "Or if you're doing stochastic gradient descent, you might want to check whether your estimated gradient is close to the true gradient."
        ],
        [
            "So somewhat more formally, will have a sequence of idea random variables X, and we will assume that they are distributed with mean mu, which is non zero if mus indeed 00.",
            "We can't.",
            "Actually, we would never be able to decide.",
            "Which player is better?",
            "So variance will be Sigma squared and we assume that they are bounded with range are so XI can be the payoff for player one on the ice hand going back to the poker example.",
            "And if muse less than zero then the second player is better.",
            "And if mu is greater than zero then the first player is better.",
            "So stopping rule observed 60 at time T an based on the history decides whether to stop or keep on sampling.",
            "And in our case, we also want your algorithm to return an estimate.",
            "And further poker case we want to decide whether the sign is.",
            "Positive or negative with high probability."
        ],
        [
            "So the problem that will actually try to solve is defined an estimate of mu will call it you had that is within epsilon relative error of the true mean with probability at least one minus Delta.",
            "So epsilon is less than one.",
            "Our estimate will actually have the same sign as the true mean with high probability, so we returned to mu.",
            "We refer to me how it is an epsilon Delta approximation and our goal is to find an epsilon Delta approximation with as few samples as possible."
        ],
        [
            "So there is a basic stopping criterion that's been derived by quite a few different people, and the way it works is first you define a sequence DT of non negative real numbers that sums up to Delta.",
            "And then we let CTB half the width over 1 minus DT confidence interval for the mean mu.",
            "And if we do this then this event will hold with probability at least one minus Delta.",
            "So we essentially constrain.",
            "The true mean to be in this range when the event occurs, we essentially know it up to some precision.",
            "So having defined this, all we do is sample until this condition is satisfied.",
            "An once it's satisfied, we simply return the sample mean of the samples we've seen up to this point.",
            "And the version of this stopping rule was developed by Domingo at all, and they refer to it as non monotonic adaptive sampling.",
            "And in their case they use Hardings inequality to construct the confidence.",
            "The sequence of confidence intervals C."
        ],
        [
            "T. So why does this work?",
            "We want to show that pawn termination.",
            "The sample mean is at most within epsilon relative error of the true mean."
        ],
        [
            "So by construction of CT we know that this is true."
        ],
        [
            "And also by the definition of CT this inequality holds."
        ],
        [
            "So if this was true, all all three inequality's would hold here, and we wouldn't have a result.",
            "But this is simply the stopping condition.",
            "So when the stopping rules stops.",
            "Sample mean is indeed within relative error of the true mean, and since the confidence intervals we constructed hold with probability at least one minus Delta, the sample mean is an epsilon Delta approximation.",
            "So Domingo and all showed that if TIS the stopping time of the Nas algorithm, non monotonic adaptive sampling, then it's expected stopping time is bounded from above by this expression where we have a dependence on the range of the random variables squared and on the bottom we have the desired precision squared.",
            "So this is good because we do have an algorithm that solves our problem.",
            "But maybe we can do better for example whereas.",
            "The variance going back to the poker example, if one player is winning hand after hand, we should be able to determine that he he or she is the better player sooner than if the hands kept going back and forth."
        ],
        [
            "So there is an algorithm for the case where the random variables are non negative and it was developed by diagram, carp, Lubian, Ross and I will not go into details but the key point is that they obtain some variant.",
            "Some estimate of the variance and based on that they determine the number of samples needed to obtain an epsilon Delta approximation so."
        ],
        [
            "So there a algorithm, actually it's stopping time is bounded from its expected stopping time is bounded from above by this expression where we now have this Max theorem where if the variance isn't small then we can at least trade off the range squared for the variance and if the variance is really small then we should be able to stop get roughly a square root speedup over the next algorithm.",
            "So this is actually quite good, but maybe this term looks a little bit funny and maybe we can do better than this."
        ],
        [
            "But it turns out that this is the best possible bound achievable by any stopping rule that returns an epsilon Delta approximation of a non negative bounded random variable.",
            "So it would be nice if we could extend this result."
        ],
        [
            "To the simply bounded case, because we can't apply the algorithm to the poker problem, it seems that we should be able to just shift the samples if they are negative and make them non negative.",
            "But this actually changes the meaning of relative error and the algorithm wouldn't do what we want and we can try a few other things, but the algorithm heavily depends on the monotonicity of partial sums because all samples are non negative so.",
            "Each time we draw a new sample, the sum of all samples up till that point will not decrease and it seems that no trivial extension to the bandit case as possible."
        ],
        [
            "So we developed an algorithm called EB stuff that actually achieves this and it's it builds on the basic stopping criterion that we looked at earlier.",
            "The first improvement we make is we use empirical Bernstein bounds to construct the sequence of confidence intervals, and this bound was derived by Odie, Bear moon, Ossian Selfish Marie last year, and it states that with probability at least minus one.",
            "The sample mean is.",
            "At most this far from the true mean after T samples and.",
            "This term looks very similar to the hauntings inequality, but instead of the range squared, we have sample variance here.",
            "Now, of course, sample variance could be 0, so we can't just have that as are bound, so we have to have some additional penalty term that depends on the range but not the sample variance.",
            "And this is what the bound does.",
            "Um?"
        ],
        [
            "So in addition to that, we also show that we can slightly improve on the basic stopping criterion and we can get rid of this CT and obtain a slightly better stopping criterion, but I will not."
        ],
        [
            "Going through the details.",
            "So our algorithm maybe stop achieves the following bound.",
            "We have again this Max term that was achieved by the algorithm, but we have this additional log term.",
            "And this is actually quite good because we come close to the optimal bound for the non negative case and in that case it's achieved by the algorithm.",
            "But in the simply bounded case it's not known whether.",
            "The lower bound is tight, or there is a higher lower bound, so maybe we can try to get rid of a reduced this term."
        ],
        [
            "And one way of doing this is performing geometric sampling instead of checking the stopping condition after each sample we check it for the case time after beta to the power of K samples have been drawn where beta is some real number greater than one, and since using fewer deviation bounds allows us to use higher confidence intervals after an equal number of samples, the confidence intervals become smaller.",
            "And their rule can stop earlier."
        ],
        [
            "And we show that this actually reduces the log term to a log log term and we can be happy because we all know that this is bounded above by 6 on the computer.",
            "So we also show that we can achieve the same bound while still checking the stopping condition at every every after every sample."
        ],
        [
            "So we wanted to evaluate the stopping rules to see if the bounds are actually telling us anything about the algorithms.",
            "So the first experiment was finding .0 one point 1 approximations of averages of end uniform random variables.",
            "So as N increases, variance decreases.",
            "But the mean stays the same, so we're controlling for the effect of variance here.",
            "And we see that just like the bounds predicted nice in a geometric version of the NASA algorithm.",
            "Actually require the same number of samples no matter what the variance is.",
            "I should say that on the Y axis we have average stopping time in log scale.",
            "But if we stop and it's geometric variant and they algorithm are both able to take advantage of smaller variance and they stop sooner.",
            "And."
        ],
        [
            "The other experiment we performed was on Bernoulli random variables in this case.",
            "If you look at the bounds then.",
            "Any LDA algorithm and the variance of EB stop should be able to require one over mu fewer time samples then master geometric noise.",
            "And here we show.",
            "Each group is Bernoulli random variable with decreasing means.",
            "And again this is log scale.",
            "So we this term does indeed show up.",
            "So these algorithms can stop can require one over mu times fewer samples.",
            "So."
        ],
        [
            "This is good, but maybe the results we obtained here only applied to this special case.",
            "So we look at a second problem where you refer to it as picking the winner and the setting is as follows.",
            "We have a number of predictors and we want to decide which one is the best, but we want to do it quickly, so a standard setup is taking a holdout set and then starting to test each predictor.",
            "On each point in the holdout set, and then we pick the one with the highest accuracy, average, reward, likelihood, whatever we're interested in.",
            "So since evaluating predictors can be quite costly, especially in the non parametric case, it's possible to save a lot of time by throwing away predictors that are clearly that will clearly not be the best."
        ],
        [
            "And the setting can be formalized racing algorithms.",
            "What we're given is M options or predictors.",
            "And N data points.",
            "And again a confidence parameter Delta greater than zero and erasing algorithm does the following at time T it receives a data point DT.",
            "And you can choose to compute the payoff XMT.",
            "For the NTH option on Datapoint DT.",
            "And we can also decide whether to keep or discard each option.",
            "And we assume that the pay offs for each option are ID and again distributed with mean mu M and range are.",
            "So erasing algorithm terminates when it has found the best option with probability at least one 1 minus Delta or it has gone through all end data points.",
            "And the goal here is to keep the best option, but compute much fewer than the total number of men pay offs."
        ],
        [
            "So Maranan more introduced the haunting race algorithm, and it does the following at time T. It builds a 1 minus Delta over amend confidence interval for each mean Umm and it constructs this again using Hardings inequality.",
            "Once these confidence intervals are constructed.",
            "They discard if the upper confidence of any option is lower than the lower confidence of any option, then we know with high probability that this.",
            "That this cannot be the best option, so we throw it away and this is how the algorithm works."
        ],
        [
            "So a similar result was proved in the Infinite Horizon case, but we prove a theorem for the finite horizon case.",
            "So the number of samples taken by the hovding race algorithm is bounded from above by the following quantity.",
            "Here we have a some overall sub optimal options.",
            "Mstar denotes the option with the highest payoff.",
            "And for each sub optimal option, the number of times.",
            "Therefore it will be evaluated against scales with.",
            "The square of the range.",
            "And it scales inversely with this square of the difference between the payoff for that option and the payoff for the best option.",
            "So this is actually quite similar to our previous problem, except we don't have a log term, because this is the finite horizon case.",
            "And again we have dependence on R-squared and variance is nowhere to be found.",
            "So in the case where the range is really high.",
            "But the payoff is small.",
            "The variance will again be really small and we should be able to do much more."
        ],
        [
            "Other than this?",
            "So really simple improvement is again to simply sub in the empirical Bernstein bound for Hopkins inequality when constructing confidence intervals at each time point.",
            "And we show that we call this algorithm EV arrays.",
            "Then the number of samples or the number of payoff it computes is bounded from above.",
            "By this we again have a some overall sub optimal arms, but.",
            "As in the poker problem, the dependence on R-squared disappears and we have a dependence on the variance.",
            "And the range.",
            "And this this bound can actually be transformed into the same form as the bounds for the previous case.",
            "And instead of sums we have the same thing.",
            "A Max of variance over precision squared and just range over the precision."
        ],
        [
            "And again we wanted to see if these bounds are telling us something about these algorithms.",
            "So what we did was we evaluated them on the task of selecting the best K for nearest neighbor regression or classification through leave one out cross validation.",
            "So the idea assumption isn't quite satisfied, but we repeated these experiments with the holdout set and the results are almost the same.",
            "And I'm presenting these because these are the results in the paper.",
            "So we started with 11 models or values of K. And.",
            "We had three datasets and we show the percentage of.",
            "Pay off a valuations over amend that was saved by each algorithm and we also show the number of models left upon termination.",
            "So the SARCODES data set was a regression data set with very high range but low variance in the pay offs.",
            "And actually in this case the Hovding race algorithm was unable to save any work.",
            "Over brute force while EB Race managed to save almost half the payoff computations and a discarded 7 models.",
            "The cover time data set data set is a classification data set and here the range is quite close to the variance, so the performance of hovding race in DB raises quite close, but even raise still manages to save almost twice as much short.",
            "And local is simply.",
            "It's a regression data set where the range is not as high in this case, so the variance is again closer to the range, but we don't have.",
            "Bernoulli random variables.",
            "So here we do again quite a bit better than the hunting race Al Gore."
        ],
        [
            "So to conclude, empirical Bernstein bounds can be used to obtain efficient stopping rules, and when used in place of Harding's inequality, we can trade off linear dependence on R-squared in the sample complexity for linear dependence on the variance and their range, and practice that.",
            "This can offer huge computational savings.",
            "So that is all, thank you.",
            "Sample size and then when you look at the curves of different algorithms.",
            "Gross.",
            "So it would be wrong to assume that one is below Max.",
            "Of the variance below the other variants.",
            "To use blood could not be would not be the case so soon.",
            "So in the idea assumption, we actually it's possible to prove we're running more proof that.",
            "The best option is discarded with probability less than Delta.",
            "So if the idea assumption is not satisfied, this might happen.",
            "So in practice you might want to.",
            "I guess permute your data points too.",
            "I guess.",
            "To avoid any unusual effects but.",
            "I'm not sure how we would extend this to the non IID case, so Markov chains we haven't looked at yet.",
            "Ever.",
            "There is the fire range mean offense, but this is a client range of some relation, like I'm constrained one the other strictly right so I don't remember.",
            "Variance in it or somehow has some kind of an jointly?",
            "Which one?",
            "You mean these bones or?",
            "So with Ranger.",
            "I guess the variance is bounded from above by.",
            "R * R minus the mean.",
            "So I think.",
            "This is still.",
            "Tighter in this sense.",
            "So we could take an algorithm, I guess that.",
            "Just depends on the range and get some sort of result for the variance."
        ],
        [
            "It wouldn't be.",
            "Yeah here.",
            "It does."
        ],
        [
            "So from 021, right?",
            "So the variance variance for the leftmost?",
            "And the rightmost.",
            "Bernoulli's is the same, but in the bound we have the mean appearing on the bottom, so.",
            "From the view parameter."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'll be talking about how we can design efficient stopping rules.",
                    "label": 1
                },
                {
                    "sent": "I'm I'll give two stopping problems.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about two inefficient algorithms.",
                    "label": 0
                },
                {
                    "sent": "Then I'll present two efficient algorithms and the key will be variance estimation, and I'll give some theoretical and experimental results.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So consider the following problem.",
                    "label": 0
                },
                {
                    "sent": "We have two poker players and we'd like to decide which one is better so we can make them play a lot of hands.",
                    "label": 1
                },
                {
                    "sent": "But after how many hands can we determine which one is actually the better player?",
                    "label": 0
                },
                {
                    "sent": "So there are many similar problems in boosting.",
                    "label": 1
                },
                {
                    "sent": "You might want to decide whether a weak learner has error below .5 or not.",
                    "label": 0
                },
                {
                    "sent": "Or if you're doing stochastic gradient descent, you might want to check whether your estimated gradient is close to the true gradient.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So somewhat more formally, will have a sequence of idea random variables X, and we will assume that they are distributed with mean mu, which is non zero if mus indeed 00.",
                    "label": 1
                },
                {
                    "sent": "We can't.",
                    "label": 0
                },
                {
                    "sent": "Actually, we would never be able to decide.",
                    "label": 0
                },
                {
                    "sent": "Which player is better?",
                    "label": 0
                },
                {
                    "sent": "So variance will be Sigma squared and we assume that they are bounded with range are so XI can be the payoff for player one on the ice hand going back to the poker example.",
                    "label": 1
                },
                {
                    "sent": "And if muse less than zero then the second player is better.",
                    "label": 0
                },
                {
                    "sent": "And if mu is greater than zero then the first player is better.",
                    "label": 0
                },
                {
                    "sent": "So stopping rule observed 60 at time T an based on the history decides whether to stop or keep on sampling.",
                    "label": 1
                },
                {
                    "sent": "And in our case, we also want your algorithm to return an estimate.",
                    "label": 1
                },
                {
                    "sent": "And further poker case we want to decide whether the sign is.",
                    "label": 0
                },
                {
                    "sent": "Positive or negative with high probability.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the problem that will actually try to solve is defined an estimate of mu will call it you had that is within epsilon relative error of the true mean with probability at least one minus Delta.",
                    "label": 0
                },
                {
                    "sent": "So epsilon is less than one.",
                    "label": 0
                },
                {
                    "sent": "Our estimate will actually have the same sign as the true mean with high probability, so we returned to mu.",
                    "label": 0
                },
                {
                    "sent": "We refer to me how it is an epsilon Delta approximation and our goal is to find an epsilon Delta approximation with as few samples as possible.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there is a basic stopping criterion that's been derived by quite a few different people, and the way it works is first you define a sequence DT of non negative real numbers that sums up to Delta.",
                    "label": 1
                },
                {
                    "sent": "And then we let CTB half the width over 1 minus DT confidence interval for the mean mu.",
                    "label": 1
                },
                {
                    "sent": "And if we do this then this event will hold with probability at least one minus Delta.",
                    "label": 0
                },
                {
                    "sent": "So we essentially constrain.",
                    "label": 0
                },
                {
                    "sent": "The true mean to be in this range when the event occurs, we essentially know it up to some precision.",
                    "label": 0
                },
                {
                    "sent": "So having defined this, all we do is sample until this condition is satisfied.",
                    "label": 1
                },
                {
                    "sent": "An once it's satisfied, we simply return the sample mean of the samples we've seen up to this point.",
                    "label": 0
                },
                {
                    "sent": "And the version of this stopping rule was developed by Domingo at all, and they refer to it as non monotonic adaptive sampling.",
                    "label": 0
                },
                {
                    "sent": "And in their case they use Hardings inequality to construct the confidence.",
                    "label": 0
                },
                {
                    "sent": "The sequence of confidence intervals C.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "T. So why does this work?",
                    "label": 0
                },
                {
                    "sent": "We want to show that pawn termination.",
                    "label": 0
                },
                {
                    "sent": "The sample mean is at most within epsilon relative error of the true mean.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So by construction of CT we know that this is true.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also by the definition of CT this inequality holds.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if this was true, all all three inequality's would hold here, and we wouldn't have a result.",
                    "label": 0
                },
                {
                    "sent": "But this is simply the stopping condition.",
                    "label": 0
                },
                {
                    "sent": "So when the stopping rules stops.",
                    "label": 0
                },
                {
                    "sent": "Sample mean is indeed within relative error of the true mean, and since the confidence intervals we constructed hold with probability at least one minus Delta, the sample mean is an epsilon Delta approximation.",
                    "label": 0
                },
                {
                    "sent": "So Domingo and all showed that if TIS the stopping time of the Nas algorithm, non monotonic adaptive sampling, then it's expected stopping time is bounded from above by this expression where we have a dependence on the range of the random variables squared and on the bottom we have the desired precision squared.",
                    "label": 1
                },
                {
                    "sent": "So this is good because we do have an algorithm that solves our problem.",
                    "label": 0
                },
                {
                    "sent": "But maybe we can do better for example whereas.",
                    "label": 0
                },
                {
                    "sent": "The variance going back to the poker example, if one player is winning hand after hand, we should be able to determine that he he or she is the better player sooner than if the hands kept going back and forth.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there is an algorithm for the case where the random variables are non negative and it was developed by diagram, carp, Lubian, Ross and I will not go into details but the key point is that they obtain some variant.",
                    "label": 0
                },
                {
                    "sent": "Some estimate of the variance and based on that they determine the number of samples needed to obtain an epsilon Delta approximation so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there a algorithm, actually it's stopping time is bounded from its expected stopping time is bounded from above by this expression where we now have this Max theorem where if the variance isn't small then we can at least trade off the range squared for the variance and if the variance is really small then we should be able to stop get roughly a square root speedup over the next algorithm.",
                    "label": 0
                },
                {
                    "sent": "So this is actually quite good, but maybe this term looks a little bit funny and maybe we can do better than this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But it turns out that this is the best possible bound achievable by any stopping rule that returns an epsilon Delta approximation of a non negative bounded random variable.",
                    "label": 0
                },
                {
                    "sent": "So it would be nice if we could extend this result.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To the simply bounded case, because we can't apply the algorithm to the poker problem, it seems that we should be able to just shift the samples if they are negative and make them non negative.",
                    "label": 1
                },
                {
                    "sent": "But this actually changes the meaning of relative error and the algorithm wouldn't do what we want and we can try a few other things, but the algorithm heavily depends on the monotonicity of partial sums because all samples are non negative so.",
                    "label": 0
                },
                {
                    "sent": "Each time we draw a new sample, the sum of all samples up till that point will not decrease and it seems that no trivial extension to the bandit case as possible.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we developed an algorithm called EB stuff that actually achieves this and it's it builds on the basic stopping criterion that we looked at earlier.",
                    "label": 1
                },
                {
                    "sent": "The first improvement we make is we use empirical Bernstein bounds to construct the sequence of confidence intervals, and this bound was derived by Odie, Bear moon, Ossian Selfish Marie last year, and it states that with probability at least minus one.",
                    "label": 1
                },
                {
                    "sent": "The sample mean is.",
                    "label": 0
                },
                {
                    "sent": "At most this far from the true mean after T samples and.",
                    "label": 0
                },
                {
                    "sent": "This term looks very similar to the hauntings inequality, but instead of the range squared, we have sample variance here.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, sample variance could be 0, so we can't just have that as are bound, so we have to have some additional penalty term that depends on the range but not the sample variance.",
                    "label": 0
                },
                {
                    "sent": "And this is what the bound does.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in addition to that, we also show that we can slightly improve on the basic stopping criterion and we can get rid of this CT and obtain a slightly better stopping criterion, but I will not.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going through the details.",
                    "label": 0
                },
                {
                    "sent": "So our algorithm maybe stop achieves the following bound.",
                    "label": 0
                },
                {
                    "sent": "We have again this Max term that was achieved by the algorithm, but we have this additional log term.",
                    "label": 0
                },
                {
                    "sent": "And this is actually quite good because we come close to the optimal bound for the non negative case and in that case it's achieved by the algorithm.",
                    "label": 1
                },
                {
                    "sent": "But in the simply bounded case it's not known whether.",
                    "label": 0
                },
                {
                    "sent": "The lower bound is tight, or there is a higher lower bound, so maybe we can try to get rid of a reduced this term.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And one way of doing this is performing geometric sampling instead of checking the stopping condition after each sample we check it for the case time after beta to the power of K samples have been drawn where beta is some real number greater than one, and since using fewer deviation bounds allows us to use higher confidence intervals after an equal number of samples, the confidence intervals become smaller.",
                    "label": 0
                },
                {
                    "sent": "And their rule can stop earlier.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we show that this actually reduces the log term to a log log term and we can be happy because we all know that this is bounded above by 6 on the computer.",
                    "label": 0
                },
                {
                    "sent": "So we also show that we can achieve the same bound while still checking the stopping condition at every every after every sample.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we wanted to evaluate the stopping rules to see if the bounds are actually telling us anything about the algorithms.",
                    "label": 0
                },
                {
                    "sent": "So the first experiment was finding .0 one point 1 approximations of averages of end uniform random variables.",
                    "label": 1
                },
                {
                    "sent": "So as N increases, variance decreases.",
                    "label": 1
                },
                {
                    "sent": "But the mean stays the same, so we're controlling for the effect of variance here.",
                    "label": 0
                },
                {
                    "sent": "And we see that just like the bounds predicted nice in a geometric version of the NASA algorithm.",
                    "label": 1
                },
                {
                    "sent": "Actually require the same number of samples no matter what the variance is.",
                    "label": 0
                },
                {
                    "sent": "I should say that on the Y axis we have average stopping time in log scale.",
                    "label": 0
                },
                {
                    "sent": "But if we stop and it's geometric variant and they algorithm are both able to take advantage of smaller variance and they stop sooner.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other experiment we performed was on Bernoulli random variables in this case.",
                    "label": 1
                },
                {
                    "sent": "If you look at the bounds then.",
                    "label": 0
                },
                {
                    "sent": "Any LDA algorithm and the variance of EB stop should be able to require one over mu fewer time samples then master geometric noise.",
                    "label": 0
                },
                {
                    "sent": "And here we show.",
                    "label": 0
                },
                {
                    "sent": "Each group is Bernoulli random variable with decreasing means.",
                    "label": 0
                },
                {
                    "sent": "And again this is log scale.",
                    "label": 0
                },
                {
                    "sent": "So we this term does indeed show up.",
                    "label": 0
                },
                {
                    "sent": "So these algorithms can stop can require one over mu times fewer samples.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is good, but maybe the results we obtained here only applied to this special case.",
                    "label": 0
                },
                {
                    "sent": "So we look at a second problem where you refer to it as picking the winner and the setting is as follows.",
                    "label": 0
                },
                {
                    "sent": "We have a number of predictors and we want to decide which one is the best, but we want to do it quickly, so a standard setup is taking a holdout set and then starting to test each predictor.",
                    "label": 1
                },
                {
                    "sent": "On each point in the holdout set, and then we pick the one with the highest accuracy, average, reward, likelihood, whatever we're interested in.",
                    "label": 1
                },
                {
                    "sent": "So since evaluating predictors can be quite costly, especially in the non parametric case, it's possible to save a lot of time by throwing away predictors that are clearly that will clearly not be the best.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the setting can be formalized racing algorithms.",
                    "label": 0
                },
                {
                    "sent": "What we're given is M options or predictors.",
                    "label": 0
                },
                {
                    "sent": "And N data points.",
                    "label": 0
                },
                {
                    "sent": "And again a confidence parameter Delta greater than zero and erasing algorithm does the following at time T it receives a data point DT.",
                    "label": 1
                },
                {
                    "sent": "And you can choose to compute the payoff XMT.",
                    "label": 1
                },
                {
                    "sent": "For the NTH option on Datapoint DT.",
                    "label": 0
                },
                {
                    "sent": "And we can also decide whether to keep or discard each option.",
                    "label": 0
                },
                {
                    "sent": "And we assume that the pay offs for each option are ID and again distributed with mean mu M and range are.",
                    "label": 0
                },
                {
                    "sent": "So erasing algorithm terminates when it has found the best option with probability at least one 1 minus Delta or it has gone through all end data points.",
                    "label": 1
                },
                {
                    "sent": "And the goal here is to keep the best option, but compute much fewer than the total number of men pay offs.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Maranan more introduced the haunting race algorithm, and it does the following at time T. It builds a 1 minus Delta over amend confidence interval for each mean Umm and it constructs this again using Hardings inequality.",
                    "label": 1
                },
                {
                    "sent": "Once these confidence intervals are constructed.",
                    "label": 0
                },
                {
                    "sent": "They discard if the upper confidence of any option is lower than the lower confidence of any option, then we know with high probability that this.",
                    "label": 1
                },
                {
                    "sent": "That this cannot be the best option, so we throw it away and this is how the algorithm works.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a similar result was proved in the Infinite Horizon case, but we prove a theorem for the finite horizon case.",
                    "label": 0
                },
                {
                    "sent": "So the number of samples taken by the hovding race algorithm is bounded from above by the following quantity.",
                    "label": 1
                },
                {
                    "sent": "Here we have a some overall sub optimal options.",
                    "label": 0
                },
                {
                    "sent": "Mstar denotes the option with the highest payoff.",
                    "label": 0
                },
                {
                    "sent": "And for each sub optimal option, the number of times.",
                    "label": 0
                },
                {
                    "sent": "Therefore it will be evaluated against scales with.",
                    "label": 0
                },
                {
                    "sent": "The square of the range.",
                    "label": 0
                },
                {
                    "sent": "And it scales inversely with this square of the difference between the payoff for that option and the payoff for the best option.",
                    "label": 0
                },
                {
                    "sent": "So this is actually quite similar to our previous problem, except we don't have a log term, because this is the finite horizon case.",
                    "label": 0
                },
                {
                    "sent": "And again we have dependence on R-squared and variance is nowhere to be found.",
                    "label": 0
                },
                {
                    "sent": "So in the case where the range is really high.",
                    "label": 0
                },
                {
                    "sent": "But the payoff is small.",
                    "label": 0
                },
                {
                    "sent": "The variance will again be really small and we should be able to do much more.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other than this?",
                    "label": 0
                },
                {
                    "sent": "So really simple improvement is again to simply sub in the empirical Bernstein bound for Hopkins inequality when constructing confidence intervals at each time point.",
                    "label": 1
                },
                {
                    "sent": "And we show that we call this algorithm EV arrays.",
                    "label": 0
                },
                {
                    "sent": "Then the number of samples or the number of payoff it computes is bounded from above.",
                    "label": 1
                },
                {
                    "sent": "By this we again have a some overall sub optimal arms, but.",
                    "label": 0
                },
                {
                    "sent": "As in the poker problem, the dependence on R-squared disappears and we have a dependence on the variance.",
                    "label": 0
                },
                {
                    "sent": "And the range.",
                    "label": 0
                },
                {
                    "sent": "And this this bound can actually be transformed into the same form as the bounds for the previous case.",
                    "label": 0
                },
                {
                    "sent": "And instead of sums we have the same thing.",
                    "label": 0
                },
                {
                    "sent": "A Max of variance over precision squared and just range over the precision.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And again we wanted to see if these bounds are telling us something about these algorithms.",
                    "label": 0
                },
                {
                    "sent": "So what we did was we evaluated them on the task of selecting the best K for nearest neighbor regression or classification through leave one out cross validation.",
                    "label": 1
                },
                {
                    "sent": "So the idea assumption isn't quite satisfied, but we repeated these experiments with the holdout set and the results are almost the same.",
                    "label": 0
                },
                {
                    "sent": "And I'm presenting these because these are the results in the paper.",
                    "label": 0
                },
                {
                    "sent": "So we started with 11 models or values of K. And.",
                    "label": 0
                },
                {
                    "sent": "We had three datasets and we show the percentage of.",
                    "label": 0
                },
                {
                    "sent": "Pay off a valuations over amend that was saved by each algorithm and we also show the number of models left upon termination.",
                    "label": 0
                },
                {
                    "sent": "So the SARCODES data set was a regression data set with very high range but low variance in the pay offs.",
                    "label": 0
                },
                {
                    "sent": "And actually in this case the Hovding race algorithm was unable to save any work.",
                    "label": 0
                },
                {
                    "sent": "Over brute force while EB Race managed to save almost half the payoff computations and a discarded 7 models.",
                    "label": 0
                },
                {
                    "sent": "The cover time data set data set is a classification data set and here the range is quite close to the variance, so the performance of hovding race in DB raises quite close, but even raise still manages to save almost twice as much short.",
                    "label": 0
                },
                {
                    "sent": "And local is simply.",
                    "label": 0
                },
                {
                    "sent": "It's a regression data set where the range is not as high in this case, so the variance is again closer to the range, but we don't have.",
                    "label": 0
                },
                {
                    "sent": "Bernoulli random variables.",
                    "label": 0
                },
                {
                    "sent": "So here we do again quite a bit better than the hunting race Al Gore.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to conclude, empirical Bernstein bounds can be used to obtain efficient stopping rules, and when used in place of Harding's inequality, we can trade off linear dependence on R-squared in the sample complexity for linear dependence on the variance and their range, and practice that.",
                    "label": 0
                },
                {
                    "sent": "This can offer huge computational savings.",
                    "label": 0
                },
                {
                    "sent": "So that is all, thank you.",
                    "label": 0
                },
                {
                    "sent": "Sample size and then when you look at the curves of different algorithms.",
                    "label": 0
                },
                {
                    "sent": "Gross.",
                    "label": 0
                },
                {
                    "sent": "So it would be wrong to assume that one is below Max.",
                    "label": 0
                },
                {
                    "sent": "Of the variance below the other variants.",
                    "label": 0
                },
                {
                    "sent": "To use blood could not be would not be the case so soon.",
                    "label": 0
                },
                {
                    "sent": "So in the idea assumption, we actually it's possible to prove we're running more proof that.",
                    "label": 0
                },
                {
                    "sent": "The best option is discarded with probability less than Delta.",
                    "label": 0
                },
                {
                    "sent": "So if the idea assumption is not satisfied, this might happen.",
                    "label": 0
                },
                {
                    "sent": "So in practice you might want to.",
                    "label": 0
                },
                {
                    "sent": "I guess permute your data points too.",
                    "label": 0
                },
                {
                    "sent": "I guess.",
                    "label": 0
                },
                {
                    "sent": "To avoid any unusual effects but.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure how we would extend this to the non IID case, so Markov chains we haven't looked at yet.",
                    "label": 0
                },
                {
                    "sent": "Ever.",
                    "label": 0
                },
                {
                    "sent": "There is the fire range mean offense, but this is a client range of some relation, like I'm constrained one the other strictly right so I don't remember.",
                    "label": 0
                },
                {
                    "sent": "Variance in it or somehow has some kind of an jointly?",
                    "label": 0
                },
                {
                    "sent": "Which one?",
                    "label": 0
                },
                {
                    "sent": "You mean these bones or?",
                    "label": 0
                },
                {
                    "sent": "So with Ranger.",
                    "label": 0
                },
                {
                    "sent": "I guess the variance is bounded from above by.",
                    "label": 0
                },
                {
                    "sent": "R * R minus the mean.",
                    "label": 0
                },
                {
                    "sent": "So I think.",
                    "label": 0
                },
                {
                    "sent": "This is still.",
                    "label": 0
                },
                {
                    "sent": "Tighter in this sense.",
                    "label": 0
                },
                {
                    "sent": "So we could take an algorithm, I guess that.",
                    "label": 0
                },
                {
                    "sent": "Just depends on the range and get some sort of result for the variance.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It wouldn't be.",
                    "label": 0
                },
                {
                    "sent": "Yeah here.",
                    "label": 0
                },
                {
                    "sent": "It does.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So from 021, right?",
                    "label": 0
                },
                {
                    "sent": "So the variance variance for the leftmost?",
                    "label": 0
                },
                {
                    "sent": "And the rightmost.",
                    "label": 0
                },
                {
                    "sent": "Bernoulli's is the same, but in the bound we have the mean appearing on the bottom, so.",
                    "label": 0
                },
                {
                    "sent": "From the view parameter.",
                    "label": 0
                }
            ]
        }
    }
}