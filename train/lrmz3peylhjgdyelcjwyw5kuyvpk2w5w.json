{
    "id": "lrmz3peylhjgdyelcjwyw5kuyvpk2w5w",
    "title": "ANAPSID: An Adaptive Query Processing Engine for SPARQL Endpoints",
    "info": {
        "author": [
            "Maribel Acosta, Institute of Applied Informatics and Formal Description Methods (AIFB), Karlsruhe Institute of Technology (KIT)",
            "Maria Esther Vidal, University Sim\u00f3n Bol\u00ed\u00advar"
        ],
        "published": "Nov. 25, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science"
        ]
    },
    "url": "http://videolectures.net/iswc2011_acosta_vidal_anapsid/",
    "segmentation": [
        [
            "OK, good afternoon today.",
            "Maribel Acosta and I will present an acid and acid base and adaptive query processing engine for sparkle endpoints.",
            "So the model."
        ],
        [
            "Turn off our work is the cloud of in data and what happened to the cloud of in data in the last years.",
            "So they having an explosion in the number of data sources in the cloud of rain data and so on of these data sources are very very large."
        ],
        [
            "And they are fully connected to many data sources and the point is that for query the cloud of in data this huge graph have to be traverse."
        ],
        [
            "So to process queries against the cloud of in data and following the publication guideline of a cloud of Linda, several endpoints have been implemented.",
            "But the problem with the same points is that many of these endpoints have been designed just for solving very, very simple queries.",
            "There are just for solving lightweight queries and also because many of these endpoints rely the query.",
            "Processing in blocking operators.",
            "They won't be able to produce any answer without reversing the their portion of the huge graph.",
            "This is required to answer the query."
        ],
        [
            "So do we look today?",
            "The behavior of these endpoints?",
            "Let's consider this query where we want to retrieve sensors that sense freezing temperatures in these days.",
            "So to ever write that query to data sources have to be access.",
            "One is the link sensor data and the other day geonames."
        ],
        [
            "So we should meet at the query against one of these endpoints they built.",
            "Also in point for the lens sensor data and we set up different values for the Sponge para meter and their answer was that after two NT 4 hours we couldn't get any result.",
            "So the problem was that even we gave the endpoint 24 hour's to produce and answer them.",
            "Point was that the endpoint timeout without able to traverse the huge graph that was needed to be traversed to produce the whole answer to the query.",
            "So the endpoint wasn't able to produce an aquarium up an answer to the query and then produce another answer.",
            "And reverse at the same time."
        ],
        [
            "So it's not considered a query where we travel.",
            "We want to retrieve genes and diseases that have been tested for the drugs that, having established for breaks in breast cancer.",
            "Clinical trials for answering this query, the lincity.",
            "This is song on Drugbank data sets have to be."
        ],
        [
            "So send the query to any other available and points and the answer will be empty.",
            "However, if we download the data sets and locali wrong the query against this huge mix data set, the answer will be will have more than 12,000 topless.",
            "So the problem here is that these endpoints are just able to traverse.",
            "They sat graph of a single data set.",
            "They are not able to jump from one data set to the other.",
            "So when several endpoints are required, where several data sets are required to be wearing the same points are not able to do it and they will answer a name tions.",
            "Even if equity is not."
        ],
        [
            "My name the answer.",
            "So while you can say OK, instead of using his particular 1.0, why don't use Sparkle don't want?"
        ],
        [
            "Done.",
            "I rewrite the query into simple subqueries against the different endpoints, so in this case we could we write a query against for single."
        ],
        [
            "In points.",
            "I'm saying I will wait, a query will follow."
        ],
        [
            "Being a bushy tree fashion and, well, the problem in this case for answering this query will be to choose the refering operators for evaluating."
        ],
        [
            "Awkward, so for example, choose the high join they had.",
            "Join is a blocking operator that it perform a join in two faces in the first phase they the input is is divided in different partitions, but the answers are produced just all the input is divided.",
            "So in this case, if one of the endpoints becomes unavailable, the answer will the query will timeout without producing any answer, so that the endpoint won't be able to produce any answer, even if we give a time out of 24 hours 45."
        ],
        [
            "Whatever, so consider, for example, this symmetric hash join and the symmetric has young is a nonblocking operator, where a partitions are proving faces are interleaved, so quite a answers could be produced even if the data from the endpoints are not comp."
        ],
        [
            "Pletely receive so that could be a solution to our problem."
        ],
        [
            "But the main problem with this operator is that if the intermediate results are large as possible in this queries against the cloud of Lynn data, main memory failure may occur and the query will fail without producing any answer.",
            "So they symmetrical joint since that."
        ],
        [
            "One work either.",
            "So let's consider the action and the action is an extension of symmetric hashing where."
        ],
        [
            "Also, intermediate results can be produced even if endpoints don't send all the data."
        ],
        [
            "Anne.",
            "If a memory main memory becomes full because the intermediate results are huge.",
            "Do."
        ],
        [
            "This operator is able to flush.",
            "Intermediate resource into secondary memory, so that could solve our problem of having large int."
        ],
        [
            "Immediate results also, even two endpoints stop sending data or becomes block do creator is able to."
        ],
        [
            "Mix to combine results in main memory, which results in secondary memory that will help.",
            "But the problem is that the memory the destructors in main memory are no customers to deal with large intermediate resource and the performance of this query could be very poorly so."
        ],
        [
            "We were used by seeing the limitations of this operator will define our approach and a sip on our challenge where to define physical operators that were able to adapt to the behavior of existing endpoints and the behavioral imitations of these endpoints, and also well established empirically established the behavior of our."
        ],
        [
            "Approach so the agenda today.",
            "Well, I will present an ACIP.",
            "Being medieval will present the operators that we have defined the related work and the angle we observe in our."
        ],
        [
            "Experiment.",
            "So an acid is is being on top of a mediator and grabber architecture where we receive a Sparkle 1.0 queries so the user doesn't have to know anything about the endpoints or the capabilities of these endpoints."
        ],
        [
            "So.",
            "This query is decompose in a square express in Sparkle dot .1 dot 1A for the Federation of Endpoints, and indeed they complete the in the query composer only formation about schema alignments are considered.",
            "We didn't consider any statistics.",
            "We don't consider any cardinality of endpoints, we just consider.",
            "Which are the predicates that are defined by that particular endpoint so.",
            "Additionally, to decompose a query into simple subqueries, a bushy tree is built in a way that this bushy tree minimize.",
            "The size of intermediate results, and we do that by using Harris ticks."
        ],
        [
            "Also."
        ],
        [
            "Beqiri"
        ],
        [
            "We should meet this new query is admitted to this engine that offers a set of physical operators that are able to adapt to the availability of the endpoints and also to the delays of the data transfers.",
            "Also implements on techniques that are able to change this.",
            "Bushy tree, in case that the plan has to be."
        ],
        [
            "Change finally there are some rappers lightweight wrappers that are built around the endpoints and will allow us to gather the data from the endpoints and send data back to the analysis query edge."
        ],
        [
            "In our approach, we propose and a structure called research, join, tuple or RJT, which is comprised of a head and a tail.",
            "The head corresponds to instantiation's of the joint variables of the joint operators and the tail corresponds to the joint topples that match that particular instantiation.",
            "The researcher in trouble are used in our non locking physical operator called."
        ],
        [
            "AG Joint, which is an extension of the X join operator.",
            "The 80 joint maintains two list of research.",
            "Join topples one list for the endpoint A where keeps the top was retrieved from Endpoint B and one list of researching troubles for imprint be where it keeps the top was retrieved from Aimpoint A.",
            "When the operator receives a tuple, for example for an."
        ],
        [
            "From the endpoint a, this tuple is proved against its corresponding list.",
            "In this case, the list is empty, so no output is produced.",
            "Then their tuple is inserted in the list for the."
        ],
        [
            "In point B.",
            "Next, the operator received, for example, the tuple R1B1."
        ],
        [
            "And in this case we can see that there is a match, so the operator produces."
        ],
        [
            "Now put, this is a tuple or one B1 and A1 on the top of receive is a store in the list of the end .8 similarly."
        ],
        [
            "The rest of the outputs are produce."
        ],
        [
            "And the."
        ],
        [
            "Execution of the Angel joint produced their first Aalbers answers very fast because of the design of the resource joint topples."
        ],
        [
            "The execution of the operator AG join is performed in three stages.",
            "The first stage is performed while at least one of the sources is sending data.",
            "The data is stored in main memory's an.",
            "If one of the hashes."
        ],
        [
            "Stable or the list of research attained."
        ],
        [
            "Tables is full and RDT is chosen as a."
        ],
        [
            "Victim unflushed the secondary memory and execution of the stage one continues.",
            "When both sources becomes blocked, the stage two is."
        ],
        [
            "Fire and then this main memory is proved against the secondary memory to excuse me to fund so much is this stage stops when one of the sources become available again and then the execution of the stitch one is performed.",
            "Once again, the execution of the agent joint continues while the the endpoints don't send the EOF when the end of file is received.",
            "This stage three is fire.",
            "And then the main memory is proved against the secondary memory and then secondary memory against secondary memory to produce the final."
        ],
        [
            "Salt the execution of the AG join produces the answer complete and no duplicates are generating during the execution of the sparkle query."
        ],
        [
            "Now I'm going to present some related work.",
            "We have three main topics.",
            "The first one is the linked data query processing and there are several approaches to query the huge graph of the linked data and to retrieve data from this link data datasets.",
            "Some of these strategies are the top down button up and mixed strategies, and there are some several systems that can contact sparkle endpoints as Avalanche on FedEx.",
            "But these approaches are not tolerated to produce adaptive bushy tree."
        ],
        [
            "In the second topic, we have the RDF storage like RDF 3X Bitmap, an Moneta B and this storage have implemented very efficient techniques to storage and access the data with.",
            "The problem with this storage is that the data need to be locally stored to be accessed.",
            "In the third topic, they are query engines that have implemented a sparkle.",
            "Want that one Federation extensions which are able to contact different endpoint in the same query like a arc.",
            "Will.",
            "The problem with this approach is is that they are not very flexible and the users need to specify completely the composition of the subqueries and Mr.",
            "Specify the endpoints that are required to execution of this query."
        ],
        [
            "We conducted a set of experimental study to evaluate the quality of our proposed solution.",
            "We work with three different datasets.",
            "Link sensor data Link City and DV pedia.",
            "And also we define three different benchmarks for these datasets.",
            "We measure the time for the first tuple and a time to produce the whole."
        ],
        [
            "Answer.",
            "The implementation of an apps.",
            "It was in Python And then we implemented an endpoint simulator comprise of servers and proxies to be able to configure the delays in the data transfers and also to configure the size of the message between the sparkle endpoints and the query engines.",
            "All this experiments were run in a dedicated computer.",
            "And also we have studied the behavior of the ARQ Amber to sparkle elements."
        ],
        [
            "In experiment one we evaluate the performance of an obsequy engine against real work.",
            "Again points and 1st.",
            "We evaluate for benchmarks one and three.",
            "And as we can see in this tables in the benchmark one and actually reduced execution time of year 12.",
            "So endpoints by at least one order of magnitude an in the case of the benchmark 3 and now sit could produce the whole answer while benchmark tree in the mental tribute towards the sparkle Aimpoint.",
            "Time out after 24 hours and did not produce any answer."
        ],
        [
            "In benchmark two, we evaluated the performance of Victoza Sparkle endpoints Airku anonops it in this case and actually reduce execution time of ARQ by at least four orders of magnitude and was able to produce the whole answer while they were supposed to sparkle endpoint timeout after 24 hours and once again did not produce any answer."
        ],
        [
            "In the second experiment, we run a set of simulations to be able to configure the delays between the sparkle endpoints and the query engine.",
            "In this case, we run the query in a bushy tree fashion.",
            "First, we evaluated the first time, the first time of the tuple.",
            "Sorry, the time for the first couple.",
            "In this case we miss her for hash joins, symmetric hash join, and an absolute.",
            "And as we can see in both graphics, symmetric hash, Rhiannon, absolute times for the first double are similar in both cases and reduce the time of the execution by up to 70% with respect to the hash joint.",
            "Then we measure the time for producing the whole answer, and in this case has joined Symmetrica, showing an absolute where evaluated and an absolute total time overcomes hash join.",
            "An symmetric has joined by up to 60% and 80% respectively."
        ],
        [
            "In the second simulations, we introduce some delays between the sparkle in points and the query engine, and again we'll run this queries with a bushy tree fashion.",
            "We evaluated the time for the first double for hash join, symmetrical shrine and Anapsid, and as we can see in this graphic, symmetric has shown an upside times for the first table are similar in both cases and reduce the time by up to 70% of hash join.",
            "Then we measure the time for producing the whole answer of the three operators.",
            "And in this case, an absolute total time overcomes the performance of the other operators by up to 60 and 80% respectively.",
            "The performance in this experiment was similar to the performance in the simulations with no delays.",
            "This is because the sub queries that we run had high selectivity an almost all them points answer could be received in few messages.",
            "So is the top of the message size 210 topples."
        ],
        [
            "And in this case we measure the time for the first tuple for hash join, symmetric hash join and an upset, and in this case blocking operator has shown is affected by the delays.",
            "Then we measure the time for producing the whole answer in the free operators.",
            "And we can see the graphic that symmetric hash join a nuff said.",
            "Have a similar behavior and this is because the high selectivity of this occurs makes that the inner structures, the hash tables, and the researcher and tapas were similar.",
            "So in this case both operators are competitive."
        ],
        [
            "Finally, we evaluated the performance of Airku against the three studied operators, and in this case we set up for different types of simulation, one with no delays and the other one we set three different distributions of delays, and in this case they are cute.",
            "Execution time is reduced by up to four orders of magnitude, and this is because a RQ implements and nested loop join blocking operator and its performance is not so good.",
            "I thought symmetric has joined an anapsid times are in the same order of magnitude and absolute reduced symmetric hashing is accused by up to 70%."
        ],
        [
            "So finally the conclusions on the future work.",
            "We presented anapsid and adaptive query processing engine.",
            "Perforation of a sparkle endpoint which is able to adapt query execution and Heights.",
            "Delays from users provides a set of non blocking physical operators on.",
            "Also is able to produce bushy tree plants which reduced the size of the intermediate results.",
            "Also reduce the situation time by up to four orders of magnitudes and produce answer when other engines failed.",
            "And produces the whole answer when other non blocking operator just produce the first double.",
            "In the future, we plan to extend an absolute with routing operators like Eddie Annam join operators and conduct an evaluation study to compare and upset with other link data query engines."
        ],
        [
            "Thank you very much for your attention.",
            "Which are which are the main problems that you found in order to identify which are the queries, the types of queries that you have to use to make this comparison?",
            "Because I mean, I have the impression that we have a lack of I mean benchmarks that we can use for Federated query processing in sparkle.",
            "And I mean I know that there will be, there will be a paper at least being presented in the conference, but I mean, what is your?",
            "Impression or or what you have found.",
            "OK, for for defining the benchmarks we consider real world applications.",
            "We were working on the Link City data and we were trying to identify so relations between the clinical trials so our queries were real queries but we have to consider a complex queries definition.",
            "These queries were complex because the number of patterns graph basic patterns in the query are large.",
            "As you can see in our.",
            "Definition of the benchmarks.",
            "So basically these queries are not simple.",
            "They are complex.",
            "They are comprised of a large number of graph basic patterns.",
            "I also these data sets are quite large, so.",
            "Hello we try to to represent real world."
        ],
        [
            "Queries.",
            "For the real war experiments for the synthetics in experiments we also use this in this real world data sets.",
            "But what we did was to the download data in our simulated and points and we configurate the delays because we want to reproduce the experiment we wanted to wish, be able to reproduce the experiments.",
            "And also to be able to see the effects of a the delays and also the size of the messages.",
            "So that's why we conducted the synthetic experiments.",
            "The cool thing about the web is that we have this real world that we don't control and an in computer science.",
            "We usually always work on one world, which is the computer.",
            "And that's where we observe.",
            "And that's where your experiments.",
            "But now that we're out the web, we have like these two worlds, right?",
            "I can run experiments in my control scenario.",
            "And then present results.",
            "But then these are apparently motivated from something in the real world.",
            "So my question is.",
            "You have great results right now, but if you actually run this on the real world.",
            "Are you what's going to happen?",
            "So do you have plans to do that?",
            "Well, see, we are also showing results."
        ],
        [
            "In real war.",
            "We have real world results, so we run it again.",
            "These real world end points and these are resolved for.",
            "These endpoints were performing as they are, so I also we are building San applications on top of this and accept query engine to identify patterns either in the link sensor data to identify we will show it tonight in the demo.",
            "We have a demo that will show how an acid can be used to identify patterns in weather observation data and to identify say.",
            "Regions in in danger of being risk, so maybe and right now is to use DEF.",
            "We need is a tool to query this endpoints and say to identify patterns either between clinical trials or diseases or between diseases and drugs, or between weather data.",
            "You always expected to Sparkle endpoint, right?",
            "I'm sorry you always expected to sparkle in well, definitely right now we are using a sparkle engines, but if you as far as you have a service that respect the Sparkle protocol, our engine can work well and eventually we could go with other type of data.",
            "It's just like what all of Hartley does with the link traversal, right?",
            "There is no sparkle endpoint exactly exactly.",
            "No, not right now.",
            "We are working with circulating and the name of our project.",
            "This is an attractive solution for sparkle endpoints because issues always we talk about querying linked data, but you can have linked data without sparkle and exactly no, not really.",
            "Right now we have a sparkle endpoints on.",
            "Our solution is customized for sparkle and points where eventually we will go with.",
            "Other type of data where there are no endpoints definitely OK.",
            "I have one question to come back to the workload like the queries.",
            "Could you comment on the predicates?",
            "Which were used for the joint, so as far as I understood you were using mostly same as and related like.",
            "See also or what.",
            "What were the predicates?",
            "No no no in the example that we show what we said is that we set up for the query that we show.",
            "There we set up the expunge parameter.",
            "To retrieve different type of data does OK is here.",
            "I'm sorry, OK."
        ],
        [
            "This is then the setup of a punch parameter is not like we use only those predicates.",
            "See these queries in the query we have.",
            "Any type of predicate is not only those predicates, no.",
            "No in the queries.",
            "Basically we are using all the the predicates in the in the data set.",
            "So to reformulate slightly my question, are there some predicates which are which occur more often than others in the queries?",
            "Like some definitely definitely be causing the cloud of lean data queries that we have the conditions and interventions have more data and more the distribution is different to the distribution of the other product key.",
            "There seems to be a strong connection here between the work you're doing and work on streaming dataflow architectures, and maybe even mentioned the Eddie operator, which I think came from the Berkeley system on Telegraph, so I'm curious if you can sort of relate what you're doing to the previous work on Telegraph.",
            "In those systems that did streaming data flow systems.",
            "Well, right now we're comparing with existing operators in the database area in adaptive.",
            "In the and active query engine.",
            "Existing active query engines, but definitely we will go to compare with respect to other approaches and thus in the future.",
            "OK. OK, so let's thank the speakers again.",
            "Text."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, good afternoon today.",
                    "label": 0
                },
                {
                    "sent": "Maribel Acosta and I will present an acid and acid base and adaptive query processing engine for sparkle endpoints.",
                    "label": 1
                },
                {
                    "sent": "So the model.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Turn off our work is the cloud of in data and what happened to the cloud of in data in the last years.",
                    "label": 0
                },
                {
                    "sent": "So they having an explosion in the number of data sources in the cloud of rain data and so on of these data sources are very very large.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And they are fully connected to many data sources and the point is that for query the cloud of in data this huge graph have to be traverse.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to process queries against the cloud of in data and following the publication guideline of a cloud of Linda, several endpoints have been implemented.",
                    "label": 1
                },
                {
                    "sent": "But the problem with the same points is that many of these endpoints have been designed just for solving very, very simple queries.",
                    "label": 1
                },
                {
                    "sent": "There are just for solving lightweight queries and also because many of these endpoints rely the query.",
                    "label": 0
                },
                {
                    "sent": "Processing in blocking operators.",
                    "label": 0
                },
                {
                    "sent": "They won't be able to produce any answer without reversing the their portion of the huge graph.",
                    "label": 0
                },
                {
                    "sent": "This is required to answer the query.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So do we look today?",
                    "label": 0
                },
                {
                    "sent": "The behavior of these endpoints?",
                    "label": 0
                },
                {
                    "sent": "Let's consider this query where we want to retrieve sensors that sense freezing temperatures in these days.",
                    "label": 1
                },
                {
                    "sent": "So to ever write that query to data sources have to be access.",
                    "label": 1
                },
                {
                    "sent": "One is the link sensor data and the other day geonames.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we should meet at the query against one of these endpoints they built.",
                    "label": 0
                },
                {
                    "sent": "Also in point for the lens sensor data and we set up different values for the Sponge para meter and their answer was that after two NT 4 hours we couldn't get any result.",
                    "label": 0
                },
                {
                    "sent": "So the problem was that even we gave the endpoint 24 hour's to produce and answer them.",
                    "label": 0
                },
                {
                    "sent": "Point was that the endpoint timeout without able to traverse the huge graph that was needed to be traversed to produce the whole answer to the query.",
                    "label": 0
                },
                {
                    "sent": "So the endpoint wasn't able to produce an aquarium up an answer to the query and then produce another answer.",
                    "label": 0
                },
                {
                    "sent": "And reverse at the same time.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's not considered a query where we travel.",
                    "label": 0
                },
                {
                    "sent": "We want to retrieve genes and diseases that have been tested for the drugs that, having established for breaks in breast cancer.",
                    "label": 1
                },
                {
                    "sent": "Clinical trials for answering this query, the lincity.",
                    "label": 0
                },
                {
                    "sent": "This is song on Drugbank data sets have to be.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So send the query to any other available and points and the answer will be empty.",
                    "label": 0
                },
                {
                    "sent": "However, if we download the data sets and locali wrong the query against this huge mix data set, the answer will be will have more than 12,000 topless.",
                    "label": 0
                },
                {
                    "sent": "So the problem here is that these endpoints are just able to traverse.",
                    "label": 0
                },
                {
                    "sent": "They sat graph of a single data set.",
                    "label": 0
                },
                {
                    "sent": "They are not able to jump from one data set to the other.",
                    "label": 0
                },
                {
                    "sent": "So when several endpoints are required, where several data sets are required to be wearing the same points are not able to do it and they will answer a name tions.",
                    "label": 1
                },
                {
                    "sent": "Even if equity is not.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name the answer.",
                    "label": 0
                },
                {
                    "sent": "So while you can say OK, instead of using his particular 1.0, why don't use Sparkle don't want?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Done.",
                    "label": 0
                },
                {
                    "sent": "I rewrite the query into simple subqueries against the different endpoints, so in this case we could we write a query against for single.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In points.",
                    "label": 0
                },
                {
                    "sent": "I'm saying I will wait, a query will follow.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Being a bushy tree fashion and, well, the problem in this case for answering this query will be to choose the refering operators for evaluating.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Awkward, so for example, choose the high join they had.",
                    "label": 0
                },
                {
                    "sent": "Join is a blocking operator that it perform a join in two faces in the first phase they the input is is divided in different partitions, but the answers are produced just all the input is divided.",
                    "label": 0
                },
                {
                    "sent": "So in this case, if one of the endpoints becomes unavailable, the answer will the query will timeout without producing any answer, so that the endpoint won't be able to produce any answer, even if we give a time out of 24 hours 45.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Whatever, so consider, for example, this symmetric hash join and the symmetric has young is a nonblocking operator, where a partitions are proving faces are interleaved, so quite a answers could be produced even if the data from the endpoints are not comp.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pletely receive so that could be a solution to our problem.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the main problem with this operator is that if the intermediate results are large as possible in this queries against the cloud of Lynn data, main memory failure may occur and the query will fail without producing any answer.",
                    "label": 0
                },
                {
                    "sent": "So they symmetrical joint since that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One work either.",
                    "label": 0
                },
                {
                    "sent": "So let's consider the action and the action is an extension of symmetric hashing where.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, intermediate results can be produced even if endpoints don't send all the data.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "If a memory main memory becomes full because the intermediate results are huge.",
                    "label": 0
                },
                {
                    "sent": "Do.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This operator is able to flush.",
                    "label": 0
                },
                {
                    "sent": "Intermediate resource into secondary memory, so that could solve our problem of having large int.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Immediate results also, even two endpoints stop sending data or becomes block do creator is able to.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mix to combine results in main memory, which results in secondary memory that will help.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that the memory the destructors in main memory are no customers to deal with large intermediate resource and the performance of this query could be very poorly so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We were used by seeing the limitations of this operator will define our approach and a sip on our challenge where to define physical operators that were able to adapt to the behavior of existing endpoints and the behavioral imitations of these endpoints, and also well established empirically established the behavior of our.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approach so the agenda today.",
                    "label": 0
                },
                {
                    "sent": "Well, I will present an ACIP.",
                    "label": 0
                },
                {
                    "sent": "Being medieval will present the operators that we have defined the related work and the angle we observe in our.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Experiment.",
                    "label": 0
                },
                {
                    "sent": "So an acid is is being on top of a mediator and grabber architecture where we receive a Sparkle 1.0 queries so the user doesn't have to know anything about the endpoints or the capabilities of these endpoints.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This query is decompose in a square express in Sparkle dot .1 dot 1A for the Federation of Endpoints, and indeed they complete the in the query composer only formation about schema alignments are considered.",
                    "label": 0
                },
                {
                    "sent": "We didn't consider any statistics.",
                    "label": 0
                },
                {
                    "sent": "We don't consider any cardinality of endpoints, we just consider.",
                    "label": 0
                },
                {
                    "sent": "Which are the predicates that are defined by that particular endpoint so.",
                    "label": 0
                },
                {
                    "sent": "Additionally, to decompose a query into simple subqueries, a bushy tree is built in a way that this bushy tree minimize.",
                    "label": 0
                },
                {
                    "sent": "The size of intermediate results, and we do that by using Harris ticks.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Beqiri",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We should meet this new query is admitted to this engine that offers a set of physical operators that are able to adapt to the availability of the endpoints and also to the delays of the data transfers.",
                    "label": 0
                },
                {
                    "sent": "Also implements on techniques that are able to change this.",
                    "label": 0
                },
                {
                    "sent": "Bushy tree, in case that the plan has to be.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Change finally there are some rappers lightweight wrappers that are built around the endpoints and will allow us to gather the data from the endpoints and send data back to the analysis query edge.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In our approach, we propose and a structure called research, join, tuple or RJT, which is comprised of a head and a tail.",
                    "label": 1
                },
                {
                    "sent": "The head corresponds to instantiation's of the joint variables of the joint operators and the tail corresponds to the joint topples that match that particular instantiation.",
                    "label": 0
                },
                {
                    "sent": "The researcher in trouble are used in our non locking physical operator called.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "AG Joint, which is an extension of the X join operator.",
                    "label": 0
                },
                {
                    "sent": "The 80 joint maintains two list of research.",
                    "label": 0
                },
                {
                    "sent": "Join topples one list for the endpoint A where keeps the top was retrieved from Endpoint B and one list of researching troubles for imprint be where it keeps the top was retrieved from Aimpoint A.",
                    "label": 1
                },
                {
                    "sent": "When the operator receives a tuple, for example for an.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the endpoint a, this tuple is proved against its corresponding list.",
                    "label": 0
                },
                {
                    "sent": "In this case, the list is empty, so no output is produced.",
                    "label": 0
                },
                {
                    "sent": "Then their tuple is inserted in the list for the.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In point B.",
                    "label": 0
                },
                {
                    "sent": "Next, the operator received, for example, the tuple R1B1.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this case we can see that there is a match, so the operator produces.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now put, this is a tuple or one B1 and A1 on the top of receive is a store in the list of the end .8 similarly.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The rest of the outputs are produce.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Execution of the Angel joint produced their first Aalbers answers very fast because of the design of the resource joint topples.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The execution of the operator AG join is performed in three stages.",
                    "label": 0
                },
                {
                    "sent": "The first stage is performed while at least one of the sources is sending data.",
                    "label": 0
                },
                {
                    "sent": "The data is stored in main memory's an.",
                    "label": 0
                },
                {
                    "sent": "If one of the hashes.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stable or the list of research attained.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tables is full and RDT is chosen as a.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Victim unflushed the secondary memory and execution of the stage one continues.",
                    "label": 0
                },
                {
                    "sent": "When both sources becomes blocked, the stage two is.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fire and then this main memory is proved against the secondary memory to excuse me to fund so much is this stage stops when one of the sources become available again and then the execution of the stitch one is performed.",
                    "label": 0
                },
                {
                    "sent": "Once again, the execution of the agent joint continues while the the endpoints don't send the EOF when the end of file is received.",
                    "label": 0
                },
                {
                    "sent": "This stage three is fire.",
                    "label": 0
                },
                {
                    "sent": "And then the main memory is proved against the secondary memory and then secondary memory against secondary memory to produce the final.",
                    "label": 1
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Salt the execution of the AG join produces the answer complete and no duplicates are generating during the execution of the sparkle query.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'm going to present some related work.",
                    "label": 0
                },
                {
                    "sent": "We have three main topics.",
                    "label": 0
                },
                {
                    "sent": "The first one is the linked data query processing and there are several approaches to query the huge graph of the linked data and to retrieve data from this link data datasets.",
                    "label": 0
                },
                {
                    "sent": "Some of these strategies are the top down button up and mixed strategies, and there are some several systems that can contact sparkle endpoints as Avalanche on FedEx.",
                    "label": 0
                },
                {
                    "sent": "But these approaches are not tolerated to produce adaptive bushy tree.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the second topic, we have the RDF storage like RDF 3X Bitmap, an Moneta B and this storage have implemented very efficient techniques to storage and access the data with.",
                    "label": 0
                },
                {
                    "sent": "The problem with this storage is that the data need to be locally stored to be accessed.",
                    "label": 0
                },
                {
                    "sent": "In the third topic, they are query engines that have implemented a sparkle.",
                    "label": 0
                },
                {
                    "sent": "Want that one Federation extensions which are able to contact different endpoint in the same query like a arc.",
                    "label": 0
                },
                {
                    "sent": "Will.",
                    "label": 0
                },
                {
                    "sent": "The problem with this approach is is that they are not very flexible and the users need to specify completely the composition of the subqueries and Mr.",
                    "label": 0
                },
                {
                    "sent": "Specify the endpoints that are required to execution of this query.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We conducted a set of experimental study to evaluate the quality of our proposed solution.",
                    "label": 0
                },
                {
                    "sent": "We work with three different datasets.",
                    "label": 0
                },
                {
                    "sent": "Link sensor data Link City and DV pedia.",
                    "label": 0
                },
                {
                    "sent": "And also we define three different benchmarks for these datasets.",
                    "label": 0
                },
                {
                    "sent": "We measure the time for the first tuple and a time to produce the whole.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Answer.",
                    "label": 0
                },
                {
                    "sent": "The implementation of an apps.",
                    "label": 0
                },
                {
                    "sent": "It was in Python And then we implemented an endpoint simulator comprise of servers and proxies to be able to configure the delays in the data transfers and also to configure the size of the message between the sparkle endpoints and the query engines.",
                    "label": 0
                },
                {
                    "sent": "All this experiments were run in a dedicated computer.",
                    "label": 0
                },
                {
                    "sent": "And also we have studied the behavior of the ARQ Amber to sparkle elements.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In experiment one we evaluate the performance of an obsequy engine against real work.",
                    "label": 0
                },
                {
                    "sent": "Again points and 1st.",
                    "label": 0
                },
                {
                    "sent": "We evaluate for benchmarks one and three.",
                    "label": 0
                },
                {
                    "sent": "And as we can see in this tables in the benchmark one and actually reduced execution time of year 12.",
                    "label": 0
                },
                {
                    "sent": "So endpoints by at least one order of magnitude an in the case of the benchmark 3 and now sit could produce the whole answer while benchmark tree in the mental tribute towards the sparkle Aimpoint.",
                    "label": 0
                },
                {
                    "sent": "Time out after 24 hours and did not produce any answer.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In benchmark two, we evaluated the performance of Victoza Sparkle endpoints Airku anonops it in this case and actually reduce execution time of ARQ by at least four orders of magnitude and was able to produce the whole answer while they were supposed to sparkle endpoint timeout after 24 hours and once again did not produce any answer.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the second experiment, we run a set of simulations to be able to configure the delays between the sparkle endpoints and the query engine.",
                    "label": 1
                },
                {
                    "sent": "In this case, we run the query in a bushy tree fashion.",
                    "label": 0
                },
                {
                    "sent": "First, we evaluated the first time, the first time of the tuple.",
                    "label": 1
                },
                {
                    "sent": "Sorry, the time for the first couple.",
                    "label": 0
                },
                {
                    "sent": "In this case we miss her for hash joins, symmetric hash join, and an absolute.",
                    "label": 0
                },
                {
                    "sent": "And as we can see in both graphics, symmetric hash, Rhiannon, absolute times for the first double are similar in both cases and reduce the time of the execution by up to 70% with respect to the hash joint.",
                    "label": 0
                },
                {
                    "sent": "Then we measure the time for producing the whole answer, and in this case has joined Symmetrica, showing an absolute where evaluated and an absolute total time overcomes hash join.",
                    "label": 0
                },
                {
                    "sent": "An symmetric has joined by up to 60% and 80% respectively.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the second simulations, we introduce some delays between the sparkle in points and the query engine, and again we'll run this queries with a bushy tree fashion.",
                    "label": 1
                },
                {
                    "sent": "We evaluated the time for the first double for hash join, symmetrical shrine and Anapsid, and as we can see in this graphic, symmetric has shown an upside times for the first table are similar in both cases and reduce the time by up to 70% of hash join.",
                    "label": 0
                },
                {
                    "sent": "Then we measure the time for producing the whole answer of the three operators.",
                    "label": 0
                },
                {
                    "sent": "And in this case, an absolute total time overcomes the performance of the other operators by up to 60 and 80% respectively.",
                    "label": 1
                },
                {
                    "sent": "The performance in this experiment was similar to the performance in the simulations with no delays.",
                    "label": 0
                },
                {
                    "sent": "This is because the sub queries that we run had high selectivity an almost all them points answer could be received in few messages.",
                    "label": 0
                },
                {
                    "sent": "So is the top of the message size 210 topples.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in this case we measure the time for the first tuple for hash join, symmetric hash join and an upset, and in this case blocking operator has shown is affected by the delays.",
                    "label": 1
                },
                {
                    "sent": "Then we measure the time for producing the whole answer in the free operators.",
                    "label": 0
                },
                {
                    "sent": "And we can see the graphic that symmetric hash join a nuff said.",
                    "label": 0
                },
                {
                    "sent": "Have a similar behavior and this is because the high selectivity of this occurs makes that the inner structures, the hash tables, and the researcher and tapas were similar.",
                    "label": 0
                },
                {
                    "sent": "So in this case both operators are competitive.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, we evaluated the performance of Airku against the three studied operators, and in this case we set up for different types of simulation, one with no delays and the other one we set three different distributions of delays, and in this case they are cute.",
                    "label": 1
                },
                {
                    "sent": "Execution time is reduced by up to four orders of magnitude, and this is because a RQ implements and nested loop join blocking operator and its performance is not so good.",
                    "label": 1
                },
                {
                    "sent": "I thought symmetric has joined an anapsid times are in the same order of magnitude and absolute reduced symmetric hashing is accused by up to 70%.",
                    "label": 1
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So finally the conclusions on the future work.",
                    "label": 0
                },
                {
                    "sent": "We presented anapsid and adaptive query processing engine.",
                    "label": 0
                },
                {
                    "sent": "Perforation of a sparkle endpoint which is able to adapt query execution and Heights.",
                    "label": 0
                },
                {
                    "sent": "Delays from users provides a set of non blocking physical operators on.",
                    "label": 0
                },
                {
                    "sent": "Also is able to produce bushy tree plants which reduced the size of the intermediate results.",
                    "label": 0
                },
                {
                    "sent": "Also reduce the situation time by up to four orders of magnitudes and produce answer when other engines failed.",
                    "label": 0
                },
                {
                    "sent": "And produces the whole answer when other non blocking operator just produce the first double.",
                    "label": 0
                },
                {
                    "sent": "In the future, we plan to extend an absolute with routing operators like Eddie Annam join operators and conduct an evaluation study to compare and upset with other link data query engines.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 0
                },
                {
                    "sent": "Which are which are the main problems that you found in order to identify which are the queries, the types of queries that you have to use to make this comparison?",
                    "label": 0
                },
                {
                    "sent": "Because I mean, I have the impression that we have a lack of I mean benchmarks that we can use for Federated query processing in sparkle.",
                    "label": 0
                },
                {
                    "sent": "And I mean I know that there will be, there will be a paper at least being presented in the conference, but I mean, what is your?",
                    "label": 0
                },
                {
                    "sent": "Impression or or what you have found.",
                    "label": 0
                },
                {
                    "sent": "OK, for for defining the benchmarks we consider real world applications.",
                    "label": 0
                },
                {
                    "sent": "We were working on the Link City data and we were trying to identify so relations between the clinical trials so our queries were real queries but we have to consider a complex queries definition.",
                    "label": 0
                },
                {
                    "sent": "These queries were complex because the number of patterns graph basic patterns in the query are large.",
                    "label": 0
                },
                {
                    "sent": "As you can see in our.",
                    "label": 0
                },
                {
                    "sent": "Definition of the benchmarks.",
                    "label": 0
                },
                {
                    "sent": "So basically these queries are not simple.",
                    "label": 0
                },
                {
                    "sent": "They are complex.",
                    "label": 0
                },
                {
                    "sent": "They are comprised of a large number of graph basic patterns.",
                    "label": 0
                },
                {
                    "sent": "I also these data sets are quite large, so.",
                    "label": 0
                },
                {
                    "sent": "Hello we try to to represent real world.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Queries.",
                    "label": 0
                },
                {
                    "sent": "For the real war experiments for the synthetics in experiments we also use this in this real world data sets.",
                    "label": 0
                },
                {
                    "sent": "But what we did was to the download data in our simulated and points and we configurate the delays because we want to reproduce the experiment we wanted to wish, be able to reproduce the experiments.",
                    "label": 0
                },
                {
                    "sent": "And also to be able to see the effects of a the delays and also the size of the messages.",
                    "label": 0
                },
                {
                    "sent": "So that's why we conducted the synthetic experiments.",
                    "label": 0
                },
                {
                    "sent": "The cool thing about the web is that we have this real world that we don't control and an in computer science.",
                    "label": 0
                },
                {
                    "sent": "We usually always work on one world, which is the computer.",
                    "label": 0
                },
                {
                    "sent": "And that's where we observe.",
                    "label": 0
                },
                {
                    "sent": "And that's where your experiments.",
                    "label": 0
                },
                {
                    "sent": "But now that we're out the web, we have like these two worlds, right?",
                    "label": 0
                },
                {
                    "sent": "I can run experiments in my control scenario.",
                    "label": 0
                },
                {
                    "sent": "And then present results.",
                    "label": 0
                },
                {
                    "sent": "But then these are apparently motivated from something in the real world.",
                    "label": 0
                },
                {
                    "sent": "So my question is.",
                    "label": 0
                },
                {
                    "sent": "You have great results right now, but if you actually run this on the real world.",
                    "label": 0
                },
                {
                    "sent": "Are you what's going to happen?",
                    "label": 0
                },
                {
                    "sent": "So do you have plans to do that?",
                    "label": 0
                },
                {
                    "sent": "Well, see, we are also showing results.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In real war.",
                    "label": 0
                },
                {
                    "sent": "We have real world results, so we run it again.",
                    "label": 0
                },
                {
                    "sent": "These real world end points and these are resolved for.",
                    "label": 0
                },
                {
                    "sent": "These endpoints were performing as they are, so I also we are building San applications on top of this and accept query engine to identify patterns either in the link sensor data to identify we will show it tonight in the demo.",
                    "label": 0
                },
                {
                    "sent": "We have a demo that will show how an acid can be used to identify patterns in weather observation data and to identify say.",
                    "label": 0
                },
                {
                    "sent": "Regions in in danger of being risk, so maybe and right now is to use DEF.",
                    "label": 0
                },
                {
                    "sent": "We need is a tool to query this endpoints and say to identify patterns either between clinical trials or diseases or between diseases and drugs, or between weather data.",
                    "label": 0
                },
                {
                    "sent": "You always expected to Sparkle endpoint, right?",
                    "label": 0
                },
                {
                    "sent": "I'm sorry you always expected to sparkle in well, definitely right now we are using a sparkle engines, but if you as far as you have a service that respect the Sparkle protocol, our engine can work well and eventually we could go with other type of data.",
                    "label": 0
                },
                {
                    "sent": "It's just like what all of Hartley does with the link traversal, right?",
                    "label": 0
                },
                {
                    "sent": "There is no sparkle endpoint exactly exactly.",
                    "label": 0
                },
                {
                    "sent": "No, not right now.",
                    "label": 0
                },
                {
                    "sent": "We are working with circulating and the name of our project.",
                    "label": 0
                },
                {
                    "sent": "This is an attractive solution for sparkle endpoints because issues always we talk about querying linked data, but you can have linked data without sparkle and exactly no, not really.",
                    "label": 0
                },
                {
                    "sent": "Right now we have a sparkle endpoints on.",
                    "label": 0
                },
                {
                    "sent": "Our solution is customized for sparkle and points where eventually we will go with.",
                    "label": 0
                },
                {
                    "sent": "Other type of data where there are no endpoints definitely OK.",
                    "label": 0
                },
                {
                    "sent": "I have one question to come back to the workload like the queries.",
                    "label": 0
                },
                {
                    "sent": "Could you comment on the predicates?",
                    "label": 0
                },
                {
                    "sent": "Which were used for the joint, so as far as I understood you were using mostly same as and related like.",
                    "label": 0
                },
                {
                    "sent": "See also or what.",
                    "label": 0
                },
                {
                    "sent": "What were the predicates?",
                    "label": 0
                },
                {
                    "sent": "No no no in the example that we show what we said is that we set up for the query that we show.",
                    "label": 0
                },
                {
                    "sent": "There we set up the expunge parameter.",
                    "label": 0
                },
                {
                    "sent": "To retrieve different type of data does OK is here.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, OK.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is then the setup of a punch parameter is not like we use only those predicates.",
                    "label": 0
                },
                {
                    "sent": "See these queries in the query we have.",
                    "label": 0
                },
                {
                    "sent": "Any type of predicate is not only those predicates, no.",
                    "label": 0
                },
                {
                    "sent": "No in the queries.",
                    "label": 0
                },
                {
                    "sent": "Basically we are using all the the predicates in the in the data set.",
                    "label": 0
                },
                {
                    "sent": "So to reformulate slightly my question, are there some predicates which are which occur more often than others in the queries?",
                    "label": 0
                },
                {
                    "sent": "Like some definitely definitely be causing the cloud of lean data queries that we have the conditions and interventions have more data and more the distribution is different to the distribution of the other product key.",
                    "label": 0
                },
                {
                    "sent": "There seems to be a strong connection here between the work you're doing and work on streaming dataflow architectures, and maybe even mentioned the Eddie operator, which I think came from the Berkeley system on Telegraph, so I'm curious if you can sort of relate what you're doing to the previous work on Telegraph.",
                    "label": 0
                },
                {
                    "sent": "In those systems that did streaming data flow systems.",
                    "label": 0
                },
                {
                    "sent": "Well, right now we're comparing with existing operators in the database area in adaptive.",
                    "label": 0
                },
                {
                    "sent": "In the and active query engine.",
                    "label": 0
                },
                {
                    "sent": "Existing active query engines, but definitely we will go to compare with respect to other approaches and thus in the future.",
                    "label": 0
                },
                {
                    "sent": "OK. OK, so let's thank the speakers again.",
                    "label": 0
                },
                {
                    "sent": "Text.",
                    "label": 0
                }
            ]
        }
    }
}