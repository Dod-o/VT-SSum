{
    "id": "5lxppanuk5df7dwu2va653jxnu45prra",
    "title": "Machine Learning",
    "info": {
        "author": [
            "Doina Precup, School of Computer Science, McGill University"
        ],
        "published": "Aug. 23, 2016",
        "recorded": "August 2016",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2016_precup_machine_learning/",
    "segmentation": [
        [
            "So I was asked to sort of do a broad introduction to machine learning just to make sure that everybody's on the same page.",
            "If you've taken the machine learning class before, you would have seen many of these topics, but I hope you can still get a little bit of a refresher and."
        ],
        [
            "And get something out of this.",
            "So the plan for today is we're going to talk a little bit about the types of machine learning problems that exist.",
            "We're going to talk about linear approximation, objective functions, chosen different ways of optimizing these.",
            "We're going to discuss bias variance, overfitting, and underfitting and regularization, and one of the threads is going to be that we're going to talk about probabilistic interpretations of these methods because the probabilistic interpretations really allow us to ground the algorithms and to understand.",
            "What they do?",
            "They don't necessarily always give us the best algorithms, but they give us sort of a good understanding.",
            "So machine."
        ],
        [
            "Running is very broad as as you know, there's sort of three different types of machine learning problems.",
            "Supervised learning and unsupervised learning is what you hear about most of the time reinforcement learning as you mentioned is on the rise, and there's going to be a day dedicated to it."
        ],
        [
            "Towards the end of the week.",
            "Supervised learning is perhaps the standard thing that you're used to.",
            "You have examples with some inputs and some desired output.",
            "You get a set of these examples and what you're trying to do is learn a function that Maps inputs into output of this type.",
            "And the goal is to obtain such a function in order to minimize loss or to optimize some kind of objective.",
            "And we're going to be talking about what kinds of objectives might be good to optimize.",
            "An ideally when you do the optimization, you would like it to work well on all the possible instances on the distribution of instances that are out there.",
            "Unfortunately, you don't have access to this distribution, you only have access to a finite sample of data, and so a lot of the problems that arise and that we need to handle are sort of driven by the fact that only a finite sample of data is available and we need to sort of make do."
        ],
        [
            "With that so this is typical example of supervised learning.",
            "You have some images you'd like to learn a system that can do face detection and face recognition based on examples of images where there might be faces.",
            "There might be multiple faces and so on."
        ],
        [
            "Reinforcement learning is a little bit of a different problem, where the signal that you get is not as strong.",
            "So basically you get some training experience by interacting with an environment.",
            "Maybe you have a stock market agent that's on the market.",
            "It observes values of different stocks, and it can make trades, and it can make investments so it can do things.",
            "It has some actions that are available to it, and there's a reward signal that comes back.",
            "For example, the agent might be making money or losing money, so it might be getting positive rewards and negative rewards.",
            "However, there's never.",
            "Direct Association between the action that's just been done and the reward that's that's given, and the reward may well be delayed, and that's sort of what makes this problem quite interesting."
        ],
        [
            "This is a cartoon of an early reinforcement learning signal, a system that was done by Jerry Tesoro in the early 90s.",
            "This is think of this as an early precursor to Alpha go.",
            "This is a system that learned by interacting with itself by playing lots of games and became the best player in the world at TD Gammon.",
            "So I'm not going to say anymore about that because we're going to have a lot on reinforcement learning."
        ],
        [
            "On Friday.",
            "Unsupervised learning is perhaps the trickiest problem to formulate.",
            "You have training experience in the form of unlabeled data.",
            "Just stuff out there and your goal is to find some kind of structure.",
            "So clustering, algorithms, dimensionality reduction algorithms, algorithms that try to get that latent variables in the data, all kind of fall into this category, and we often don't have one single correct answer which makes this problem slightly more difficult.",
            "So again, there's going to be discussion during the week.",
            "Of different algorithms that do once."
        ],
        [
            "Supervised learning this is just an example that I thought I'd show you of sort of interesting supervised learning going on.",
            "This is a cancer data set.",
            "Genes are measured and then you do cluster analysis in order to determine if there are certain clusters that are correlated together and the interesting thing here is that even though you do this unsupervised, what comes out as correlation with clinical outcomes that was not known before."
        ],
        [
            "Anne.",
            "So that's about the types of machine learning.",
            "Now we're going to start introducing a little bit of notation and discussing sort of the broad topics.",
            "This is an example of a data set.",
            "This is the Wisconsin breast cancer data set, so it's images of pathology that have been sort of segmented by an expert and the first question that comes up when you're faced with a data set like this is what kind of input representation do we want to have?",
            "You could be working with the image and the pixels in the image.",
            "You could do some image feature extraction.",
            "Or you could do something."
        ],
        [
            "More complicated like talk to the expert and actually get some features that the expert nodes are important.",
            "OK, so in this case we have some features that have been extracted that are measurements on the different parts of the image.",
            "And we have some desired outputs that we're trying to predict.",
            "In this case, there's two outputs.",
            "One is the outcome.",
            "Does the cancer recur or not, and then the other one is.",
            "If the cancer recurs, what's the time until that happens?",
            "So in general, the output the desired output that we're trying to predict could be discrete, or it could be continuous, or in fact could be more complicated than that.",
            "Could be something like a tree or a graph, and so on."
        ],
        [
            "So just in terms of terminology, when when you're faced with a table of data like this, we often call these columns input variables or features or attributes.",
            "We call these columns here that we're trying to predict output variables or targets, and each of these rows in as an example, or an instance, and in this case we're looking at two specific problems which are kind of easier to understand and to work with.",
            "One is a problem of binary classification.",
            "The re kernel recur label.",
            "And then the other one is regression, so we're just trying to predict the array."
        ],
        [
            "Number there.",
            "And I'm always going to use access to denote the inputs and why student out the outputs.",
            "And I think this will be consistent in the follow up talk as well.",
            "And very often we think of this here as a matrix of data.",
            "Big X. OK, that has number instances by number of columns and then the output.",
            "You can think of them as a vector Y and so the bold denotes matrix."
        ],
        [
            "Convectors so now we get to the supervised learning problem.",
            "What we want is to learn a mapping from X to Y.",
            "We're going to call such a mapping of hypothesis and we would like this to be a good predictor of the output, and this could be called classification or regression or structured prediction in more complicated cases."
        ],
        [
            "And we've already kind of decided on what the input set space would be.",
            "We've decided on the output space.",
            "Now we're choosing a class of hypothesis or representations."
        ],
        [
            "These functions H and so this is a sort of cartoon example.",
            "If I have some points, the simplest thing that we can."
        ],
        [
            "Think of is to put a line through these."
        ],
        [
            "Point OK, so here is a linear hypothesis H. the W means that there is a parameter vector W that is sort of defining this hypothesis and we have inputs and so in this case we just have a linear combination of the of the inputs weighted by these parameters or weights, and what we would like our algorithm to do is to determine the best weight vector.",
            "OK."
        ],
        [
            "So now how should we pick this weight vector?",
            "Well, we should pick it in such a way as to get a good fit to the data.",
            "So now we need to formalize what does that mean and that we do this using an error function or a cost function or loss function.",
            "OK?",
            "Or sometimes people call this the optimization objective, in which case you can talk about either loss or sort of the quality update."
        ],
        [
            "And as I'm sure you know, one of the standard things that people do is to use the sum of squared error or the mean squared error as the objective which is depicted here.",
            "This is just measuring the difference between the output of the hypothesis and the actual output observed in the data.",
            "You squared this up and there is a lot of nice reasons why this is kind of a good error function when you're trying to do regression, we're going to talk a little bit about the probabilistic assumptions about this in a minute.",
            "But"
        ],
        [
            "For now, let's just sort of stick with this and say OK. Now we have this.",
            "This error function.",
            "We have our hypothesis class.",
            "What we need to do is to search within the hypothesis class for the best hypothesis.",
            "According to this error function.",
            "OK, so we chose a hypothesis.",
            "We chose an objective and now we need to optimize that objective and we need to see how we can do that."
        ],
        [
            "And one of the things that you're going to see a lot during this week is the use of gradient based methods.",
            "In order to do this optimization.",
            "So just like a refresher reminder can take partial derivatives of a function, you can take a gradient.",
            "The gradient is just a vector of partial derivatives, and so a standard way to do the optimization is to take the gradient and set it to 0 and that will give you extreme points."
        ],
        [
            "Of the function.",
            "So in our case we have an objective function JFW OK depends on the parameter vector W. We can take the derivative of this.",
            "We can take the gradient in this case because we have such a simple function and a simple objective.",
            "You can solve this in closed form, not."
        ],
        [
            "Go through the algebra and you can get sort of the best value of the parameter vector W and it's got a nice closed form solution in terms of the input and the output.",
            "OK, and this is all good.",
            "The solution exists is unique if the columns of X are linearly independent.",
            "There are several problems with going this route.",
            "OK, one is that you might have lots and lots of data, so doing this kind of matrix inversion may actually not be feasable.",
            "Another problem is that maybe your matrix is actually ill conditioned.",
            "OK, and the more fundamental problem is that we've used a very, very simple hypothesis space.",
            "OK, so this is the one happy case where you can solve things in closed form.",
            "That's great most of the time we won't be able to do things like this.",
            "But this is just to give you a warm fuzzy feeling that sometimes it does work OK."
        ],
        [
            "Anne."
        ],
        [
            "OK, so in general this is a very sort of simple kind of hypothesis space.",
            "So what do we do to make this more interesting?",
            "Well, we use a transformation of the input using nonlinear features.",
            "OK, and this case is basically almost the same.",
            "We use a matrix Phi here to denote the features.",
            "So the way you think about it is that you can take the input and map it through a function Phi into some kind of space that you want.",
            "And now you have a lot of choices about what fine might be reduced polynomials.",
            "You could use Gaussians, sigmoids, Boolean combinations if you have binary features, lots of different things and depending on the feature space you will get more complicated hypothesis or more simple hypothesis.",
            "These are still all linear hypothesis, not in the input, but in terms of the parameter vector W. So if we look at the hypothesis function.",
            "H It's a linear function of W, even though it's not a linear function of the input, and that means that the optimization is still going to be quite easy to do, and we still get a closed form."
        ],
        [
            "Cat.",
            "Anne.",
            "So the other thing that I would like to point out is that in these sort of."
        ],
        [
            "Linear models we actually fix.",
            "What the basis functions are.",
            "OK, so you decide ahead of time you want to take the inputs and take polynomials up to degree two OK. Or you decide you want to take Gaussians and you want to take them regularly spaced with certain means and certain variances, and there's a fixed number of basis functions that does not depend on how much data you actually have.",
            "OK, so that's the flavor of what we call parametric methods parametric methods.",
            "Have a fixed size parameter vector the size of that parameter vector is decided ahead of time and the basis functions are fixed.",
            "Only the parameters are moving.",
            "There are other kinds of methods.",
            "Nonparametric methods allow the representation to grow with the size of the data.",
            "So nearest neighbor methods for example, or certain forms of locally weighted regression are nonparametric methods.",
            "I'm not really going to be talking about that.",
            "In this talk, the deepnet methods that you're going to hear a lot about in this week are essentially parametric methods, but with very very large sets of parameters.",
            "OK, and any questions or comments so far.",
            "Like good OK?",
            "So now let's look."
        ],
        [
            "Look at the problem that's created by the fact that we have sort of fixed size hypothesis that may somehow reflect or not what we have in the data.",
            "So we have a set of data.",
            "OK, the blue points there are data points, and now we're doing some fits through these data points.",
            "OK, so here we fit an order two polynomial.",
            "You can see that it looks pretty good.",
            "OK goes pretty close to the points, OK?"
        ],
        [
            "And we could do an order 3 fit.",
            "OK."
        ],
        [
            "Or an order for fit."
        ],
        [
            "Or in order 5."
        ],
        [
            "And."
        ],
        [
            "6."
        ],
        [
            "Go on OK.",
            "Which of these is the best 5th to the data?",
            "Is it this one?"
        ],
        [
            "With this said, this is what you mean by fifth.",
            "So that's part of the problem.",
            "Depends what we mean by fit to the data OK?",
            "So what can we mean?",
            "Well, one thing we could mean is what's the error on the training set that we're using OK and we can do something really good on the train."
        ],
        [
            "Things that we can do this OK?",
            "We can actually find high enough degree polynomial that will exactly fit the training set and the error on the training set is zero OK. Is this a good fit to the data?",
            "Well, sort of.",
            "Our intuition says no, OK, why?",
            "Because it's very wild.",
            "OK, it goes through the points, but it seems to have no rhyme or reason.",
            "In other words, we're not confident that this kind of fit actually generalizes from the training data that we have to new data that we might see in the future.",
            "OK, probably some."
        ],
        [
            "Other things you know?",
            "Maybe order to order three might actually be better.",
            "OK, so this points to a problem of a mismatch between what we would like to measure in the objective of the optimization and what we can actually measure.",
            "OK, what we?"
        ],
        [
            "Would like to do.",
            "Is to measure the true error on the whole distribution of the data, but we don't have access to that.",
            "We only have access to a finite sample.",
            "As a result, we can only measure things on that finite sample of data.",
            "OK, now if all we do is train and test on the same sample of data, then we're going to run into trouble.",
            "OK, we essentially get."
        ],
        [
            "Solutions that look like this, where we have, you know, the training data fit perfectly, but not really good hypothesis, not hypothesis that generalize well."
        ],
        [
            "So this is a really, really important problem and all of machine learning called overfitting.",
            "And it basically means that we find the hypothesis that fits the training data very well, but does not generalize well to unseen examples and essentially the nature of this comes from having too many parameters for how much data we have.",
            "Again, we're going to make this a little bit more formal now.",
            "A lot of the stuff that you're going to hear during the week is methods to get around this problem.",
            "When you do have.",
            "Of parameters and not very much training data."
        ],
        [
            "So this is another example of the picture taken from Bishop's book of different hypothesis fit through these blue circles.",
            "OK, here we have one specific function.",
            "That's the green function.",
            "That's sort of the true function.",
            "The points were generated by applying a little bit of noise to that function, and then we do fit a various degrees of polynomials, and as you can see.",
            "If your degree is too small, OK, basically can't fit the data.",
            "That's called underfitting.",
            "OK, it means that your hypothesis space is too simple and you cannot represent the true function, doesn't allow you to represent the true function.",
            "If you have a hypothesis space that's too complicated, like the degree 9 polynomials over here, you have the overfitting problem that you have just seen.",
            "In other words, you can represent perfectly the training data.",
            "You can in fact memorize it because you have enough parameters to memorize it, but there's no generalization OK, and So what we would like to have is the learning method that goes in between and finds the right complexity of the hypothesis, and so now we're going to have to talk about."
        ],
        [
            "How to do that?",
            "So this is just to give you the definition of overfitting a little bit more formally.",
            "OK, so in general we have for any hypothesis a true error, which we did not buy.",
            "J Star J Star is the expected error when the data comes from the true distribution OK?",
            "But we don't have all the data.",
            "OK, So what do we do?",
            "We get a sample of data Big D. That's our data set.",
            "And so we estimate this true error by a finite sample.",
            "OK, now the problem is that if we use this finite sample both to find the hypothesis and to estimate the error, we might be fooling ourselves so we can be in a situation where we find a hypothesis that's better on the data set that we have.",
            "That, but which is actually worse when we look at the entire data set, and so we need theoretical and empirical methods to guard against this, we're going to talk a little bit about cross validation and about regularization as two different ways of doing."
        ],
        [
            "This.",
            "How do you know if you have a problem?",
            "Well, this is a typical plot that you might see when you have a hypothesis space and you have a complexity parameter over here.",
            "OK, so here we're going from simple hypothesis on that side to more complicated hypothesis going this way, and you have the error and you are measuring the error now on two different datasets.",
            "OK, the training data set is the one that's used to obtain the parameters of the hypothesis.",
            "And the test set is a test is a set of data that's not been used during the training process or has been untouched in the training.",
            "So this is a fairly typical graph where you see the training error going down as the complexity of the hypothesis increases, and then you see this U shaped curved in the test error where the test error starts high and then goes down to some good level and then goes up again.",
            "OK so on that end of the spectrum.",
            "OK when you have very simple hypothesis you're essentially underfitting your hypothesis are two simple.",
            "They cannot capture the complexity in the data so both the training and the test there are high.",
            "When you have over fitting your training error is actually low, but the test error is high because you're not generalizing very well and what we would like is a model selection procedure or search procedure that brings us in the happy middle zone.",
            "OK, what this is also telling you is that it is really, really important to have a separate set of data on which you're doing evaluations.",
            "OK, because otherwise the training set is not a reliable indicator of how well you're doing so.",
            "What we will do is we will always take the data that we have and separated out OK. You'll have a training set.",
            "You typically have a validation set which we use in order to train hyperparameters.",
            "OK, so decide what the hypothesis space might be, decide parameters of the optimization procedure and so on.",
            "You're going to see a lot more on this in you guys talk and then you have a test set that's not touched in this process at all that you just at the end in order to establish how good.",
            "Your approximate are actually is and in order to compare different algorithms and sometimes these sets are specified for you ahead of time, sometimes you have to go through a procedure where you take your whole data set, then you chop it up into these pieces and you make sure that the pieces are balanced and so on in order to obtain accurate estimates of how good your hypothesis is."
        ],
        [
            "So this is a procedure called Cross validation where we take the data and we split it up, making sure these tests are disjoint and in cross validation we typically repeat this procedure multiple times.",
            "OK, now of course, the more times you repeat this procedure, the more expensive the computation is.",
            "But I'm not going to be worried about this.",
            "OK, well, always encourage you to do this a lot.",
            "OK and repeat it in order to get good accurate estimate of.",
            "The generalization capability.",
            "OK."
        ],
        [
            "So now we're going to take a little bit of a look at the error in estimators and what's the anatomy of that error and how does that relate to this kind of overfitting phenomenon.",
            "OK, so if we have some examples OK, and let's say that we have outputs that are generated from some true function F OK plus some Gaussian noise, OK, Gaussian noise of 0 mean and some unknown standard deviation.",
            "And now we fit a linear hypothesis.",
            "OK, to minimize the squared error.",
            "Alright, so we have.",
            "We've seen that we sort of have two different kinds of errors that can come in.",
            "One is maybe your hypothesis is too simple.",
            "It's just the line OK even with basis functions that are nonlinear and might still be too simple.",
            "So there's.",
            "There's a kind of error that comes from the hypothesis being unable to represent the data set that it needs to represent.",
            "There's a different kind of error which is due to the fact that your hypothesis maybe has too many parameters.",
            "OK, and we run into trouble because we can memorize the data.",
            "So there is these two sources of error.",
            "One is sort of a systematic prediction error due to the hypothesis class and the other one is a variability.",
            "That means that if I take a different data set and I've hit the same hypothesis, you can sing the same procedure and so on.",
            "I'm going to get different results and so now we're going to."
        ],
        [
            "Sort of split this up OK.",
            "So we can think of what's the expected prediction error at a particular data point X OK, and in order to make the analysis easier, we're going to make an assumption.",
            "That's quite standard now in machine learning called the idea assumption.",
            "So we're going to assume that all the examples are drawn independently from the distribution of data and what we're interested in is what's the expected squared error at a given point.",
            "OK, overall training sets of a certain size that are drawn.",
            "From the probability distribution.",
            "And.",
            "We are going to try and decompose this expectation into different parts.",
            "OK, in order to understand what the different components of the error acts."
        ],
        [
            "We are OK.",
            "So this is just a reminder of statistics definitions.",
            "You have the expected value or the mean of the random variable you have the variance and you can write the variance as the expectation of the square minus the square of the mean."
        ],
        [
            "And that's just a short proof of that statement, so we're going to use this at value."
        ],
        [
            "Definition now to kind of massage this this big expectation into different parts.",
            "So the first thing that we do is we take the square of Y -- H of X and break it up OK. And then, once we've done that, we can, by linearity of expectation, break up the pieces over here, OK, and we're going to have three components.",
            "OK, one component here is the expectation of Y squared given X expectation of the output given X.",
            "On one component, here is the expectation of the square of the hypothesis, and we're going to have to use our variance lemma in order to do something interesting with that.",
            "And then we have this component over here which is expectation of a product.",
            "But because the noise is drawn before knowing the hypothesis really, we can break that up.",
            "So the why and the H of X are independent of each other and we can break that up into a product of two expectations.",
            "So for the first term here, we're going to use.",
            "The variance lemma OK. Variance lemma says expectation of a square.",
            "We can write it as the square of the mean plus the variance.",
            "So we just do that here OK?",
            "And here by H bar we mean the average prediction for X over hypothesis that are fit with multiple draws of this data set.",
            "Cat.",
            "Anne.",
            "Over here, the expectation of Y given X, that's just the expectation of the function plus the Gaussian random noise.",
            "So it's just the value of the function.",
            "OK, so this is, this is nice.",
            "And then for the second term, the expectation of Y squared, we again use the variance lemma OK and we get some interesting terms over here.",
            "Now we're going to have to look at these terms a little bit more in detail."
        ],
        [
            "To see what they do.",
            "OK.",
            "So.",
            "Here the you know, once we do cancellations and once we sort of put squares together and so on just a little bit of algebra we get here.",
            "Three terms that are kind of interesting to look at.",
            "OK, and I'm actually going to start with this last one the last time here.",
            "Expected value of y -- F of X squared.",
            "OK, what is this?",
            "Well, we said that.",
            "Oh why is equal F of X.",
            "Plus epsilon OK.",
            "So y -- F of X is just the Gaussian random noise, so the expectation of that.",
            "This case is the noise OK?",
            "In general, OK, whenever we have additive noise, this kind of expectations expectation of the noise is a component that is not under your control.",
            "OK, there could be lots of noise, so long as it's additive.",
            "We're not going to worry about this.",
            "'cause this is not something that our hypothesis can actually touch.",
            "It's a term that doesn't depend on.",
            "We have here an interesting term F of X -- H bar of X squared.",
            "OK, So what is this F of X -- H bar?",
            "That's a systematic error.",
            "OK, it's a systematic error between the true value of a function and sort of the average predicted by the hypothesis and that we can do something about that's basically controlled by our hypothesis class.",
            "So and so this is essentially the square of the bias, OK?",
            "And then the first term here H -- H bar squared in expectation.",
            "That's the variance.",
            "OK, that's telling you how much H varies around the mean, OK?",
            "So the noise we're not going to worry about, but these two terms, the square of the bias and the variance, are the ones that are driving the error, and one could be bigger or the other one could be bigger OK, and in fact we're going to have."
        ],
        [
            "To trade these off, typically against each other.",
            "OK, so this is another picture where we're showing complexity of hypothesis on the X axis.",
            "We're showing error on the Y axis and you can see the bias square.",
            "You can see the variance bias squared plus variance, and you can see the test error here.",
            "OK, so here the bias and variance have been computed analytically because it's a synthetic example.",
            "OK, so the error that you see over there is in some sense the best case that you can see.",
            "The test there is actually computed on data, so the tester is higher than the analytical prediction.",
            "However, you can see that the tester actually mimics very accurately the analytical prediction.",
            "The other thing that you see is that as bias increases various decreases and vice versa.",
            "So this is a very typical tradeoff that we see when we play around with the complexity of the hypothesis space.",
            "We make the hypothesis space more complicated.",
            "That intuitively means hypothesis is going to have more parameters.",
            "The bias is going to go down 'cause we can now represent more functions, but the variance is going to go up OK because we have more parameters and potentially we might need more data in order to deal with this."
        ],
        [
            "So this is always a tradeoff.",
            "OK, you choose a more expensive expressive class of hypothesis.",
            "That means you have higher variance and you're going to lower your bias.",
            "And typically this is not a black and white trade off because it depends on the amount of data that you have.",
            "If you have very little data, you're going to have to tolerate bias 'cause there's nothing else you can possibly do.",
            "And if you have a lot of data, then we can go for very expressive hypothesis classes and so part of the sort of deep learning.",
            "Revolution has been in fact driven by the fact that massive amounts of data are available, and so we can actually fit these complicated hypothesis.",
            "There are also other ways of putting in bias control in the hypothesis spaces.",
            "We're going to talk in a minute about Bayesian methods where essentially inject prior information, and that can also help you keep complexity under control."
        ],
        [
            "So it's really it's not the hypothesis that's at fault.",
            "OK, it's really the balance between the hypothesis and the amount of data.",
            "And so, for example here you have when you have few points, you can't use complicated hypothesis, but when you have lots of points, they support the complicated hypothesis and you can you can use it just fine.",
            "Cat.",
            "Any questions or comments about these ideas of bias, variance, overfitting, underfitting?",
            "You know this is going by very quickly.",
            "You have access to the slides, so you can actually go through the math.",
            "If you've never seen this one before.",
            "OK."
        ],
        [
            "So now let's go back and talk a little bit more about the mean squared error and why the mean squared error might be a good idea.",
            "OK, as an optimization objective, and what's its interpretation?",
            "So one reason why people like the mean squared error is that it's got a good intuitive feeling.",
            "If you have real numbers.",
            "If you have errors, the big errors are amplified.",
            "The small errors are squished down by using the square.",
            "Another reason why people like it is that you can take derivatives very easily and so gradient based methods work very well.",
            "There are actually some interesting geometric interpretations of this.",
            "OK, so if you consider a linear hypothesis, for example, you essentially imagine that all the hypothesis possible hypothesis lie in a hyperplane.",
            "A linear hyperplane and then essentially the mean squared error.",
            "Finding the hypothesis with the minimum mean squared error means that we're finding the projection of the true function onto this space of hypothesis.",
            "OK, so that's kind of nice."
        ],
        [
            "I'm more interested in showing you a probabilistic interpretation because this is going to elucidate a little bit.",
            "What are the assumptions behind using the mean squared error and what?",
            "How do you go about thinking about your assumptions when you choose objective functions?",
            "So we're going to make a probabilistic assumption.",
            "OK, we're going to assume again, that your output Yi is a noisy value that's obtained by using a hypothesis from your hypothesis class plus some Gaussian noise.",
            "OK, so for each example HW, excise the output of the hypothesis epsilon.",
            "I is the Gaussian noise that we're injecting on to this, and that gives you the why, I.",
            "And now we're trying to figure out how to choose the best parameter vector.",
            "OK, so now we have a probabilistic system where data is drawn from some probability distribution.",
            "Noise is drawn from some distribution.",
            "We're going to want to find a W that gives us."
        ],
        [
            "Best fit OK. How to do this?",
            "Well because we have a set of probabilistic assumptions we're going to use base theorem in order to figure out what's the best hypothesis.",
            "OK, So what does best DM say?",
            "It says the probability of a hypothesis given the data is equal to the probability of the data given the hypothesis times the probability of the hypothesis and then the denominator.",
            "Here is the probability of the data.",
            "We don't really care about that, because that doesn't depend on our hypothesis.",
            "If we just want to solve an optimization problem, it's not going to influence us.",
            "One way or another, so we're going to kind of ignore the denominator and focus on the things that are here on top OK.",
            "So what do we have on top?",
            "We have PFD given H OK, that's the likelihood of the data.",
            "And we have PFH.",
            "That's a prior OK, which is a prior on the probability."
        ],
        [
            "Different hypothesis.",
            "So now we can ask a more specific question, not what's the best hypothesis, but what's the most probable hypothesis given the training data?",
            "So we think the learning now essentially as a kind of inference process, where the data is evidence and the hypothesis space we want to explore an.",
            "So we're going to sort of solve this maximization problem Max a posteriori maximization problem where we want to find the most likely hypothesis given the data.",
            "Again we use Bayes theorem, so that means we just want.",
            "The argmax of PFD given H times pH.",
            "And so here we've dropped the FD because it doesn't depend on age and so it doesn't effect the maximization."
        ],
        [
            "So now I can make some further assumptions.",
            "OK, we can assume that all hypothesis are equally likely.",
            "OK. That's also an assumption that people often make.",
            "And so in this case, what we want is a maximum likelihood hypothesis, and otherwise we want to find the hypothesis that maximizes the likelihood of the data.",
            "And to do this efficiently, we're again going to make the standard assumption that the data is drawn IID from some distribution.",
            "And so we can simplify PFD given H into a product of probabilities of each example given the hypothesis.",
            "And again here we can simplify things a little bit by saying this is the probability of the output given the input and the hypothesis times the probability of the input OK. Probability of the input is not under our control.",
            "That's the environment.",
            "That's the world, it's the data distribution OK, and P of Y given XY&H is something where we've made an assumption.",
            "OK, we've made the Gaussian assumption."
        ],
        [
            "So now we do.",
            "The standard thing would take this likelihood.",
            "We're going to take a log of it in order to not work with products, but work with sums and we get the log likelihood.",
            "Here we have two sums, log of P, XI and log of PFY.",
            "Given XINH, the second sum here only depends on the data set, not on H, so we're not going to have to care about it since we're just going to do."
        ],
        [
            "Optimization.",
            "And under the assumption that we have Gaussian noise Now the first part OK, the term over here is actually quite nice.",
            "OK, so the likelihood has this sort of Gaussian.",
            "Turn."
        ],
        [
            "Here and we can take the log and maximizing the right side.",
            "Here is the same as minimizing the mean squared error.",
            "So this is a little bit magical.",
            "OK, we've made an assumption.",
            "We've kind of picked the right assumption because we knew it ahead of time and we went through this procedure and what we have obtained is that essentially the mean squared error or the sum squared error is a surrogate for maximum likelihood criterion.",
            "Maximum likelihood in general says we want to find the most likely hypothesis given the data under the assumption that all hypothesis are equally likely to begin with OK. Um?",
            "The other thing that's a little bit interesting about this formulation is that it spells out exactly what your assumptions have been OK.",
            "The data drawn IID.",
            "We had Gaussian noise applied on top of the true, some true hypothesis from your hypothesis space, and this Gaussian noise has the same standard deviation for all of the examples.",
            "OK, so under these assumptions, the mean squared error is the right error function in the sense that it is giving you is going to give you the same hypothesis maximum likelihood.",
            "Now this also that if your data violates these assumptions, then in some sense using the sum squared error is not the right thing to do OK.",
            "In particular, if you have, let's say, standard deviations that depend on the input.",
            "OK, so that some examples are affected by more noise than others, then using the squared error is the wrong thing to do.",
            "And what you should do instead.",
            "If you do a little bit of math, you figure it out quite easily, is to wait the examples differently, OK and.",
            "Perhaps throw out some examples that are affected by too much noise in order to to do your fits."
        ],
        [
            "K. So."
        ],
        [
            "Now I'm going to show you a little picture here.",
            "OK, to kind of represent this process.",
            "OK, and this is going to establish a link to a sort of a general class of machine learning algorithms called graphical models.",
            "I don't know how much you'll see these pictures during this week, but I figured that it might be a good idea for you to actually visualize things this way.",
            "At least once.",
            "OK, so this is a cartoon of how the data is being generated in the case of linear regression that we've talked about.",
            "OK, and under the assumptions that we've talked about, so we have some inputs.",
            "There is a random variable here X. OK, that's drawn from some distribution P of X.",
            "So each node here is going to be some kind of random variable.",
            "OK, and the errors are going to show sort of influences between these random variables and at each of these nodes were going to have a conditional distribution of that particular node given its parents.",
            "OK, so X has no parents, it's just drawn from some distribution which is unknown OK. Epsilon, the noise is also has no parents, is drawn from a normal distribution of mean zero and some variance Sigma that we have some standard deviation Sigma that we don't really know.",
            "W here.",
            "Under these assumptions that we've used so far is fixed but unknown.",
            "OK, and so we're going to try to use this model to infer what W might be given the evidence that's being presented.",
            "And the output Y is in fact the deterministic node that does the operation in this case, where it takes the output of the hypothesis that depends on W&X and that's the noise that comes from epsilon.",
            "So.",
            "In this case, some of the variables are observed.",
            "Some of the variables are UN observed OK, we can see X and we can see why, but we don't actually see epsilon, nor do we see W. OK. And we actually don't really know the parameter of the probability distribution that governs epsilon either.",
            "So this is going to be a very typical case where you have data you have some observed variables.",
            "You kind of know there are some other variables that are important, but you don't see them.",
            "Those are called hidden or latent variables and a lot of the time we're going to try to build the model that infers these variables, their probability distributions, and their values from data.",
            "The other thing that's interesting about this model is that it points out places where we could make more interesting assumptions.",
            "OK, so for example, here we've assumed that W is fixed but unknown.",
            "OK, because we're under maximum likelihood.",
            "But now, let's assume that W is actually a random variable.",
            "OK, so if W is a random variable, then it might be drawn from some probability distribution.",
            "OK, then we're moving towards Abbasian setting where we actually have priors over the parameters, and we can use the data to infer.",
            "A posterior probability distribution over the parameters OK. And of course, here we've made a specific assumption about how the output interacts with the input.",
            "OK, this kind of cartoon is typical of discriminative models, where you have the input sort of determining the output and some kind of sort of close to deterministic fashion.",
            "But in general we could have variables interacting in all kinds of ways, so we could have many variables.",
            "We could have arrows going forward and backward, and so on.",
            "And so you would get a lot more generality by drawing models in that way.",
            "Are there any questions or comments about this picture about the sort of this graphical models probabilistic view?",
            "Everybody is very quiet.",
            "That's kind of suspicious."
        ],
        [
            "Cat.",
            "So now let's talk a little bit about regularization from this kind of perspective.",
            "OK of graphical models.",
            "So regularization is a way of controlling the bias variance tradeoff in order to obtain a good value of this tradeoff and it's essential."
        ],
        [
            "Really sort of getting to the punch line.",
            "It boils down to controlling this W here through some kind of prior.",
            "OK, that is going to help us inject some bias, but perhaps mop away some of the variants."
        ],
        [
            "OK, now what does regularization usually look like?",
            "It looks like this.",
            "We have our initial objective which is J DFW.",
            "That's to optimize something on the data.",
            "Either minimize squared error or maximize likelihood or something like this and we add to it a penalty term.",
            "OK, and this penalty term depends on the weight vector and the penalty term essentially captures some kind of intuition that we have about priors on the hypothesis space.",
            "What hypothesis?",
            "Are better than others in the absence of any data and the parameter Lambda over there controls the straight off.",
            "So the higher I make the Lambda, the more we pay attention to the penalty.",
            "The lower we make the Lambda, the less we pay attention to this penalty.",
            "If we set Lambda to 0 then essentially we just try to optimize performance on the data and we don't care at all about the actual prior on the hypothesis.",
            "So in statistics this is called shrinkage.",
            "In machine learning we call this regularization and Lambda here is called regulation isation coefficient and in principle you have criteria that can help you select this and in practice very often people do cross validation and treat this as a sort of hyperparameter as well."
        ],
        [
            "So now let's look a little bit at regularization for linear models.",
            "OK, so here we have a linear model.",
            "We have the error function and then we have here a term W transpose W that is what's called L2 regularization or weight decay.",
            "OK, So what does this do?",
            "It basically says that we would like our weight magnitude to be small.",
            "OK, 'cause if we emphasize this term and the weight magnitude is high, this is going to make things look worse.",
            "So.",
            "That's why weight decay OK, and the nice thing about this is that of course, here's a quadratic term in the front.",
            "We also have a quadratic term, so everything is nice and quadratic, and we can take gradients and we can optimize and things work very well.",
            "In fact, they work very well in closed form, and we get this solution over here where the best weight vector has basically the same form as before except 5.",
            "Transpose Five has a Lambda times identity matrix added to it.",
            "OK, so in other words you're adding mass.",
            "On the diagonal of the spy transpose file.",
            "OK, that helps you with two things.",
            "OK, it helps you with making this a little bit better condition.",
            "OK, and again it sort of drives your weight stored O."
        ],
        [
            "Anne.",
            "And of course, if Lambda is equal to 0, you get exactly the same solution As for usual linear regression.",
            "And if Lambda goes to Infinity, then the solution is just going to go to 0.",
            "So this is called Ridge regression.",
            "There's a more general class of regularization which actually I'm not going to tell you about really called canal regularization that has all this kind of form.",
            "And."
        ],
        [
            "Sort of an alternative view of this.",
            "OK, which is derived in the slides, but I'm really not going to go through the derivation is the following.",
            "We could think of this criterion, and as saying we have some objective function here, which is the squared error.",
            "OK, we're trying to minimize that.",
            "And at the same time we want to keep the magnitude of the weights bounded OK and this parameter ETA is sort of the inverse of Lambda OK?",
            "So what is the?"
        ],
        [
            "I mean, OK, how do we visualize this?",
            "We basically do the following.",
            "In general, we would like the weights to be close to zero.",
            "OK, so you have this red circle over here around the origin.",
            "That's saying I want the weights to be small, OK?",
            "And we have a sort of point over here.",
            "That's the best fit based on the data.",
            "OK, now what is the best solution according to this criterion?",
            "Well, it's where these circles intersect.",
            "OK, and that's going to be on the sort of line that unites these two centers.",
            "Or if you're many dimensions, is going to be a hyper line.",
            "So now what happens with the regularization?",
            "If I if I make Lambda very small, OK, Ada, which is one over Lambda is very big.",
            "And the circle that surround the origin is going to blow up OK, and all solutions are acceptable essentially.",
            "Otherwise, when we shrink the circle, OK, we really want the weights to be close to 0.",
            "That's the emphasis, and so the weights are going to migrate away from the point that's best for the data towards the point that's best for this this prior.",
            "So that's all to regularization."
        ],
        [
            "So this is actually quite nice.",
            "OK, if you find a good value for the regularization parameter, this helps you avoid overfitting.",
            "If there are irrelevant features in the input, then you're going to get small weights for those features, typically OK without having to do some kind of complicated pre selection procedure where you just keep some features and so on, but their weights are not going to be quite zero.",
            "OK, they're going to stay a little bit away from zero because there's nothing really encouraging them to be all OK. We're working with the magnitude of the weight vector rather than particular weights.",
            "So there is a way to to actually get these weights to be equal."
        ],
        [
            "OK, that's called L1 regularization, OK?"
        ],
        [
            "And I'll actually show."
        ],
        [
            "The picture first OK, the picture for one regularization is that instead of using a circle around the origin, we use a little diamond OK. And So what we require is for the weights to be inside of this diamond.",
            "And so now you have the circle.",
            "Here it's going to touch the diamond somewhere along its edges.",
            "OK, but one can actually formally show that you are more likely to touch at the corner then to touch in the middle of an edge.",
            "OK, now that's actually kind of nice because here if you're touching at the corner, that means that one of your weights is actually zero and only the other weight matters.",
            "So if you have irrelevant features then those irrelevant features essentially will have zero weights, and they'll be thrown out.",
            "So it's a large class of methods called lasso, very popular in statistics.",
            "Community works very well with linear approximators.",
            "Doesn't work so well with non linear approximators, because this kind of constraint is actually a little bit ugly.",
            "OK, and the optimization procedure is signif."
        ],
        [
            "Gently, more elaborate, the type of constraint that we have here is that the sum of the absolute values of the weights has to be bounded by parameter ETA and ETA.",
            "Again controls the size of this diamond.",
            "So why is this more complicated?",
            "While you can easily see that if I take this absolute value, Onyx."
        ],
        [
            "Founded in all possible ways, we get a blow up of these constraints.",
            "You still have a sort of in principle, a nice optimization procedure, but with lots and lots of constraints and so where is this useful?",
            "That depends.",
            "There are some things that go in between where people use sort of L1 style regularization in some parts of the space and then smoothly going to an L2.",
            "These are called Huber Ized losses.",
            "Some in some cases those work better."
        ],
        [
            "Then either L1 or L2, the advantage of L2 is that it eliminates completely features that are irrelevant, and so in some applications that's actually useful.",
            "So for example, if you work in medical applications, doctors really want to know what are the three different symptoms that are determining the diagnosis or the five different genes that are determining the diagnosis, and they don't want everything else to be around in other applications.",
            "This is not so important."
        ],
        [
            "And this is just to show you sort of visually the effect.",
            "So that says L1 regularization.",
            "This is L2 regularization as we vary the strength of the regularization parameter.",
            "Of course in the end everything goes to zero, the weights go to zero, but as you can see and L1 regularization, certain ways just go to zero and stay O OK. And you can consider that the more important variables are the ones that are lasting longer OK, whereas in L2 everything kind of goes to zero roughly at the same time, and so it's harder to determine which of these things actually has to be."
        ],
        [
            "No, not.",
            "OK.",
            "So now what's the beige and view of this?",
            "The Bayesian view is that in both of these cases were really what we're dealing with is a prior distribution of our hypothesis OK?",
            "And when the data comes in, we compute the posterior distribution and the difference.",
            "Since between L2 and L1 is what kind of distribution do we assume as the prior?",
            "So in the AL 2 case we have a circular Gaussian that's the prior, and so when we compute the posterior, we also obtain a Gaussian distribution OK, and so for that reason it's actually very easy to work with L2 regularization in many cases and at least all kinds of interesting algorithms, Gaussian processes and so on.",
            "In the one case, what we use is a double exponential prior.",
            "OK, that corresponds to this kind of diamond shape.",
            "This sort of goes out much much quicker than a Gaussian.",
            "And so as a result, you sort of put in a little bit different kind of prior knowledge, and so you're going to get slightly different hypothesis when you do your search.",
            "This is something that is under your control and the choice is really guided by two criteria.",
            "One is the ease of the optimization because working with for example with conjugate priors really makes things easy from the point of view of solving the optimization problem or sometimes choosing sort of smoothness in the prior and smoothness in the error function makes gradient based optimization easier to deal with and then the other.",
            "Sort of important consideration is what do we actually know about the problem, and so here it's sort of it's easy problem.",
            "It's aggression problems, but often when we deal with structured data, the prior actually reflects something that we know about the hypothesis space.",
            "For example, if we're trying to infer gene networks, maybe we know that certain genes cannot be connected, and so we can build that into the prior."
        ],
        [
            "So this is just to give you a cartoon picture of this vision, view of regularization.",
            "OK, and what we're going to do here is start with a prior over the weight space.",
            "OK, this is the picture here with the red circle is a Gaussian prior over the white space and it's sort of centered at zero.",
            "OK, so in the absence of any data, we can use this to draw weight vectors, and each weight vector is going to be a hypothesis.",
            "And so here these red lines represent different hypothesis that we've drawn from this prior, and you can see there all over the place.",
            "All we say is, we'd like the weights to be roughly small.",
            "OK, but there is no rhyme or reason until you actually see some data.",
            "Now it's a little bit hard to see, but over here on the right hand side in the 2nd row we have a data point, so little blue circle OK and so now what we do.",
            "When we do, the regularization essentially is we compute the posterior over the weight space over the parameter space, and that posterior says we would like to fit the data OK and so all the lines are encouraged to go through this point to fit the point OK.",
            "So compared to here where the lines were all over the place, here we have lines that are still all over the place, but they do fit the blue point that we've just gotten.",
            "OK. Now what does that mean from the point of view of the weights?",
            "OK, what it means is that this Gaussian that used to be round OK is no longer round, because we've taken the round prior when we've combined it with the likelihood of the data.",
            "Likelihood is here OK, this sort of red line likelihood says all weights are good, so long as they fit this point.",
            "And so when we do that, we get a Gaussian that's more squished OK?",
            "So on one side we have to go through this this data point that we have on the other side.",
            "We still still have a lot of freedom, so there's still a lot of variance.",
            "OK, in the weight vector, but we've restricted this somewhat OK, so now the second point comes in here is the second point.",
            "And now you can see that we want actually to fit both of these things.",
            "OK, So what happens is we take this.",
            "Sort of posterior probability over the weight vector.",
            "We combine it with a new likelihood from the new point and now we have something that's very sort of concentrated in one spot.",
            "OK, and now if you look at the lines that result, they all go roughly through the two points.",
            "There is some variability.",
            "OK, 'cause we have a distribution.",
            "OK, but they're all pretty well aligned together.",
            "And as we get more data, what happens is the spot that tells me what's the best weight vector?",
            "Kind of squishes in the variance reduces and the lines get more and more aligned together.",
            "So how does this relate to bias variance?",
            "Well, we've put in some bias here through the choice of prior OK, and then the data comes in OK and the data is helping to decide how to sort of shrink this in order to actually fit the observations that we have OK. And the more data we have, the more we're going to shrink this OK and the limit of infinite amount of data.",
            "Maybe we're going to fit this.",
            "Exactly correct.",
            "So the posterior is always skewed by the data."
        ],
        [
            "OK.",
            "So why is this interesting?",
            "Well, it's interesting because it gives us more than just estimates of the values of the output.",
            "It actually also gives us some kind of uncertainty estimates in where our hypothesis is confident on its output and where it is not OK, so this is sort of another picture of the same problem.",
            "Basically you have these circles here, which are the data points that are observed.",
            "The true function is this green function here, and we have these red lines that are drawn.",
            "From posterior distribution over the weight factor.",
            "So what you see here is that when we have a data point, the blue point here around that data point, we have little uncertain because we know we have to fit it.",
            "Not exactly 'cause we're allowed some noise, but more or less, whereas when you're away from the data, there's a lot of uncertainty because you don't really know that you can't really tell what's a good hypothesis.",
            "And you can see it in these lines.",
            "They all kind of go through the blue point, but they're all over the place.",
            "As we get more points.",
            "OK, these lines focus in order to capture these points outside of where we have data, we still have a lot of uncertainty.",
            "OK, so the moral of the story is that you can always generalize well around where data actually is.",
            "If you're working with a Bayesian method, you can actually get analytical estimates sometimes, or empirical estimates of this uncertainty.",
            "OK, an you can work with multiple hypothesis at the same time.",
            "It is expensive and it is somewhat unpleasant in the sense that you can point and say, oh, you know this is my function.",
            "OK now you have a whole space of possible functions and you can draw from that space at the same time you can easily quantify how uncertain you are and the other interesting thing about this picture is that if we see where the uncertainty is high, that indicates perhaps where we should collect more data.",
            "Now that's not a setting that's often talked about in sort of standard supervised learning.",
            "It's sort of active learning setting where if we know where uncertainty is, we can actually make a question an ask.",
            "OK, we want an example in this area.",
            "What's the label of that example and that can drive the learning?",
            "There's a very interesting sort of research question of how to do that well."
        ],
        [
            "Efficiently.",
            "So this is just a picture of continuing this sort of drawing points and you can see that as you draw more and more points, you still have multiple hypothesis in the sort of Bashan view, because you have a distribution of our hypothesis, but they all sort of clustered together in order to fit the data in the limit, as you have an infinite amount of data, the optimization becomes the same as maximum likelihood, but when you have a small amount of data, the prior has a say OK, and so the hypothesis that you get are driven by both the prior.",
            "And the data."
        ],
        [
            "OK, so so beige and the Bayesian view is kind of interesting because it tells us about what are our assumptions.",
            "It gives us uncertainty estimates.",
            "It can guide active learning.",
            "It is tricky.",
            "OK, in the sense that if you, for example, overwhelm your prior with data too quickly, then the plot prior doesn't really help you.",
            "It's also tricky because it is sort of expensive to work with this sort of sampled hypothesis.",
            "But it can be actually quite interesting.",
            "Are there any questions or comments about that?"
        ],
        [
            "There will be an exam at the end.",
            "So now the last thing I wanted to mention to you is logistic regression.",
            "Why?",
            "Well?",
            "Because that's sort of the equivalent of linear regression for classification problems, and you know, is going to tell you all about how to do this a lot better.",
            "But this is kind of the usual statistical view of things.",
            "So here we have a hypothesis.",
            "OK, and the hypothesis is a logistic function of this linear combination of the inputs.",
            "So access the input W. Transpose X is a linear combination and then we do this kind of action and you get this sort of shape.",
            "Have your function.",
            "That goes kind of like this.",
            "You'll see a lot more about this later.",
            "It's also called sigmoid neuron in the neural net literature.",
            "So why is this close to linear?",
            "OK, we're going to interpret the output of this hypothesis as the probability of the class label being one given the input OK, and so if that's our interpretation, and if we look at the log odds ratio of the probability of the two classes, the binary classification case Y equal to 1 and Y equal to 0, you get the weights times the inputs.",
            "OK, so that's linear.",
            "OK, that's the sense in which we have things that are linear.",
            "And.",
            "The interesting thing is that if we find the best weights here, the best weights are going to maximize the conditional likelihood of the outputs given the inputs.",
            "OK, so that's kind of nice.",
            "It's again a maximum likelihood criterion, and it's sort of the sort of standard discriminative setting."
        ],
        [
            "So now what are we going to optimize?",
            "Well, we can optimize the cross entropy, OK?",
            "So how do we think about the cross entropy?",
            "We have it some distribution of observed outputs in the data and then we have some distribution that's generated by the output of our hypothesis.",
            "OK, we're going to measure how far off one is from the other.",
            "OK, so the log likelihood of the hypothesis here, assuming again that we have all hypothesis being equally likely, we're going to have here some of the log of P of Y given X, and this is going to be either log of.",
            "H of X of or 1 -- H of X depending on whether we have class one or class zero.",
            "We can do a little trick to kind of put these together OK by using this kind of multiplication of Y times the log in 1 -- y times the log of 1 -- H of X here and so we obtain the cross entropy error function and now we can optimize this."
        ],
        [
            "To obtain the best parameter vector.",
            "So this is a plot of what cross entropy error surface looks like for logistic function, and you can see that it's nice.",
            "It's convex an.",
            "Unfortunately we can't really solve it in closed form anymore.",
            "So in the case of linear regression we obtained an actual formula of what the weights ought to be as a function of the inputs and outputs.",
            "Here we can't quite do that OK, but it is a nice convex optimization.",
            "OK, and so."
        ],
        [
            "What we're going to do is to use our best weapon that we're going to use a lot this week called Gradient Descent.",
            "So just to remind you, gradient descent basically says if we have some kind of error function that we're trying to optimize, we're going to start somewhere and follow the gradient OK until we get to the bottom.",
            "Now, if you have something that's nice and convex, like here, you can start anywhere and you're going to end up at the bottom under mild technical conditions.",
            "If you have a nonlinear optimization objective with lots of little wells, then when you do your optimization you may end up in a local optimal optimum which is.",
            "One of these local little words, and so there's then all kinds of tricks to encourage you to end up in a good spot, and you going to tell you all about that so."
        ],
        [
            "Don't really discuss that in detail.",
            "One of the very standard ones, of course, is to just do this multiple times and just start from different initialization points, and that's going to be due to different solution."
        ],
        [
            "So what does the gradient descent algorithm look like?",
            "You have an objective JK.",
            "We're going to assume that we can compute the gradient of this objective easily.",
            "So the objective is smooth and the hypothesis is smooth.",
            "For example, then this is easily done.",
            "And we're going to produce a sequence of weight vectors.",
            "Such that the limit of this is some weight vector that's locally optimal.",
            "And what we're going to do instead of so now instead of solving the set of equations that sets the gradient to 0, or simply going to step in the direction of the gradient?",
            "Because this is an error function, we want to step down in the direction of the gradient, hence the - over here, and we have a learning rate Alpha that controls how much we step down.",
            "And these Alpha eyes could be different from iteration to iteration from step to step.",
            "And there's also smart ways of actually."
        ],
        [
            "Setting up.",
            "So now we can apply this to the case of logistic regression.",
            "We can take the likelihood of the data.",
            "We can take the gradient, we can write the update rule for the gradient, and we get a very nice update.",
            "OK, that basically says we started with some arbitrary weight vector and then we step OK in such a way as to minimize the error on the inputs.",
            "OK."
        ],
        [
            "Now, this kind of optimization is all good, but it requires you.",
            "To pick these learning rates.",
            "And you can treat this as a hyperparameter and use cross validation and pick the rates.",
            "Sometimes the theory says.",
            "Of course you should decay these rates.",
            "Then you have more things to deal with.",
            "Maybe you want to decay them in according to some schedule.",
            "That schedule might have parameters and so on.",
            "So there's another thing that you can do.",
            "Which is to apply Newton's method.",
            "OK, and so how does this look like?",
            "Newton's method is basically an interesting way of finding zeros of a function.",
            "In our case, we want to find zeros of the gradient OK, and the idea is that if I have some function.",
            "OK. And I'm at some point here.",
            "We're going to approximate the function.",
            "Using a straight line and then we're going to solve the equation for where this reaches 0 and then move to that point.",
            "So this is written out here, assuming that you just have a univariate function, But if you have a multivariate function, you can do exactly the same sort of thing using here a gradient in."
        ],
        [
            "Stead of.",
            "Of a derivative.",
            "And so now here what we want is we want to find the zeros of the gradient.",
            "OK, so on top or G function here is the derivative and on the bottom we have the 2nd order derivative.",
            "So this is part of a class of methods called 2nd order methods because they make use of 2nd order derivative information.",
            "If you have access to that.",
            "And then you step in this direction and that's really the best you can possibly do.",
            "So notice that if I have an iteration like this, there's no learning rate and there's no step size.",
            "You just do this computation.",
            "You the price to pay is that you do have to compute the 2nd order derivative, and that may be expensive depending on variety of circumstances.",
            "If you have a quadratic error function, then you find the optimum in one step, OK, using."
        ],
        [
            "Snap it.",
            "So this is the multivariate setting here with where now instead of having a second order derivative, we have the multivariate equivalent, which is the Hessian matrix.",
            "The Hessian matrix has the 2nd order derivatives according to pairs of parameters, and so the iteration just moves in the direction of the gradient of the objective and the learning rate is the inverse of the hash.",
            "You do have to estimate this Hessian OK, and so typically these methods in order to be used require more data.",
            "Than methods that are just based on step size.",
            "So this is called an intern Raphson method."
        ],
        [
            "Sometimes called Fisher scoring.",
            "What's better?",
            "Well, that depends.",
            "OK, typically this kind of 2nd order method requires fewer iterations in order to do the computation, because you sort of take optimal steps.",
            "At the same time, you need a batch of data, so it's not an online algorithm.",
            "And also there's this inversion of the Hessian twitch is expensive.",
            "There actually tricks for avoiding this kind of explicit computation and inversion, which you may hear about later on."
        ],
        [
            "But you can actually do this for logistic regression and it results in an algorithm called iterative recursive least squares, and the Hessian has a nice form in this case where you have the features and then this kind of diagonal matrix of H * 1 -- H, and so they wait.",
            "Updates also become quite nice, and it's it's a.",
            "It's a good algorithm if you are going to do logistic regression and you can work with these large matrices."
        ],
        [
            "How do we do regularization for logistic regression while we do it just the way we do it for linear regression?",
            "OK, we're going to have to put a prior over the parameter vector.",
            "So for example, we can just do L2 regularization.",
            "We can just say we want the weight of the norm of the weight vector to be small.",
            "This means that again we have a sort of quadratic element in there, and the optimization is easy.",
            "It's a little bit harder now to make sense of what's going on in the sense that this is suggesting a Gaussian prior, but then the data comes in and we don't have a conjugate.",
            "It's not a conjugate, so we don't really get a conjugate posterior.",
            "There are other things that one can do here.",
            "Different kinds of regularization that perhaps would be better matched to binary data.",
            "So, for example, you can consider what is the error, what does the error look like for binary data will typically the error is not a Gaussian type of error.",
            "But it's actually flipping the label, and so perhaps working with Gaussians here is not ideal.",
            "However, from a practical point of view, this is very nice, and so that's one of the reasons why why people use this map."
        ],
        [
            "Now what's the probabilistic view of logistic regression?",
            "So just like we thought about linear regression, and we thought about this kind of noise model, we can treat logistic regression in the same way.",
            "OK, so we can consider the output as being produced by a hypothesis plus some noise, OK?",
            "But this is actually kind of strange.",
            "OK, again, because the output is binary and So what does this kind of model really mean?",
            "So instead what we will do is we will consider a continuous variable.",
            "OK, why had that's produced by the hypothesis plus some noise?",
            "And then we're going to consider the output being generated by thresholding this variable at 0.",
            "So we're going to generate the one if this variable is positive and 0 otherwise.",
            "And so in this case, we actually obtain a nice probabilistic model for logistic regression.",
            "We now have the.",
            "The graphical model is a little bit more complicated.",
            "We have the inputs.",
            "We have epsilon.",
            "These are used to go into this sort of.",
            "Yhat variable which is then used.",
            "To generate Y. OK.",
            "So again, there's this sort of notion of a latent variable somewhere in there that we don't actually get to observe, but that controls the output that gets absorbed.",
            "Now.",
            "The other interesting thing about this kind of interpretation is that it directly shows you that logistic regression is not a generative model.",
            "In other words, if I just consider the inputs and the outputs, there's not a good way for me to generate what this yhat might have been.",
            "OK, and so there are other models, other probabilistic models that are fully probabilistic that allow you to populate these latent variables in nicer ways."
        ],
        [
            "OK, so we're going to recap now a little bit.",
            "We talked about machine learning algorithms.",
            "Hopefully this was more of a refresher.",
            "If you've seen this now for the first time, I'm sure it's like completely whizzed by.",
            "So whenever you have a machine learning algorithm, you have to think of making a choice of hypothesis.",
            "A choice of an error function, and a choice of an optimization procedure.",
            "Very often we're going to make gradient descent kind of optimization procedures just because they're convenient and they work sort of in many, many cases.",
            "In some cases, this optimization is easy and in closed form in almost all the cases you're going to see for the rest of the week.",
            "This is not the case, and you're going to have to work harder to get that.",
            "Um?",
            "And all of the algorithms are affected by this kind of bias variance tradeoff, so the overfitting phenomenon is always a concern.",
            "You always have to do cross validation.",
            "You always have to make sure that you're not building a model that's too large for the amount of data that you have.",
            "You could do regularization to control that.",
            "You can put priors on hypothesis space, and I've showed you a little bit of this patient interpretation.",
            "I'm not sure how much you'll see of this for the rest of the week, but I think it's useful to keep this in mind because it both captures.",
            "What the algorithms are trying to do?",
            "What are the hidden assumptions behind the algorithms and also it gives you a way of perhaps expanding the class of algorithms by modifying those assumptions explicitly.",
            "So I'll stop there and I'm going to take questions if there aren't, yeah.",
            "Cross entropy error.",
            "Hire some people think that it's better than the music euro for Fire Protection problems you through or why so?",
            "For binary classification the mean squared error sort of doesn't make sense, because the mean squared error is under this assumption that you have some output and then it's affected by Gaussian noise.",
            "OK, now that's not the case in binary classification binary classification, you have some.",
            "Output and the nature of the noise is to flip that output.",
            "OK, so instead of 1, make it 0 and the other way around, and so using the mean squared error in this case really does not fit at all with the nature of the output data.",
            "Cross entropy explicitly says, well, we have some distribution of this output condition on the inputs and we have some distribution of this output that's generated by the hypothesis, and now we're measuring called different.",
            "These two distributions are.",
            "So in that sense it is a fit for this problem as well as many other problems.",
            "It's a very general kind of error function that whenever you have this kind of probabilistic assumption on the problem at hand, you can work with it.",
            "It's just a matter of in this particular case, the cross entropy also has a nice form that you can actually work with computationally or other problems that might be more complicated depending on the on the distribution.",
            "Audio.",
            "Right, so the question was, is the is the cross entropy better than the mean squared error for binary classification?",
            "Yeah, I just wanted to be devil's advocate here.",
            "Even if it is square with 01 targets, then you're actually doing something meaningful which is estimating the expected value of the binary variable.",
            "Given X, so it's not completely crazy, but I think the reason it doesn't work as well as cross entropy for signaling.",
            "Or herself, Max is more numerical.",
            "So if you want your output to be bounded between zero and one, you have something like sigmoid or softmax and then you can use squared error.",
            "End up with problems where derivatives might be close to 0 even though the.",
            "The output is confidently wrong and this is a bad situation, so there's certainly numerical aspects, but at least from my point of view.",
            "You know, I would like the interpretation to be consistent with the choice of algorithm and so in this particular case.",
            "And this is the right thing exactly.",
            "Exactly now there is a.",
            "There is a debate of whether maximum likelihood is the right thing to do.",
            "And that's that's a whole big debate that I'm sure has many, many sides to it.",
            "Yeah, so it's actually an interesting point actually.",
            "To make at this disjunction that sometimes our choices are driven by sort of theoretical considerations of what sort of the right thing to do given the data.",
            "And sometimes the choices are driven by numerical considerations, and what is actually feasible, and so there may be methods that are very nice theoretically, but that numerically or unstable or don't work well with certain classes of function approximators or certain classes.",
            "Of these hypothesis, and so we're going to make a choice, even if it's not quite theoretically justified, but one that actually works in practice.",
            "So that's a tradeoff as well.",
            "Yeah.",
            "So this graph or.",
            "So the generative models means that you can actually use the model to generate data.",
            "OK, so in other words, I could use this.",
            "Can I use this model to actually generate you inputs and outputs?",
            "OK, so the question is, is logistic regression and generalized artistic regression not a generative model?",
            "So in logistic regression, what I can do is if you give me an input I can infer.",
            "The output OK with a probabilistic assumption on the weights.",
            "I could even for distribution of the output.",
            "What I cannot do is invert that and say, given the output, what does the input look like now?",
            "There's a large literature on generative models.",
            "Naive Bayes is the typical example, sort of simple classifier example of a generative model where you can actually generate both inputs and outputs.",
            "When is that interesting to do?",
            "It's interesting to do when you actually want to generate data.",
            "For example, if you want to generate text or you want to generate images, then it's good to have a generative model.",
            "The other thing is that it allows you sometimes a way to supplement your data under certain circumstances by generating more examples.",
            "So logistics regression is typically as a typical discriminator.",
            "Given the input, you can compute the output, but you cannot infer that computation.",
            "If we make different assumptions here on the structure of this graph.",
            "So really the problem comes from the snowed over here where we then apply a threshold.",
            "OK, so once we add a random variable and we apply a threshold, the information about that random variable is completely gone.",
            "If instead we have some other probabilistic assumption here about how this output is generated, then we can actually perhaps invert that.",
            "OK, and so naive Bayes has some different assumptions that it works under specifically.",
            "It's assumption is like this.",
            "You have an output here.",
            "And it generates inputs OK, and then we can sample this way or sample that way conditioned on anything and end up dying data.",
            "Yep, when you were talking about the variance tradeoff intervation one weeks vacation over.",
            "So the expectation is always over the true probability of the data.",
            "So P is the P is the true probability of the data, so the one that's generating the inputs.",
            "So sampling different training set.",
            "Yep.",
            "That is, a parametric model.",
            "Is there such thing as nonparametric through Mac and there's no.",
            "So I will give you now my my own view of this, which may be completely off kilter, but they know your Shannon can correct me if I'm wrong.",
            "My own view is that these are very large parametric models, so large that you actually don't need the non parametric stuff at all.",
            "So what you do is you essentially overparameterized, you have a very large parameter space you can represent very complicated hypothesis and then you are smart about the way that you do the search in this space.",
            "And so you avoid overfitting problems by being smart about the optimization.",
            "And as a result, you don't really need the nonparametric stuff at all, because you build a very large model to begin with.",
            "Now.",
            "Will there ever be a need to have something nonparametric?",
            "If you had even more data, I don't really know.",
            "There is something that's fundamentally very nice about parametric models, which is that you have a handle on the complexity OK, and so the parameter sizes given, whereas in nonparametric models potentially you can memorize data and the model can grow very unwieldy, and then you have to know the theory is nice, but in practice you have to do things like throw stuff out and forget and so on and so at least in my view, parametric models are a little bit better.",
            "And there, since they're so big.",
            "Yeah, I really answer, but I would add this nonparametric for me at least for many people means that.",
            "Your learning algorithm can adapt to the amount of data, so you have more data you can you know putting more capacity.",
            "In fact, that's what we do with the neural Nets and other things like extra models, even though given the number of units or the number of mixture components, it's a parametric model.",
            "In practice, you will actually choose the size of the model depending on how much data you have, and so these models really are nonparametric, not the usual nonparametric.",
            "But they are nonparametric.",
            "So is there any theory that's been that has looked into the sort of parametric nonparametric interpretation of deep Nets at all?",
            "All the universal approximation properties of neural Nets is really about saying as the number of parameters grows, you can approximate any distribution.",
            "So you basically have all the same characteristics of standard nonparametric methods that you can approach the true data function as the amount of data and capacity grow to Infinity at the right rate.",
            "So there's no such thing as they start with the right training your Mac, and with a large data set and the neural net somehow grew in a non parametric yes fashion so that there.",
            "So there have been historically a lot of methods that do that very explicitly back in the 90s there was a whole literature on growing neural Nets and adding units and noticing that units are unhappy and oscillating and cutting them up into pieces and so on.",
            "I think that is the current methods that we use make that unnecessary.",
            "And so the you know the current methods are more elegant.",
            "The optimization is better, and so we don't need to do this kind of hacking of you know, we add something, we remove something and so.",
            "So I have two questions about the Regulation, the way that you do not share this location.",
            "Sorry.",
            "I mean, the regularization developing authorization is just to decrease the variance of the hypothesis.",
            "So first question is if we have enough data, do we need your validation or not?",
            "The second question is why would lorizon network then we can just decrease the size of the hypothesis that the number of problems or something.",
            "OK?",
            "So first question is.",
            "In the IF we have a lot of data, do we need regularization and in principle in the limit of infinite data you don't OK because in the limit of infinite data, if you think of regularization as a sort of beige and prior, the prior is going to wash out and you gotta do Max likelihood on that data.",
            "However, we never have an infinite amount of data.",
            "We always have a finite amount of data.",
            "Therefore in practice it is always a smart idea to use some form of regularization.",
            "And the second question.",
            "Can you repeat that, sorry.",
            "If it's safe to go to just to decrease the variance, right?",
            "Yeah, so so, why not just drop the size rather than do regularization and?",
            "The way the way I think about it is that you want to control the size of the hypothesis space and regularization gives you a very nice, uniform way of doing that.",
            "And it has one parameter that you control, and that parameter essentially has a nice geometric interpretation, as we've seen, and so you know, it's all good.",
            "You kind of let the algorithm decide how many things it needs.",
            "In there you could.",
            "You could control the number of units, but then the overfitting phenomenon does not always come as a direct sort of connection with the number of parameters.",
            "There are other things that come into play as well.",
            "So for example, if you have certain types of units and deep nuts, things like sigmoids, you can have saturation.",
            "Saturation essentially means that you can't move those units anywhere.",
            "You're memorizing whatever you had in the past.",
            "You can't adapt anymore to future data, so that's a form of sort of.",
            "Let's call it overtraining, not quite over fitting that regularization can help you avoid.",
            "You know, because you're right, shrink and then your parameters are more free to move, so there's other reasons for doing this kind of thing, not just you know, not just controlling for numbers of units specifically, so I would add that in the last few years it's been pretty obvious that what works really well.",
            "It's have huge yo Mets.",
            "There are regular eyes one way or another, usually by injecting noise.",
            "And that just works much better than having tightly parameterized models, for reasons that may be due to optimization.",
            "But we should stop here and thank Joyner."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I was asked to sort of do a broad introduction to machine learning just to make sure that everybody's on the same page.",
                    "label": 0
                },
                {
                    "sent": "If you've taken the machine learning class before, you would have seen many of these topics, but I hope you can still get a little bit of a refresher and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And get something out of this.",
                    "label": 0
                },
                {
                    "sent": "So the plan for today is we're going to talk a little bit about the types of machine learning problems that exist.",
                    "label": 1
                },
                {
                    "sent": "We're going to talk about linear approximation, objective functions, chosen different ways of optimizing these.",
                    "label": 0
                },
                {
                    "sent": "We're going to discuss bias variance, overfitting, and underfitting and regularization, and one of the threads is going to be that we're going to talk about probabilistic interpretations of these methods because the probabilistic interpretations really allow us to ground the algorithms and to understand.",
                    "label": 0
                },
                {
                    "sent": "What they do?",
                    "label": 0
                },
                {
                    "sent": "They don't necessarily always give us the best algorithms, but they give us sort of a good understanding.",
                    "label": 0
                },
                {
                    "sent": "So machine.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Running is very broad as as you know, there's sort of three different types of machine learning problems.",
                    "label": 0
                },
                {
                    "sent": "Supervised learning and unsupervised learning is what you hear about most of the time reinforcement learning as you mentioned is on the rise, and there's going to be a day dedicated to it.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Towards the end of the week.",
                    "label": 0
                },
                {
                    "sent": "Supervised learning is perhaps the standard thing that you're used to.",
                    "label": 1
                },
                {
                    "sent": "You have examples with some inputs and some desired output.",
                    "label": 0
                },
                {
                    "sent": "You get a set of these examples and what you're trying to do is learn a function that Maps inputs into output of this type.",
                    "label": 1
                },
                {
                    "sent": "And the goal is to obtain such a function in order to minimize loss or to optimize some kind of objective.",
                    "label": 0
                },
                {
                    "sent": "And we're going to be talking about what kinds of objectives might be good to optimize.",
                    "label": 1
                },
                {
                    "sent": "An ideally when you do the optimization, you would like it to work well on all the possible instances on the distribution of instances that are out there.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, you don't have access to this distribution, you only have access to a finite sample of data, and so a lot of the problems that arise and that we need to handle are sort of driven by the fact that only a finite sample of data is available and we need to sort of make do.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With that so this is typical example of supervised learning.",
                    "label": 0
                },
                {
                    "sent": "You have some images you'd like to learn a system that can do face detection and face recognition based on examples of images where there might be faces.",
                    "label": 1
                },
                {
                    "sent": "There might be multiple faces and so on.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reinforcement learning is a little bit of a different problem, where the signal that you get is not as strong.",
                    "label": 1
                },
                {
                    "sent": "So basically you get some training experience by interacting with an environment.",
                    "label": 1
                },
                {
                    "sent": "Maybe you have a stock market agent that's on the market.",
                    "label": 0
                },
                {
                    "sent": "It observes values of different stocks, and it can make trades, and it can make investments so it can do things.",
                    "label": 1
                },
                {
                    "sent": "It has some actions that are available to it, and there's a reward signal that comes back.",
                    "label": 0
                },
                {
                    "sent": "For example, the agent might be making money or losing money, so it might be getting positive rewards and negative rewards.",
                    "label": 0
                },
                {
                    "sent": "However, there's never.",
                    "label": 0
                },
                {
                    "sent": "Direct Association between the action that's just been done and the reward that's that's given, and the reward may well be delayed, and that's sort of what makes this problem quite interesting.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is a cartoon of an early reinforcement learning signal, a system that was done by Jerry Tesoro in the early 90s.",
                    "label": 0
                },
                {
                    "sent": "This is think of this as an early precursor to Alpha go.",
                    "label": 0
                },
                {
                    "sent": "This is a system that learned by interacting with itself by playing lots of games and became the best player in the world at TD Gammon.",
                    "label": 1
                },
                {
                    "sent": "So I'm not going to say anymore about that because we're going to have a lot on reinforcement learning.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On Friday.",
                    "label": 0
                },
                {
                    "sent": "Unsupervised learning is perhaps the trickiest problem to formulate.",
                    "label": 1
                },
                {
                    "sent": "You have training experience in the form of unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "Just stuff out there and your goal is to find some kind of structure.",
                    "label": 0
                },
                {
                    "sent": "So clustering, algorithms, dimensionality reduction algorithms, algorithms that try to get that latent variables in the data, all kind of fall into this category, and we often don't have one single correct answer which makes this problem slightly more difficult.",
                    "label": 1
                },
                {
                    "sent": "So again, there's going to be discussion during the week.",
                    "label": 0
                },
                {
                    "sent": "Of different algorithms that do once.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Supervised learning this is just an example that I thought I'd show you of sort of interesting supervised learning going on.",
                    "label": 0
                },
                {
                    "sent": "This is a cancer data set.",
                    "label": 0
                },
                {
                    "sent": "Genes are measured and then you do cluster analysis in order to determine if there are certain clusters that are correlated together and the interesting thing here is that even though you do this unsupervised, what comes out as correlation with clinical outcomes that was not known before.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So that's about the types of machine learning.",
                    "label": 0
                },
                {
                    "sent": "Now we're going to start introducing a little bit of notation and discussing sort of the broad topics.",
                    "label": 0
                },
                {
                    "sent": "This is an example of a data set.",
                    "label": 1
                },
                {
                    "sent": "This is the Wisconsin breast cancer data set, so it's images of pathology that have been sort of segmented by an expert and the first question that comes up when you're faced with a data set like this is what kind of input representation do we want to have?",
                    "label": 0
                },
                {
                    "sent": "You could be working with the image and the pixels in the image.",
                    "label": 0
                },
                {
                    "sent": "You could do some image feature extraction.",
                    "label": 0
                },
                {
                    "sent": "Or you could do something.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More complicated like talk to the expert and actually get some features that the expert nodes are important.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case we have some features that have been extracted that are measurements on the different parts of the image.",
                    "label": 0
                },
                {
                    "sent": "And we have some desired outputs that we're trying to predict.",
                    "label": 0
                },
                {
                    "sent": "In this case, there's two outputs.",
                    "label": 0
                },
                {
                    "sent": "One is the outcome.",
                    "label": 0
                },
                {
                    "sent": "Does the cancer recur or not, and then the other one is.",
                    "label": 0
                },
                {
                    "sent": "If the cancer recurs, what's the time until that happens?",
                    "label": 0
                },
                {
                    "sent": "So in general, the output the desired output that we're trying to predict could be discrete, or it could be continuous, or in fact could be more complicated than that.",
                    "label": 0
                },
                {
                    "sent": "Could be something like a tree or a graph, and so on.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just in terms of terminology, when when you're faced with a table of data like this, we often call these columns input variables or features or attributes.",
                    "label": 1
                },
                {
                    "sent": "We call these columns here that we're trying to predict output variables or targets, and each of these rows in as an example, or an instance, and in this case we're looking at two specific problems which are kind of easier to understand and to work with.",
                    "label": 1
                },
                {
                    "sent": "One is a problem of binary classification.",
                    "label": 0
                },
                {
                    "sent": "The re kernel recur label.",
                    "label": 0
                },
                {
                    "sent": "And then the other one is regression, so we're just trying to predict the array.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Number there.",
                    "label": 0
                },
                {
                    "sent": "And I'm always going to use access to denote the inputs and why student out the outputs.",
                    "label": 1
                },
                {
                    "sent": "And I think this will be consistent in the follow up talk as well.",
                    "label": 1
                },
                {
                    "sent": "And very often we think of this here as a matrix of data.",
                    "label": 0
                },
                {
                    "sent": "Big X. OK, that has number instances by number of columns and then the output.",
                    "label": 0
                },
                {
                    "sent": "You can think of them as a vector Y and so the bold denotes matrix.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Convectors so now we get to the supervised learning problem.",
                    "label": 1
                },
                {
                    "sent": "What we want is to learn a mapping from X to Y.",
                    "label": 0
                },
                {
                    "sent": "We're going to call such a mapping of hypothesis and we would like this to be a good predictor of the output, and this could be called classification or regression or structured prediction in more complicated cases.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we've already kind of decided on what the input set space would be.",
                    "label": 1
                },
                {
                    "sent": "We've decided on the output space.",
                    "label": 1
                },
                {
                    "sent": "Now we're choosing a class of hypothesis or representations.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These functions H and so this is a sort of cartoon example.",
                    "label": 0
                },
                {
                    "sent": "If I have some points, the simplest thing that we can.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Think of is to put a line through these.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Point OK, so here is a linear hypothesis H. the W means that there is a parameter vector W that is sort of defining this hypothesis and we have inputs and so in this case we just have a linear combination of the of the inputs weighted by these parameters or weights, and what we would like our algorithm to do is to determine the best weight vector.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now how should we pick this weight vector?",
                    "label": 1
                },
                {
                    "sent": "Well, we should pick it in such a way as to get a good fit to the data.",
                    "label": 0
                },
                {
                    "sent": "So now we need to formalize what does that mean and that we do this using an error function or a cost function or loss function.",
                    "label": 1
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "Or sometimes people call this the optimization objective, in which case you can talk about either loss or sort of the quality update.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And as I'm sure you know, one of the standard things that people do is to use the sum of squared error or the mean squared error as the objective which is depicted here.",
                    "label": 0
                },
                {
                    "sent": "This is just measuring the difference between the output of the hypothesis and the actual output observed in the data.",
                    "label": 1
                },
                {
                    "sent": "You squared this up and there is a lot of nice reasons why this is kind of a good error function when you're trying to do regression, we're going to talk a little bit about the probabilistic assumptions about this in a minute.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For now, let's just sort of stick with this and say OK. Now we have this.",
                    "label": 0
                },
                {
                    "sent": "This error function.",
                    "label": 0
                },
                {
                    "sent": "We have our hypothesis class.",
                    "label": 0
                },
                {
                    "sent": "What we need to do is to search within the hypothesis class for the best hypothesis.",
                    "label": 1
                },
                {
                    "sent": "According to this error function.",
                    "label": 0
                },
                {
                    "sent": "OK, so we chose a hypothesis.",
                    "label": 0
                },
                {
                    "sent": "We chose an objective and now we need to optimize that objective and we need to see how we can do that.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And one of the things that you're going to see a lot during this week is the use of gradient based methods.",
                    "label": 1
                },
                {
                    "sent": "In order to do this optimization.",
                    "label": 0
                },
                {
                    "sent": "So just like a refresher reminder can take partial derivatives of a function, you can take a gradient.",
                    "label": 1
                },
                {
                    "sent": "The gradient is just a vector of partial derivatives, and so a standard way to do the optimization is to take the gradient and set it to 0 and that will give you extreme points.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the function.",
                    "label": 0
                },
                {
                    "sent": "So in our case we have an objective function JFW OK depends on the parameter vector W. We can take the derivative of this.",
                    "label": 0
                },
                {
                    "sent": "We can take the gradient in this case because we have such a simple function and a simple objective.",
                    "label": 0
                },
                {
                    "sent": "You can solve this in closed form, not.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go through the algebra and you can get sort of the best value of the parameter vector W and it's got a nice closed form solution in terms of the input and the output.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is all good.",
                    "label": 0
                },
                {
                    "sent": "The solution exists is unique if the columns of X are linearly independent.",
                    "label": 1
                },
                {
                    "sent": "There are several problems with going this route.",
                    "label": 0
                },
                {
                    "sent": "OK, one is that you might have lots and lots of data, so doing this kind of matrix inversion may actually not be feasable.",
                    "label": 0
                },
                {
                    "sent": "Another problem is that maybe your matrix is actually ill conditioned.",
                    "label": 0
                },
                {
                    "sent": "OK, and the more fundamental problem is that we've used a very, very simple hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the one happy case where you can solve things in closed form.",
                    "label": 0
                },
                {
                    "sent": "That's great most of the time we won't be able to do things like this.",
                    "label": 0
                },
                {
                    "sent": "But this is just to give you a warm fuzzy feeling that sometimes it does work OK.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so in general this is a very sort of simple kind of hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "So what do we do to make this more interesting?",
                    "label": 0
                },
                {
                    "sent": "Well, we use a transformation of the input using nonlinear features.",
                    "label": 0
                },
                {
                    "sent": "OK, and this case is basically almost the same.",
                    "label": 0
                },
                {
                    "sent": "We use a matrix Phi here to denote the features.",
                    "label": 0
                },
                {
                    "sent": "So the way you think about it is that you can take the input and map it through a function Phi into some kind of space that you want.",
                    "label": 0
                },
                {
                    "sent": "And now you have a lot of choices about what fine might be reduced polynomials.",
                    "label": 0
                },
                {
                    "sent": "You could use Gaussians, sigmoids, Boolean combinations if you have binary features, lots of different things and depending on the feature space you will get more complicated hypothesis or more simple hypothesis.",
                    "label": 0
                },
                {
                    "sent": "These are still all linear hypothesis, not in the input, but in terms of the parameter vector W. So if we look at the hypothesis function.",
                    "label": 0
                },
                {
                    "sent": "H It's a linear function of W, even though it's not a linear function of the input, and that means that the optimization is still going to be quite easy to do, and we still get a closed form.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cat.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So the other thing that I would like to point out is that in these sort of.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Linear models we actually fix.",
                    "label": 1
                },
                {
                    "sent": "What the basis functions are.",
                    "label": 0
                },
                {
                    "sent": "OK, so you decide ahead of time you want to take the inputs and take polynomials up to degree two OK. Or you decide you want to take Gaussians and you want to take them regularly spaced with certain means and certain variances, and there's a fixed number of basis functions that does not depend on how much data you actually have.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the flavor of what we call parametric methods parametric methods.",
                    "label": 0
                },
                {
                    "sent": "Have a fixed size parameter vector the size of that parameter vector is decided ahead of time and the basis functions are fixed.",
                    "label": 0
                },
                {
                    "sent": "Only the parameters are moving.",
                    "label": 0
                },
                {
                    "sent": "There are other kinds of methods.",
                    "label": 0
                },
                {
                    "sent": "Nonparametric methods allow the representation to grow with the size of the data.",
                    "label": 1
                },
                {
                    "sent": "So nearest neighbor methods for example, or certain forms of locally weighted regression are nonparametric methods.",
                    "label": 0
                },
                {
                    "sent": "I'm not really going to be talking about that.",
                    "label": 0
                },
                {
                    "sent": "In this talk, the deepnet methods that you're going to hear a lot about in this week are essentially parametric methods, but with very very large sets of parameters.",
                    "label": 0
                },
                {
                    "sent": "OK, and any questions or comments so far.",
                    "label": 0
                },
                {
                    "sent": "Like good OK?",
                    "label": 0
                },
                {
                    "sent": "So now let's look.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look at the problem that's created by the fact that we have sort of fixed size hypothesis that may somehow reflect or not what we have in the data.",
                    "label": 0
                },
                {
                    "sent": "So we have a set of data.",
                    "label": 0
                },
                {
                    "sent": "OK, the blue points there are data points, and now we're doing some fits through these data points.",
                    "label": 0
                },
                {
                    "sent": "OK, so here we fit an order two polynomial.",
                    "label": 0
                },
                {
                    "sent": "You can see that it looks pretty good.",
                    "label": 0
                },
                {
                    "sent": "OK goes pretty close to the points, OK?",
                    "label": 1
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we could do an order 3 fit.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or an order for fit.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or in order 5.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "6.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go on OK.",
                    "label": 0
                },
                {
                    "sent": "Which of these is the best 5th to the data?",
                    "label": 1
                },
                {
                    "sent": "Is it this one?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With this said, this is what you mean by fifth.",
                    "label": 0
                },
                {
                    "sent": "So that's part of the problem.",
                    "label": 0
                },
                {
                    "sent": "Depends what we mean by fit to the data OK?",
                    "label": 1
                },
                {
                    "sent": "So what can we mean?",
                    "label": 0
                },
                {
                    "sent": "Well, one thing we could mean is what's the error on the training set that we're using OK and we can do something really good on the train.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Things that we can do this OK?",
                    "label": 0
                },
                {
                    "sent": "We can actually find high enough degree polynomial that will exactly fit the training set and the error on the training set is zero OK. Is this a good fit to the data?",
                    "label": 1
                },
                {
                    "sent": "Well, sort of.",
                    "label": 0
                },
                {
                    "sent": "Our intuition says no, OK, why?",
                    "label": 0
                },
                {
                    "sent": "Because it's very wild.",
                    "label": 0
                },
                {
                    "sent": "OK, it goes through the points, but it seems to have no rhyme or reason.",
                    "label": 0
                },
                {
                    "sent": "In other words, we're not confident that this kind of fit actually generalizes from the training data that we have to new data that we might see in the future.",
                    "label": 0
                },
                {
                    "sent": "OK, probably some.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other things you know?",
                    "label": 0
                },
                {
                    "sent": "Maybe order to order three might actually be better.",
                    "label": 0
                },
                {
                    "sent": "OK, so this points to a problem of a mismatch between what we would like to measure in the objective of the optimization and what we can actually measure.",
                    "label": 0
                },
                {
                    "sent": "OK, what we?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Would like to do.",
                    "label": 0
                },
                {
                    "sent": "Is to measure the true error on the whole distribution of the data, but we don't have access to that.",
                    "label": 1
                },
                {
                    "sent": "We only have access to a finite sample.",
                    "label": 1
                },
                {
                    "sent": "As a result, we can only measure things on that finite sample of data.",
                    "label": 0
                },
                {
                    "sent": "OK, now if all we do is train and test on the same sample of data, then we're going to run into trouble.",
                    "label": 0
                },
                {
                    "sent": "OK, we essentially get.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Solutions that look like this, where we have, you know, the training data fit perfectly, but not really good hypothesis, not hypothesis that generalize well.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a really, really important problem and all of machine learning called overfitting.",
                    "label": 0
                },
                {
                    "sent": "And it basically means that we find the hypothesis that fits the training data very well, but does not generalize well to unseen examples and essentially the nature of this comes from having too many parameters for how much data we have.",
                    "label": 1
                },
                {
                    "sent": "Again, we're going to make this a little bit more formal now.",
                    "label": 1
                },
                {
                    "sent": "A lot of the stuff that you're going to hear during the week is methods to get around this problem.",
                    "label": 0
                },
                {
                    "sent": "When you do have.",
                    "label": 0
                },
                {
                    "sent": "Of parameters and not very much training data.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is another example of the picture taken from Bishop's book of different hypothesis fit through these blue circles.",
                    "label": 0
                },
                {
                    "sent": "OK, here we have one specific function.",
                    "label": 0
                },
                {
                    "sent": "That's the green function.",
                    "label": 0
                },
                {
                    "sent": "That's sort of the true function.",
                    "label": 1
                },
                {
                    "sent": "The points were generated by applying a little bit of noise to that function, and then we do fit a various degrees of polynomials, and as you can see.",
                    "label": 0
                },
                {
                    "sent": "If your degree is too small, OK, basically can't fit the data.",
                    "label": 0
                },
                {
                    "sent": "That's called underfitting.",
                    "label": 1
                },
                {
                    "sent": "OK, it means that your hypothesis space is too simple and you cannot represent the true function, doesn't allow you to represent the true function.",
                    "label": 0
                },
                {
                    "sent": "If you have a hypothesis space that's too complicated, like the degree 9 polynomials over here, you have the overfitting problem that you have just seen.",
                    "label": 0
                },
                {
                    "sent": "In other words, you can represent perfectly the training data.",
                    "label": 1
                },
                {
                    "sent": "You can in fact memorize it because you have enough parameters to memorize it, but there's no generalization OK, and So what we would like to have is the learning method that goes in between and finds the right complexity of the hypothesis, and so now we're going to have to talk about.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How to do that?",
                    "label": 0
                },
                {
                    "sent": "So this is just to give you the definition of overfitting a little bit more formally.",
                    "label": 0
                },
                {
                    "sent": "OK, so in general we have for any hypothesis a true error, which we did not buy.",
                    "label": 0
                },
                {
                    "sent": "J Star J Star is the expected error when the data comes from the true distribution OK?",
                    "label": 1
                },
                {
                    "sent": "But we don't have all the data.",
                    "label": 0
                },
                {
                    "sent": "OK, So what do we do?",
                    "label": 0
                },
                {
                    "sent": "We get a sample of data Big D. That's our data set.",
                    "label": 0
                },
                {
                    "sent": "And so we estimate this true error by a finite sample.",
                    "label": 0
                },
                {
                    "sent": "OK, now the problem is that if we use this finite sample both to find the hypothesis and to estimate the error, we might be fooling ourselves so we can be in a situation where we find a hypothesis that's better on the data set that we have.",
                    "label": 0
                },
                {
                    "sent": "That, but which is actually worse when we look at the entire data set, and so we need theoretical and empirical methods to guard against this, we're going to talk a little bit about cross validation and about regularization as two different ways of doing.",
                    "label": 1
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "How do you know if you have a problem?",
                    "label": 0
                },
                {
                    "sent": "Well, this is a typical plot that you might see when you have a hypothesis space and you have a complexity parameter over here.",
                    "label": 0
                },
                {
                    "sent": "OK, so here we're going from simple hypothesis on that side to more complicated hypothesis going this way, and you have the error and you are measuring the error now on two different datasets.",
                    "label": 0
                },
                {
                    "sent": "OK, the training data set is the one that's used to obtain the parameters of the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And the test set is a test is a set of data that's not been used during the training process or has been untouched in the training.",
                    "label": 1
                },
                {
                    "sent": "So this is a fairly typical graph where you see the training error going down as the complexity of the hypothesis increases, and then you see this U shaped curved in the test error where the test error starts high and then goes down to some good level and then goes up again.",
                    "label": 0
                },
                {
                    "sent": "OK so on that end of the spectrum.",
                    "label": 0
                },
                {
                    "sent": "OK when you have very simple hypothesis you're essentially underfitting your hypothesis are two simple.",
                    "label": 0
                },
                {
                    "sent": "They cannot capture the complexity in the data so both the training and the test there are high.",
                    "label": 0
                },
                {
                    "sent": "When you have over fitting your training error is actually low, but the test error is high because you're not generalizing very well and what we would like is a model selection procedure or search procedure that brings us in the happy middle zone.",
                    "label": 0
                },
                {
                    "sent": "OK, what this is also telling you is that it is really, really important to have a separate set of data on which you're doing evaluations.",
                    "label": 0
                },
                {
                    "sent": "OK, because otherwise the training set is not a reliable indicator of how well you're doing so.",
                    "label": 1
                },
                {
                    "sent": "What we will do is we will always take the data that we have and separated out OK. You'll have a training set.",
                    "label": 0
                },
                {
                    "sent": "You typically have a validation set which we use in order to train hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "OK, so decide what the hypothesis space might be, decide parameters of the optimization procedure and so on.",
                    "label": 0
                },
                {
                    "sent": "You're going to see a lot more on this in you guys talk and then you have a test set that's not touched in this process at all that you just at the end in order to establish how good.",
                    "label": 0
                },
                {
                    "sent": "Your approximate are actually is and in order to compare different algorithms and sometimes these sets are specified for you ahead of time, sometimes you have to go through a procedure where you take your whole data set, then you chop it up into these pieces and you make sure that the pieces are balanced and so on in order to obtain accurate estimates of how good your hypothesis is.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a procedure called Cross validation where we take the data and we split it up, making sure these tests are disjoint and in cross validation we typically repeat this procedure multiple times.",
                    "label": 0
                },
                {
                    "sent": "OK, now of course, the more times you repeat this procedure, the more expensive the computation is.",
                    "label": 0
                },
                {
                    "sent": "But I'm not going to be worried about this.",
                    "label": 0
                },
                {
                    "sent": "OK, well, always encourage you to do this a lot.",
                    "label": 0
                },
                {
                    "sent": "OK and repeat it in order to get good accurate estimate of.",
                    "label": 0
                },
                {
                    "sent": "The generalization capability.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we're going to take a little bit of a look at the error in estimators and what's the anatomy of that error and how does that relate to this kind of overfitting phenomenon.",
                    "label": 0
                },
                {
                    "sent": "OK, so if we have some examples OK, and let's say that we have outputs that are generated from some true function F OK plus some Gaussian noise, OK, Gaussian noise of 0 mean and some unknown standard deviation.",
                    "label": 1
                },
                {
                    "sent": "And now we fit a linear hypothesis.",
                    "label": 1
                },
                {
                    "sent": "OK, to minimize the squared error.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we have.",
                    "label": 0
                },
                {
                    "sent": "We've seen that we sort of have two different kinds of errors that can come in.",
                    "label": 0
                },
                {
                    "sent": "One is maybe your hypothesis is too simple.",
                    "label": 0
                },
                {
                    "sent": "It's just the line OK even with basis functions that are nonlinear and might still be too simple.",
                    "label": 0
                },
                {
                    "sent": "So there's.",
                    "label": 1
                },
                {
                    "sent": "There's a kind of error that comes from the hypothesis being unable to represent the data set that it needs to represent.",
                    "label": 0
                },
                {
                    "sent": "There's a different kind of error which is due to the fact that your hypothesis maybe has too many parameters.",
                    "label": 0
                },
                {
                    "sent": "OK, and we run into trouble because we can memorize the data.",
                    "label": 0
                },
                {
                    "sent": "So there is these two sources of error.",
                    "label": 0
                },
                {
                    "sent": "One is sort of a systematic prediction error due to the hypothesis class and the other one is a variability.",
                    "label": 1
                },
                {
                    "sent": "That means that if I take a different data set and I've hit the same hypothesis, you can sing the same procedure and so on.",
                    "label": 0
                },
                {
                    "sent": "I'm going to get different results and so now we're going to.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sort of split this up OK.",
                    "label": 0
                },
                {
                    "sent": "So we can think of what's the expected prediction error at a particular data point X OK, and in order to make the analysis easier, we're going to make an assumption.",
                    "label": 1
                },
                {
                    "sent": "That's quite standard now in machine learning called the idea assumption.",
                    "label": 1
                },
                {
                    "sent": "So we're going to assume that all the examples are drawn independently from the distribution of data and what we're interested in is what's the expected squared error at a given point.",
                    "label": 0
                },
                {
                    "sent": "OK, overall training sets of a certain size that are drawn.",
                    "label": 1
                },
                {
                    "sent": "From the probability distribution.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We are going to try and decompose this expectation into different parts.",
                    "label": 0
                },
                {
                    "sent": "OK, in order to understand what the different components of the error acts.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We are OK.",
                    "label": 0
                },
                {
                    "sent": "So this is just a reminder of statistics definitions.",
                    "label": 0
                },
                {
                    "sent": "You have the expected value or the mean of the random variable you have the variance and you can write the variance as the expectation of the square minus the square of the mean.",
                    "label": 1
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's just a short proof of that statement, so we're going to use this at value.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Definition now to kind of massage this this big expectation into different parts.",
                    "label": 0
                },
                {
                    "sent": "So the first thing that we do is we take the square of Y -- H of X and break it up OK. And then, once we've done that, we can, by linearity of expectation, break up the pieces over here, OK, and we're going to have three components.",
                    "label": 0
                },
                {
                    "sent": "OK, one component here is the expectation of Y squared given X expectation of the output given X.",
                    "label": 0
                },
                {
                    "sent": "On one component, here is the expectation of the square of the hypothesis, and we're going to have to use our variance lemma in order to do something interesting with that.",
                    "label": 0
                },
                {
                    "sent": "And then we have this component over here which is expectation of a product.",
                    "label": 0
                },
                {
                    "sent": "But because the noise is drawn before knowing the hypothesis really, we can break that up.",
                    "label": 0
                },
                {
                    "sent": "So the why and the H of X are independent of each other and we can break that up into a product of two expectations.",
                    "label": 0
                },
                {
                    "sent": "So for the first term here, we're going to use.",
                    "label": 1
                },
                {
                    "sent": "The variance lemma OK. Variance lemma says expectation of a square.",
                    "label": 1
                },
                {
                    "sent": "We can write it as the square of the mean plus the variance.",
                    "label": 0
                },
                {
                    "sent": "So we just do that here OK?",
                    "label": 0
                },
                {
                    "sent": "And here by H bar we mean the average prediction for X over hypothesis that are fit with multiple draws of this data set.",
                    "label": 0
                },
                {
                    "sent": "Cat.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Over here, the expectation of Y given X, that's just the expectation of the function plus the Gaussian random noise.",
                    "label": 0
                },
                {
                    "sent": "So it's just the value of the function.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is, this is nice.",
                    "label": 0
                },
                {
                    "sent": "And then for the second term, the expectation of Y squared, we again use the variance lemma OK and we get some interesting terms over here.",
                    "label": 1
                },
                {
                    "sent": "Now we're going to have to look at these terms a little bit more in detail.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To see what they do.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here the you know, once we do cancellations and once we sort of put squares together and so on just a little bit of algebra we get here.",
                    "label": 0
                },
                {
                    "sent": "Three terms that are kind of interesting to look at.",
                    "label": 0
                },
                {
                    "sent": "OK, and I'm actually going to start with this last one the last time here.",
                    "label": 1
                },
                {
                    "sent": "Expected value of y -- F of X squared.",
                    "label": 0
                },
                {
                    "sent": "OK, what is this?",
                    "label": 0
                },
                {
                    "sent": "Well, we said that.",
                    "label": 0
                },
                {
                    "sent": "Oh why is equal F of X.",
                    "label": 0
                },
                {
                    "sent": "Plus epsilon OK.",
                    "label": 0
                },
                {
                    "sent": "So y -- F of X is just the Gaussian random noise, so the expectation of that.",
                    "label": 0
                },
                {
                    "sent": "This case is the noise OK?",
                    "label": 1
                },
                {
                    "sent": "In general, OK, whenever we have additive noise, this kind of expectations expectation of the noise is a component that is not under your control.",
                    "label": 1
                },
                {
                    "sent": "OK, there could be lots of noise, so long as it's additive.",
                    "label": 0
                },
                {
                    "sent": "We're not going to worry about this.",
                    "label": 0
                },
                {
                    "sent": "'cause this is not something that our hypothesis can actually touch.",
                    "label": 0
                },
                {
                    "sent": "It's a term that doesn't depend on.",
                    "label": 0
                },
                {
                    "sent": "We have here an interesting term F of X -- H bar of X squared.",
                    "label": 0
                },
                {
                    "sent": "OK, So what is this F of X -- H bar?",
                    "label": 1
                },
                {
                    "sent": "That's a systematic error.",
                    "label": 0
                },
                {
                    "sent": "OK, it's a systematic error between the true value of a function and sort of the average predicted by the hypothesis and that we can do something about that's basically controlled by our hypothesis class.",
                    "label": 0
                },
                {
                    "sent": "So and so this is essentially the square of the bias, OK?",
                    "label": 1
                },
                {
                    "sent": "And then the first term here H -- H bar squared in expectation.",
                    "label": 0
                },
                {
                    "sent": "That's the variance.",
                    "label": 0
                },
                {
                    "sent": "OK, that's telling you how much H varies around the mean, OK?",
                    "label": 0
                },
                {
                    "sent": "So the noise we're not going to worry about, but these two terms, the square of the bias and the variance, are the ones that are driving the error, and one could be bigger or the other one could be bigger OK, and in fact we're going to have.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To trade these off, typically against each other.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is another picture where we're showing complexity of hypothesis on the X axis.",
                    "label": 0
                },
                {
                    "sent": "We're showing error on the Y axis and you can see the bias square.",
                    "label": 1
                },
                {
                    "sent": "You can see the variance bias squared plus variance, and you can see the test error here.",
                    "label": 1
                },
                {
                    "sent": "OK, so here the bias and variance have been computed analytically because it's a synthetic example.",
                    "label": 0
                },
                {
                    "sent": "OK, so the error that you see over there is in some sense the best case that you can see.",
                    "label": 0
                },
                {
                    "sent": "The test there is actually computed on data, so the tester is higher than the analytical prediction.",
                    "label": 0
                },
                {
                    "sent": "However, you can see that the tester actually mimics very accurately the analytical prediction.",
                    "label": 1
                },
                {
                    "sent": "The other thing that you see is that as bias increases various decreases and vice versa.",
                    "label": 0
                },
                {
                    "sent": "So this is a very typical tradeoff that we see when we play around with the complexity of the hypothesis space.",
                    "label": 1
                },
                {
                    "sent": "We make the hypothesis space more complicated.",
                    "label": 0
                },
                {
                    "sent": "That intuitively means hypothesis is going to have more parameters.",
                    "label": 0
                },
                {
                    "sent": "The bias is going to go down 'cause we can now represent more functions, but the variance is going to go up OK because we have more parameters and potentially we might need more data in order to deal with this.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is always a tradeoff.",
                    "label": 1
                },
                {
                    "sent": "OK, you choose a more expensive expressive class of hypothesis.",
                    "label": 1
                },
                {
                    "sent": "That means you have higher variance and you're going to lower your bias.",
                    "label": 1
                },
                {
                    "sent": "And typically this is not a black and white trade off because it depends on the amount of data that you have.",
                    "label": 0
                },
                {
                    "sent": "If you have very little data, you're going to have to tolerate bias 'cause there's nothing else you can possibly do.",
                    "label": 0
                },
                {
                    "sent": "And if you have a lot of data, then we can go for very expressive hypothesis classes and so part of the sort of deep learning.",
                    "label": 1
                },
                {
                    "sent": "Revolution has been in fact driven by the fact that massive amounts of data are available, and so we can actually fit these complicated hypothesis.",
                    "label": 0
                },
                {
                    "sent": "There are also other ways of putting in bias control in the hypothesis spaces.",
                    "label": 0
                },
                {
                    "sent": "We're going to talk in a minute about Bayesian methods where essentially inject prior information, and that can also help you keep complexity under control.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's really it's not the hypothesis that's at fault.",
                    "label": 0
                },
                {
                    "sent": "OK, it's really the balance between the hypothesis and the amount of data.",
                    "label": 1
                },
                {
                    "sent": "And so, for example here you have when you have few points, you can't use complicated hypothesis, but when you have lots of points, they support the complicated hypothesis and you can you can use it just fine.",
                    "label": 0
                },
                {
                    "sent": "Cat.",
                    "label": 0
                },
                {
                    "sent": "Any questions or comments about these ideas of bias, variance, overfitting, underfitting?",
                    "label": 0
                },
                {
                    "sent": "You know this is going by very quickly.",
                    "label": 1
                },
                {
                    "sent": "You have access to the slides, so you can actually go through the math.",
                    "label": 0
                },
                {
                    "sent": "If you've never seen this one before.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let's go back and talk a little bit more about the mean squared error and why the mean squared error might be a good idea.",
                    "label": 0
                },
                {
                    "sent": "OK, as an optimization objective, and what's its interpretation?",
                    "label": 0
                },
                {
                    "sent": "So one reason why people like the mean squared error is that it's got a good intuitive feeling.",
                    "label": 0
                },
                {
                    "sent": "If you have real numbers.",
                    "label": 0
                },
                {
                    "sent": "If you have errors, the big errors are amplified.",
                    "label": 1
                },
                {
                    "sent": "The small errors are squished down by using the square.",
                    "label": 1
                },
                {
                    "sent": "Another reason why people like it is that you can take derivatives very easily and so gradient based methods work very well.",
                    "label": 0
                },
                {
                    "sent": "There are actually some interesting geometric interpretations of this.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you consider a linear hypothesis, for example, you essentially imagine that all the hypothesis possible hypothesis lie in a hyperplane.",
                    "label": 0
                },
                {
                    "sent": "A linear hyperplane and then essentially the mean squared error.",
                    "label": 0
                },
                {
                    "sent": "Finding the hypothesis with the minimum mean squared error means that we're finding the projection of the true function onto this space of hypothesis.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's kind of nice.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm more interested in showing you a probabilistic interpretation because this is going to elucidate a little bit.",
                    "label": 0
                },
                {
                    "sent": "What are the assumptions behind using the mean squared error and what?",
                    "label": 0
                },
                {
                    "sent": "How do you go about thinking about your assumptions when you choose objective functions?",
                    "label": 0
                },
                {
                    "sent": "So we're going to make a probabilistic assumption.",
                    "label": 0
                },
                {
                    "sent": "OK, we're going to assume again, that your output Yi is a noisy value that's obtained by using a hypothesis from your hypothesis class plus some Gaussian noise.",
                    "label": 1
                },
                {
                    "sent": "OK, so for each example HW, excise the output of the hypothesis epsilon.",
                    "label": 0
                },
                {
                    "sent": "I is the Gaussian noise that we're injecting on to this, and that gives you the why, I.",
                    "label": 0
                },
                {
                    "sent": "And now we're trying to figure out how to choose the best parameter vector.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we have a probabilistic system where data is drawn from some probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Noise is drawn from some distribution.",
                    "label": 0
                },
                {
                    "sent": "We're going to want to find a W that gives us.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Best fit OK. How to do this?",
                    "label": 0
                },
                {
                    "sent": "Well because we have a set of probabilistic assumptions we're going to use base theorem in order to figure out what's the best hypothesis.",
                    "label": 0
                },
                {
                    "sent": "OK, So what does best DM say?",
                    "label": 0
                },
                {
                    "sent": "It says the probability of a hypothesis given the data is equal to the probability of the data given the hypothesis times the probability of the hypothesis and then the denominator.",
                    "label": 1
                },
                {
                    "sent": "Here is the probability of the data.",
                    "label": 0
                },
                {
                    "sent": "We don't really care about that, because that doesn't depend on our hypothesis.",
                    "label": 0
                },
                {
                    "sent": "If we just want to solve an optimization problem, it's not going to influence us.",
                    "label": 0
                },
                {
                    "sent": "One way or another, so we're going to kind of ignore the denominator and focus on the things that are here on top OK.",
                    "label": 0
                },
                {
                    "sent": "So what do we have on top?",
                    "label": 1
                },
                {
                    "sent": "We have PFD given H OK, that's the likelihood of the data.",
                    "label": 0
                },
                {
                    "sent": "And we have PFH.",
                    "label": 0
                },
                {
                    "sent": "That's a prior OK, which is a prior on the probability.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Different hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So now we can ask a more specific question, not what's the best hypothesis, but what's the most probable hypothesis given the training data?",
                    "label": 1
                },
                {
                    "sent": "So we think the learning now essentially as a kind of inference process, where the data is evidence and the hypothesis space we want to explore an.",
                    "label": 0
                },
                {
                    "sent": "So we're going to sort of solve this maximization problem Max a posteriori maximization problem where we want to find the most likely hypothesis given the data.",
                    "label": 1
                },
                {
                    "sent": "Again we use Bayes theorem, so that means we just want.",
                    "label": 0
                },
                {
                    "sent": "The argmax of PFD given H times pH.",
                    "label": 0
                },
                {
                    "sent": "And so here we've dropped the FD because it doesn't depend on age and so it doesn't effect the maximization.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now I can make some further assumptions.",
                    "label": 0
                },
                {
                    "sent": "OK, we can assume that all hypothesis are equally likely.",
                    "label": 1
                },
                {
                    "sent": "OK. That's also an assumption that people often make.",
                    "label": 0
                },
                {
                    "sent": "And so in this case, what we want is a maximum likelihood hypothesis, and otherwise we want to find the hypothesis that maximizes the likelihood of the data.",
                    "label": 1
                },
                {
                    "sent": "And to do this efficiently, we're again going to make the standard assumption that the data is drawn IID from some distribution.",
                    "label": 0
                },
                {
                    "sent": "And so we can simplify PFD given H into a product of probabilities of each example given the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And again here we can simplify things a little bit by saying this is the probability of the output given the input and the hypothesis times the probability of the input OK. Probability of the input is not under our control.",
                    "label": 0
                },
                {
                    "sent": "That's the environment.",
                    "label": 0
                },
                {
                    "sent": "That's the world, it's the data distribution OK, and P of Y given XY&H is something where we've made an assumption.",
                    "label": 0
                },
                {
                    "sent": "OK, we've made the Gaussian assumption.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we do.",
                    "label": 0
                },
                {
                    "sent": "The standard thing would take this likelihood.",
                    "label": 0
                },
                {
                    "sent": "We're going to take a log of it in order to not work with products, but work with sums and we get the log likelihood.",
                    "label": 0
                },
                {
                    "sent": "Here we have two sums, log of P, XI and log of PFY.",
                    "label": 0
                },
                {
                    "sent": "Given XINH, the second sum here only depends on the data set, not on H, so we're not going to have to care about it since we're just going to do.",
                    "label": 1
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Optimization.",
                    "label": 0
                },
                {
                    "sent": "And under the assumption that we have Gaussian noise Now the first part OK, the term over here is actually quite nice.",
                    "label": 1
                },
                {
                    "sent": "OK, so the likelihood has this sort of Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Turn.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here and we can take the log and maximizing the right side.",
                    "label": 1
                },
                {
                    "sent": "Here is the same as minimizing the mean squared error.",
                    "label": 1
                },
                {
                    "sent": "So this is a little bit magical.",
                    "label": 0
                },
                {
                    "sent": "OK, we've made an assumption.",
                    "label": 0
                },
                {
                    "sent": "We've kind of picked the right assumption because we knew it ahead of time and we went through this procedure and what we have obtained is that essentially the mean squared error or the sum squared error is a surrogate for maximum likelihood criterion.",
                    "label": 0
                },
                {
                    "sent": "Maximum likelihood in general says we want to find the most likely hypothesis given the data under the assumption that all hypothesis are equally likely to begin with OK. Um?",
                    "label": 0
                },
                {
                    "sent": "The other thing that's a little bit interesting about this formulation is that it spells out exactly what your assumptions have been OK.",
                    "label": 0
                },
                {
                    "sent": "The data drawn IID.",
                    "label": 0
                },
                {
                    "sent": "We had Gaussian noise applied on top of the true, some true hypothesis from your hypothesis space, and this Gaussian noise has the same standard deviation for all of the examples.",
                    "label": 0
                },
                {
                    "sent": "OK, so under these assumptions, the mean squared error is the right error function in the sense that it is giving you is going to give you the same hypothesis maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "Now this also that if your data violates these assumptions, then in some sense using the sum squared error is not the right thing to do OK.",
                    "label": 0
                },
                {
                    "sent": "In particular, if you have, let's say, standard deviations that depend on the input.",
                    "label": 0
                },
                {
                    "sent": "OK, so that some examples are affected by more noise than others, then using the squared error is the wrong thing to do.",
                    "label": 0
                },
                {
                    "sent": "And what you should do instead.",
                    "label": 0
                },
                {
                    "sent": "If you do a little bit of math, you figure it out quite easily, is to wait the examples differently, OK and.",
                    "label": 0
                },
                {
                    "sent": "Perhaps throw out some examples that are affected by too much noise in order to to do your fits.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "K. So.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I'm going to show you a little picture here.",
                    "label": 0
                },
                {
                    "sent": "OK, to kind of represent this process.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is going to establish a link to a sort of a general class of machine learning algorithms called graphical models.",
                    "label": 0
                },
                {
                    "sent": "I don't know how much you'll see these pictures during this week, but I figured that it might be a good idea for you to actually visualize things this way.",
                    "label": 0
                },
                {
                    "sent": "At least once.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a cartoon of how the data is being generated in the case of linear regression that we've talked about.",
                    "label": 0
                },
                {
                    "sent": "OK, and under the assumptions that we've talked about, so we have some inputs.",
                    "label": 0
                },
                {
                    "sent": "There is a random variable here X. OK, that's drawn from some distribution P of X.",
                    "label": 0
                },
                {
                    "sent": "So each node here is going to be some kind of random variable.",
                    "label": 1
                },
                {
                    "sent": "OK, and the errors are going to show sort of influences between these random variables and at each of these nodes were going to have a conditional distribution of that particular node given its parents.",
                    "label": 0
                },
                {
                    "sent": "OK, so X has no parents, it's just drawn from some distribution which is unknown OK. Epsilon, the noise is also has no parents, is drawn from a normal distribution of mean zero and some variance Sigma that we have some standard deviation Sigma that we don't really know.",
                    "label": 0
                },
                {
                    "sent": "W here.",
                    "label": 0
                },
                {
                    "sent": "Under these assumptions that we've used so far is fixed but unknown.",
                    "label": 1
                },
                {
                    "sent": "OK, and so we're going to try to use this model to infer what W might be given the evidence that's being presented.",
                    "label": 0
                },
                {
                    "sent": "And the output Y is in fact the deterministic node that does the operation in this case, where it takes the output of the hypothesis that depends on W&X and that's the noise that comes from epsilon.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In this case, some of the variables are observed.",
                    "label": 1
                },
                {
                    "sent": "Some of the variables are UN observed OK, we can see X and we can see why, but we don't actually see epsilon, nor do we see W. OK. And we actually don't really know the parameter of the probability distribution that governs epsilon either.",
                    "label": 0
                },
                {
                    "sent": "So this is going to be a very typical case where you have data you have some observed variables.",
                    "label": 0
                },
                {
                    "sent": "You kind of know there are some other variables that are important, but you don't see them.",
                    "label": 0
                },
                {
                    "sent": "Those are called hidden or latent variables and a lot of the time we're going to try to build the model that infers these variables, their probability distributions, and their values from data.",
                    "label": 0
                },
                {
                    "sent": "The other thing that's interesting about this model is that it points out places where we could make more interesting assumptions.",
                    "label": 0
                },
                {
                    "sent": "OK, so for example, here we've assumed that W is fixed but unknown.",
                    "label": 0
                },
                {
                    "sent": "OK, because we're under maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "But now, let's assume that W is actually a random variable.",
                    "label": 0
                },
                {
                    "sent": "OK, so if W is a random variable, then it might be drawn from some probability distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, then we're moving towards Abbasian setting where we actually have priors over the parameters, and we can use the data to infer.",
                    "label": 0
                },
                {
                    "sent": "A posterior probability distribution over the parameters OK. And of course, here we've made a specific assumption about how the output interacts with the input.",
                    "label": 0
                },
                {
                    "sent": "OK, this kind of cartoon is typical of discriminative models, where you have the input sort of determining the output and some kind of sort of close to deterministic fashion.",
                    "label": 0
                },
                {
                    "sent": "But in general we could have variables interacting in all kinds of ways, so we could have many variables.",
                    "label": 0
                },
                {
                    "sent": "We could have arrows going forward and backward, and so on.",
                    "label": 0
                },
                {
                    "sent": "And so you would get a lot more generality by drawing models in that way.",
                    "label": 0
                },
                {
                    "sent": "Are there any questions or comments about this picture about the sort of this graphical models probabilistic view?",
                    "label": 0
                },
                {
                    "sent": "Everybody is very quiet.",
                    "label": 0
                },
                {
                    "sent": "That's kind of suspicious.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cat.",
                    "label": 0
                },
                {
                    "sent": "So now let's talk a little bit about regularization from this kind of perspective.",
                    "label": 0
                },
                {
                    "sent": "OK of graphical models.",
                    "label": 0
                },
                {
                    "sent": "So regularization is a way of controlling the bias variance tradeoff in order to obtain a good value of this tradeoff and it's essential.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Really sort of getting to the punch line.",
                    "label": 0
                },
                {
                    "sent": "It boils down to controlling this W here through some kind of prior.",
                    "label": 0
                },
                {
                    "sent": "OK, that is going to help us inject some bias, but perhaps mop away some of the variants.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now what does regularization usually look like?",
                    "label": 0
                },
                {
                    "sent": "It looks like this.",
                    "label": 0
                },
                {
                    "sent": "We have our initial objective which is J DFW.",
                    "label": 0
                },
                {
                    "sent": "That's to optimize something on the data.",
                    "label": 0
                },
                {
                    "sent": "Either minimize squared error or maximize likelihood or something like this and we add to it a penalty term.",
                    "label": 0
                },
                {
                    "sent": "OK, and this penalty term depends on the weight vector and the penalty term essentially captures some kind of intuition that we have about priors on the hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "What hypothesis?",
                    "label": 0
                },
                {
                    "sent": "Are better than others in the absence of any data and the parameter Lambda over there controls the straight off.",
                    "label": 0
                },
                {
                    "sent": "So the higher I make the Lambda, the more we pay attention to the penalty.",
                    "label": 0
                },
                {
                    "sent": "The lower we make the Lambda, the less we pay attention to this penalty.",
                    "label": 0
                },
                {
                    "sent": "If we set Lambda to 0 then essentially we just try to optimize performance on the data and we don't care at all about the actual prior on the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So in statistics this is called shrinkage.",
                    "label": 1
                },
                {
                    "sent": "In machine learning we call this regularization and Lambda here is called regulation isation coefficient and in principle you have criteria that can help you select this and in practice very often people do cross validation and treat this as a sort of hyperparameter as well.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let's look a little bit at regularization for linear models.",
                    "label": 1
                },
                {
                    "sent": "OK, so here we have a linear model.",
                    "label": 0
                },
                {
                    "sent": "We have the error function and then we have here a term W transpose W that is what's called L2 regularization or weight decay.",
                    "label": 1
                },
                {
                    "sent": "OK, So what does this do?",
                    "label": 0
                },
                {
                    "sent": "It basically says that we would like our weight magnitude to be small.",
                    "label": 0
                },
                {
                    "sent": "OK, 'cause if we emphasize this term and the weight magnitude is high, this is going to make things look worse.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That's why weight decay OK, and the nice thing about this is that of course, here's a quadratic term in the front.",
                    "label": 0
                },
                {
                    "sent": "We also have a quadratic term, so everything is nice and quadratic, and we can take gradients and we can optimize and things work very well.",
                    "label": 0
                },
                {
                    "sent": "In fact, they work very well in closed form, and we get this solution over here where the best weight vector has basically the same form as before except 5.",
                    "label": 0
                },
                {
                    "sent": "Transpose Five has a Lambda times identity matrix added to it.",
                    "label": 1
                },
                {
                    "sent": "OK, so in other words you're adding mass.",
                    "label": 0
                },
                {
                    "sent": "On the diagonal of the spy transpose file.",
                    "label": 0
                },
                {
                    "sent": "OK, that helps you with two things.",
                    "label": 0
                },
                {
                    "sent": "OK, it helps you with making this a little bit better condition.",
                    "label": 0
                },
                {
                    "sent": "OK, and again it sort of drives your weight stored O.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And of course, if Lambda is equal to 0, you get exactly the same solution As for usual linear regression.",
                    "label": 1
                },
                {
                    "sent": "And if Lambda goes to Infinity, then the solution is just going to go to 0.",
                    "label": 0
                },
                {
                    "sent": "So this is called Ridge regression.",
                    "label": 1
                },
                {
                    "sent": "There's a more general class of regularization which actually I'm not going to tell you about really called canal regularization that has all this kind of form.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sort of an alternative view of this.",
                    "label": 0
                },
                {
                    "sent": "OK, which is derived in the slides, but I'm really not going to go through the derivation is the following.",
                    "label": 1
                },
                {
                    "sent": "We could think of this criterion, and as saying we have some objective function here, which is the squared error.",
                    "label": 0
                },
                {
                    "sent": "OK, we're trying to minimize that.",
                    "label": 0
                },
                {
                    "sent": "And at the same time we want to keep the magnitude of the weights bounded OK and this parameter ETA is sort of the inverse of Lambda OK?",
                    "label": 1
                },
                {
                    "sent": "So what is the?",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean, OK, how do we visualize this?",
                    "label": 0
                },
                {
                    "sent": "We basically do the following.",
                    "label": 0
                },
                {
                    "sent": "In general, we would like the weights to be close to zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so you have this red circle over here around the origin.",
                    "label": 0
                },
                {
                    "sent": "That's saying I want the weights to be small, OK?",
                    "label": 0
                },
                {
                    "sent": "And we have a sort of point over here.",
                    "label": 0
                },
                {
                    "sent": "That's the best fit based on the data.",
                    "label": 0
                },
                {
                    "sent": "OK, now what is the best solution according to this criterion?",
                    "label": 0
                },
                {
                    "sent": "Well, it's where these circles intersect.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's going to be on the sort of line that unites these two centers.",
                    "label": 0
                },
                {
                    "sent": "Or if you're many dimensions, is going to be a hyper line.",
                    "label": 0
                },
                {
                    "sent": "So now what happens with the regularization?",
                    "label": 0
                },
                {
                    "sent": "If I if I make Lambda very small, OK, Ada, which is one over Lambda is very big.",
                    "label": 0
                },
                {
                    "sent": "And the circle that surround the origin is going to blow up OK, and all solutions are acceptable essentially.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, when we shrink the circle, OK, we really want the weights to be close to 0.",
                    "label": 0
                },
                {
                    "sent": "That's the emphasis, and so the weights are going to migrate away from the point that's best for the data towards the point that's best for this this prior.",
                    "label": 0
                },
                {
                    "sent": "So that's all to regularization.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is actually quite nice.",
                    "label": 0
                },
                {
                    "sent": "OK, if you find a good value for the regularization parameter, this helps you avoid overfitting.",
                    "label": 1
                },
                {
                    "sent": "If there are irrelevant features in the input, then you're going to get small weights for those features, typically OK without having to do some kind of complicated pre selection procedure where you just keep some features and so on, but their weights are not going to be quite zero.",
                    "label": 1
                },
                {
                    "sent": "OK, they're going to stay a little bit away from zero because there's nothing really encouraging them to be all OK. We're working with the magnitude of the weight vector rather than particular weights.",
                    "label": 0
                },
                {
                    "sent": "So there is a way to to actually get these weights to be equal.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, that's called L1 regularization, OK?",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'll actually show.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The picture first OK, the picture for one regularization is that instead of using a circle around the origin, we use a little diamond OK. And So what we require is for the weights to be inside of this diamond.",
                    "label": 0
                },
                {
                    "sent": "And so now you have the circle.",
                    "label": 1
                },
                {
                    "sent": "Here it's going to touch the diamond somewhere along its edges.",
                    "label": 0
                },
                {
                    "sent": "OK, but one can actually formally show that you are more likely to touch at the corner then to touch in the middle of an edge.",
                    "label": 1
                },
                {
                    "sent": "OK, now that's actually kind of nice because here if you're touching at the corner, that means that one of your weights is actually zero and only the other weight matters.",
                    "label": 0
                },
                {
                    "sent": "So if you have irrelevant features then those irrelevant features essentially will have zero weights, and they'll be thrown out.",
                    "label": 0
                },
                {
                    "sent": "So it's a large class of methods called lasso, very popular in statistics.",
                    "label": 0
                },
                {
                    "sent": "Community works very well with linear approximators.",
                    "label": 0
                },
                {
                    "sent": "Doesn't work so well with non linear approximators, because this kind of constraint is actually a little bit ugly.",
                    "label": 0
                },
                {
                    "sent": "OK, and the optimization procedure is signif.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gently, more elaborate, the type of constraint that we have here is that the sum of the absolute values of the weights has to be bounded by parameter ETA and ETA.",
                    "label": 1
                },
                {
                    "sent": "Again controls the size of this diamond.",
                    "label": 0
                },
                {
                    "sent": "So why is this more complicated?",
                    "label": 0
                },
                {
                    "sent": "While you can easily see that if I take this absolute value, Onyx.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Founded in all possible ways, we get a blow up of these constraints.",
                    "label": 0
                },
                {
                    "sent": "You still have a sort of in principle, a nice optimization procedure, but with lots and lots of constraints and so where is this useful?",
                    "label": 0
                },
                {
                    "sent": "That depends.",
                    "label": 0
                },
                {
                    "sent": "There are some things that go in between where people use sort of L1 style regularization in some parts of the space and then smoothly going to an L2.",
                    "label": 0
                },
                {
                    "sent": "These are called Huber Ized losses.",
                    "label": 0
                },
                {
                    "sent": "Some in some cases those work better.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then either L1 or L2, the advantage of L2 is that it eliminates completely features that are irrelevant, and so in some applications that's actually useful.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you work in medical applications, doctors really want to know what are the three different symptoms that are determining the diagnosis or the five different genes that are determining the diagnosis, and they don't want everything else to be around in other applications.",
                    "label": 0
                },
                {
                    "sent": "This is not so important.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is just to show you sort of visually the effect.",
                    "label": 0
                },
                {
                    "sent": "So that says L1 regularization.",
                    "label": 0
                },
                {
                    "sent": "This is L2 regularization as we vary the strength of the regularization parameter.",
                    "label": 0
                },
                {
                    "sent": "Of course in the end everything goes to zero, the weights go to zero, but as you can see and L1 regularization, certain ways just go to zero and stay O OK. And you can consider that the more important variables are the ones that are lasting longer OK, whereas in L2 everything kind of goes to zero roughly at the same time, and so it's harder to determine which of these things actually has to be.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, not.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now what's the beige and view of this?",
                    "label": 0
                },
                {
                    "sent": "The Bayesian view is that in both of these cases were really what we're dealing with is a prior distribution of our hypothesis OK?",
                    "label": 0
                },
                {
                    "sent": "And when the data comes in, we compute the posterior distribution and the difference.",
                    "label": 1
                },
                {
                    "sent": "Since between L2 and L1 is what kind of distribution do we assume as the prior?",
                    "label": 1
                },
                {
                    "sent": "So in the AL 2 case we have a circular Gaussian that's the prior, and so when we compute the posterior, we also obtain a Gaussian distribution OK, and so for that reason it's actually very easy to work with L2 regularization in many cases and at least all kinds of interesting algorithms, Gaussian processes and so on.",
                    "label": 0
                },
                {
                    "sent": "In the one case, what we use is a double exponential prior.",
                    "label": 0
                },
                {
                    "sent": "OK, that corresponds to this kind of diamond shape.",
                    "label": 0
                },
                {
                    "sent": "This sort of goes out much much quicker than a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And so as a result, you sort of put in a little bit different kind of prior knowledge, and so you're going to get slightly different hypothesis when you do your search.",
                    "label": 0
                },
                {
                    "sent": "This is something that is under your control and the choice is really guided by two criteria.",
                    "label": 0
                },
                {
                    "sent": "One is the ease of the optimization because working with for example with conjugate priors really makes things easy from the point of view of solving the optimization problem or sometimes choosing sort of smoothness in the prior and smoothness in the error function makes gradient based optimization easier to deal with and then the other.",
                    "label": 0
                },
                {
                    "sent": "Sort of important consideration is what do we actually know about the problem, and so here it's sort of it's easy problem.",
                    "label": 0
                },
                {
                    "sent": "It's aggression problems, but often when we deal with structured data, the prior actually reflects something that we know about the hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "For example, if we're trying to infer gene networks, maybe we know that certain genes cannot be connected, and so we can build that into the prior.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is just to give you a cartoon picture of this vision, view of regularization.",
                    "label": 1
                },
                {
                    "sent": "OK, and what we're going to do here is start with a prior over the weight space.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the picture here with the red circle is a Gaussian prior over the white space and it's sort of centered at zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the absence of any data, we can use this to draw weight vectors, and each weight vector is going to be a hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And so here these red lines represent different hypothesis that we've drawn from this prior, and you can see there all over the place.",
                    "label": 0
                },
                {
                    "sent": "All we say is, we'd like the weights to be roughly small.",
                    "label": 0
                },
                {
                    "sent": "OK, but there is no rhyme or reason until you actually see some data.",
                    "label": 0
                },
                {
                    "sent": "Now it's a little bit hard to see, but over here on the right hand side in the 2nd row we have a data point, so little blue circle OK and so now what we do.",
                    "label": 0
                },
                {
                    "sent": "When we do, the regularization essentially is we compute the posterior over the weight space over the parameter space, and that posterior says we would like to fit the data OK and so all the lines are encouraged to go through this point to fit the point OK.",
                    "label": 0
                },
                {
                    "sent": "So compared to here where the lines were all over the place, here we have lines that are still all over the place, but they do fit the blue point that we've just gotten.",
                    "label": 0
                },
                {
                    "sent": "OK. Now what does that mean from the point of view of the weights?",
                    "label": 0
                },
                {
                    "sent": "OK, what it means is that this Gaussian that used to be round OK is no longer round, because we've taken the round prior when we've combined it with the likelihood of the data.",
                    "label": 0
                },
                {
                    "sent": "Likelihood is here OK, this sort of red line likelihood says all weights are good, so long as they fit this point.",
                    "label": 0
                },
                {
                    "sent": "And so when we do that, we get a Gaussian that's more squished OK?",
                    "label": 0
                },
                {
                    "sent": "So on one side we have to go through this this data point that we have on the other side.",
                    "label": 0
                },
                {
                    "sent": "We still still have a lot of freedom, so there's still a lot of variance.",
                    "label": 0
                },
                {
                    "sent": "OK, in the weight vector, but we've restricted this somewhat OK, so now the second point comes in here is the second point.",
                    "label": 0
                },
                {
                    "sent": "And now you can see that we want actually to fit both of these things.",
                    "label": 0
                },
                {
                    "sent": "OK, So what happens is we take this.",
                    "label": 0
                },
                {
                    "sent": "Sort of posterior probability over the weight vector.",
                    "label": 0
                },
                {
                    "sent": "We combine it with a new likelihood from the new point and now we have something that's very sort of concentrated in one spot.",
                    "label": 0
                },
                {
                    "sent": "OK, and now if you look at the lines that result, they all go roughly through the two points.",
                    "label": 0
                },
                {
                    "sent": "There is some variability.",
                    "label": 0
                },
                {
                    "sent": "OK, 'cause we have a distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, but they're all pretty well aligned together.",
                    "label": 0
                },
                {
                    "sent": "And as we get more data, what happens is the spot that tells me what's the best weight vector?",
                    "label": 0
                },
                {
                    "sent": "Kind of squishes in the variance reduces and the lines get more and more aligned together.",
                    "label": 0
                },
                {
                    "sent": "So how does this relate to bias variance?",
                    "label": 0
                },
                {
                    "sent": "Well, we've put in some bias here through the choice of prior OK, and then the data comes in OK and the data is helping to decide how to sort of shrink this in order to actually fit the observations that we have OK. And the more data we have, the more we're going to shrink this OK and the limit of infinite amount of data.",
                    "label": 0
                },
                {
                    "sent": "Maybe we're going to fit this.",
                    "label": 0
                },
                {
                    "sent": "Exactly correct.",
                    "label": 0
                },
                {
                    "sent": "So the posterior is always skewed by the data.",
                    "label": 1
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So why is this interesting?",
                    "label": 0
                },
                {
                    "sent": "Well, it's interesting because it gives us more than just estimates of the values of the output.",
                    "label": 0
                },
                {
                    "sent": "It actually also gives us some kind of uncertainty estimates in where our hypothesis is confident on its output and where it is not OK, so this is sort of another picture of the same problem.",
                    "label": 0
                },
                {
                    "sent": "Basically you have these circles here, which are the data points that are observed.",
                    "label": 0
                },
                {
                    "sent": "The true function is this green function here, and we have these red lines that are drawn.",
                    "label": 1
                },
                {
                    "sent": "From posterior distribution over the weight factor.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is that when we have a data point, the blue point here around that data point, we have little uncertain because we know we have to fit it.",
                    "label": 0
                },
                {
                    "sent": "Not exactly 'cause we're allowed some noise, but more or less, whereas when you're away from the data, there's a lot of uncertainty because you don't really know that you can't really tell what's a good hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And you can see it in these lines.",
                    "label": 0
                },
                {
                    "sent": "They all kind of go through the blue point, but they're all over the place.",
                    "label": 0
                },
                {
                    "sent": "As we get more points.",
                    "label": 0
                },
                {
                    "sent": "OK, these lines focus in order to capture these points outside of where we have data, we still have a lot of uncertainty.",
                    "label": 0
                },
                {
                    "sent": "OK, so the moral of the story is that you can always generalize well around where data actually is.",
                    "label": 0
                },
                {
                    "sent": "If you're working with a Bayesian method, you can actually get analytical estimates sometimes, or empirical estimates of this uncertainty.",
                    "label": 0
                },
                {
                    "sent": "OK, an you can work with multiple hypothesis at the same time.",
                    "label": 0
                },
                {
                    "sent": "It is expensive and it is somewhat unpleasant in the sense that you can point and say, oh, you know this is my function.",
                    "label": 0
                },
                {
                    "sent": "OK now you have a whole space of possible functions and you can draw from that space at the same time you can easily quantify how uncertain you are and the other interesting thing about this picture is that if we see where the uncertainty is high, that indicates perhaps where we should collect more data.",
                    "label": 0
                },
                {
                    "sent": "Now that's not a setting that's often talked about in sort of standard supervised learning.",
                    "label": 0
                },
                {
                    "sent": "It's sort of active learning setting where if we know where uncertainty is, we can actually make a question an ask.",
                    "label": 0
                },
                {
                    "sent": "OK, we want an example in this area.",
                    "label": 0
                },
                {
                    "sent": "What's the label of that example and that can drive the learning?",
                    "label": 0
                },
                {
                    "sent": "There's a very interesting sort of research question of how to do that well.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Efficiently.",
                    "label": 0
                },
                {
                    "sent": "So this is just a picture of continuing this sort of drawing points and you can see that as you draw more and more points, you still have multiple hypothesis in the sort of Bashan view, because you have a distribution of our hypothesis, but they all sort of clustered together in order to fit the data in the limit, as you have an infinite amount of data, the optimization becomes the same as maximum likelihood, but when you have a small amount of data, the prior has a say OK, and so the hypothesis that you get are driven by both the prior.",
                    "label": 0
                },
                {
                    "sent": "And the data.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so beige and the Bayesian view is kind of interesting because it tells us about what are our assumptions.",
                    "label": 1
                },
                {
                    "sent": "It gives us uncertainty estimates.",
                    "label": 1
                },
                {
                    "sent": "It can guide active learning.",
                    "label": 0
                },
                {
                    "sent": "It is tricky.",
                    "label": 0
                },
                {
                    "sent": "OK, in the sense that if you, for example, overwhelm your prior with data too quickly, then the plot prior doesn't really help you.",
                    "label": 0
                },
                {
                    "sent": "It's also tricky because it is sort of expensive to work with this sort of sampled hypothesis.",
                    "label": 0
                },
                {
                    "sent": "But it can be actually quite interesting.",
                    "label": 0
                },
                {
                    "sent": "Are there any questions or comments about that?",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There will be an exam at the end.",
                    "label": 0
                },
                {
                    "sent": "So now the last thing I wanted to mention to you is logistic regression.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Well?",
                    "label": 0
                },
                {
                    "sent": "Because that's sort of the equivalent of linear regression for classification problems, and you know, is going to tell you all about how to do this a lot better.",
                    "label": 0
                },
                {
                    "sent": "But this is kind of the usual statistical view of things.",
                    "label": 0
                },
                {
                    "sent": "So here we have a hypothesis.",
                    "label": 0
                },
                {
                    "sent": "OK, and the hypothesis is a logistic function of this linear combination of the inputs.",
                    "label": 1
                },
                {
                    "sent": "So access the input W. Transpose X is a linear combination and then we do this kind of action and you get this sort of shape.",
                    "label": 0
                },
                {
                    "sent": "Have your function.",
                    "label": 0
                },
                {
                    "sent": "That goes kind of like this.",
                    "label": 0
                },
                {
                    "sent": "You'll see a lot more about this later.",
                    "label": 0
                },
                {
                    "sent": "It's also called sigmoid neuron in the neural net literature.",
                    "label": 0
                },
                {
                    "sent": "So why is this close to linear?",
                    "label": 0
                },
                {
                    "sent": "OK, we're going to interpret the output of this hypothesis as the probability of the class label being one given the input OK, and so if that's our interpretation, and if we look at the log odds ratio of the probability of the two classes, the binary classification case Y equal to 1 and Y equal to 0, you get the weights times the inputs.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's linear.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the sense in which we have things that are linear.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "The interesting thing is that if we find the best weights here, the best weights are going to maximize the conditional likelihood of the outputs given the inputs.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's kind of nice.",
                    "label": 0
                },
                {
                    "sent": "It's again a maximum likelihood criterion, and it's sort of the sort of standard discriminative setting.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now what are we going to optimize?",
                    "label": 0
                },
                {
                    "sent": "Well, we can optimize the cross entropy, OK?",
                    "label": 0
                },
                {
                    "sent": "So how do we think about the cross entropy?",
                    "label": 0
                },
                {
                    "sent": "We have it some distribution of observed outputs in the data and then we have some distribution that's generated by the output of our hypothesis.",
                    "label": 1
                },
                {
                    "sent": "OK, we're going to measure how far off one is from the other.",
                    "label": 1
                },
                {
                    "sent": "OK, so the log likelihood of the hypothesis here, assuming again that we have all hypothesis being equally likely, we're going to have here some of the log of P of Y given X, and this is going to be either log of.",
                    "label": 0
                },
                {
                    "sent": "H of X of or 1 -- H of X depending on whether we have class one or class zero.",
                    "label": 0
                },
                {
                    "sent": "We can do a little trick to kind of put these together OK by using this kind of multiplication of Y times the log in 1 -- y times the log of 1 -- H of X here and so we obtain the cross entropy error function and now we can optimize this.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To obtain the best parameter vector.",
                    "label": 0
                },
                {
                    "sent": "So this is a plot of what cross entropy error surface looks like for logistic function, and you can see that it's nice.",
                    "label": 1
                },
                {
                    "sent": "It's convex an.",
                    "label": 1
                },
                {
                    "sent": "Unfortunately we can't really solve it in closed form anymore.",
                    "label": 0
                },
                {
                    "sent": "So in the case of linear regression we obtained an actual formula of what the weights ought to be as a function of the inputs and outputs.",
                    "label": 0
                },
                {
                    "sent": "Here we can't quite do that OK, but it is a nice convex optimization.",
                    "label": 0
                },
                {
                    "sent": "OK, and so.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we're going to do is to use our best weapon that we're going to use a lot this week called Gradient Descent.",
                    "label": 0
                },
                {
                    "sent": "So just to remind you, gradient descent basically says if we have some kind of error function that we're trying to optimize, we're going to start somewhere and follow the gradient OK until we get to the bottom.",
                    "label": 1
                },
                {
                    "sent": "Now, if you have something that's nice and convex, like here, you can start anywhere and you're going to end up at the bottom under mild technical conditions.",
                    "label": 0
                },
                {
                    "sent": "If you have a nonlinear optimization objective with lots of little wells, then when you do your optimization you may end up in a local optimal optimum which is.",
                    "label": 0
                },
                {
                    "sent": "One of these local little words, and so there's then all kinds of tricks to encourage you to end up in a good spot, and you going to tell you all about that so.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Don't really discuss that in detail.",
                    "label": 0
                },
                {
                    "sent": "One of the very standard ones, of course, is to just do this multiple times and just start from different initialization points, and that's going to be due to different solution.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what does the gradient descent algorithm look like?",
                    "label": 1
                },
                {
                    "sent": "You have an objective JK.",
                    "label": 0
                },
                {
                    "sent": "We're going to assume that we can compute the gradient of this objective easily.",
                    "label": 0
                },
                {
                    "sent": "So the objective is smooth and the hypothesis is smooth.",
                    "label": 1
                },
                {
                    "sent": "For example, then this is easily done.",
                    "label": 0
                },
                {
                    "sent": "And we're going to produce a sequence of weight vectors.",
                    "label": 1
                },
                {
                    "sent": "Such that the limit of this is some weight vector that's locally optimal.",
                    "label": 0
                },
                {
                    "sent": "And what we're going to do instead of so now instead of solving the set of equations that sets the gradient to 0, or simply going to step in the direction of the gradient?",
                    "label": 0
                },
                {
                    "sent": "Because this is an error function, we want to step down in the direction of the gradient, hence the - over here, and we have a learning rate Alpha that controls how much we step down.",
                    "label": 0
                },
                {
                    "sent": "And these Alpha eyes could be different from iteration to iteration from step to step.",
                    "label": 0
                },
                {
                    "sent": "And there's also smart ways of actually.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Setting up.",
                    "label": 0
                },
                {
                    "sent": "So now we can apply this to the case of logistic regression.",
                    "label": 0
                },
                {
                    "sent": "We can take the likelihood of the data.",
                    "label": 0
                },
                {
                    "sent": "We can take the gradient, we can write the update rule for the gradient, and we get a very nice update.",
                    "label": 1
                },
                {
                    "sent": "OK, that basically says we started with some arbitrary weight vector and then we step OK in such a way as to minimize the error on the inputs.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, this kind of optimization is all good, but it requires you.",
                    "label": 0
                },
                {
                    "sent": "To pick these learning rates.",
                    "label": 0
                },
                {
                    "sent": "And you can treat this as a hyperparameter and use cross validation and pick the rates.",
                    "label": 0
                },
                {
                    "sent": "Sometimes the theory says.",
                    "label": 0
                },
                {
                    "sent": "Of course you should decay these rates.",
                    "label": 0
                },
                {
                    "sent": "Then you have more things to deal with.",
                    "label": 0
                },
                {
                    "sent": "Maybe you want to decay them in according to some schedule.",
                    "label": 0
                },
                {
                    "sent": "That schedule might have parameters and so on.",
                    "label": 0
                },
                {
                    "sent": "So there's another thing that you can do.",
                    "label": 0
                },
                {
                    "sent": "Which is to apply Newton's method.",
                    "label": 1
                },
                {
                    "sent": "OK, and so how does this look like?",
                    "label": 0
                },
                {
                    "sent": "Newton's method is basically an interesting way of finding zeros of a function.",
                    "label": 1
                },
                {
                    "sent": "In our case, we want to find zeros of the gradient OK, and the idea is that if I have some function.",
                    "label": 0
                },
                {
                    "sent": "OK. And I'm at some point here.",
                    "label": 1
                },
                {
                    "sent": "We're going to approximate the function.",
                    "label": 0
                },
                {
                    "sent": "Using a straight line and then we're going to solve the equation for where this reaches 0 and then move to that point.",
                    "label": 1
                },
                {
                    "sent": "So this is written out here, assuming that you just have a univariate function, But if you have a multivariate function, you can do exactly the same sort of thing using here a gradient in.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stead of.",
                    "label": 0
                },
                {
                    "sent": "Of a derivative.",
                    "label": 0
                },
                {
                    "sent": "And so now here what we want is we want to find the zeros of the gradient.",
                    "label": 1
                },
                {
                    "sent": "OK, so on top or G function here is the derivative and on the bottom we have the 2nd order derivative.",
                    "label": 0
                },
                {
                    "sent": "So this is part of a class of methods called 2nd order methods because they make use of 2nd order derivative information.",
                    "label": 0
                },
                {
                    "sent": "If you have access to that.",
                    "label": 0
                },
                {
                    "sent": "And then you step in this direction and that's really the best you can possibly do.",
                    "label": 1
                },
                {
                    "sent": "So notice that if I have an iteration like this, there's no learning rate and there's no step size.",
                    "label": 0
                },
                {
                    "sent": "You just do this computation.",
                    "label": 0
                },
                {
                    "sent": "You the price to pay is that you do have to compute the 2nd order derivative, and that may be expensive depending on variety of circumstances.",
                    "label": 1
                },
                {
                    "sent": "If you have a quadratic error function, then you find the optimum in one step, OK, using.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Snap it.",
                    "label": 0
                },
                {
                    "sent": "So this is the multivariate setting here with where now instead of having a second order derivative, we have the multivariate equivalent, which is the Hessian matrix.",
                    "label": 1
                },
                {
                    "sent": "The Hessian matrix has the 2nd order derivatives according to pairs of parameters, and so the iteration just moves in the direction of the gradient of the objective and the learning rate is the inverse of the hash.",
                    "label": 0
                },
                {
                    "sent": "You do have to estimate this Hessian OK, and so typically these methods in order to be used require more data.",
                    "label": 0
                },
                {
                    "sent": "Than methods that are just based on step size.",
                    "label": 0
                },
                {
                    "sent": "So this is called an intern Raphson method.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sometimes called Fisher scoring.",
                    "label": 0
                },
                {
                    "sent": "What's better?",
                    "label": 0
                },
                {
                    "sent": "Well, that depends.",
                    "label": 0
                },
                {
                    "sent": "OK, typically this kind of 2nd order method requires fewer iterations in order to do the computation, because you sort of take optimal steps.",
                    "label": 0
                },
                {
                    "sent": "At the same time, you need a batch of data, so it's not an online algorithm.",
                    "label": 1
                },
                {
                    "sent": "And also there's this inversion of the Hessian twitch is expensive.",
                    "label": 0
                },
                {
                    "sent": "There actually tricks for avoiding this kind of explicit computation and inversion, which you may hear about later on.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But you can actually do this for logistic regression and it results in an algorithm called iterative recursive least squares, and the Hessian has a nice form in this case where you have the features and then this kind of diagonal matrix of H * 1 -- H, and so they wait.",
                    "label": 1
                },
                {
                    "sent": "Updates also become quite nice, and it's it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a good algorithm if you are going to do logistic regression and you can work with these large matrices.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do we do regularization for logistic regression while we do it just the way we do it for linear regression?",
                    "label": 0
                },
                {
                    "sent": "OK, we're going to have to put a prior over the parameter vector.",
                    "label": 0
                },
                {
                    "sent": "So for example, we can just do L2 regularization.",
                    "label": 0
                },
                {
                    "sent": "We can just say we want the weight of the norm of the weight vector to be small.",
                    "label": 0
                },
                {
                    "sent": "This means that again we have a sort of quadratic element in there, and the optimization is easy.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit harder now to make sense of what's going on in the sense that this is suggesting a Gaussian prior, but then the data comes in and we don't have a conjugate.",
                    "label": 0
                },
                {
                    "sent": "It's not a conjugate, so we don't really get a conjugate posterior.",
                    "label": 0
                },
                {
                    "sent": "There are other things that one can do here.",
                    "label": 0
                },
                {
                    "sent": "Different kinds of regularization that perhaps would be better matched to binary data.",
                    "label": 0
                },
                {
                    "sent": "So, for example, you can consider what is the error, what does the error look like for binary data will typically the error is not a Gaussian type of error.",
                    "label": 0
                },
                {
                    "sent": "But it's actually flipping the label, and so perhaps working with Gaussians here is not ideal.",
                    "label": 0
                },
                {
                    "sent": "However, from a practical point of view, this is very nice, and so that's one of the reasons why why people use this map.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now what's the probabilistic view of logistic regression?",
                    "label": 0
                },
                {
                    "sent": "So just like we thought about linear regression, and we thought about this kind of noise model, we can treat logistic regression in the same way.",
                    "label": 1
                },
                {
                    "sent": "OK, so we can consider the output as being produced by a hypothesis plus some noise, OK?",
                    "label": 0
                },
                {
                    "sent": "But this is actually kind of strange.",
                    "label": 0
                },
                {
                    "sent": "OK, again, because the output is binary and So what does this kind of model really mean?",
                    "label": 0
                },
                {
                    "sent": "So instead what we will do is we will consider a continuous variable.",
                    "label": 0
                },
                {
                    "sent": "OK, why had that's produced by the hypothesis plus some noise?",
                    "label": 0
                },
                {
                    "sent": "And then we're going to consider the output being generated by thresholding this variable at 0.",
                    "label": 0
                },
                {
                    "sent": "So we're going to generate the one if this variable is positive and 0 otherwise.",
                    "label": 1
                },
                {
                    "sent": "And so in this case, we actually obtain a nice probabilistic model for logistic regression.",
                    "label": 0
                },
                {
                    "sent": "We now have the.",
                    "label": 0
                },
                {
                    "sent": "The graphical model is a little bit more complicated.",
                    "label": 0
                },
                {
                    "sent": "We have the inputs.",
                    "label": 0
                },
                {
                    "sent": "We have epsilon.",
                    "label": 0
                },
                {
                    "sent": "These are used to go into this sort of.",
                    "label": 0
                },
                {
                    "sent": "Yhat variable which is then used.",
                    "label": 0
                },
                {
                    "sent": "To generate Y. OK.",
                    "label": 0
                },
                {
                    "sent": "So again, there's this sort of notion of a latent variable somewhere in there that we don't actually get to observe, but that controls the output that gets absorbed.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "The other interesting thing about this kind of interpretation is that it directly shows you that logistic regression is not a generative model.",
                    "label": 0
                },
                {
                    "sent": "In other words, if I just consider the inputs and the outputs, there's not a good way for me to generate what this yhat might have been.",
                    "label": 0
                },
                {
                    "sent": "OK, and so there are other models, other probabilistic models that are fully probabilistic that allow you to populate these latent variables in nicer ways.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we're going to recap now a little bit.",
                    "label": 0
                },
                {
                    "sent": "We talked about machine learning algorithms.",
                    "label": 1
                },
                {
                    "sent": "Hopefully this was more of a refresher.",
                    "label": 1
                },
                {
                    "sent": "If you've seen this now for the first time, I'm sure it's like completely whizzed by.",
                    "label": 0
                },
                {
                    "sent": "So whenever you have a machine learning algorithm, you have to think of making a choice of hypothesis.",
                    "label": 0
                },
                {
                    "sent": "A choice of an error function, and a choice of an optimization procedure.",
                    "label": 0
                },
                {
                    "sent": "Very often we're going to make gradient descent kind of optimization procedures just because they're convenient and they work sort of in many, many cases.",
                    "label": 0
                },
                {
                    "sent": "In some cases, this optimization is easy and in closed form in almost all the cases you're going to see for the rest of the week.",
                    "label": 0
                },
                {
                    "sent": "This is not the case, and you're going to have to work harder to get that.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And all of the algorithms are affected by this kind of bias variance tradeoff, so the overfitting phenomenon is always a concern.",
                    "label": 0
                },
                {
                    "sent": "You always have to do cross validation.",
                    "label": 0
                },
                {
                    "sent": "You always have to make sure that you're not building a model that's too large for the amount of data that you have.",
                    "label": 0
                },
                {
                    "sent": "You could do regularization to control that.",
                    "label": 0
                },
                {
                    "sent": "You can put priors on hypothesis space, and I've showed you a little bit of this patient interpretation.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure how much you'll see of this for the rest of the week, but I think it's useful to keep this in mind because it both captures.",
                    "label": 0
                },
                {
                    "sent": "What the algorithms are trying to do?",
                    "label": 0
                },
                {
                    "sent": "What are the hidden assumptions behind the algorithms and also it gives you a way of perhaps expanding the class of algorithms by modifying those assumptions explicitly.",
                    "label": 0
                },
                {
                    "sent": "So I'll stop there and I'm going to take questions if there aren't, yeah.",
                    "label": 0
                },
                {
                    "sent": "Cross entropy error.",
                    "label": 0
                },
                {
                    "sent": "Hire some people think that it's better than the music euro for Fire Protection problems you through or why so?",
                    "label": 0
                },
                {
                    "sent": "For binary classification the mean squared error sort of doesn't make sense, because the mean squared error is under this assumption that you have some output and then it's affected by Gaussian noise.",
                    "label": 0
                },
                {
                    "sent": "OK, now that's not the case in binary classification binary classification, you have some.",
                    "label": 0
                },
                {
                    "sent": "Output and the nature of the noise is to flip that output.",
                    "label": 1
                },
                {
                    "sent": "OK, so instead of 1, make it 0 and the other way around, and so using the mean squared error in this case really does not fit at all with the nature of the output data.",
                    "label": 1
                },
                {
                    "sent": "Cross entropy explicitly says, well, we have some distribution of this output condition on the inputs and we have some distribution of this output that's generated by the hypothesis, and now we're measuring called different.",
                    "label": 0
                },
                {
                    "sent": "These two distributions are.",
                    "label": 0
                },
                {
                    "sent": "So in that sense it is a fit for this problem as well as many other problems.",
                    "label": 0
                },
                {
                    "sent": "It's a very general kind of error function that whenever you have this kind of probabilistic assumption on the problem at hand, you can work with it.",
                    "label": 0
                },
                {
                    "sent": "It's just a matter of in this particular case, the cross entropy also has a nice form that you can actually work with computationally or other problems that might be more complicated depending on the on the distribution.",
                    "label": 0
                },
                {
                    "sent": "Audio.",
                    "label": 0
                },
                {
                    "sent": "Right, so the question was, is the is the cross entropy better than the mean squared error for binary classification?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I just wanted to be devil's advocate here.",
                    "label": 0
                },
                {
                    "sent": "Even if it is square with 01 targets, then you're actually doing something meaningful which is estimating the expected value of the binary variable.",
                    "label": 0
                },
                {
                    "sent": "Given X, so it's not completely crazy, but I think the reason it doesn't work as well as cross entropy for signaling.",
                    "label": 0
                },
                {
                    "sent": "Or herself, Max is more numerical.",
                    "label": 0
                },
                {
                    "sent": "So if you want your output to be bounded between zero and one, you have something like sigmoid or softmax and then you can use squared error.",
                    "label": 0
                },
                {
                    "sent": "End up with problems where derivatives might be close to 0 even though the.",
                    "label": 0
                },
                {
                    "sent": "The output is confidently wrong and this is a bad situation, so there's certainly numerical aspects, but at least from my point of view.",
                    "label": 0
                },
                {
                    "sent": "You know, I would like the interpretation to be consistent with the choice of algorithm and so in this particular case.",
                    "label": 0
                },
                {
                    "sent": "And this is the right thing exactly.",
                    "label": 0
                },
                {
                    "sent": "Exactly now there is a.",
                    "label": 0
                },
                {
                    "sent": "There is a debate of whether maximum likelihood is the right thing to do.",
                    "label": 0
                },
                {
                    "sent": "And that's that's a whole big debate that I'm sure has many, many sides to it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's actually an interesting point actually.",
                    "label": 0
                },
                {
                    "sent": "To make at this disjunction that sometimes our choices are driven by sort of theoretical considerations of what sort of the right thing to do given the data.",
                    "label": 0
                },
                {
                    "sent": "And sometimes the choices are driven by numerical considerations, and what is actually feasible, and so there may be methods that are very nice theoretically, but that numerically or unstable or don't work well with certain classes of function approximators or certain classes.",
                    "label": 0
                },
                {
                    "sent": "Of these hypothesis, and so we're going to make a choice, even if it's not quite theoretically justified, but one that actually works in practice.",
                    "label": 0
                },
                {
                    "sent": "So that's a tradeoff as well.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So this graph or.",
                    "label": 0
                },
                {
                    "sent": "So the generative models means that you can actually use the model to generate data.",
                    "label": 1
                },
                {
                    "sent": "OK, so in other words, I could use this.",
                    "label": 0
                },
                {
                    "sent": "Can I use this model to actually generate you inputs and outputs?",
                    "label": 0
                },
                {
                    "sent": "OK, so the question is, is logistic regression and generalized artistic regression not a generative model?",
                    "label": 0
                },
                {
                    "sent": "So in logistic regression, what I can do is if you give me an input I can infer.",
                    "label": 0
                },
                {
                    "sent": "The output OK with a probabilistic assumption on the weights.",
                    "label": 0
                },
                {
                    "sent": "I could even for distribution of the output.",
                    "label": 0
                },
                {
                    "sent": "What I cannot do is invert that and say, given the output, what does the input look like now?",
                    "label": 0
                },
                {
                    "sent": "There's a large literature on generative models.",
                    "label": 0
                },
                {
                    "sent": "Naive Bayes is the typical example, sort of simple classifier example of a generative model where you can actually generate both inputs and outputs.",
                    "label": 0
                },
                {
                    "sent": "When is that interesting to do?",
                    "label": 0
                },
                {
                    "sent": "It's interesting to do when you actually want to generate data.",
                    "label": 0
                },
                {
                    "sent": "For example, if you want to generate text or you want to generate images, then it's good to have a generative model.",
                    "label": 0
                },
                {
                    "sent": "The other thing is that it allows you sometimes a way to supplement your data under certain circumstances by generating more examples.",
                    "label": 0
                },
                {
                    "sent": "So logistics regression is typically as a typical discriminator.",
                    "label": 0
                },
                {
                    "sent": "Given the input, you can compute the output, but you cannot infer that computation.",
                    "label": 0
                },
                {
                    "sent": "If we make different assumptions here on the structure of this graph.",
                    "label": 0
                },
                {
                    "sent": "So really the problem comes from the snowed over here where we then apply a threshold.",
                    "label": 0
                },
                {
                    "sent": "OK, so once we add a random variable and we apply a threshold, the information about that random variable is completely gone.",
                    "label": 1
                },
                {
                    "sent": "If instead we have some other probabilistic assumption here about how this output is generated, then we can actually perhaps invert that.",
                    "label": 0
                },
                {
                    "sent": "OK, and so naive Bayes has some different assumptions that it works under specifically.",
                    "label": 0
                },
                {
                    "sent": "It's assumption is like this.",
                    "label": 0
                },
                {
                    "sent": "You have an output here.",
                    "label": 0
                },
                {
                    "sent": "And it generates inputs OK, and then we can sample this way or sample that way conditioned on anything and end up dying data.",
                    "label": 0
                },
                {
                    "sent": "Yep, when you were talking about the variance tradeoff intervation one weeks vacation over.",
                    "label": 0
                },
                {
                    "sent": "So the expectation is always over the true probability of the data.",
                    "label": 0
                },
                {
                    "sent": "So P is the P is the true probability of the data, so the one that's generating the inputs.",
                    "label": 0
                },
                {
                    "sent": "So sampling different training set.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "That is, a parametric model.",
                    "label": 0
                },
                {
                    "sent": "Is there such thing as nonparametric through Mac and there's no.",
                    "label": 0
                },
                {
                    "sent": "So I will give you now my my own view of this, which may be completely off kilter, but they know your Shannon can correct me if I'm wrong.",
                    "label": 0
                },
                {
                    "sent": "My own view is that these are very large parametric models, so large that you actually don't need the non parametric stuff at all.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you essentially overparameterized, you have a very large parameter space you can represent very complicated hypothesis and then you are smart about the way that you do the search in this space.",
                    "label": 0
                },
                {
                    "sent": "And so you avoid overfitting problems by being smart about the optimization.",
                    "label": 0
                },
                {
                    "sent": "And as a result, you don't really need the nonparametric stuff at all, because you build a very large model to begin with.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Will there ever be a need to have something nonparametric?",
                    "label": 0
                },
                {
                    "sent": "If you had even more data, I don't really know.",
                    "label": 0
                },
                {
                    "sent": "There is something that's fundamentally very nice about parametric models, which is that you have a handle on the complexity OK, and so the parameter sizes given, whereas in nonparametric models potentially you can memorize data and the model can grow very unwieldy, and then you have to know the theory is nice, but in practice you have to do things like throw stuff out and forget and so on and so at least in my view, parametric models are a little bit better.",
                    "label": 0
                },
                {
                    "sent": "And there, since they're so big.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I really answer, but I would add this nonparametric for me at least for many people means that.",
                    "label": 0
                },
                {
                    "sent": "Your learning algorithm can adapt to the amount of data, so you have more data you can you know putting more capacity.",
                    "label": 0
                },
                {
                    "sent": "In fact, that's what we do with the neural Nets and other things like extra models, even though given the number of units or the number of mixture components, it's a parametric model.",
                    "label": 0
                },
                {
                    "sent": "In practice, you will actually choose the size of the model depending on how much data you have, and so these models really are nonparametric, not the usual nonparametric.",
                    "label": 0
                },
                {
                    "sent": "But they are nonparametric.",
                    "label": 0
                },
                {
                    "sent": "So is there any theory that's been that has looked into the sort of parametric nonparametric interpretation of deep Nets at all?",
                    "label": 0
                },
                {
                    "sent": "All the universal approximation properties of neural Nets is really about saying as the number of parameters grows, you can approximate any distribution.",
                    "label": 0
                },
                {
                    "sent": "So you basically have all the same characteristics of standard nonparametric methods that you can approach the true data function as the amount of data and capacity grow to Infinity at the right rate.",
                    "label": 0
                },
                {
                    "sent": "So there's no such thing as they start with the right training your Mac, and with a large data set and the neural net somehow grew in a non parametric yes fashion so that there.",
                    "label": 0
                },
                {
                    "sent": "So there have been historically a lot of methods that do that very explicitly back in the 90s there was a whole literature on growing neural Nets and adding units and noticing that units are unhappy and oscillating and cutting them up into pieces and so on.",
                    "label": 0
                },
                {
                    "sent": "I think that is the current methods that we use make that unnecessary.",
                    "label": 0
                },
                {
                    "sent": "And so the you know the current methods are more elegant.",
                    "label": 0
                },
                {
                    "sent": "The optimization is better, and so we don't need to do this kind of hacking of you know, we add something, we remove something and so.",
                    "label": 0
                },
                {
                    "sent": "So I have two questions about the Regulation, the way that you do not share this location.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "I mean, the regularization developing authorization is just to decrease the variance of the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So first question is if we have enough data, do we need your validation or not?",
                    "label": 0
                },
                {
                    "sent": "The second question is why would lorizon network then we can just decrease the size of the hypothesis that the number of problems or something.",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "So first question is.",
                    "label": 0
                },
                {
                    "sent": "In the IF we have a lot of data, do we need regularization and in principle in the limit of infinite data you don't OK because in the limit of infinite data, if you think of regularization as a sort of beige and prior, the prior is going to wash out and you gotta do Max likelihood on that data.",
                    "label": 0
                },
                {
                    "sent": "However, we never have an infinite amount of data.",
                    "label": 0
                },
                {
                    "sent": "We always have a finite amount of data.",
                    "label": 0
                },
                {
                    "sent": "Therefore in practice it is always a smart idea to use some form of regularization.",
                    "label": 0
                },
                {
                    "sent": "And the second question.",
                    "label": 0
                },
                {
                    "sent": "Can you repeat that, sorry.",
                    "label": 0
                },
                {
                    "sent": "If it's safe to go to just to decrease the variance, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so, why not just drop the size rather than do regularization and?",
                    "label": 0
                },
                {
                    "sent": "The way the way I think about it is that you want to control the size of the hypothesis space and regularization gives you a very nice, uniform way of doing that.",
                    "label": 0
                },
                {
                    "sent": "And it has one parameter that you control, and that parameter essentially has a nice geometric interpretation, as we've seen, and so you know, it's all good.",
                    "label": 0
                },
                {
                    "sent": "You kind of let the algorithm decide how many things it needs.",
                    "label": 0
                },
                {
                    "sent": "In there you could.",
                    "label": 0
                },
                {
                    "sent": "You could control the number of units, but then the overfitting phenomenon does not always come as a direct sort of connection with the number of parameters.",
                    "label": 0
                },
                {
                    "sent": "There are other things that come into play as well.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you have certain types of units and deep nuts, things like sigmoids, you can have saturation.",
                    "label": 0
                },
                {
                    "sent": "Saturation essentially means that you can't move those units anywhere.",
                    "label": 0
                },
                {
                    "sent": "You're memorizing whatever you had in the past.",
                    "label": 0
                },
                {
                    "sent": "You can't adapt anymore to future data, so that's a form of sort of.",
                    "label": 0
                },
                {
                    "sent": "Let's call it overtraining, not quite over fitting that regularization can help you avoid.",
                    "label": 0
                },
                {
                    "sent": "You know, because you're right, shrink and then your parameters are more free to move, so there's other reasons for doing this kind of thing, not just you know, not just controlling for numbers of units specifically, so I would add that in the last few years it's been pretty obvious that what works really well.",
                    "label": 0
                },
                {
                    "sent": "It's have huge yo Mets.",
                    "label": 0
                },
                {
                    "sent": "There are regular eyes one way or another, usually by injecting noise.",
                    "label": 0
                },
                {
                    "sent": "And that just works much better than having tightly parameterized models, for reasons that may be due to optimization.",
                    "label": 0
                },
                {
                    "sent": "But we should stop here and thank Joyner.",
                    "label": 0
                }
            ]
        }
    }
}