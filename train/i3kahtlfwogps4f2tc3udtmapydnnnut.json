{
    "id": "i3kahtlfwogps4f2tc3udtmapydnnnut",
    "title": "Bayesian model selection: mechanistic models of Erk MAP kinase phosphorylation dynamics",
    "info": {
        "author": [
            "Tina Toni, Centre for Bioinformatics, Imperial College London"
        ],
        "published": "April 16, 2009",
        "recorded": "April 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/licsb09_toni_bms/",
    "segmentation": [
        [
            "Talk is.",
            "Chinese.",
            "Tina OK hello everyone.",
            "My name is Tina Tony.",
            "I'm a PhD student at Imperial College and today I'll be talking about Bayesian model selection applied to map kinase phosphorylation dynamics."
        ],
        [
            "So post translational modification is an important process.",
            "If it plays a crucial role in many cellular processes and one of the well studied post translational modifications is phosphorylation and perspiration is really important, which can be seen from the facts that 30% of all proteins in any eukaryotic cell are phosphorylated at any one time and there are 500 different protein kinases in the human genome.",
            "So in this talk we will be studying phosphorylation and dephosphorylation and we will show how Bayesian statistics can contributes to our understanding of phosphorylation."
        ],
        [
            "Namics so I will first show what kind of data we use and how the biological experiments were done.",
            "I will then move to different phosphorylation models and explain some of the existing approaches for model selection.",
            "And the main part of the talk will be about ABC, SMC, Bayesian model selection algorithm that we developed.",
            "And I will also show some preliminary."
        ],
        [
            "Results that we obtained.",
            "So I started working on this project when I was visiting a systems biology lab at the University of Tokyo.",
            "An in this group they developed an automated immunofluorescence.",
            "Technique to study the Erk signaling pathway.",
            "So they developed a robot that can automatically stimulate an immuno stain.",
            "The cells and then at each time point the images were taken with an automated microscope and these images were analyzed.",
            "So this group was.",
            "They were the first one to develop such a high throughput technique to collect in vivo phosphorylation data for individual cells."
        ],
        [
            "So the data that they obtained is PP Mac versus PP Erk.",
            "So they can plot a picture like this for each of around 100 time points.",
            "Where each of these dots.",
            "Corresponds to an individual cell.",
            "And they can also average this data over individual cells and they get like two time cores datasets, one for PP, Erk and 1 four PP Mac.",
            "So pee pee pee pee Mak corresponds to active map kinase kinase and PP Erk corresponds to doubly phosphorylated map kindness and from now on I'm going to use these expressions instead of instead of this so map kinase kinase is a kinase that phosphorylates map kinase.",
            "And the question is, can we use this data and how can we use this data to study phosphorylation dynamics?"
        ],
        [
            "So map kinase kinase phosphorylates map kinase twice, so there are two different mechanisms in which this can happen.",
            "The first one is called distributive phosphorylation and here map kinase kinase binds to the first phosphorylation site phosphorylates, then disassociates.",
            "Then binds again to the second phosphorylation site, phosphorylates, and then disassociates again.",
            "The second mechanism is processive phosphorylation, where map KK binds was formulates at the first phosphorylation sites, then slides along to the second oscillation site as formulates and only then disassociates."
        ],
        [
            "So these two mechanisms can be written down with the following reactions, and the only difference is that in distributive phosphorylation map, KK Disassociates after the first phosphorylation and in process if it doesn't.",
            "And the big question is which of these two mechanisms is happening in ourselves?",
            "Hours."
        ],
        [
            "So.",
            "It has been shown that in vitro phosphorylation of MAP K is distributive, and it's also been shown that in vitro dephosphorylation of mark is also distributive.",
            "But is it the same in vivo?",
            "So no one has studied what's happening in vivo and also in vivo, we cannot study phosphorylation indifference relation separately.",
            "So in fact we have."
        ],
        [
            "Four different models.",
            "So DD model stands for distributed phosphorylation and distributed dephosphorylation.",
            "PD for Processive phosphorylation, distributive discourse relation and in the same way we can get DP.",
            "NPT models.",
            "And we can write down ordinary differential equations for this Ann.",
            "We get 12 parameters for DD Model, 10 parameters for PD&DP, and eight parameters for a PP model."
        ],
        [
            "So the 1st way of distinguishing whether the phosphorylation is processive or distributive is by fitting a Hill curve.",
            "Through this data.",
            "And if it has been shown that if phosphorylation is processive, then the slope of the skill curve is 1 and if the phosphorylation is distributive then the slope is 2."
        ],
        [
            "So we were expecting to show that for the PP&PD models we will get slope one and four DP&DD models will get slope too.",
            "So we simulated the steady state data for all four models for different parameter combinations.",
            "And the result that we got was quite surprising.",
            "So we got slope 2 for the DD model and slope one.",
            "For the other two models, so fitting the Hill curve is not a good way of distinguishing between the models, especially if you get slope one."
        ],
        [
            "And then we came across about a very nice theoretical result of Jeremy gonna verbana from Harvard Medical School who found a way of distinguishing between these four models by looking at steady state invariants in a certain way.",
            "But to apply his method, one would have to collect data on all."
        ],
        [
            "Phosphorylation states so M MP and MPP and with the current technology this is virtually impossible.",
            "So for example we only have the data on MPP.",
            "So we need another way of distinguishing."
        ],
        [
            "In the models and that's what we that's why we thought of going about of using Bayesian model selection.",
            "So in a Bayesian model selection, we have a set of candidate models."
        ],
        [
            "In our case, these models are PPDPPD and DD and what we do is we calculate base factor and depending on the value of this base factor we can then say whether one model is better or worse than the other model and to calculate the base vector we need the priors for the model and we need this marginal posterior distributions of the model and this is the hard part this it's hard to calculate this integral an in the next three slides.",
            "I'm going to explain the ABC approach that we developed for an efficient calculation of this integral."
        ],
        [
            "So I'm going to start with.",
            "Explaining the approximate Bayesian computation or ABC framework for the estimation of the posterior parameter distribution data given the data.",
            "So we need to define the prior distribution.",
            "Here we define a U1 and what?"
        ],
        [
            "Do is we sample one parameter from the prior?"
        ],
        [
            "We simulate a data set for this parameter for the model fixed to this parameter.",
            "And then we compare these datasets to the experimental data set with.",
            "This crosses here and if the simulated data set is close to experimental data set then we."
        ],
        [
            "CEPT the parameter.",
            "Then we sample another parameter from the prior."
        ],
        [
            "We"
        ],
        [
            "Simulate data set again, and if this simulated data set is very different, very far away from the expert."
        ],
        [
            "Mental data set.",
            "Then we throw this parameter away.",
            "We reject it."
        ],
        [
            "And then we do this all over again."
        ],
        [
            "Until we have enough."
        ],
        [
            "Accepted parameters and we say that this is our posterior approximation of the posterior distribution.",
            "So this method is very simple.",
            "But it's quite computationally slow."
        ],
        [
            "So that's why we developed an ABC SMC approach which is based on sequential Monte Carlo an.",
            "Unfortunately, there's no time to go through the method, but the only thing you need to remember is that is based on the same principles as the algorithm from the previous slide, but it works.",
            "It's computationally much faster."
        ],
        [
            "So now we know that we can use ABC SMC to obtain the posterior parameter distribution and to use ABC SMC for the model selection.",
            "What we need to do is.",
            "We need to adapt the algorithm a little bit, so we include model parameter M as an extra parameter to the set of existing parameters Theta, and then we do ABC SMC on this new parameter set to obtain the posterior distribution.",
            "These posterior distribution and then we can marginalized it to obtain the posterior marginal posterior distribution of the model, and this is the hard part.",
            "This is hard integral.",
            "That I was talking about before.",
            "And now we have everything to calculate the base vector."
        ],
        [
            "So we started by fitting each of the four models to the data an.",
            "We used map.",
            "KK Data is an input to the models and because this data was very noisy, we used Gaussian process regression to smoothen it and we used empty data for fitting."
        ],
        [
            "And these are some preliminary model selection results, so this here is the.",
            "Marginal posterior distribution of the model.",
            "So what we can see is that models PP&PD have a very high posterior probability and this might as well mean that the phosphorylation follows a processive mechanism, so this.",
            "Would be this is very interesting result and a bit controversial if we manage to prove that it is correct."
        ],
        [
            "So that's what we're doing at the moment.",
            "So at the moment we are still working on the average data with the ordinary differential equations and we are studying the dependence on our result on the Gaussian process regression and the priors in the future.",
            "We would like to analyze the population data bit more.",
            "So we would like to study what extra information is carried in this population compared to the average data.",
            "We are planning to adapt the ABC SMC algorithm to work with this kind of data.",
            "And we are interested in what is the main source of variability in this data.",
            "So is it the initial conditions that make the difference for different cells or is it different parameters or what?",
            "Or is it?"
        ],
        [
            "Nails.",
            "And I would like to thank the Systems Biology lab at the University of Tokyo, led by Professor Sheena Kuroda.",
            "Doctor Ritchie Ozaki worked closely with me on this project, and he also did all the experiments.",
            "I'd like to thank my supervisor, Michael Stone, and I'd like to thank Paul Kirk for helping me with the Gaussian process regression and everyone else in our group, and my PhD is funded by Mercy Division of Molecular Biosciences and Slovenian Academy of Sciences and Arts."
        ],
        [
            "And thank you for your attention.",
            "Pencil questions.",
            "Excellent.",
            "We choose them.",
            "With trial and error.",
            "Yeah, it's it's one of the one of the things that the user has to specify.",
            "An it would be good to find an automated way how to select them, and I believe some work is being done on this.",
            "Try just assuming that you got measurement error menu.",
            "Yeah, PC hardware exactly, so it's not sorry.",
            "Sarah.",
            "Your ABC positive as I can.",
            "Yeah, are you talking about this paper of Darren Wilkinson?",
            "Yeah, this is psoriatic paper and it is.",
            "A matter of interpretation of the posterior distribution of the posterior distribution that you obtain.",
            "Yes, it could be interpreted as the.",
            "Is the noise in the data?",
            "I just got a question about these two mechanisms in terms of committed is right, some reactions was relation markers.",
            "This permission operations they have committed?",
            "Like saying he has to complete for both of them.",
            "Is it the same connected concepts or actually different?"
        ],
        [
            "Yeah, you know, for example distributed and process you have Q1 and King on.",
            "Yeah yeah yeah yeah.",
            "No, when we do the parameter estimation, so we estimate them independently so they're different, like they can be different.",
            "Data available on this connection.",
            "Constance transfer, mental.",
            "No, the data is not available.",
            "That's why we have to do so in our model selection algorithm.",
            "The parameter estimation is done automatically, so we also have to estimate the parameters.",
            "Questions.",
            "Otherwise, I would question related to your question actually, and that is I mean ABCD.",
            "Typically is if you can't compute the like of it and so then the projection is based on some metric that we impose which is related to the noise.",
            "And So what is the practical advantage of using ABC is supposed to making sort of introducing a noise model and making sort of the last model.",
            "More explicit is not in some way of implicit noise model that isn't mixer make explicit.",
            "Yeah, so yeah.",
            "So an advantage of ABC is actually when you when when it's hard to work with the likelihood, or when you can't define it.",
            "So we're using it on the ODS, but it's actually.",
            "It becomes more useful when you use it on the SDS because in the SD is it's very hard to work with the likelihood.",
            "Alright, then, let's.",
            "Sing again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Talk is.",
                    "label": 0
                },
                {
                    "sent": "Chinese.",
                    "label": 0
                },
                {
                    "sent": "Tina OK hello everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is Tina Tony.",
                    "label": 0
                },
                {
                    "sent": "I'm a PhD student at Imperial College and today I'll be talking about Bayesian model selection applied to map kinase phosphorylation dynamics.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So post translational modification is an important process.",
                    "label": 0
                },
                {
                    "sent": "If it plays a crucial role in many cellular processes and one of the well studied post translational modifications is phosphorylation and perspiration is really important, which can be seen from the facts that 30% of all proteins in any eukaryotic cell are phosphorylated at any one time and there are 500 different protein kinases in the human genome.",
                    "label": 1
                },
                {
                    "sent": "So in this talk we will be studying phosphorylation and dephosphorylation and we will show how Bayesian statistics can contributes to our understanding of phosphorylation.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Namics so I will first show what kind of data we use and how the biological experiments were done.",
                    "label": 0
                },
                {
                    "sent": "I will then move to different phosphorylation models and explain some of the existing approaches for model selection.",
                    "label": 0
                },
                {
                    "sent": "And the main part of the talk will be about ABC, SMC, Bayesian model selection algorithm that we developed.",
                    "label": 1
                },
                {
                    "sent": "And I will also show some preliminary.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Results that we obtained.",
                    "label": 0
                },
                {
                    "sent": "So I started working on this project when I was visiting a systems biology lab at the University of Tokyo.",
                    "label": 0
                },
                {
                    "sent": "An in this group they developed an automated immunofluorescence.",
                    "label": 0
                },
                {
                    "sent": "Technique to study the Erk signaling pathway.",
                    "label": 1
                },
                {
                    "sent": "So they developed a robot that can automatically stimulate an immuno stain.",
                    "label": 0
                },
                {
                    "sent": "The cells and then at each time point the images were taken with an automated microscope and these images were analyzed.",
                    "label": 0
                },
                {
                    "sent": "So this group was.",
                    "label": 0
                },
                {
                    "sent": "They were the first one to develop such a high throughput technique to collect in vivo phosphorylation data for individual cells.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the data that they obtained is PP Mac versus PP Erk.",
                    "label": 0
                },
                {
                    "sent": "So they can plot a picture like this for each of around 100 time points.",
                    "label": 0
                },
                {
                    "sent": "Where each of these dots.",
                    "label": 0
                },
                {
                    "sent": "Corresponds to an individual cell.",
                    "label": 1
                },
                {
                    "sent": "And they can also average this data over individual cells and they get like two time cores datasets, one for PP, Erk and 1 four PP Mac.",
                    "label": 0
                },
                {
                    "sent": "So pee pee pee pee Mak corresponds to active map kinase kinase and PP Erk corresponds to doubly phosphorylated map kindness and from now on I'm going to use these expressions instead of instead of this so map kinase kinase is a kinase that phosphorylates map kinase.",
                    "label": 0
                },
                {
                    "sent": "And the question is, can we use this data and how can we use this data to study phosphorylation dynamics?",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So map kinase kinase phosphorylates map kinase twice, so there are two different mechanisms in which this can happen.",
                    "label": 0
                },
                {
                    "sent": "The first one is called distributive phosphorylation and here map kinase kinase binds to the first phosphorylation site phosphorylates, then disassociates.",
                    "label": 0
                },
                {
                    "sent": "Then binds again to the second phosphorylation site, phosphorylates, and then disassociates again.",
                    "label": 0
                },
                {
                    "sent": "The second mechanism is processive phosphorylation, where map KK binds was formulates at the first phosphorylation sites, then slides along to the second oscillation site as formulates and only then disassociates.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these two mechanisms can be written down with the following reactions, and the only difference is that in distributive phosphorylation map, KK Disassociates after the first phosphorylation and in process if it doesn't.",
                    "label": 0
                },
                {
                    "sent": "And the big question is which of these two mechanisms is happening in ourselves?",
                    "label": 0
                },
                {
                    "sent": "Hours.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It has been shown that in vitro phosphorylation of MAP K is distributive, and it's also been shown that in vitro dephosphorylation of mark is also distributive.",
                    "label": 1
                },
                {
                    "sent": "But is it the same in vivo?",
                    "label": 1
                },
                {
                    "sent": "So no one has studied what's happening in vivo and also in vivo, we cannot study phosphorylation indifference relation separately.",
                    "label": 0
                },
                {
                    "sent": "So in fact we have.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Four different models.",
                    "label": 0
                },
                {
                    "sent": "So DD model stands for distributed phosphorylation and distributed dephosphorylation.",
                    "label": 0
                },
                {
                    "sent": "PD for Processive phosphorylation, distributive discourse relation and in the same way we can get DP.",
                    "label": 0
                },
                {
                    "sent": "NPT models.",
                    "label": 0
                },
                {
                    "sent": "And we can write down ordinary differential equations for this Ann.",
                    "label": 0
                },
                {
                    "sent": "We get 12 parameters for DD Model, 10 parameters for PD&DP, and eight parameters for a PP model.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the 1st way of distinguishing whether the phosphorylation is processive or distributive is by fitting a Hill curve.",
                    "label": 1
                },
                {
                    "sent": "Through this data.",
                    "label": 0
                },
                {
                    "sent": "And if it has been shown that if phosphorylation is processive, then the slope of the skill curve is 1 and if the phosphorylation is distributive then the slope is 2.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we were expecting to show that for the PP&PD models we will get slope one and four DP&DD models will get slope too.",
                    "label": 0
                },
                {
                    "sent": "So we simulated the steady state data for all four models for different parameter combinations.",
                    "label": 0
                },
                {
                    "sent": "And the result that we got was quite surprising.",
                    "label": 0
                },
                {
                    "sent": "So we got slope 2 for the DD model and slope one.",
                    "label": 0
                },
                {
                    "sent": "For the other two models, so fitting the Hill curve is not a good way of distinguishing between the models, especially if you get slope one.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we came across about a very nice theoretical result of Jeremy gonna verbana from Harvard Medical School who found a way of distinguishing between these four models by looking at steady state invariants in a certain way.",
                    "label": 0
                },
                {
                    "sent": "But to apply his method, one would have to collect data on all.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Phosphorylation states so M MP and MPP and with the current technology this is virtually impossible.",
                    "label": 0
                },
                {
                    "sent": "So for example we only have the data on MPP.",
                    "label": 0
                },
                {
                    "sent": "So we need another way of distinguishing.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the models and that's what we that's why we thought of going about of using Bayesian model selection.",
                    "label": 0
                },
                {
                    "sent": "So in a Bayesian model selection, we have a set of candidate models.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In our case, these models are PPDPPD and DD and what we do is we calculate base factor and depending on the value of this base factor we can then say whether one model is better or worse than the other model and to calculate the base vector we need the priors for the model and we need this marginal posterior distributions of the model and this is the hard part this it's hard to calculate this integral an in the next three slides.",
                    "label": 0
                },
                {
                    "sent": "I'm going to explain the ABC approach that we developed for an efficient calculation of this integral.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to start with.",
                    "label": 0
                },
                {
                    "sent": "Explaining the approximate Bayesian computation or ABC framework for the estimation of the posterior parameter distribution data given the data.",
                    "label": 1
                },
                {
                    "sent": "So we need to define the prior distribution.",
                    "label": 0
                },
                {
                    "sent": "Here we define a U1 and what?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do is we sample one parameter from the prior?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We simulate a data set for this parameter for the model fixed to this parameter.",
                    "label": 1
                },
                {
                    "sent": "And then we compare these datasets to the experimental data set with.",
                    "label": 0
                },
                {
                    "sent": "This crosses here and if the simulated data set is close to experimental data set then we.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "CEPT the parameter.",
                    "label": 0
                },
                {
                    "sent": "Then we sample another parameter from the prior.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simulate data set again, and if this simulated data set is very different, very far away from the expert.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mental data set.",
                    "label": 0
                },
                {
                    "sent": "Then we throw this parameter away.",
                    "label": 0
                },
                {
                    "sent": "We reject it.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we do this all over again.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Until we have enough.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Accepted parameters and we say that this is our posterior approximation of the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "So this method is very simple.",
                    "label": 0
                },
                {
                    "sent": "But it's quite computationally slow.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's why we developed an ABC SMC approach which is based on sequential Monte Carlo an.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, there's no time to go through the method, but the only thing you need to remember is that is based on the same principles as the algorithm from the previous slide, but it works.",
                    "label": 0
                },
                {
                    "sent": "It's computationally much faster.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we know that we can use ABC SMC to obtain the posterior parameter distribution and to use ABC SMC for the model selection.",
                    "label": 0
                },
                {
                    "sent": "What we need to do is.",
                    "label": 0
                },
                {
                    "sent": "We need to adapt the algorithm a little bit, so we include model parameter M as an extra parameter to the set of existing parameters Theta, and then we do ABC SMC on this new parameter set to obtain the posterior distribution.",
                    "label": 1
                },
                {
                    "sent": "These posterior distribution and then we can marginalized it to obtain the posterior marginal posterior distribution of the model, and this is the hard part.",
                    "label": 0
                },
                {
                    "sent": "This is hard integral.",
                    "label": 0
                },
                {
                    "sent": "That I was talking about before.",
                    "label": 0
                },
                {
                    "sent": "And now we have everything to calculate the base vector.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we started by fitting each of the four models to the data an.",
                    "label": 0
                },
                {
                    "sent": "We used map.",
                    "label": 0
                },
                {
                    "sent": "KK Data is an input to the models and because this data was very noisy, we used Gaussian process regression to smoothen it and we used empty data for fitting.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And these are some preliminary model selection results, so this here is the.",
                    "label": 1
                },
                {
                    "sent": "Marginal posterior distribution of the model.",
                    "label": 1
                },
                {
                    "sent": "So what we can see is that models PP&PD have a very high posterior probability and this might as well mean that the phosphorylation follows a processive mechanism, so this.",
                    "label": 0
                },
                {
                    "sent": "Would be this is very interesting result and a bit controversial if we manage to prove that it is correct.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's what we're doing at the moment.",
                    "label": 0
                },
                {
                    "sent": "So at the moment we are still working on the average data with the ordinary differential equations and we are studying the dependence on our result on the Gaussian process regression and the priors in the future.",
                    "label": 1
                },
                {
                    "sent": "We would like to analyze the population data bit more.",
                    "label": 0
                },
                {
                    "sent": "So we would like to study what extra information is carried in this population compared to the average data.",
                    "label": 1
                },
                {
                    "sent": "We are planning to adapt the ABC SMC algorithm to work with this kind of data.",
                    "label": 0
                },
                {
                    "sent": "And we are interested in what is the main source of variability in this data.",
                    "label": 1
                },
                {
                    "sent": "So is it the initial conditions that make the difference for different cells or is it different parameters or what?",
                    "label": 0
                },
                {
                    "sent": "Or is it?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nails.",
                    "label": 0
                },
                {
                    "sent": "And I would like to thank the Systems Biology lab at the University of Tokyo, led by Professor Sheena Kuroda.",
                    "label": 0
                },
                {
                    "sent": "Doctor Ritchie Ozaki worked closely with me on this project, and he also did all the experiments.",
                    "label": 0
                },
                {
                    "sent": "I'd like to thank my supervisor, Michael Stone, and I'd like to thank Paul Kirk for helping me with the Gaussian process regression and everyone else in our group, and my PhD is funded by Mercy Division of Molecular Biosciences and Slovenian Academy of Sciences and Arts.",
                    "label": 1
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And thank you for your attention.",
                    "label": 1
                },
                {
                    "sent": "Pencil questions.",
                    "label": 0
                },
                {
                    "sent": "Excellent.",
                    "label": 0
                },
                {
                    "sent": "We choose them.",
                    "label": 0
                },
                {
                    "sent": "With trial and error.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's it's one of the one of the things that the user has to specify.",
                    "label": 0
                },
                {
                    "sent": "An it would be good to find an automated way how to select them, and I believe some work is being done on this.",
                    "label": 0
                },
                {
                    "sent": "Try just assuming that you got measurement error menu.",
                    "label": 0
                },
                {
                    "sent": "Yeah, PC hardware exactly, so it's not sorry.",
                    "label": 0
                },
                {
                    "sent": "Sarah.",
                    "label": 0
                },
                {
                    "sent": "Your ABC positive as I can.",
                    "label": 0
                },
                {
                    "sent": "Yeah, are you talking about this paper of Darren Wilkinson?",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is psoriatic paper and it is.",
                    "label": 0
                },
                {
                    "sent": "A matter of interpretation of the posterior distribution of the posterior distribution that you obtain.",
                    "label": 0
                },
                {
                    "sent": "Yes, it could be interpreted as the.",
                    "label": 0
                },
                {
                    "sent": "Is the noise in the data?",
                    "label": 0
                },
                {
                    "sent": "I just got a question about these two mechanisms in terms of committed is right, some reactions was relation markers.",
                    "label": 0
                },
                {
                    "sent": "This permission operations they have committed?",
                    "label": 0
                },
                {
                    "sent": "Like saying he has to complete for both of them.",
                    "label": 0
                },
                {
                    "sent": "Is it the same connected concepts or actually different?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, you know, for example distributed and process you have Q1 and King on.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "No, when we do the parameter estimation, so we estimate them independently so they're different, like they can be different.",
                    "label": 0
                },
                {
                    "sent": "Data available on this connection.",
                    "label": 0
                },
                {
                    "sent": "Constance transfer, mental.",
                    "label": 0
                },
                {
                    "sent": "No, the data is not available.",
                    "label": 0
                },
                {
                    "sent": "That's why we have to do so in our model selection algorithm.",
                    "label": 0
                },
                {
                    "sent": "The parameter estimation is done automatically, so we also have to estimate the parameters.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, I would question related to your question actually, and that is I mean ABCD.",
                    "label": 0
                },
                {
                    "sent": "Typically is if you can't compute the like of it and so then the projection is based on some metric that we impose which is related to the noise.",
                    "label": 0
                },
                {
                    "sent": "And So what is the practical advantage of using ABC is supposed to making sort of introducing a noise model and making sort of the last model.",
                    "label": 0
                },
                {
                    "sent": "More explicit is not in some way of implicit noise model that isn't mixer make explicit.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so yeah.",
                    "label": 0
                },
                {
                    "sent": "So an advantage of ABC is actually when you when when it's hard to work with the likelihood, or when you can't define it.",
                    "label": 0
                },
                {
                    "sent": "So we're using it on the ODS, but it's actually.",
                    "label": 0
                },
                {
                    "sent": "It becomes more useful when you use it on the SDS because in the SD is it's very hard to work with the likelihood.",
                    "label": 0
                },
                {
                    "sent": "Alright, then, let's.",
                    "label": 0
                },
                {
                    "sent": "Sing again.",
                    "label": 0
                }
            ]
        }
    }
}