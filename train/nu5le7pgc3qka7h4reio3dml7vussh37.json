{
    "id": "nu5le7pgc3qka7h4reio3dml7vussh37",
    "title": "Bayes Average Case Performance of PAC - Bayes Bounds",
    "info": {
        "author": [
            "Manfred Opper, Department of Artificial Intelligence, TU Berlin"
        ],
        "published": "April 14, 2010",
        "recorded": "March 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/pacbayesian_opper_bacp/",
    "segmentation": [
        [
            "You know the data generated from real beige."
        ],
        [
            "In setting and the queue that we're using is the corresponding true posterior and just wanted to see you know, are these bounds very pessimistic or not?",
            "And that was just the question and."
        ],
        [
            "So the basic setup that I was using instead of my knowledge about that well, I used explicitly this type of notation because I have to change the sample size little bit later from time to time and then I was using because Bayesians like to have these priors over Theta is usually, so I replaced all the the H is of the concepts by Theta, so this is probably the difference to other talks.",
            "And I was using for simplicity and expectation version of the band.",
            "So if I'm interested in in the expected loss, I would use the right hand side as a proxy for it.",
            "So this is the version not not not the high probability with high probability.",
            "We have the inequality, but this is expected inequality and here's this nice sigh of EM.",
            "And so there were these two loss function stuff that have appeared.",
            "Before, so this is well, we all know about that, right so?"
        ],
        [
            "Now I want to take sort of an average of these Peck bounds, assuming that we're really living in a in a Bayesian setting, so we have we have a data generating probability given a true parameter, Theta, which factorizes in a conditional probability well for classification.",
            "There would be some simple things that produce 01 wise or plus minus one wise, and there would be.",
            "A density that we usually don't model in a Bayesian setting, but this would sort of depend on Theta and Theta would be the type of classifier that we're using.",
            "The type of model well, as Matthias is already mentioned, well if we look at this callback, Libra divergance, which always appears on the right hand side of these pack Bayesian bounds, and if we take the expectation with respect to the data samples.",
            "And the expectation of the true parameters that change that that would generate the data in a Bayesian setting.",
            "Sorry, this is all because I probably am low on battery adeno, so it's very easy to see in his materials already showed that is actually the.",
            "Mutual information between the parameter and the data in a Bayesian setting.",
            "So on average it's the mutual information that we have on the right hand side of these PAC Bayesian bounds.",
            "If you're mid this this additional term, so we would say well in a Bayesian averaging setting, the expected loss is less than or equal to a proxy, which is one over in the mutual information between the parameter.",
            "End the data."
        ],
        [
            "So now if I would look at go away from the PAC Bayes bound and try to bound the loss directly under a Bayesian setting and it would specialize on that loss that we have seen before, well probably."
        ],
        [
            "I've seen that so this type of loss has been studied by Attorney Sharma and all so."
        ],
        [
            "So an if I would look at a setting where I specialize on on this type of data model, which actually would correspond also to the models that optimize these loss bounds.",
            "As far as I remember, so that would be like.",
            "Label noise, so you say with high, so you have an ideal classifier with some probability.",
            "The label is flipped at random and see is kind of and tells you how strong the label noises and in the case for safety to Infinity you have error free labels.",
            "So if you look at this model and and compute posterior with respect to some prior, then you would see by a direct calculation that the expected loss.",
            "This and this is just a little bit playing.",
            "I think what I did was, well, first of all you see if you if you take this expectation probably outside and you you see this shit, sorry.",
            "This so this indicator function is 01.",
            "You can write it as one minus indicator function times 1 minus that, and then you see this is essentially a log probability and what happens?",
            "You see, with a little bit of calculation that on the right hand side you can upper bound that quantity by the well.",
            "I call this the information gain.",
            "Sorry for the confusion.",
            "This is the mutual information, but the change of the mutual information with increasing data site I call information gain because it's also related to A to an instantaneous expected log loss.",
            "In a Bayesian setting, so you can easily show that.",
            "All kind of details, but I think I did the math correctly.",
            "So you see this expected loss for this setting is upper bounded by the.",
            "By the inch by the change in mutual information.",
            "So what?"
        ],
        [
            "Get in the Bayesian setting.",
            "In contrast to the pack setting.",
            "So in the pack setting you would have 1 / M The.",
            "The mutual information in here would have sort of the difference in mutual information in the average case Bayesian setting.",
            "And now if I assume that in for a parametric nice, well, dementia Knol.",
            "Class of classifier models.",
            "Then hopefully this.",
            "Typically this mutual information would scale logarithmically in the number of data points and there's some constant, probably related to the dimensionality of the parameter space.",
            "Then the pack upper bound would just be a log M / M, Whereas this Bayesian upper bound that I got would be essentially the derivative because it's the change of this mutual information.",
            "So you would get.",
            "A key over M and you get an extra log factor, which is probably not so bad.",
            "And if you could would go to cases that are nonparametric, like probably bought models that are related to Gaussian processes, you would get something this would grow.",
            "With them to some power of AA will be less than one.",
            "Then you would just get the pack.",
            "One would be M to the Alpha minus one, and well they have the same growth essentially and there might be log factors or not, but essentially it doesn't seem so bad.",
            "So on the other side, so can we also bound things from the other side get a lower bound and that's also."
        ],
        [
            "Something that I looked at.",
            "They use another bound on the mutual information, which is quite useful.",
            "Here's an old one.",
            "Says this mutual information.",
            "I need this for a second as a as a technical trick is upper well.",
            "OK, so let's I looked only at a specific setting where things are simpler.",
            "So I looked at the case where we have a noise free model, so the same set."
        ],
        [
            "Thing is, before.",
            "Looked at this loss and if we take C to Infinity I go to the case where there are no there's no noise assumed in the data and in this setting."
        ],
        [
            "Show that the mutual information is upper bounded by the log of similar Laplace transform.",
            "Essentially, where this function in the exponent is, the probability that the predictor with parameter Theta is disagreeing with the with the true predictor which has Theta star and you have to average from the outside over the prior over Theta star inside over Theta.",
            "Well, that's not a big deal to prove that.",
            "Essentially, you use Jensen's inequality to move some data average into the exponent, and what originally appears here is a callback Leiber divergent, but it can play a little bit and.",
            "And get this, and so the way to use that bound is."
        ],
        [
            "To combine it with a very simple or, but I think today we have seen these types of bounds so many times, so I don't have to really discuss what they do.",
            "I mean, Matias has shown them and and you have shown them before as well, so it's a standard way of just deriving now lower bound on some expectation over some function of a parameters Theta.",
            "And here I have a well.",
            "Some distribution over these parameters I get the kullback, Leiber and here I get another Laplace transform.",
            "So I use this bound just to convert.",
            "Now the Laplace transform into another cubuk lie blur and then on average.",
            "Well sorry I average this bound.",
            "I used this Mount for for this function I average the bound over data.",
            "I use this bound bound on the Laplace transform that I had."
        ],
        [
            "On the previous."
        ],
        [
            "Inspiron see to get another expected Kullback Leiber, another mutual information into it.",
            "So I get a lower bound on this expected risk.",
            "Bayes risk in in terms of differences of two mutual information.",
            "So that's the sub and from the."
        ],
        [
            "This side and so that would give me that would give me, well to be precise.",
            "Here I'm just saying if I don't have any error in the data, that means the limit of flow zero actually zero empirical error and I look at this loss function.",
            "Then I just simply say, well, I'm also interested in the limit where I can achieve very small generalization errors, so I just take the log 1 minus generalization error to be this one.",
            "Generalization error is just simply the disagreement.",
            "The probability of disagreement between.",
            "The guy Theta and the true predictor on average over the posterior.",
            "So this right simply there very close to each other.",
            "And then I would get a lower bound on that expected loss, which is a difference of two.",
            "Have two mutual informations where I can sort of play with this with this parameter N and make this make this as large as possible and if I again."
        ],
        [
            "Look at look at parametric classes were assumed that these mutual information scale as log M, then sort of again from before we had the pack result.",
            "Just said this is K over.",
            "This is well sorry, get it wrong.",
            "Probably there was another lock factor.",
            "Yes, I forgot the log factor here, so there's another luck factor in the exponent here.",
            "And if I use look at the lower bound on the on the true Bayesian risk, there is a log factor.",
            "In the denominator here, and you can also play a little bit.",
            "You get a bunch of more log factors and so my conclusion was, well, it's not such a pessimistic scenario."
        ],
        [
            "At all, so in a sense, the PAC Bayesian bounds, at least for this simple setting, are accurate within log factors compared to an optimistic Bayesian average case.",
            "And so somehow I like them for that reason.",
            "Another question that I don't have any answer, but would that have any consequences?",
            "Sort of for model selection, which I don't know.",
            "You know you probably have to study the slackness in these bounds to see what's how you could use them, but well, that's essentially what I wanted to talk about, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know the data generated from real beige.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In setting and the queue that we're using is the corresponding true posterior and just wanted to see you know, are these bounds very pessimistic or not?",
                    "label": 0
                },
                {
                    "sent": "And that was just the question and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the basic setup that I was using instead of my knowledge about that well, I used explicitly this type of notation because I have to change the sample size little bit later from time to time and then I was using because Bayesians like to have these priors over Theta is usually, so I replaced all the the H is of the concepts by Theta, so this is probably the difference to other talks.",
                    "label": 0
                },
                {
                    "sent": "And I was using for simplicity and expectation version of the band.",
                    "label": 0
                },
                {
                    "sent": "So if I'm interested in in the expected loss, I would use the right hand side as a proxy for it.",
                    "label": 0
                },
                {
                    "sent": "So this is the version not not not the high probability with high probability.",
                    "label": 0
                },
                {
                    "sent": "We have the inequality, but this is expected inequality and here's this nice sigh of EM.",
                    "label": 0
                },
                {
                    "sent": "And so there were these two loss function stuff that have appeared.",
                    "label": 0
                },
                {
                    "sent": "Before, so this is well, we all know about that, right so?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I want to take sort of an average of these Peck bounds, assuming that we're really living in a in a Bayesian setting, so we have we have a data generating probability given a true parameter, Theta, which factorizes in a conditional probability well for classification.",
                    "label": 0
                },
                {
                    "sent": "There would be some simple things that produce 01 wise or plus minus one wise, and there would be.",
                    "label": 0
                },
                {
                    "sent": "A density that we usually don't model in a Bayesian setting, but this would sort of depend on Theta and Theta would be the type of classifier that we're using.",
                    "label": 0
                },
                {
                    "sent": "The type of model well, as Matthias is already mentioned, well if we look at this callback, Libra divergance, which always appears on the right hand side of these pack Bayesian bounds, and if we take the expectation with respect to the data samples.",
                    "label": 0
                },
                {
                    "sent": "And the expectation of the true parameters that change that that would generate the data in a Bayesian setting.",
                    "label": 0
                },
                {
                    "sent": "Sorry, this is all because I probably am low on battery adeno, so it's very easy to see in his materials already showed that is actually the.",
                    "label": 0
                },
                {
                    "sent": "Mutual information between the parameter and the data in a Bayesian setting.",
                    "label": 0
                },
                {
                    "sent": "So on average it's the mutual information that we have on the right hand side of these PAC Bayesian bounds.",
                    "label": 0
                },
                {
                    "sent": "If you're mid this this additional term, so we would say well in a Bayesian averaging setting, the expected loss is less than or equal to a proxy, which is one over in the mutual information between the parameter.",
                    "label": 0
                },
                {
                    "sent": "End the data.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now if I would look at go away from the PAC Bayes bound and try to bound the loss directly under a Bayesian setting and it would specialize on that loss that we have seen before, well probably.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've seen that so this type of loss has been studied by Attorney Sharma and all so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So an if I would look at a setting where I specialize on on this type of data model, which actually would correspond also to the models that optimize these loss bounds.",
                    "label": 0
                },
                {
                    "sent": "As far as I remember, so that would be like.",
                    "label": 0
                },
                {
                    "sent": "Label noise, so you say with high, so you have an ideal classifier with some probability.",
                    "label": 0
                },
                {
                    "sent": "The label is flipped at random and see is kind of and tells you how strong the label noises and in the case for safety to Infinity you have error free labels.",
                    "label": 0
                },
                {
                    "sent": "So if you look at this model and and compute posterior with respect to some prior, then you would see by a direct calculation that the expected loss.",
                    "label": 0
                },
                {
                    "sent": "This and this is just a little bit playing.",
                    "label": 0
                },
                {
                    "sent": "I think what I did was, well, first of all you see if you if you take this expectation probably outside and you you see this shit, sorry.",
                    "label": 0
                },
                {
                    "sent": "This so this indicator function is 01.",
                    "label": 0
                },
                {
                    "sent": "You can write it as one minus indicator function times 1 minus that, and then you see this is essentially a log probability and what happens?",
                    "label": 0
                },
                {
                    "sent": "You see, with a little bit of calculation that on the right hand side you can upper bound that quantity by the well.",
                    "label": 0
                },
                {
                    "sent": "I call this the information gain.",
                    "label": 1
                },
                {
                    "sent": "Sorry for the confusion.",
                    "label": 0
                },
                {
                    "sent": "This is the mutual information, but the change of the mutual information with increasing data site I call information gain because it's also related to A to an instantaneous expected log loss.",
                    "label": 0
                },
                {
                    "sent": "In a Bayesian setting, so you can easily show that.",
                    "label": 0
                },
                {
                    "sent": "All kind of details, but I think I did the math correctly.",
                    "label": 0
                },
                {
                    "sent": "So you see this expected loss for this setting is upper bounded by the.",
                    "label": 0
                },
                {
                    "sent": "By the inch by the change in mutual information.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Get in the Bayesian setting.",
                    "label": 0
                },
                {
                    "sent": "In contrast to the pack setting.",
                    "label": 0
                },
                {
                    "sent": "So in the pack setting you would have 1 / M The.",
                    "label": 0
                },
                {
                    "sent": "The mutual information in here would have sort of the difference in mutual information in the average case Bayesian setting.",
                    "label": 0
                },
                {
                    "sent": "And now if I assume that in for a parametric nice, well, dementia Knol.",
                    "label": 0
                },
                {
                    "sent": "Class of classifier models.",
                    "label": 0
                },
                {
                    "sent": "Then hopefully this.",
                    "label": 0
                },
                {
                    "sent": "Typically this mutual information would scale logarithmically in the number of data points and there's some constant, probably related to the dimensionality of the parameter space.",
                    "label": 0
                },
                {
                    "sent": "Then the pack upper bound would just be a log M / M, Whereas this Bayesian upper bound that I got would be essentially the derivative because it's the change of this mutual information.",
                    "label": 0
                },
                {
                    "sent": "So you would get.",
                    "label": 0
                },
                {
                    "sent": "A key over M and you get an extra log factor, which is probably not so bad.",
                    "label": 0
                },
                {
                    "sent": "And if you could would go to cases that are nonparametric, like probably bought models that are related to Gaussian processes, you would get something this would grow.",
                    "label": 0
                },
                {
                    "sent": "With them to some power of AA will be less than one.",
                    "label": 0
                },
                {
                    "sent": "Then you would just get the pack.",
                    "label": 0
                },
                {
                    "sent": "One would be M to the Alpha minus one, and well they have the same growth essentially and there might be log factors or not, but essentially it doesn't seem so bad.",
                    "label": 0
                },
                {
                    "sent": "So on the other side, so can we also bound things from the other side get a lower bound and that's also.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Something that I looked at.",
                    "label": 0
                },
                {
                    "sent": "They use another bound on the mutual information, which is quite useful.",
                    "label": 1
                },
                {
                    "sent": "Here's an old one.",
                    "label": 0
                },
                {
                    "sent": "Says this mutual information.",
                    "label": 0
                },
                {
                    "sent": "I need this for a second as a as a technical trick is upper well.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's I looked only at a specific setting where things are simpler.",
                    "label": 1
                },
                {
                    "sent": "So I looked at the case where we have a noise free model, so the same set.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing is, before.",
                    "label": 0
                },
                {
                    "sent": "Looked at this loss and if we take C to Infinity I go to the case where there are no there's no noise assumed in the data and in this setting.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Show that the mutual information is upper bounded by the log of similar Laplace transform.",
                    "label": 1
                },
                {
                    "sent": "Essentially, where this function in the exponent is, the probability that the predictor with parameter Theta is disagreeing with the with the true predictor which has Theta star and you have to average from the outside over the prior over Theta star inside over Theta.",
                    "label": 0
                },
                {
                    "sent": "Well, that's not a big deal to prove that.",
                    "label": 0
                },
                {
                    "sent": "Essentially, you use Jensen's inequality to move some data average into the exponent, and what originally appears here is a callback Leiber divergent, but it can play a little bit and.",
                    "label": 0
                },
                {
                    "sent": "And get this, and so the way to use that bound is.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To combine it with a very simple or, but I think today we have seen these types of bounds so many times, so I don't have to really discuss what they do.",
                    "label": 0
                },
                {
                    "sent": "I mean, Matias has shown them and and you have shown them before as well, so it's a standard way of just deriving now lower bound on some expectation over some function of a parameters Theta.",
                    "label": 0
                },
                {
                    "sent": "And here I have a well.",
                    "label": 0
                },
                {
                    "sent": "Some distribution over these parameters I get the kullback, Leiber and here I get another Laplace transform.",
                    "label": 0
                },
                {
                    "sent": "So I use this bound just to convert.",
                    "label": 0
                },
                {
                    "sent": "Now the Laplace transform into another cubuk lie blur and then on average.",
                    "label": 0
                },
                {
                    "sent": "Well sorry I average this bound.",
                    "label": 0
                },
                {
                    "sent": "I used this Mount for for this function I average the bound over data.",
                    "label": 0
                },
                {
                    "sent": "I use this bound bound on the Laplace transform that I had.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the previous.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Inspiron see to get another expected Kullback Leiber, another mutual information into it.",
                    "label": 0
                },
                {
                    "sent": "So I get a lower bound on this expected risk.",
                    "label": 1
                },
                {
                    "sent": "Bayes risk in in terms of differences of two mutual information.",
                    "label": 0
                },
                {
                    "sent": "So that's the sub and from the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This side and so that would give me that would give me, well to be precise.",
                    "label": 0
                },
                {
                    "sent": "Here I'm just saying if I don't have any error in the data, that means the limit of flow zero actually zero empirical error and I look at this loss function.",
                    "label": 0
                },
                {
                    "sent": "Then I just simply say, well, I'm also interested in the limit where I can achieve very small generalization errors, so I just take the log 1 minus generalization error to be this one.",
                    "label": 0
                },
                {
                    "sent": "Generalization error is just simply the disagreement.",
                    "label": 0
                },
                {
                    "sent": "The probability of disagreement between.",
                    "label": 0
                },
                {
                    "sent": "The guy Theta and the true predictor on average over the posterior.",
                    "label": 0
                },
                {
                    "sent": "So this right simply there very close to each other.",
                    "label": 0
                },
                {
                    "sent": "And then I would get a lower bound on that expected loss, which is a difference of two.",
                    "label": 1
                },
                {
                    "sent": "Have two mutual informations where I can sort of play with this with this parameter N and make this make this as large as possible and if I again.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at look at parametric classes were assumed that these mutual information scale as log M, then sort of again from before we had the pack result.",
                    "label": 0
                },
                {
                    "sent": "Just said this is K over.",
                    "label": 0
                },
                {
                    "sent": "This is well sorry, get it wrong.",
                    "label": 0
                },
                {
                    "sent": "Probably there was another lock factor.",
                    "label": 0
                },
                {
                    "sent": "Yes, I forgot the log factor here, so there's another luck factor in the exponent here.",
                    "label": 0
                },
                {
                    "sent": "And if I use look at the lower bound on the on the true Bayesian risk, there is a log factor.",
                    "label": 0
                },
                {
                    "sent": "In the denominator here, and you can also play a little bit.",
                    "label": 0
                },
                {
                    "sent": "You get a bunch of more log factors and so my conclusion was, well, it's not such a pessimistic scenario.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At all, so in a sense, the PAC Bayesian bounds, at least for this simple setting, are accurate within log factors compared to an optimistic Bayesian average case.",
                    "label": 1
                },
                {
                    "sent": "And so somehow I like them for that reason.",
                    "label": 0
                },
                {
                    "sent": "Another question that I don't have any answer, but would that have any consequences?",
                    "label": 1
                },
                {
                    "sent": "Sort of for model selection, which I don't know.",
                    "label": 0
                },
                {
                    "sent": "You know you probably have to study the slackness in these bounds to see what's how you could use them, but well, that's essentially what I wanted to talk about, thank you.",
                    "label": 0
                }
            ]
        }
    }
}