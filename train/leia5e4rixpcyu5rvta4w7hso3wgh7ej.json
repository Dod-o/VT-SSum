{
    "id": "leia5e4rixpcyu5rvta4w7hso3wgh7ej",
    "title": "Utility-weighted sampling in decisions from experience",
    "info": {
        "author": [
            "Falk Lieder, Computational Cognitive Science Lab, Department of Psychology, UC Berkeley"
        ],
        "published": "July 28, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Artificial Intelligence",
            "Top->Social Sciences->Psychology",
            "Top->Social Sciences->Economics",
            "Top->Medicine->Neuroscience",
            "Top->Technology->Engineering->Electrical Engineering->Control Engineering"
        ]
    },
    "url": "http://videolectures.net/rldm2015_lieder_utility_weighted/",
    "segmentation": [
        [
            "In this talk, I will propose a rational model according to which this memory bias helps us make better decisions under uncertainty, especially if you have to be very quick."
        ],
        [
            "When we make decisions, we sometimes imagine the consequences that our actions might have based on our memory of past situations.",
            "And indoor situations or memories of emotionally salient experiences come to mind more easily than those of unremarkable ones."
        ],
        [
            "So for instance, if you have been in a traumatic car accident and you're considering whether or not to go on a road trip, you're very likely to remember this traumatic experience, and you're much less likely to remember the 15,370 first time that you drove to work and nothing remarkable happened, and therefore the traumatic accident is likely to have a higher weight in your decision then the unremarkable experience."
        ],
        [
            "This also holds for positive experiences such as having won the jackpot in a casino is something that is likely going to come to your mind when you consider gambling again, and much more likely than any of the thousands of times in which you lost a very small sum of money.",
            "And is also."
        ],
        [
            "Holes for vicarious experience such as news reports about 911 or the."
        ],
        [
            "Human beings incident."
        ],
        [
            "We developed a rational theory of these biases by thinking about two fundamental limitations of expected utility theory and how they might be overcome.",
            "According to Excel."
        ],
        [
            "Utility theory you should choose the action with the highest expected utility, which is."
        ],
        [
            "Effectively, the sum over all over the utility's of all possible consequences that your action might have rated by its respective probability.",
            "The problem with this formulation is that in realistic real world decision problems, you have to consider infinitely many possible futures, and that would require an infinite amount of computation."
        ],
        [
            "And therefore evaluating this expected integral is intractable.",
            "For for brains and machines.",
            "A second problem is that even in simple laboratory task where people have sufficient computational resources to evaluate expected utilities, they still."
        ],
        [
            "Violate the prescriptions of expected utility theory.",
            "So to overcome these two problems, we propose that.",
            "People approximate expected utility by spice sampling."
        ],
        [
            "The simplest way in which expected utility's can be approximated by sampling is to simulate potential outcomes according to the probability that they will occur."
        ],
        [
            "So effectively, we're now sampling from P of all given a.",
            "And be."
        ],
        [
            "Valuate the utility of each sample outcome and simply average demand.",
            "This gives us an estimate of the actions, expected utility, and."
        ],
        [
            "If we do this for all available actions, then we can simply choose the action with the highest estimated utility.",
            "And the good news is that with this simple algorithm we can identify.",
            "The best action.",
            "And converge the true expected utilities if you perform an infinite number of simulations.",
            "But the bad news is that we always."
        ],
        [
            "Have only a finite amount of time and effort.",
            "We can only perform a finite number of simulations, meaning that we have to neglect and ignore the majority of the infinitely many possible futures that might ensue from our action.",
            "And this makes it very important how we simulate because how we simulate determines what we will consider and what we might ignore."
        ],
        [
            "The intuitive version to simulate according to how probable an event is to occur can fail miserably.",
            "Becaused the resulting utility estimates have a very high variance, so if you apply that representative sampling scheme, I just showed you to the decision whether or not to play Russian roulette, you would effectively."
        ],
        [
            "You rolling a dice and you would consider the possibility of death whenever DICE comes up one.",
            "And for all other numbers you would think it would be a thrilling experience.",
            "That would be fun and completely harmless.",
            "So that means if you only oldest eyes a few times and people in fact seem to perform only one or a handful of simulations, there is a good chance you will completely ignore the possibility of death.",
            "And in that case the."
        ],
        [
            "Millions of his estimate literally kills you.",
            "Therefore.",
            "In order to make safe decisions in these high high risk situations under time pressure, the brain needs a sampling and simulation scheme that shrinks this variance."
        ],
        [
            "And one way to shrink the variance is."
        ],
        [
            "Buy instead rolling loaded dice.",
            "And ice that will, with high probability, come up one and thereby telling you that you might die, such that whenever you assess the expect utility in a decision problem like this, you're going to take into account this very important potential outcome.",
            "As a consequence, you will have a much lower variance estimate of the expected utility at the expense of a little bit of bias, so you would be a little bit pessimistic about how bad it is to play Russian roulette, but on the other hand, you would at least always decline the offer to play this game."
        ],
        [
            "So this is an example of the bias variance tradeoff and the general argument that I'm making is that in many decision situations a little bit of bias is rational to accept at because it reduces the variance of your estimate, and especially with small numbers of simulations, the variance is more important than the bias."
        ],
        [
            "OK, so one sampling algorithm.",
            "That can achieve better bias variance tradeoff than representative simulation in principle, is important sampling.",
            "In important sampling, you don't simulate outcomes according to the true probability of occurrence, but in."
        ],
        [
            "According to an important distribution queue, which is different from P, this would correspond to the loaded dice."
        ],
        [
            "And if you did that in our Russian roulette example with the importance distribution Q shown here, he would very likely consider the possibility of death as one of your first outcomes, such that even with a few simulations you would take it into account with very high probability."
        ],
        [
            "Um?",
            "You can still compute an estimate of the expected utility by averaging, but now you're taking a weighted average where your weights."
        ],
        [
            "The probability that something actually occurs divided by the probability of which is simulated.",
            "And that corrects for the difference between the simulation distribution and the true outcome distribution.",
            "So in this way."
        ],
        [
            "Um?"
        ],
        [
            "You get utility estimates that.",
            "May have a much lower variance.",
            "And you can again use these utility estimates to identify the action that appears best.",
            "So as I motivated.",
            "This might have the potential to lead to much better decisions with a small number of simulations, but there's an important degree of freedom here, which is the important distribution Q.",
            "And that raises the question of."
        ],
        [
            "Each distribution should be in sample form in order to make good decisions with a small number of simulations."
        ],
        [
            "Our proposal is that the brain should approximate optimal important sampling bias scheme that we call utility weighted sampling.",
            "Which way is the probability that an event will occur by the events extremity, which is the absolute value of its utility, hence the name, our utility weighted sampling."
        ],
        [
            "In previous work we have shown that this cognitive model can explain people's biases in.",
            "Frequency estimation as well as their biases in decisions from description.",
            "And upon hearing about these results."
        ],
        [
            "Blue tick alerted us that he is observed similar biases in decisions from experience and this motivated the submission in which we investigate where our model can also account for biases in decisions from experience.",
            "So in a clever series of experiments.",
            "Ludwig Madonna in Spanish.",
            "Presented subjects with.",
            "A large number of binary decisions between 2 doors.",
            "In game trials as shown here."
        ],
        [
            "One of the doors.",
            "Mystically led to a small reward.",
            "And another door."
        ],
        [
            "Or had a 5050 chance of a high reward or no reward at all."
        ],
        [
            "Lost trials.",
            "One of the doors deterministically leads to."
        ],
        [
            "A small loss.",
            "And the other door."
        ],
        [
            "Had a 5050 chance of Ibara very large loss or no loss.",
            "Ah."
        ],
        [
            "And in this experiment.",
            "There's a very interesting phenomenon.",
            "People develop inconsistent with preferences overtime, such that eventually they become with seeking for gain trials, but risk averse for loss trials and this pattern of risk preferences is not there initially, but it only occurs after several blocks of decisions from experience.",
            "So these are two interesting and challenging phenomena.",
            "They violate prospect theory, and they also posed additional challenge of explaining how it is that.",
            "We don't initially have these risk preferences, but we develop them overtime."
        ],
        [
            "2.",
            "Explain this phenomenon.",
            "We developed a learning model that is can be phrased as a abstract neural network model.",
            "In which act?"
        ],
        [
            "Represented by one of the layers, another layer."
        ],
        [
            "Represents the potential outcomes and rates, but."
        ],
        [
            "In this, layers represent a probability with which each outcome will follow each of the actions.",
            "Now when.",
            "An action and outcome unit simultaneously active, then their rate is going to be strengthened by."
        ],
        [
            "We bought modulated.",
            "Associative plasticity role.",
            "And we, especially when we assume."
        ],
        [
            "In this ruled out, the new weight is going to be the old way, plus a learning rate times the absolute value of this prediction error.",
            "This is consistent with the observation that the base lateral amygdala encodes the absolute value of the prediction error and modulates associative plasticity in Australia time.",
            "In addition to this.",
            "Activation dependent plasticity process.",
            "There's also a decay process."
        ],
        [
            "Is such that?"
        ],
        [
            "When the outcome unit was not active, then its weight is going to decay according to a forgetting rate, We chose these particular learning rates."
        ],
        [
            "'cause they ensure that the rates of this network converge to those weights that are required to implement utility weighted sampling as described before.",
            "Um?",
            "This happens if the utility is the reward prediction error.",
            "And the act."
        ],
        [
            "Creation function of outcome units is such that the probability that they become active is proportional to.",
            "Weighted sum of their inputs."
        ],
        [
            "So the prediction error is simply the difference between reward reward value of an outcome minus a reward expectancy, and as we wanted."
        ],
        [
            "Spectrin see is learned by a model free temporal difference learning algorithm that ignores the specifics of the choice context."
        ],
        [
            "And we assume that rewards are encoded by deficient coding scheme proposed by Summerfield and set source according to which.",
            "The range of all outcomes that can occur in this current situation that have to be represented in order to make the choice is fit into the finite dynamic range of the neurons firing rate."
        ],
        [
            "This concludes the definition of our model.",
            "We then fitted this model simultaneously to all of the experiments by Ludwig ET al.",
            "And with a single set of parameters, we were able to explain all of the puzzling qualitative phenomena observed in these experiments.",
            "I only."
        ],
        [
            "Time to tell you about the first 2 experiments, so this is the data that I've already showed you and we found it."
        ],
        [
            "Our model can accurately capture this interesting qualitative phenomenon that people become overtime with seeking for gains and risk averse for losses.",
            "This is a natural prediction of utility weighted sampling because utility weighted sampling, always over, weighs the most extreme outcome, and when the most extreme outcome is positive, as in game trials, that leads to a seeking.",
            "But when the most extreme outcome is negative, as in last trials that leads to risk aversion.",
            "And our model also naturally explains that the Swiss preferences only emerged with learning becausw.",
            "The weights are initialized uniformly and only full learning.",
            "Debates over way extreme outcomes which have a high absolute value of the prediction error."
        ],
        [
            "Next, we modeled memory biases in a follow up study.",
            "My download wiggans Patch.",
            "When the same choice experiments.",
            "But afterwards they gave people memory tests so people were asked which of the?",
            "Outcomes comes to your mind when you see this yellow door."
        ],
        [
            "And people systematically reported the extreme outcome much more frequently than the moderate one, and this is it."
        ],
        [
            "Exactly what is predicted by simulating outcomes according to utility weighted sampling."
        ],
        [
            "Similarly, when people ask to estimate frequencies, they overestimate the frequency of the extreme over the model."
        ],
        [
            "Come, this is also captured by our model."
        ],
        [
            "Furthermore, devices that people have in frequency estimation and memory recall are predictive of their is seeking at a subject by subject level and."
        ],
        [
            "Is also predicted."
        ],
        [
            "Our model."
        ],
        [
            "For the relationship between overestimating the frequency of gains and with seeking and overestimating the frequency of extreme loss and risk aversion."
        ],
        [
            "So to conclude.",
            "Utility."
        ],
        [
            "Sampling presents a unifying explanation for biases in memory, judgment, and decision making."
        ],
        [
            "It can emerge from biologically plausible.",
            "We bought a modulated associated plasticity mechanism.",
            "And."
        ],
        [
            "We suggested a rational explanation according to which the reason that we overweigh and overestimate extreme outcomes is that.",
            "It is rational for us to focus only on the most important potential consequences of our actions when we have only finite time, and therefore can only consider a very small number of them.",
            "And more generally."
        ],
        [
            "Or practical approach suggests that some of our cognitive biases may serve or reflect the rational use of finite cognitive resources.",
            "Thank you very much.",
            "We have time for some questions."
        ],
        [
            "And I'm hoping to see some of you at my poster T 28.",
            "Let's face it.",
            "Thank you for your talk.",
            "It's very interesting.",
            "There are two sort of metaphors that seem to be going on.",
            "You're talking, I just want if you could do the disentangle them for me.",
            "When one metaphor is something traumatic, happens to us, we remember it more and we learn more from the event and that you seem to talk about that.",
            "But in the end it seemed like you were not talking about a bigger emphasis on things that happening, but actually in our actions.",
            "We do things more often.",
            "We oversample in our behavior the risky events and things like that.",
            "So is is really what you're talking about?",
            "Is the ladder and not the not the remembering more or learning more from you know from a particular things.",
            "It is both.",
            "So I have argued that we have.",
            "A biased learning mechanism that learns more strongly from events with high positive or large negative utility.",
            "And this determines how likely we are to simulate that event.",
            "When we make a decision and that leads to particular biases in situations where.",
            "One action is favorable in.",
            "In the case of extreme outcomes, there's another one is less stable.",
            "In case of those extreme outcomes.",
            "So these two are tightly interconnected, and this bias learning mechanism serves 2.",
            "Focus our mental simulations on those things that have a high weight in our utility calculation and should not be ignored.",
            "Thank you for your talk.",
            "You express this as a small sample issue as people see more more experiences.",
            "Does this effect diminish?",
            "They start getting more correct at probabilities of events, so the small sample problem is in how many things we can imagine sample from our memory at a time that we make a decision.",
            "So what we predict is that if people invest more time into making a decision, then despise becomes weaker and.",
            "I think this is a plausible prediction, but as soon as you know 1000 examples of this, are they different?",
            "If they've seen 100 or 10?",
            "Or is it just the memory issue?",
            "So the key reason why we see this effect is not so much how much experience you have, but really how much you sample from your memory at decision time.",
            "As you saw in the simulation, bias becomes emerges as you learn.",
            "So there in this case there were hundreds of decisions that you've made before, and only after that we saw more pronounced biases, but then there was an asset old.",
            "Thank you.",
            "You just one last quick question.",
            "Thanks for your talk so.",
            "Death is really bad.",
            "But is a large win really good?",
            "Should you?",
            "So?",
            "Does this just make people pathological gamblers or is there also some normative?",
            "Benefit in gains.",
            "So it's not that.",
            "High financial outcomes will be over weighted per say.",
            "It's things that have a high utility and what exactly the utility functions somehow outside the scope of my of my theory.",
            "But I think it is rational to obey events that have a high utility and.",
            "Whether or not you should place high utility on a lot of money or not, as some more question outside of Fury.",
            "OK, looks like that speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this talk, I will propose a rational model according to which this memory bias helps us make better decisions under uncertainty, especially if you have to be very quick.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we make decisions, we sometimes imagine the consequences that our actions might have based on our memory of past situations.",
                    "label": 0
                },
                {
                    "sent": "And indoor situations or memories of emotionally salient experiences come to mind more easily than those of unremarkable ones.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for instance, if you have been in a traumatic car accident and you're considering whether or not to go on a road trip, you're very likely to remember this traumatic experience, and you're much less likely to remember the 15,370 first time that you drove to work and nothing remarkable happened, and therefore the traumatic accident is likely to have a higher weight in your decision then the unremarkable experience.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This also holds for positive experiences such as having won the jackpot in a casino is something that is likely going to come to your mind when you consider gambling again, and much more likely than any of the thousands of times in which you lost a very small sum of money.",
                    "label": 0
                },
                {
                    "sent": "And is also.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Holes for vicarious experience such as news reports about 911 or the.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Human beings incident.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We developed a rational theory of these biases by thinking about two fundamental limitations of expected utility theory and how they might be overcome.",
                    "label": 0
                },
                {
                    "sent": "According to Excel.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Utility theory you should choose the action with the highest expected utility, which is.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Effectively, the sum over all over the utility's of all possible consequences that your action might have rated by its respective probability.",
                    "label": 0
                },
                {
                    "sent": "The problem with this formulation is that in realistic real world decision problems, you have to consider infinitely many possible futures, and that would require an infinite amount of computation.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And therefore evaluating this expected integral is intractable.",
                    "label": 0
                },
                {
                    "sent": "For for brains and machines.",
                    "label": 0
                },
                {
                    "sent": "A second problem is that even in simple laboratory task where people have sufficient computational resources to evaluate expected utilities, they still.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Violate the prescriptions of expected utility theory.",
                    "label": 1
                },
                {
                    "sent": "So to overcome these two problems, we propose that.",
                    "label": 0
                },
                {
                    "sent": "People approximate expected utility by spice sampling.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The simplest way in which expected utility's can be approximated by sampling is to simulate potential outcomes according to the probability that they will occur.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So effectively, we're now sampling from P of all given a.",
                    "label": 0
                },
                {
                    "sent": "And be.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Valuate the utility of each sample outcome and simply average demand.",
                    "label": 0
                },
                {
                    "sent": "This gives us an estimate of the actions, expected utility, and.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we do this for all available actions, then we can simply choose the action with the highest estimated utility.",
                    "label": 0
                },
                {
                    "sent": "And the good news is that with this simple algorithm we can identify.",
                    "label": 0
                },
                {
                    "sent": "The best action.",
                    "label": 0
                },
                {
                    "sent": "And converge the true expected utilities if you perform an infinite number of simulations.",
                    "label": 0
                },
                {
                    "sent": "But the bad news is that we always.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have only a finite amount of time and effort.",
                    "label": 0
                },
                {
                    "sent": "We can only perform a finite number of simulations, meaning that we have to neglect and ignore the majority of the infinitely many possible futures that might ensue from our action.",
                    "label": 0
                },
                {
                    "sent": "And this makes it very important how we simulate because how we simulate determines what we will consider and what we might ignore.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The intuitive version to simulate according to how probable an event is to occur can fail miserably.",
                    "label": 0
                },
                {
                    "sent": "Becaused the resulting utility estimates have a very high variance, so if you apply that representative sampling scheme, I just showed you to the decision whether or not to play Russian roulette, you would effectively.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You rolling a dice and you would consider the possibility of death whenever DICE comes up one.",
                    "label": 0
                },
                {
                    "sent": "And for all other numbers you would think it would be a thrilling experience.",
                    "label": 0
                },
                {
                    "sent": "That would be fun and completely harmless.",
                    "label": 0
                },
                {
                    "sent": "So that means if you only oldest eyes a few times and people in fact seem to perform only one or a handful of simulations, there is a good chance you will completely ignore the possibility of death.",
                    "label": 0
                },
                {
                    "sent": "And in that case the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Millions of his estimate literally kills you.",
                    "label": 0
                },
                {
                    "sent": "Therefore.",
                    "label": 0
                },
                {
                    "sent": "In order to make safe decisions in these high high risk situations under time pressure, the brain needs a sampling and simulation scheme that shrinks this variance.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And one way to shrink the variance is.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Buy instead rolling loaded dice.",
                    "label": 0
                },
                {
                    "sent": "And ice that will, with high probability, come up one and thereby telling you that you might die, such that whenever you assess the expect utility in a decision problem like this, you're going to take into account this very important potential outcome.",
                    "label": 0
                },
                {
                    "sent": "As a consequence, you will have a much lower variance estimate of the expected utility at the expense of a little bit of bias, so you would be a little bit pessimistic about how bad it is to play Russian roulette, but on the other hand, you would at least always decline the offer to play this game.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is an example of the bias variance tradeoff and the general argument that I'm making is that in many decision situations a little bit of bias is rational to accept at because it reduces the variance of your estimate, and especially with small numbers of simulations, the variance is more important than the bias.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so one sampling algorithm.",
                    "label": 0
                },
                {
                    "sent": "That can achieve better bias variance tradeoff than representative simulation in principle, is important sampling.",
                    "label": 0
                },
                {
                    "sent": "In important sampling, you don't simulate outcomes according to the true probability of occurrence, but in.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "According to an important distribution queue, which is different from P, this would correspond to the loaded dice.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you did that in our Russian roulette example with the importance distribution Q shown here, he would very likely consider the possibility of death as one of your first outcomes, such that even with a few simulations you would take it into account with very high probability.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You can still compute an estimate of the expected utility by averaging, but now you're taking a weighted average where your weights.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The probability that something actually occurs divided by the probability of which is simulated.",
                    "label": 0
                },
                {
                    "sent": "And that corrects for the difference between the simulation distribution and the true outcome distribution.",
                    "label": 0
                },
                {
                    "sent": "So in this way.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You get utility estimates that.",
                    "label": 0
                },
                {
                    "sent": "May have a much lower variance.",
                    "label": 0
                },
                {
                    "sent": "And you can again use these utility estimates to identify the action that appears best.",
                    "label": 0
                },
                {
                    "sent": "So as I motivated.",
                    "label": 0
                },
                {
                    "sent": "This might have the potential to lead to much better decisions with a small number of simulations, but there's an important degree of freedom here, which is the important distribution Q.",
                    "label": 0
                },
                {
                    "sent": "And that raises the question of.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each distribution should be in sample form in order to make good decisions with a small number of simulations.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our proposal is that the brain should approximate optimal important sampling bias scheme that we call utility weighted sampling.",
                    "label": 0
                },
                {
                    "sent": "Which way is the probability that an event will occur by the events extremity, which is the absolute value of its utility, hence the name, our utility weighted sampling.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In previous work we have shown that this cognitive model can explain people's biases in.",
                    "label": 0
                },
                {
                    "sent": "Frequency estimation as well as their biases in decisions from description.",
                    "label": 0
                },
                {
                    "sent": "And upon hearing about these results.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Blue tick alerted us that he is observed similar biases in decisions from experience and this motivated the submission in which we investigate where our model can also account for biases in decisions from experience.",
                    "label": 1
                },
                {
                    "sent": "So in a clever series of experiments.",
                    "label": 0
                },
                {
                    "sent": "Ludwig Madonna in Spanish.",
                    "label": 0
                },
                {
                    "sent": "Presented subjects with.",
                    "label": 0
                },
                {
                    "sent": "A large number of binary decisions between 2 doors.",
                    "label": 0
                },
                {
                    "sent": "In game trials as shown here.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of the doors.",
                    "label": 0
                },
                {
                    "sent": "Mystically led to a small reward.",
                    "label": 0
                },
                {
                    "sent": "And another door.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or had a 5050 chance of a high reward or no reward at all.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lost trials.",
                    "label": 0
                },
                {
                    "sent": "One of the doors deterministically leads to.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A small loss.",
                    "label": 0
                },
                {
                    "sent": "And the other door.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Had a 5050 chance of Ibara very large loss or no loss.",
                    "label": 0
                },
                {
                    "sent": "Ah.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in this experiment.",
                    "label": 0
                },
                {
                    "sent": "There's a very interesting phenomenon.",
                    "label": 0
                },
                {
                    "sent": "People develop inconsistent with preferences overtime, such that eventually they become with seeking for gain trials, but risk averse for loss trials and this pattern of risk preferences is not there initially, but it only occurs after several blocks of decisions from experience.",
                    "label": 0
                },
                {
                    "sent": "So these are two interesting and challenging phenomena.",
                    "label": 0
                },
                {
                    "sent": "They violate prospect theory, and they also posed additional challenge of explaining how it is that.",
                    "label": 0
                },
                {
                    "sent": "We don't initially have these risk preferences, but we develop them overtime.",
                    "label": 1
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "Explain this phenomenon.",
                    "label": 0
                },
                {
                    "sent": "We developed a learning model that is can be phrased as a abstract neural network model.",
                    "label": 0
                },
                {
                    "sent": "In which act?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Represented by one of the layers, another layer.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Represents the potential outcomes and rates, but.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this, layers represent a probability with which each outcome will follow each of the actions.",
                    "label": 0
                },
                {
                    "sent": "Now when.",
                    "label": 0
                },
                {
                    "sent": "An action and outcome unit simultaneously active, then their rate is going to be strengthened by.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We bought modulated.",
                    "label": 0
                },
                {
                    "sent": "Associative plasticity role.",
                    "label": 0
                },
                {
                    "sent": "And we, especially when we assume.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this ruled out, the new weight is going to be the old way, plus a learning rate times the absolute value of this prediction error.",
                    "label": 1
                },
                {
                    "sent": "This is consistent with the observation that the base lateral amygdala encodes the absolute value of the prediction error and modulates associative plasticity in Australia time.",
                    "label": 0
                },
                {
                    "sent": "In addition to this.",
                    "label": 0
                },
                {
                    "sent": "Activation dependent plasticity process.",
                    "label": 0
                },
                {
                    "sent": "There's also a decay process.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is such that?",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When the outcome unit was not active, then its weight is going to decay according to a forgetting rate, We chose these particular learning rates.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "'cause they ensure that the rates of this network converge to those weights that are required to implement utility weighted sampling as described before.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "This happens if the utility is the reward prediction error.",
                    "label": 0
                },
                {
                    "sent": "And the act.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Creation function of outcome units is such that the probability that they become active is proportional to.",
                    "label": 0
                },
                {
                    "sent": "Weighted sum of their inputs.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the prediction error is simply the difference between reward reward value of an outcome minus a reward expectancy, and as we wanted.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Spectrin see is learned by a model free temporal difference learning algorithm that ignores the specifics of the choice context.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we assume that rewards are encoded by deficient coding scheme proposed by Summerfield and set source according to which.",
                    "label": 0
                },
                {
                    "sent": "The range of all outcomes that can occur in this current situation that have to be represented in order to make the choice is fit into the finite dynamic range of the neurons firing rate.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This concludes the definition of our model.",
                    "label": 0
                },
                {
                    "sent": "We then fitted this model simultaneously to all of the experiments by Ludwig ET al.",
                    "label": 0
                },
                {
                    "sent": "And with a single set of parameters, we were able to explain all of the puzzling qualitative phenomena observed in these experiments.",
                    "label": 1
                },
                {
                    "sent": "I only.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time to tell you about the first 2 experiments, so this is the data that I've already showed you and we found it.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our model can accurately capture this interesting qualitative phenomenon that people become overtime with seeking for gains and risk averse for losses.",
                    "label": 1
                },
                {
                    "sent": "This is a natural prediction of utility weighted sampling because utility weighted sampling, always over, weighs the most extreme outcome, and when the most extreme outcome is positive, as in game trials, that leads to a seeking.",
                    "label": 0
                },
                {
                    "sent": "But when the most extreme outcome is negative, as in last trials that leads to risk aversion.",
                    "label": 0
                },
                {
                    "sent": "And our model also naturally explains that the Swiss preferences only emerged with learning becausw.",
                    "label": 0
                },
                {
                    "sent": "The weights are initialized uniformly and only full learning.",
                    "label": 0
                },
                {
                    "sent": "Debates over way extreme outcomes which have a high absolute value of the prediction error.",
                    "label": 1
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next, we modeled memory biases in a follow up study.",
                    "label": 1
                },
                {
                    "sent": "My download wiggans Patch.",
                    "label": 0
                },
                {
                    "sent": "When the same choice experiments.",
                    "label": 0
                },
                {
                    "sent": "But afterwards they gave people memory tests so people were asked which of the?",
                    "label": 1
                },
                {
                    "sent": "Outcomes comes to your mind when you see this yellow door.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And people systematically reported the extreme outcome much more frequently than the moderate one, and this is it.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Exactly what is predicted by simulating outcomes according to utility weighted sampling.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Similarly, when people ask to estimate frequencies, they overestimate the frequency of the extreme over the model.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Come, this is also captured by our model.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Furthermore, devices that people have in frequency estimation and memory recall are predictive of their is seeking at a subject by subject level and.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is also predicted.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our model.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the relationship between overestimating the frequency of gains and with seeking and overestimating the frequency of extreme loss and risk aversion.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to conclude.",
                    "label": 0
                },
                {
                    "sent": "Utility.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sampling presents a unifying explanation for biases in memory, judgment, and decision making.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It can emerge from biologically plausible.",
                    "label": 0
                },
                {
                    "sent": "We bought a modulated associated plasticity mechanism.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We suggested a rational explanation according to which the reason that we overweigh and overestimate extreme outcomes is that.",
                    "label": 0
                },
                {
                    "sent": "It is rational for us to focus only on the most important potential consequences of our actions when we have only finite time, and therefore can only consider a very small number of them.",
                    "label": 0
                },
                {
                    "sent": "And more generally.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or practical approach suggests that some of our cognitive biases may serve or reflect the rational use of finite cognitive resources.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "We have time for some questions.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I'm hoping to see some of you at my poster T 28.",
                    "label": 0
                },
                {
                    "sent": "Let's face it.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your talk.",
                    "label": 0
                },
                {
                    "sent": "It's very interesting.",
                    "label": 0
                },
                {
                    "sent": "There are two sort of metaphors that seem to be going on.",
                    "label": 0
                },
                {
                    "sent": "You're talking, I just want if you could do the disentangle them for me.",
                    "label": 0
                },
                {
                    "sent": "When one metaphor is something traumatic, happens to us, we remember it more and we learn more from the event and that you seem to talk about that.",
                    "label": 0
                },
                {
                    "sent": "But in the end it seemed like you were not talking about a bigger emphasis on things that happening, but actually in our actions.",
                    "label": 0
                },
                {
                    "sent": "We do things more often.",
                    "label": 0
                },
                {
                    "sent": "We oversample in our behavior the risky events and things like that.",
                    "label": 0
                },
                {
                    "sent": "So is is really what you're talking about?",
                    "label": 0
                },
                {
                    "sent": "Is the ladder and not the not the remembering more or learning more from you know from a particular things.",
                    "label": 0
                },
                {
                    "sent": "It is both.",
                    "label": 0
                },
                {
                    "sent": "So I have argued that we have.",
                    "label": 0
                },
                {
                    "sent": "A biased learning mechanism that learns more strongly from events with high positive or large negative utility.",
                    "label": 0
                },
                {
                    "sent": "And this determines how likely we are to simulate that event.",
                    "label": 0
                },
                {
                    "sent": "When we make a decision and that leads to particular biases in situations where.",
                    "label": 1
                },
                {
                    "sent": "One action is favorable in.",
                    "label": 0
                },
                {
                    "sent": "In the case of extreme outcomes, there's another one is less stable.",
                    "label": 0
                },
                {
                    "sent": "In case of those extreme outcomes.",
                    "label": 0
                },
                {
                    "sent": "So these two are tightly interconnected, and this bias learning mechanism serves 2.",
                    "label": 0
                },
                {
                    "sent": "Focus our mental simulations on those things that have a high weight in our utility calculation and should not be ignored.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your talk.",
                    "label": 0
                },
                {
                    "sent": "You express this as a small sample issue as people see more more experiences.",
                    "label": 0
                },
                {
                    "sent": "Does this effect diminish?",
                    "label": 0
                },
                {
                    "sent": "They start getting more correct at probabilities of events, so the small sample problem is in how many things we can imagine sample from our memory at a time that we make a decision.",
                    "label": 0
                },
                {
                    "sent": "So what we predict is that if people invest more time into making a decision, then despise becomes weaker and.",
                    "label": 0
                },
                {
                    "sent": "I think this is a plausible prediction, but as soon as you know 1000 examples of this, are they different?",
                    "label": 0
                },
                {
                    "sent": "If they've seen 100 or 10?",
                    "label": 0
                },
                {
                    "sent": "Or is it just the memory issue?",
                    "label": 0
                },
                {
                    "sent": "So the key reason why we see this effect is not so much how much experience you have, but really how much you sample from your memory at decision time.",
                    "label": 0
                },
                {
                    "sent": "As you saw in the simulation, bias becomes emerges as you learn.",
                    "label": 0
                },
                {
                    "sent": "So there in this case there were hundreds of decisions that you've made before, and only after that we saw more pronounced biases, but then there was an asset old.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "You just one last quick question.",
                    "label": 0
                },
                {
                    "sent": "Thanks for your talk so.",
                    "label": 0
                },
                {
                    "sent": "Death is really bad.",
                    "label": 0
                },
                {
                    "sent": "But is a large win really good?",
                    "label": 0
                },
                {
                    "sent": "Should you?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "Does this just make people pathological gamblers or is there also some normative?",
                    "label": 0
                },
                {
                    "sent": "Benefit in gains.",
                    "label": 0
                },
                {
                    "sent": "So it's not that.",
                    "label": 0
                },
                {
                    "sent": "High financial outcomes will be over weighted per say.",
                    "label": 0
                },
                {
                    "sent": "It's things that have a high utility and what exactly the utility functions somehow outside the scope of my of my theory.",
                    "label": 0
                },
                {
                    "sent": "But I think it is rational to obey events that have a high utility and.",
                    "label": 1
                },
                {
                    "sent": "Whether or not you should place high utility on a lot of money or not, as some more question outside of Fury.",
                    "label": 0
                },
                {
                    "sent": "OK, looks like that speaker again.",
                    "label": 0
                }
            ]
        }
    }
}