{
    "id": "6puyme5k2zrqseufa63aggdd5com3fdy",
    "title": "Learning Concurrent Motor Skills in Versatile Solution Spaces",
    "info": {
        "author": [
            "Christian Daniel, Department of Computer Science, Darmstadt University of Technology"
        ],
        "published": "Aug. 6, 2013",
        "recorded": "April 2013",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/machine_daniel_motor_skills/",
    "segmentation": [
        [
            "I'm Christian Daniel and the work I'm presenting today is joint work with Norman and Jan Peters.",
            "And together we are interested in reinforcement learning algorithms for real robots.",
            "So what it gives us is that we are also need to find methods that work with continuous states.",
            "The actions for example, and once we have that fixed."
        ],
        [
            "Add please.",
            "We have methods that solve tasks, but as we go into the real world, we realized that solving a task with one solution is often not enough.",
            "So for example, if you look at tennis again now we see that playing tennis it's not enough just to learn how to play a forehand to return the ball.",
            "But if you want to successfully play tennis, then you also need to know how to smash or how to play a backhand.",
            "And also going back to what Vincent said before is that often if you learn only one solution to a task and the environment changes, it may happen that the solution is unavailable.",
            "So for example, if you think about finding a path from point A to point B, if for some reason this path is blocked an you're lost, you cannot go to point B anymore, and instead what we propose is that basically we enable our learning algorithms to learn multiple solutions to tasks.",
            "And to learn them simultaneously.",
            "Thank you."
        ],
        [
            "And the way we propose to do this is by basically expanding our policy from a flat policy to a hierarchical policy.",
            "So usually on the left you see what traditional methods will do that.",
            "Basically you have a state, and given that state you would select an action and instead we propose.",
            "Now that we say OK, we have a state, and given that state, we select a discrete option that basically defines what kind of action we want to take.",
            "So it's going to be a four hand.",
            "Back end if you want to go route A or B and then when we selected this option that we want to follow again we have this option policy is the sub policy's which then define our actions given the state and the option."
        ],
        [
            "So we applied this to this game of tetherball.",
            "And you see here a brat Wama robot 7 degree of freedom robot.",
            "And the task is to hit the ball on the string such that it hits the target zone which is behind the pole.",
            "So basically you have to hit the ball around the pole and The thing is here again you have these tool options.",
            "We have two possibilities.",
            "You can hit around left or the right side if you would just basically take the combination you want to hit the ball straight into the middle of the pole.",
            "And what we could show is that we basically learn both solutions so that the robot can really either hit to the left or to riot.",
            "It's all learn together.",
            "And if you were to block one side, the robot could still hit around the other side and the next slide there."
        ],
        [
            "So what we present is basically mathematically sound framework which automatically learns multiple options to a learning task, and what we could actually show is that it does not only learn multiple options, but actually because we were able to disambiguate between these options, which might not basically be able to work together, like going around the left or the right side, we're actually able to learn a little bit faster, and on average we learn also better solutions.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm Christian Daniel and the work I'm presenting today is joint work with Norman and Jan Peters.",
                    "label": 1
                },
                {
                    "sent": "And together we are interested in reinforcement learning algorithms for real robots.",
                    "label": 0
                },
                {
                    "sent": "So what it gives us is that we are also need to find methods that work with continuous states.",
                    "label": 0
                },
                {
                    "sent": "The actions for example, and once we have that fixed.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Add please.",
                    "label": 0
                },
                {
                    "sent": "We have methods that solve tasks, but as we go into the real world, we realized that solving a task with one solution is often not enough.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you look at tennis again now we see that playing tennis it's not enough just to learn how to play a forehand to return the ball.",
                    "label": 0
                },
                {
                    "sent": "But if you want to successfully play tennis, then you also need to know how to smash or how to play a backhand.",
                    "label": 0
                },
                {
                    "sent": "And also going back to what Vincent said before is that often if you learn only one solution to a task and the environment changes, it may happen that the solution is unavailable.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you think about finding a path from point A to point B, if for some reason this path is blocked an you're lost, you cannot go to point B anymore, and instead what we propose is that basically we enable our learning algorithms to learn multiple solutions to tasks.",
                    "label": 0
                },
                {
                    "sent": "And to learn them simultaneously.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the way we propose to do this is by basically expanding our policy from a flat policy to a hierarchical policy.",
                    "label": 0
                },
                {
                    "sent": "So usually on the left you see what traditional methods will do that.",
                    "label": 0
                },
                {
                    "sent": "Basically you have a state, and given that state you would select an action and instead we propose.",
                    "label": 0
                },
                {
                    "sent": "Now that we say OK, we have a state, and given that state, we select a discrete option that basically defines what kind of action we want to take.",
                    "label": 0
                },
                {
                    "sent": "So it's going to be a four hand.",
                    "label": 0
                },
                {
                    "sent": "Back end if you want to go route A or B and then when we selected this option that we want to follow again we have this option policy is the sub policy's which then define our actions given the state and the option.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we applied this to this game of tetherball.",
                    "label": 0
                },
                {
                    "sent": "And you see here a brat Wama robot 7 degree of freedom robot.",
                    "label": 0
                },
                {
                    "sent": "And the task is to hit the ball on the string such that it hits the target zone which is behind the pole.",
                    "label": 1
                },
                {
                    "sent": "So basically you have to hit the ball around the pole and The thing is here again you have these tool options.",
                    "label": 0
                },
                {
                    "sent": "We have two possibilities.",
                    "label": 0
                },
                {
                    "sent": "You can hit around left or the right side if you would just basically take the combination you want to hit the ball straight into the middle of the pole.",
                    "label": 0
                },
                {
                    "sent": "And what we could show is that we basically learn both solutions so that the robot can really either hit to the left or to riot.",
                    "label": 0
                },
                {
                    "sent": "It's all learn together.",
                    "label": 0
                },
                {
                    "sent": "And if you were to block one side, the robot could still hit around the other side and the next slide there.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we present is basically mathematically sound framework which automatically learns multiple options to a learning task, and what we could actually show is that it does not only learn multiple options, but actually because we were able to disambiguate between these options, which might not basically be able to work together, like going around the left or the right side, we're actually able to learn a little bit faster, and on average we learn also better solutions.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}