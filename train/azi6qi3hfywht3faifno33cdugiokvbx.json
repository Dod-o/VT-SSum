{
    "id": "azi6qi3hfywht3faifno33cdugiokvbx",
    "title": "Towards 3D modeling of Interacting TM Helix Pairs Based on Classification of Helix Pair Sequence",
    "info": {
        "author": [
            "Witold Dyrka, Institute of Biomedical Engineering and Instrumentation, Wroc\u0142aw University of Science and Technology"
        ],
        "published": "Oct. 14, 2010",
        "recorded": "September 2010",
        "category": [
            "Top->Computer Science->Bioinformatics"
        ]
    },
    "url": "http://videolectures.net/prib2010_dyrka_t3mi/",
    "segmentation": [
        [
            "Pistol my name is Victor Burka I'm from rocephin ver.",
            "City of Technology and I will present our work on classification of contract of transmembrane Helix pairs but it on Helix per sequences."
        ],
        [
            "Our research focus.",
            "Is on transforming proteins as they represent 30% of human genome and roughly half of drug targets.",
            "But on the other side there consists of all the only one or two percent of non protein structures are just moving properties.",
            "So there is basically a need for a conditional structure prediction methods.",
            "Unfortunately as there is not that many templates I homology based methods are not really the solution in majority of cases.",
            "And also of initial methods are only successful for for smaller chains up to maybe 200 amino acids and often longer chains.",
            "As for instance for protein for protein channels and then the search space needs to be constrained because of inaccurate system definition of the energy."
        ],
        [
            "Function.",
            "And the kind of constraints which has improved to be very successful or contact Maps.",
            "And our method in fact is a method to enhance information on in contact Maps between palaces.",
            "By I think information about the confirmation of the of the hell expire."
        ],
        [
            "On the top of this practical motivation, we also would like to improve our knowledge on sequence, structure, relation, alcoholic ultrasound proteins and Moreover understand the nature of polymeric molecules better.",
            "Where we build on analogies with natural language sentence."
        ],
        [
            "Rational for our metals is provided by the study by Walters Integrado for 2006.",
            "They have.",
            "They were able to a cluster 90% of headaches.",
            "Alex interactions into just eight clusters, which were represented by accurately by 8 templates.",
            "And while this classification was made on basis of geometry, there are also well known some sequence level motives underlying Alex parking, such as GHXXXG, Sorry, motive and other motives which can be found for existing remote database.",
            "However, all these sequence motifs are motives which refer to one or maybe two analysis from the from the interacting power, but each each each model.",
            "Every motive is refers to one Halleck separately, so there has been no matter which directly represents interactions between two palaces."
        ],
        [
            "One of the prerequisites of such a method is ability of of.",
            "Represent Barwise nested dependencies which can be found in antiparallel helical Alex interactions and such interactions can be for instance represented by stochastic context free grammars which are successfully applied for many RNA structures and also for.",
            "For binding site recognition in our area work.",
            "In this work we build on on the division of Hell Excel expert on Outer Face and Interface part.",
            "And also we have to include the periodicity of the hallex into into the grammar structure.",
            "So this grammar is based in the general scheme of the grammars based on Vardis pornstar at work from 2005, and for instance if we have a grammar rule for interface, it says that interface is built from interface residues from one or two interface residues from 1 from 1 Helix, one or two.",
            "Is this from the other headaches and this rule should be.",
            "After this we should call outer face rule in our derivation tree also to reduce the.",
            "The search space.",
            "And and and to deal effectively with control complexity as the complexity of parsing so has the context grammar.",
            "SIS is cubic instead of using unnoted entities we use.",
            "We represent residues by by a level of a given physicochemical property.",
            "In our case, we decided to build grammars based on Accessibility under volume Alpha Helix and beta intern, propensity's and frequency."
        ],
        [
            "Once we get the structure, which is general structure of the grammar, which is general for or for all Helix interactions, then we train probabilities for for grammar rules which are specific for each interaction class and we use genetic algorithms evolutionary algorithm to do this as an input, we've got positive training set, only organized sequences of had expires, which represents given class of confirmation.",
            "And during during evolution we we evaluate them on the basis of objective function which provides some of log probabilities that sequence that will die from training set as belongs to language described by grammar G."
        ],
        [
            "In order to make the learning more effective with design at a novel genotype phenotype function which I have this exploratory capabilities and allows for faster computation.",
            "Because if if I.",
            "If the genome value is small, it is reduced to 0 for quite many rules, and then there's this rules doesn't need to be processed during training.",
            "And also there is a there is a region.",
            "If there are small changes in the genotype value in this region, there will be a relatively large differences in phenotype values, so it enhances exploratory capabilities."
        ],
        [
            "As the output of the procedure, we get the grammar with probability with rules with assigning probabilities and what is also quite nice is that typically only some percentage like 10 to 20% of rose have some relevant probabilities, so in principle they are human readable.",
            "So in this case it's 20 rolls out of initial 201 and on the right hand side you can see the parse through.",
            "Actually this faster is built using rules of high probability which can be seen as a way of.",
            "Visualizing grammar switches, on the other hand, intrinsically ambiguous."
        ],
        [
            "Now I move to that was benchmarks.",
            "So for benchmarks we created two data sets.",
            "First data set was created using waters and the broader origonal data it consisted of headaches for fragments with 10 aces from one headaches and analysis from another Helix, and there were roughly 200 such pairs with homological of similarity below 40%.",
            "And then we've got another data set which was created by us using PDT and database.",
            "Then we.",
            "I looked for us for products for palaces in interaction using promotive and then assign it the purse to alter the Grado classes.",
            "It resulted in 227 verse if I remember well.",
            "What is nice is that the relative numbers in both clusters seem to agree and this both both of these groups were made also non homologist to make them independent from."
        ],
        [
            "Each other.",
            "So the first benchmark was to assign a Helix expert, one of four classes according to passing score that reflects how Helix Helix contact fragment sequence fits the grammar.",
            "In use it for a given class.",
            "So in for training we use 20 helixx colleagues.",
            "Contact fragments from PDB TM set which were closest to each class template or in terms of our MSD and in this case we accepted, logas sequences and for validation we used autism.",
            "Gradual basis set.",
            "And this set was made in Houma Logus, and and was independent from the training set."
        ],
        [
            "Here here occurs we obtain.",
            "So we can.",
            "We can see that there were different properties which underlie the best performing grammars, because there are best performing grammars, which I'll show here.",
            "So it was Accessibility for a class one.",
            "It was a wonderful volume for class two and three and better propensity for Class 4.",
            "The best results were obtained for for Class 2 and class three with other areas on the Roc curves up to a .68 and As for C2 that there are curve is shifted two outs sensitivity it is shifted towards specificity for Class 3."
        ],
        [
            "And here is a table which shows the most useful properties for grammars, but in a class by class comparison in class by class classification.",
            "Sorry, in five out of 12 cases the areas under a curve where above oh point 7.",
            "And the most, it seems like the most useful are Accessibility, environment versus volume, and especially, but it can be traced it to them.",
            "To the fact that, for instance for class One it uses, there are there are high risk which are quite close together on quite long relatively long distance.",
            "So the Accessibility things that is important and for for instance for Class 2 it consists of her expert which has a relatively high number of smaller."
        ],
        [
            "Videos.",
            "And then there is a benchmark to it's.",
            "It's a live one out cross validation and this is this has been done only on what is the gradual basis set.",
            "This set was slightly modified from the from the.",
            "That was on the previous slide, but these were not important for modifications for these results actually.",
            "And and they thought it was the same and and the motivation was to get more insight into what?",
            "Going on inside the."
        ],
        [
            "Authors inside the classes and here is here are benchmark results.",
            "So what is interesting that as accuracy on the full set is?",
            "Of some values that there can be in all the cases that can distinguish some subclasses of high accuracy where accuracy is much improved, like here from 55% to almost 90, or even like here from 58 to almost 90%, and for instance in this case this high accuracy subset is as large as 47% of.",
            "A of all expressed and as we can see on this plot for Class 2 and Class 3 at this subset, high accuracy subset seems to be relatively well distinguishable.",
            "So it suggests that there are some subclasses which are there may be more prone to structural description and at the moment we investigate it further."
        ],
        [
            "So just to conclude, we developed the first method for prediction of confirmation of his interaction classes, which explicitly represents dependences between 2.",
            "Alice is the method was tested using independent validation set and achieved areas under a curve from open 59 to oh point 68.",
            "Access ability and Vander Waals volume seemed to be the most useful, most informative amino acid physical chemical properties for building the grammars and the performance of the method seems things that can be improved in terms of accuracy up to around 90% for certain subclasses which contains from 1/3 to 1/2 of Alex Alex."
        ],
        [
            "Nurse.",
            "And that's it.",
            "I just would like to thank my PhD advisor.",
            "More girls like a tourist and our collaborator from Kingston University in London.",
            "Jean Christophe Novelli.",
            "And other people from my lap and you for your attention.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pistol my name is Victor Burka I'm from rocephin ver.",
                    "label": 0
                },
                {
                    "sent": "City of Technology and I will present our work on classification of contract of transmembrane Helix pairs but it on Helix per sequences.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our research focus.",
                    "label": 0
                },
                {
                    "sent": "Is on transforming proteins as they represent 30% of human genome and roughly half of drug targets.",
                    "label": 1
                },
                {
                    "sent": "But on the other side there consists of all the only one or two percent of non protein structures are just moving properties.",
                    "label": 1
                },
                {
                    "sent": "So there is basically a need for a conditional structure prediction methods.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately as there is not that many templates I homology based methods are not really the solution in majority of cases.",
                    "label": 0
                },
                {
                    "sent": "And also of initial methods are only successful for for smaller chains up to maybe 200 amino acids and often longer chains.",
                    "label": 1
                },
                {
                    "sent": "As for instance for protein for protein channels and then the search space needs to be constrained because of inaccurate system definition of the energy.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Function.",
                    "label": 0
                },
                {
                    "sent": "And the kind of constraints which has improved to be very successful or contact Maps.",
                    "label": 0
                },
                {
                    "sent": "And our method in fact is a method to enhance information on in contact Maps between palaces.",
                    "label": 1
                },
                {
                    "sent": "By I think information about the confirmation of the of the hell expire.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the top of this practical motivation, we also would like to improve our knowledge on sequence, structure, relation, alcoholic ultrasound proteins and Moreover understand the nature of polymeric molecules better.",
                    "label": 0
                },
                {
                    "sent": "Where we build on analogies with natural language sentence.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rational for our metals is provided by the study by Walters Integrado for 2006.",
                    "label": 0
                },
                {
                    "sent": "They have.",
                    "label": 0
                },
                {
                    "sent": "They were able to a cluster 90% of headaches.",
                    "label": 1
                },
                {
                    "sent": "Alex interactions into just eight clusters, which were represented by accurately by 8 templates.",
                    "label": 1
                },
                {
                    "sent": "And while this classification was made on basis of geometry, there are also well known some sequence level motives underlying Alex parking, such as GHXXXG, Sorry, motive and other motives which can be found for existing remote database.",
                    "label": 0
                },
                {
                    "sent": "However, all these sequence motifs are motives which refer to one or maybe two analysis from the from the interacting power, but each each each model.",
                    "label": 0
                },
                {
                    "sent": "Every motive is refers to one Halleck separately, so there has been no matter which directly represents interactions between two palaces.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One of the prerequisites of such a method is ability of of.",
                    "label": 0
                },
                {
                    "sent": "Represent Barwise nested dependencies which can be found in antiparallel helical Alex interactions and such interactions can be for instance represented by stochastic context free grammars which are successfully applied for many RNA structures and also for.",
                    "label": 1
                },
                {
                    "sent": "For binding site recognition in our area work.",
                    "label": 0
                },
                {
                    "sent": "In this work we build on on the division of Hell Excel expert on Outer Face and Interface part.",
                    "label": 0
                },
                {
                    "sent": "And also we have to include the periodicity of the hallex into into the grammar structure.",
                    "label": 0
                },
                {
                    "sent": "So this grammar is based in the general scheme of the grammars based on Vardis pornstar at work from 2005, and for instance if we have a grammar rule for interface, it says that interface is built from interface residues from one or two interface residues from 1 from 1 Helix, one or two.",
                    "label": 0
                },
                {
                    "sent": "Is this from the other headaches and this rule should be.",
                    "label": 0
                },
                {
                    "sent": "After this we should call outer face rule in our derivation tree also to reduce the.",
                    "label": 0
                },
                {
                    "sent": "The search space.",
                    "label": 0
                },
                {
                    "sent": "And and and to deal effectively with control complexity as the complexity of parsing so has the context grammar.",
                    "label": 0
                },
                {
                    "sent": "SIS is cubic instead of using unnoted entities we use.",
                    "label": 1
                },
                {
                    "sent": "We represent residues by by a level of a given physicochemical property.",
                    "label": 1
                },
                {
                    "sent": "In our case, we decided to build grammars based on Accessibility under volume Alpha Helix and beta intern, propensity's and frequency.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once we get the structure, which is general structure of the grammar, which is general for or for all Helix interactions, then we train probabilities for for grammar rules which are specific for each interaction class and we use genetic algorithms evolutionary algorithm to do this as an input, we've got positive training set, only organized sequences of had expires, which represents given class of confirmation.",
                    "label": 0
                },
                {
                    "sent": "And during during evolution we we evaluate them on the basis of objective function which provides some of log probabilities that sequence that will die from training set as belongs to language described by grammar G.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to make the learning more effective with design at a novel genotype phenotype function which I have this exploratory capabilities and allows for faster computation.",
                    "label": 1
                },
                {
                    "sent": "Because if if I.",
                    "label": 0
                },
                {
                    "sent": "If the genome value is small, it is reduced to 0 for quite many rules, and then there's this rules doesn't need to be processed during training.",
                    "label": 0
                },
                {
                    "sent": "And also there is a there is a region.",
                    "label": 0
                },
                {
                    "sent": "If there are small changes in the genotype value in this region, there will be a relatively large differences in phenotype values, so it enhances exploratory capabilities.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As the output of the procedure, we get the grammar with probability with rules with assigning probabilities and what is also quite nice is that typically only some percentage like 10 to 20% of rose have some relevant probabilities, so in principle they are human readable.",
                    "label": 0
                },
                {
                    "sent": "So in this case it's 20 rolls out of initial 201 and on the right hand side you can see the parse through.",
                    "label": 1
                },
                {
                    "sent": "Actually this faster is built using rules of high probability which can be seen as a way of.",
                    "label": 1
                },
                {
                    "sent": "Visualizing grammar switches, on the other hand, intrinsically ambiguous.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I move to that was benchmarks.",
                    "label": 0
                },
                {
                    "sent": "So for benchmarks we created two data sets.",
                    "label": 0
                },
                {
                    "sent": "First data set was created using waters and the broader origonal data it consisted of headaches for fragments with 10 aces from one headaches and analysis from another Helix, and there were roughly 200 such pairs with homological of similarity below 40%.",
                    "label": 0
                },
                {
                    "sent": "And then we've got another data set which was created by us using PDT and database.",
                    "label": 0
                },
                {
                    "sent": "Then we.",
                    "label": 0
                },
                {
                    "sent": "I looked for us for products for palaces in interaction using promotive and then assign it the purse to alter the Grado classes.",
                    "label": 0
                },
                {
                    "sent": "It resulted in 227 verse if I remember well.",
                    "label": 0
                },
                {
                    "sent": "What is nice is that the relative numbers in both clusters seem to agree and this both both of these groups were made also non homologist to make them independent from.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Each other.",
                    "label": 0
                },
                {
                    "sent": "So the first benchmark was to assign a Helix expert, one of four classes according to passing score that reflects how Helix Helix contact fragment sequence fits the grammar.",
                    "label": 1
                },
                {
                    "sent": "In use it for a given class.",
                    "label": 0
                },
                {
                    "sent": "So in for training we use 20 helixx colleagues.",
                    "label": 1
                },
                {
                    "sent": "Contact fragments from PDB TM set which were closest to each class template or in terms of our MSD and in this case we accepted, logas sequences and for validation we used autism.",
                    "label": 0
                },
                {
                    "sent": "Gradual basis set.",
                    "label": 0
                },
                {
                    "sent": "And this set was made in Houma Logus, and and was independent from the training set.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here here occurs we obtain.",
                    "label": 0
                },
                {
                    "sent": "So we can.",
                    "label": 0
                },
                {
                    "sent": "We can see that there were different properties which underlie the best performing grammars, because there are best performing grammars, which I'll show here.",
                    "label": 0
                },
                {
                    "sent": "So it was Accessibility for a class one.",
                    "label": 0
                },
                {
                    "sent": "It was a wonderful volume for class two and three and better propensity for Class 4.",
                    "label": 0
                },
                {
                    "sent": "The best results were obtained for for Class 2 and class three with other areas on the Roc curves up to a .68 and As for C2 that there are curve is shifted two outs sensitivity it is shifted towards specificity for Class 3.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is a table which shows the most useful properties for grammars, but in a class by class comparison in class by class classification.",
                    "label": 0
                },
                {
                    "sent": "Sorry, in five out of 12 cases the areas under a curve where above oh point 7.",
                    "label": 0
                },
                {
                    "sent": "And the most, it seems like the most useful are Accessibility, environment versus volume, and especially, but it can be traced it to them.",
                    "label": 0
                },
                {
                    "sent": "To the fact that, for instance for class One it uses, there are there are high risk which are quite close together on quite long relatively long distance.",
                    "label": 0
                },
                {
                    "sent": "So the Accessibility things that is important and for for instance for Class 2 it consists of her expert which has a relatively high number of smaller.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Videos.",
                    "label": 0
                },
                {
                    "sent": "And then there is a benchmark to it's.",
                    "label": 0
                },
                {
                    "sent": "It's a live one out cross validation and this is this has been done only on what is the gradual basis set.",
                    "label": 0
                },
                {
                    "sent": "This set was slightly modified from the from the.",
                    "label": 0
                },
                {
                    "sent": "That was on the previous slide, but these were not important for modifications for these results actually.",
                    "label": 0
                },
                {
                    "sent": "And and they thought it was the same and and the motivation was to get more insight into what?",
                    "label": 0
                },
                {
                    "sent": "Going on inside the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Authors inside the classes and here is here are benchmark results.",
                    "label": 0
                },
                {
                    "sent": "So what is interesting that as accuracy on the full set is?",
                    "label": 1
                },
                {
                    "sent": "Of some values that there can be in all the cases that can distinguish some subclasses of high accuracy where accuracy is much improved, like here from 55% to almost 90, or even like here from 58 to almost 90%, and for instance in this case this high accuracy subset is as large as 47% of.",
                    "label": 0
                },
                {
                    "sent": "A of all expressed and as we can see on this plot for Class 2 and Class 3 at this subset, high accuracy subset seems to be relatively well distinguishable.",
                    "label": 1
                },
                {
                    "sent": "So it suggests that there are some subclasses which are there may be more prone to structural description and at the moment we investigate it further.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to conclude, we developed the first method for prediction of confirmation of his interaction classes, which explicitly represents dependences between 2.",
                    "label": 1
                },
                {
                    "sent": "Alice is the method was tested using independent validation set and achieved areas under a curve from open 59 to oh point 68.",
                    "label": 0
                },
                {
                    "sent": "Access ability and Vander Waals volume seemed to be the most useful, most informative amino acid physical chemical properties for building the grammars and the performance of the method seems things that can be improved in terms of accuracy up to around 90% for certain subclasses which contains from 1/3 to 1/2 of Alex Alex.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nurse.",
                    "label": 0
                },
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "I just would like to thank my PhD advisor.",
                    "label": 0
                },
                {
                    "sent": "More girls like a tourist and our collaborator from Kingston University in London.",
                    "label": 0
                },
                {
                    "sent": "Jean Christophe Novelli.",
                    "label": 0
                },
                {
                    "sent": "And other people from my lap and you for your attention.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}