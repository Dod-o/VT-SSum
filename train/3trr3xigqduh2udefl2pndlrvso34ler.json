{
    "id": "3trr3xigqduh2udefl2pndlrvso34ler",
    "title": "Welcome",
    "info": {
        "author": [
            "Pascal Poupart, School of Computer Science, University of Waterloo"
        ],
        "published": "June 22, 2007",
        "recorded": "June 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Reinforcement Learning"
        ]
    },
    "url": "http://videolectures.net/icml07_poupart_intro/",
    "segmentation": [
        [
            "Good morning everyone.",
            "So we're going to get started, but I'd like to ask you to please move forward.",
            "We have such a big room and there's really no need for everyone to sit so far.",
            "If you guys have questions.",
            "Also be easier if you're closer.",
            "OK, don't be shy.",
            "Just feel free to come forward.",
            "There's plenty of room, OK?",
            "Oh, I see.",
            "OK, so this it's easier to see from the back, OK?",
            "OK. OK, in any case, welcome to the ICM Ello 7 tutorial on Bayesian methods for reinforcement learning.",
            "My name is Pascal Poupart.",
            "I'm from the University of Waterloo and then two of my colleagues will join me as well to give this tutorial so Mohammed Gavins Dad who's sitting in the front row here and Yakov Angle also sitting in the front row.",
            "They're both from the University of Alberta and then.",
            "Basically will be telling you about what we really like about vision, reinforcement learning and hopefully convince you that vision techniques you know would be a great tool for reinforcement learning."
        ],
        [
            "OK, so why tutorial invasion reinforcement learning so Bashan?",
            "Methods have actually only been used periodically in reinforcement learning, and it turns out that you can actually trace them back to the 1950s, so we thought it would be nice to have a tutorial on this, and also because there are several advantages that we feel would really help the field move forward.",
            "So some of these advantages that we're going to talk about today.",
            "They include capturing the uncertainty with a full property distribution, dealing with the exploration exploitation tradeoff in the principled way, and then unifying the framework for plane reinforcement, learning, inversion enforcement, learning, and other types of reinforcement learning, and several others that will talk in the next."
        ],
        [
            "She was slides OK, so but roughly, what's our goal today?",
            "Here's our reinforcement learning Builder an all we want to do is put into your toolbox for reinforcement learning.",
            "Some techniques that can be traced back to Thomas Base for Bayesian learning."
        ],
        [
            "And so here's the outline of our talk.",
            "So we're going to start with an intro to reinforcement learning and Bayesian learning then.",
            "So actually Mohammed will give this intro.",
            "Then I'll come back and talk about the history of Asian reinforcement learning.",
            "I'll talk as well about model based Bayesian reinforcement learning, and then we'll take a break after this.",
            "This should be around 10:30.",
            "We may actually go overboard a little bit, but will make sure that you guys have a break.",
            "And then after that.",
            "Mohammed an Yaakov will talk about Model 3 beige and reinforcement learning and then Yaakov will end with a nice demo about controlling an octopus arm.",
            "OK, so Muhammad will come for the intro."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "So we're going to get started, but I'd like to ask you to please move forward.",
                    "label": 0
                },
                {
                    "sent": "We have such a big room and there's really no need for everyone to sit so far.",
                    "label": 0
                },
                {
                    "sent": "If you guys have questions.",
                    "label": 0
                },
                {
                    "sent": "Also be easier if you're closer.",
                    "label": 0
                },
                {
                    "sent": "OK, don't be shy.",
                    "label": 0
                },
                {
                    "sent": "Just feel free to come forward.",
                    "label": 0
                },
                {
                    "sent": "There's plenty of room, OK?",
                    "label": 0
                },
                {
                    "sent": "Oh, I see.",
                    "label": 0
                },
                {
                    "sent": "OK, so this it's easier to see from the back, OK?",
                    "label": 0
                },
                {
                    "sent": "OK. OK, in any case, welcome to the ICM Ello 7 tutorial on Bayesian methods for reinforcement learning.",
                    "label": 1
                },
                {
                    "sent": "My name is Pascal Poupart.",
                    "label": 0
                },
                {
                    "sent": "I'm from the University of Waterloo and then two of my colleagues will join me as well to give this tutorial so Mohammed Gavins Dad who's sitting in the front row here and Yakov Angle also sitting in the front row.",
                    "label": 0
                },
                {
                    "sent": "They're both from the University of Alberta and then.",
                    "label": 0
                },
                {
                    "sent": "Basically will be telling you about what we really like about vision, reinforcement learning and hopefully convince you that vision techniques you know would be a great tool for reinforcement learning.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so why tutorial invasion reinforcement learning so Bashan?",
                    "label": 0
                },
                {
                    "sent": "Methods have actually only been used periodically in reinforcement learning, and it turns out that you can actually trace them back to the 1950s, so we thought it would be nice to have a tutorial on this, and also because there are several advantages that we feel would really help the field move forward.",
                    "label": 1
                },
                {
                    "sent": "So some of these advantages that we're going to talk about today.",
                    "label": 0
                },
                {
                    "sent": "They include capturing the uncertainty with a full property distribution, dealing with the exploration exploitation tradeoff in the principled way, and then unifying the framework for plane reinforcement, learning, inversion enforcement, learning, and other types of reinforcement learning, and several others that will talk in the next.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "She was slides OK, so but roughly, what's our goal today?",
                    "label": 0
                },
                {
                    "sent": "Here's our reinforcement learning Builder an all we want to do is put into your toolbox for reinforcement learning.",
                    "label": 1
                },
                {
                    "sent": "Some techniques that can be traced back to Thomas Base for Bayesian learning.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so here's the outline of our talk.",
                    "label": 0
                },
                {
                    "sent": "So we're going to start with an intro to reinforcement learning and Bayesian learning then.",
                    "label": 1
                },
                {
                    "sent": "So actually Mohammed will give this intro.",
                    "label": 0
                },
                {
                    "sent": "Then I'll come back and talk about the history of Asian reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "I'll talk as well about model based Bayesian reinforcement learning, and then we'll take a break after this.",
                    "label": 0
                },
                {
                    "sent": "This should be around 10:30.",
                    "label": 0
                },
                {
                    "sent": "We may actually go overboard a little bit, but will make sure that you guys have a break.",
                    "label": 0
                },
                {
                    "sent": "And then after that.",
                    "label": 0
                },
                {
                    "sent": "Mohammed an Yaakov will talk about Model 3 beige and reinforcement learning and then Yaakov will end with a nice demo about controlling an octopus arm.",
                    "label": 0
                },
                {
                    "sent": "OK, so Muhammad will come for the intro.",
                    "label": 0
                }
            ]
        }
    }
}