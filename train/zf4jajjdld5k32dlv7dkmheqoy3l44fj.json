{
    "id": "zf4jajjdld5k32dlv7dkmheqoy3l44fj",
    "title": "Graphical models",
    "info": {
        "author": [
            "Zoubin Ghahramani, Department of Engineering, University of Cambridge"
        ],
        "published": "Aug. 25, 2007",
        "recorded": "August 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Graphical Models"
        ]
    },
    "url": "http://videolectures.net/mlss07_ghahramani_grafm/",
    "segmentation": [
        [
            "He said we are very happy to have Zubin Ghahremani teacher calls about graphical models.",
            "Zubin is very well known.",
            "I don't really need to introduce him but nevertheless I had to ask him because I don't remember all the details about his career.",
            "So he did his PhD with Mike Gordon at MIT.",
            "He was a postdoc in Toronto.",
            "He then moved on to become a group leader at the Casper Institute.",
            "He was in charge problem machine learning part.",
            "You can't hear it.",
            "Nothing.",
            "How about now?",
            "Sorry yeah.",
            "Case I hope it works better with that with the other microphone or with somebody elses voice.",
            "So Zubin got his PhD at MIT.",
            "He was a postdoc in.",
            "Jeff Hinton's lap in Toronto.",
            "I guess differences that yeah he later on was a group leader in London, so I think it's the angle of the microphone.",
            "He was a group leader in London and the Gatsby Institute into since recently he's been appointed to a chair in Cambridge in the engineering Department.",
            "So we're very happy and looking forward to your post to win.",
            "I'll I'll try to.",
            "It's good, OK, you're you're my threshold so you know if I speak too low just let me know.",
            "OK, so?",
            "So I'm going to talk about graphical models and.",
            "I'm really excited to do this because I think.",
            "In the last decade or 15 years apart from kernel machines, the other thing that's really revolutionized machine learning is graphical models, so.",
            "How many people actually have studied graphical models formally in coursework before?",
            "OK, so a fair number of you I hope I don't bore everybody.",
            "It's about half of you.",
            "I think that have studied this.",
            "I'm sure the way I presented will be different from whatever you've heard, and repetition can't hurt anyway, right?",
            "Unless I confused."
        ],
        [
            "OK, so here's what we're going to do.",
            "We're going to talk about three main kinds of graphical models.",
            "In the first lecture, what I'm going to do is just introduce the models and talk about conditional independence relationships in these models.",
            "In the second lecture, I'm going to talk about propagation algorithms.",
            "Then I'm going to talk about learning parameters and learning structure in tomorrow's lectures, approximate inference, and then I'll sort of carry on with some other topics, and maybe talk a little bit about.",
            "Some research areas that we've been working on as well.",
            "OK, so.",
            "There are three main kinds of graphical models that are very commonly used these days.",
            "These are factor graphs that look like this undirected graphs that look like this and directed graphs that look like this.",
            "There are other kinds of graphical models I'll mention if you get really involved in this field, you'll realize that all of these models have some kind of some limitations, and so the search for.",
            "You know interesting representations is definitely very important.",
            "But what these models have in common is that their ways of representing joint probability distributions and the nodes in these graphical models correspond to random variables and the edges correspond to statistical dependencies between the variables.",
            "OK."
        ],
        [
            "So.",
            "Why do we need graphical models before I sort of go into all the formal descriptions and so on?",
            "Well, there are several reasons for this.",
            "First of all.",
            "Graphs are intuitive, they're just a nice pictorial way of representing and visualizing relationships between lots and lots of variables, and we're familiar with graphs from all sorts of other places, like, you know, we could draw family trees or electric circuit diagrams, or neural networks, connectivity diagrams, etc.",
            "Were just very good at interpreting the visual information in graphs.",
            "Um?",
            "But there are other reasons why graphical models are very important and useful.",
            "And in terms of representations, what graphical models allow us to do?",
            "Is they allow us to represent conditional independence relationships between variables?",
            "Without bothering with the details of the parametric forms of the probability distributions, so we're just representing the relationships between these variables, and that helps us answer questions like is a dependent on B.",
            "Given that we know the value of C. And we can answer these just by looking at the structure of the graph.",
            "Without having to know, you know what the probability distributions are.",
            "Um?",
            "And then computationally graphical models are incredibly useful because they allow us to define general message passing algorithms to implement probabilistic inference efficiently.",
            "So we can answer questions like what is the probability distribution over some variable a given that we know that the variable C takes on the value little C without enumerating all of the variables in our model, just by passing messages in our graph.",
            "So graphical models really borrow ideas from a few different fields.",
            "They're fundamentally statistical.",
            "Their representations of statistical dependencies.",
            "You obviously make use of some fairly elementary graph theory, and in terms of computer science, when you think of actually implementing algorithms for doing inference in probabilistic models, you make use of.",
            "Basic ideas in computer science to develop efficient algorithms, object oriented representations, etc.",
            "OK."
        ],
        [
            "So.",
            "The main thing graphical models do is represent conditional independence.",
            "So let me introduce some notation and let's just talk about the concept of conditional independence.",
            "So the notation is the following.",
            "We say that.",
            "X is conditionally independent from Y given V. That's the notation that we use.",
            "And this means that the probability of X given Y&V.",
            "Is not dependent on Y.",
            "In other words, the probability of X given Y&B is just equal to the probability of X given B.",
            "And this condition.",
            "Is just that the thing on the conditioning side can't be an impossibility.",
            "You shouldn't really condition on something that's impossible, so whenever PYNV is greater than strictly greater than 0.",
            "Another way to see conditional independence is.",
            "This follows the probability distribution.",
            "For X&Y.",
            "X&Y are conditionally independent given V If the joint probability between X&Y given B factors into the probability of X given V and the probability of Y given V. OK, so it's the usual notion of independence or marginal independence, which I have down here, except that we've conditioned on having observed the value of some variables, the variable V. And in general, we can think of conditional independence relationships between sets of variables.",
            "So if we write down the set, X is conditionally independent from the set Y given the set V. What we mean by that is that for all variables X in the set X an all variables.",
            "Why in the set Curly?",
            "Why these are independent given the entire set V having observed all of the variables in V?",
            "Now the traditional independence that we all learn about in elementary probability, we're going to call marginal independence, and that's just conditional independence condition on nothing condition on not observing anything.",
            "So I've represented that as the empty set here, and that just says the probability of X&Y factors into the probability of X times the probability of Y."
        ],
        [
            "So here are some examples of things we might think about as being.",
            "You know satisfying conditional independence relationships.",
            "Hopefully if you get a speeding fine, the amount of your speeding fine is independent of the type of car that you're driving.",
            "Given the speed that you were driving, right, the policeman shouldn't really penalize you for driving a Porsche or something like that.",
            "Obviously these things are not.",
            "You know they're not marginally independent because presumably some some types of cars drive faster than other types of cars, and so you know if you just measured types of cars and amounts of speeding fines, you would find some dependencies, but they should be conditionally independent given speed.",
            "Now we know that smoking causes both.",
            "You know your teeth to get yellow, an lung cancer.",
            "But given that you smoke, presumably in fairly simplistic model of the world where you don't do other things that turn your teeth, yellow lung cancer is independent of yellow teeth.",
            "Given smoking, if you're modeling an object, this could be, for example, modeling the movement of objects in a video or modeling.",
            "Some robotic joints or something like that.",
            "If you measure the position and velocity of that object at time T + 1 and it's following some sort of Newtonian dynamics, and you measure the position of velocity at time T -- 1, then these two things would presume are conditionally independent given the position and velocity at time T and the acceleration at time T. Um?",
            "If you measure child jeans, then those should be independent of the grandparents genes.",
            "Given the parents genes.",
            "If you have some competition with lots of different teams.",
            "Then presumably.",
            "As long as the teams are taking players from a very large pool, the ability of some team you pick it random is independent of the ability of another team you would pick at random from that pool teams.",
            "That's the marginal independence.",
            "So think of like a.",
            "You know some sort of big League, but now it's not the case that the ability of team A is independent of the ability of Team B.",
            "If we actually know the outcome of the game between A&B.",
            "OK so I just wanted to have one example of something where.",
            "Conditioned on some knowledge which we presume is actually a function of these two things, then those two things that were marginally independent are no longer independent.",
            "Conditioned on that knowledge, OK?",
            "So any questions about that?",
            "OK, so we're trying to represent conditional independence between variable."
        ],
        [
            "And let's start out with factor graphs.",
            "Although these are sort of the most the most modern one, they're nice and easy to understand.",
            "So in a factor graph we have two types of nodes.",
            "We have the circles that represent the random variables, like for example A and then we have filled dots that represent factors in the joint distribution.",
            "So for example, there's this build dot here connecting A&C and that represents a factor in this joint distribution of fact by factor.",
            "I just mean non negative function of its arguments.",
            "An essentially what a factor graph represents is a factorization of a joint probability distribution.",
            "So factor graph A here represents the probability solution of ABCD and E factors into the product of a distribution over A&C.",
            "A distribution over sorry not a distribution.",
            "A non negative function between A&C.",
            "A non negative function of BC&D and a non negative function of CD and E. OK, and this term here is simply a normalization constant.",
            "So that when you multiply these three non negative functions you get something that integrates or sums to one.",
            "So.",
            "That was for graph A here, for graph B we are representing a slightly different factorization, which I've written down here.",
            "And just to drive the point home, Zed is a normalization constant.",
            "In other words, in this probability distribution represented by the factor graph A, if all variables are discrete and take on values in sets ABCD and E corresponding to the names of those variables, then that normalization function is just the sum over all possible values of ABCD and E of the product of these factors.",
            "We're going to define two nodes to be neighbors if they share a common factor.",
            "OK, so for example, A&C are neighbors."
        ],
        [
            "OK.",
            "So.",
            "At the top I've just rewritten stuff that I had on the previous slide and now let's think about what the factor graph represents in terms of conditional independence relationships between the variables.",
            "So remember, 2 nodes are neighbors if they share a common factor.",
            "And we're going to define a path to be a sequence of neighboring nodes.",
            "So for example, a CB is a path.",
            "And here's a fact.",
            "X is independent of Y given the set V if every path between X&Y contains contains some node in the set V. OK, so just by looking at the factor graph and knowing that the factor graph corresponds to some factorization of the joint probability distribution, we can say all sorts of things about which variables are independent of which other variables.",
            "Um?",
            "A corollary of this fact.",
            "Which is fairly trivial.",
            "Is that given the neighbors of X the variable X is conditionally independent of all other variables which we can write out as X is independent of Y given the neighbors of X for all Y that aren't X and the neighbors of X. Alright, and that's pretty clear, because if this is true, then every path between X and something else has to go through one of its neighbors.",
            "Right?",
            "OK.",
            "So how do we show a statement like this?",
            "Uh.",
            "Remember, we started out with with the fact that this graph represents that the probability distribution factors in a particular way.",
            "And from that we're making grand claims about conditional."
        ],
        [
            "Dependence?",
            "OK, so.",
            "Let's take a look at the following conditional independence.",
            "Let's just say X is conditionally independent from Y given V that corresponds to this statement.",
            "That's one way of writing that statement.",
            "OK, now assume we have the following factorization.",
            "Let's say the joint distribution of XY&V can be written as the product of a factor between X&V and a factor between Y&V and some normalization constant said OK.",
            "So this is what we're going to start out with.",
            "Now take this equation here an sum this over X. OK, so we sum both sides of this equation over X.",
            "On the left hand side we get the joint distribution over Y&V.",
            "Um?",
            "Since we've summed over X and that has to sum to one.",
            "Right?",
            "On the right hand side, the normalization constant comes out and we get some.",
            "Thing here where we've summed over X, we can basically bring this summation.",
            "Inside he ran just some G 1 / X. Alright.",
            "Now.",
            "Take.",
            "Equation 2 and divide it by equation 3.",
            "On the left hand side, what you get is the joint probability of XY and V divided by the probability of Y&V, and we know that that.",
            "By the definition of conditional probability, that's just the probability of X given Y&V.",
            "That's just dividing this by this.",
            "And now on the right hand side, when we divide this by this, what do we get when we get 1 / Z cancelling?",
            "We get this factor G2 cancelling.",
            "And so we get this expression here.",
            "So what was the point of all that?",
            "Well, the interesting thing about that expression is that the right hand side of this expression is no longer functionally dependent on Y.",
            "Right?",
            "This doesn't depend on Y, and from that it follows that.",
            "X is independent of Y given V. OK, so this thing here.",
            "Just.",
            "No longer depends on why and so.",
            "We can.",
            "Basically, define that to be the probability of X given V. And if we were to compute the probability of X given B directly, we could.",
            "We could derive this equation as well from that.",
            "And therefore the factorization we had in equation 2 implies the conditional independence in this statement one.",
            "Alright, this is how we generally get from factorizations of probability distributions to statements about conditional independence, and we can apply this simple logical argument to basically prove essentially all of the claims.",
            "I'm going to make about conditional independence for factor graphs, directed graphs, undirected graphs, etc.",
            "It's the same kind of reasoning.",
            "OK, like we did in the previous slide."
        ],
        [
            "Alright.",
            "So that was factor graphs.",
            "Let me now talk about undirected graphical models, which are older but very similar to factor graphs.",
            "So in an undirected graphical model, the joint probability overall variables can be written in a factored form.",
            "So we say the joint probability of all variables I'm going to represent that as a vector X going from X1 through XK.",
            "Is some normalization constant times the product over JA factors GJ where each factor is just the function of some subset CJ of the set of all variables one through K?",
            "So CJ are subsets of the set of all variables and the notation X with the with the subscript.",
            "That's one of these subsets, is just think of it as the vector of all the X is that belong in that subset S. OK, so that's what X up CJ means.",
            "So here's how you specify a graph, an undirected graph, starting from the knowledge that your joint probability distribution factors in this way.",
            "You create a node for each variable and then you connect nodes INK.",
            "If they exist.",
            "Sorry if there exist some set CJ such that both.",
            "I, as in CJ&K as in CJ.",
            "In other words, if INK participate in common factor, you connect them directly to each other.",
            "So an undirected graphical model doesn't have two kinds of nodes, it's just you know like we saw in the first slide, just the nodes with undirected links between them.",
            "Now all of the variables in some subset will be connected to each other, so all the variables in some subset CJ.",
            "For example, we connected to each other and that means that these sets form cliques of the graph.",
            "In other words, they form fully connected subgraphs of the whole graph.",
            "Now undirected graphical models are also called Markov networks.",
            "You'll hear that term.",
            "Markov got his name associated with too many things, I think, so let's call them undirected graphical models, 'cause they're more descriptive than Markov networks."
        ],
        [
            "So here is an undirected graphical model.",
            "The the undirected graph here basically asserts that the joint probability of these variables factors into the product of a function of this clique AC.",
            "That's a fully connected sub graph.",
            "This clique BCD another fully direct connected subgraphs an the clique CDE.",
            "And again we have similar statements which we can prove in exactly the same way as before.",
            "We can prove that X is independent of Y given the set V if every path between X&Y contains some node in V. Again, we have a corollary of that which is given the neighbors of X, the variable X is conditionally independent of all other variables.",
            "And a few other useful definitions are the idea of a Markov blanket.",
            "The Set V is a Markov blanket for X if it only if.",
            "Given VX is independent of all Y not in X&V is kind of a blanket that protects X from the rest of the variables.",
            "Markov boundary is the minimal such Markov blanket, and that's just the neighbors of X in an undirected graph for affective graph.",
            "OK. Any questions about this?",
            "Yep.",
            "No, the question was is the factor graph equivalent to an undirected graphical model?",
            "I'll mention how they are slightly different.",
            "Yep.",
            "The the question is, is a Markov blanket the same as a clique?",
            "The Markov blanket is just defined to be the set of variables that make some variable independent of everything else.",
            "So for example, for the variable E. Um?",
            "C&D is the Markov blanket, so it's relative to the variable E, whereas a clique is just any foot fully connected sub graph, but also BC and D is a Markov blanket for E. It's just not a minimal Markov blanket.",
            "It's not a Markov boundary.",
            "The minimum markup blanket for the node is the clique.",
            "It's a little more complicated because, OK, it's not quite right.",
            "Statement consider the variables.",
            "See the minimal Markov blanket for C. In other words, the Markov boundary for C is a BD&E, which isn't any clique any particular clique, so that was the question.",
            "It's not not quite right, OK?"
        ],
        [
            "So let's compare undirected graphs and factor graphs.",
            "That was exactly your question.",
            "Consider the following three graphs.",
            "The nodes in these three graphs have exactly the same neighbors, right?",
            "Therefore, these three graphs represent exactly the same conditional independence relationships.",
            "But they're actually slightly different, so see in particular, sorry, not the node.",
            "See, but this graph C. Also represents the fact that the probability factors into a product of pairwise functions of the variables.",
            "OK.",
            "So a factor graph is a little more expressive than an undirected graph because it tells you how the cliques can factor.",
            "You know within themselves into products of functions.",
            "So consider the case where each of the variables is discrete and can take on K possible values.",
            "Then the functions and A&B are tables with order K. Cube sells OK, so consider for example the factor involving the variables BC&D.",
            "That's a function of these three variables.",
            "Each of them can take K values, so a function of three variables, each of which can take K values, can be represented as a kabi kabi K table, right so?",
            "That's a table with order K cubed cells in it, whereas here all of the tables have order K squared cells in them.",
            "OK, Yep.",
            "OK, so the question was in this graph, does it make sense to connect C&D with an extra factor involving those two?",
            "You can do that, but that factor can be absorbed by one of these two factors.",
            "It's just then not a very minimal representation of the factorization.",
            "But sometimes it's convenient if you want to represent your probability distribution in terms of specific function.",
            "Yep, question.",
            "That's right, so this last probability, sorry this last factor graph, represents a more constrained subspace of all possible probability distributions over these five variables.",
            "And you can think of all conditional independence relationships as representing subspaces of the space of possible probability distributions.",
            "OK, it's more constrained, but that also means that it takes fewer parameters to represent it.",
            "OK."
        ],
        [
            "So why?",
            "Why do we need anything other than undirected graphs and factor graphs?",
            "Well undirected graphs and factor graphs.",
            "Have a lot of nice properties, but a lot of useful independence relationships are unrepresented in these graphs.",
            "In other words, it's not actually possible to represent.",
            "All conceivable sets of independence relationships, and in fact a lot of very natural independence relationships.",
            "It's impossible to represent in undirected graphs an factor graph.",
            "So.",
            "The Canonical example of this, which we can reproduce in a graph with three nodes, is that two variables have to be connected in an undirected graph or factor graph merely because some other variable depends on them.",
            "And the example that everybody uses of this is due to Udaya Pearl, who is a real pioneer in the area of graphical models and his.",
            "His book is an excellent source for knowledge about graphical models you did at Pearl lives in California.",
            "And.",
            "Here is a sort of scenario you could imagine happening in California.",
            "The.",
            "You come home and you observe that the ground is wet.",
            "OK, like outside your house.",
            "You find that your lawn is wet or the ground is wet.",
            "Now you can infer two things.",
            "One of them is that while you were at work and not paying attention, it actually rained so rain can cause the ground to be wet.",
            "The other possibility is that your sprinkler came on and you know sprinkled water all over all over the ground.",
            "OK, so.",
            "Rain and sprinkler.",
            "We're going to assume are independent.",
            "In other words, what time the sprinkler comes on is independent of whether it rained or not.",
            "It's not a very intelligent sprinkler, it just goes on some sort of timer, let's say.",
            "But whether the ground is wet is dependent both on rain and sprinkler.",
            "Now the following graph, which is a directed graph and I'll talk about directed graphs in a minute, is a very natural way of representing the relationship between these variables.",
            "We're saying that essentially what this graph says is that rain and sprinkler are marginally independent.",
            "But there's some other variable ground being wet, which is dependent on rain and sprinkler.",
            "OK, now how do we represent this as a an undirected graph or a factor graph?",
            "Well as an undirected graph.",
            "Because the ground being wet depends on rain and sprinkler.",
            "There is a factor that involves all three of these variables, and so we would have to connect all of them together.",
            "And as a factor graph, we would just put a dot here and would connect all three of these things together.",
            "Now the problem with that is that all of the possible causes of some.",
            "Affect variable have to be connected to each other to represent the conditional independence relationships correctly.",
            "And that's really unsatisfactory, so you could imagine.",
            "Some variables might have many, many different causes, all of which are independent.",
            "But when you draw it as a graph, you draw all of these connections between them and that really doesn't represent the fact that those variables are marginally independent.",
            "So the truth of the situation is that rain and sprinkler are marginally independent.",
            "I given nothing.",
            "They are independent, but they are conditionally dependent given the variable G that the ground is wet.",
            "And those.",
            "Two things cannot be represented by any undirected graph or factor graph over these three variables.",
            "So.",
            "Let me just try to.",
            "Explain why is there a chalk here or should I use?",
            "Oh in the drawer.",
            "I can use this actually.",
            "Haha it's in a box.",
            "It doesn't look like chalk when it's in a box.",
            "Alright.",
            "So.",
            "Let's try to do this, let's say.",
            "Rain.",
            "And ground.",
            "And sprinkler well, what does this represent?",
            "This represents?",
            "That rain and sprinkler are dependent.",
            "Because there's a path between them.",
            "Which is wrong.",
            "And it represents something else that's wrong.",
            "That, given that the ground is wet, rain and sprinkler are independent.",
            "So this is, this is not a right.",
            "The correct probability distribution.",
            "And now if we add in.",
            "An edge here, then again, Rainan sprinkler become dependent.",
            "Marginally, which is also incorrect, so there's nothing I can do to represent these simple sets of dependencies that arise very naturally from causal relationships between cause variables and effect variables.",
            "Now there's another interesting aspect of graphs like this.",
            "These particular structures exhibit something called explaining away.",
            "Which is.",
            "Imagine that we observe that the ground is wet.",
            "Now there are two possible explanations under this model, either if both of these are rained, either it rained or the sprinkler was on, or with some very small probability.",
            "Both both rained and the sprinkler was on.",
            "OK, so we have to think of all the possible explanations for the ground being wet.",
            "Now if we look at the weather report and we find that in fact it did rain.",
            "Knowing this variable explains away the observations that the ground was wet and therefore we don't need to infer that the sprinkler was on.",
            "So these two variables by having a common child.",
            "Um?",
            "Become dependent on each other in this particular way.",
            "Once we observe that common child OK. Short way of saying that is that observing that the sprinkler is on would explain away the observation of the ground was wet, making it less probable that it rained."
        ],
        [
            "OK.",
            "So.",
            "Let's move on to directed graphical models or directed acyclic graphs.",
            "These are sometimes called Bayesian networks, but I also think this isn't a great name for them.",
            "In particular, I have a footnote here which says Bayesian networks can often R learned using non Bayesian.",
            "In other words, frequentist methods.",
            "And.",
            "Bayesian networks there's nothing about Bayesian networks that require parameter structure.",
            "Learning to use Bayesian methods, and if you look in UDF pearls book, he doesn't actually use Bayesian methods for the most part for learning Bayesian network.",
            "So let's just call them more descriptively.",
            "We can just call them directed graphical models or directed acyclic graphs.",
            "And a directed acyclic graph.",
            "Corresponds to a factorization of the joint probability distribution in the following way.",
            "We say that if we have this graph, that means that the joint probability of these variables factors into the probability distribution over a.",
            "Times the probability distribution over B.",
            "Times the probability distribution over C given A&BB given B&C an E given C&D.",
            "And in general, what we have is that the joint distribution factors into the product of the probability of each of the variables given its parents in the graph.",
            "So the parents of I are just the parents of no die.",
            "That's obviously the nodes that are at the tail end of the arrows that point through that OK."
        ],
        [
            "So.",
            "That's a directed graphical model and like undirected graphs an.",
            "And factor graphs.",
            "We can read off conditional independence relationships between the variables from the directed graph.",
            "Now it undirected graphs and factor graphs is really easy.",
            "We just looked at paths and we could tell whether things are conditionally independent or not.",
            "Now we have a slightly more complicated criterion which takes.",
            "You know an hour or so to get used to, but we don't have an arrow, so so I'll give you a slide and a few examples.",
            "Then you can work through it afterwards if you want so.",
            "X is conditionally independent from Y given this set of variables V if V dependencies separates that these separates X from Y.",
            "So think of essentially dependency flowing through the graph, and we're trying to see whether the set of variables V separates X from Y so that X&Y become independent when we observe the variables V. And here is the definition.",
            "Of the separation.",
            "The set VD separates X from Y if every undirected path that means path when we actually can go both along the arrows and backwards through the arrows.",
            "If every undirected path between X&V at sorry, X&Y is blocked by V, so that sounds a bit intuitive.",
            "Still, we're trying to think of Dependency's passing from X to Y, and if every path gets blocked by V then X&Y are independent of each other.",
            "So now let's look to see how dependency is blocked by Phi.",
            "A path is blocked by V if there's no W on the path.",
            "Such that it satisfies one of two conditions.",
            "The first condition is that W has converging arrows along the path.",
            "In other words.",
            "The path goes down to W and then up from W. And then neither W nor its descendants are observed.",
            "In other words, are in the set B. OK. That will block a path.",
            "Or if W does not have converging arrows along the path.",
            "So you go either right through W this way or that way.",
            "And W is observed.",
            "W is.",
            "In the set B.",
            "So.",
            "If that's the case.",
            "Then VD separates X from Y.",
            "And.",
            "The corollary of this is that we can find out what the Markov boundary of X is and the Markov boundary of X is the Union of the parents of X.",
            "The children of X and the parents of the children of X. OK, this is going to take a couple of minutes.",
            "How many people have encountered the separation before?",
            "OK, same people who've done graphical models.",
            "That's a good sign."
        ],
        [
            "Alright.",
            "So let's look at some examples of these separation.",
            "Again, just looking at this graph.",
            "Alright.",
            "Um?",
            "A is independent of.",
            "BAA is marginally independent of B conditioned on V being the empty set.",
            "Since.",
            "Let's look at every path between A&B.",
            "Since essentially the statement is, since all the paths between A&B are blocked OK.",
            "So.",
            "The path ACB.",
            "Is blocked by sea.",
            "Why is that?",
            "Well, let's look at this.",
            "See.",
            "Past converging arrows along the path right a CB.",
            "And neither see Nor's descendants are observed are in the set B.",
            "Remember, the set B is the empty set.",
            "OK, so see definitely blocks the path between A&B.",
            "The direct path between A&B.",
            "But now.",
            "We really need to look at all paths between A&B, so if we examine the path ACDBACDB then D blocks.",
            "The path between A&B along that path ACD because D has converging arrows and neither D nor its descendants are in the set V. Alright.",
            "So essentially.",
            "By examining these, we can tell that A&B are marginally independent.",
            "Let's look at another statement.",
            "It is not the case for this graph that a.",
            "Is independent of the givency.",
            "And let's consider that, well, a. CB is a path between.",
            "A&B and that path is not blocked.",
            "OK.",
            "So therefore dependency flows between A&B.",
            "You could think of it that way intuitively.",
            "Or intuitively, from our rain and sprinkler example, if you observe the effect.",
            "Of two independent causes.",
            "Then condition on that observation you know the costs become dependent on each other.",
            "Here's another intuitive way of doing that.",
            "If if I tell you I'm going to draw.",
            "Um?",
            "2 random numbers between one and 10 in dependently you know that those two variables are independent, right?",
            "But now if I tell you that the sum of those two variables is 7?",
            "Now, your inferences about the first variable will be highly dependent.",
            "On what you think about the second variable.",
            "OK, so although the two variables were marginally independent, conditioned on some common effect of those two variables, they become dependent.",
            "Alright, so we get the second statement.",
            "Now let's look at this third statement.",
            "A is independent of B.",
            "Given the set B&C.",
            "So, given B&CA is independent of D and essentially the way we show that as we look at all the paths between A&B and they are all blocked by something.",
            "OK, and I won't go through them in detail.",
            "You can check them afterwards.",
            "Here's another one.",
            "This is tricky.",
            "If I had asked you without showing it whether A is independent of B given East.",
            "You would have scratched your head a little bit, right?",
            "Um?",
            "Well, in fact.",
            "A is not independent of B given E because.",
            "Although he is not a direct.",
            "Affect of A&B.",
            "E is an indirect effect of A&B via C right?",
            "So observing E?",
            "Sort of makes you know something about C, and once you know something about C that causes dependency between A&B.",
            "OK, Yep.",
            "Right, the question is if you condition on C, It unblocks the flow from East up that way.",
            "Yeah, I mean if you condition on C, we're just thinking of different ways of conditioning on things.",
            "If we condition on C that causes the dependencies between A&B.",
            "But you know?",
            "It doesn't really solve anything for us, so we have to consider all of these cases.",
            "There are other ways of checking.",
            "These separation there is something called the baseball algorithm, which I have in the appendix of these slides.",
            "I'll post these slides to the website and that just in that you just imagine a ball flowing according to some rules to figure out what the dependencies are.",
            "OK."
        ],
        [
            "So.",
            "A couple more things and then we can take a break.",
            "So let's consider the special case of directed trees.",
            "So here we have a graph over 7 variables.",
            "I've just denoted them by their numbers X1 through X7, and this graph corresponds to the following joint factorization.",
            "Of the variables.",
            "Now each of these terms like X1 given X3, I can write as.",
            "You know X one.",
            "Sorry X1 and X3 probability X1 and X3 divided by the probability of X3.",
            "So I can rewrite this expression here as the product of all of these joint probabilities divided by all of these marginal probabilities.",
            "And.",
            "I can take that expression and I can just call each of these things factors.",
            "Making a factor graph or an undirected graph.",
            "These are all non negative functions.",
            "The factors involving one variable I can lump into any of the factors involving any of the factors involving that variable and other variables.",
            "So I can rewrite this.",
            "In several different ways as a product of factors like this.",
            "And what that corresponds to is a graph.",
            "An undirected graph where the structure is identical to the structure of the directed graph except that we throw away the directionality of the arrows.",
            "Alright, so any directed tree can be converted into an undirected tree representing the same conditional independence relationships and vice versa.",
            "OK. Haven't proven that, but I sort of just gave you an example of that.",
            "So in the case of trees they're representing kind of the same thing.",
            "But in other cases, in particular, when you have."
        ],
        [
            "You know structures like this?",
            "They represent very different things.",
            "In the directed case, will represent very different things.",
            "OK. Um?",
            "Something you'll see in a lot of papers is plate notation, so this is a shorthand for variables that repeat.",
            "So consider this directed graph representing a very simple statistical model.",
            "We have a mean and a variance defining a Gaussian distribution, and then we have N observations drawn from that Gaussian distribution.",
            "So rather than representing each of those observations.",
            "As a separate node in the graph, we can just write X sub N with an index little N and then put a plate which is this box usually dashed box with an index on that plate.",
            "That just means repeat this structure N times with the same connectivity.",
            "OK, this is incredibly useful.",
            "You'll see this in all sorts of papers if you haven't already, and that represents the following factorization of the probability distribution."
        ],
        [
            "Then now let's talk a little bit about the expressive power of directed undirected graphs.",
            "Um?",
            "We already know the the bottom thing that no undirected graph or factor graph can represent these and only these in dependencies represented by this graph.",
            "We already talked about that.",
            "You can show yourself that by just enumerating all the undirected graphs and checking.",
            "Here's a here's the converse statement.",
            "If we have an undirected graph that looks like this.",
            "No directed graph over those same four variables can represent these, and only these in dependencies.",
            "OK, why is that?",
            "Well?",
            "You have to check it, but essentially, what does this graph represent?",
            "This graph represents that, given this variable in this variable, this variable and that variable are independent.",
            "Conversely, given this variable in this variable, this and this are independent.",
            "But all the variables are marginally dependent on each other.",
            "OK, that's what that graph represents.",
            "And now no matter how we try to direct the arrows, there will always be 2 nonadjacent parents sharing a common child that causes dependence in the directed graph.",
            "But independence in the undirected graph and so.",
            "It's just not possible to represent it.",
            "And the general rule of thumb is that directed graphs are going to be much better at representing causal generative models, and undirected graphs are better at representing soft constraints between variables.",
            "OK."
        ],
        [
            "So here is just the summary.",
            "We talked about three kinds of graphical models directed, undirected and factor graphs.",
            "There are other important classes of graphical models like directed mixed graphs which I didn't talk about.",
            "We talked about marginal and conditional independence, Markov boundaries, D separation, differences between directed and undirected graphs, and then in the next lectures we're going to talk about exact inference and propagation, parameter and structure learning, approximate inference, and a bunch of other topics.",
            "OK, so let's take I think we can take a true take a break.",
            "Now it's usually.",
            "Yeah, like, let's take a 5 minute break or so.",
            "Stretch your legs.",
            "And then.",
            "We continue."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "He said we are very happy to have Zubin Ghahremani teacher calls about graphical models.",
                    "label": 0
                },
                {
                    "sent": "Zubin is very well known.",
                    "label": 0
                },
                {
                    "sent": "I don't really need to introduce him but nevertheless I had to ask him because I don't remember all the details about his career.",
                    "label": 0
                },
                {
                    "sent": "So he did his PhD with Mike Gordon at MIT.",
                    "label": 0
                },
                {
                    "sent": "He was a postdoc in Toronto.",
                    "label": 0
                },
                {
                    "sent": "He then moved on to become a group leader at the Casper Institute.",
                    "label": 0
                },
                {
                    "sent": "He was in charge problem machine learning part.",
                    "label": 1
                },
                {
                    "sent": "You can't hear it.",
                    "label": 0
                },
                {
                    "sent": "Nothing.",
                    "label": 0
                },
                {
                    "sent": "How about now?",
                    "label": 0
                },
                {
                    "sent": "Sorry yeah.",
                    "label": 0
                },
                {
                    "sent": "Case I hope it works better with that with the other microphone or with somebody elses voice.",
                    "label": 0
                },
                {
                    "sent": "So Zubin got his PhD at MIT.",
                    "label": 0
                },
                {
                    "sent": "He was a postdoc in.",
                    "label": 0
                },
                {
                    "sent": "Jeff Hinton's lap in Toronto.",
                    "label": 0
                },
                {
                    "sent": "I guess differences that yeah he later on was a group leader in London, so I think it's the angle of the microphone.",
                    "label": 0
                },
                {
                    "sent": "He was a group leader in London and the Gatsby Institute into since recently he's been appointed to a chair in Cambridge in the engineering Department.",
                    "label": 0
                },
                {
                    "sent": "So we're very happy and looking forward to your post to win.",
                    "label": 0
                },
                {
                    "sent": "I'll I'll try to.",
                    "label": 0
                },
                {
                    "sent": "It's good, OK, you're you're my threshold so you know if I speak too low just let me know.",
                    "label": 0
                },
                {
                    "sent": "OK, so?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to talk about graphical models and.",
                    "label": 0
                },
                {
                    "sent": "I'm really excited to do this because I think.",
                    "label": 0
                },
                {
                    "sent": "In the last decade or 15 years apart from kernel machines, the other thing that's really revolutionized machine learning is graphical models, so.",
                    "label": 1
                },
                {
                    "sent": "How many people actually have studied graphical models formally in coursework before?",
                    "label": 0
                },
                {
                    "sent": "OK, so a fair number of you I hope I don't bore everybody.",
                    "label": 0
                },
                {
                    "sent": "It's about half of you.",
                    "label": 0
                },
                {
                    "sent": "I think that have studied this.",
                    "label": 0
                },
                {
                    "sent": "I'm sure the way I presented will be different from whatever you've heard, and repetition can't hurt anyway, right?",
                    "label": 0
                },
                {
                    "sent": "Unless I confused.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's what we're going to do.",
                    "label": 0
                },
                {
                    "sent": "We're going to talk about three main kinds of graphical models.",
                    "label": 0
                },
                {
                    "sent": "In the first lecture, what I'm going to do is just introduce the models and talk about conditional independence relationships in these models.",
                    "label": 0
                },
                {
                    "sent": "In the second lecture, I'm going to talk about propagation algorithms.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to talk about learning parameters and learning structure in tomorrow's lectures, approximate inference, and then I'll sort of carry on with some other topics, and maybe talk a little bit about.",
                    "label": 0
                },
                {
                    "sent": "Some research areas that we've been working on as well.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "There are three main kinds of graphical models that are very commonly used these days.",
                    "label": 0
                },
                {
                    "sent": "These are factor graphs that look like this undirected graphs that look like this and directed graphs that look like this.",
                    "label": 0
                },
                {
                    "sent": "There are other kinds of graphical models I'll mention if you get really involved in this field, you'll realize that all of these models have some kind of some limitations, and so the search for.",
                    "label": 0
                },
                {
                    "sent": "You know interesting representations is definitely very important.",
                    "label": 0
                },
                {
                    "sent": "But what these models have in common is that their ways of representing joint probability distributions and the nodes in these graphical models correspond to random variables and the edges correspond to statistical dependencies between the variables.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Why do we need graphical models before I sort of go into all the formal descriptions and so on?",
                    "label": 0
                },
                {
                    "sent": "Well, there are several reasons for this.",
                    "label": 0
                },
                {
                    "sent": "First of all.",
                    "label": 0
                },
                {
                    "sent": "Graphs are intuitive, they're just a nice pictorial way of representing and visualizing relationships between lots and lots of variables, and we're familiar with graphs from all sorts of other places, like, you know, we could draw family trees or electric circuit diagrams, or neural networks, connectivity diagrams, etc.",
                    "label": 0
                },
                {
                    "sent": "Were just very good at interpreting the visual information in graphs.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But there are other reasons why graphical models are very important and useful.",
                    "label": 0
                },
                {
                    "sent": "And in terms of representations, what graphical models allow us to do?",
                    "label": 0
                },
                {
                    "sent": "Is they allow us to represent conditional independence relationships between variables?",
                    "label": 0
                },
                {
                    "sent": "Without bothering with the details of the parametric forms of the probability distributions, so we're just representing the relationships between these variables, and that helps us answer questions like is a dependent on B.",
                    "label": 0
                },
                {
                    "sent": "Given that we know the value of C. And we can answer these just by looking at the structure of the graph.",
                    "label": 0
                },
                {
                    "sent": "Without having to know, you know what the probability distributions are.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And then computationally graphical models are incredibly useful because they allow us to define general message passing algorithms to implement probabilistic inference efficiently.",
                    "label": 0
                },
                {
                    "sent": "So we can answer questions like what is the probability distribution over some variable a given that we know that the variable C takes on the value little C without enumerating all of the variables in our model, just by passing messages in our graph.",
                    "label": 0
                },
                {
                    "sent": "So graphical models really borrow ideas from a few different fields.",
                    "label": 1
                },
                {
                    "sent": "They're fundamentally statistical.",
                    "label": 0
                },
                {
                    "sent": "Their representations of statistical dependencies.",
                    "label": 1
                },
                {
                    "sent": "You obviously make use of some fairly elementary graph theory, and in terms of computer science, when you think of actually implementing algorithms for doing inference in probabilistic models, you make use of.",
                    "label": 0
                },
                {
                    "sent": "Basic ideas in computer science to develop efficient algorithms, object oriented representations, etc.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The main thing graphical models do is represent conditional independence.",
                    "label": 1
                },
                {
                    "sent": "So let me introduce some notation and let's just talk about the concept of conditional independence.",
                    "label": 0
                },
                {
                    "sent": "So the notation is the following.",
                    "label": 0
                },
                {
                    "sent": "We say that.",
                    "label": 1
                },
                {
                    "sent": "X is conditionally independent from Y given V. That's the notation that we use.",
                    "label": 0
                },
                {
                    "sent": "And this means that the probability of X given Y&V.",
                    "label": 0
                },
                {
                    "sent": "Is not dependent on Y.",
                    "label": 1
                },
                {
                    "sent": "In other words, the probability of X given Y&B is just equal to the probability of X given B.",
                    "label": 0
                },
                {
                    "sent": "And this condition.",
                    "label": 0
                },
                {
                    "sent": "Is just that the thing on the conditioning side can't be an impossibility.",
                    "label": 0
                },
                {
                    "sent": "You shouldn't really condition on something that's impossible, so whenever PYNV is greater than strictly greater than 0.",
                    "label": 0
                },
                {
                    "sent": "Another way to see conditional independence is.",
                    "label": 0
                },
                {
                    "sent": "This follows the probability distribution.",
                    "label": 0
                },
                {
                    "sent": "For X&Y.",
                    "label": 0
                },
                {
                    "sent": "X&Y are conditionally independent given V If the joint probability between X&Y given B factors into the probability of X given V and the probability of Y given V. OK, so it's the usual notion of independence or marginal independence, which I have down here, except that we've conditioned on having observed the value of some variables, the variable V. And in general, we can think of conditional independence relationships between sets of variables.",
                    "label": 1
                },
                {
                    "sent": "So if we write down the set, X is conditionally independent from the set Y given the set V. What we mean by that is that for all variables X in the set X an all variables.",
                    "label": 1
                },
                {
                    "sent": "Why in the set Curly?",
                    "label": 0
                },
                {
                    "sent": "Why these are independent given the entire set V having observed all of the variables in V?",
                    "label": 0
                },
                {
                    "sent": "Now the traditional independence that we all learn about in elementary probability, we're going to call marginal independence, and that's just conditional independence condition on nothing condition on not observing anything.",
                    "label": 0
                },
                {
                    "sent": "So I've represented that as the empty set here, and that just says the probability of X&Y factors into the probability of X times the probability of Y.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are some examples of things we might think about as being.",
                    "label": 0
                },
                {
                    "sent": "You know satisfying conditional independence relationships.",
                    "label": 1
                },
                {
                    "sent": "Hopefully if you get a speeding fine, the amount of your speeding fine is independent of the type of car that you're driving.",
                    "label": 0
                },
                {
                    "sent": "Given the speed that you were driving, right, the policeman shouldn't really penalize you for driving a Porsche or something like that.",
                    "label": 0
                },
                {
                    "sent": "Obviously these things are not.",
                    "label": 0
                },
                {
                    "sent": "You know they're not marginally independent because presumably some some types of cars drive faster than other types of cars, and so you know if you just measured types of cars and amounts of speeding fines, you would find some dependencies, but they should be conditionally independent given speed.",
                    "label": 0
                },
                {
                    "sent": "Now we know that smoking causes both.",
                    "label": 0
                },
                {
                    "sent": "You know your teeth to get yellow, an lung cancer.",
                    "label": 0
                },
                {
                    "sent": "But given that you smoke, presumably in fairly simplistic model of the world where you don't do other things that turn your teeth, yellow lung cancer is independent of yellow teeth.",
                    "label": 0
                },
                {
                    "sent": "Given smoking, if you're modeling an object, this could be, for example, modeling the movement of objects in a video or modeling.",
                    "label": 0
                },
                {
                    "sent": "Some robotic joints or something like that.",
                    "label": 0
                },
                {
                    "sent": "If you measure the position and velocity of that object at time T + 1 and it's following some sort of Newtonian dynamics, and you measure the position of velocity at time T -- 1, then these two things would presume are conditionally independent given the position and velocity at time T and the acceleration at time T. Um?",
                    "label": 0
                },
                {
                    "sent": "If you measure child jeans, then those should be independent of the grandparents genes.",
                    "label": 0
                },
                {
                    "sent": "Given the parents genes.",
                    "label": 0
                },
                {
                    "sent": "If you have some competition with lots of different teams.",
                    "label": 0
                },
                {
                    "sent": "Then presumably.",
                    "label": 0
                },
                {
                    "sent": "As long as the teams are taking players from a very large pool, the ability of some team you pick it random is independent of the ability of another team you would pick at random from that pool teams.",
                    "label": 0
                },
                {
                    "sent": "That's the marginal independence.",
                    "label": 0
                },
                {
                    "sent": "So think of like a.",
                    "label": 1
                },
                {
                    "sent": "You know some sort of big League, but now it's not the case that the ability of team A is independent of the ability of Team B.",
                    "label": 0
                },
                {
                    "sent": "If we actually know the outcome of the game between A&B.",
                    "label": 0
                },
                {
                    "sent": "OK so I just wanted to have one example of something where.",
                    "label": 0
                },
                {
                    "sent": "Conditioned on some knowledge which we presume is actually a function of these two things, then those two things that were marginally independent are no longer independent.",
                    "label": 0
                },
                {
                    "sent": "Conditioned on that knowledge, OK?",
                    "label": 0
                },
                {
                    "sent": "So any questions about that?",
                    "label": 0
                },
                {
                    "sent": "OK, so we're trying to represent conditional independence between variable.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And let's start out with factor graphs.",
                    "label": 0
                },
                {
                    "sent": "Although these are sort of the most the most modern one, they're nice and easy to understand.",
                    "label": 0
                },
                {
                    "sent": "So in a factor graph we have two types of nodes.",
                    "label": 0
                },
                {
                    "sent": "We have the circles that represent the random variables, like for example A and then we have filled dots that represent factors in the joint distribution.",
                    "label": 0
                },
                {
                    "sent": "So for example, there's this build dot here connecting A&C and that represents a factor in this joint distribution of fact by factor.",
                    "label": 0
                },
                {
                    "sent": "I just mean non negative function of its arguments.",
                    "label": 0
                },
                {
                    "sent": "An essentially what a factor graph represents is a factorization of a joint probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So factor graph A here represents the probability solution of ABCD and E factors into the product of a distribution over A&C.",
                    "label": 0
                },
                {
                    "sent": "A distribution over sorry not a distribution.",
                    "label": 0
                },
                {
                    "sent": "A non negative function between A&C.",
                    "label": 0
                },
                {
                    "sent": "A non negative function of BC&D and a non negative function of CD and E. OK, and this term here is simply a normalization constant.",
                    "label": 0
                },
                {
                    "sent": "So that when you multiply these three non negative functions you get something that integrates or sums to one.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That was for graph A here, for graph B we are representing a slightly different factorization, which I've written down here.",
                    "label": 0
                },
                {
                    "sent": "And just to drive the point home, Zed is a normalization constant.",
                    "label": 0
                },
                {
                    "sent": "In other words, in this probability distribution represented by the factor graph A, if all variables are discrete and take on values in sets ABCD and E corresponding to the names of those variables, then that normalization function is just the sum over all possible values of ABCD and E of the product of these factors.",
                    "label": 0
                },
                {
                    "sent": "We're going to define two nodes to be neighbors if they share a common factor.",
                    "label": 0
                },
                {
                    "sent": "OK, so for example, A&C are neighbors.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "At the top I've just rewritten stuff that I had on the previous slide and now let's think about what the factor graph represents in terms of conditional independence relationships between the variables.",
                    "label": 0
                },
                {
                    "sent": "So remember, 2 nodes are neighbors if they share a common factor.",
                    "label": 1
                },
                {
                    "sent": "And we're going to define a path to be a sequence of neighboring nodes.",
                    "label": 1
                },
                {
                    "sent": "So for example, a CB is a path.",
                    "label": 1
                },
                {
                    "sent": "And here's a fact.",
                    "label": 0
                },
                {
                    "sent": "X is independent of Y given the set V if every path between X&Y contains contains some node in the set V. OK, so just by looking at the factor graph and knowing that the factor graph corresponds to some factorization of the joint probability distribution, we can say all sorts of things about which variables are independent of which other variables.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "A corollary of this fact.",
                    "label": 0
                },
                {
                    "sent": "Which is fairly trivial.",
                    "label": 0
                },
                {
                    "sent": "Is that given the neighbors of X the variable X is conditionally independent of all other variables which we can write out as X is independent of Y given the neighbors of X for all Y that aren't X and the neighbors of X. Alright, and that's pretty clear, because if this is true, then every path between X and something else has to go through one of its neighbors.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So how do we show a statement like this?",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 1
                },
                {
                    "sent": "Remember, we started out with with the fact that this graph represents that the probability distribution factors in a particular way.",
                    "label": 0
                },
                {
                    "sent": "And from that we're making grand claims about conditional.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dependence?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Let's take a look at the following conditional independence.",
                    "label": 0
                },
                {
                    "sent": "Let's just say X is conditionally independent from Y given V that corresponds to this statement.",
                    "label": 1
                },
                {
                    "sent": "That's one way of writing that statement.",
                    "label": 0
                },
                {
                    "sent": "OK, now assume we have the following factorization.",
                    "label": 1
                },
                {
                    "sent": "Let's say the joint distribution of XY&V can be written as the product of a factor between X&V and a factor between Y&V and some normalization constant said OK.",
                    "label": 0
                },
                {
                    "sent": "So this is what we're going to start out with.",
                    "label": 0
                },
                {
                    "sent": "Now take this equation here an sum this over X. OK, so we sum both sides of this equation over X.",
                    "label": 0
                },
                {
                    "sent": "On the left hand side we get the joint distribution over Y&V.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Since we've summed over X and that has to sum to one.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "On the right hand side, the normalization constant comes out and we get some.",
                    "label": 0
                },
                {
                    "sent": "Thing here where we've summed over X, we can basically bring this summation.",
                    "label": 0
                },
                {
                    "sent": "Inside he ran just some G 1 / X. Alright.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Take.",
                    "label": 0
                },
                {
                    "sent": "Equation 2 and divide it by equation 3.",
                    "label": 0
                },
                {
                    "sent": "On the left hand side, what you get is the joint probability of XY and V divided by the probability of Y&V, and we know that that.",
                    "label": 0
                },
                {
                    "sent": "By the definition of conditional probability, that's just the probability of X given Y&V.",
                    "label": 0
                },
                {
                    "sent": "That's just dividing this by this.",
                    "label": 0
                },
                {
                    "sent": "And now on the right hand side, when we divide this by this, what do we get when we get 1 / Z cancelling?",
                    "label": 0
                },
                {
                    "sent": "We get this factor G2 cancelling.",
                    "label": 0
                },
                {
                    "sent": "And so we get this expression here.",
                    "label": 0
                },
                {
                    "sent": "So what was the point of all that?",
                    "label": 0
                },
                {
                    "sent": "Well, the interesting thing about that expression is that the right hand side of this expression is no longer functionally dependent on Y.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 1
                },
                {
                    "sent": "This doesn't depend on Y, and from that it follows that.",
                    "label": 0
                },
                {
                    "sent": "X is independent of Y given V. OK, so this thing here.",
                    "label": 0
                },
                {
                    "sent": "Just.",
                    "label": 0
                },
                {
                    "sent": "No longer depends on why and so.",
                    "label": 0
                },
                {
                    "sent": "We can.",
                    "label": 0
                },
                {
                    "sent": "Basically, define that to be the probability of X given V. And if we were to compute the probability of X given B directly, we could.",
                    "label": 0
                },
                {
                    "sent": "We could derive this equation as well from that.",
                    "label": 0
                },
                {
                    "sent": "And therefore the factorization we had in equation 2 implies the conditional independence in this statement one.",
                    "label": 0
                },
                {
                    "sent": "Alright, this is how we generally get from factorizations of probability distributions to statements about conditional independence, and we can apply this simple logical argument to basically prove essentially all of the claims.",
                    "label": 0
                },
                {
                    "sent": "I'm going to make about conditional independence for factor graphs, directed graphs, undirected graphs, etc.",
                    "label": 0
                },
                {
                    "sent": "It's the same kind of reasoning.",
                    "label": 0
                },
                {
                    "sent": "OK, like we did in the previous slide.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So that was factor graphs.",
                    "label": 0
                },
                {
                    "sent": "Let me now talk about undirected graphical models, which are older but very similar to factor graphs.",
                    "label": 0
                },
                {
                    "sent": "So in an undirected graphical model, the joint probability overall variables can be written in a factored form.",
                    "label": 0
                },
                {
                    "sent": "So we say the joint probability of all variables I'm going to represent that as a vector X going from X1 through XK.",
                    "label": 0
                },
                {
                    "sent": "Is some normalization constant times the product over JA factors GJ where each factor is just the function of some subset CJ of the set of all variables one through K?",
                    "label": 0
                },
                {
                    "sent": "So CJ are subsets of the set of all variables and the notation X with the with the subscript.",
                    "label": 0
                },
                {
                    "sent": "That's one of these subsets, is just think of it as the vector of all the X is that belong in that subset S. OK, so that's what X up CJ means.",
                    "label": 0
                },
                {
                    "sent": "So here's how you specify a graph, an undirected graph, starting from the knowledge that your joint probability distribution factors in this way.",
                    "label": 0
                },
                {
                    "sent": "You create a node for each variable and then you connect nodes INK.",
                    "label": 0
                },
                {
                    "sent": "If they exist.",
                    "label": 0
                },
                {
                    "sent": "Sorry if there exist some set CJ such that both.",
                    "label": 0
                },
                {
                    "sent": "I, as in CJ&K as in CJ.",
                    "label": 0
                },
                {
                    "sent": "In other words, if INK participate in common factor, you connect them directly to each other.",
                    "label": 0
                },
                {
                    "sent": "So an undirected graphical model doesn't have two kinds of nodes, it's just you know like we saw in the first slide, just the nodes with undirected links between them.",
                    "label": 0
                },
                {
                    "sent": "Now all of the variables in some subset will be connected to each other, so all the variables in some subset CJ.",
                    "label": 0
                },
                {
                    "sent": "For example, we connected to each other and that means that these sets form cliques of the graph.",
                    "label": 0
                },
                {
                    "sent": "In other words, they form fully connected subgraphs of the whole graph.",
                    "label": 0
                },
                {
                    "sent": "Now undirected graphical models are also called Markov networks.",
                    "label": 0
                },
                {
                    "sent": "You'll hear that term.",
                    "label": 0
                },
                {
                    "sent": "Markov got his name associated with too many things, I think, so let's call them undirected graphical models, 'cause they're more descriptive than Markov networks.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is an undirected graphical model.",
                    "label": 1
                },
                {
                    "sent": "The the undirected graph here basically asserts that the joint probability of these variables factors into the product of a function of this clique AC.",
                    "label": 0
                },
                {
                    "sent": "That's a fully connected sub graph.",
                    "label": 0
                },
                {
                    "sent": "This clique BCD another fully direct connected subgraphs an the clique CDE.",
                    "label": 0
                },
                {
                    "sent": "And again we have similar statements which we can prove in exactly the same way as before.",
                    "label": 0
                },
                {
                    "sent": "We can prove that X is independent of Y given the set V if every path between X&Y contains some node in V. Again, we have a corollary of that which is given the neighbors of X, the variable X is conditionally independent of all other variables.",
                    "label": 0
                },
                {
                    "sent": "And a few other useful definitions are the idea of a Markov blanket.",
                    "label": 0
                },
                {
                    "sent": "The Set V is a Markov blanket for X if it only if.",
                    "label": 0
                },
                {
                    "sent": "Given VX is independent of all Y not in X&V is kind of a blanket that protects X from the rest of the variables.",
                    "label": 0
                },
                {
                    "sent": "Markov boundary is the minimal such Markov blanket, and that's just the neighbors of X in an undirected graph for affective graph.",
                    "label": 0
                },
                {
                    "sent": "OK. Any questions about this?",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "No, the question was is the factor graph equivalent to an undirected graphical model?",
                    "label": 0
                },
                {
                    "sent": "I'll mention how they are slightly different.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "The the question is, is a Markov blanket the same as a clique?",
                    "label": 1
                },
                {
                    "sent": "The Markov blanket is just defined to be the set of variables that make some variable independent of everything else.",
                    "label": 0
                },
                {
                    "sent": "So for example, for the variable E. Um?",
                    "label": 0
                },
                {
                    "sent": "C&D is the Markov blanket, so it's relative to the variable E, whereas a clique is just any foot fully connected sub graph, but also BC and D is a Markov blanket for E. It's just not a minimal Markov blanket.",
                    "label": 0
                },
                {
                    "sent": "It's not a Markov boundary.",
                    "label": 0
                },
                {
                    "sent": "The minimum markup blanket for the node is the clique.",
                    "label": 0
                },
                {
                    "sent": "It's a little more complicated because, OK, it's not quite right.",
                    "label": 0
                },
                {
                    "sent": "Statement consider the variables.",
                    "label": 0
                },
                {
                    "sent": "See the minimal Markov blanket for C. In other words, the Markov boundary for C is a BD&E, which isn't any clique any particular clique, so that was the question.",
                    "label": 0
                },
                {
                    "sent": "It's not not quite right, OK?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's compare undirected graphs and factor graphs.",
                    "label": 1
                },
                {
                    "sent": "That was exactly your question.",
                    "label": 0
                },
                {
                    "sent": "Consider the following three graphs.",
                    "label": 0
                },
                {
                    "sent": "The nodes in these three graphs have exactly the same neighbors, right?",
                    "label": 0
                },
                {
                    "sent": "Therefore, these three graphs represent exactly the same conditional independence relationships.",
                    "label": 0
                },
                {
                    "sent": "But they're actually slightly different, so see in particular, sorry, not the node.",
                    "label": 0
                },
                {
                    "sent": "See, but this graph C. Also represents the fact that the probability factors into a product of pairwise functions of the variables.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So a factor graph is a little more expressive than an undirected graph because it tells you how the cliques can factor.",
                    "label": 0
                },
                {
                    "sent": "You know within themselves into products of functions.",
                    "label": 0
                },
                {
                    "sent": "So consider the case where each of the variables is discrete and can take on K possible values.",
                    "label": 0
                },
                {
                    "sent": "Then the functions and A&B are tables with order K. Cube sells OK, so consider for example the factor involving the variables BC&D.",
                    "label": 0
                },
                {
                    "sent": "That's a function of these three variables.",
                    "label": 0
                },
                {
                    "sent": "Each of them can take K values, so a function of three variables, each of which can take K values, can be represented as a kabi kabi K table, right so?",
                    "label": 0
                },
                {
                    "sent": "That's a table with order K cubed cells in it, whereas here all of the tables have order K squared cells in them.",
                    "label": 0
                },
                {
                    "sent": "OK, Yep.",
                    "label": 0
                },
                {
                    "sent": "OK, so the question was in this graph, does it make sense to connect C&D with an extra factor involving those two?",
                    "label": 0
                },
                {
                    "sent": "You can do that, but that factor can be absorbed by one of these two factors.",
                    "label": 0
                },
                {
                    "sent": "It's just then not a very minimal representation of the factorization.",
                    "label": 0
                },
                {
                    "sent": "But sometimes it's convenient if you want to represent your probability distribution in terms of specific function.",
                    "label": 0
                },
                {
                    "sent": "Yep, question.",
                    "label": 0
                },
                {
                    "sent": "That's right, so this last probability, sorry this last factor graph, represents a more constrained subspace of all possible probability distributions over these five variables.",
                    "label": 1
                },
                {
                    "sent": "And you can think of all conditional independence relationships as representing subspaces of the space of possible probability distributions.",
                    "label": 0
                },
                {
                    "sent": "OK, it's more constrained, but that also means that it takes fewer parameters to represent it.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why?",
                    "label": 0
                },
                {
                    "sent": "Why do we need anything other than undirected graphs and factor graphs?",
                    "label": 0
                },
                {
                    "sent": "Well undirected graphs and factor graphs.",
                    "label": 1
                },
                {
                    "sent": "Have a lot of nice properties, but a lot of useful independence relationships are unrepresented in these graphs.",
                    "label": 0
                },
                {
                    "sent": "In other words, it's not actually possible to represent.",
                    "label": 0
                },
                {
                    "sent": "All conceivable sets of independence relationships, and in fact a lot of very natural independence relationships.",
                    "label": 0
                },
                {
                    "sent": "It's impossible to represent in undirected graphs an factor graph.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The Canonical example of this, which we can reproduce in a graph with three nodes, is that two variables have to be connected in an undirected graph or factor graph merely because some other variable depends on them.",
                    "label": 0
                },
                {
                    "sent": "And the example that everybody uses of this is due to Udaya Pearl, who is a real pioneer in the area of graphical models and his.",
                    "label": 1
                },
                {
                    "sent": "His book is an excellent source for knowledge about graphical models you did at Pearl lives in California.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Here is a sort of scenario you could imagine happening in California.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "You come home and you observe that the ground is wet.",
                    "label": 0
                },
                {
                    "sent": "OK, like outside your house.",
                    "label": 0
                },
                {
                    "sent": "You find that your lawn is wet or the ground is wet.",
                    "label": 0
                },
                {
                    "sent": "Now you can infer two things.",
                    "label": 0
                },
                {
                    "sent": "One of them is that while you were at work and not paying attention, it actually rained so rain can cause the ground to be wet.",
                    "label": 0
                },
                {
                    "sent": "The other possibility is that your sprinkler came on and you know sprinkled water all over all over the ground.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Rain and sprinkler.",
                    "label": 0
                },
                {
                    "sent": "We're going to assume are independent.",
                    "label": 0
                },
                {
                    "sent": "In other words, what time the sprinkler comes on is independent of whether it rained or not.",
                    "label": 0
                },
                {
                    "sent": "It's not a very intelligent sprinkler, it just goes on some sort of timer, let's say.",
                    "label": 0
                },
                {
                    "sent": "But whether the ground is wet is dependent both on rain and sprinkler.",
                    "label": 0
                },
                {
                    "sent": "Now the following graph, which is a directed graph and I'll talk about directed graphs in a minute, is a very natural way of representing the relationship between these variables.",
                    "label": 0
                },
                {
                    "sent": "We're saying that essentially what this graph says is that rain and sprinkler are marginally independent.",
                    "label": 0
                },
                {
                    "sent": "But there's some other variable ground being wet, which is dependent on rain and sprinkler.",
                    "label": 0
                },
                {
                    "sent": "OK, now how do we represent this as a an undirected graph or a factor graph?",
                    "label": 1
                },
                {
                    "sent": "Well as an undirected graph.",
                    "label": 0
                },
                {
                    "sent": "Because the ground being wet depends on rain and sprinkler.",
                    "label": 0
                },
                {
                    "sent": "There is a factor that involves all three of these variables, and so we would have to connect all of them together.",
                    "label": 0
                },
                {
                    "sent": "And as a factor graph, we would just put a dot here and would connect all three of these things together.",
                    "label": 0
                },
                {
                    "sent": "Now the problem with that is that all of the possible causes of some.",
                    "label": 0
                },
                {
                    "sent": "Affect variable have to be connected to each other to represent the conditional independence relationships correctly.",
                    "label": 0
                },
                {
                    "sent": "And that's really unsatisfactory, so you could imagine.",
                    "label": 0
                },
                {
                    "sent": "Some variables might have many, many different causes, all of which are independent.",
                    "label": 0
                },
                {
                    "sent": "But when you draw it as a graph, you draw all of these connections between them and that really doesn't represent the fact that those variables are marginally independent.",
                    "label": 0
                },
                {
                    "sent": "So the truth of the situation is that rain and sprinkler are marginally independent.",
                    "label": 0
                },
                {
                    "sent": "I given nothing.",
                    "label": 0
                },
                {
                    "sent": "They are independent, but they are conditionally dependent given the variable G that the ground is wet.",
                    "label": 0
                },
                {
                    "sent": "And those.",
                    "label": 0
                },
                {
                    "sent": "Two things cannot be represented by any undirected graph or factor graph over these three variables.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let me just try to.",
                    "label": 0
                },
                {
                    "sent": "Explain why is there a chalk here or should I use?",
                    "label": 1
                },
                {
                    "sent": "Oh in the drawer.",
                    "label": 1
                },
                {
                    "sent": "I can use this actually.",
                    "label": 0
                },
                {
                    "sent": "Haha it's in a box.",
                    "label": 0
                },
                {
                    "sent": "It doesn't look like chalk when it's in a box.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let's try to do this, let's say.",
                    "label": 0
                },
                {
                    "sent": "Rain.",
                    "label": 0
                },
                {
                    "sent": "And ground.",
                    "label": 0
                },
                {
                    "sent": "And sprinkler well, what does this represent?",
                    "label": 0
                },
                {
                    "sent": "This represents?",
                    "label": 0
                },
                {
                    "sent": "That rain and sprinkler are dependent.",
                    "label": 0
                },
                {
                    "sent": "Because there's a path between them.",
                    "label": 0
                },
                {
                    "sent": "Which is wrong.",
                    "label": 0
                },
                {
                    "sent": "And it represents something else that's wrong.",
                    "label": 0
                },
                {
                    "sent": "That, given that the ground is wet, rain and sprinkler are independent.",
                    "label": 0
                },
                {
                    "sent": "So this is, this is not a right.",
                    "label": 0
                },
                {
                    "sent": "The correct probability distribution.",
                    "label": 0
                },
                {
                    "sent": "And now if we add in.",
                    "label": 0
                },
                {
                    "sent": "An edge here, then again, Rainan sprinkler become dependent.",
                    "label": 0
                },
                {
                    "sent": "Marginally, which is also incorrect, so there's nothing I can do to represent these simple sets of dependencies that arise very naturally from causal relationships between cause variables and effect variables.",
                    "label": 0
                },
                {
                    "sent": "Now there's another interesting aspect of graphs like this.",
                    "label": 0
                },
                {
                    "sent": "These particular structures exhibit something called explaining away.",
                    "label": 0
                },
                {
                    "sent": "Which is.",
                    "label": 0
                },
                {
                    "sent": "Imagine that we observe that the ground is wet.",
                    "label": 0
                },
                {
                    "sent": "Now there are two possible explanations under this model, either if both of these are rained, either it rained or the sprinkler was on, or with some very small probability.",
                    "label": 0
                },
                {
                    "sent": "Both both rained and the sprinkler was on.",
                    "label": 1
                },
                {
                    "sent": "OK, so we have to think of all the possible explanations for the ground being wet.",
                    "label": 0
                },
                {
                    "sent": "Now if we look at the weather report and we find that in fact it did rain.",
                    "label": 0
                },
                {
                    "sent": "Knowing this variable explains away the observations that the ground was wet and therefore we don't need to infer that the sprinkler was on.",
                    "label": 0
                },
                {
                    "sent": "So these two variables by having a common child.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Become dependent on each other in this particular way.",
                    "label": 0
                },
                {
                    "sent": "Once we observe that common child OK. Short way of saying that is that observing that the sprinkler is on would explain away the observation of the ground was wet, making it less probable that it rained.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let's move on to directed graphical models or directed acyclic graphs.",
                    "label": 0
                },
                {
                    "sent": "These are sometimes called Bayesian networks, but I also think this isn't a great name for them.",
                    "label": 0
                },
                {
                    "sent": "In particular, I have a footnote here which says Bayesian networks can often R learned using non Bayesian.",
                    "label": 0
                },
                {
                    "sent": "In other words, frequentist methods.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Bayesian networks there's nothing about Bayesian networks that require parameter structure.",
                    "label": 0
                },
                {
                    "sent": "Learning to use Bayesian methods, and if you look in UDF pearls book, he doesn't actually use Bayesian methods for the most part for learning Bayesian network.",
                    "label": 0
                },
                {
                    "sent": "So let's just call them more descriptively.",
                    "label": 0
                },
                {
                    "sent": "We can just call them directed graphical models or directed acyclic graphs.",
                    "label": 0
                },
                {
                    "sent": "And a directed acyclic graph.",
                    "label": 0
                },
                {
                    "sent": "Corresponds to a factorization of the joint probability distribution in the following way.",
                    "label": 0
                },
                {
                    "sent": "We say that if we have this graph, that means that the joint probability of these variables factors into the probability distribution over a.",
                    "label": 0
                },
                {
                    "sent": "Times the probability distribution over B.",
                    "label": 0
                },
                {
                    "sent": "Times the probability distribution over C given A&BB given B&C an E given C&D.",
                    "label": 0
                },
                {
                    "sent": "And in general, what we have is that the joint distribution factors into the product of the probability of each of the variables given its parents in the graph.",
                    "label": 0
                },
                {
                    "sent": "So the parents of I are just the parents of no die.",
                    "label": 0
                },
                {
                    "sent": "That's obviously the nodes that are at the tail end of the arrows that point through that OK.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That's a directed graphical model and like undirected graphs an.",
                    "label": 0
                },
                {
                    "sent": "And factor graphs.",
                    "label": 0
                },
                {
                    "sent": "We can read off conditional independence relationships between the variables from the directed graph.",
                    "label": 0
                },
                {
                    "sent": "Now it undirected graphs and factor graphs is really easy.",
                    "label": 0
                },
                {
                    "sent": "We just looked at paths and we could tell whether things are conditionally independent or not.",
                    "label": 0
                },
                {
                    "sent": "Now we have a slightly more complicated criterion which takes.",
                    "label": 0
                },
                {
                    "sent": "You know an hour or so to get used to, but we don't have an arrow, so so I'll give you a slide and a few examples.",
                    "label": 0
                },
                {
                    "sent": "Then you can work through it afterwards if you want so.",
                    "label": 0
                },
                {
                    "sent": "X is conditionally independent from Y given this set of variables V if V dependencies separates that these separates X from Y.",
                    "label": 0
                },
                {
                    "sent": "So think of essentially dependency flowing through the graph, and we're trying to see whether the set of variables V separates X from Y so that X&Y become independent when we observe the variables V. And here is the definition.",
                    "label": 0
                },
                {
                    "sent": "Of the separation.",
                    "label": 0
                },
                {
                    "sent": "The set VD separates X from Y if every undirected path that means path when we actually can go both along the arrows and backwards through the arrows.",
                    "label": 0
                },
                {
                    "sent": "If every undirected path between X&V at sorry, X&Y is blocked by V, so that sounds a bit intuitive.",
                    "label": 0
                },
                {
                    "sent": "Still, we're trying to think of Dependency's passing from X to Y, and if every path gets blocked by V then X&Y are independent of each other.",
                    "label": 0
                },
                {
                    "sent": "So now let's look to see how dependency is blocked by Phi.",
                    "label": 0
                },
                {
                    "sent": "A path is blocked by V if there's no W on the path.",
                    "label": 0
                },
                {
                    "sent": "Such that it satisfies one of two conditions.",
                    "label": 0
                },
                {
                    "sent": "The first condition is that W has converging arrows along the path.",
                    "label": 0
                },
                {
                    "sent": "In other words.",
                    "label": 0
                },
                {
                    "sent": "The path goes down to W and then up from W. And then neither W nor its descendants are observed.",
                    "label": 0
                },
                {
                    "sent": "In other words, are in the set B. OK. That will block a path.",
                    "label": 0
                },
                {
                    "sent": "Or if W does not have converging arrows along the path.",
                    "label": 0
                },
                {
                    "sent": "So you go either right through W this way or that way.",
                    "label": 0
                },
                {
                    "sent": "And W is observed.",
                    "label": 0
                },
                {
                    "sent": "W is.",
                    "label": 0
                },
                {
                    "sent": "In the set B.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If that's the case.",
                    "label": 0
                },
                {
                    "sent": "Then VD separates X from Y.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The corollary of this is that we can find out what the Markov boundary of X is and the Markov boundary of X is the Union of the parents of X.",
                    "label": 0
                },
                {
                    "sent": "The children of X and the parents of the children of X. OK, this is going to take a couple of minutes.",
                    "label": 1
                },
                {
                    "sent": "How many people have encountered the separation before?",
                    "label": 1
                },
                {
                    "sent": "OK, same people who've done graphical models.",
                    "label": 0
                },
                {
                    "sent": "That's a good sign.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So let's look at some examples of these separation.",
                    "label": 0
                },
                {
                    "sent": "Again, just looking at this graph.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "A is independent of.",
                    "label": 0
                },
                {
                    "sent": "BAA is marginally independent of B conditioned on V being the empty set.",
                    "label": 0
                },
                {
                    "sent": "Since.",
                    "label": 0
                },
                {
                    "sent": "Let's look at every path between A&B.",
                    "label": 0
                },
                {
                    "sent": "Since essentially the statement is, since all the paths between A&B are blocked OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The path ACB.",
                    "label": 0
                },
                {
                    "sent": "Is blocked by sea.",
                    "label": 0
                },
                {
                    "sent": "Why is that?",
                    "label": 0
                },
                {
                    "sent": "Well, let's look at this.",
                    "label": 0
                },
                {
                    "sent": "See.",
                    "label": 0
                },
                {
                    "sent": "Past converging arrows along the path right a CB.",
                    "label": 1
                },
                {
                    "sent": "And neither see Nor's descendants are observed are in the set B.",
                    "label": 0
                },
                {
                    "sent": "Remember, the set B is the empty set.",
                    "label": 1
                },
                {
                    "sent": "OK, so see definitely blocks the path between A&B.",
                    "label": 0
                },
                {
                    "sent": "The direct path between A&B.",
                    "label": 0
                },
                {
                    "sent": "But now.",
                    "label": 0
                },
                {
                    "sent": "We really need to look at all paths between A&B, so if we examine the path ACDBACDB then D blocks.",
                    "label": 0
                },
                {
                    "sent": "The path between A&B along that path ACD because D has converging arrows and neither D nor its descendants are in the set V. Alright.",
                    "label": 1
                },
                {
                    "sent": "So essentially.",
                    "label": 0
                },
                {
                    "sent": "By examining these, we can tell that A&B are marginally independent.",
                    "label": 0
                },
                {
                    "sent": "Let's look at another statement.",
                    "label": 1
                },
                {
                    "sent": "It is not the case for this graph that a.",
                    "label": 1
                },
                {
                    "sent": "Is independent of the givency.",
                    "label": 0
                },
                {
                    "sent": "And let's consider that, well, a. CB is a path between.",
                    "label": 0
                },
                {
                    "sent": "A&B and that path is not blocked.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So therefore dependency flows between A&B.",
                    "label": 0
                },
                {
                    "sent": "You could think of it that way intuitively.",
                    "label": 0
                },
                {
                    "sent": "Or intuitively, from our rain and sprinkler example, if you observe the effect.",
                    "label": 0
                },
                {
                    "sent": "Of two independent causes.",
                    "label": 0
                },
                {
                    "sent": "Then condition on that observation you know the costs become dependent on each other.",
                    "label": 0
                },
                {
                    "sent": "Here's another intuitive way of doing that.",
                    "label": 0
                },
                {
                    "sent": "If if I tell you I'm going to draw.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "2 random numbers between one and 10 in dependently you know that those two variables are independent, right?",
                    "label": 0
                },
                {
                    "sent": "But now if I tell you that the sum of those two variables is 7?",
                    "label": 0
                },
                {
                    "sent": "Now, your inferences about the first variable will be highly dependent.",
                    "label": 0
                },
                {
                    "sent": "On what you think about the second variable.",
                    "label": 0
                },
                {
                    "sent": "OK, so although the two variables were marginally independent, conditioned on some common effect of those two variables, they become dependent.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we get the second statement.",
                    "label": 0
                },
                {
                    "sent": "Now let's look at this third statement.",
                    "label": 0
                },
                {
                    "sent": "A is independent of B.",
                    "label": 0
                },
                {
                    "sent": "Given the set B&C.",
                    "label": 0
                },
                {
                    "sent": "So, given B&CA is independent of D and essentially the way we show that as we look at all the paths between A&B and they are all blocked by something.",
                    "label": 0
                },
                {
                    "sent": "OK, and I won't go through them in detail.",
                    "label": 0
                },
                {
                    "sent": "You can check them afterwards.",
                    "label": 0
                },
                {
                    "sent": "Here's another one.",
                    "label": 0
                },
                {
                    "sent": "This is tricky.",
                    "label": 0
                },
                {
                    "sent": "If I had asked you without showing it whether A is independent of B given East.",
                    "label": 0
                },
                {
                    "sent": "You would have scratched your head a little bit, right?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Well, in fact.",
                    "label": 0
                },
                {
                    "sent": "A is not independent of B given E because.",
                    "label": 0
                },
                {
                    "sent": "Although he is not a direct.",
                    "label": 0
                },
                {
                    "sent": "Affect of A&B.",
                    "label": 0
                },
                {
                    "sent": "E is an indirect effect of A&B via C right?",
                    "label": 0
                },
                {
                    "sent": "So observing E?",
                    "label": 0
                },
                {
                    "sent": "Sort of makes you know something about C, and once you know something about C that causes dependency between A&B.",
                    "label": 0
                },
                {
                    "sent": "OK, Yep.",
                    "label": 0
                },
                {
                    "sent": "Right, the question is if you condition on C, It unblocks the flow from East up that way.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean if you condition on C, we're just thinking of different ways of conditioning on things.",
                    "label": 0
                },
                {
                    "sent": "If we condition on C that causes the dependencies between A&B.",
                    "label": 1
                },
                {
                    "sent": "But you know?",
                    "label": 0
                },
                {
                    "sent": "It doesn't really solve anything for us, so we have to consider all of these cases.",
                    "label": 0
                },
                {
                    "sent": "There are other ways of checking.",
                    "label": 0
                },
                {
                    "sent": "These separation there is something called the baseball algorithm, which I have in the appendix of these slides.",
                    "label": 0
                },
                {
                    "sent": "I'll post these slides to the website and that just in that you just imagine a ball flowing according to some rules to figure out what the dependencies are.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "A couple more things and then we can take a break.",
                    "label": 0
                },
                {
                    "sent": "So let's consider the special case of directed trees.",
                    "label": 0
                },
                {
                    "sent": "So here we have a graph over 7 variables.",
                    "label": 0
                },
                {
                    "sent": "I've just denoted them by their numbers X1 through X7, and this graph corresponds to the following joint factorization.",
                    "label": 0
                },
                {
                    "sent": "Of the variables.",
                    "label": 0
                },
                {
                    "sent": "Now each of these terms like X1 given X3, I can write as.",
                    "label": 0
                },
                {
                    "sent": "You know X one.",
                    "label": 0
                },
                {
                    "sent": "Sorry X1 and X3 probability X1 and X3 divided by the probability of X3.",
                    "label": 0
                },
                {
                    "sent": "So I can rewrite this expression here as the product of all of these joint probabilities divided by all of these marginal probabilities.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I can take that expression and I can just call each of these things factors.",
                    "label": 0
                },
                {
                    "sent": "Making a factor graph or an undirected graph.",
                    "label": 0
                },
                {
                    "sent": "These are all non negative functions.",
                    "label": 0
                },
                {
                    "sent": "The factors involving one variable I can lump into any of the factors involving any of the factors involving that variable and other variables.",
                    "label": 0
                },
                {
                    "sent": "So I can rewrite this.",
                    "label": 0
                },
                {
                    "sent": "In several different ways as a product of factors like this.",
                    "label": 0
                },
                {
                    "sent": "And what that corresponds to is a graph.",
                    "label": 0
                },
                {
                    "sent": "An undirected graph where the structure is identical to the structure of the directed graph except that we throw away the directionality of the arrows.",
                    "label": 0
                },
                {
                    "sent": "Alright, so any directed tree can be converted into an undirected tree representing the same conditional independence relationships and vice versa.",
                    "label": 0
                },
                {
                    "sent": "OK. Haven't proven that, but I sort of just gave you an example of that.",
                    "label": 0
                },
                {
                    "sent": "So in the case of trees they're representing kind of the same thing.",
                    "label": 0
                },
                {
                    "sent": "But in other cases, in particular, when you have.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know structures like this?",
                    "label": 0
                },
                {
                    "sent": "They represent very different things.",
                    "label": 0
                },
                {
                    "sent": "In the directed case, will represent very different things.",
                    "label": 0
                },
                {
                    "sent": "OK. Um?",
                    "label": 0
                },
                {
                    "sent": "Something you'll see in a lot of papers is plate notation, so this is a shorthand for variables that repeat.",
                    "label": 0
                },
                {
                    "sent": "So consider this directed graph representing a very simple statistical model.",
                    "label": 0
                },
                {
                    "sent": "We have a mean and a variance defining a Gaussian distribution, and then we have N observations drawn from that Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "So rather than representing each of those observations.",
                    "label": 0
                },
                {
                    "sent": "As a separate node in the graph, we can just write X sub N with an index little N and then put a plate which is this box usually dashed box with an index on that plate.",
                    "label": 0
                },
                {
                    "sent": "That just means repeat this structure N times with the same connectivity.",
                    "label": 0
                },
                {
                    "sent": "OK, this is incredibly useful.",
                    "label": 0
                },
                {
                    "sent": "You'll see this in all sorts of papers if you haven't already, and that represents the following factorization of the probability distribution.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then now let's talk a little bit about the expressive power of directed undirected graphs.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We already know the the bottom thing that no undirected graph or factor graph can represent these and only these in dependencies represented by this graph.",
                    "label": 0
                },
                {
                    "sent": "We already talked about that.",
                    "label": 0
                },
                {
                    "sent": "You can show yourself that by just enumerating all the undirected graphs and checking.",
                    "label": 0
                },
                {
                    "sent": "Here's a here's the converse statement.",
                    "label": 0
                },
                {
                    "sent": "If we have an undirected graph that looks like this.",
                    "label": 0
                },
                {
                    "sent": "No directed graph over those same four variables can represent these, and only these in dependencies.",
                    "label": 0
                },
                {
                    "sent": "OK, why is that?",
                    "label": 0
                },
                {
                    "sent": "Well?",
                    "label": 0
                },
                {
                    "sent": "You have to check it, but essentially, what does this graph represent?",
                    "label": 0
                },
                {
                    "sent": "This graph represents that, given this variable in this variable, this variable and that variable are independent.",
                    "label": 0
                },
                {
                    "sent": "Conversely, given this variable in this variable, this and this are independent.",
                    "label": 0
                },
                {
                    "sent": "But all the variables are marginally dependent on each other.",
                    "label": 0
                },
                {
                    "sent": "OK, that's what that graph represents.",
                    "label": 0
                },
                {
                    "sent": "And now no matter how we try to direct the arrows, there will always be 2 nonadjacent parents sharing a common child that causes dependence in the directed graph.",
                    "label": 0
                },
                {
                    "sent": "But independence in the undirected graph and so.",
                    "label": 0
                },
                {
                    "sent": "It's just not possible to represent it.",
                    "label": 0
                },
                {
                    "sent": "And the general rule of thumb is that directed graphs are going to be much better at representing causal generative models, and undirected graphs are better at representing soft constraints between variables.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is just the summary.",
                    "label": 0
                },
                {
                    "sent": "We talked about three kinds of graphical models directed, undirected and factor graphs.",
                    "label": 0
                },
                {
                    "sent": "There are other important classes of graphical models like directed mixed graphs which I didn't talk about.",
                    "label": 0
                },
                {
                    "sent": "We talked about marginal and conditional independence, Markov boundaries, D separation, differences between directed and undirected graphs, and then in the next lectures we're going to talk about exact inference and propagation, parameter and structure learning, approximate inference, and a bunch of other topics.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's take I think we can take a true take a break.",
                    "label": 0
                },
                {
                    "sent": "Now it's usually.",
                    "label": 0
                },
                {
                    "sent": "Yeah, like, let's take a 5 minute break or so.",
                    "label": 0
                },
                {
                    "sent": "Stretch your legs.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "We continue.",
                    "label": 0
                }
            ]
        }
    }
}