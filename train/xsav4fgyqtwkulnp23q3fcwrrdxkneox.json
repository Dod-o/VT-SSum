{
    "id": "xsav4fgyqtwkulnp23q3fcwrrdxkneox",
    "title": "Detecting Duplicate Web Documents using Clickthrough Data",
    "info": {
        "author": [
            "Filip Radlinski, Microsoft Canada"
        ],
        "published": "Aug. 9, 2011",
        "recorded": "February 2011",
        "category": [
            "Top->Computer Science->Web Search"
        ]
    },
    "url": "http://videolectures.net/wsdm2011_radlinski_duc/",
    "segmentation": [
        [
            "So this is joint work with Paul Benneth and Eminem."
        ],
        [
            "Yes.",
            "So this is a motivation near duplicates, and duplicates are very common on the web.",
            "We've all seen this in many cases, showing them isn't helpful.",
            "Sometimes it hurts, sometimes just not helpful.",
            "There's been a lot of work on detecting duplicate and very close to applicants, but these techniques are usually based on content.",
            "I'll give you a little bit more background in a moment, but in particular this means it's not sensitive to the query.",
            "A duplicate can be thought of in the context of the user's information need or their intent, and so it could be that two documents.",
            "Duplicate for some queries while being non duplicates for other queries and so that's the setting that we're thinking about here.",
            "So in particular, I'll show you how how clicks give you a more sensitive context dependent way of detecting duplication.",
            "So in this example here you see sort of the text test text twist query, which is a popular flash game you can play online and almost all these results show the same game, just in different wrappers.",
            "So the content on the content level the pages are completely different in terms of the user using them.",
            "There actually almost all of them are completely."
        ],
        [
            "Founded so previous approaches are usually based on fingerprints, so there are two general ways right.",
            "Either you couldn't take your your document generated complete fingerprint and then match these up and find exact duplicate or you can take us take a step by first looking at N grams to find a rough estimate of things that might be duplicated, as in a couple of passes to be more efficient and have a higher recall, have a higher precision and a higher recall.",
            "So that's that's where content duplication.",
            "Another way that duplicates have been removed is a post processing step.",
            "So you run a query and then you'll diversify the search results.",
            "You might say, OK, I'm going to reorder my list by relevant minus some amount of duplication going on, but even when this is reordering a query dependent set of documents, the metrics have in the past been query independent in the same way.",
            "So typical example of that might be the MMR algorithm of carbon Goldstein, so yeah.",
            "Like I say.",
            "So we gotta introduces this hypothesize redundancy score."
        ],
        [
            "So here's a typical search results page and we're going to be trying to workout whether document U&V are duplicates of each other in some sense.",
            "I'm so document you is going to have some some rate at which is clicked, so it might be clicked 70% of the time in this order document V might be click 20% of the time, so we have a click right on the top document and then click right on the second document and you can think of the fraction of clicks, the fraction of impressions for which the top document is clicked as a presentation bias.",
            "It's how often the user prefers number one and being observed observed that number one is clicked a lot more than #2 and so it's been thought that this is just.",
            "The bias in the presentation, but we're going to we're going to call that bias sub UV.",
            "So in the order of presentation."
        ],
        [
            "Movie.",
            "Now suppose sometimes we show the same pair of documents in the opposite order Vu.",
            "In this case, there's also a clickthrough rate.",
            "And there's also a bias or bias vu."
        ],
        [
            "And we're going to hypothesize that this redundancy score is the minimum of these two biases.",
            "So there are two possible orders of these documents, and.",
            "If in both presentation orders, the top thing is clicked, then we're going to have a high score.",
            "In other words, if there's an extreme presentation bias that the top result is always clicked, well, that's going to give us a high redundancy score, and vice versa if there exists an order.",
            "If in one of the two orders, the second document is clicked off and this minimum is going to be small.",
            "And so we're going to be looking at this redundancy score."
        ],
        [
            "So here's a hidden picture, right?",
            "So suppose you have two documents.",
            "In the grey documented number one it gets clicked.",
            "On the other case, when you present the red document first, it always gets clicked.",
            "The results are probably duplicate or or.",
            "Like I said, we might just be in a case for presentation bias is causing this problem."
        ],
        [
            "On the other hand, if one of the documents is clicked more often, if in the other order, the lower documents click.",
            "This redundancy score is going to be small.",
            "These are not going to be redundant at some level, and most as you expect we'd hope most documents."
        ],
        [
            "Somewhere in between.",
            "So how does this relate to the click skipping and fair pairs approaches that are skipped document followed by click document is a is a relevant signal.",
            "Right, so in the fair pairs algorithm you're randomizing the two documents randomizing the order, and you're seeing if one of the documents reliably is clicked more often when it's in the second position.",
            "And so both these approaches are saying a bottom click is a relevant signal, so you can tell which is more relevant based on the click of the bottom document in a pair.",
            "In this work, we're looking at the top click and we're going to see that the top click is a duplication signal, so nicely.",
            "Shows the other side."
        ],
        [
            "The coin, if you will so do pairs really exist with this.",
            "Different redundancy score.",
            "Is it a metric that makes any sense?",
            "So this is a sample of pairs of documents on a real web search engine.",
            "Admittedly somewhat biased sample, but as you see for a variety of redundancy scores we actually see pairs of documents that have these scores."
        ],
        [
            "What's interesting is if you then go in and you inspect some of these pairs of documents that are in the higher end of this range, what do you see?",
            "We actually see three different types of duplication that are happening on the web that are causing these scores to be high.",
            "First, their exact duplicates, we seen those, then there are content duplicates which are coming back to text twist example, something that in the context of the query the pages provide something that you've seen one seeing the other roughly as useful to me and the other one is not going to be so useful.",
            "I don't really care which one I get.",
            "And the third one really surprised us with the navigational duplicates.",
            "In other words, this is 2 documents that are just on the same site.",
            "One might be more relevant than the other, but users know their way around these sites, so they run this query.",
            "They don't really care which page they get to, they know their way, and they'll be there on the right site."
        ],
        [
            "So here's an example of navigation duplication, right?",
            "So the homepage of the Cambridge, UK local news and their entertainment section.",
            "The order you presented these doesn't really matter to users if they're searching for Cambridge News.",
            "They'll just navigate to the right one if they're at the wrong one, despite the fact that one of them might be more relevant for their query.",
            "Other typical examples we've seen in the literature bank home pages versus the login page of a bank.",
            "Yes, people prefer the login page, but they tend to be.",
            "They tend to exhibit some of these duplication or similar Amazon product similar eBay products.",
            "Users tend to more often than for non duplicate pairs.",
            "Click on the."
        ],
        [
            "Higher rank document.",
            "Here's the content.",
            "Deep example.",
            "Right text twist.",
            "It's the same game ones just syndicated through MSN games.",
            "One through Yahoo games.",
            "Other examples are things like song lyrics, websites, different recipe websites where you have essentially the same style of recipe or competing sofa manufacturers.",
            "So you were getting slightly away from the setting where duplicate is not useful, but it's nice to know and you can find this in the click data weather.",
            "Two sites are actually competing with each other while providing more or less comperable service."
        ],
        [
            "Or not.",
            "So here's how it went.",
            "It came in about evaluating it.",
            "So we start by sample link couples from couples of query document document from a query log, and we're going to judge these for duplication.",
            "I'll describe that in half a slide we're going to measure the agreement between the score in the judgments, and finally we're going to drill down a little bit more and see if we can actually learn a classifier.",
            "Do something smarter than just using this hypothesize redundancy score.",
            "Maybe it's not enough.",
            "So for each triplet we asked, we judge for three questions.",
            "We judged which page is most relevant to the query.",
            "We judge how similar is the utility of these pages for the query.",
            "And isn't easy to navigate as you can as you can see some of these questions might be hard to answer sometimes, so let's."
        ],
        [
            "Look what happened.",
            "So for a distribution of queries of these couples.",
            "We saw that both were judged equally relevant and identical utility about 6% of the time, so we're going to call.",
            "These are exact duplicates because the judgment rule was if it's identical utility, or that's usually it's because it's the same content.",
            "On the other hand, if if their navigational, it's easy to get between the two sites, and we've seen the site navigation, which is why I say yes within one of the options available for navigation question, that's about 18% of queries.",
            "And we're going to call these navigational duplicates.",
            "Then there's the content.",
            "Duplication will just say OK. Well, if the utility is very similar, we're going to call this a content duplicate.",
            "And finally, everything else is not implicate.",
            "But for the purposes of analysis, we're going to call this related utility question 'cause that turned out the hardest question to answer.",
            "We're going to call those weak duplicates, and you'll see why in just a second.",
            "Temporar"
        ],
        [
            "So here's this integer agreement you get with these questions, so we only measured into judge agreement on relatively small set of these couples.",
            "And So what it turns out is that we had no executive biscuits in the sets.",
            "I called into our judgments.",
            "On the other hand, when one judge judged a tuple navigational, the other judged tended to judge a navigational quite reliably.",
            "On the other hand, for content duplicates you see this is more difficult because this was based on this utility question, right?",
            "So if one judges the content, duplicate the other one agreed 30, they both judged the same content duplicate 31 times.",
            "Then again 27 * 1 Judge said it's a content duplicate.",
            "One judge says the week content duplicant, and similarly 32 times a week and are not duplicate, right?",
            "So you see, there's a little bit of washer Now what we decided to do in the further analysis is take content duplicate.",
            "To be a higher precision, lower recall metric, and we're going to call this this week this week duplicators as non duplicate.",
            "But it's nice to see at least that the differences are one level in our judgment scheme, so suggesting that that there is that this isn't just."
        ],
        [
            "Random noise.",
            "So here's the distribution of redundancy scores across the types of duplicates.",
            "So for exact replicates, most of them fell in the redundancy score above .8, or at least .6.",
            "On the on the other hand, the navigational duplicates had slightly lower than T scores.",
            "Still, they tended to be high.",
            "Now content duplicates fell in the fell on the low end, right?",
            "So most the largest number of content duplicates had another discord about .5.",
            "So there was some preference between the documents, but yet you still see a different distribution then the non duplicates.",
            "And the non duplicates are particularly interesting to to look at in this case, so you'll notice that most of the red mass is on the left hand side, and recall that the redundancy score is basically a measure of presentation bias.",
            "So for most of the most pairs of documents that have been judged non duplicated for a query.",
            "There exists an order in which the bottom line is clicked more often.",
            "So there is actually a preference, I guess an absolute click signals the presentation bias isn't causing is smaller.",
            "I guess in this case, so it gives you a little bit of bound on the presentation bias.",
            "Once you know things are non duplicate and so duplication Conversely might be explaining a fair amount of the presentation bias we see in in click data usually."
        ],
        [
            "His twist, he's turning it the other way around.",
            "Given you have a redundancy score, which class do you fall in?",
            "So on the high end your navigation or exact duplicates in the middle, you tend to be more content on the low end.",
            "You tend to be non duplicated, so there's obviously a little bit of noise in this."
        ],
        [
            "So we can now go ahead and say, OK, well, maybe this isn't the most the best way to classify duplicates.",
            "Maybe we can learn something more interesting or more sophisticated.",
            "So we added a few more features to our data set.",
            "We first looked at is it the?",
            "Are these pages on the same host name?",
            "And so the redundancy score is the minimum top click rate.",
            "So we added the minimum, mean and maximum top and bottom click rate for the pass and what you see some quite interesting effect.",
            "So given the amount of data that we had, same host meant navigational duplicate pretty much right away, which I. Yeah, OK, given that you're not on the same host.",
            "If your maximum bottom click rate is high, so if there's an order where the bottom thing is clicked on often cannot duplicate.",
            "It makes sense.",
            "If the minimum top click rate is low, which is separate, but again if it's as minimum top click rate is low then again in non duplicates.",
            "It's particularly interesting to look at also the difference between these exact and navigation duplicate, which we saw both sit on the high end of this redundancy score.",
            "That's the minimum.",
            "The minimum bottom click rate is.",
            "The is what eventually decides.",
            "So if you never really click on the bottom line, you're more likely to be an exact duplicate.",
            "If you do.",
            "Sometimes after all, well, then you're more likely to be navigational.",
            "Duplicate.",
            "Some people do really want to go through the right side, and this is where you're seeing combination of relevance and presentation bias signals coming in.",
            "It's also interesting that if you click on both too often, you're not duplicant again.",
            "If there is a duplicate, well, you wouldn't.",
            "Really, there's less utility to having both of them.",
            "So this was trained on all of our data with the."
        ],
        [
            "A simple decision tree?",
            "What about if we actually do the proper proper evaluation of what our precision recall?",
            "So we trained both cart decision trees and logistic regression on the model.",
            "It turns out logistic regression work better in this case, and we're seeing that with a fairly reasonable recall, around 1/2 almost half were getting 90% precision, so this is interesting in that is not too hard to detect these duplicates from clicks if you, especially if you want to focus more on the high precision cases."
        ],
        [
            "But I guess the question I haven't touched on yet is acting on these duplicates.",
            "So assuming we can detect them, so we've hypothesized navigational exact and content duplicates, So what right sometimes, for exact duplicates, we probably do want to remove them, and that's standard practice in web search.",
            "On the other hand, for navigational duplicates it becomes a different ranking problem.",
            "Suppose you know a pair is navigationally duplicated.",
            "Maybe then you do that.",
            "You do want to maybe pick one, but you want to pick the right one.",
            "So maybe there is a post processing step in ranking.",
            "On the other hand, getting to content duplicates gets much harder.",
            "And here what, you have two different sites for song lyrics.",
            "Maybe I prefer a or someone else prefers be there not completely redundant and you don't want to pick one necessarily entail.",
            "I'm only going to care about this site because some sites maybe hasn't has a nicer UI or people.",
            "Some people do care.",
            "So maybe, but maybe you want indicated user somehow, and so there's an interesting open question what to do about this, especially for these navigation and content duplicacy much softer in terms of redundancy user utility.",
            "There's also aspects to to this data that help outside of just the pure ranking problem, for one thing.",
            "What if you want to estimate relevance from clickthrough data so there's been a fair bit of work on taking clicks and transforming that into relevance judgments so you can trainer anchor?",
            "So a lot of these clicks, we know that they suffer from presentation bias, so click skip methods have been used to try and get cleaner judgments.",
            "Once you can add duplication to that, it explains a little bit more of the click signal, so you might well get cleaner training data.",
            "Additionally, you suppose you already have training data or evaluation data.",
            "It's a nice way to say, hey, wait a minute.",
            "Users think these are near duplicates, but judges don't.",
            "What's going on and that can be used to to think about why these discrepancies happen in the data."
        ],
        [
            "To conclude, we proposed a taxonomy of duplication, exact navigational and content duplication, and we've seen that clicks give you let you distinguish among these, and users behave differently.",
            "They really do exactly applicants, they just click on top one content duplicates is more other fuzzy mass, but you know what's going on and for non duplicate presentation bias looks like it has a much smaller effect than on the general web.",
            "So and so the open questions are so sometimes near duplicates are useful.",
            "How do we?",
            "How do we act upon this?",
            "And the second question that came up earlier was we had this problem in defining content duplicates between.",
            "We can and so the questions you asked judging and so judging for duplication hasn't been explored much.",
            "And so how do you?",
            "How does the judge know?",
            "And how do you give instructions to a judge to give you a cleaner set?",
            "Training set.",
            "Finally, this is this work has just been based on clicks.",
            "That's all.",
            "We've ignored the entire literature of using content.",
            "And so maybe content does clean up the signal.",
            "I'm sure it does help, at least for the exact duplicates.",
            "So we have to investigate how to how to combine these different signals and think about other signals that might be coming in that causing causing clicking.",
            "And that's it.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is joint work with Paul Benneth and Eminem.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So this is a motivation near duplicates, and duplicates are very common on the web.",
                    "label": 0
                },
                {
                    "sent": "We've all seen this in many cases, showing them isn't helpful.",
                    "label": 1
                },
                {
                    "sent": "Sometimes it hurts, sometimes just not helpful.",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of work on detecting duplicate and very close to applicants, but these techniques are usually based on content.",
                    "label": 0
                },
                {
                    "sent": "I'll give you a little bit more background in a moment, but in particular this means it's not sensitive to the query.",
                    "label": 0
                },
                {
                    "sent": "A duplicate can be thought of in the context of the user's information need or their intent, and so it could be that two documents.",
                    "label": 0
                },
                {
                    "sent": "Duplicate for some queries while being non duplicates for other queries and so that's the setting that we're thinking about here.",
                    "label": 0
                },
                {
                    "sent": "So in particular, I'll show you how how clicks give you a more sensitive context dependent way of detecting duplication.",
                    "label": 0
                },
                {
                    "sent": "So in this example here you see sort of the text test text twist query, which is a popular flash game you can play online and almost all these results show the same game, just in different wrappers.",
                    "label": 0
                },
                {
                    "sent": "So the content on the content level the pages are completely different in terms of the user using them.",
                    "label": 0
                },
                {
                    "sent": "There actually almost all of them are completely.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Founded so previous approaches are usually based on fingerprints, so there are two general ways right.",
                    "label": 0
                },
                {
                    "sent": "Either you couldn't take your your document generated complete fingerprint and then match these up and find exact duplicate or you can take us take a step by first looking at N grams to find a rough estimate of things that might be duplicated, as in a couple of passes to be more efficient and have a higher recall, have a higher precision and a higher recall.",
                    "label": 0
                },
                {
                    "sent": "So that's that's where content duplication.",
                    "label": 0
                },
                {
                    "sent": "Another way that duplicates have been removed is a post processing step.",
                    "label": 0
                },
                {
                    "sent": "So you run a query and then you'll diversify the search results.",
                    "label": 0
                },
                {
                    "sent": "You might say, OK, I'm going to reorder my list by relevant minus some amount of duplication going on, but even when this is reordering a query dependent set of documents, the metrics have in the past been query independent in the same way.",
                    "label": 0
                },
                {
                    "sent": "So typical example of that might be the MMR algorithm of carbon Goldstein, so yeah.",
                    "label": 0
                },
                {
                    "sent": "Like I say.",
                    "label": 0
                },
                {
                    "sent": "So we gotta introduces this hypothesize redundancy score.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's a typical search results page and we're going to be trying to workout whether document U&V are duplicates of each other in some sense.",
                    "label": 0
                },
                {
                    "sent": "I'm so document you is going to have some some rate at which is clicked, so it might be clicked 70% of the time in this order document V might be click 20% of the time, so we have a click right on the top document and then click right on the second document and you can think of the fraction of clicks, the fraction of impressions for which the top document is clicked as a presentation bias.",
                    "label": 0
                },
                {
                    "sent": "It's how often the user prefers number one and being observed observed that number one is clicked a lot more than #2 and so it's been thought that this is just.",
                    "label": 0
                },
                {
                    "sent": "The bias in the presentation, but we're going to we're going to call that bias sub UV.",
                    "label": 0
                },
                {
                    "sent": "So in the order of presentation.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Movie.",
                    "label": 0
                },
                {
                    "sent": "Now suppose sometimes we show the same pair of documents in the opposite order Vu.",
                    "label": 0
                },
                {
                    "sent": "In this case, there's also a clickthrough rate.",
                    "label": 0
                },
                {
                    "sent": "And there's also a bias or bias vu.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we're going to hypothesize that this redundancy score is the minimum of these two biases.",
                    "label": 1
                },
                {
                    "sent": "So there are two possible orders of these documents, and.",
                    "label": 1
                },
                {
                    "sent": "If in both presentation orders, the top thing is clicked, then we're going to have a high score.",
                    "label": 0
                },
                {
                    "sent": "In other words, if there's an extreme presentation bias that the top result is always clicked, well, that's going to give us a high redundancy score, and vice versa if there exists an order.",
                    "label": 0
                },
                {
                    "sent": "If in one of the two orders, the second document is clicked off and this minimum is going to be small.",
                    "label": 0
                },
                {
                    "sent": "And so we're going to be looking at this redundancy score.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a hidden picture, right?",
                    "label": 0
                },
                {
                    "sent": "So suppose you have two documents.",
                    "label": 0
                },
                {
                    "sent": "In the grey documented number one it gets clicked.",
                    "label": 0
                },
                {
                    "sent": "On the other case, when you present the red document first, it always gets clicked.",
                    "label": 0
                },
                {
                    "sent": "The results are probably duplicate or or.",
                    "label": 1
                },
                {
                    "sent": "Like I said, we might just be in a case for presentation bias is causing this problem.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the other hand, if one of the documents is clicked more often, if in the other order, the lower documents click.",
                    "label": 1
                },
                {
                    "sent": "This redundancy score is going to be small.",
                    "label": 1
                },
                {
                    "sent": "These are not going to be redundant at some level, and most as you expect we'd hope most documents.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Somewhere in between.",
                    "label": 0
                },
                {
                    "sent": "So how does this relate to the click skipping and fair pairs approaches that are skipped document followed by click document is a is a relevant signal.",
                    "label": 0
                },
                {
                    "sent": "Right, so in the fair pairs algorithm you're randomizing the two documents randomizing the order, and you're seeing if one of the documents reliably is clicked more often when it's in the second position.",
                    "label": 0
                },
                {
                    "sent": "And so both these approaches are saying a bottom click is a relevant signal, so you can tell which is more relevant based on the click of the bottom document in a pair.",
                    "label": 1
                },
                {
                    "sent": "In this work, we're looking at the top click and we're going to see that the top click is a duplication signal, so nicely.",
                    "label": 1
                },
                {
                    "sent": "Shows the other side.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The coin, if you will so do pairs really exist with this.",
                    "label": 1
                },
                {
                    "sent": "Different redundancy score.",
                    "label": 0
                },
                {
                    "sent": "Is it a metric that makes any sense?",
                    "label": 0
                },
                {
                    "sent": "So this is a sample of pairs of documents on a real web search engine.",
                    "label": 0
                },
                {
                    "sent": "Admittedly somewhat biased sample, but as you see for a variety of redundancy scores we actually see pairs of documents that have these scores.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What's interesting is if you then go in and you inspect some of these pairs of documents that are in the higher end of this range, what do you see?",
                    "label": 1
                },
                {
                    "sent": "We actually see three different types of duplication that are happening on the web that are causing these scores to be high.",
                    "label": 1
                },
                {
                    "sent": "First, their exact duplicates, we seen those, then there are content duplicates which are coming back to text twist example, something that in the context of the query the pages provide something that you've seen one seeing the other roughly as useful to me and the other one is not going to be so useful.",
                    "label": 1
                },
                {
                    "sent": "I don't really care which one I get.",
                    "label": 1
                },
                {
                    "sent": "And the third one really surprised us with the navigational duplicates.",
                    "label": 0
                },
                {
                    "sent": "In other words, this is 2 documents that are just on the same site.",
                    "label": 0
                },
                {
                    "sent": "One might be more relevant than the other, but users know their way around these sites, so they run this query.",
                    "label": 0
                },
                {
                    "sent": "They don't really care which page they get to, they know their way, and they'll be there on the right site.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's an example of navigation duplication, right?",
                    "label": 0
                },
                {
                    "sent": "So the homepage of the Cambridge, UK local news and their entertainment section.",
                    "label": 0
                },
                {
                    "sent": "The order you presented these doesn't really matter to users if they're searching for Cambridge News.",
                    "label": 0
                },
                {
                    "sent": "They'll just navigate to the right one if they're at the wrong one, despite the fact that one of them might be more relevant for their query.",
                    "label": 0
                },
                {
                    "sent": "Other typical examples we've seen in the literature bank home pages versus the login page of a bank.",
                    "label": 0
                },
                {
                    "sent": "Yes, people prefer the login page, but they tend to be.",
                    "label": 0
                },
                {
                    "sent": "They tend to exhibit some of these duplication or similar Amazon product similar eBay products.",
                    "label": 0
                },
                {
                    "sent": "Users tend to more often than for non duplicate pairs.",
                    "label": 0
                },
                {
                    "sent": "Click on the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Higher rank document.",
                    "label": 0
                },
                {
                    "sent": "Here's the content.",
                    "label": 0
                },
                {
                    "sent": "Deep example.",
                    "label": 0
                },
                {
                    "sent": "Right text twist.",
                    "label": 0
                },
                {
                    "sent": "It's the same game ones just syndicated through MSN games.",
                    "label": 0
                },
                {
                    "sent": "One through Yahoo games.",
                    "label": 0
                },
                {
                    "sent": "Other examples are things like song lyrics, websites, different recipe websites where you have essentially the same style of recipe or competing sofa manufacturers.",
                    "label": 1
                },
                {
                    "sent": "So you were getting slightly away from the setting where duplicate is not useful, but it's nice to know and you can find this in the click data weather.",
                    "label": 0
                },
                {
                    "sent": "Two sites are actually competing with each other while providing more or less comperable service.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or not.",
                    "label": 0
                },
                {
                    "sent": "So here's how it went.",
                    "label": 0
                },
                {
                    "sent": "It came in about evaluating it.",
                    "label": 0
                },
                {
                    "sent": "So we start by sample link couples from couples of query document document from a query log, and we're going to judge these for duplication.",
                    "label": 0
                },
                {
                    "sent": "I'll describe that in half a slide we're going to measure the agreement between the score in the judgments, and finally we're going to drill down a little bit more and see if we can actually learn a classifier.",
                    "label": 0
                },
                {
                    "sent": "Do something smarter than just using this hypothesize redundancy score.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's not enough.",
                    "label": 0
                },
                {
                    "sent": "So for each triplet we asked, we judge for three questions.",
                    "label": 1
                },
                {
                    "sent": "We judged which page is most relevant to the query.",
                    "label": 1
                },
                {
                    "sent": "We judge how similar is the utility of these pages for the query.",
                    "label": 1
                },
                {
                    "sent": "And isn't easy to navigate as you can as you can see some of these questions might be hard to answer sometimes, so let's.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look what happened.",
                    "label": 0
                },
                {
                    "sent": "So for a distribution of queries of these couples.",
                    "label": 0
                },
                {
                    "sent": "We saw that both were judged equally relevant and identical utility about 6% of the time, so we're going to call.",
                    "label": 0
                },
                {
                    "sent": "These are exact duplicates because the judgment rule was if it's identical utility, or that's usually it's because it's the same content.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if if their navigational, it's easy to get between the two sites, and we've seen the site navigation, which is why I say yes within one of the options available for navigation question, that's about 18% of queries.",
                    "label": 0
                },
                {
                    "sent": "And we're going to call these navigational duplicates.",
                    "label": 1
                },
                {
                    "sent": "Then there's the content.",
                    "label": 0
                },
                {
                    "sent": "Duplication will just say OK. Well, if the utility is very similar, we're going to call this a content duplicate.",
                    "label": 0
                },
                {
                    "sent": "And finally, everything else is not implicate.",
                    "label": 0
                },
                {
                    "sent": "But for the purposes of analysis, we're going to call this related utility question 'cause that turned out the hardest question to answer.",
                    "label": 0
                },
                {
                    "sent": "We're going to call those weak duplicates, and you'll see why in just a second.",
                    "label": 0
                },
                {
                    "sent": "Temporar",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's this integer agreement you get with these questions, so we only measured into judge agreement on relatively small set of these couples.",
                    "label": 1
                },
                {
                    "sent": "And So what it turns out is that we had no executive biscuits in the sets.",
                    "label": 0
                },
                {
                    "sent": "I called into our judgments.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, when one judge judged a tuple navigational, the other judged tended to judge a navigational quite reliably.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, for content duplicates you see this is more difficult because this was based on this utility question, right?",
                    "label": 1
                },
                {
                    "sent": "So if one judges the content, duplicate the other one agreed 30, they both judged the same content duplicate 31 times.",
                    "label": 0
                },
                {
                    "sent": "Then again 27 * 1 Judge said it's a content duplicate.",
                    "label": 1
                },
                {
                    "sent": "One judge says the week content duplicant, and similarly 32 times a week and are not duplicate, right?",
                    "label": 0
                },
                {
                    "sent": "So you see, there's a little bit of washer Now what we decided to do in the further analysis is take content duplicate.",
                    "label": 0
                },
                {
                    "sent": "To be a higher precision, lower recall metric, and we're going to call this this week this week duplicators as non duplicate.",
                    "label": 0
                },
                {
                    "sent": "But it's nice to see at least that the differences are one level in our judgment scheme, so suggesting that that there is that this isn't just.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Random noise.",
                    "label": 0
                },
                {
                    "sent": "So here's the distribution of redundancy scores across the types of duplicates.",
                    "label": 0
                },
                {
                    "sent": "So for exact replicates, most of them fell in the redundancy score above .8, or at least .6.",
                    "label": 0
                },
                {
                    "sent": "On the on the other hand, the navigational duplicates had slightly lower than T scores.",
                    "label": 0
                },
                {
                    "sent": "Still, they tended to be high.",
                    "label": 0
                },
                {
                    "sent": "Now content duplicates fell in the fell on the low end, right?",
                    "label": 0
                },
                {
                    "sent": "So most the largest number of content duplicates had another discord about .5.",
                    "label": 0
                },
                {
                    "sent": "So there was some preference between the documents, but yet you still see a different distribution then the non duplicates.",
                    "label": 0
                },
                {
                    "sent": "And the non duplicates are particularly interesting to to look at in this case, so you'll notice that most of the red mass is on the left hand side, and recall that the redundancy score is basically a measure of presentation bias.",
                    "label": 0
                },
                {
                    "sent": "So for most of the most pairs of documents that have been judged non duplicated for a query.",
                    "label": 0
                },
                {
                    "sent": "There exists an order in which the bottom line is clicked more often.",
                    "label": 0
                },
                {
                    "sent": "So there is actually a preference, I guess an absolute click signals the presentation bias isn't causing is smaller.",
                    "label": 0
                },
                {
                    "sent": "I guess in this case, so it gives you a little bit of bound on the presentation bias.",
                    "label": 0
                },
                {
                    "sent": "Once you know things are non duplicate and so duplication Conversely might be explaining a fair amount of the presentation bias we see in in click data usually.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "His twist, he's turning it the other way around.",
                    "label": 0
                },
                {
                    "sent": "Given you have a redundancy score, which class do you fall in?",
                    "label": 0
                },
                {
                    "sent": "So on the high end your navigation or exact duplicates in the middle, you tend to be more content on the low end.",
                    "label": 0
                },
                {
                    "sent": "You tend to be non duplicated, so there's obviously a little bit of noise in this.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we can now go ahead and say, OK, well, maybe this isn't the most the best way to classify duplicates.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can learn something more interesting or more sophisticated.",
                    "label": 0
                },
                {
                    "sent": "So we added a few more features to our data set.",
                    "label": 0
                },
                {
                    "sent": "We first looked at is it the?",
                    "label": 0
                },
                {
                    "sent": "Are these pages on the same host name?",
                    "label": 0
                },
                {
                    "sent": "And so the redundancy score is the minimum top click rate.",
                    "label": 0
                },
                {
                    "sent": "So we added the minimum, mean and maximum top and bottom click rate for the pass and what you see some quite interesting effect.",
                    "label": 0
                },
                {
                    "sent": "So given the amount of data that we had, same host meant navigational duplicate pretty much right away, which I. Yeah, OK, given that you're not on the same host.",
                    "label": 0
                },
                {
                    "sent": "If your maximum bottom click rate is high, so if there's an order where the bottom thing is clicked on often cannot duplicate.",
                    "label": 0
                },
                {
                    "sent": "It makes sense.",
                    "label": 0
                },
                {
                    "sent": "If the minimum top click rate is low, which is separate, but again if it's as minimum top click rate is low then again in non duplicates.",
                    "label": 0
                },
                {
                    "sent": "It's particularly interesting to look at also the difference between these exact and navigation duplicate, which we saw both sit on the high end of this redundancy score.",
                    "label": 0
                },
                {
                    "sent": "That's the minimum.",
                    "label": 0
                },
                {
                    "sent": "The minimum bottom click rate is.",
                    "label": 0
                },
                {
                    "sent": "The is what eventually decides.",
                    "label": 0
                },
                {
                    "sent": "So if you never really click on the bottom line, you're more likely to be an exact duplicate.",
                    "label": 0
                },
                {
                    "sent": "If you do.",
                    "label": 0
                },
                {
                    "sent": "Sometimes after all, well, then you're more likely to be navigational.",
                    "label": 0
                },
                {
                    "sent": "Duplicate.",
                    "label": 0
                },
                {
                    "sent": "Some people do really want to go through the right side, and this is where you're seeing combination of relevance and presentation bias signals coming in.",
                    "label": 0
                },
                {
                    "sent": "It's also interesting that if you click on both too often, you're not duplicant again.",
                    "label": 0
                },
                {
                    "sent": "If there is a duplicate, well, you wouldn't.",
                    "label": 0
                },
                {
                    "sent": "Really, there's less utility to having both of them.",
                    "label": 0
                },
                {
                    "sent": "So this was trained on all of our data with the.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A simple decision tree?",
                    "label": 0
                },
                {
                    "sent": "What about if we actually do the proper proper evaluation of what our precision recall?",
                    "label": 0
                },
                {
                    "sent": "So we trained both cart decision trees and logistic regression on the model.",
                    "label": 0
                },
                {
                    "sent": "It turns out logistic regression work better in this case, and we're seeing that with a fairly reasonable recall, around 1/2 almost half were getting 90% precision, so this is interesting in that is not too hard to detect these duplicates from clicks if you, especially if you want to focus more on the high precision cases.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But I guess the question I haven't touched on yet is acting on these duplicates.",
                    "label": 0
                },
                {
                    "sent": "So assuming we can detect them, so we've hypothesized navigational exact and content duplicates, So what right sometimes, for exact duplicates, we probably do want to remove them, and that's standard practice in web search.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, for navigational duplicates it becomes a different ranking problem.",
                    "label": 0
                },
                {
                    "sent": "Suppose you know a pair is navigationally duplicated.",
                    "label": 0
                },
                {
                    "sent": "Maybe then you do that.",
                    "label": 1
                },
                {
                    "sent": "You do want to maybe pick one, but you want to pick the right one.",
                    "label": 0
                },
                {
                    "sent": "So maybe there is a post processing step in ranking.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, getting to content duplicates gets much harder.",
                    "label": 0
                },
                {
                    "sent": "And here what, you have two different sites for song lyrics.",
                    "label": 0
                },
                {
                    "sent": "Maybe I prefer a or someone else prefers be there not completely redundant and you don't want to pick one necessarily entail.",
                    "label": 0
                },
                {
                    "sent": "I'm only going to care about this site because some sites maybe hasn't has a nicer UI or people.",
                    "label": 0
                },
                {
                    "sent": "Some people do care.",
                    "label": 0
                },
                {
                    "sent": "So maybe, but maybe you want indicated user somehow, and so there's an interesting open question what to do about this, especially for these navigation and content duplicacy much softer in terms of redundancy user utility.",
                    "label": 0
                },
                {
                    "sent": "There's also aspects to to this data that help outside of just the pure ranking problem, for one thing.",
                    "label": 0
                },
                {
                    "sent": "What if you want to estimate relevance from clickthrough data so there's been a fair bit of work on taking clicks and transforming that into relevance judgments so you can trainer anchor?",
                    "label": 0
                },
                {
                    "sent": "So a lot of these clicks, we know that they suffer from presentation bias, so click skip methods have been used to try and get cleaner judgments.",
                    "label": 0
                },
                {
                    "sent": "Once you can add duplication to that, it explains a little bit more of the click signal, so you might well get cleaner training data.",
                    "label": 0
                },
                {
                    "sent": "Additionally, you suppose you already have training data or evaluation data.",
                    "label": 0
                },
                {
                    "sent": "It's a nice way to say, hey, wait a minute.",
                    "label": 0
                },
                {
                    "sent": "Users think these are near duplicates, but judges don't.",
                    "label": 0
                },
                {
                    "sent": "What's going on and that can be used to to think about why these discrepancies happen in the data.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To conclude, we proposed a taxonomy of duplication, exact navigational and content duplication, and we've seen that clicks give you let you distinguish among these, and users behave differently.",
                    "label": 1
                },
                {
                    "sent": "They really do exactly applicants, they just click on top one content duplicates is more other fuzzy mass, but you know what's going on and for non duplicate presentation bias looks like it has a much smaller effect than on the general web.",
                    "label": 1
                },
                {
                    "sent": "So and so the open questions are so sometimes near duplicates are useful.",
                    "label": 0
                },
                {
                    "sent": "How do we?",
                    "label": 0
                },
                {
                    "sent": "How do we act upon this?",
                    "label": 0
                },
                {
                    "sent": "And the second question that came up earlier was we had this problem in defining content duplicates between.",
                    "label": 0
                },
                {
                    "sent": "We can and so the questions you asked judging and so judging for duplication hasn't been explored much.",
                    "label": 1
                },
                {
                    "sent": "And so how do you?",
                    "label": 0
                },
                {
                    "sent": "How does the judge know?",
                    "label": 0
                },
                {
                    "sent": "And how do you give instructions to a judge to give you a cleaner set?",
                    "label": 0
                },
                {
                    "sent": "Training set.",
                    "label": 0
                },
                {
                    "sent": "Finally, this is this work has just been based on clicks.",
                    "label": 0
                },
                {
                    "sent": "That's all.",
                    "label": 0
                },
                {
                    "sent": "We've ignored the entire literature of using content.",
                    "label": 0
                },
                {
                    "sent": "And so maybe content does clean up the signal.",
                    "label": 0
                },
                {
                    "sent": "I'm sure it does help, at least for the exact duplicates.",
                    "label": 0
                },
                {
                    "sent": "So we have to investigate how to how to combine these different signals and think about other signals that might be coming in that causing causing clicking.",
                    "label": 0
                },
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}