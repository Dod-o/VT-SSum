{
    "id": "33ajdbps7wvbyc33z4tqetx4uwap2hln",
    "title": "Face detection without bells and whistles",
    "info": {
        "author": [
            "Markus Mathias, Department of Electrical Engineering, KU Leuven"
        ],
        "published": "Oct. 29, 2014",
        "recorded": "September 2014",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2014_mathias_face_detection/",
    "segmentation": [
        [
            "Hello everyone.",
            "In this work, we try to figure out how to get a really good face detector."
        ],
        [
            "And.",
            "During the process, we saw that there are many issues with."
        ],
        [
            "Current face detection benchmarks and it's work.",
            "We tried to fix these issues so in the main part of my talk I will talk about these issues and how we fix them.",
            "The second part would be about baseline and we showed that they are surprisingly effective for face detection."
        ],
        [
            "Let me see what recent benchmarks we have."
        ],
        [
            "Is POSCO faces afw FTP and all these benchmarks compare many different systems for face detection's and these systems originate from both research community and commercial products?",
            "So we asked the authors to provide us the detection bounding boxes for the different methods and we did the first evaluation on Pascal faces."
        ],
        [
            "The curves are shown.",
            "Here is a precision recall curve, so we have to position on X axis and the recall and position on the Y axis and the recall on the X axis.",
            "So you want to be in the upper right corner.",
            "This curves look really suspicious for us."
        ],
        [
            "This detection is a mature system and as you can see him for the high scoring detection's.",
            "There are a lot of false positive for all methods, so we're wondering what was going on here.",
            "Let's just."
        ],
        [
            "Picked the best performer in this data set and look at the higher scoring.",
            "False positive."
        ],
        [
            "So this highest going cross positive is the red bounding box.",
            "The annotations are the white bounding boxes and is to consider the detector clearly triggers on the face, but this is counted as a false positive.",
            "We use the standard Pascal VOC intersection over Union criterium here.",
            "So this is a false positive and probably noticed that."
        ],
        [
            "Also, here in the background there are non annotated phases.",
            "If a detector fires and then we again introduce false positives.",
            "Let me give you overview over the issues with."
        ],
        [
            "Figure out the first issue is what constitutes a face, so it's very unclear and different in between different datasets.",
            "What is the face?",
            "So it's already a mask over face to face.",
            "What about the drawing?",
            "What about the woman on the T shirt on the guy on the right?",
            "And the more interesting question is, would you want to penalize the detector which detects one of these faces?",
            "So if they fire on the on the woman with the red box, would you penalize this detector and counted as a false positive?"
        ],
        [
            "The second problem we figured out, it's a really severe problem that we observed for many different classes as well for pedestrian detection or traffic sign detection, and this concerns the minimum annotation face size.",
            "So let's say you your data set has some fixed size.",
            "What is the minimum size that you annotated and you set up your detector to detect very small faces?",
            "Then you introduce a lot of false positives.",
            "If you go too big then you miss out a lot of detections and you miss out in recall.",
            "And if you manage to get the same size as this annotated, then you still might have problems.",
            "For example, there is a very small face that is just not annotated anymore and you detect it a little bit bigger.",
            "So in the truth again, a false positive.",
            "And this boundary effects really have severe impact on the overall quality, up to 5% average precision."
        ],
        [
            "The third issue is different annotation policies, so we figured out that this is within the data set sometimes.",
            "So let's say once you annotate the face spanning over the whole head another time you only have a very constrained region of the face.",
            "And if it's within a data set, you can imagine that the minimum annotation face size is not even defined there.",
            "Also, when you evaluate across different datasets, let's say you train on one data set to predict faces with the red bounding boxes on the right.",
            "And you evaluate on the data set where faces are annotated with the white boxes spanning over the whole head.",
            "And you can clearly see that there is a mismatch.",
            "And in the end we don't know which methods took actually care of this mismatch.",
            "So when we have the comparison and the precision recall curves of all the different methods, it's really hard to decide which is actually better, because there might be a better method which just predicts always two small boxes."
        ],
        [
            "So we want a more fair and meaningful comparison between different methods and in the paper we propose several solution for this.",
            "So."
        ],
        [
            "First we have to improve the annotations, so this is the most straightforward solution.",
            "We go into the data set and we ensure that at least within the data set, there is a consistent policy of how the faces are annotated or to."
        ],
        [
            "We try to Add all the missed faces that were overlooked.",
            "Curiously, so here the white boxes were previously annotated and the colored boxes where the missed annotations.",
            "And most of the new annotations we add we labeled with ignore flick.",
            "This means if our detector hits one of these ignore flecked annotations, then we don't count it as a true positive, but also if we don't detect it, we will not count it as a miss."
        ],
        [
            "The second solution is about handling this different policies.",
            "If you are starting evaluating of different datasets, so you can clearly see if you take the left example, annual detector predicts the red boxes you detect, output will directly be much better if you just shift the box a little bit up when you scale it a bit.",
            "Then you would get the much better precision recall curve as we don't know which methods took care of this issue, we just made it part of the evaluation protocol, so."
        ],
        [
            "Every method we estimate, the global richer transform, translation and scaling to maximize detection, annotation overlap.",
            "Now we can be sure that every method took care of this, and it's part of the protocol, and we don't advantage any specific method anymore."
        ],
        [
            "The second, the third solution is about handling this different annotation sizes.",
            "So let's say you want to evaluate your detectors for faces that are bigger Alpha equals 30 pixels, and you ask your annotator to annotate all phases that are 15 pixels.",
            "It's a concrete example.",
            "We figure out the most common border cases.",
            "First.",
            "We have annotation of size Alpha, so exactly the size we want to start evaluating on and the detection, which is a little bit smaller the second case."
        ],
        [
            "We have a detection of siphan annotation which is a little bit smaller."
        ],
        [
            "In the third case, we have a detection which is actually smaller than every annotation in the data set.",
            "If you try some naive ideas, for example."
        ],
        [
            "Just deleting annotations which showed this now and the sender is dashed lines."
        ],
        [
            "Then immediately said you don't have annotation anymore, but still a detection, you generate false positive."
        ],
        [
            "So when you delete detections, you."
        ],
        [
            "And into problems, suits and red false negatives.",
            "If you delete both detections and annotations, you just shift the boundary and you."
        ],
        [
            "Do they make a lot of problem of ours?",
            "So in our solution we try to get rather smooth boundary here."
        ],
        [
            "So we propose first to flag all annotations which are smaller Alpha equals 30 pixel with the ignore flag.",
            "And delete all detections with the smaller than better.",
            "Dispater selected in a way that we want to keep all that actions which are of size better which are big enough that it could still generate a true positive with annotation of size Alpha.",
            "Let me show you."
        ],
        [
            "This detection is bigger than better.",
            "Better in this specific case is 21 pixel.",
            "We would keep it because it still can generate the true positive with the annotation.",
            "The blue annotation."
        ],
        [
            "The annotation, which is smaller than every flag with the ignore labor, so it will not generate false positives.",
            "So we will handle this case as well, and the detection which is even smaller than better, we would just."
        ],
        [
            "Eat."
        ],
        [
            "So as you can see, now we can.",
            "We have like a smooth boundary and we can handle all this border cases."
        ],
        [
            "Let's look in the view evaluation again.",
            "So previously you see that all curve have dispatched precision in the beginning, and we as soon as we apply our better annotations and the new evaluation protocol or the curve."
        ],
        [
            "Jump up drastically.",
            "And as well, some of the curves change their order.",
            "So this is where points out that it's really important to have a proper evaluation there.",
            "So why is this curve better?",
            "So it's mostly better, because this is more what we observed in the data set.",
            "High scoring detections usually always hit faces, and as you can see here that up to 50% recall nearly all methods have perfect precision.",
            "Let me look at the examples again from the structured models."
        ],
        [
            "This was the situation before.",
            "We have the annotations and widen the detection in red."
        ],
        [
            "Now you can see afterwards we added new detections and we shifted some bounding boxes and our evaluation method by itself changed the size of this of this specific detector to be a little bit smaller and we came from a false positive to a true positive."
        ],
        [
            "Same with the next thoughts for its positive.",
            "These are all very high scoring, false positive before."
        ],
        [
            "Then you see that as well, we introduced the two new faces in the background and the false positive will be turned into a true positive."
        ],
        [
            "So now we fixed the evaluation protocol and we can get back to our initial problem, which is we want to do face detection.",
            "So we want to look into some baselines.",
            "We"
        ],
        [
            "Served that most methods are either based on Viola Jones.",
            "Or"
        ],
        [
            "Three based on DPM deformable parts model, so we wanted to have based my lines of these two categories."
        ],
        [
            "As the data set, we selected the FLW data set and we cluster the data into five different fuels.",
            "We have frontal faces, slightly rotated faces and lateral views on faces.",
            "And then we transfer the deep."
        ],
        [
            "And model here we used completely vanilla TPM default parameters.",
            "The only thing that we changes instead of having a bounding box aspect ratio is less initialization.",
            "We use your angles of the phases that we specified before.",
            "DPM has been evaluated before on face detection on the FW data set and in the next slide."
        ],
        [
            "You see?",
            "The two solid lines are DPM evaluation, previously one from true at all in Cpl 2012.",
            "An in magenta is our curve is shown.",
            "And you can see that our curve is around 2.5% better than what was previously proposed, but this makes a lot of sense as we have now much better training data or more training data.",
            "And we also use a newer version of DPM.",
            "This type of graph have been proposed many times when people compare their baseline to DPM.",
            "But now I can tell you that, but changing a single parameter in the in the evaluation of DPM you can come from this curve."
        ],
        [
            "To this once and the parameter that we changed is just an unmarked suppression threshold."
        ],
        [
            "So if we have a threshold of 0.5, we get this initial curves that we always see there are not so great in position, but if we change it."
        ],
        [
            "For example to 0.3.",
            "Then our DPM method is not better than any other method in this data set, including methods that were initially built upon DPN.",
            "So."
        ],
        [
            "This non Max oppression really matters a lot for the face detection and when you change the threshold you get really different curves.",
            "For the SP."
        ],
        [
            "Sific case of DPM, we observed a lot of this overlapping detection, so we have a very high scoring detection on the center of the face and the second detection which is just big enough not to be removed by the non Max suppression and for TPM it seems that the cost for that information is really dominated by the appearance cost.",
            "So you can just shift all the all the parts in words and you get the second detection which just has a slightly slightly lower score but it's bigger than the previous one and of course this messes up the evaluation and generates these false positives."
        ],
        [
            "Let's go to the second baseline, which is based on Viola Jones."
        ],
        [
            "And here we use the integral channel features detector.",
            "This is basically a more modern version of Viola Jones and the main difference is that instead of having only a grayscale image, we use a color.",
            "Basically HTN color channels.",
            "And we are very familiar with this architecture as we used it before."
        ],
        [
            "We call this baseline square channel features five.",
            "We use exactly the same training data with exactly the same views, and we trained our models."
        ],
        [
            "We also did a additional experiments on this data set to try to figure out what makes a face detector truly take.",
            "So we evaluate the number of training samples, the number of templates, the influence of the color channels, how many weak learners do you need when you perform boosting?",
            "The most important one here."
        ],
        [
            "Is the number of templates and here it turns out that DPM actually saturates when you have to six templates.",
            "It does not improve anymore quality when you give it a traditional.",
            "For example rotated faces.",
            "The square channel features set up on the other side really benefits if you give him rotated faces then other without having this in the training data, you cannot detect rotated faces that really benefits from it."
        ],
        [
            "So let's look at the result.",
            "This is other curves that you saw before on our new benchmark.",
            "With the better annotations and at the moment structured model is the best performing method."
        ],
        [
            "I."
        ],
        [
            "The promised some commercial products.",
            "Here's face plus Plus in Picasa these are only dots because we don't have confidence value for this things.",
            "But as you can see the clear clearly see that actions are the methods are tuned for high precision.",
            "When we now look at."
        ],
        [
            "Our baseline from square channel features.",
            "You can see that it's slightly better than the previous ones, and if we add the."
        ],
        [
            "Umm, you see a big jump in quality, but as I said before, the components really matter for the square channel features.",
            "So if we just rotate the data set so we augmented and get additional views on the data and we train another model which is again Viola Jones based on Richard template we get are fine."
        ],
        [
            "Headhunter model, which matches the result of DPM.",
            "On the F."
        ],
        [
            "W data set we observe similar things and this data set is more or less already exhausted, so there are most of the methods already reach more than 95% average position."
        ],
        [
            "As a sanity check, we did final evaluation on the FTP data set.",
            "Here we did not change any annotations.",
            "We did not use our evaluation protocol, we just used what they offered us.",
            "This is slightly different curve that shows the false positive on the X axis and the true positive rate on the Y axis.",
            "So we want to be in the upper left corner and as you can see as well here, our baselines perform really good.",
            "We could not even use our system on this data set because the policy here is to share the precision recall curves directly, rather than the detection bounding boxes."
        ],
        [
            "In conclusion, we release a new, more principled evaluation toolkit, new evaluation tool box with improved annotations for the most common datasets and the research systems are on par with.",
            "In total we evaluated 6 commercial products and EPM and Richard templates can both reach top performance for the task of face detection."
        ],
        [
            "As the take home message detection evaluation is really nontrivial and there are still many problems to be solved, and many people are facing exactly these problems that we quantified before, and also the baseline methods can be surprisingly effective.",
            "If you really take care to train them properly."
        ],
        [
            "So thank you very much for your attention.",
            "I want to say that resonates very well with how I feel about evaluation, and I think this bounding box approach in general is somewhat flawed.",
            "Becausw the bounding box as a rule is somewhat of a matter of taste, and particularly when you deal with poses, it's not quite clear how to apply the bounding box.",
            "Do you want to put it on the face or maybe around the whole head?",
            "And I would like to make a suggestion.",
            "Why not try to evaluate the ability of a detector to reconstruct the position of certain local features of the face, like the eyes or the mouse.",
            "Eyes and mouse, for instance, maybe also knows these are just points.",
            "There can be no ambiguity of where they are, and they are pretty robust against all kinds of poses.",
            "So that means there is no pose where all these points project onto a single point.",
            "So you can always kind of reconstruct the matching the scale, the orientation and so forth.",
            "So so you're completely right about this.",
            "The only thing is we wanted to use at the moment the existing data sets and they just don't.",
            "Most of them just don't.",
            "Content annotations for the facial points and as well this under.",
            "To get this annotations.",
            "Especially a lot of Labor work and you see already on if you just use simple bounding boxes for annotations, there are already a lot of errors in the data set, and I guess that these hours are even more severe if you use this facial points.",
            "So yeah, if you can get a good data set with facial points annotated and it makes a lot of sense to change the metric for evaluation.",
            "Yes, yeah.",
            "When you have three points, for instance, you have only just one more coordinate.",
            "You need to fix.",
            "Compared to bounding box so it's not really much more work and I think as far as annotation is concerned, it's not really more complicated.",
            "Thanks a lot, thank you.",
            "Another question, there's a one question over there.",
            "So as you point, is first of all great work.",
            "As you point out, the datasets available are almost saturated for the current detector, so it would be important, I think to.",
            "Understand if the problem is solved or whether there are interesting pockets where we're not doing well yet, so to give an example when Petrodollar did his benchmark on pedestrian detector detection he looked into where do current methods fail and he identified a couple of places.",
            "One is highly blocked out or highly occluded pedestrians and one is pedestrians that are smaller than 50 pixels and both of them there is a big difference between human observers and the current algorithms and so that was a useful outcome.",
            "Do you have any observations about?",
            "Sort and you have any proposal how to create new datasets that challenges.",
            "So first what we observed, we were really surprised face detection, which is around so long.",
            "The data set are actually worse than where it will have for pedestrian detection.",
            "So pedestrian detection we had actually much larger datasets and annotations had much better quality, so this was already surprising that this is not the case for face detection where you really would expect that.",
            "And also of course we looked what's going wrong now, and it seems that it's in fact the case that most of the method detect like 80% of the face is really well.",
            "And then the differences are just in the occluded cases in a very small cases and defocused faces and these things.",
            "So I think there should still be some evaluations for phases as well, how?",
            "The specific issues of the different methods and on what their struggle here.",
            "OK thanks Marcus.",
            "Will have to move on then, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone.",
                    "label": 0
                },
                {
                    "sent": "In this work, we try to figure out how to get a really good face detector.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "During the process, we saw that there are many issues with.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Current face detection benchmarks and it's work.",
                    "label": 1
                },
                {
                    "sent": "We tried to fix these issues so in the main part of my talk I will talk about these issues and how we fix them.",
                    "label": 0
                },
                {
                    "sent": "The second part would be about baseline and we showed that they are surprisingly effective for face detection.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me see what recent benchmarks we have.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is POSCO faces afw FTP and all these benchmarks compare many different systems for face detection's and these systems originate from both research community and commercial products?",
                    "label": 0
                },
                {
                    "sent": "So we asked the authors to provide us the detection bounding boxes for the different methods and we did the first evaluation on Pascal faces.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The curves are shown.",
                    "label": 0
                },
                {
                    "sent": "Here is a precision recall curve, so we have to position on X axis and the recall and position on the Y axis and the recall on the X axis.",
                    "label": 0
                },
                {
                    "sent": "So you want to be in the upper right corner.",
                    "label": 0
                },
                {
                    "sent": "This curves look really suspicious for us.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This detection is a mature system and as you can see him for the high scoring detection's.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of false positive for all methods, so we're wondering what was going on here.",
                    "label": 0
                },
                {
                    "sent": "Let's just.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Picked the best performer in this data set and look at the higher scoring.",
                    "label": 0
                },
                {
                    "sent": "False positive.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this highest going cross positive is the red bounding box.",
                    "label": 0
                },
                {
                    "sent": "The annotations are the white bounding boxes and is to consider the detector clearly triggers on the face, but this is counted as a false positive.",
                    "label": 0
                },
                {
                    "sent": "We use the standard Pascal VOC intersection over Union criterium here.",
                    "label": 0
                },
                {
                    "sent": "So this is a false positive and probably noticed that.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also, here in the background there are non annotated phases.",
                    "label": 0
                },
                {
                    "sent": "If a detector fires and then we again introduce false positives.",
                    "label": 1
                },
                {
                    "sent": "Let me give you overview over the issues with.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Figure out the first issue is what constitutes a face, so it's very unclear and different in between different datasets.",
                    "label": 1
                },
                {
                    "sent": "What is the face?",
                    "label": 0
                },
                {
                    "sent": "So it's already a mask over face to face.",
                    "label": 0
                },
                {
                    "sent": "What about the drawing?",
                    "label": 0
                },
                {
                    "sent": "What about the woman on the T shirt on the guy on the right?",
                    "label": 0
                },
                {
                    "sent": "And the more interesting question is, would you want to penalize the detector which detects one of these faces?",
                    "label": 0
                },
                {
                    "sent": "So if they fire on the on the woman with the red box, would you penalize this detector and counted as a false positive?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second problem we figured out, it's a really severe problem that we observed for many different classes as well for pedestrian detection or traffic sign detection, and this concerns the minimum annotation face size.",
                    "label": 0
                },
                {
                    "sent": "So let's say you your data set has some fixed size.",
                    "label": 0
                },
                {
                    "sent": "What is the minimum size that you annotated and you set up your detector to detect very small faces?",
                    "label": 1
                },
                {
                    "sent": "Then you introduce a lot of false positives.",
                    "label": 0
                },
                {
                    "sent": "If you go too big then you miss out a lot of detections and you miss out in recall.",
                    "label": 0
                },
                {
                    "sent": "And if you manage to get the same size as this annotated, then you still might have problems.",
                    "label": 0
                },
                {
                    "sent": "For example, there is a very small face that is just not annotated anymore and you detect it a little bit bigger.",
                    "label": 0
                },
                {
                    "sent": "So in the truth again, a false positive.",
                    "label": 0
                },
                {
                    "sent": "And this boundary effects really have severe impact on the overall quality, up to 5% average precision.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The third issue is different annotation policies, so we figured out that this is within the data set sometimes.",
                    "label": 0
                },
                {
                    "sent": "So let's say once you annotate the face spanning over the whole head another time you only have a very constrained region of the face.",
                    "label": 0
                },
                {
                    "sent": "And if it's within a data set, you can imagine that the minimum annotation face size is not even defined there.",
                    "label": 1
                },
                {
                    "sent": "Also, when you evaluate across different datasets, let's say you train on one data set to predict faces with the red bounding boxes on the right.",
                    "label": 0
                },
                {
                    "sent": "And you evaluate on the data set where faces are annotated with the white boxes spanning over the whole head.",
                    "label": 1
                },
                {
                    "sent": "And you can clearly see that there is a mismatch.",
                    "label": 0
                },
                {
                    "sent": "And in the end we don't know which methods took actually care of this mismatch.",
                    "label": 0
                },
                {
                    "sent": "So when we have the comparison and the precision recall curves of all the different methods, it's really hard to decide which is actually better, because there might be a better method which just predicts always two small boxes.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we want a more fair and meaningful comparison between different methods and in the paper we propose several solution for this.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First we have to improve the annotations, so this is the most straightforward solution.",
                    "label": 0
                },
                {
                    "sent": "We go into the data set and we ensure that at least within the data set, there is a consistent policy of how the faces are annotated or to.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We try to Add all the missed faces that were overlooked.",
                    "label": 0
                },
                {
                    "sent": "Curiously, so here the white boxes were previously annotated and the colored boxes where the missed annotations.",
                    "label": 0
                },
                {
                    "sent": "And most of the new annotations we add we labeled with ignore flick.",
                    "label": 1
                },
                {
                    "sent": "This means if our detector hits one of these ignore flecked annotations, then we don't count it as a true positive, but also if we don't detect it, we will not count it as a miss.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second solution is about handling this different policies.",
                    "label": 0
                },
                {
                    "sent": "If you are starting evaluating of different datasets, so you can clearly see if you take the left example, annual detector predicts the red boxes you detect, output will directly be much better if you just shift the box a little bit up when you scale it a bit.",
                    "label": 0
                },
                {
                    "sent": "Then you would get the much better precision recall curve as we don't know which methods took care of this issue, we just made it part of the evaluation protocol, so.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Every method we estimate, the global richer transform, translation and scaling to maximize detection, annotation overlap.",
                    "label": 0
                },
                {
                    "sent": "Now we can be sure that every method took care of this, and it's part of the protocol, and we don't advantage any specific method anymore.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second, the third solution is about handling this different annotation sizes.",
                    "label": 0
                },
                {
                    "sent": "So let's say you want to evaluate your detectors for faces that are bigger Alpha equals 30 pixels, and you ask your annotator to annotate all phases that are 15 pixels.",
                    "label": 0
                },
                {
                    "sent": "It's a concrete example.",
                    "label": 0
                },
                {
                    "sent": "We figure out the most common border cases.",
                    "label": 0
                },
                {
                    "sent": "First.",
                    "label": 0
                },
                {
                    "sent": "We have annotation of size Alpha, so exactly the size we want to start evaluating on and the detection, which is a little bit smaller the second case.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a detection of siphan annotation which is a little bit smaller.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the third case, we have a detection which is actually smaller than every annotation in the data set.",
                    "label": 0
                },
                {
                    "sent": "If you try some naive ideas, for example.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just deleting annotations which showed this now and the sender is dashed lines.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then immediately said you don't have annotation anymore, but still a detection, you generate false positive.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when you delete detections, you.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And into problems, suits and red false negatives.",
                    "label": 0
                },
                {
                    "sent": "If you delete both detections and annotations, you just shift the boundary and you.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do they make a lot of problem of ours?",
                    "label": 0
                },
                {
                    "sent": "So in our solution we try to get rather smooth boundary here.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we propose first to flag all annotations which are smaller Alpha equals 30 pixel with the ignore flag.",
                    "label": 1
                },
                {
                    "sent": "And delete all detections with the smaller than better.",
                    "label": 1
                },
                {
                    "sent": "Dispater selected in a way that we want to keep all that actions which are of size better which are big enough that it could still generate a true positive with annotation of size Alpha.",
                    "label": 1
                },
                {
                    "sent": "Let me show you.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This detection is bigger than better.",
                    "label": 0
                },
                {
                    "sent": "Better in this specific case is 21 pixel.",
                    "label": 0
                },
                {
                    "sent": "We would keep it because it still can generate the true positive with the annotation.",
                    "label": 0
                },
                {
                    "sent": "The blue annotation.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The annotation, which is smaller than every flag with the ignore labor, so it will not generate false positives.",
                    "label": 0
                },
                {
                    "sent": "So we will handle this case as well, and the detection which is even smaller than better, we would just.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Eat.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as you can see, now we can.",
                    "label": 0
                },
                {
                    "sent": "We have like a smooth boundary and we can handle all this border cases.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's look in the view evaluation again.",
                    "label": 0
                },
                {
                    "sent": "So previously you see that all curve have dispatched precision in the beginning, and we as soon as we apply our better annotations and the new evaluation protocol or the curve.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Jump up drastically.",
                    "label": 0
                },
                {
                    "sent": "And as well, some of the curves change their order.",
                    "label": 0
                },
                {
                    "sent": "So this is where points out that it's really important to have a proper evaluation there.",
                    "label": 0
                },
                {
                    "sent": "So why is this curve better?",
                    "label": 0
                },
                {
                    "sent": "So it's mostly better, because this is more what we observed in the data set.",
                    "label": 0
                },
                {
                    "sent": "High scoring detections usually always hit faces, and as you can see here that up to 50% recall nearly all methods have perfect precision.",
                    "label": 0
                },
                {
                    "sent": "Let me look at the examples again from the structured models.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This was the situation before.",
                    "label": 0
                },
                {
                    "sent": "We have the annotations and widen the detection in red.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now you can see afterwards we added new detections and we shifted some bounding boxes and our evaluation method by itself changed the size of this of this specific detector to be a little bit smaller and we came from a false positive to a true positive.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same with the next thoughts for its positive.",
                    "label": 0
                },
                {
                    "sent": "These are all very high scoring, false positive before.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you see that as well, we introduced the two new faces in the background and the false positive will be turned into a true positive.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we fixed the evaluation protocol and we can get back to our initial problem, which is we want to do face detection.",
                    "label": 0
                },
                {
                    "sent": "So we want to look into some baselines.",
                    "label": 0
                },
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Served that most methods are either based on Viola Jones.",
                    "label": 0
                },
                {
                    "sent": "Or",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Three based on DPM deformable parts model, so we wanted to have based my lines of these two categories.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As the data set, we selected the FLW data set and we cluster the data into five different fuels.",
                    "label": 0
                },
                {
                    "sent": "We have frontal faces, slightly rotated faces and lateral views on faces.",
                    "label": 0
                },
                {
                    "sent": "And then we transfer the deep.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And model here we used completely vanilla TPM default parameters.",
                    "label": 0
                },
                {
                    "sent": "The only thing that we changes instead of having a bounding box aspect ratio is less initialization.",
                    "label": 0
                },
                {
                    "sent": "We use your angles of the phases that we specified before.",
                    "label": 0
                },
                {
                    "sent": "DPM has been evaluated before on face detection on the FW data set and in the next slide.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You see?",
                    "label": 0
                },
                {
                    "sent": "The two solid lines are DPM evaluation, previously one from true at all in Cpl 2012.",
                    "label": 0
                },
                {
                    "sent": "An in magenta is our curve is shown.",
                    "label": 0
                },
                {
                    "sent": "And you can see that our curve is around 2.5% better than what was previously proposed, but this makes a lot of sense as we have now much better training data or more training data.",
                    "label": 0
                },
                {
                    "sent": "And we also use a newer version of DPM.",
                    "label": 0
                },
                {
                    "sent": "This type of graph have been proposed many times when people compare their baseline to DPM.",
                    "label": 0
                },
                {
                    "sent": "But now I can tell you that, but changing a single parameter in the in the evaluation of DPM you can come from this curve.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To this once and the parameter that we changed is just an unmarked suppression threshold.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we have a threshold of 0.5, we get this initial curves that we always see there are not so great in position, but if we change it.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example to 0.3.",
                    "label": 0
                },
                {
                    "sent": "Then our DPM method is not better than any other method in this data set, including methods that were initially built upon DPN.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This non Max oppression really matters a lot for the face detection and when you change the threshold you get really different curves.",
                    "label": 0
                },
                {
                    "sent": "For the SP.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sific case of DPM, we observed a lot of this overlapping detection, so we have a very high scoring detection on the center of the face and the second detection which is just big enough not to be removed by the non Max suppression and for TPM it seems that the cost for that information is really dominated by the appearance cost.",
                    "label": 0
                },
                {
                    "sent": "So you can just shift all the all the parts in words and you get the second detection which just has a slightly slightly lower score but it's bigger than the previous one and of course this messes up the evaluation and generates these false positives.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's go to the second baseline, which is based on Viola Jones.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here we use the integral channel features detector.",
                    "label": 0
                },
                {
                    "sent": "This is basically a more modern version of Viola Jones and the main difference is that instead of having only a grayscale image, we use a color.",
                    "label": 0
                },
                {
                    "sent": "Basically HTN color channels.",
                    "label": 0
                },
                {
                    "sent": "And we are very familiar with this architecture as we used it before.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We call this baseline square channel features five.",
                    "label": 0
                },
                {
                    "sent": "We use exactly the same training data with exactly the same views, and we trained our models.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also did a additional experiments on this data set to try to figure out what makes a face detector truly take.",
                    "label": 0
                },
                {
                    "sent": "So we evaluate the number of training samples, the number of templates, the influence of the color channels, how many weak learners do you need when you perform boosting?",
                    "label": 0
                },
                {
                    "sent": "The most important one here.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the number of templates and here it turns out that DPM actually saturates when you have to six templates.",
                    "label": 0
                },
                {
                    "sent": "It does not improve anymore quality when you give it a traditional.",
                    "label": 0
                },
                {
                    "sent": "For example rotated faces.",
                    "label": 0
                },
                {
                    "sent": "The square channel features set up on the other side really benefits if you give him rotated faces then other without having this in the training data, you cannot detect rotated faces that really benefits from it.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at the result.",
                    "label": 0
                },
                {
                    "sent": "This is other curves that you saw before on our new benchmark.",
                    "label": 0
                },
                {
                    "sent": "With the better annotations and at the moment structured model is the best performing method.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The promised some commercial products.",
                    "label": 0
                },
                {
                    "sent": "Here's face plus Plus in Picasa these are only dots because we don't have confidence value for this things.",
                    "label": 0
                },
                {
                    "sent": "But as you can see the clear clearly see that actions are the methods are tuned for high precision.",
                    "label": 0
                },
                {
                    "sent": "When we now look at.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our baseline from square channel features.",
                    "label": 0
                },
                {
                    "sent": "You can see that it's slightly better than the previous ones, and if we add the.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Umm, you see a big jump in quality, but as I said before, the components really matter for the square channel features.",
                    "label": 0
                },
                {
                    "sent": "So if we just rotate the data set so we augmented and get additional views on the data and we train another model which is again Viola Jones based on Richard template we get are fine.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Headhunter model, which matches the result of DPM.",
                    "label": 0
                },
                {
                    "sent": "On the F.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "W data set we observe similar things and this data set is more or less already exhausted, so there are most of the methods already reach more than 95% average position.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a sanity check, we did final evaluation on the FTP data set.",
                    "label": 0
                },
                {
                    "sent": "Here we did not change any annotations.",
                    "label": 0
                },
                {
                    "sent": "We did not use our evaluation protocol, we just used what they offered us.",
                    "label": 0
                },
                {
                    "sent": "This is slightly different curve that shows the false positive on the X axis and the true positive rate on the Y axis.",
                    "label": 0
                },
                {
                    "sent": "So we want to be in the upper left corner and as you can see as well here, our baselines perform really good.",
                    "label": 0
                },
                {
                    "sent": "We could not even use our system on this data set because the policy here is to share the precision recall curves directly, rather than the detection bounding boxes.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In conclusion, we release a new, more principled evaluation toolkit, new evaluation tool box with improved annotations for the most common datasets and the research systems are on par with.",
                    "label": 0
                },
                {
                    "sent": "In total we evaluated 6 commercial products and EPM and Richard templates can both reach top performance for the task of face detection.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As the take home message detection evaluation is really nontrivial and there are still many problems to be solved, and many people are facing exactly these problems that we quantified before, and also the baseline methods can be surprisingly effective.",
                    "label": 0
                },
                {
                    "sent": "If you really take care to train them properly.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thank you very much for your attention.",
                    "label": 0
                },
                {
                    "sent": "I want to say that resonates very well with how I feel about evaluation, and I think this bounding box approach in general is somewhat flawed.",
                    "label": 0
                },
                {
                    "sent": "Becausw the bounding box as a rule is somewhat of a matter of taste, and particularly when you deal with poses, it's not quite clear how to apply the bounding box.",
                    "label": 0
                },
                {
                    "sent": "Do you want to put it on the face or maybe around the whole head?",
                    "label": 0
                },
                {
                    "sent": "And I would like to make a suggestion.",
                    "label": 0
                },
                {
                    "sent": "Why not try to evaluate the ability of a detector to reconstruct the position of certain local features of the face, like the eyes or the mouse.",
                    "label": 0
                },
                {
                    "sent": "Eyes and mouse, for instance, maybe also knows these are just points.",
                    "label": 0
                },
                {
                    "sent": "There can be no ambiguity of where they are, and they are pretty robust against all kinds of poses.",
                    "label": 0
                },
                {
                    "sent": "So that means there is no pose where all these points project onto a single point.",
                    "label": 0
                },
                {
                    "sent": "So you can always kind of reconstruct the matching the scale, the orientation and so forth.",
                    "label": 0
                },
                {
                    "sent": "So so you're completely right about this.",
                    "label": 0
                },
                {
                    "sent": "The only thing is we wanted to use at the moment the existing data sets and they just don't.",
                    "label": 0
                },
                {
                    "sent": "Most of them just don't.",
                    "label": 0
                },
                {
                    "sent": "Content annotations for the facial points and as well this under.",
                    "label": 0
                },
                {
                    "sent": "To get this annotations.",
                    "label": 0
                },
                {
                    "sent": "Especially a lot of Labor work and you see already on if you just use simple bounding boxes for annotations, there are already a lot of errors in the data set, and I guess that these hours are even more severe if you use this facial points.",
                    "label": 0
                },
                {
                    "sent": "So yeah, if you can get a good data set with facial points annotated and it makes a lot of sense to change the metric for evaluation.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah.",
                    "label": 0
                },
                {
                    "sent": "When you have three points, for instance, you have only just one more coordinate.",
                    "label": 0
                },
                {
                    "sent": "You need to fix.",
                    "label": 0
                },
                {
                    "sent": "Compared to bounding box so it's not really much more work and I think as far as annotation is concerned, it's not really more complicated.",
                    "label": 0
                },
                {
                    "sent": "Thanks a lot, thank you.",
                    "label": 0
                },
                {
                    "sent": "Another question, there's a one question over there.",
                    "label": 0
                },
                {
                    "sent": "So as you point, is first of all great work.",
                    "label": 0
                },
                {
                    "sent": "As you point out, the datasets available are almost saturated for the current detector, so it would be important, I think to.",
                    "label": 0
                },
                {
                    "sent": "Understand if the problem is solved or whether there are interesting pockets where we're not doing well yet, so to give an example when Petrodollar did his benchmark on pedestrian detector detection he looked into where do current methods fail and he identified a couple of places.",
                    "label": 0
                },
                {
                    "sent": "One is highly blocked out or highly occluded pedestrians and one is pedestrians that are smaller than 50 pixels and both of them there is a big difference between human observers and the current algorithms and so that was a useful outcome.",
                    "label": 0
                },
                {
                    "sent": "Do you have any observations about?",
                    "label": 0
                },
                {
                    "sent": "Sort and you have any proposal how to create new datasets that challenges.",
                    "label": 0
                },
                {
                    "sent": "So first what we observed, we were really surprised face detection, which is around so long.",
                    "label": 0
                },
                {
                    "sent": "The data set are actually worse than where it will have for pedestrian detection.",
                    "label": 0
                },
                {
                    "sent": "So pedestrian detection we had actually much larger datasets and annotations had much better quality, so this was already surprising that this is not the case for face detection where you really would expect that.",
                    "label": 0
                },
                {
                    "sent": "And also of course we looked what's going wrong now, and it seems that it's in fact the case that most of the method detect like 80% of the face is really well.",
                    "label": 0
                },
                {
                    "sent": "And then the differences are just in the occluded cases in a very small cases and defocused faces and these things.",
                    "label": 0
                },
                {
                    "sent": "So I think there should still be some evaluations for phases as well, how?",
                    "label": 0
                },
                {
                    "sent": "The specific issues of the different methods and on what their struggle here.",
                    "label": 0
                },
                {
                    "sent": "OK thanks Marcus.",
                    "label": 0
                },
                {
                    "sent": "Will have to move on then, thanks.",
                    "label": 0
                }
            ]
        }
    }
}