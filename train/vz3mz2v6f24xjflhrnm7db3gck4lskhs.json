{
    "id": "vz3mz2v6f24xjflhrnm7db3gck4lskhs",
    "title": "Subgroup Discovery: Recent Biomedical Applications",
    "info": {
        "author": [
            "Nada Lavra\u010d, Department of Knowledge Technologies, Jo\u017eef Stefan Institute"
        ],
        "published": "Jan. 10, 2008",
        "recorded": "January 2008",
        "category": [
            "Top->Biology->Human Biology",
            "Top->Computer Science->Decision Support",
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/solomon_lavrac_sdrba/",
    "segmentation": [
        [
            "Thank you for being here.",
            "So today's talk is about subgroup discovery.",
            "This is a topic of research which has been around for about five years, and the use of Stephen Institute and I will present some results.",
            "Some methods as well as some recent biomedical applications."
        ],
        [
            "The talk outline first, very briefly, about data mining, subgroup discovery, and then I will switch to relational data mining and propositional azatian approach and then present some applications of the subgroup discovering algorithm SD in DNA microarray data analysis and then propositional isation approach to subgroup discovery applied in the analysis of differentially expressed genes.",
            "Then there will be at the end one slide towards service oriented knowledge technologies for information Fusion."
        ],
        [
            "So data mining in a nutshell, we are given transactional database database.",
            "So one Excel table for instance and then through data mining we're trying to extract interesting patterns or models and this data can be typically either simple relational table or something more elaborate like a relational database, text, documents, web pages.",
            "So the problem is to find either a classification model.",
            "Or a set of interesting patterns."
        ],
        [
            "The data.",
            "So once we get such a model, we can use it for classification of new instances.",
            "We get a classified instance and it can be either a black blocks classifier which doesn't provide any explanation, or it can be a symbolic model, which in addition to classifying instances, can provide also the explanation.",
            "We can also induce some interesting symbolic."
        ],
        [
            "Patterns.",
            "So well, you have all seen this example.",
            "It's about data mining.",
            "Example about contact lens data.",
            "We have instances 24 instances about patients coming to an optician who prescribes contact lenses, either soft heart or no contact lenses at all.",
            "And there are four attributes describing the patients."
        ],
        [
            "And we can induce tighter decieve."
        ],
        [
            "Country.",
            "A set of rules which."
        ],
        [
            "Are used for classification.",
            "Well and we can reformulate also this task differently into a concept learning task.",
            "Before we had three different possibilities for target classes which were soft, hard and no lenses, here we have reformulated the problem into a two class classification problem where we have just yes and no.",
            "Yes for prescribing contact lenses and no for no, no contact lens prescription.",
            "So this is a concept learning problem.",
            "Where we looking at positive examples versus negative examples.",
            "For instance, we can look at positive examples for prescribing contact lenses versus the negative examples when we don't prescribe any."
        ],
        [
            "Lances so subgroup discovery will be in the context of this."
        ],
        [
            "In this context of concept learning, therefore I have reformulated."
        ],
        [
            "Problem.",
            "Here.",
            "So if we look at classification versus subgroup discovery, we can see that the classification task aims at constructing a model from the data.",
            "For instance in the form of a set of prescriptive rules.",
            "So in this sense it is a form of predictive induction.",
            "Which is aimed at learning models for classification and prediction purposes.",
            "If we do such a model in the form of rules, this classification rules aim at covering only positive examples.",
            "In an ideal case, and this set of rules forms their domain model in subgroup discovery.",
            "On the other hand, we are interested in finding interesting individual rules, interesting patterns.",
            "Which are described in the form of individual rules.",
            "So opposed to predictive induction, this is a form of descriptive induction which is aimed at exploratory data analysis.",
            "So we're trying to find interesting patterns in the data.",
            "In this sense, it is not predictive.",
            "But Discriptive and it's as the rules are symbolic.",
            "We can use them for also explained which patterns have been induced from the data.",
            "So the subgroup descriptions aimed at covering a significant proportion of positive examples as opposed to the ideal scenario in classification rule learning, where individual rules would aim at classifying only positive examples when there is no noise in the data.",
            "So and here each rule describes an interesting pattern, and it is also an independent chunk of knowledge as opposed to hear where each rule depends on the other rules which have been induced and which former model."
        ],
        [
            "So if I illustrate this also on this slide in predictive induction, when we are building classification rules, we would like classification rules to cover all the positives and none of the negatives.",
            "In the ideal case when there is no noise and in subgroup discovery, we aim at covering many positives, but we allow some negatives to be covered as well, and this would be for instance, one rule which covers 4 positives and one negative, and then this rule could be.",
            "Covering two positives, one negative and so.",
            "So here if we illustrate it here, let's say subgroup discovery would find set of independent rules, some of them may only cover the positives, like this one or this one.",
            "Some may cover positives and some negatives, some of them may intersect, and so on."
        ],
        [
            "So this was very briefly about data mining.",
            "Now how do we?"
        ],
        [
            "Perform subgroup discovery.",
            "The task of subgroup discovery is to find from a set of labeled training examples.",
            "Such descriptions of most interesting subgroups of the target class examples which are large enough, which means high target class coverage and which have significantly different distribution of the target class examples.",
            "For instance, this can be measured by the high ratio of the true positives versus false positives or high relative accuracy or high weighted relative accuracy.",
            "High significance of such rules, and there can be also some additional other.",
            "Criteria of interestingness which are more of a subjective nature like.",
            "Rules could be surprising to the user.",
            "Simple, useful or actionable."
        ],
        [
            "So if we look at the one particular medical problem, the task being finding and characterizing population subgroups with high risk for coronary heart disease, the input are patient records described by some attributes from anamnestic stage of the analysis from an amnestic and laboratory and amnestic, laboratory and ECG attributes, and the output are the best subgroup descriptions that are most actionable.",
            "For coronary heart disease risk screening at Primary Health level.",
            "So why did I say here most actionable?",
            "It is not necessarily that if you perform subgroup discovery and optimize a certain criterion, these rules may be the best according to the particular heuristics, but maybe they may not be the most actionable for a certain purpose.",
            "For instance, in primary care scale, the most actionable rules would be such which required the least tests to be made, and with the least tests which are the least cost you could do the screening action.",
            "Based on that and you will see that."
        ],
        [
            "Actually, in this medical problem we have induced best subgroup descriptions.",
            "Five were only selected by the expert as most actionable, however there.",
            "Quality criterion was not the highest, but was just slightly less than the highest value of the quality criterion.",
            "So for instance, the first crew subgroup being group of patients characterized by the property that these are male patients, they have positive family history and age being over 46.",
            "So you see, it's a very simple rule, a conjunction of features, and at the conclusion site we have the target class which is.",
            "Coronary heart disease another rule.",
            "Female patients body mass index over 25 age over 60 three and so on and so on.",
            "So.",
            "No.",
            "It was chosen by the medical expert in this particular case.",
            "So action ability is an interesting concept.",
            "We have looked at that quite carefully.",
            "There is a notion of action ability with, which means that you can perform a certain action like select people for being screened for coronary heart disease.",
            "There is another option notion being operation ability and we have discussed test in our paper which was published in Machine Learning Journal in 2004.",
            "So you can if you're interested in this, most sub more subjective criteria of interesting this you could find.",
            "Some discussion on that in that paper.",
            "So these features have been proposed by the SD algorithm.",
            "And they are named in our approach.",
            "They're called principle risk factors or principal factors which are found by an algorithm for subgroup mining.",
            "In the work with the Dragon Gamberger, we have also developed the notion of.",
            "Additional explanatory power of subgroups which is called finding additional risk factors which are called supporting factors and they are found by statistical analysis.",
            "For instance, if we look at the first subgroup which is characterized by people who are male, have positive family history and age over 46 additional characteristic of this group of people.",
            "Which are significantly different from for this group of people compared to the other patients is that these patients also are prone to psychological stress.",
            "They are smoking.",
            "They have typically hypertension and overweight.",
            "So.",
            "Actually, not the conditions.",
            "In the rule define the subgroup.",
            "Now you look at this subgroup and now you look at all the attribute values for this subgroup versus all the other patients, and you see which of these features have significantly different for the subgroup versus the others.",
            "Two people in the body.",
            "Mass Index 25, which also constitutes overweight.",
            "Yeah, OK, so let me go.",
            "I think I have a slide on that."
        ],
        [
            "OK, so for instance, if we have a rule here, high risk for coronary heart disease, body mass index over 25 and age over certain C and other supporting characteristics."
        ],
        [
            "So how do we?"
        ],
        [
            "Find it.",
            "OK. We start from the you subgroup description and then we compute the statistical significance of all the available features.",
            "Given two populations, the true positive positive cases, which means coronary heart disease patients which are correctly included into the subgroup.",
            "Versus the negative cases, which are healthy subjects and then we simply do the high square test with 95% significance and those which are in favor which are characteristic for the subgroup are simply listed as supporting factors.",
            "In addition, we began that this support for this additional factor side not some significant as the one which formed the rule, but still yeah.",
            "So all the ones which are in the rule would also fulfill this criterion, but they have fulfilled also a different criterion, which is the one which is used for building the subgroups, and we will discuss this criterion as well.",
            "It's just this game.",
            "Yeah.",
            "It is true, but in practice all the all the factors which are there also statistically significant."
        ],
        [
            "For instance, if we would use CN Two, which uses the significance measure to build the bodies of rule, then they would for sure be there so.",
            "In our algorithms, which we have developed, which is as the algorithm uproariously which upgrades a priority for the context of subgroup discovery and CN, two SD which upgrades CN 24 subgroup Discovery, we have basically implemented awaited covering algorithm used weighted relative accuracy search heuristic with added example weights.",
            "And if I go a little bit back because I have skipped a number of slides I can explain.",
            "Some of this?"
        ],
        [
            "So if we look at the ASD algorithm.",
            "DSD well just let me still explain a little bit the difference between classification rules and subgroup discovery rules.",
            "Is the algorithm doesn't look for single complex rule which will describe all the examples of the target class, but it will build several rules like this.",
            "As he prefers rules which are accurate, covering patients of the target class and which have high generalization potential.",
            "And this is modeled by the parameter G of the rule quality heuristic, which I don't know whether I have it here.",
            "I don't think I have it here, so.",
            "The quality measure.",
            "Q used in the air as the algorithm is.",
            "True positives divided.",
            "Bye.",
            "False positives plus G. And we are trying to.",
            "For input those.",
            "Features.",
            "Which have a high value of this quality criterion.",
            "So the idea is that we are maximizing the true positive versus false positive rate, and then we have a G parameter, the larger G, the bigger is the generalization potential of the subgroup discovery algorithm.",
            "So we can have small G and we are really in that case maximizing TP versus FP.",
            "And with the Big G, we are given a bigger tolerance for false positives.",
            "OK, so if we now.",
            "Obviously this is the number of positives covered, the number of incorrectly covered negatives.",
            "You will see that we can naturally use example weights in the procedure for repetitive subgroup generalization via weighted covering algorithm and let me."
        ],
        [
            "Illustrate the weighted covering algorithm now.",
            "So suppose we have some patients positive examples in the data we have some negative examples in the data.",
            "Initially we set the weights of all examples to one.",
            "And now we learn the first subgroup."
        ],
        [
            "So, for instance, this might be a subgroup characterized by two features, feature two and features three.",
            "It covers 6 positive examples and one negative example.",
            "Now in the second step of the covering algorithm.",
            "Well, here is this first step of of the subgroup Discovery algorithm, so I have.",
            "Showing you this quality criterion through maximizing true positive versus divided by false positive slash G. Whereas in CN two SD we are maximizing the weighted relative accuracy.",
            "Which is computed as follows if we have a rule if condition then target class, it is computed as the probability of the condition times the difference between the prior probability of the target class.",
            "And the conditional probability of the target class given the condition of the rule.",
            "So we could call this relative accuracy of the rule.",
            "Because we are comparing the prior probability of the class and we are comparing it with the improved probability.",
            "Of the class, given the conditions of the road, so we could also say, well, is the condition of the rule really characteristic for the target class?",
            "If it is, then this difference will be large.",
            "We could optimize just this difference if we were at optimizing this.",
            "Rule accuracy, however, it turns out that if we want to have large subgroups then it is good to have a weight which will give additional weights to subgroups which are large becausw.",
            "The probability of the condition actually tells you how large is the subgroup it is proportional to the size of the subgroup.",
            "So we could interpret this formula which is called weighted relative accuracy like.",
            "Coverage times precision means minus default precision.",
            "And if you look if you do a little bit of manipulation of this formula, you can see that this is proportional to the difference between the true positive rate and the false positive rate.",
            "So this is the formula which is used in the CL2 SD algorithm, whereas this is the formula which is used in the SD algorithm.",
            "So you will see that here we have true positives.",
            "Here we have true positive rate and he we divide true positives with the false positives and we here we look at the difference between the two.",
            "OK, now that we have learned the first subgroup.",
            "Yeah.",
            "Minus.",
            "Times.",
            "How do you get from one step to another?",
            "Oh, you mean here?",
            "From here to here?",
            "So P of count is the true positive divided by an OK. Oh probability of the class given the condition.",
            "I would need to look into this, but it is the case.",
            "So it should be one additional slide which would tell you how exactly you get to that."
        ],
        [
            "OK, so now now that."
        ],
        [
            "We have learned the first rule.",
            "Which covers some positives and some negatives.",
            "In the second iteration of the weighted covering algorithm, what do we do?",
            "We decrease the weights of the covered examples just in order for the algorithm to search the other part of the search space as well.",
            "And by."
        ],
        [
            "In doing so, for instance, we can do it by decreasing simply to value 05.",
            "Now the algorithm will search.",
            "More in this part of the space or here and not that much here.",
            "Because now in all the our formulas."
        ],
        [
            "We actually have computations which.",
            "Talk about the number of numbers of instances like 2 positives being a number of instances now instead of these numbers, we simply use the weights and by that we model."
        ],
        [
            "This.",
            "That is how we implement the weighted covering algorithm."
        ],
        [
            "OK, so now we have developed some approaches to subgroup visualization.",
            "This is actually an approach developed by Petra.",
            "We have positives and negatives and here we have subgroups and we just show what is the proportion of covered positives versus covered negatives.",
            "Here we can show let's say if this is the set of all instances and this is the initial distribution of positives and negatives with the first Group subgroup which is illustrated here.",
            "It is quite large and it has a significantly different proportion of positives versus negatives compared to the initial distribution.",
            "On the other hand, the group A2 which is characteristic for female patients, it is relatively small, but its proportion of positives is significantly larger.",
            "And these are the three other subgroups which were evaluated by the expert as being actionable and interesting."
        ],
        [
            "The endless.",
            "OK, I have already explained the supporting factors, how they are computed.",
            "So in this particular application we had five subgroups which were chosen as most actionable and for each of them we have also computed the supporting factors.",
            "So why are the supporting factors really interesting in the work of Canonico and colleagues?",
            "It turned out that.",
            "Medical people don't like.",
            "Short rules, so they also don't like decision trees cause the decision trees only take into account a couple of attributes, but on the other hand they very much like the Bayesian classifier which says for every feature basically whether it speaks in favor or in contrast of a certain diagnosis.",
            "And we view this approach as a kind of halfway of the of both worlds.",
            "We say these are the most important factors.",
            "But these factors also provide some additional explanatory potential.",
            "And actually, with the people we choose with whom we worked with medical experts, they quite liked the supporting factors in addition to the principle factors explaining the subgroups.",
            "OK."
        ],
        [
            "I have explained this already.",
            "So the lessons learned in the development of subgroup discovery algorithms.",
            "Oh all these algorithms.",
            "Well, as the algorithm is expert guided, which means that the G parameter which is used to model how large the subgroups will be and how many false positives are tolerated.",
            "So this G parameter is part of the algorithm which is set by the user.",
            "In addition, in this expert guided framework also, the expert chooses the most actionable rules.",
            "Weighted covering algorithm for rule subset construction.",
            "Using decreased weights of covered positive examples, it turns out to be useful when constructing a set of relatively independent subgroup descriptions.",
            "And this additional evidence, in the form of supporting factors, increases the experts confidence in the rules resulting from automatic discovery.",
            "Value added here is subgroup visualization."
        ],
        [
            "Now I will switch from propositional data mining to relational data mining."
        ],
        [
            "So until now, in our data mining approach we had here a single table from which we have induced a model or a set of interesting patterns.",
            "On the other hand, in relational data mining we have a slightly more complicated situation.",
            "Here we have a relational database or a set of relational tables which is linked which are linked, and we use a relational data mining algorithm to induce a model from that data or some interesting pattern.",
            "So this week and have now a relational database, set of tables, set of logical facts, maybe a graph structure, and the intention is to build a classification model or a set of interesting patterns."
        ],
        [
            "So let's look at some examples.",
            "So maybe we are looking at molecules which may be mutagenic or non multigenic.",
            "So we have two classes of molecules between which we would like to distinguish.",
            "So a molecule is a complex structure consisting of atoms.",
            "So each molecule can consist of one or more atoms.",
            "Each Atom can be connected to other atoms through bonds.",
            "And.",
            "Atoms have some properties and molecules have some properties, one of them being to which class it belongs to, like being with a genie or non multigenic and there are some other properties describing the molecules.",
            "So such complex data.",
            "We have we can model it through.",
            "We can describe this in multiple tables.",
            "Or this would be the entity relation diagram for such a relational database.",
            "So complex relational problems involve temporal data like type series in medicine, traffic control, structured data like representation, representation of molecules and their properties.",
            "In very chemistry and so on.",
            "So I will describe an approach to relational data mining through propositional isation, and for that I will use a very simple example about trains.",
            "They come from Richard Michalski in the 80s, where he has described a complex problem of true."
        ],
        [
            "Things going."
        ],
        [
            "East or going West.",
            "Which are described by some properties.",
            "So let us look at 1 train."
        ],
        [
            "Just let's go back in the sense that we have a train.",
            "It's classes direction.",
            "Some trains are going East, some trains are going West.",
            "Train has car.",
            "One or more cars.",
            "Each car has certain properties like shape of the car length, roof wheels and it.",
            "It can carry loads and each of the loads can be can have some characteristics.",
            "For instance, what is the shape of the load, how many loads the card is?",
            "How many loads are on a car and see similar properties?"
        ],
        [
            "So we will show how the RSD algorithm works, which upgrades CN two SD to context of relational subgroup discovery.",
            "It uses a propositional azatian approach by First order feature construction, and then once done a substandard subgroup Discovery algorithm is used to induce rules."
        ],
        [
            "So if we go back to this particular example of trains.",
            "We have 10 trains.",
            "For each train we know to which class it belongs to, we said that the class is going East or going West.",
            "So if we say eastbound trains are the target property, which we would like to analyze and for which we would like to find rules about trains going East.",
            "So we are classifying this examples as positive and the other five examples as negative examples.",
            "So if we look at this train T1.",
            "We can see that the train T1 has four cars.",
            "Car one is of rectangular shape.",
            "It is short.",
            "It has no roof and it has two wheels car, two rectangular shape, long card, none roof and three wheels.",
            "That is this car and so on.",
            "So as you see.",
            "No, we can in this representation when we have put the trains in one table together with the class.",
            "And then we have another table where for each train we can have descriptions of several cars and we can have a variable number of cars per trains, which is something which we cannot easily represent in a propositional representation within a single table.",
            "Now, each of these cars can have loads like car one.",
            "As a single note cartoon.",
            "Yes, also one load cars 3 has one load whereas car four has four loads.",
            "OK, so how can we transform such a multi relational representation into a single table representation?",
            "We do it as follows.",
            "Each line here corresponds to one instance.",
            "And so it will be also in this derived representation.",
            "Each train will be.",
            "Described by one line in this propositional table, which we are constructing.",
            "Now what can we do?",
            "We will now try to build features.",
            "Which will talk about properties of these strings and these features will have to talk actually about the properties of the cars which constitute the traits.",
            "So we will try to find such features.",
            "Whose properties will be will be characterized, the trends, and then the values of these features will be either true or false, so this will be logical features with values true and false.",
            "So this approach was developed in the early 90s and it has been continued later from starting also with the work of teaching cardio then alignments and then later in the real."
        ],
        [
            "National subgroup Discovery algorithm RSD.",
            "So how do we build firstorder features from?",
            "Such properties of cars.",
            "Now we will say, well.",
            "The feature will be such that.",
            "The feature of a train is that it has a car which has.",
            "Length short.",
            "So we could say this feature talks about trains and it says well feature train.",
            "Train has a car which is short.",
            "Or this one?",
            "A train has a car which carries a lot of circular shape.",
            "So if we look at it from the logical perspective, what have we done?",
            "We have built a close.",
            "In the head of the cloth we have a predicate which is actually a feature.",
            "This predicate talks about the property of this variable, so it is a prolog notation.",
            "In Prolog notation, we're using capitals for variables and variable stands for a train.",
            "And now in the body of the clothes we have used this universal variable becausw.",
            "You can read this for every T it holds that F1 of T if there exists variable C. And now this is an existential variable.",
            "So we are looking whether Train has a car, whether there exists such a car with the property that it is short.",
            "And through that conjunction of features.",
            "We have actually built.",
            "A conjunction of these two features tells us something about the property of this universal variable T. Another feature.",
            "For every teeth, does there exist AC?",
            "Such debt for this particular see there exists an L which is a load which is of circular shape.",
            "So now the art of transforming the.",
            "Multiple table representation into a single table representation.",
            "It is about can we find such interesting features which will be characteristic for trains and which will be able to distinguish between eastbound and westbound trains.",
            "So if we look at the first one.",
            "This feature said, does there exist a car whose length is short?",
            "If we look at the car train number one?",
            "We will see that.",
            "This feature is true."
        ],
        [
            "Becausw the train has a car.",
            "Which is short.",
            "So the this existential condition has been satisfied.",
            "Therefore the value of feature one is true.",
            "The value of feature one for train.",
            "Well, I don't have all the trains here, so I can't check whether this is true or not true for the other trains, but you should believe me.",
            "So for train one let's say feature 2 feet."
        ],
        [
            "Two was.",
            "Whether there exists a car which has a load which is of circular shape, let's see whether it is."
        ],
        [
            "Before train one.",
            "It has a load.",
            "It has a car which has a load of circular shape.",
            "That is true.",
            "So the value of this feature is true.",
            "Now you can imagine that you could build very many features of that kind.",
            "And the approach which is implemented is that we have."
        ],
        [
            "Feature construction algorithm which will.",
            "For a given universal variable construct, first introduce.",
            "Such a property about the individual T which will introduce an existential variable, and then we will add such a.",
            "Determine which will.",
            "Give a value of the logically introduced existential variable C. We will do it within a certain language.",
            "Bias this language bias can be such that you only allow let's say up to five literals to be added to the body of a clause.",
            "Or it can allow just one existential variable to be introduced, or maximally two existential variables to be introduced, like in this case C&L.",
            "Or it can be such that you put a certain constraint on the coverage.",
            "So such a feature or conjunction of features should be such that it covers at least a minimal number of positive examples, so you can put such constraints on this feature generation algorithm.",
            "And then obviously, instead of having just a couple of features describing trains, you will have now.",
            "Number numerous features and well, it is upon the user to decide what constraints to be put on the feature generation."
        ],
        [
            "Algorithm.",
            "So in the ZND algorithm, which has been developed in the 2002 and published in Journal in 2006.",
            "We are implemented this propositional isation approach to relational learning through very efficient 1st order feature construction.",
            "It is a syntax driven approach using Prolog slash LF kind of declarations.",
            "We build such 1st order features like for instance for molecules.",
            "For a molecule M, does there exist an Atom Atom a which is of a certain type or for a molecule?",
            "Does it have a property of LUMO big of?",
            "Whose value is less than a certain value.",
            "Through that we can then build these features."
        ],
        [
            "Then if we now have such a representation, you can see that we can use whatever machine learning algorithm which is appropriate for propositional learning.",
            "We can also use either classification rule, learning algorithm or subgroup discovery algorithm, and if we use this."
        ],
        [
            "Subgroup discovery algorithm like C and two we can get such subgroup descriptions like molecule is mutagenic.",
            "A certain feature feature number 121 is true and the feature 102 hundred 235 is true.",
            "Whatever these features actually are, there are some conjunct of features about the molecules and atoms and bonds and things like that."
        ],
        [
            "So the.",
            "Construction goes like that.",
            "We will first build the first literal such that it includes one free global variable like train like for every train.",
            "Teak would be the free global variable.",
            "And then we introduce one or several structural predicates like has Atom or has a car which introduced new existential local variables like Atom here or car in the case of trains.",
            "And then using either the global variable or a local variable introduced by the local variable.",
            "So like we had here, molecule Atom was the local variable introduced and now we could have another local variable introduced by this one like in the cars example we had cars.",
            "We in the trains example we had cars and the cars could introduce a new variable being loads.",
            "And then finally we can have one or more utility predicates which define the properties of individuals or their parts, assigning values to the variables.",
            "So for instance, like here here we assign value 21 to variable R. Through this literal.",
            "So if we have now this feature and another feature our subgroup discovery, we can be described with these two features of the molecule."
        ],
        [
            "So let's now go to the applications.",
            "DNA micro array data analysis with the as the algorithm we are now in the propositional case, not in the relay."
        ],
        [
            "Data mining case.",
            "So we're looking at the problem from functional genomics and the problems is here we are studying genes and their functions, and typically there is a very large number of attributes, namely genes relative to the relatively small number of examples or observations, and this is usually for machine learning, not a very favorable setting.",
            "So for instance we may have just 50 or 100 examples described by several thousands of attributes.",
            "Or jeans.",
            "So what we are doing here we are trying to better understand biological pro properties and process is through."
        ],
        [
            "DNI microarray DNA analysis.",
            "So typically we would have a situation like that we would have.",
            "We would transform this into.",
            "Oh the form appropriate for machine learning.",
            "Each of these.",
            "DNA would be.",
            "Micro each of the micro race would correspond to one line.",
            "Some of them are characterized for certain types of tumors.",
            "And then we have certain values for individual genes like maybe we have 10,000 genes.",
            "And we have now one line per microarray.",
            "Experiment.",
            "Uh huh.",
            "OK."
        ],
        [
            "So the standard approach to the analysis is that we are using people use neural networks, support vector machines or combination of different classifiers.",
            "To learn a model which will be able to distinguish between different types of tumors.",
            "So and then for a new sample, you put it into this black box classifier and you get.",
            "An answer whether it is a certain type of."
        ],
        [
            "Cancer or some other type of cancer.",
            "Usually these models have relatively good predictive accuracy.",
            "They are relatively resistant to overfitting, especially if you use in samples of such strong classifiers.",
            "But this black box models are very hard to be interpreted or impossible to be interpreted."
        ],
        [
            "Therefore we are using a different approach.",
            "We are using an approach through subgroup discovery from DNA microarray data.",
            "In our first work, we used the problem of Gollop.",
            "Where we were distinguishing between examples of AALL.",
            "Leukemia versus AML leukemia and we had 27 samples of this.",
            "111 samples of the other ones and there are three 3734 samples in the test set.",
            "Every sample is described with gene expression values of over 1000 genes.",
            "Another problem we have analyzed with this approach is the problem of distinguishing between 14 different types of cancers.",
            "In total there were 144 samples in the training set and 54.",
            "Compass in the independent test set.",
            "Every sample was described with gene expression values with over 16,000 genes.",
            "So this is a well known problem."
        ],
        [
            "Grab the nature by Gollop and colleagues.",
            "We use the SD algorithm.",
            "And we got such rules.",
            "Like if a certain gene.",
            "Is over expressed and another gene is not expressed, then this is characteristic for leukemia and the classification accuracy on the training set it would cover.",
            "It would be covering 23 positives out of 24.",
            "And it would be relatively good also on the test set.",
            "So the advantage here is that you can get."
        ],
        [
            "Interpretable descriptions of these groups.",
            "And this if then rules are actually interpretable, so.",
            "We cite the medical expert the best scoring rule for leukemia shows that expression of a certain.",
            "Gene, whose relation to the diagnosis is directly explicable.",
            "The second condition, which is."
        ],
        [
            "This one."
        ],
        [
            "According to the expert, it is an in team.",
            "Its elevated expression has not been found in brain tumors and this cancers.",
            "While this one the same condition has not been to our knowledge associated with Leukemia's.",
            "So this second condition turned out to be interesting piece of information."
        ],
        [
            "For the medical expert.",
            "OK, so through some good discovery we have.",
            "Found logical rules which are easily to be interpreted.",
            "We have also taken care to avoid flu cruise through a mechanism of.",
            "Handling.",
            "Such situations, but these obviously are still inferior in terms of accuracy compared to the."
        ],
        [
            "Complex classifiers.",
            "Unable to find any rules before new Xbox or this will just be confirmation of fire.",
            "In most cases it was re confirmation of what they already knew, but this particular rule was very interesting to the expert.",
            "What's new, yeah?",
            "So if we now switch to the more complex situation where we would have a relational representation of the data.",
            "And we are now trying to find descriptions such that we will try to analyze genes which are differentially expressed between different types of."
        ],
        [
            "Answers.",
            "So we have now this dilemma whether we are building interpretable rules which are less accurate.",
            "Or can we do something about it?",
            "Trying to build accurate rules and then explain them simply by using subgroup discovery approach?",
            "So actually this was done in this second experiment.",
            "So in the first learning phase we built descriptors which will separate positives from the negatives.",
            "Let's say a certain type of cancers versions.",
            "All the other types of cancer.",
            "We use this for classifying instances, and now that we have such a classifier distinguishing.",
            "Positives from negatives.",
            "We will now transform the learning problem as follows.",
            "We will first learn an accurate classifier and then we will learn comprehensible summarization's of genes.",
            "Which are characterized for a certain type of flick tissue versus all the other genes.",
            "So this learning two phase.",
            "What happens here is that we now transform the problem in such a way that instances become the jeans, not the patients.",
            "So initially we have a very small number of patients describe the very large number of genes.",
            "Now that we have made learn the classifier, we are now know which genes are characteristic for certain type of tissues versus other genes.",
            "We are.",
            "These are maybe large numbers of such genes which are characteristic.",
            "And I would we would like to find interpretable characterizations of these sets of genes, which are typical for certain types of tissues.",
            "In this learning two phase which can be viewed as a phase of exploratory data analysis, we can build such rules like genes encoding for proteins located in the integral membrane, rather whose function includes repertory activities.",
            "This is an interpretation of the set of genes which are characteristic for certain types of tissues.",
            "So how should we now build such?"
        ],
        [
            "Rules.",
            "So.",
            "The typical problem is finding, let's say groups of genes which would be overexpressed for some tissues and not for the others, and compare it to the other groups of genes."
        ],
        [
            "So that is the standard problem.",
            "And if these are characterized for certain cancer, and these are characterized for other types of cancer, we would like to identify differentially expressed genes.",
            "Like for instance this one.",
            "Gene, I would be typically characteristic for class I.",
            "And we do that with simple T test.",
            "Finding which are the genes which are characterized."
        ],
        [
            "Check for certain types of tissues.",
            "So when trying to identify differentially expressed genes, we would like to see whether they are indeed differentially expressed between this class and this class.",
            "So in this case we would say yes.",
            "These genes are differentially expressed.",
            "In this case we will also say they are differentially expressed, whereas here the difference is not large enough.",
            "We are testing this through the T test.",
            "And through that we will distinguish the most differentially expressed genes."
        ],
        [
            "Maybe this would be the first.",
            "100 most expressions which have been identified they are identified through T tests.",
            "They have a certain score and we would say, well, these are overexpressed and all the others are not overexpressed, and we would like to characterize groups of genes which are over expressed through their characteristics.",
            "So this would be this learning two phase.",
            "Of which I have descri."
        ],
        [
            "Did before.",
            "So what can we do now?",
            "Well, if a certain gene is interesting because it is highly ranked according to the test.",
            "However, search such a gene, which is less highly ranked could be also interesting.",
            "Becausw although it has a lower P value.",
            "It could be interesting becausw this gene could interact with some other gene and because of that interaction his interesting needs may arise.",
            "Although according to the T test."
        ],
        [
            "It is not that interesting.",
            "So what are we doing here in this second phase?",
            "We're trying to find group of genes.",
            "Which largely overlap with those associated with the classifier for the given class and can be compactly summarized in terms of their features.",
            "Now what are the features?",
            "The features are the attributes of the original attribute of the original instances, namely the jeans, and then we have first order features which are extracted from the gene ontology and the other databases like go on three and cake.",
            "So this is now the work done together initially with Philip jealously and then."
        ],
        [
            "Eagle Tri Kolski did this work further in his PhD thesis.",
            "OK, so gene ontology.",
            "We have genes.",
            "And we have their hierarchy.",
            "According to their functions, we have one part of the Gene Ontology talking about the processes and one part of the gene ontology about the components.",
            "So the functions, what does the gene?",
            "Product do the process is why does it perform a certain activity and where does it act?",
            "So this is these are the numbers of processes, components and functions which are encoded in the gene ontology currently.",
            "We have an SA and part of our the relations here, so amino acid metabolism.",
            "Is.",
            "Subpart of amino metabolism of this particular genes.",
            "So the level represents the specificity."
        ],
        [
            "Off turns into Gene Ontology, so if you look at the one part of the gene ontology, it could be viewed like that.",
            "We have processes, components and functions."
        ],
        [
            "If we look at this representation from the multi relational perspective, we have the main table which is about genes.",
            "We have gene gene interactions and then we have.",
            "These properties in individual tables talking about functions, processes and components."
        ],
        [
            "OK, so how do we transform this representation into a prolog representation?",
            "We have some genes which are differentially expressed.",
            "This would be the jeans which are at the top 50 of the jeans or top 100 of the jeans.",
            "They would be classified as differentially expressed.",
            "The other genes would be considered random genes which don't have anything to do with the specific type of tissue with a specific type of cancer.",
            "And then we have information about the components.",
            "So this particular gene.",
            "Is a component of this gene gene ontology term.",
            "It is it has a certain function annotated with this term in the gene ontology.",
            "It belongs to a certain process annotated in the gene ontology, like that and Inter it interacts with some other genes."
        ],
        [
            "Now we perform 1st order feature construction.",
            "Feature about a particular gene.",
            "It is feature #7, for instance says well, this gene has a particular function annotated by this particular Geo term.",
            "Or it has a certain process?",
            "Or it?",
            "This is already a more complicated 1st order feature.",
            "Gene.",
            "Has a circle function and it.",
            "He's annotated by this gene.",
            "Ontology term representing a certain process or even more complicated feature.",
            "Gene A interacts with gene B.",
            "Whose function is annotated by this Geo.",
            "Term, and this B belongs to this process annotated by this particular term.",
            "So these are the simple.",
            "Features which don't introduce any existential variable, and these are more complex features.",
            "Because we have introduced existential variable naming another gene which interacts with the gene which we would like to analyze.",
            "So if Gene A was overly expressed.",
            "It is not necessarily that actually Gene B was also overly expressed like in the first 50.",
            "Through that we have introduced a connection with some gene which might be among the random genes.",
            "But because of this interaction.",
            "And be cause it has a certain function and belongs to a certain process.",
            "This gene B has also become interesting and important for analyzing the overly expressed genes through their interaction with these other."
        ],
        [
            "No, again the same as before.",
            "This would be the most the overly expressed genes.",
            "Each of them described with this first order features these first order features are either true or false.",
            "We look at them, we evaluate them being either true.",
            "Or force.",
            "And this would be some of the non differentially expressed genes like randomly sampled genes from the set of non overly expressions and actually in the experiment figure.",
            "These were 50 most topmost expressed overly expressions, and these were 50 randomly sampled jeans from the other set of genes."
        ],
        [
            "We now use subgroup Discovery algorithm, which will now for instance build a conjunction of features feature two and features three covering 4 out of 50 overly expressed genes and none of the random genes."
        ],
        [
            "Now again we use weighted covering algorithm to."
        ],
        [
            "Find a set of rules or a set of subgroups.",
            "In RSD we are using CN Two SD algorithm which again has this weighted relative accurate."
        ],
        [
            "See heuristic."
        ],
        [
            "And then we built these rules.",
            "So if we look at some rules which have been constructed.",
            "One constructive truth is that we have found a group of genes.",
            "Which interact with this G, which is an existential variable whose function is protein binding.",
            "So G interacts with another gene whose function include protein binding.",
            "And distant describes a group of genes which have been now discovered into it."
        ],
        [
            "Which can be logically interpreted.",
            "We have used this approach in several databases, so one is this gold database distinguishing between LL type of tumor versus AML.",
            "Then we had several subtypes of LL and also this 14 cancer types which I have introduced before in the experiments with the SD algorithm.",
            "In all these experiments, as I said, we selected a set of most differentially expressed genes, the highest score and the same number of randomly chosen, non differentially expressed genes.",
            "And this was the setting.",
            "For our experiments."
        ],
        [
            "So this would be some of the rules describing subgroups of genes which have turned out to be of interest.",
            "For instance this one.",
            "Gene A, which interacts with B&B belonging to this particular process.",
            "So this one covers 12 of the over the expressions and none of the non over the expressions and similar."
        ],
        [
            "Also, these rules have been evaluated."
        ],
        [
            "The medical expert.",
            "It turns out that if we use all the information which includes information from the gene ontology, including the interaction and as well as weights of examples, if we use all this information, we get better results than by excluding any of these types of information in our."
        ],
        [
            "Journalists in recent work.",
            "We have developed an approach which is called search for enriched gene sets.",
            "This is the second method developed by eager try Kolski in his PhD thesis.",
            "This method overcomes the problem of fixed thresholds which we have used in the first method in the first method, we say 50 most expressed genes and others are considered random genes or non overly expressed and in this method eager has taken an approach which is known from bioinformatics and this approach avoids the fixed threshold.",
            "The problem of the fixed thresholds when determining the over the set, the number of over expressed genes."
        ],
        [
            "So if we try to summarize this approach presented with the ZND algorithm, this method provides.",
            "It is a method which adds interpretability to this high dimensional gene expression classifiers.",
            "And it employs the idea of.",
            "Using a sequence of two data mining task first being a predictive classifier, construction.",
            "In our case very simple predictive classifier construction just distinguishing between overly expressions and those which are not, and then in the second step trying to explain groups of this overly expressions through descriptive subgroup discovery.",
            "We have done that by integrating the information which is available in public databases, in particular in Gene Ontology entries and cake."
        ],
        [
            "So what is the idea of the future work?",
            "So in the this approach of two step learning?",
            "We have developed a workflow for that which is implemented in the algorithms of eager try kolski in his PhD thesis.",
            "We see that this workflow can be generalized as a general machine learning workflow for types of problems where we are dealing with ranking.",
            "So in ranking problems we are trying to distinguish the highly ranked instances compared to those which are not highly ranked.",
            "And if our if we have some publicly available information in terms of ontologies, we could use the approach which has been presented in this.",
            "Presentation to get the explanation in addition to the differentiation, which is the original task.",
            "In the coming week we are planning to organize.",
            "We are actually organizing a workshop which we will name the service oriented Knowledge Technologies Workshop.",
            "The idea is that in the first step we will implement this workflow of.",
            "In the gene sets.",
            "In service oriented architecture.",
            "So we will have a web based algorithm which everybody will be able to use.",
            "You could try Kolski has also downloaded.",
            "He has a script which downloads the current version of all these ontologies which can be then used for the interpretation.",
            "And then in the future we would like to implement some other modules of the algorithms like the subgroup discovery algorithms which we have developed at the user Steven Institute.",
            "Maybe also some of the modules from decision support.",
            "Maybe some of the modules description of such as group.",
            "We would like to implement in this.",
            "Architecture, which could be a potential step towards new data mining tool box available on the web as opposed to waka and Orange which are simply downloadable machine learning algorithms.",
            "So today's lecture is the first lecture in the series of events in the.",
            "The coming week, two weeks until January 18.",
            "It will be a small workshop and people will from basically from.",
            "Vidant Massage and Petra and your own and puncture will participate together with Martin and Marie, who will also look at this approach to.",
            "Web based toolbox development, which might be one of the goals of our future work.",
            "OK, with this I would finish this talk and I'm prone to questions.",
            "Yeah, it's.",
            "Of course, that was initial work which has motivated our work, but now it is quite lively.",
            "There is Martin Alice Miller, who is doing full-time research on suburb Discovery.",
            "There is arnac number who is doing full-time research in this area and at least one or two more people Patreon.",
            "Maybe you could help me.",
            "OK, well for instance I have just reviewed the subgroup discovery paper for Christmas, so it's quite lively.",
            "Also, our recent work is pretty interesting.",
            "We are now about to submit a paper to Journal of Machine Learning research together with Jeffrey Web where we have compared subgroup discovery with contrast set mining and emerging pattern mining and it basically turns out that these three.",
            "Areas of research are very strongly related, and basically you can transform one to the other.",
            "Now if you see it from this broader context, you could see that a lot of people are doing this kind of research.",
            "Lots of people are doing emerging pattern mining.",
            "Quite some people started to do contrast set mining recently, and there are some people working on subgroup discovery as well.",
            "So we recently have called this descriptive supervised descriptive rule induction and it is a generalized framework for which incorporates all these three sub areas of data mining research.",
            "In terms of software.",
            "Work with feeling.",
            "Jealousy is downloadable.",
            "It is there, but it's very hard to use because it uses Oracle database and you can't get it simply.",
            "So we had a lot of trouble getting it and having it.",
            "Operational and things like that.",
            "Well, Bronco headed here for awhile and I don't know exactly what is the state of the art.",
            "So Peter has developed his implemented the three algorithms as DC and two SD and a priority as D in the orange toolbox.",
            "So this is operational.",
            "The problem there is that the internal representation is not feature based but it is attribute value based which actually means that these implementations are.",
            "Actually different from the other implementations, but they are operational and at hand.",
            "The work by.",
            "Close game.",
            "Could actually be also be continuous targets.",
            "Is there any of them being followed?",
            "Well, we are looking only at binary classes.",
            "I don't know the answer.",
            "You had a comment.",
            "Yeah.",
            "If you look at from far enough.",
            "It is described in the hasty and Tipsy Ronnie Book and it actually looks at the rectangulars rectangles of instances which could be interpreted as subgroups as well.",
            "And well, there is also work of Suzuki.",
            "Exception rules well.",
            "Quite a lot of related work, but not exactly subgroup discovery.",
            "Yeah.",
            "I have a question about the.",
            "When you're searching for this gene.",
            "Well, obviously we're not overfitting because our heuristic is not intended at overfitting because it is a tradeoff between coverage and precision, so it is quite vague.",
            "It doesn't optimize the accuracy gain.",
            "So we made.",
            "So we basically don't overfit, I would say.",
            "Your wife is.",
            "Let's say without reduction in data because there are many if you combine certain genes in such a small data set and enter the same information, yeah, well, that is a good question.",
            "So let's say once you have generated many subgroup descriptions, what do you do with that?",
            "So.",
            "Our current approach is that either we generate all of them within certain constraints and then we use this weighted covering algorithm in the post processing step in the sense that we first take the best rule.",
            "Then we delete.",
            "We reduce the weights of these examples covered by this best rule, and then we look at all the other rules and we rank them according to the weighted relative accuracy.",
            "But now with the decreased values of weights of instances of which have been covered by the first rule.",
            "So that's our approach to reducing the set of subgroups which can be induced.",
            "But I for instance close gun and verbal have a different approach which is called.",
            "You help me?",
            "Compression I think.",
            "I think it's well, I don't know, but they have a different approach.",
            "Suppression, yeah?",
            "Yeah, sure sure.",
            "I mean, and with every data mining approach like with the.",
            "Association rule learning and with all this, when you are billed exhaustively, building all the interesting patterns, and then how to reduce this to a manageable size.",
            "You still use them, yeah?",
            "Global criterion yeah.",
            "The accuracy on the training set was validated.",
            "Let's say it is a measure and then you may want to try to select a subset of the rooms that optimizing that letter.",
            "Here in Suffolk Discovery is not obvious what the global quality measure.",
            "Yeah, I mean so I didn't have time to look into this, but we have analyzed all these algorithms also in the aerospace and obviously you can see every subgroup as being a point in the aerospace somewhere because it covers a certain number of positives and it covers certain number of negatives and when selecting between these different.",
            "Subgroup descriptions you could say, well, I will only choose those which are at the arosi curve, so that's one of the possible views.",
            "How to select a set of interesting subgroups out of all the subgroups.",
            "Or at least those which are close enough to the arosi convex Hull.",
            "Maybe it would be interesting to try some utility function.",
            "For the first case, when we were talking about which are operational.",
            "Jackie, finally yeah, that's for sure.",
            "I mean, the point is that subgroup discovery actually can be viewed as a kind of cost sensitive learning.",
            "And by modeling the costs you can actually you will actually get different subgroups as being the most interesting.",
            "That's for sure.",
            "You were using directions there.",
            "How are the computer they are obtained from the gene ontology that's there simply modeled by relation between 2:00, so.",
            "Sorry.",
            "Sorry yeah, so they they are simply stated as facts.",
            "Interactions among peers or.",
            "Yes.",
            "OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you for being here.",
                    "label": 0
                },
                {
                    "sent": "So today's talk is about subgroup discovery.",
                    "label": 1
                },
                {
                    "sent": "This is a topic of research which has been around for about five years, and the use of Stephen Institute and I will present some results.",
                    "label": 0
                },
                {
                    "sent": "Some methods as well as some recent biomedical applications.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The talk outline first, very briefly, about data mining, subgroup discovery, and then I will switch to relational data mining and propositional azatian approach and then present some applications of the subgroup discovering algorithm SD in DNA microarray data analysis and then propositional isation approach to subgroup discovery applied in the analysis of differentially expressed genes.",
                    "label": 0
                },
                {
                    "sent": "Then there will be at the end one slide towards service oriented knowledge technologies for information Fusion.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So data mining in a nutshell, we are given transactional database database.",
                    "label": 1
                },
                {
                    "sent": "So one Excel table for instance and then through data mining we're trying to extract interesting patterns or models and this data can be typically either simple relational table or something more elaborate like a relational database, text, documents, web pages.",
                    "label": 1
                },
                {
                    "sent": "So the problem is to find either a classification model.",
                    "label": 0
                },
                {
                    "sent": "Or a set of interesting patterns.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The data.",
                    "label": 0
                },
                {
                    "sent": "So once we get such a model, we can use it for classification of new instances.",
                    "label": 0
                },
                {
                    "sent": "We get a classified instance and it can be either a black blocks classifier which doesn't provide any explanation, or it can be a symbolic model, which in addition to classifying instances, can provide also the explanation.",
                    "label": 0
                },
                {
                    "sent": "We can also induce some interesting symbolic.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Patterns.",
                    "label": 0
                },
                {
                    "sent": "So well, you have all seen this example.",
                    "label": 0
                },
                {
                    "sent": "It's about data mining.",
                    "label": 0
                },
                {
                    "sent": "Example about contact lens data.",
                    "label": 0
                },
                {
                    "sent": "We have instances 24 instances about patients coming to an optician who prescribes contact lenses, either soft heart or no contact lenses at all.",
                    "label": 0
                },
                {
                    "sent": "And there are four attributes describing the patients.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can induce tighter decieve.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Country.",
                    "label": 0
                },
                {
                    "sent": "A set of rules which.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are used for classification.",
                    "label": 0
                },
                {
                    "sent": "Well and we can reformulate also this task differently into a concept learning task.",
                    "label": 0
                },
                {
                    "sent": "Before we had three different possibilities for target classes which were soft, hard and no lenses, here we have reformulated the problem into a two class classification problem where we have just yes and no.",
                    "label": 0
                },
                {
                    "sent": "Yes for prescribing contact lenses and no for no, no contact lens prescription.",
                    "label": 0
                },
                {
                    "sent": "So this is a concept learning problem.",
                    "label": 1
                },
                {
                    "sent": "Where we looking at positive examples versus negative examples.",
                    "label": 0
                },
                {
                    "sent": "For instance, we can look at positive examples for prescribing contact lenses versus the negative examples when we don't prescribe any.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lances so subgroup discovery will be in the context of this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this context of concept learning, therefore I have reformulated.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "So if we look at classification versus subgroup discovery, we can see that the classification task aims at constructing a model from the data.",
                    "label": 0
                },
                {
                    "sent": "For instance in the form of a set of prescriptive rules.",
                    "label": 0
                },
                {
                    "sent": "So in this sense it is a form of predictive induction.",
                    "label": 0
                },
                {
                    "sent": "Which is aimed at learning models for classification and prediction purposes.",
                    "label": 1
                },
                {
                    "sent": "If we do such a model in the form of rules, this classification rules aim at covering only positive examples.",
                    "label": 0
                },
                {
                    "sent": "In an ideal case, and this set of rules forms their domain model in subgroup discovery.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, we are interested in finding interesting individual rules, interesting patterns.",
                    "label": 1
                },
                {
                    "sent": "Which are described in the form of individual rules.",
                    "label": 0
                },
                {
                    "sent": "So opposed to predictive induction, this is a form of descriptive induction which is aimed at exploratory data analysis.",
                    "label": 0
                },
                {
                    "sent": "So we're trying to find interesting patterns in the data.",
                    "label": 0
                },
                {
                    "sent": "In this sense, it is not predictive.",
                    "label": 0
                },
                {
                    "sent": "But Discriptive and it's as the rules are symbolic.",
                    "label": 0
                },
                {
                    "sent": "We can use them for also explained which patterns have been induced from the data.",
                    "label": 0
                },
                {
                    "sent": "So the subgroup descriptions aimed at covering a significant proportion of positive examples as opposed to the ideal scenario in classification rule learning, where individual rules would aim at classifying only positive examples when there is no noise in the data.",
                    "label": 1
                },
                {
                    "sent": "So and here each rule describes an interesting pattern, and it is also an independent chunk of knowledge as opposed to hear where each rule depends on the other rules which have been induced and which former model.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if I illustrate this also on this slide in predictive induction, when we are building classification rules, we would like classification rules to cover all the positives and none of the negatives.",
                    "label": 1
                },
                {
                    "sent": "In the ideal case when there is no noise and in subgroup discovery, we aim at covering many positives, but we allow some negatives to be covered as well, and this would be for instance, one rule which covers 4 positives and one negative, and then this rule could be.",
                    "label": 1
                },
                {
                    "sent": "Covering two positives, one negative and so.",
                    "label": 1
                },
                {
                    "sent": "So here if we illustrate it here, let's say subgroup discovery would find set of independent rules, some of them may only cover the positives, like this one or this one.",
                    "label": 0
                },
                {
                    "sent": "Some may cover positives and some negatives, some of them may intersect, and so on.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this was very briefly about data mining.",
                    "label": 0
                },
                {
                    "sent": "Now how do we?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Perform subgroup discovery.",
                    "label": 0
                },
                {
                    "sent": "The task of subgroup discovery is to find from a set of labeled training examples.",
                    "label": 1
                },
                {
                    "sent": "Such descriptions of most interesting subgroups of the target class examples which are large enough, which means high target class coverage and which have significantly different distribution of the target class examples.",
                    "label": 0
                },
                {
                    "sent": "For instance, this can be measured by the high ratio of the true positives versus false positives or high relative accuracy or high weighted relative accuracy.",
                    "label": 0
                },
                {
                    "sent": "High significance of such rules, and there can be also some additional other.",
                    "label": 0
                },
                {
                    "sent": "Criteria of interestingness which are more of a subjective nature like.",
                    "label": 0
                },
                {
                    "sent": "Rules could be surprising to the user.",
                    "label": 0
                },
                {
                    "sent": "Simple, useful or actionable.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we look at the one particular medical problem, the task being finding and characterizing population subgroups with high risk for coronary heart disease, the input are patient records described by some attributes from anamnestic stage of the analysis from an amnestic and laboratory and amnestic, laboratory and ECG attributes, and the output are the best subgroup descriptions that are most actionable.",
                    "label": 0
                },
                {
                    "sent": "For coronary heart disease risk screening at Primary Health level.",
                    "label": 0
                },
                {
                    "sent": "So why did I say here most actionable?",
                    "label": 0
                },
                {
                    "sent": "It is not necessarily that if you perform subgroup discovery and optimize a certain criterion, these rules may be the best according to the particular heuristics, but maybe they may not be the most actionable for a certain purpose.",
                    "label": 0
                },
                {
                    "sent": "For instance, in primary care scale, the most actionable rules would be such which required the least tests to be made, and with the least tests which are the least cost you could do the screening action.",
                    "label": 0
                },
                {
                    "sent": "Based on that and you will see that.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, in this medical problem we have induced best subgroup descriptions.",
                    "label": 0
                },
                {
                    "sent": "Five were only selected by the expert as most actionable, however there.",
                    "label": 0
                },
                {
                    "sent": "Quality criterion was not the highest, but was just slightly less than the highest value of the quality criterion.",
                    "label": 1
                },
                {
                    "sent": "So for instance, the first crew subgroup being group of patients characterized by the property that these are male patients, they have positive family history and age being over 46.",
                    "label": 0
                },
                {
                    "sent": "So you see, it's a very simple rule, a conjunction of features, and at the conclusion site we have the target class which is.",
                    "label": 1
                },
                {
                    "sent": "Coronary heart disease another rule.",
                    "label": 0
                },
                {
                    "sent": "Female patients body mass index over 25 age over 60 three and so on and so on.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "It was chosen by the medical expert in this particular case.",
                    "label": 0
                },
                {
                    "sent": "So action ability is an interesting concept.",
                    "label": 0
                },
                {
                    "sent": "We have looked at that quite carefully.",
                    "label": 0
                },
                {
                    "sent": "There is a notion of action ability with, which means that you can perform a certain action like select people for being screened for coronary heart disease.",
                    "label": 0
                },
                {
                    "sent": "There is another option notion being operation ability and we have discussed test in our paper which was published in Machine Learning Journal in 2004.",
                    "label": 0
                },
                {
                    "sent": "So you can if you're interested in this, most sub more subjective criteria of interesting this you could find.",
                    "label": 1
                },
                {
                    "sent": "Some discussion on that in that paper.",
                    "label": 0
                },
                {
                    "sent": "So these features have been proposed by the SD algorithm.",
                    "label": 0
                },
                {
                    "sent": "And they are named in our approach.",
                    "label": 0
                },
                {
                    "sent": "They're called principle risk factors or principal factors which are found by an algorithm for subgroup mining.",
                    "label": 0
                },
                {
                    "sent": "In the work with the Dragon Gamberger, we have also developed the notion of.",
                    "label": 0
                },
                {
                    "sent": "Additional explanatory power of subgroups which is called finding additional risk factors which are called supporting factors and they are found by statistical analysis.",
                    "label": 1
                },
                {
                    "sent": "For instance, if we look at the first subgroup which is characterized by people who are male, have positive family history and age over 46 additional characteristic of this group of people.",
                    "label": 0
                },
                {
                    "sent": "Which are significantly different from for this group of people compared to the other patients is that these patients also are prone to psychological stress.",
                    "label": 0
                },
                {
                    "sent": "They are smoking.",
                    "label": 0
                },
                {
                    "sent": "They have typically hypertension and overweight.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Actually, not the conditions.",
                    "label": 0
                },
                {
                    "sent": "In the rule define the subgroup.",
                    "label": 0
                },
                {
                    "sent": "Now you look at this subgroup and now you look at all the attribute values for this subgroup versus all the other patients, and you see which of these features have significantly different for the subgroup versus the others.",
                    "label": 0
                },
                {
                    "sent": "Two people in the body.",
                    "label": 0
                },
                {
                    "sent": "Mass Index 25, which also constitutes overweight.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so let me go.",
                    "label": 0
                },
                {
                    "sent": "I think I have a slide on that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so for instance, if we have a rule here, high risk for coronary heart disease, body mass index over 25 and age over certain C and other supporting characteristics.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find it.",
                    "label": 0
                },
                {
                    "sent": "OK. We start from the you subgroup description and then we compute the statistical significance of all the available features.",
                    "label": 0
                },
                {
                    "sent": "Given two populations, the true positive positive cases, which means coronary heart disease patients which are correctly included into the subgroup.",
                    "label": 0
                },
                {
                    "sent": "Versus the negative cases, which are healthy subjects and then we simply do the high square test with 95% significance and those which are in favor which are characteristic for the subgroup are simply listed as supporting factors.",
                    "label": 0
                },
                {
                    "sent": "In addition, we began that this support for this additional factor side not some significant as the one which formed the rule, but still yeah.",
                    "label": 0
                },
                {
                    "sent": "So all the ones which are in the rule would also fulfill this criterion, but they have fulfilled also a different criterion, which is the one which is used for building the subgroups, and we will discuss this criterion as well.",
                    "label": 0
                },
                {
                    "sent": "It's just this game.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "It is true, but in practice all the all the factors which are there also statistically significant.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For instance, if we would use CN Two, which uses the significance measure to build the bodies of rule, then they would for sure be there so.",
                    "label": 0
                },
                {
                    "sent": "In our algorithms, which we have developed, which is as the algorithm uproariously which upgrades a priority for the context of subgroup discovery and CN, two SD which upgrades CN 24 subgroup Discovery, we have basically implemented awaited covering algorithm used weighted relative accuracy search heuristic with added example weights.",
                    "label": 0
                },
                {
                    "sent": "And if I go a little bit back because I have skipped a number of slides I can explain.",
                    "label": 0
                },
                {
                    "sent": "Some of this?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we look at the ASD algorithm.",
                    "label": 0
                },
                {
                    "sent": "DSD well just let me still explain a little bit the difference between classification rules and subgroup discovery rules.",
                    "label": 0
                },
                {
                    "sent": "Is the algorithm doesn't look for single complex rule which will describe all the examples of the target class, but it will build several rules like this.",
                    "label": 0
                },
                {
                    "sent": "As he prefers rules which are accurate, covering patients of the target class and which have high generalization potential.",
                    "label": 1
                },
                {
                    "sent": "And this is modeled by the parameter G of the rule quality heuristic, which I don't know whether I have it here.",
                    "label": 1
                },
                {
                    "sent": "I don't think I have it here, so.",
                    "label": 0
                },
                {
                    "sent": "The quality measure.",
                    "label": 0
                },
                {
                    "sent": "Q used in the air as the algorithm is.",
                    "label": 0
                },
                {
                    "sent": "True positives divided.",
                    "label": 0
                },
                {
                    "sent": "Bye.",
                    "label": 0
                },
                {
                    "sent": "False positives plus G. And we are trying to.",
                    "label": 0
                },
                {
                    "sent": "For input those.",
                    "label": 0
                },
                {
                    "sent": "Features.",
                    "label": 0
                },
                {
                    "sent": "Which have a high value of this quality criterion.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that we are maximizing the true positive versus false positive rate, and then we have a G parameter, the larger G, the bigger is the generalization potential of the subgroup discovery algorithm.",
                    "label": 0
                },
                {
                    "sent": "So we can have small G and we are really in that case maximizing TP versus FP.",
                    "label": 0
                },
                {
                    "sent": "And with the Big G, we are given a bigger tolerance for false positives.",
                    "label": 0
                },
                {
                    "sent": "OK, so if we now.",
                    "label": 0
                },
                {
                    "sent": "Obviously this is the number of positives covered, the number of incorrectly covered negatives.",
                    "label": 1
                },
                {
                    "sent": "You will see that we can naturally use example weights in the procedure for repetitive subgroup generalization via weighted covering algorithm and let me.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Illustrate the weighted covering algorithm now.",
                    "label": 1
                },
                {
                    "sent": "So suppose we have some patients positive examples in the data we have some negative examples in the data.",
                    "label": 0
                },
                {
                    "sent": "Initially we set the weights of all examples to one.",
                    "label": 0
                },
                {
                    "sent": "And now we learn the first subgroup.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, for instance, this might be a subgroup characterized by two features, feature two and features three.",
                    "label": 0
                },
                {
                    "sent": "It covers 6 positive examples and one negative example.",
                    "label": 0
                },
                {
                    "sent": "Now in the second step of the covering algorithm.",
                    "label": 0
                },
                {
                    "sent": "Well, here is this first step of of the subgroup Discovery algorithm, so I have.",
                    "label": 0
                },
                {
                    "sent": "Showing you this quality criterion through maximizing true positive versus divided by false positive slash G. Whereas in CN two SD we are maximizing the weighted relative accuracy.",
                    "label": 0
                },
                {
                    "sent": "Which is computed as follows if we have a rule if condition then target class, it is computed as the probability of the condition times the difference between the prior probability of the target class.",
                    "label": 0
                },
                {
                    "sent": "And the conditional probability of the target class given the condition of the rule.",
                    "label": 0
                },
                {
                    "sent": "So we could call this relative accuracy of the rule.",
                    "label": 0
                },
                {
                    "sent": "Because we are comparing the prior probability of the class and we are comparing it with the improved probability.",
                    "label": 0
                },
                {
                    "sent": "Of the class, given the conditions of the road, so we could also say, well, is the condition of the rule really characteristic for the target class?",
                    "label": 0
                },
                {
                    "sent": "If it is, then this difference will be large.",
                    "label": 0
                },
                {
                    "sent": "We could optimize just this difference if we were at optimizing this.",
                    "label": 0
                },
                {
                    "sent": "Rule accuracy, however, it turns out that if we want to have large subgroups then it is good to have a weight which will give additional weights to subgroups which are large becausw.",
                    "label": 0
                },
                {
                    "sent": "The probability of the condition actually tells you how large is the subgroup it is proportional to the size of the subgroup.",
                    "label": 0
                },
                {
                    "sent": "So we could interpret this formula which is called weighted relative accuracy like.",
                    "label": 0
                },
                {
                    "sent": "Coverage times precision means minus default precision.",
                    "label": 0
                },
                {
                    "sent": "And if you look if you do a little bit of manipulation of this formula, you can see that this is proportional to the difference between the true positive rate and the false positive rate.",
                    "label": 0
                },
                {
                    "sent": "So this is the formula which is used in the CL2 SD algorithm, whereas this is the formula which is used in the SD algorithm.",
                    "label": 0
                },
                {
                    "sent": "So you will see that here we have true positives.",
                    "label": 0
                },
                {
                    "sent": "Here we have true positive rate and he we divide true positives with the false positives and we here we look at the difference between the two.",
                    "label": 0
                },
                {
                    "sent": "OK, now that we have learned the first subgroup.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Minus.",
                    "label": 0
                },
                {
                    "sent": "Times.",
                    "label": 0
                },
                {
                    "sent": "How do you get from one step to another?",
                    "label": 0
                },
                {
                    "sent": "Oh, you mean here?",
                    "label": 0
                },
                {
                    "sent": "From here to here?",
                    "label": 0
                },
                {
                    "sent": "So P of count is the true positive divided by an OK. Oh probability of the class given the condition.",
                    "label": 0
                },
                {
                    "sent": "I would need to look into this, but it is the case.",
                    "label": 0
                },
                {
                    "sent": "So it should be one additional slide which would tell you how exactly you get to that.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now now that.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have learned the first rule.",
                    "label": 0
                },
                {
                    "sent": "Which covers some positives and some negatives.",
                    "label": 0
                },
                {
                    "sent": "In the second iteration of the weighted covering algorithm, what do we do?",
                    "label": 0
                },
                {
                    "sent": "We decrease the weights of the covered examples just in order for the algorithm to search the other part of the search space as well.",
                    "label": 0
                },
                {
                    "sent": "And by.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In doing so, for instance, we can do it by decreasing simply to value 05.",
                    "label": 0
                },
                {
                    "sent": "Now the algorithm will search.",
                    "label": 0
                },
                {
                    "sent": "More in this part of the space or here and not that much here.",
                    "label": 0
                },
                {
                    "sent": "Because now in all the our formulas.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We actually have computations which.",
                    "label": 0
                },
                {
                    "sent": "Talk about the number of numbers of instances like 2 positives being a number of instances now instead of these numbers, we simply use the weights and by that we model.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "That is how we implement the weighted covering algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now we have developed some approaches to subgroup visualization.",
                    "label": 0
                },
                {
                    "sent": "This is actually an approach developed by Petra.",
                    "label": 0
                },
                {
                    "sent": "We have positives and negatives and here we have subgroups and we just show what is the proportion of covered positives versus covered negatives.",
                    "label": 0
                },
                {
                    "sent": "Here we can show let's say if this is the set of all instances and this is the initial distribution of positives and negatives with the first Group subgroup which is illustrated here.",
                    "label": 0
                },
                {
                    "sent": "It is quite large and it has a significantly different proportion of positives versus negatives compared to the initial distribution.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, the group A2 which is characteristic for female patients, it is relatively small, but its proportion of positives is significantly larger.",
                    "label": 0
                },
                {
                    "sent": "And these are the three other subgroups which were evaluated by the expert as being actionable and interesting.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The endless.",
                    "label": 0
                },
                {
                    "sent": "OK, I have already explained the supporting factors, how they are computed.",
                    "label": 0
                },
                {
                    "sent": "So in this particular application we had five subgroups which were chosen as most actionable and for each of them we have also computed the supporting factors.",
                    "label": 1
                },
                {
                    "sent": "So why are the supporting factors really interesting in the work of Canonico and colleagues?",
                    "label": 0
                },
                {
                    "sent": "It turned out that.",
                    "label": 0
                },
                {
                    "sent": "Medical people don't like.",
                    "label": 0
                },
                {
                    "sent": "Short rules, so they also don't like decision trees cause the decision trees only take into account a couple of attributes, but on the other hand they very much like the Bayesian classifier which says for every feature basically whether it speaks in favor or in contrast of a certain diagnosis.",
                    "label": 0
                },
                {
                    "sent": "And we view this approach as a kind of halfway of the of both worlds.",
                    "label": 0
                },
                {
                    "sent": "We say these are the most important factors.",
                    "label": 0
                },
                {
                    "sent": "But these factors also provide some additional explanatory potential.",
                    "label": 0
                },
                {
                    "sent": "And actually, with the people we choose with whom we worked with medical experts, they quite liked the supporting factors in addition to the principle factors explaining the subgroups.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have explained this already.",
                    "label": 0
                },
                {
                    "sent": "So the lessons learned in the development of subgroup discovery algorithms.",
                    "label": 0
                },
                {
                    "sent": "Oh all these algorithms.",
                    "label": 0
                },
                {
                    "sent": "Well, as the algorithm is expert guided, which means that the G parameter which is used to model how large the subgroups will be and how many false positives are tolerated.",
                    "label": 0
                },
                {
                    "sent": "So this G parameter is part of the algorithm which is set by the user.",
                    "label": 0
                },
                {
                    "sent": "In addition, in this expert guided framework also, the expert chooses the most actionable rules.",
                    "label": 0
                },
                {
                    "sent": "Weighted covering algorithm for rule subset construction.",
                    "label": 0
                },
                {
                    "sent": "Using decreased weights of covered positive examples, it turns out to be useful when constructing a set of relatively independent subgroup descriptions.",
                    "label": 0
                },
                {
                    "sent": "And this additional evidence, in the form of supporting factors, increases the experts confidence in the rules resulting from automatic discovery.",
                    "label": 0
                },
                {
                    "sent": "Value added here is subgroup visualization.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I will switch from propositional data mining to relational data mining.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So until now, in our data mining approach we had here a single table from which we have induced a model or a set of interesting patterns.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, in relational data mining we have a slightly more complicated situation.",
                    "label": 0
                },
                {
                    "sent": "Here we have a relational database or a set of relational tables which is linked which are linked, and we use a relational data mining algorithm to induce a model from that data or some interesting pattern.",
                    "label": 0
                },
                {
                    "sent": "So this week and have now a relational database, set of tables, set of logical facts, maybe a graph structure, and the intention is to build a classification model or a set of interesting patterns.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at some examples.",
                    "label": 0
                },
                {
                    "sent": "So maybe we are looking at molecules which may be mutagenic or non multigenic.",
                    "label": 0
                },
                {
                    "sent": "So we have two classes of molecules between which we would like to distinguish.",
                    "label": 0
                },
                {
                    "sent": "So a molecule is a complex structure consisting of atoms.",
                    "label": 0
                },
                {
                    "sent": "So each molecule can consist of one or more atoms.",
                    "label": 0
                },
                {
                    "sent": "Each Atom can be connected to other atoms through bonds.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Atoms have some properties and molecules have some properties, one of them being to which class it belongs to, like being with a genie or non multigenic and there are some other properties describing the molecules.",
                    "label": 0
                },
                {
                    "sent": "So such complex data.",
                    "label": 0
                },
                {
                    "sent": "We have we can model it through.",
                    "label": 0
                },
                {
                    "sent": "We can describe this in multiple tables.",
                    "label": 0
                },
                {
                    "sent": "Or this would be the entity relation diagram for such a relational database.",
                    "label": 0
                },
                {
                    "sent": "So complex relational problems involve temporal data like type series in medicine, traffic control, structured data like representation, representation of molecules and their properties.",
                    "label": 0
                },
                {
                    "sent": "In very chemistry and so on.",
                    "label": 0
                },
                {
                    "sent": "So I will describe an approach to relational data mining through propositional isation, and for that I will use a very simple example about trains.",
                    "label": 0
                },
                {
                    "sent": "They come from Richard Michalski in the 80s, where he has described a complex problem of true.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things going.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "East or going West.",
                    "label": 0
                },
                {
                    "sent": "Which are described by some properties.",
                    "label": 0
                },
                {
                    "sent": "So let us look at 1 train.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just let's go back in the sense that we have a train.",
                    "label": 0
                },
                {
                    "sent": "It's classes direction.",
                    "label": 0
                },
                {
                    "sent": "Some trains are going East, some trains are going West.",
                    "label": 0
                },
                {
                    "sent": "Train has car.",
                    "label": 0
                },
                {
                    "sent": "One or more cars.",
                    "label": 0
                },
                {
                    "sent": "Each car has certain properties like shape of the car length, roof wheels and it.",
                    "label": 0
                },
                {
                    "sent": "It can carry loads and each of the loads can be can have some characteristics.",
                    "label": 0
                },
                {
                    "sent": "For instance, what is the shape of the load, how many loads the card is?",
                    "label": 0
                },
                {
                    "sent": "How many loads are on a car and see similar properties?",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we will show how the RSD algorithm works, which upgrades CN two SD to context of relational subgroup discovery.",
                    "label": 0
                },
                {
                    "sent": "It uses a propositional azatian approach by First order feature construction, and then once done a substandard subgroup Discovery algorithm is used to induce rules.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we go back to this particular example of trains.",
                    "label": 0
                },
                {
                    "sent": "We have 10 trains.",
                    "label": 0
                },
                {
                    "sent": "For each train we know to which class it belongs to, we said that the class is going East or going West.",
                    "label": 0
                },
                {
                    "sent": "So if we say eastbound trains are the target property, which we would like to analyze and for which we would like to find rules about trains going East.",
                    "label": 0
                },
                {
                    "sent": "So we are classifying this examples as positive and the other five examples as negative examples.",
                    "label": 0
                },
                {
                    "sent": "So if we look at this train T1.",
                    "label": 0
                },
                {
                    "sent": "We can see that the train T1 has four cars.",
                    "label": 0
                },
                {
                    "sent": "Car one is of rectangular shape.",
                    "label": 0
                },
                {
                    "sent": "It is short.",
                    "label": 0
                },
                {
                    "sent": "It has no roof and it has two wheels car, two rectangular shape, long card, none roof and three wheels.",
                    "label": 0
                },
                {
                    "sent": "That is this car and so on.",
                    "label": 0
                },
                {
                    "sent": "So as you see.",
                    "label": 0
                },
                {
                    "sent": "No, we can in this representation when we have put the trains in one table together with the class.",
                    "label": 0
                },
                {
                    "sent": "And then we have another table where for each train we can have descriptions of several cars and we can have a variable number of cars per trains, which is something which we cannot easily represent in a propositional representation within a single table.",
                    "label": 0
                },
                {
                    "sent": "Now, each of these cars can have loads like car one.",
                    "label": 0
                },
                {
                    "sent": "As a single note cartoon.",
                    "label": 0
                },
                {
                    "sent": "Yes, also one load cars 3 has one load whereas car four has four loads.",
                    "label": 0
                },
                {
                    "sent": "OK, so how can we transform such a multi relational representation into a single table representation?",
                    "label": 0
                },
                {
                    "sent": "We do it as follows.",
                    "label": 0
                },
                {
                    "sent": "Each line here corresponds to one instance.",
                    "label": 0
                },
                {
                    "sent": "And so it will be also in this derived representation.",
                    "label": 0
                },
                {
                    "sent": "Each train will be.",
                    "label": 0
                },
                {
                    "sent": "Described by one line in this propositional table, which we are constructing.",
                    "label": 0
                },
                {
                    "sent": "Now what can we do?",
                    "label": 0
                },
                {
                    "sent": "We will now try to build features.",
                    "label": 0
                },
                {
                    "sent": "Which will talk about properties of these strings and these features will have to talk actually about the properties of the cars which constitute the traits.",
                    "label": 0
                },
                {
                    "sent": "So we will try to find such features.",
                    "label": 0
                },
                {
                    "sent": "Whose properties will be will be characterized, the trends, and then the values of these features will be either true or false, so this will be logical features with values true and false.",
                    "label": 0
                },
                {
                    "sent": "So this approach was developed in the early 90s and it has been continued later from starting also with the work of teaching cardio then alignments and then later in the real.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "National subgroup Discovery algorithm RSD.",
                    "label": 0
                },
                {
                    "sent": "So how do we build firstorder features from?",
                    "label": 0
                },
                {
                    "sent": "Such properties of cars.",
                    "label": 0
                },
                {
                    "sent": "Now we will say, well.",
                    "label": 0
                },
                {
                    "sent": "The feature will be such that.",
                    "label": 0
                },
                {
                    "sent": "The feature of a train is that it has a car which has.",
                    "label": 0
                },
                {
                    "sent": "Length short.",
                    "label": 0
                },
                {
                    "sent": "So we could say this feature talks about trains and it says well feature train.",
                    "label": 0
                },
                {
                    "sent": "Train has a car which is short.",
                    "label": 0
                },
                {
                    "sent": "Or this one?",
                    "label": 0
                },
                {
                    "sent": "A train has a car which carries a lot of circular shape.",
                    "label": 0
                },
                {
                    "sent": "So if we look at it from the logical perspective, what have we done?",
                    "label": 0
                },
                {
                    "sent": "We have built a close.",
                    "label": 0
                },
                {
                    "sent": "In the head of the cloth we have a predicate which is actually a feature.",
                    "label": 0
                },
                {
                    "sent": "This predicate talks about the property of this variable, so it is a prolog notation.",
                    "label": 0
                },
                {
                    "sent": "In Prolog notation, we're using capitals for variables and variable stands for a train.",
                    "label": 0
                },
                {
                    "sent": "And now in the body of the clothes we have used this universal variable becausw.",
                    "label": 0
                },
                {
                    "sent": "You can read this for every T it holds that F1 of T if there exists variable C. And now this is an existential variable.",
                    "label": 0
                },
                {
                    "sent": "So we are looking whether Train has a car, whether there exists such a car with the property that it is short.",
                    "label": 0
                },
                {
                    "sent": "And through that conjunction of features.",
                    "label": 0
                },
                {
                    "sent": "We have actually built.",
                    "label": 0
                },
                {
                    "sent": "A conjunction of these two features tells us something about the property of this universal variable T. Another feature.",
                    "label": 0
                },
                {
                    "sent": "For every teeth, does there exist AC?",
                    "label": 0
                },
                {
                    "sent": "Such debt for this particular see there exists an L which is a load which is of circular shape.",
                    "label": 0
                },
                {
                    "sent": "So now the art of transforming the.",
                    "label": 0
                },
                {
                    "sent": "Multiple table representation into a single table representation.",
                    "label": 0
                },
                {
                    "sent": "It is about can we find such interesting features which will be characteristic for trains and which will be able to distinguish between eastbound and westbound trains.",
                    "label": 0
                },
                {
                    "sent": "So if we look at the first one.",
                    "label": 0
                },
                {
                    "sent": "This feature said, does there exist a car whose length is short?",
                    "label": 0
                },
                {
                    "sent": "If we look at the car train number one?",
                    "label": 0
                },
                {
                    "sent": "We will see that.",
                    "label": 0
                },
                {
                    "sent": "This feature is true.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Becausw the train has a car.",
                    "label": 0
                },
                {
                    "sent": "Which is short.",
                    "label": 0
                },
                {
                    "sent": "So the this existential condition has been satisfied.",
                    "label": 0
                },
                {
                    "sent": "Therefore the value of feature one is true.",
                    "label": 0
                },
                {
                    "sent": "The value of feature one for train.",
                    "label": 0
                },
                {
                    "sent": "Well, I don't have all the trains here, so I can't check whether this is true or not true for the other trains, but you should believe me.",
                    "label": 0
                },
                {
                    "sent": "So for train one let's say feature 2 feet.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two was.",
                    "label": 0
                },
                {
                    "sent": "Whether there exists a car which has a load which is of circular shape, let's see whether it is.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before train one.",
                    "label": 0
                },
                {
                    "sent": "It has a load.",
                    "label": 0
                },
                {
                    "sent": "It has a car which has a load of circular shape.",
                    "label": 0
                },
                {
                    "sent": "That is true.",
                    "label": 0
                },
                {
                    "sent": "So the value of this feature is true.",
                    "label": 0
                },
                {
                    "sent": "Now you can imagine that you could build very many features of that kind.",
                    "label": 0
                },
                {
                    "sent": "And the approach which is implemented is that we have.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Feature construction algorithm which will.",
                    "label": 0
                },
                {
                    "sent": "For a given universal variable construct, first introduce.",
                    "label": 0
                },
                {
                    "sent": "Such a property about the individual T which will introduce an existential variable, and then we will add such a.",
                    "label": 0
                },
                {
                    "sent": "Determine which will.",
                    "label": 0
                },
                {
                    "sent": "Give a value of the logically introduced existential variable C. We will do it within a certain language.",
                    "label": 0
                },
                {
                    "sent": "Bias this language bias can be such that you only allow let's say up to five literals to be added to the body of a clause.",
                    "label": 0
                },
                {
                    "sent": "Or it can allow just one existential variable to be introduced, or maximally two existential variables to be introduced, like in this case C&L.",
                    "label": 0
                },
                {
                    "sent": "Or it can be such that you put a certain constraint on the coverage.",
                    "label": 0
                },
                {
                    "sent": "So such a feature or conjunction of features should be such that it covers at least a minimal number of positive examples, so you can put such constraints on this feature generation algorithm.",
                    "label": 0
                },
                {
                    "sent": "And then obviously, instead of having just a couple of features describing trains, you will have now.",
                    "label": 0
                },
                {
                    "sent": "Number numerous features and well, it is upon the user to decide what constraints to be put on the feature generation.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Algorithm.",
                    "label": 0
                },
                {
                    "sent": "So in the ZND algorithm, which has been developed in the 2002 and published in Journal in 2006.",
                    "label": 0
                },
                {
                    "sent": "We are implemented this propositional isation approach to relational learning through very efficient 1st order feature construction.",
                    "label": 1
                },
                {
                    "sent": "It is a syntax driven approach using Prolog slash LF kind of declarations.",
                    "label": 0
                },
                {
                    "sent": "We build such 1st order features like for instance for molecules.",
                    "label": 0
                },
                {
                    "sent": "For a molecule M, does there exist an Atom Atom a which is of a certain type or for a molecule?",
                    "label": 0
                },
                {
                    "sent": "Does it have a property of LUMO big of?",
                    "label": 0
                },
                {
                    "sent": "Whose value is less than a certain value.",
                    "label": 0
                },
                {
                    "sent": "Through that we can then build these features.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then if we now have such a representation, you can see that we can use whatever machine learning algorithm which is appropriate for propositional learning.",
                    "label": 0
                },
                {
                    "sent": "We can also use either classification rule, learning algorithm or subgroup discovery algorithm, and if we use this.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Subgroup discovery algorithm like C and two we can get such subgroup descriptions like molecule is mutagenic.",
                    "label": 0
                },
                {
                    "sent": "A certain feature feature number 121 is true and the feature 102 hundred 235 is true.",
                    "label": 0
                },
                {
                    "sent": "Whatever these features actually are, there are some conjunct of features about the molecules and atoms and bonds and things like that.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "Construction goes like that.",
                    "label": 0
                },
                {
                    "sent": "We will first build the first literal such that it includes one free global variable like train like for every train.",
                    "label": 0
                },
                {
                    "sent": "Teak would be the free global variable.",
                    "label": 0
                },
                {
                    "sent": "And then we introduce one or several structural predicates like has Atom or has a car which introduced new existential local variables like Atom here or car in the case of trains.",
                    "label": 0
                },
                {
                    "sent": "And then using either the global variable or a local variable introduced by the local variable.",
                    "label": 0
                },
                {
                    "sent": "So like we had here, molecule Atom was the local variable introduced and now we could have another local variable introduced by this one like in the cars example we had cars.",
                    "label": 0
                },
                {
                    "sent": "We in the trains example we had cars and the cars could introduce a new variable being loads.",
                    "label": 0
                },
                {
                    "sent": "And then finally we can have one or more utility predicates which define the properties of individuals or their parts, assigning values to the variables.",
                    "label": 0
                },
                {
                    "sent": "So for instance, like here here we assign value 21 to variable R. Through this literal.",
                    "label": 0
                },
                {
                    "sent": "So if we have now this feature and another feature our subgroup discovery, we can be described with these two features of the molecule.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's now go to the applications.",
                    "label": 0
                },
                {
                    "sent": "DNA micro array data analysis with the as the algorithm we are now in the propositional case, not in the relay.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data mining case.",
                    "label": 0
                },
                {
                    "sent": "So we're looking at the problem from functional genomics and the problems is here we are studying genes and their functions, and typically there is a very large number of attributes, namely genes relative to the relatively small number of examples or observations, and this is usually for machine learning, not a very favorable setting.",
                    "label": 0
                },
                {
                    "sent": "So for instance we may have just 50 or 100 examples described by several thousands of attributes.",
                    "label": 0
                },
                {
                    "sent": "Or jeans.",
                    "label": 0
                },
                {
                    "sent": "So what we are doing here we are trying to better understand biological pro properties and process is through.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "DNI microarray DNA analysis.",
                    "label": 0
                },
                {
                    "sent": "So typically we would have a situation like that we would have.",
                    "label": 0
                },
                {
                    "sent": "We would transform this into.",
                    "label": 0
                },
                {
                    "sent": "Oh the form appropriate for machine learning.",
                    "label": 0
                },
                {
                    "sent": "Each of these.",
                    "label": 0
                },
                {
                    "sent": "DNA would be.",
                    "label": 0
                },
                {
                    "sent": "Micro each of the micro race would correspond to one line.",
                    "label": 0
                },
                {
                    "sent": "Some of them are characterized for certain types of tumors.",
                    "label": 0
                },
                {
                    "sent": "And then we have certain values for individual genes like maybe we have 10,000 genes.",
                    "label": 0
                },
                {
                    "sent": "And we have now one line per microarray.",
                    "label": 0
                },
                {
                    "sent": "Experiment.",
                    "label": 0
                },
                {
                    "sent": "Uh huh.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the standard approach to the analysis is that we are using people use neural networks, support vector machines or combination of different classifiers.",
                    "label": 0
                },
                {
                    "sent": "To learn a model which will be able to distinguish between different types of tumors.",
                    "label": 0
                },
                {
                    "sent": "So and then for a new sample, you put it into this black box classifier and you get.",
                    "label": 0
                },
                {
                    "sent": "An answer whether it is a certain type of.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cancer or some other type of cancer.",
                    "label": 0
                },
                {
                    "sent": "Usually these models have relatively good predictive accuracy.",
                    "label": 0
                },
                {
                    "sent": "They are relatively resistant to overfitting, especially if you use in samples of such strong classifiers.",
                    "label": 0
                },
                {
                    "sent": "But this black box models are very hard to be interpreted or impossible to be interpreted.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Therefore we are using a different approach.",
                    "label": 0
                },
                {
                    "sent": "We are using an approach through subgroup discovery from DNA microarray data.",
                    "label": 1
                },
                {
                    "sent": "In our first work, we used the problem of Gollop.",
                    "label": 0
                },
                {
                    "sent": "Where we were distinguishing between examples of AALL.",
                    "label": 0
                },
                {
                    "sent": "Leukemia versus AML leukemia and we had 27 samples of this.",
                    "label": 0
                },
                {
                    "sent": "111 samples of the other ones and there are three 3734 samples in the test set.",
                    "label": 0
                },
                {
                    "sent": "Every sample is described with gene expression values of over 1000 genes.",
                    "label": 0
                },
                {
                    "sent": "Another problem we have analyzed with this approach is the problem of distinguishing between 14 different types of cancers.",
                    "label": 0
                },
                {
                    "sent": "In total there were 144 samples in the training set and 54.",
                    "label": 0
                },
                {
                    "sent": "Compass in the independent test set.",
                    "label": 0
                },
                {
                    "sent": "Every sample was described with gene expression values with over 16,000 genes.",
                    "label": 0
                },
                {
                    "sent": "So this is a well known problem.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Grab the nature by Gollop and colleagues.",
                    "label": 0
                },
                {
                    "sent": "We use the SD algorithm.",
                    "label": 0
                },
                {
                    "sent": "And we got such rules.",
                    "label": 0
                },
                {
                    "sent": "Like if a certain gene.",
                    "label": 0
                },
                {
                    "sent": "Is over expressed and another gene is not expressed, then this is characteristic for leukemia and the classification accuracy on the training set it would cover.",
                    "label": 0
                },
                {
                    "sent": "It would be covering 23 positives out of 24.",
                    "label": 0
                },
                {
                    "sent": "And it would be relatively good also on the test set.",
                    "label": 0
                },
                {
                    "sent": "So the advantage here is that you can get.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interpretable descriptions of these groups.",
                    "label": 0
                },
                {
                    "sent": "And this if then rules are actually interpretable, so.",
                    "label": 0
                },
                {
                    "sent": "We cite the medical expert the best scoring rule for leukemia shows that expression of a certain.",
                    "label": 0
                },
                {
                    "sent": "Gene, whose relation to the diagnosis is directly explicable.",
                    "label": 0
                },
                {
                    "sent": "The second condition, which is.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "According to the expert, it is an in team.",
                    "label": 0
                },
                {
                    "sent": "Its elevated expression has not been found in brain tumors and this cancers.",
                    "label": 0
                },
                {
                    "sent": "While this one the same condition has not been to our knowledge associated with Leukemia's.",
                    "label": 0
                },
                {
                    "sent": "So this second condition turned out to be interesting piece of information.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the medical expert.",
                    "label": 0
                },
                {
                    "sent": "OK, so through some good discovery we have.",
                    "label": 0
                },
                {
                    "sent": "Found logical rules which are easily to be interpreted.",
                    "label": 0
                },
                {
                    "sent": "We have also taken care to avoid flu cruise through a mechanism of.",
                    "label": 0
                },
                {
                    "sent": "Handling.",
                    "label": 0
                },
                {
                    "sent": "Such situations, but these obviously are still inferior in terms of accuracy compared to the.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Complex classifiers.",
                    "label": 0
                },
                {
                    "sent": "Unable to find any rules before new Xbox or this will just be confirmation of fire.",
                    "label": 0
                },
                {
                    "sent": "In most cases it was re confirmation of what they already knew, but this particular rule was very interesting to the expert.",
                    "label": 0
                },
                {
                    "sent": "What's new, yeah?",
                    "label": 0
                },
                {
                    "sent": "So if we now switch to the more complex situation where we would have a relational representation of the data.",
                    "label": 0
                },
                {
                    "sent": "And we are now trying to find descriptions such that we will try to analyze genes which are differentially expressed between different types of.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Answers.",
                    "label": 0
                },
                {
                    "sent": "So we have now this dilemma whether we are building interpretable rules which are less accurate.",
                    "label": 0
                },
                {
                    "sent": "Or can we do something about it?",
                    "label": 0
                },
                {
                    "sent": "Trying to build accurate rules and then explain them simply by using subgroup discovery approach?",
                    "label": 1
                },
                {
                    "sent": "So actually this was done in this second experiment.",
                    "label": 1
                },
                {
                    "sent": "So in the first learning phase we built descriptors which will separate positives from the negatives.",
                    "label": 0
                },
                {
                    "sent": "Let's say a certain type of cancers versions.",
                    "label": 0
                },
                {
                    "sent": "All the other types of cancer.",
                    "label": 0
                },
                {
                    "sent": "We use this for classifying instances, and now that we have such a classifier distinguishing.",
                    "label": 0
                },
                {
                    "sent": "Positives from negatives.",
                    "label": 0
                },
                {
                    "sent": "We will now transform the learning problem as follows.",
                    "label": 0
                },
                {
                    "sent": "We will first learn an accurate classifier and then we will learn comprehensible summarization's of genes.",
                    "label": 0
                },
                {
                    "sent": "Which are characterized for a certain type of flick tissue versus all the other genes.",
                    "label": 0
                },
                {
                    "sent": "So this learning two phase.",
                    "label": 0
                },
                {
                    "sent": "What happens here is that we now transform the problem in such a way that instances become the jeans, not the patients.",
                    "label": 0
                },
                {
                    "sent": "So initially we have a very small number of patients describe the very large number of genes.",
                    "label": 0
                },
                {
                    "sent": "Now that we have made learn the classifier, we are now know which genes are characteristic for certain type of tissues versus other genes.",
                    "label": 0
                },
                {
                    "sent": "We are.",
                    "label": 0
                },
                {
                    "sent": "These are maybe large numbers of such genes which are characteristic.",
                    "label": 0
                },
                {
                    "sent": "And I would we would like to find interpretable characterizations of these sets of genes, which are typical for certain types of tissues.",
                    "label": 0
                },
                {
                    "sent": "In this learning two phase which can be viewed as a phase of exploratory data analysis, we can build such rules like genes encoding for proteins located in the integral membrane, rather whose function includes repertory activities.",
                    "label": 1
                },
                {
                    "sent": "This is an interpretation of the set of genes which are characteristic for certain types of tissues.",
                    "label": 0
                },
                {
                    "sent": "So how should we now build such?",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rules.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The typical problem is finding, let's say groups of genes which would be overexpressed for some tissues and not for the others, and compare it to the other groups of genes.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that is the standard problem.",
                    "label": 0
                },
                {
                    "sent": "And if these are characterized for certain cancer, and these are characterized for other types of cancer, we would like to identify differentially expressed genes.",
                    "label": 0
                },
                {
                    "sent": "Like for instance this one.",
                    "label": 0
                },
                {
                    "sent": "Gene, I would be typically characteristic for class I.",
                    "label": 0
                },
                {
                    "sent": "And we do that with simple T test.",
                    "label": 0
                },
                {
                    "sent": "Finding which are the genes which are characterized.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Check for certain types of tissues.",
                    "label": 0
                },
                {
                    "sent": "So when trying to identify differentially expressed genes, we would like to see whether they are indeed differentially expressed between this class and this class.",
                    "label": 0
                },
                {
                    "sent": "So in this case we would say yes.",
                    "label": 0
                },
                {
                    "sent": "These genes are differentially expressed.",
                    "label": 0
                },
                {
                    "sent": "In this case we will also say they are differentially expressed, whereas here the difference is not large enough.",
                    "label": 0
                },
                {
                    "sent": "We are testing this through the T test.",
                    "label": 0
                },
                {
                    "sent": "And through that we will distinguish the most differentially expressed genes.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe this would be the first.",
                    "label": 0
                },
                {
                    "sent": "100 most expressions which have been identified they are identified through T tests.",
                    "label": 0
                },
                {
                    "sent": "They have a certain score and we would say, well, these are overexpressed and all the others are not overexpressed, and we would like to characterize groups of genes which are over expressed through their characteristics.",
                    "label": 0
                },
                {
                    "sent": "So this would be this learning two phase.",
                    "label": 0
                },
                {
                    "sent": "Of which I have descri.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Did before.",
                    "label": 0
                },
                {
                    "sent": "So what can we do now?",
                    "label": 0
                },
                {
                    "sent": "Well, if a certain gene is interesting because it is highly ranked according to the test.",
                    "label": 0
                },
                {
                    "sent": "However, search such a gene, which is less highly ranked could be also interesting.",
                    "label": 0
                },
                {
                    "sent": "Becausw although it has a lower P value.",
                    "label": 0
                },
                {
                    "sent": "It could be interesting becausw this gene could interact with some other gene and because of that interaction his interesting needs may arise.",
                    "label": 0
                },
                {
                    "sent": "Although according to the T test.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is not that interesting.",
                    "label": 0
                },
                {
                    "sent": "So what are we doing here in this second phase?",
                    "label": 0
                },
                {
                    "sent": "We're trying to find group of genes.",
                    "label": 0
                },
                {
                    "sent": "Which largely overlap with those associated with the classifier for the given class and can be compactly summarized in terms of their features.",
                    "label": 0
                },
                {
                    "sent": "Now what are the features?",
                    "label": 0
                },
                {
                    "sent": "The features are the attributes of the original attribute of the original instances, namely the jeans, and then we have first order features which are extracted from the gene ontology and the other databases like go on three and cake.",
                    "label": 0
                },
                {
                    "sent": "So this is now the work done together initially with Philip jealously and then.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Eagle Tri Kolski did this work further in his PhD thesis.",
                    "label": 0
                },
                {
                    "sent": "OK, so gene ontology.",
                    "label": 0
                },
                {
                    "sent": "We have genes.",
                    "label": 0
                },
                {
                    "sent": "And we have their hierarchy.",
                    "label": 0
                },
                {
                    "sent": "According to their functions, we have one part of the Gene Ontology talking about the processes and one part of the gene ontology about the components.",
                    "label": 0
                },
                {
                    "sent": "So the functions, what does the gene?",
                    "label": 0
                },
                {
                    "sent": "Product do the process is why does it perform a certain activity and where does it act?",
                    "label": 0
                },
                {
                    "sent": "So this is these are the numbers of processes, components and functions which are encoded in the gene ontology currently.",
                    "label": 0
                },
                {
                    "sent": "We have an SA and part of our the relations here, so amino acid metabolism.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "Subpart of amino metabolism of this particular genes.",
                    "label": 0
                },
                {
                    "sent": "So the level represents the specificity.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Off turns into Gene Ontology, so if you look at the one part of the gene ontology, it could be viewed like that.",
                    "label": 0
                },
                {
                    "sent": "We have processes, components and functions.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we look at this representation from the multi relational perspective, we have the main table which is about genes.",
                    "label": 0
                },
                {
                    "sent": "We have gene gene interactions and then we have.",
                    "label": 0
                },
                {
                    "sent": "These properties in individual tables talking about functions, processes and components.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so how do we transform this representation into a prolog representation?",
                    "label": 0
                },
                {
                    "sent": "We have some genes which are differentially expressed.",
                    "label": 0
                },
                {
                    "sent": "This would be the jeans which are at the top 50 of the jeans or top 100 of the jeans.",
                    "label": 0
                },
                {
                    "sent": "They would be classified as differentially expressed.",
                    "label": 0
                },
                {
                    "sent": "The other genes would be considered random genes which don't have anything to do with the specific type of tissue with a specific type of cancer.",
                    "label": 0
                },
                {
                    "sent": "And then we have information about the components.",
                    "label": 0
                },
                {
                    "sent": "So this particular gene.",
                    "label": 0
                },
                {
                    "sent": "Is a component of this gene gene ontology term.",
                    "label": 0
                },
                {
                    "sent": "It is it has a certain function annotated with this term in the gene ontology.",
                    "label": 0
                },
                {
                    "sent": "It belongs to a certain process annotated in the gene ontology, like that and Inter it interacts with some other genes.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we perform 1st order feature construction.",
                    "label": 0
                },
                {
                    "sent": "Feature about a particular gene.",
                    "label": 0
                },
                {
                    "sent": "It is feature #7, for instance says well, this gene has a particular function annotated by this particular Geo term.",
                    "label": 0
                },
                {
                    "sent": "Or it has a certain process?",
                    "label": 0
                },
                {
                    "sent": "Or it?",
                    "label": 0
                },
                {
                    "sent": "This is already a more complicated 1st order feature.",
                    "label": 0
                },
                {
                    "sent": "Gene.",
                    "label": 0
                },
                {
                    "sent": "Has a circle function and it.",
                    "label": 0
                },
                {
                    "sent": "He's annotated by this gene.",
                    "label": 0
                },
                {
                    "sent": "Ontology term representing a certain process or even more complicated feature.",
                    "label": 0
                },
                {
                    "sent": "Gene A interacts with gene B.",
                    "label": 0
                },
                {
                    "sent": "Whose function is annotated by this Geo.",
                    "label": 0
                },
                {
                    "sent": "Term, and this B belongs to this process annotated by this particular term.",
                    "label": 0
                },
                {
                    "sent": "So these are the simple.",
                    "label": 0
                },
                {
                    "sent": "Features which don't introduce any existential variable, and these are more complex features.",
                    "label": 0
                },
                {
                    "sent": "Because we have introduced existential variable naming another gene which interacts with the gene which we would like to analyze.",
                    "label": 0
                },
                {
                    "sent": "So if Gene A was overly expressed.",
                    "label": 0
                },
                {
                    "sent": "It is not necessarily that actually Gene B was also overly expressed like in the first 50.",
                    "label": 0
                },
                {
                    "sent": "Through that we have introduced a connection with some gene which might be among the random genes.",
                    "label": 0
                },
                {
                    "sent": "But because of this interaction.",
                    "label": 0
                },
                {
                    "sent": "And be cause it has a certain function and belongs to a certain process.",
                    "label": 0
                },
                {
                    "sent": "This gene B has also become interesting and important for analyzing the overly expressed genes through their interaction with these other.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No, again the same as before.",
                    "label": 0
                },
                {
                    "sent": "This would be the most the overly expressed genes.",
                    "label": 0
                },
                {
                    "sent": "Each of them described with this first order features these first order features are either true or false.",
                    "label": 0
                },
                {
                    "sent": "We look at them, we evaluate them being either true.",
                    "label": 0
                },
                {
                    "sent": "Or force.",
                    "label": 0
                },
                {
                    "sent": "And this would be some of the non differentially expressed genes like randomly sampled genes from the set of non overly expressions and actually in the experiment figure.",
                    "label": 0
                },
                {
                    "sent": "These were 50 most topmost expressed overly expressions, and these were 50 randomly sampled jeans from the other set of genes.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We now use subgroup Discovery algorithm, which will now for instance build a conjunction of features feature two and features three covering 4 out of 50 overly expressed genes and none of the random genes.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now again we use weighted covering algorithm to.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find a set of rules or a set of subgroups.",
                    "label": 0
                },
                {
                    "sent": "In RSD we are using CN Two SD algorithm which again has this weighted relative accurate.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See heuristic.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we built these rules.",
                    "label": 0
                },
                {
                    "sent": "So if we look at some rules which have been constructed.",
                    "label": 0
                },
                {
                    "sent": "One constructive truth is that we have found a group of genes.",
                    "label": 0
                },
                {
                    "sent": "Which interact with this G, which is an existential variable whose function is protein binding.",
                    "label": 0
                },
                {
                    "sent": "So G interacts with another gene whose function include protein binding.",
                    "label": 0
                },
                {
                    "sent": "And distant describes a group of genes which have been now discovered into it.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which can be logically interpreted.",
                    "label": 0
                },
                {
                    "sent": "We have used this approach in several databases, so one is this gold database distinguishing between LL type of tumor versus AML.",
                    "label": 0
                },
                {
                    "sent": "Then we had several subtypes of LL and also this 14 cancer types which I have introduced before in the experiments with the SD algorithm.",
                    "label": 0
                },
                {
                    "sent": "In all these experiments, as I said, we selected a set of most differentially expressed genes, the highest score and the same number of randomly chosen, non differentially expressed genes.",
                    "label": 0
                },
                {
                    "sent": "And this was the setting.",
                    "label": 0
                },
                {
                    "sent": "For our experiments.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this would be some of the rules describing subgroups of genes which have turned out to be of interest.",
                    "label": 0
                },
                {
                    "sent": "For instance this one.",
                    "label": 0
                },
                {
                    "sent": "Gene A, which interacts with B&B belonging to this particular process.",
                    "label": 0
                },
                {
                    "sent": "So this one covers 12 of the over the expressions and none of the non over the expressions and similar.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, these rules have been evaluated.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The medical expert.",
                    "label": 0
                },
                {
                    "sent": "It turns out that if we use all the information which includes information from the gene ontology, including the interaction and as well as weights of examples, if we use all this information, we get better results than by excluding any of these types of information in our.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Journalists in recent work.",
                    "label": 0
                },
                {
                    "sent": "We have developed an approach which is called search for enriched gene sets.",
                    "label": 0
                },
                {
                    "sent": "This is the second method developed by eager try Kolski in his PhD thesis.",
                    "label": 0
                },
                {
                    "sent": "This method overcomes the problem of fixed thresholds which we have used in the first method in the first method, we say 50 most expressed genes and others are considered random genes or non overly expressed and in this method eager has taken an approach which is known from bioinformatics and this approach avoids the fixed threshold.",
                    "label": 0
                },
                {
                    "sent": "The problem of the fixed thresholds when determining the over the set, the number of over expressed genes.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we try to summarize this approach presented with the ZND algorithm, this method provides.",
                    "label": 0
                },
                {
                    "sent": "It is a method which adds interpretability to this high dimensional gene expression classifiers.",
                    "label": 0
                },
                {
                    "sent": "And it employs the idea of.",
                    "label": 0
                },
                {
                    "sent": "Using a sequence of two data mining task first being a predictive classifier, construction.",
                    "label": 0
                },
                {
                    "sent": "In our case very simple predictive classifier construction just distinguishing between overly expressions and those which are not, and then in the second step trying to explain groups of this overly expressions through descriptive subgroup discovery.",
                    "label": 0
                },
                {
                    "sent": "We have done that by integrating the information which is available in public databases, in particular in Gene Ontology entries and cake.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is the idea of the future work?",
                    "label": 0
                },
                {
                    "sent": "So in the this approach of two step learning?",
                    "label": 0
                },
                {
                    "sent": "We have developed a workflow for that which is implemented in the algorithms of eager try kolski in his PhD thesis.",
                    "label": 0
                },
                {
                    "sent": "We see that this workflow can be generalized as a general machine learning workflow for types of problems where we are dealing with ranking.",
                    "label": 0
                },
                {
                    "sent": "So in ranking problems we are trying to distinguish the highly ranked instances compared to those which are not highly ranked.",
                    "label": 0
                },
                {
                    "sent": "And if our if we have some publicly available information in terms of ontologies, we could use the approach which has been presented in this.",
                    "label": 0
                },
                {
                    "sent": "Presentation to get the explanation in addition to the differentiation, which is the original task.",
                    "label": 0
                },
                {
                    "sent": "In the coming week we are planning to organize.",
                    "label": 0
                },
                {
                    "sent": "We are actually organizing a workshop which we will name the service oriented Knowledge Technologies Workshop.",
                    "label": 0
                },
                {
                    "sent": "The idea is that in the first step we will implement this workflow of.",
                    "label": 0
                },
                {
                    "sent": "In the gene sets.",
                    "label": 0
                },
                {
                    "sent": "In service oriented architecture.",
                    "label": 0
                },
                {
                    "sent": "So we will have a web based algorithm which everybody will be able to use.",
                    "label": 0
                },
                {
                    "sent": "You could try Kolski has also downloaded.",
                    "label": 0
                },
                {
                    "sent": "He has a script which downloads the current version of all these ontologies which can be then used for the interpretation.",
                    "label": 0
                },
                {
                    "sent": "And then in the future we would like to implement some other modules of the algorithms like the subgroup discovery algorithms which we have developed at the user Steven Institute.",
                    "label": 0
                },
                {
                    "sent": "Maybe also some of the modules from decision support.",
                    "label": 0
                },
                {
                    "sent": "Maybe some of the modules description of such as group.",
                    "label": 0
                },
                {
                    "sent": "We would like to implement in this.",
                    "label": 0
                },
                {
                    "sent": "Architecture, which could be a potential step towards new data mining tool box available on the web as opposed to waka and Orange which are simply downloadable machine learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "So today's lecture is the first lecture in the series of events in the.",
                    "label": 0
                },
                {
                    "sent": "The coming week, two weeks until January 18.",
                    "label": 0
                },
                {
                    "sent": "It will be a small workshop and people will from basically from.",
                    "label": 0
                },
                {
                    "sent": "Vidant Massage and Petra and your own and puncture will participate together with Martin and Marie, who will also look at this approach to.",
                    "label": 0
                },
                {
                    "sent": "Web based toolbox development, which might be one of the goals of our future work.",
                    "label": 0
                },
                {
                    "sent": "OK, with this I would finish this talk and I'm prone to questions.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's.",
                    "label": 0
                },
                {
                    "sent": "Of course, that was initial work which has motivated our work, but now it is quite lively.",
                    "label": 0
                },
                {
                    "sent": "There is Martin Alice Miller, who is doing full-time research on suburb Discovery.",
                    "label": 0
                },
                {
                    "sent": "There is arnac number who is doing full-time research in this area and at least one or two more people Patreon.",
                    "label": 0
                },
                {
                    "sent": "Maybe you could help me.",
                    "label": 0
                },
                {
                    "sent": "OK, well for instance I have just reviewed the subgroup discovery paper for Christmas, so it's quite lively.",
                    "label": 0
                },
                {
                    "sent": "Also, our recent work is pretty interesting.",
                    "label": 0
                },
                {
                    "sent": "We are now about to submit a paper to Journal of Machine Learning research together with Jeffrey Web where we have compared subgroup discovery with contrast set mining and emerging pattern mining and it basically turns out that these three.",
                    "label": 0
                },
                {
                    "sent": "Areas of research are very strongly related, and basically you can transform one to the other.",
                    "label": 0
                },
                {
                    "sent": "Now if you see it from this broader context, you could see that a lot of people are doing this kind of research.",
                    "label": 0
                },
                {
                    "sent": "Lots of people are doing emerging pattern mining.",
                    "label": 0
                },
                {
                    "sent": "Quite some people started to do contrast set mining recently, and there are some people working on subgroup discovery as well.",
                    "label": 0
                },
                {
                    "sent": "So we recently have called this descriptive supervised descriptive rule induction and it is a generalized framework for which incorporates all these three sub areas of data mining research.",
                    "label": 0
                },
                {
                    "sent": "In terms of software.",
                    "label": 0
                },
                {
                    "sent": "Work with feeling.",
                    "label": 0
                },
                {
                    "sent": "Jealousy is downloadable.",
                    "label": 0
                },
                {
                    "sent": "It is there, but it's very hard to use because it uses Oracle database and you can't get it simply.",
                    "label": 0
                },
                {
                    "sent": "So we had a lot of trouble getting it and having it.",
                    "label": 0
                },
                {
                    "sent": "Operational and things like that.",
                    "label": 0
                },
                {
                    "sent": "Well, Bronco headed here for awhile and I don't know exactly what is the state of the art.",
                    "label": 0
                },
                {
                    "sent": "So Peter has developed his implemented the three algorithms as DC and two SD and a priority as D in the orange toolbox.",
                    "label": 0
                },
                {
                    "sent": "So this is operational.",
                    "label": 0
                },
                {
                    "sent": "The problem there is that the internal representation is not feature based but it is attribute value based which actually means that these implementations are.",
                    "label": 0
                },
                {
                    "sent": "Actually different from the other implementations, but they are operational and at hand.",
                    "label": 0
                },
                {
                    "sent": "The work by.",
                    "label": 0
                },
                {
                    "sent": "Close game.",
                    "label": 0
                },
                {
                    "sent": "Could actually be also be continuous targets.",
                    "label": 0
                },
                {
                    "sent": "Is there any of them being followed?",
                    "label": 0
                },
                {
                    "sent": "Well, we are looking only at binary classes.",
                    "label": 0
                },
                {
                    "sent": "I don't know the answer.",
                    "label": 0
                },
                {
                    "sent": "You had a comment.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "If you look at from far enough.",
                    "label": 0
                },
                {
                    "sent": "It is described in the hasty and Tipsy Ronnie Book and it actually looks at the rectangulars rectangles of instances which could be interpreted as subgroups as well.",
                    "label": 0
                },
                {
                    "sent": "And well, there is also work of Suzuki.",
                    "label": 0
                },
                {
                    "sent": "Exception rules well.",
                    "label": 0
                },
                {
                    "sent": "Quite a lot of related work, but not exactly subgroup discovery.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I have a question about the.",
                    "label": 0
                },
                {
                    "sent": "When you're searching for this gene.",
                    "label": 0
                },
                {
                    "sent": "Well, obviously we're not overfitting because our heuristic is not intended at overfitting because it is a tradeoff between coverage and precision, so it is quite vague.",
                    "label": 0
                },
                {
                    "sent": "It doesn't optimize the accuracy gain.",
                    "label": 0
                },
                {
                    "sent": "So we made.",
                    "label": 0
                },
                {
                    "sent": "So we basically don't overfit, I would say.",
                    "label": 0
                },
                {
                    "sent": "Your wife is.",
                    "label": 0
                },
                {
                    "sent": "Let's say without reduction in data because there are many if you combine certain genes in such a small data set and enter the same information, yeah, well, that is a good question.",
                    "label": 0
                },
                {
                    "sent": "So let's say once you have generated many subgroup descriptions, what do you do with that?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Our current approach is that either we generate all of them within certain constraints and then we use this weighted covering algorithm in the post processing step in the sense that we first take the best rule.",
                    "label": 0
                },
                {
                    "sent": "Then we delete.",
                    "label": 0
                },
                {
                    "sent": "We reduce the weights of these examples covered by this best rule, and then we look at all the other rules and we rank them according to the weighted relative accuracy.",
                    "label": 0
                },
                {
                    "sent": "But now with the decreased values of weights of instances of which have been covered by the first rule.",
                    "label": 0
                },
                {
                    "sent": "So that's our approach to reducing the set of subgroups which can be induced.",
                    "label": 0
                },
                {
                    "sent": "But I for instance close gun and verbal have a different approach which is called.",
                    "label": 0
                },
                {
                    "sent": "You help me?",
                    "label": 0
                },
                {
                    "sent": "Compression I think.",
                    "label": 0
                },
                {
                    "sent": "I think it's well, I don't know, but they have a different approach.",
                    "label": 0
                },
                {
                    "sent": "Suppression, yeah?",
                    "label": 0
                },
                {
                    "sent": "Yeah, sure sure.",
                    "label": 0
                },
                {
                    "sent": "I mean, and with every data mining approach like with the.",
                    "label": 0
                },
                {
                    "sent": "Association rule learning and with all this, when you are billed exhaustively, building all the interesting patterns, and then how to reduce this to a manageable size.",
                    "label": 0
                },
                {
                    "sent": "You still use them, yeah?",
                    "label": 0
                },
                {
                    "sent": "Global criterion yeah.",
                    "label": 0
                },
                {
                    "sent": "The accuracy on the training set was validated.",
                    "label": 0
                },
                {
                    "sent": "Let's say it is a measure and then you may want to try to select a subset of the rooms that optimizing that letter.",
                    "label": 0
                },
                {
                    "sent": "Here in Suffolk Discovery is not obvious what the global quality measure.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean so I didn't have time to look into this, but we have analyzed all these algorithms also in the aerospace and obviously you can see every subgroup as being a point in the aerospace somewhere because it covers a certain number of positives and it covers certain number of negatives and when selecting between these different.",
                    "label": 0
                },
                {
                    "sent": "Subgroup descriptions you could say, well, I will only choose those which are at the arosi curve, so that's one of the possible views.",
                    "label": 0
                },
                {
                    "sent": "How to select a set of interesting subgroups out of all the subgroups.",
                    "label": 0
                },
                {
                    "sent": "Or at least those which are close enough to the arosi convex Hull.",
                    "label": 0
                },
                {
                    "sent": "Maybe it would be interesting to try some utility function.",
                    "label": 0
                },
                {
                    "sent": "For the first case, when we were talking about which are operational.",
                    "label": 0
                },
                {
                    "sent": "Jackie, finally yeah, that's for sure.",
                    "label": 0
                },
                {
                    "sent": "I mean, the point is that subgroup discovery actually can be viewed as a kind of cost sensitive learning.",
                    "label": 0
                },
                {
                    "sent": "And by modeling the costs you can actually you will actually get different subgroups as being the most interesting.",
                    "label": 0
                },
                {
                    "sent": "That's for sure.",
                    "label": 0
                },
                {
                    "sent": "You were using directions there.",
                    "label": 0
                },
                {
                    "sent": "How are the computer they are obtained from the gene ontology that's there simply modeled by relation between 2:00, so.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Sorry yeah, so they they are simply stated as facts.",
                    "label": 0
                },
                {
                    "sent": "Interactions among peers or.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        }
    }
}