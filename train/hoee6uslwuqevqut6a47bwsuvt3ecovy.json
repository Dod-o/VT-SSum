{
    "id": "hoee6uslwuqevqut6a47bwsuvt3ecovy",
    "title": "Generalization Analysis of Listwise Learning-to-Rank Algorithms",
    "info": {
        "author": [
            "Hang Li, Microsoft Research Asia, Microsoft Research"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Recommender Systems"
        ]
    },
    "url": "http://videolectures.net/icml09_li_galltra/",
    "segmentation": [
        [
            "Good morning, so I'm going to present our paper entitled Generalization Analysis of Listwise learning to rank algorithms.",
            "This is joint work with Jen Lantian do trimming MA."
        ],
        [
            "So let's consider the learning to rank problem with information retrieval as an example.",
            "So we have two systems learning system, an ranking system.",
            "So given some training data, the learning system tries to construct a ranking model by minimizing a loss function.",
            "And.",
            "Ranking system takes a query and its associated documents as input and.",
            "Riford to the ranking model and ranks the documents by applying the ranking function.",
            "OK, so the training data consists of queries and documents.",
            "Each query is associated with a number of documents and labels are assigned to the documents.",
            "For example, here we have a query Q1 and its associated documents are D11D12D1N1 OK and we also have labels like this and the labels can be in different forms.",
            "They can be binary labels, multiple labels representing multiple levels of relevance, for example.",
            "The labels can also be given as orders of document pairs.",
            "And they can also be given as a permutation of documents.",
            "OK, so the ranking model is a function of query and document.",
            "OK, single query and a single document with the parameter.",
            "WW usually is Victor and so in ranking.",
            "So given the query and associated documents from D1 to DN, the ranking system ranks.",
            "The documents by looking at the scores given by the ranking model.",
            "OK, so the ranking represents degree of relevance.",
            "For example, in information retrieval."
        ],
        [
            "And so because of its importance, there have been many methods proposed for learning to rank in recent years.",
            "So in our view there are three groups.",
            "There are pointwise, pairwise and listwise approaches to learning to rank.",
            "Particularly recently, listwise approach is very popular.",
            "Many new algorithms have been proposed.",
            "For example, so at rank list net soft rank as an SVM AP etc.",
            "So we think that the listwise approach represents the state of the art, cause it more naturally formalize the ranking problem, particularly for information retrieval.",
            "And it has shown better performance than the peer wise and.",
            "Pointwise approaches in general.",
            "So there are."
        ],
        [
            "Many new algorithms proposed for the listwise approach, but as far as I know, as we know there was not much work on theoretical analysis on the leastwise methods, so this is exactly the motivation of this work.",
            "We try to conduct generalization analysis of leastwise algorithms, so as far as we know, for example, previously there were some studies on peer wise algorithms.",
            "For example, we proposed.",
            "A framework for analyzing."
        ],
        [
            "Pairwise algorithms and we also have analyzed the generalization ability of pairwise algorithms.",
            "So in this work we try to conduct generalization analysis on the listwise approach.",
            "So these are the contributions of our work.",
            "So we have proposed a general framework for analyzing leastwise algorithms, and we have given a generalization bound for this device algorithms.",
            "Specifically, we have analyzed three algorithms belonging to the leastwise category, so they are least Emery.",
            "List net and rank cosine.",
            "So, so in this talk I'll first give you."
        ],
        [
            "The introduction on the list wise algorithms, and then I will introduce our general framework for conducting journalism, generalization analysis of learning to rank algorithms, particularly leastwise algorithms.",
            "I will then introduce our result on the generalization ability of leastwise algorithms, and then I'll finish my talk by some remarks on.",
            "On the result and few."
        ],
        [
            "To work.",
            "So first, let's look at the differences between the pointwise pairwise and the least wise approaches.",
            "So, very roughly speaking, all these approaches employ the same model.",
            "The major differences lie in the loss functions used in the different approaches.",
            "So again, let's look at the information retrieval example.",
            "So given a query, we have a number of associated documents, so we can generate feature vectors from the.",
            "Query and the documents.",
            "For example we have feature vectors from X1 to XN.",
            "All of them are associated with the query Q and we also have some labels Y one to YM.",
            "So suppose we use multiple levels of rating.",
            "OK, So what I want YM can be for example from one to five representing different degrees of relevance, and so this is a single example.",
            "In learning to rank and so for the pointwise approach, we actually derive examples from this data, and so each instance in the pointwise approaches training instance is appear of XYX is a feature vector, Y is a label, so it's very similar to that used in traditional machine learning like regression and classification.",
            "OK, so that's why.",
            "People try to use traditional machine learning algorithms to the ranking by using the pointwise approach.",
            "So you can simply apply the existing approaches of regression or classification to the ranking problem.",
            "By taking this approach OK, so the loss function looks like this.",
            "It's only a function of a pair of XY.",
            "And the F. So let's look at the pairwise approach.",
            "So in this case, each training instance is appear is an ordered pair of feature vectors.",
            "OK, so we have two vectors XI, an XJ, and we know that their order their ranking order, so this is 1 instance.",
            "This consists of 1 instance for the pairwise approach.",
            "So we have a number of.",
            "Such kind of instances derived from one data in linear rank and then we can take the pairwise approach.",
            "For example, we can apply the pairwise classification techniques to this problem so the loss function for the pairwise approach looks like this.",
            "So let's look at the list wise approach, then next.",
            "So in the least wise approach.",
            "So actually each instance is more.",
            "Complicated, it is directly taken from the data in information retrieval.",
            "The query and its associated feature vectors and labels.",
            "So each instance is a permutation on the feature vectors, so we have a set of feature vectors from X1 to XN.",
            "We also have YY represent a permutation on the whole set of feature vectors.",
            "OK, so then we can define.",
            "Loss function based on the the instance and the ranking model.",
            "OK, so these are the differences between the two.",
            "The three approaches and you can see from this example the listwise approach.",
            "More naturally more reasonably represents the problem of ranking in in IR, so we think it's more powerful in practice, 'cause in our ranking you care about the relative order of the feature vectors.",
            "The documents and the listwise approach exactly defines the."
        ],
        [
            "Loss function in that way.",
            "So next, let's look into the details of the loss function in the listwise approach.",
            "So again, so we have feature vectors from X1 to XN.",
            "We use Z to represent all of them.",
            "The set of the feature vectors, and now we're trying to construct the ranking function.",
            "FF is defined on the individual feature vectors.",
            "OK, so by applying F we can get a list of scores on all the feature vectors from.",
            "FX12FX M OK and we can also think about another list of scores based on the ground truth.",
            "In training we are given some ground truth.",
            "We can derive a list of course based on the ground ground truth.",
            "We represent them as gyz.",
            "So for example, if we are given some labels as ground truth representing the degrees of relevance so we can just use the labels.",
            "To generate this list of scores, for example 543121 etc.",
            "Right so then the question is we want in training which we try to build a good ranking model which can be very close to the ground truth, right?",
            "So in the least wise approach, the idea is we introduce a transformation function and we transform both the two.",
            "Functions FG&GYZ and then we get two list of scores by applying a kind of transformation and then in this way we can.",
            "We can easily compare the differences between the two lists of scores, right?",
            "Because originally it would be hard to make comparison between two lists of the scores.",
            "One is from the ranking model, the other is from the ground truth.",
            "Usually hard make comparison, but if we have in general.",
            "Introduce a transformation function.",
            "Then it will be easy for us to make comparison between the two lists of scores, and this is exactly the idea of the listwise approach.",
            "So by defining different similarity measures between the two lists of the final scores, then we can introduce different types of loss functions and so."
        ],
        [
            "For example, in the, let's look at this one in the run cosine method, so we can just define a kind of cosine similarity similarity between the final two lists of scores and define a loss function like this based on the cosine similarity, and so in.",
            "This way we can easily compare the differences between two lists of scores and that means kind of loss function between the ranking model and the ground truth.",
            "OK, so in the.",
            "Listen at approach.",
            "The idea is because we have already 2 lists of scores.",
            "We can transfer them.",
            "We can further define them as probabilities.",
            "We can use the loose model in statistics and use the care divergance to calculate the distance between the two distribution probability distributions.",
            "One is from the ranking model, the other is from the ground truth.",
            "So then we can use the care divergent as a kind of loss function to compare the differences.",
            "Between the ranking model under the ground truth.",
            "So this is the idea of listen at least Emery.",
            "We can think about using.",
            "The logarithmic loss function as distance between the probabilities of two lists.",
            "One is from ranking model, the other is from the ground truth.",
            "So these are the ideas of listwise algorithms again, so they employ different loss functions, but they can use the simple and linear model or exactly the same model for ranking.",
            "So we represent them as F here, right?",
            "So the major differences?",
            "Lie in."
        ],
        [
            "Loss functions use in the algorithms."
        ],
        [
            "So now the question is, can we conduct some kind of theoretical analysis on the leastwise algorithms or on in general all the other?"
        ],
        [
            "Learning to rank algorithms here we propose a kind of framework for performing the analysis.",
            "So the idea is very simple and it's the same as that used in general machine learning.",
            "So we can think about we have data like this.",
            "We use ZY to represent one single data.",
            "We have the symbol, one single data instance.",
            "We have, so Z is a feature vector.",
            "Again, C consists of a number of feature vectors.",
            "From X1 to XM&Y is ground truth.",
            "It represent the permutation in the listwise approach.",
            "So we can think about Cy as random variables and they represent random variables according to a joint probability distribution.",
            "OK, so, and we assume that in training we get some ID data from this unknown probability distribution and then so as usual we can define.",
            "Expected risk and empirical risk for this learning task.",
            "OK, so we use the listwise loss function here for the definition of expected risk and empirical risk."
        ],
        [
            "And then the question is so how we achieve the expected risk?",
            "Usually because we don't know the joint probability distribution.",
            "We have to minimize the empirical risk instead.",
            "And so there is a difference between the empirical risk and the expected risk.",
            "And this is exactly we want to know the difference and the generalization analysis is exactly about.",
            "Theoretical analysis on the differences on the bound.",
            "And."
        ],
        [
            "So in our case we have.",
            "Developed a new tech."
        ],
        [
            "Seek to analyze the generalization ability of leastwise algorithms, so the generalization analyst techniques is something like this.",
            "So we use red matcher average as a quantity as a technique in the proof of the generalization ability, and we derive generalization bound based on the red Metro average.",
            "And we further this is a general bound and further derive some bonds for specific algorithms of list in America list net and rank cosine.",
            "So this is the definition of the red marker average.",
            "So suppose we have a general ranking function, last G, and so we can define a quantity called empirical red."
        ],
        [
            "Natural average like this and so here.",
            "XI's eyes are iid random variables and Sigma eyes ID random variables as well.",
            "So we first have a small G is a function within the LG G and we have GSI and times Sigma I and we take average over North is the data size and we.",
            "Take a soup and finally we take expectation over the Sigma.",
            "So this is definition of the empirical Rademacher average.",
            "An with this quantity."
        ],
        [
            "We can prove we can derive a generalization bound like this, so by applying the result of Bartlett and Mendelsohn so we can get the bound like this.",
            "The first term on the right hand side is the red match or average.",
            "And it's a red Metro average of the compound function whose outer function is the least wise loss function, and the inner function is the ranking function.",
            "So we have the red marker average like this.",
            "So we have ranking function and also the loss function in the least wise algorithms.",
            "And so we can further derive bounds on this red Metro average.",
            "Answer for different."
        ],
        [
            "Algorithms, for example, for the so we for the general red marker average for leastwise algorithm it is bounded by this quantity and it consists of three factors.",
            "The first one depends on the transformation function fine, and there's this one in five depends on the transformation function and will also have a factor depends on the specific algorithms.",
            "Loss functions and the final one is Red Marshall.",
            "Average of the ranking model.",
            "So according to previous work we can easily derive the red marker average of this of this ranking model."
        ],
        [
            "So in this way we can obtain the general bound for this twice algorithms with probability at least 1 -- 30.",
            "We can have a bound like this, so the right hand side contains several factors.",
            "The CCNC A5 depends on the specific algorithms.",
            "So the M5 only depends on the transformation function.",
            "So this the entire right hand side is only a function of.",
            "The sample size N and."
        ],
        [
            "It's only order this that means when the sample size goes to Infinity so the red hand side will vanish with the rate of this and we also have some other reason."
        ],
        [
            "So to conclude, in this work we have proposed a new framework for analyzing leastwise algorithms, and we have derived generalization bound for leastwise algorithms, including list, netlist, memory and run cosine."
        ],
        [
            "So in the future we would like to further apply these algorithms to other techniques and also conduct some empirical studies and also to study other properties of listwise algorithms like approximation error, thank you."
        ],
        [
            "Questions."
        ],
        [
            "I was wondering whether.",
            "Fact that you are working with the lists really comes into.",
            "To play mean you have a general, you have presented a general framework which looks very much like supervised learning.",
            "Your people out of their generated ID and so on.",
            "But where exactly does not reflect that you are working with lists come into play.",
            "Specific components of your results.",
            "Sorry I didn't get your point.",
            "So what do you mean by come to play so?",
            "I mean you have a set of objects you have a loss function.",
            "Yes, yes.",
            "Basically applied not only to list.",
            "That's what every kind of input that you get us training information.",
            "But my question is, what is list specific?",
            "OK, OK, OK, so your question is what this basically I think the structure is quite specific, so you have a list of feature vectors, a number of feature vectors.",
            "They are not ID they are dependent right?",
            "Given a query we retrieve a number of documents that usually dependent so that kind of structure make this very.",
            "Make the learning task really unique on the top of the structure you have ID data exactly, but when you look at individual instance, each of them actually has a very rich structure and so it's not so easy to deal with in learning because the ranking model is based on one individual feature vector is not defined on the whole list of feature vectors.",
            "That's the major difference and in.",
            "In as I think in the model part and in practice there are also other challenges like how to create this twice data so we can derive this wise data from pairs or pointwise data.",
            "But still ideally we would be.",
            "It would be better to have leastwise data for example.",
            "That's another challenge in practice because these represent the problem more naturally, but it's, but it's hard to get the data.",
            "Did I answer your question?",
            "One more question.",
            "We have more than one sample like is ever greater than one.",
            "Independence.",
            "Give me a query.",
            "You have a number of documents, right?",
            "They are not dependent independent.",
            "So.",
            "Sorry.",
            "Suppose that point is.",
            "I.",
            "It's just one data point for each.",
            "For each query the query, but we think the data points.",
            "You have many documents and each of them has reached structure and also the ranking model is defined based on one query, usually one query on one single document.",
            "Skills do this custom turn off set skills.",
            "Gross yeah yeah yeah yeah yeah.",
            "Application to learning to rank.",
            "Do you ever have more than one data point in this setting?",
            "We have usually have many data points, but not so many.",
            "Yeah, maybe we can talk offline.",
            "Thank you.",
            "Lunch Break is now and I believe the next sessions start at 2.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning, so I'm going to present our paper entitled Generalization Analysis of Listwise learning to rank algorithms.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with Jen Lantian do trimming MA.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's consider the learning to rank problem with information retrieval as an example.",
                    "label": 1
                },
                {
                    "sent": "So we have two systems learning system, an ranking system.",
                    "label": 0
                },
                {
                    "sent": "So given some training data, the learning system tries to construct a ranking model by minimizing a loss function.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Ranking system takes a query and its associated documents as input and.",
                    "label": 1
                },
                {
                    "sent": "Riford to the ranking model and ranks the documents by applying the ranking function.",
                    "label": 0
                },
                {
                    "sent": "OK, so the training data consists of queries and documents.",
                    "label": 0
                },
                {
                    "sent": "Each query is associated with a number of documents and labels are assigned to the documents.",
                    "label": 1
                },
                {
                    "sent": "For example, here we have a query Q1 and its associated documents are D11D12D1N1 OK and we also have labels like this and the labels can be in different forms.",
                    "label": 1
                },
                {
                    "sent": "They can be binary labels, multiple labels representing multiple levels of relevance, for example.",
                    "label": 1
                },
                {
                    "sent": "The labels can also be given as orders of document pairs.",
                    "label": 0
                },
                {
                    "sent": "And they can also be given as a permutation of documents.",
                    "label": 0
                },
                {
                    "sent": "OK, so the ranking model is a function of query and document.",
                    "label": 0
                },
                {
                    "sent": "OK, single query and a single document with the parameter.",
                    "label": 0
                },
                {
                    "sent": "WW usually is Victor and so in ranking.",
                    "label": 0
                },
                {
                    "sent": "So given the query and associated documents from D1 to DN, the ranking system ranks.",
                    "label": 0
                },
                {
                    "sent": "The documents by looking at the scores given by the ranking model.",
                    "label": 0
                },
                {
                    "sent": "OK, so the ranking represents degree of relevance.",
                    "label": 0
                },
                {
                    "sent": "For example, in information retrieval.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so because of its importance, there have been many methods proposed for learning to rank in recent years.",
                    "label": 0
                },
                {
                    "sent": "So in our view there are three groups.",
                    "label": 0
                },
                {
                    "sent": "There are pointwise, pairwise and listwise approaches to learning to rank.",
                    "label": 1
                },
                {
                    "sent": "Particularly recently, listwise approach is very popular.",
                    "label": 0
                },
                {
                    "sent": "Many new algorithms have been proposed.",
                    "label": 0
                },
                {
                    "sent": "For example, so at rank list net soft rank as an SVM AP etc.",
                    "label": 0
                },
                {
                    "sent": "So we think that the listwise approach represents the state of the art, cause it more naturally formalize the ranking problem, particularly for information retrieval.",
                    "label": 0
                },
                {
                    "sent": "And it has shown better performance than the peer wise and.",
                    "label": 0
                },
                {
                    "sent": "Pointwise approaches in general.",
                    "label": 0
                },
                {
                    "sent": "So there are.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many new algorithms proposed for the listwise approach, but as far as I know, as we know there was not much work on theoretical analysis on the leastwise methods, so this is exactly the motivation of this work.",
                    "label": 0
                },
                {
                    "sent": "We try to conduct generalization analysis of leastwise algorithms, so as far as we know, for example, previously there were some studies on peer wise algorithms.",
                    "label": 0
                },
                {
                    "sent": "For example, we proposed.",
                    "label": 0
                },
                {
                    "sent": "A framework for analyzing.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pairwise algorithms and we also have analyzed the generalization ability of pairwise algorithms.",
                    "label": 1
                },
                {
                    "sent": "So in this work we try to conduct generalization analysis on the listwise approach.",
                    "label": 0
                },
                {
                    "sent": "So these are the contributions of our work.",
                    "label": 0
                },
                {
                    "sent": "So we have proposed a general framework for analyzing leastwise algorithms, and we have given a generalization bound for this device algorithms.",
                    "label": 0
                },
                {
                    "sent": "Specifically, we have analyzed three algorithms belonging to the leastwise category, so they are least Emery.",
                    "label": 0
                },
                {
                    "sent": "List net and rank cosine.",
                    "label": 0
                },
                {
                    "sent": "So, so in this talk I'll first give you.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The introduction on the list wise algorithms, and then I will introduce our general framework for conducting journalism, generalization analysis of learning to rank algorithms, particularly leastwise algorithms.",
                    "label": 1
                },
                {
                    "sent": "I will then introduce our result on the generalization ability of leastwise algorithms, and then I'll finish my talk by some remarks on.",
                    "label": 0
                },
                {
                    "sent": "On the result and few.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To work.",
                    "label": 0
                },
                {
                    "sent": "So first, let's look at the differences between the pointwise pairwise and the least wise approaches.",
                    "label": 1
                },
                {
                    "sent": "So, very roughly speaking, all these approaches employ the same model.",
                    "label": 0
                },
                {
                    "sent": "The major differences lie in the loss functions used in the different approaches.",
                    "label": 0
                },
                {
                    "sent": "So again, let's look at the information retrieval example.",
                    "label": 0
                },
                {
                    "sent": "So given a query, we have a number of associated documents, so we can generate feature vectors from the.",
                    "label": 0
                },
                {
                    "sent": "Query and the documents.",
                    "label": 0
                },
                {
                    "sent": "For example we have feature vectors from X1 to XN.",
                    "label": 0
                },
                {
                    "sent": "All of them are associated with the query Q and we also have some labels Y one to YM.",
                    "label": 0
                },
                {
                    "sent": "So suppose we use multiple levels of rating.",
                    "label": 0
                },
                {
                    "sent": "OK, So what I want YM can be for example from one to five representing different degrees of relevance, and so this is a single example.",
                    "label": 1
                },
                {
                    "sent": "In learning to rank and so for the pointwise approach, we actually derive examples from this data, and so each instance in the pointwise approaches training instance is appear of XYX is a feature vector, Y is a label, so it's very similar to that used in traditional machine learning like regression and classification.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's why.",
                    "label": 0
                },
                {
                    "sent": "People try to use traditional machine learning algorithms to the ranking by using the pointwise approach.",
                    "label": 0
                },
                {
                    "sent": "So you can simply apply the existing approaches of regression or classification to the ranking problem.",
                    "label": 0
                },
                {
                    "sent": "By taking this approach OK, so the loss function looks like this.",
                    "label": 0
                },
                {
                    "sent": "It's only a function of a pair of XY.",
                    "label": 0
                },
                {
                    "sent": "And the F. So let's look at the pairwise approach.",
                    "label": 0
                },
                {
                    "sent": "So in this case, each training instance is appear is an ordered pair of feature vectors.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have two vectors XI, an XJ, and we know that their order their ranking order, so this is 1 instance.",
                    "label": 1
                },
                {
                    "sent": "This consists of 1 instance for the pairwise approach.",
                    "label": 0
                },
                {
                    "sent": "So we have a number of.",
                    "label": 0
                },
                {
                    "sent": "Such kind of instances derived from one data in linear rank and then we can take the pairwise approach.",
                    "label": 0
                },
                {
                    "sent": "For example, we can apply the pairwise classification techniques to this problem so the loss function for the pairwise approach looks like this.",
                    "label": 0
                },
                {
                    "sent": "So let's look at the list wise approach, then next.",
                    "label": 0
                },
                {
                    "sent": "So in the least wise approach.",
                    "label": 0
                },
                {
                    "sent": "So actually each instance is more.",
                    "label": 0
                },
                {
                    "sent": "Complicated, it is directly taken from the data in information retrieval.",
                    "label": 0
                },
                {
                    "sent": "The query and its associated feature vectors and labels.",
                    "label": 0
                },
                {
                    "sent": "So each instance is a permutation on the feature vectors, so we have a set of feature vectors from X1 to XN.",
                    "label": 0
                },
                {
                    "sent": "We also have YY represent a permutation on the whole set of feature vectors.",
                    "label": 0
                },
                {
                    "sent": "OK, so then we can define.",
                    "label": 0
                },
                {
                    "sent": "Loss function based on the the instance and the ranking model.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are the differences between the two.",
                    "label": 0
                },
                {
                    "sent": "The three approaches and you can see from this example the listwise approach.",
                    "label": 1
                },
                {
                    "sent": "More naturally more reasonably represents the problem of ranking in in IR, so we think it's more powerful in practice, 'cause in our ranking you care about the relative order of the feature vectors.",
                    "label": 0
                },
                {
                    "sent": "The documents and the listwise approach exactly defines the.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Loss function in that way.",
                    "label": 0
                },
                {
                    "sent": "So next, let's look into the details of the loss function in the listwise approach.",
                    "label": 0
                },
                {
                    "sent": "So again, so we have feature vectors from X1 to XN.",
                    "label": 0
                },
                {
                    "sent": "We use Z to represent all of them.",
                    "label": 0
                },
                {
                    "sent": "The set of the feature vectors, and now we're trying to construct the ranking function.",
                    "label": 0
                },
                {
                    "sent": "FF is defined on the individual feature vectors.",
                    "label": 0
                },
                {
                    "sent": "OK, so by applying F we can get a list of scores on all the feature vectors from.",
                    "label": 0
                },
                {
                    "sent": "FX12FX M OK and we can also think about another list of scores based on the ground truth.",
                    "label": 0
                },
                {
                    "sent": "In training we are given some ground truth.",
                    "label": 0
                },
                {
                    "sent": "We can derive a list of course based on the ground ground truth.",
                    "label": 0
                },
                {
                    "sent": "We represent them as gyz.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we are given some labels as ground truth representing the degrees of relevance so we can just use the labels.",
                    "label": 0
                },
                {
                    "sent": "To generate this list of scores, for example 543121 etc.",
                    "label": 0
                },
                {
                    "sent": "Right so then the question is we want in training which we try to build a good ranking model which can be very close to the ground truth, right?",
                    "label": 0
                },
                {
                    "sent": "So in the least wise approach, the idea is we introduce a transformation function and we transform both the two.",
                    "label": 0
                },
                {
                    "sent": "Functions FG&GYZ and then we get two list of scores by applying a kind of transformation and then in this way we can.",
                    "label": 0
                },
                {
                    "sent": "We can easily compare the differences between the two lists of scores, right?",
                    "label": 0
                },
                {
                    "sent": "Because originally it would be hard to make comparison between two lists of the scores.",
                    "label": 0
                },
                {
                    "sent": "One is from the ranking model, the other is from the ground truth.",
                    "label": 0
                },
                {
                    "sent": "Usually hard make comparison, but if we have in general.",
                    "label": 0
                },
                {
                    "sent": "Introduce a transformation function.",
                    "label": 0
                },
                {
                    "sent": "Then it will be easy for us to make comparison between the two lists of scores, and this is exactly the idea of the listwise approach.",
                    "label": 0
                },
                {
                    "sent": "So by defining different similarity measures between the two lists of the final scores, then we can introduce different types of loss functions and so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, in the, let's look at this one in the run cosine method, so we can just define a kind of cosine similarity similarity between the final two lists of scores and define a loss function like this based on the cosine similarity, and so in.",
                    "label": 0
                },
                {
                    "sent": "This way we can easily compare the differences between two lists of scores and that means kind of loss function between the ranking model and the ground truth.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the.",
                    "label": 0
                },
                {
                    "sent": "Listen at approach.",
                    "label": 0
                },
                {
                    "sent": "The idea is because we have already 2 lists of scores.",
                    "label": 0
                },
                {
                    "sent": "We can transfer them.",
                    "label": 0
                },
                {
                    "sent": "We can further define them as probabilities.",
                    "label": 0
                },
                {
                    "sent": "We can use the loose model in statistics and use the care divergance to calculate the distance between the two distribution probability distributions.",
                    "label": 0
                },
                {
                    "sent": "One is from the ranking model, the other is from the ground truth.",
                    "label": 0
                },
                {
                    "sent": "So then we can use the care divergent as a kind of loss function to compare the differences.",
                    "label": 0
                },
                {
                    "sent": "Between the ranking model under the ground truth.",
                    "label": 0
                },
                {
                    "sent": "So this is the idea of listen at least Emery.",
                    "label": 0
                },
                {
                    "sent": "We can think about using.",
                    "label": 0
                },
                {
                    "sent": "The logarithmic loss function as distance between the probabilities of two lists.",
                    "label": 0
                },
                {
                    "sent": "One is from ranking model, the other is from the ground truth.",
                    "label": 0
                },
                {
                    "sent": "So these are the ideas of listwise algorithms again, so they employ different loss functions, but they can use the simple and linear model or exactly the same model for ranking.",
                    "label": 0
                },
                {
                    "sent": "So we represent them as F here, right?",
                    "label": 0
                },
                {
                    "sent": "So the major differences?",
                    "label": 0
                },
                {
                    "sent": "Lie in.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Loss functions use in the algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now the question is, can we conduct some kind of theoretical analysis on the leastwise algorithms or on in general all the other?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learning to rank algorithms here we propose a kind of framework for performing the analysis.",
                    "label": 0
                },
                {
                    "sent": "So the idea is very simple and it's the same as that used in general machine learning.",
                    "label": 0
                },
                {
                    "sent": "So we can think about we have data like this.",
                    "label": 0
                },
                {
                    "sent": "We use ZY to represent one single data.",
                    "label": 0
                },
                {
                    "sent": "We have the symbol, one single data instance.",
                    "label": 0
                },
                {
                    "sent": "We have, so Z is a feature vector.",
                    "label": 0
                },
                {
                    "sent": "Again, C consists of a number of feature vectors.",
                    "label": 0
                },
                {
                    "sent": "From X1 to XM&Y is ground truth.",
                    "label": 0
                },
                {
                    "sent": "It represent the permutation in the listwise approach.",
                    "label": 0
                },
                {
                    "sent": "So we can think about Cy as random variables and they represent random variables according to a joint probability distribution.",
                    "label": 1
                },
                {
                    "sent": "OK, so, and we assume that in training we get some ID data from this unknown probability distribution and then so as usual we can define.",
                    "label": 1
                },
                {
                    "sent": "Expected risk and empirical risk for this learning task.",
                    "label": 0
                },
                {
                    "sent": "OK, so we use the listwise loss function here for the definition of expected risk and empirical risk.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then the question is so how we achieve the expected risk?",
                    "label": 0
                },
                {
                    "sent": "Usually because we don't know the joint probability distribution.",
                    "label": 0
                },
                {
                    "sent": "We have to minimize the empirical risk instead.",
                    "label": 1
                },
                {
                    "sent": "And so there is a difference between the empirical risk and the expected risk.",
                    "label": 1
                },
                {
                    "sent": "And this is exactly we want to know the difference and the generalization analysis is exactly about.",
                    "label": 0
                },
                {
                    "sent": "Theoretical analysis on the differences on the bound.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in our case we have.",
                    "label": 0
                },
                {
                    "sent": "Developed a new tech.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Seek to analyze the generalization ability of leastwise algorithms, so the generalization analyst techniques is something like this.",
                    "label": 0
                },
                {
                    "sent": "So we use red matcher average as a quantity as a technique in the proof of the generalization ability, and we derive generalization bound based on the red Metro average.",
                    "label": 1
                },
                {
                    "sent": "And we further this is a general bound and further derive some bonds for specific algorithms of list in America list net and rank cosine.",
                    "label": 0
                },
                {
                    "sent": "So this is the definition of the red marker average.",
                    "label": 0
                },
                {
                    "sent": "So suppose we have a general ranking function, last G, and so we can define a quantity called empirical red.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Natural average like this and so here.",
                    "label": 0
                },
                {
                    "sent": "XI's eyes are iid random variables and Sigma eyes ID random variables as well.",
                    "label": 1
                },
                {
                    "sent": "So we first have a small G is a function within the LG G and we have GSI and times Sigma I and we take average over North is the data size and we.",
                    "label": 0
                },
                {
                    "sent": "Take a soup and finally we take expectation over the Sigma.",
                    "label": 1
                },
                {
                    "sent": "So this is definition of the empirical Rademacher average.",
                    "label": 0
                },
                {
                    "sent": "An with this quantity.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can prove we can derive a generalization bound like this, so by applying the result of Bartlett and Mendelsohn so we can get the bound like this.",
                    "label": 0
                },
                {
                    "sent": "The first term on the right hand side is the red match or average.",
                    "label": 0
                },
                {
                    "sent": "And it's a red Metro average of the compound function whose outer function is the least wise loss function, and the inner function is the ranking function.",
                    "label": 1
                },
                {
                    "sent": "So we have the red marker average like this.",
                    "label": 0
                },
                {
                    "sent": "So we have ranking function and also the loss function in the least wise algorithms.",
                    "label": 0
                },
                {
                    "sent": "And so we can further derive bounds on this red Metro average.",
                    "label": 0
                },
                {
                    "sent": "Answer for different.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Algorithms, for example, for the so we for the general red marker average for leastwise algorithm it is bounded by this quantity and it consists of three factors.",
                    "label": 0
                },
                {
                    "sent": "The first one depends on the transformation function fine, and there's this one in five depends on the transformation function and will also have a factor depends on the specific algorithms.",
                    "label": 0
                },
                {
                    "sent": "Loss functions and the final one is Red Marshall.",
                    "label": 0
                },
                {
                    "sent": "Average of the ranking model.",
                    "label": 0
                },
                {
                    "sent": "So according to previous work we can easily derive the red marker average of this of this ranking model.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this way we can obtain the general bound for this twice algorithms with probability at least 1 -- 30.",
                    "label": 1
                },
                {
                    "sent": "We can have a bound like this, so the right hand side contains several factors.",
                    "label": 0
                },
                {
                    "sent": "The CCNC A5 depends on the specific algorithms.",
                    "label": 1
                },
                {
                    "sent": "So the M5 only depends on the transformation function.",
                    "label": 0
                },
                {
                    "sent": "So this the entire right hand side is only a function of.",
                    "label": 0
                },
                {
                    "sent": "The sample size N and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's only order this that means when the sample size goes to Infinity so the red hand side will vanish with the rate of this and we also have some other reason.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to conclude, in this work we have proposed a new framework for analyzing leastwise algorithms, and we have derived generalization bound for leastwise algorithms, including list, netlist, memory and run cosine.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the future we would like to further apply these algorithms to other techniques and also conduct some empirical studies and also to study other properties of listwise algorithms like approximation error, thank you.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Questions.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I was wondering whether.",
                    "label": 0
                },
                {
                    "sent": "Fact that you are working with the lists really comes into.",
                    "label": 0
                },
                {
                    "sent": "To play mean you have a general, you have presented a general framework which looks very much like supervised learning.",
                    "label": 0
                },
                {
                    "sent": "Your people out of their generated ID and so on.",
                    "label": 0
                },
                {
                    "sent": "But where exactly does not reflect that you are working with lists come into play.",
                    "label": 0
                },
                {
                    "sent": "Specific components of your results.",
                    "label": 0
                },
                {
                    "sent": "Sorry I didn't get your point.",
                    "label": 0
                },
                {
                    "sent": "So what do you mean by come to play so?",
                    "label": 0
                },
                {
                    "sent": "I mean you have a set of objects you have a loss function.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes.",
                    "label": 0
                },
                {
                    "sent": "Basically applied not only to list.",
                    "label": 0
                },
                {
                    "sent": "That's what every kind of input that you get us training information.",
                    "label": 0
                },
                {
                    "sent": "But my question is, what is list specific?",
                    "label": 0
                },
                {
                    "sent": "OK, OK, OK, so your question is what this basically I think the structure is quite specific, so you have a list of feature vectors, a number of feature vectors.",
                    "label": 0
                },
                {
                    "sent": "They are not ID they are dependent right?",
                    "label": 0
                },
                {
                    "sent": "Given a query we retrieve a number of documents that usually dependent so that kind of structure make this very.",
                    "label": 0
                },
                {
                    "sent": "Make the learning task really unique on the top of the structure you have ID data exactly, but when you look at individual instance, each of them actually has a very rich structure and so it's not so easy to deal with in learning because the ranking model is based on one individual feature vector is not defined on the whole list of feature vectors.",
                    "label": 0
                },
                {
                    "sent": "That's the major difference and in.",
                    "label": 0
                },
                {
                    "sent": "In as I think in the model part and in practice there are also other challenges like how to create this twice data so we can derive this wise data from pairs or pointwise data.",
                    "label": 0
                },
                {
                    "sent": "But still ideally we would be.",
                    "label": 0
                },
                {
                    "sent": "It would be better to have leastwise data for example.",
                    "label": 0
                },
                {
                    "sent": "That's another challenge in practice because these represent the problem more naturally, but it's, but it's hard to get the data.",
                    "label": 0
                },
                {
                    "sent": "Did I answer your question?",
                    "label": 0
                },
                {
                    "sent": "One more question.",
                    "label": 0
                },
                {
                    "sent": "We have more than one sample like is ever greater than one.",
                    "label": 0
                },
                {
                    "sent": "Independence.",
                    "label": 0
                },
                {
                    "sent": "Give me a query.",
                    "label": 0
                },
                {
                    "sent": "You have a number of documents, right?",
                    "label": 0
                },
                {
                    "sent": "They are not dependent independent.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Suppose that point is.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "It's just one data point for each.",
                    "label": 0
                },
                {
                    "sent": "For each query the query, but we think the data points.",
                    "label": 0
                },
                {
                    "sent": "You have many documents and each of them has reached structure and also the ranking model is defined based on one query, usually one query on one single document.",
                    "label": 0
                },
                {
                    "sent": "Skills do this custom turn off set skills.",
                    "label": 0
                },
                {
                    "sent": "Gross yeah yeah yeah yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "Application to learning to rank.",
                    "label": 0
                },
                {
                    "sent": "Do you ever have more than one data point in this setting?",
                    "label": 0
                },
                {
                    "sent": "We have usually have many data points, but not so many.",
                    "label": 0
                },
                {
                    "sent": "Yeah, maybe we can talk offline.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Lunch Break is now and I believe the next sessions start at 2.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}