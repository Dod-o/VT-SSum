{
    "id": "77v3lsxkwbxvsvovd7vytjbfhas5qy7q",
    "title": "\u201cClustering by Composition\u201d for Unsupervised Discovery of Image Categories",
    "info": {
        "author": [
            "Alon Faktor, Weizmann Institute of Science"
        ],
        "chairman": [
            "Tinne Tuytelaars, Faculty of Engineering, KU Leuven",
            "Serge J. Belongie, University of California, San Diego"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Machine Learning->Clustering"
        ]
    },
    "url": "http://videolectures.net/eccv2012_faktor_image/",
    "segmentation": [
        [
            "Hi my name is Ron Factor and this is joint work with Kalyani.",
            "So name of the work is clustering by composition for unsupervised discovery of image categories.",
            "So it is the problem we're trying to solve."
        ],
        [
            "Here are 40 images and 20 of these images are."
        ],
        [
            "Adding images and 20 are yoga images and notice the huge variability in appearance of those images.",
            "So very different yoga poses lots of background, clutter, occlusions and so on, yet would like to cluster those images into two clusters of yoga and ballet in it."
        ],
        [
            "Totally unsupervised manner.",
            "No, we were spoken unsupervised category discovery is either dealt with relatively simple pairwise affinity's which cannot handle this.",
            "The huge availability in the appearance of the images I've just shown you or use more sophisticated methods to try to discover a common cluster model.",
            "This may include a common distribution of descriptors, common segments, common shapes, and so on.",
            "The problem is that these methods require a large number of images to learn from, and Moreover, looking at these images, there isn't really any simple model that is common to all of this.",
            "All of these yoga or ballet images.",
            "So it makes images simpler."
        ],
        [
            "So I want to give you a overview of our approach, so we use sophisticated Paris affinity's, which we call affinity by composition.",
            "What do I mean by that?",
            "So let's take a look at the two following Valley, which is.",
            "So those are very different from each other.",
            "One image can be easily composed, like a simple puzzle from the other image using large non trivial pieces.",
            "And if you look at another body image to begin, the images are very different from each other.",
            "But they share this large nontrivial region.",
            "Now notice screen region has a very low chance of occurring at random.",
            "So the fact that we are able to find it at another image provides high evidence to the affinity between the images.",
            "Even if we can't find this region in any of the other Valley images, or in other words, a good region is, which induces high affinity is not necessarily a good segment.",
            "It cannot be extracted ahead of time for image segmentation.",
            "What makes original Good is the fact that it is where it is a low chance of occurring at random, yet it is shared by two images.",
            "Now, it's not that we not be able to compose the body image from yoga image.",
            "We will, but this will be tiny.",
            "Itsy bitsy regions that are more likely to occur at other images, inducing a low affinity between the images.",
            "So this is how we compute our affinity's, but this may seem to like a very tiresome process.",
            "How do you find all these large nontrivial shared regions?",
            "However, in this work we show this can be done very efficiently."
        ],
        [
            "Using a randomized search process with images collaborating with each other to search this shared regions.",
            "In fact, this can be done in time, which is linear in the size of the data set."
        ],
        [
            "And when we play algorithm, this is the kind of results we get able to obtain these two clusters, one mostly of Valley images and second most yoga images and the accuracy of this clustering is very high.",
            "Only three images were miss clustered.",
            "Those that are marked in red.",
            "So this was a high level overview of our approach.",
            "Let's now dive into the details."
        ],
        [
            "So do we compute the affinity between the two images, so we extend previous work?",
            "Bye bye man everybody.",
            "And let's assume that someone marked region in one image and would like to know how much affinity this region induces between the two images.",
            "So we saw before that the region is good if it is shared by two images and is where has a low chance of occurring at window Now this is captured mathematically, but the following likelihood ratio where the top says?",
            "How good is the region match across the two images at the bottom says how well the region is."
        ],
        [
            "And we find the log of this likelihood ratio to be the contribution of the region to the affinity between the two images.",
            "Now the region is made of a bunch of dense descriptors, say hog descriptors and.",
            "If we assume those descriptors are IID."
        ],
        [
            "You write the log likelihood.",
            "Is it additive?",
            "Some in those descriptors.",
            "For the first term."
        ],
        [
            "Measures how good descriptors match across the images.",
            "So for each descriptor we measure how well it matches its corresponding descriptor in the other image.",
            "By allowing small nonrigid deformations during this matching.",
            "And this induces."
        ],
        [
            "This error over here, the second term measures how where is each descriptor, so."
        ],
        [
            "Do we measure how rare is its descriptor?",
            "How statistically significant it is?",
            "So just take any descriptor in any image and ask how likely it is to occur at random.",
            "So for that we take a bunch of images.",
            "This can be any random collection of natural images with images wish to cluster and ask how likely is a descriptor to occur in those images.",
            "So we could try to compute this frequency in those images, but this will take a very long time, so instead we approximate it in the following way.",
            "What we do is we take all descriptors from all images and generate the code book from them just by applying K means and then what will happen is that frequent descriptors will be represented well by the code book, so we have a low error and on the other hand where descriptors will be represented poorly by the code book.",
            "So you have a higher.",
            "So if your computer."
        ],
        [
            "Descriptor its nearest neighbor in the code book that the error to these nearest neighbor will tell us how frequent a descriptor is so we can estimate the log."
        ],
        [
            "Likelihood of a descriptor to occur at random just by its error with respect to the codebook.",
            "So let's see what this gives us.",
            "So here we can see."
        ],
        [
            "Each image to error with respect to the codebook of each of the descriptors.",
            "Red signifies very high error.",
            "Very well descriptors green lower in grayscale.",
            "Very low error.",
            "Very frequent descriptors and what we see here.",
            "It is the most informative descriptors.",
            "Other ones, especially yoga, pose to hand posters.",
            "The ballet dancer and the Hunter and the long horizontal edge between the wall and the floor does not get a high error.",
            "It is not statistically significant because having the horizontal edges occur.",
            "Bentley at natural images.",
            "Note that this is very different from how people usually use code books in classification and recognition.",
            "Usually a codebook is used in order to represent an image.",
            "Here we look for the descriptors that are not represented well by the codebook, and those are the most informative force.",
            "So let's recap the contribution of."
        ],
        [
            "Single region to the affinity between 2 images.",
            "Sequel to the log likelihood between how Good is a region match across the two images versus how well the region is in this bowl is up to the fall."
        ],
        [
            "The expression notice yellow term inside inside says is that for each descriptor we measure its error with respect."
        ],
        [
            "To the codebook and measure its error with respect to its corresponding descriptor in the other image."
        ],
        [
            "And then just take the difference between the two.",
            "And if we like to know the contribution of the entire region, we just have to sum up over all the descriptors inside the region.",
            "Now, if you have more."
        ],
        [
            "People shared regions across the image is all we have to do is just to sum up."
        ],
        [
            "The contributions of the individual regions in these forms are fine."
        ],
        [
            "Affinity now?"
        ],
        [
            "So far we assume the shared regions are given to us.",
            "Now we no longer assume that and show you how to detect those regions very efficiently."
        ],
        [
            "For that we use a randomized search which is inspired by Patch match.",
            "So what we do is that for each descriptor in one image."
        ],
        [
            "We just randomly sampled several descriptors in the other image.",
            "So here are the samples for the yellow descriptor in here."
        ],
        [
            "Samples for the magenta descriptor and here's the samples for the reading Scripture over here.",
            "Now the chance the single descriptor will fall into accurate matching.",
            "The other image is of course very low, but the chance that the single at least one of the descriptors before it's accurate match in the other image is actually very high, and once the script."
        ],
        [
            "Find is correct match it can propagate information to nearby descriptors.",
            "So for example it can suggest to this green descriptor to look over here and this indeed improves its match and it then can propagate information to this yellow descriptor and so on.",
            "Two more nearby descriptors.",
            "Now such large chunks of coherently map descriptors form."
        ],
        [
            "Shared regions and in the paper we prove that it feels 40 random samples, but the pair descriptor, regardless of the size of the image and then propagate.",
            "We are guaranteed to detect regions of at least 10 percent.",
            "10% of the image size with very high probability above 98%.",
            "Moreover, this can be done in time which is linear in the size of the image, and you can find the proof in the paper.",
            "Now such a random sampling process and propagation is able to detect all of these shared regions very efficiently and in fact."
        ],
        [
            "We don't even have to explicitly segment out those regions.",
            "All we need to do is to detect these large chunks of coherently map descriptors and iterate over these when computing the affinity."
        ],
        [
            "Now, going back to a clustering problem.",
            "So instead of computing all the pairwise affinity's.",
            "Which would take a long time and it would grow quadratically with the number of images in the collection.",
            "We just extend our search to the entire collection of images.",
            "So what do I mean by that?",
            "So for each descriptor, we still sample 40 descriptors, but now we distribute them across the entire collection of images, and this number 40 is regardless of the number of images in the collection.",
            "So we also sample 40 descriptors for this yellow descriptor over here, and so on for all descriptors in all images.",
            "Now in the paper we prove."
        ],
        [
            "But if you use 40 samples by descriptor and scatter them uniformly across the entire collection of images, then regardless of the number of images in the collection, we are guaranteed with very high probability that each image would generate at least one strong connection with another image in its cluster.",
            "So let's say that such a process generated these two strong."
        ],
        [
            "Elections by finding large shared regions.",
            "Between A1 and A2 and A2 and A3, then I suite is very likely to be similar to I-1, so I too can encourage ice way to search harder in Taiwan or in other words, ice.",
            "We we no longer use a uniform sampling, but we've now distributed samples in a nonuniform way according to suggestions made by other images, so this ready script over here will settle in the entire collection, but with simple more in Taiwan.",
            "And this results in this green."
        ],
        [
            "Shared region between one and three.",
            "Inducing a high affinity between those images.",
            "So such an image collaboration generates a sparse set of meaningful affinity's without having to compute all the pairwise infinities, and this can be done in time, which is linear in the size of the data set."
        ],
        [
            "Refer to this is the wisdom of cause of images.",
            "Images collaborate in order to search shared regions very efficiently without having to scan all the images."
        ],
        [
            "So let's recap the full clustering process goes as follows.",
            "Issues crypto samples, 40 descriptors uniformly distributed across the entire collection of images, and said after propagating and detecting shared regions.",
            "This generates as far set of meaningful affinity's inducing a sparse affinity matrix.",
            "We then use all the finches computed so far in order to update the sampling distribution of each image.",
            "According to suggestions made by other images.",
            "Refer to this as the wisdom of crowd of images.",
            "We continues and use sampling distribution.",
            "In order to generate a new set of sparse and meaningful affinity's and update the affinity metrics, we don't repeat this process several times and then just take the final affinity matrix and applied normal as normalized cuts on it to get our final clustering.",
            "So let's say you know some results and by that I will conclude my talk.",
            "So we did two kinds of experiments."
        ],
        [
            "The first was comparison to other methods on benchmark data sets that assists like Caltech 101 or it aged and on this we got significant improvement over state of the art.",
            "In fact, on the most challenging subjects we could improve it of up to 30% over state of the art.",
            "Now interest of time I will skip this experiments, but you can find all the details in the paper.",
            "I want to focus now on what I find to be more interesting and that is experiment on more challenging data set on extremely tiny data sets that existing methods cannot handle because there's just not enough images to learn a common cluster model from.",
            "And on the Pascal VLC just a huge variability in scale and appearance.",
            "So let's start with the tiny data set.",
            "So here's an uwu."
        ],
        [
            "To sit and all it contains is 20 images for four classes here at the images there are five images of monkeys, 5 images of bears, 5 images of Elks and find images of horses and notice how much variability there is within each class.",
            "Yet how much confusions there are between different classes.",
            "So for example, the background of the horse and the elk is very similar here, yet we would like to cluster those 20 images into the four corresponding animal clusters in a totally unsupervised manner.",
            "Now this is the reason."
        ],
        [
            "We get able to obtain perfect clustering.",
            "So how come we were able to cluster according to the animals and will get confused by the background.",
            "So to understand this."
        ],
        [
            "See what the script does.",
            "Gotta hire statistical significance and if you recall, it's also the ones that are not represented well by the codebook.",
            "So let's look."
        ],
        [
            "These and we can see that they are focused mostly on the animals and not the background to the marketing red.",
            "So those are the horns of the Elks, face of the Burns horse and to handle fit in the of the monkey.",
            "So this is how we are able to cluster according to the animals and not get confused by the background."
        ],
        [
            "So let's move to the Pascal.",
            "If you see.",
            "So here we chose for classes.",
            "We chose cars, bicycles, chairs and horses and I don't have to tell you how complex this data set is.",
            "Another huge is the variability in appearance and scale.",
            "So horses, for example, can be tiny or huge.",
            "Have known rigidities and also splatter like these bars and carriage over here and we have hundreds of."
        ],
        [
            "Images, yet we'd like to cluster them into the four corresponding clusters.",
            "In a totally unsupervised way.",
            "Now, the way we handle this huge variability in scale is by allowing our algorithm to search for shared regions also across different scales of different images.",
            "And now I want to show you some results so our supervised unsupervised clustering."
        ],
        [
            "Rhythm was able to obtain a cluster accuracy of 67% and to best knowledge no one is ever performed totally unsupervised.",
            "Clustering on this data set before.",
            "So we've known to compare against, but we did some baseline experiment with Special pyramid match kernel and normalized cuts and our results were 20% better."
        ],
        [
            "So let's conclude.",
            "So our approach is based on computing sophisticated powers, Affinity's, which we call affinity by composition.",
            "We do this by looking for large, non trivial regions which are shared between images.",
            "We thought that we can estimate how rare region is but using the code will quantization error and we sorted by applying a randomized search using the wisdom of crowds of images, meaning that images collaborate in order to find shared regions.",
            "These regions can be found very efficiently in time which is linear in the size of the data set.",
            "Finally we obtain stereos out results on benchmark data sets and got very encouraging results when you challenging data sets.",
            "Thank you for your attention.",
            "Hello can you give us some intuition about that claim that you should?",
            "Where is that number 40 coming from an what is assumption behind it?",
            "So the intuition behind it never mind the number now because it just could you can you can see it empirically, but intuition is like the larger lower large numbers.",
            "OK, because we like the birthday problem.",
            "If you know, like.",
            "That's what they said before that.",
            "The chance that a single descriptor will find its accurate match say that there is only one good matching.",
            "The other image is very low, it's just got one over the number of pixels.",
            "But the chance it.",
            "If we look for each of the descriptors for, say that it is a good matching the other image sensors at least one of them will fall in separate matches, is very is quite high, about 5050%.",
            "OK, that's OK now.",
            "If you if you have a region that is enough for one of the descriptors inside the region to find this correct match.",
            "OK, because then it can just propagate information to all the other descriptors in the region.",
            "So actually also.",
            "Each of them is a very low chance.",
            "It's enough that one of them will find it.",
            "OK, so it's a very simple proof you can.",
            "You can find it in our attach material in the website and it's like 2 rows of proof, OK?",
            "I just want to add that the number 40 comes from the size of the region, the 10% mean we have in the paper a graph showing how many samples you need in order to guarantee with at least 98% that the region of a certain percent of the image size will be found.",
            "And for 10% image size you need 40.",
            "If you want a different size, you'll need a different number of samples.",
            "In your paper, you were giving examples for low number of class object classes or like 45.",
            "Do you have any intuition how it scales to hundreds of classes or thousands of classes?",
            "So in the paper we show, we have shown up to 20 classes and actually we've got 20 Caltech classes and actually the state of the art on this data set was like 65% and we got 85.",
            "So I guess it can scale up to more classes.",
            "We didn't see that it was sensitive to that.",
            "OK, thank you.",
            "It's quite surprising that your salience measure is so salient on these objects.",
            "Have you run it on the Pascal classes where there's a lot more kind of objects in the in the image, and what does it give in that case?",
            "So when we built our subset of classes so we moved images that contain two classes of the four of the bicycles cars chosen horses, but there are a lot of other objects in those images which may be shared between different images, so we didn't.",
            "We didn't take images that have just have one class, one class of objects.",
            "OK, so this is the results I've shown.",
            "You is on images with a lot of object classes.",
            "But if you run your salience measure on it like you've got those yoga people up there, for example, do you get similar results for the Pascal images?",
            "So it would usually focus on the object in the image and once we have found a good matches for this objects then we have high affinity between the images so.",
            "OK, so this is basically how it works.",
            "OK, let's thank the speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hi my name is Ron Factor and this is joint work with Kalyani.",
                    "label": 0
                },
                {
                    "sent": "So name of the work is clustering by composition for unsupervised discovery of image categories.",
                    "label": 1
                },
                {
                    "sent": "So it is the problem we're trying to solve.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are 40 images and 20 of these images are.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adding images and 20 are yoga images and notice the huge variability in appearance of those images.",
                    "label": 0
                },
                {
                    "sent": "So very different yoga poses lots of background, clutter, occlusions and so on, yet would like to cluster those images into two clusters of yoga and ballet in it.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Totally unsupervised manner.",
                    "label": 0
                },
                {
                    "sent": "No, we were spoken unsupervised category discovery is either dealt with relatively simple pairwise affinity's which cannot handle this.",
                    "label": 0
                },
                {
                    "sent": "The huge availability in the appearance of the images I've just shown you or use more sophisticated methods to try to discover a common cluster model.",
                    "label": 0
                },
                {
                    "sent": "This may include a common distribution of descriptors, common segments, common shapes, and so on.",
                    "label": 0
                },
                {
                    "sent": "The problem is that these methods require a large number of images to learn from, and Moreover, looking at these images, there isn't really any simple model that is common to all of this.",
                    "label": 0
                },
                {
                    "sent": "All of these yoga or ballet images.",
                    "label": 0
                },
                {
                    "sent": "So it makes images simpler.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I want to give you a overview of our approach, so we use sophisticated Paris affinity's, which we call affinity by composition.",
                    "label": 1
                },
                {
                    "sent": "What do I mean by that?",
                    "label": 0
                },
                {
                    "sent": "So let's take a look at the two following Valley, which is.",
                    "label": 0
                },
                {
                    "sent": "So those are very different from each other.",
                    "label": 0
                },
                {
                    "sent": "One image can be easily composed, like a simple puzzle from the other image using large non trivial pieces.",
                    "label": 0
                },
                {
                    "sent": "And if you look at another body image to begin, the images are very different from each other.",
                    "label": 0
                },
                {
                    "sent": "But they share this large nontrivial region.",
                    "label": 0
                },
                {
                    "sent": "Now notice screen region has a very low chance of occurring at random.",
                    "label": 0
                },
                {
                    "sent": "So the fact that we are able to find it at another image provides high evidence to the affinity between the images.",
                    "label": 0
                },
                {
                    "sent": "Even if we can't find this region in any of the other Valley images, or in other words, a good region is, which induces high affinity is not necessarily a good segment.",
                    "label": 0
                },
                {
                    "sent": "It cannot be extracted ahead of time for image segmentation.",
                    "label": 0
                },
                {
                    "sent": "What makes original Good is the fact that it is where it is a low chance of occurring at random, yet it is shared by two images.",
                    "label": 0
                },
                {
                    "sent": "Now, it's not that we not be able to compose the body image from yoga image.",
                    "label": 0
                },
                {
                    "sent": "We will, but this will be tiny.",
                    "label": 0
                },
                {
                    "sent": "Itsy bitsy regions that are more likely to occur at other images, inducing a low affinity between the images.",
                    "label": 0
                },
                {
                    "sent": "So this is how we compute our affinity's, but this may seem to like a very tiresome process.",
                    "label": 0
                },
                {
                    "sent": "How do you find all these large nontrivial shared regions?",
                    "label": 0
                },
                {
                    "sent": "However, in this work we show this can be done very efficiently.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using a randomized search process with images collaborating with each other to search this shared regions.",
                    "label": 0
                },
                {
                    "sent": "In fact, this can be done in time, which is linear in the size of the data set.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And when we play algorithm, this is the kind of results we get able to obtain these two clusters, one mostly of Valley images and second most yoga images and the accuracy of this clustering is very high.",
                    "label": 0
                },
                {
                    "sent": "Only three images were miss clustered.",
                    "label": 0
                },
                {
                    "sent": "Those that are marked in red.",
                    "label": 0
                },
                {
                    "sent": "So this was a high level overview of our approach.",
                    "label": 0
                },
                {
                    "sent": "Let's now dive into the details.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So do we compute the affinity between the two images, so we extend previous work?",
                    "label": 0
                },
                {
                    "sent": "Bye bye man everybody.",
                    "label": 0
                },
                {
                    "sent": "And let's assume that someone marked region in one image and would like to know how much affinity this region induces between the two images.",
                    "label": 0
                },
                {
                    "sent": "So we saw before that the region is good if it is shared by two images and is where has a low chance of occurring at window Now this is captured mathematically, but the following likelihood ratio where the top says?",
                    "label": 0
                },
                {
                    "sent": "How good is the region match across the two images at the bottom says how well the region is.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we find the log of this likelihood ratio to be the contribution of the region to the affinity between the two images.",
                    "label": 0
                },
                {
                    "sent": "Now the region is made of a bunch of dense descriptors, say hog descriptors and.",
                    "label": 0
                },
                {
                    "sent": "If we assume those descriptors are IID.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You write the log likelihood.",
                    "label": 0
                },
                {
                    "sent": "Is it additive?",
                    "label": 0
                },
                {
                    "sent": "Some in those descriptors.",
                    "label": 0
                },
                {
                    "sent": "For the first term.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Measures how good descriptors match across the images.",
                    "label": 0
                },
                {
                    "sent": "So for each descriptor we measure how well it matches its corresponding descriptor in the other image.",
                    "label": 0
                },
                {
                    "sent": "By allowing small nonrigid deformations during this matching.",
                    "label": 0
                },
                {
                    "sent": "And this induces.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This error over here, the second term measures how where is each descriptor, so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do we measure how rare is its descriptor?",
                    "label": 1
                },
                {
                    "sent": "How statistically significant it is?",
                    "label": 0
                },
                {
                    "sent": "So just take any descriptor in any image and ask how likely it is to occur at random.",
                    "label": 0
                },
                {
                    "sent": "So for that we take a bunch of images.",
                    "label": 0
                },
                {
                    "sent": "This can be any random collection of natural images with images wish to cluster and ask how likely is a descriptor to occur in those images.",
                    "label": 0
                },
                {
                    "sent": "So we could try to compute this frequency in those images, but this will take a very long time, so instead we approximate it in the following way.",
                    "label": 0
                },
                {
                    "sent": "What we do is we take all descriptors from all images and generate the code book from them just by applying K means and then what will happen is that frequent descriptors will be represented well by the code book, so we have a low error and on the other hand where descriptors will be represented poorly by the code book.",
                    "label": 0
                },
                {
                    "sent": "So you have a higher.",
                    "label": 0
                },
                {
                    "sent": "So if your computer.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Descriptor its nearest neighbor in the code book that the error to these nearest neighbor will tell us how frequent a descriptor is so we can estimate the log.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Likelihood of a descriptor to occur at random just by its error with respect to the codebook.",
                    "label": 0
                },
                {
                    "sent": "So let's see what this gives us.",
                    "label": 0
                },
                {
                    "sent": "So here we can see.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Each image to error with respect to the codebook of each of the descriptors.",
                    "label": 0
                },
                {
                    "sent": "Red signifies very high error.",
                    "label": 0
                },
                {
                    "sent": "Very well descriptors green lower in grayscale.",
                    "label": 0
                },
                {
                    "sent": "Very low error.",
                    "label": 0
                },
                {
                    "sent": "Very frequent descriptors and what we see here.",
                    "label": 0
                },
                {
                    "sent": "It is the most informative descriptors.",
                    "label": 1
                },
                {
                    "sent": "Other ones, especially yoga, pose to hand posters.",
                    "label": 0
                },
                {
                    "sent": "The ballet dancer and the Hunter and the long horizontal edge between the wall and the floor does not get a high error.",
                    "label": 1
                },
                {
                    "sent": "It is not statistically significant because having the horizontal edges occur.",
                    "label": 0
                },
                {
                    "sent": "Bentley at natural images.",
                    "label": 0
                },
                {
                    "sent": "Note that this is very different from how people usually use code books in classification and recognition.",
                    "label": 0
                },
                {
                    "sent": "Usually a codebook is used in order to represent an image.",
                    "label": 0
                },
                {
                    "sent": "Here we look for the descriptors that are not represented well by the codebook, and those are the most informative force.",
                    "label": 0
                },
                {
                    "sent": "So let's recap the contribution of.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Single region to the affinity between 2 images.",
                    "label": 0
                },
                {
                    "sent": "Sequel to the log likelihood between how Good is a region match across the two images versus how well the region is in this bowl is up to the fall.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The expression notice yellow term inside inside says is that for each descriptor we measure its error with respect.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To the codebook and measure its error with respect to its corresponding descriptor in the other image.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then just take the difference between the two.",
                    "label": 0
                },
                {
                    "sent": "And if we like to know the contribution of the entire region, we just have to sum up over all the descriptors inside the region.",
                    "label": 0
                },
                {
                    "sent": "Now, if you have more.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "People shared regions across the image is all we have to do is just to sum up.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The contributions of the individual regions in these forms are fine.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Affinity now?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So far we assume the shared regions are given to us.",
                    "label": 0
                },
                {
                    "sent": "Now we no longer assume that and show you how to detect those regions very efficiently.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For that we use a randomized search which is inspired by Patch match.",
                    "label": 0
                },
                {
                    "sent": "So what we do is that for each descriptor in one image.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We just randomly sampled several descriptors in the other image.",
                    "label": 0
                },
                {
                    "sent": "So here are the samples for the yellow descriptor in here.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Samples for the magenta descriptor and here's the samples for the reading Scripture over here.",
                    "label": 0
                },
                {
                    "sent": "Now the chance the single descriptor will fall into accurate matching.",
                    "label": 0
                },
                {
                    "sent": "The other image is of course very low, but the chance that the single at least one of the descriptors before it's accurate match in the other image is actually very high, and once the script.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find is correct match it can propagate information to nearby descriptors.",
                    "label": 0
                },
                {
                    "sent": "So for example it can suggest to this green descriptor to look over here and this indeed improves its match and it then can propagate information to this yellow descriptor and so on.",
                    "label": 0
                },
                {
                    "sent": "Two more nearby descriptors.",
                    "label": 0
                },
                {
                    "sent": "Now such large chunks of coherently map descriptors form.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Shared regions and in the paper we prove that it feels 40 random samples, but the pair descriptor, regardless of the size of the image and then propagate.",
                    "label": 0
                },
                {
                    "sent": "We are guaranteed to detect regions of at least 10 percent.",
                    "label": 0
                },
                {
                    "sent": "10% of the image size with very high probability above 98%.",
                    "label": 0
                },
                {
                    "sent": "Moreover, this can be done in time which is linear in the size of the image, and you can find the proof in the paper.",
                    "label": 0
                },
                {
                    "sent": "Now such a random sampling process and propagation is able to detect all of these shared regions very efficiently and in fact.",
                    "label": 1
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We don't even have to explicitly segment out those regions.",
                    "label": 0
                },
                {
                    "sent": "All we need to do is to detect these large chunks of coherently map descriptors and iterate over these when computing the affinity.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, going back to a clustering problem.",
                    "label": 1
                },
                {
                    "sent": "So instead of computing all the pairwise affinity's.",
                    "label": 0
                },
                {
                    "sent": "Which would take a long time and it would grow quadratically with the number of images in the collection.",
                    "label": 0
                },
                {
                    "sent": "We just extend our search to the entire collection of images.",
                    "label": 0
                },
                {
                    "sent": "So what do I mean by that?",
                    "label": 0
                },
                {
                    "sent": "So for each descriptor, we still sample 40 descriptors, but now we distribute them across the entire collection of images, and this number 40 is regardless of the number of images in the collection.",
                    "label": 0
                },
                {
                    "sent": "So we also sample 40 descriptors for this yellow descriptor over here, and so on for all descriptors in all images.",
                    "label": 0
                },
                {
                    "sent": "Now in the paper we prove.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if you use 40 samples by descriptor and scatter them uniformly across the entire collection of images, then regardless of the number of images in the collection, we are guaranteed with very high probability that each image would generate at least one strong connection with another image in its cluster.",
                    "label": 0
                },
                {
                    "sent": "So let's say that such a process generated these two strong.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Elections by finding large shared regions.",
                    "label": 0
                },
                {
                    "sent": "Between A1 and A2 and A2 and A3, then I suite is very likely to be similar to I-1, so I too can encourage ice way to search harder in Taiwan or in other words, ice.",
                    "label": 0
                },
                {
                    "sent": "We we no longer use a uniform sampling, but we've now distributed samples in a nonuniform way according to suggestions made by other images, so this ready script over here will settle in the entire collection, but with simple more in Taiwan.",
                    "label": 0
                },
                {
                    "sent": "And this results in this green.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Shared region between one and three.",
                    "label": 0
                },
                {
                    "sent": "Inducing a high affinity between those images.",
                    "label": 0
                },
                {
                    "sent": "So such an image collaboration generates a sparse set of meaningful affinity's without having to compute all the pairwise infinities, and this can be done in time, which is linear in the size of the data set.",
                    "label": 1
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Refer to this is the wisdom of cause of images.",
                    "label": 0
                },
                {
                    "sent": "Images collaborate in order to search shared regions very efficiently without having to scan all the images.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's recap the full clustering process goes as follows.",
                    "label": 0
                },
                {
                    "sent": "Issues crypto samples, 40 descriptors uniformly distributed across the entire collection of images, and said after propagating and detecting shared regions.",
                    "label": 0
                },
                {
                    "sent": "This generates as far set of meaningful affinity's inducing a sparse affinity matrix.",
                    "label": 1
                },
                {
                    "sent": "We then use all the finches computed so far in order to update the sampling distribution of each image.",
                    "label": 0
                },
                {
                    "sent": "According to suggestions made by other images.",
                    "label": 1
                },
                {
                    "sent": "Refer to this as the wisdom of crowd of images.",
                    "label": 0
                },
                {
                    "sent": "We continues and use sampling distribution.",
                    "label": 0
                },
                {
                    "sent": "In order to generate a new set of sparse and meaningful affinity's and update the affinity metrics, we don't repeat this process several times and then just take the final affinity matrix and applied normal as normalized cuts on it to get our final clustering.",
                    "label": 0
                },
                {
                    "sent": "So let's say you know some results and by that I will conclude my talk.",
                    "label": 0
                },
                {
                    "sent": "So we did two kinds of experiments.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first was comparison to other methods on benchmark data sets that assists like Caltech 101 or it aged and on this we got significant improvement over state of the art.",
                    "label": 1
                },
                {
                    "sent": "In fact, on the most challenging subjects we could improve it of up to 30% over state of the art.",
                    "label": 0
                },
                {
                    "sent": "Now interest of time I will skip this experiments, but you can find all the details in the paper.",
                    "label": 0
                },
                {
                    "sent": "I want to focus now on what I find to be more interesting and that is experiment on more challenging data set on extremely tiny data sets that existing methods cannot handle because there's just not enough images to learn a common cluster model from.",
                    "label": 0
                },
                {
                    "sent": "And on the Pascal VLC just a huge variability in scale and appearance.",
                    "label": 0
                },
                {
                    "sent": "So let's start with the tiny data set.",
                    "label": 0
                },
                {
                    "sent": "So here's an uwu.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To sit and all it contains is 20 images for four classes here at the images there are five images of monkeys, 5 images of bears, 5 images of Elks and find images of horses and notice how much variability there is within each class.",
                    "label": 0
                },
                {
                    "sent": "Yet how much confusions there are between different classes.",
                    "label": 0
                },
                {
                    "sent": "So for example, the background of the horse and the elk is very similar here, yet we would like to cluster those 20 images into the four corresponding animal clusters in a totally unsupervised manner.",
                    "label": 0
                },
                {
                    "sent": "Now this is the reason.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We get able to obtain perfect clustering.",
                    "label": 0
                },
                {
                    "sent": "So how come we were able to cluster according to the animals and will get confused by the background.",
                    "label": 0
                },
                {
                    "sent": "So to understand this.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See what the script does.",
                    "label": 0
                },
                {
                    "sent": "Gotta hire statistical significance and if you recall, it's also the ones that are not represented well by the codebook.",
                    "label": 0
                },
                {
                    "sent": "So let's look.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These and we can see that they are focused mostly on the animals and not the background to the marketing red.",
                    "label": 1
                },
                {
                    "sent": "So those are the horns of the Elks, face of the Burns horse and to handle fit in the of the monkey.",
                    "label": 0
                },
                {
                    "sent": "So this is how we are able to cluster according to the animals and not get confused by the background.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's move to the Pascal.",
                    "label": 0
                },
                {
                    "sent": "If you see.",
                    "label": 0
                },
                {
                    "sent": "So here we chose for classes.",
                    "label": 0
                },
                {
                    "sent": "We chose cars, bicycles, chairs and horses and I don't have to tell you how complex this data set is.",
                    "label": 1
                },
                {
                    "sent": "Another huge is the variability in appearance and scale.",
                    "label": 0
                },
                {
                    "sent": "So horses, for example, can be tiny or huge.",
                    "label": 0
                },
                {
                    "sent": "Have known rigidities and also splatter like these bars and carriage over here and we have hundreds of.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Images, yet we'd like to cluster them into the four corresponding clusters.",
                    "label": 0
                },
                {
                    "sent": "In a totally unsupervised way.",
                    "label": 0
                },
                {
                    "sent": "Now, the way we handle this huge variability in scale is by allowing our algorithm to search for shared regions also across different scales of different images.",
                    "label": 0
                },
                {
                    "sent": "And now I want to show you some results so our supervised unsupervised clustering.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rhythm was able to obtain a cluster accuracy of 67% and to best knowledge no one is ever performed totally unsupervised.",
                    "label": 0
                },
                {
                    "sent": "Clustering on this data set before.",
                    "label": 0
                },
                {
                    "sent": "So we've known to compare against, but we did some baseline experiment with Special pyramid match kernel and normalized cuts and our results were 20% better.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's conclude.",
                    "label": 0
                },
                {
                    "sent": "So our approach is based on computing sophisticated powers, Affinity's, which we call affinity by composition.",
                    "label": 0
                },
                {
                    "sent": "We do this by looking for large, non trivial regions which are shared between images.",
                    "label": 0
                },
                {
                    "sent": "We thought that we can estimate how rare region is but using the code will quantization error and we sorted by applying a randomized search using the wisdom of crowds of images, meaning that images collaborate in order to find shared regions.",
                    "label": 1
                },
                {
                    "sent": "These regions can be found very efficiently in time which is linear in the size of the data set.",
                    "label": 0
                },
                {
                    "sent": "Finally we obtain stereos out results on benchmark data sets and got very encouraging results when you challenging data sets.",
                    "label": 1
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "Hello can you give us some intuition about that claim that you should?",
                    "label": 0
                },
                {
                    "sent": "Where is that number 40 coming from an what is assumption behind it?",
                    "label": 0
                },
                {
                    "sent": "So the intuition behind it never mind the number now because it just could you can you can see it empirically, but intuition is like the larger lower large numbers.",
                    "label": 0
                },
                {
                    "sent": "OK, because we like the birthday problem.",
                    "label": 0
                },
                {
                    "sent": "If you know, like.",
                    "label": 0
                },
                {
                    "sent": "That's what they said before that.",
                    "label": 0
                },
                {
                    "sent": "The chance that a single descriptor will find its accurate match say that there is only one good matching.",
                    "label": 0
                },
                {
                    "sent": "The other image is very low, it's just got one over the number of pixels.",
                    "label": 0
                },
                {
                    "sent": "But the chance it.",
                    "label": 0
                },
                {
                    "sent": "If we look for each of the descriptors for, say that it is a good matching the other image sensors at least one of them will fall in separate matches, is very is quite high, about 5050%.",
                    "label": 0
                },
                {
                    "sent": "OK, that's OK now.",
                    "label": 0
                },
                {
                    "sent": "If you if you have a region that is enough for one of the descriptors inside the region to find this correct match.",
                    "label": 0
                },
                {
                    "sent": "OK, because then it can just propagate information to all the other descriptors in the region.",
                    "label": 0
                },
                {
                    "sent": "So actually also.",
                    "label": 0
                },
                {
                    "sent": "Each of them is a very low chance.",
                    "label": 0
                },
                {
                    "sent": "It's enough that one of them will find it.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a very simple proof you can.",
                    "label": 0
                },
                {
                    "sent": "You can find it in our attach material in the website and it's like 2 rows of proof, OK?",
                    "label": 0
                },
                {
                    "sent": "I just want to add that the number 40 comes from the size of the region, the 10% mean we have in the paper a graph showing how many samples you need in order to guarantee with at least 98% that the region of a certain percent of the image size will be found.",
                    "label": 0
                },
                {
                    "sent": "And for 10% image size you need 40.",
                    "label": 0
                },
                {
                    "sent": "If you want a different size, you'll need a different number of samples.",
                    "label": 0
                },
                {
                    "sent": "In your paper, you were giving examples for low number of class object classes or like 45.",
                    "label": 0
                },
                {
                    "sent": "Do you have any intuition how it scales to hundreds of classes or thousands of classes?",
                    "label": 0
                },
                {
                    "sent": "So in the paper we show, we have shown up to 20 classes and actually we've got 20 Caltech classes and actually the state of the art on this data set was like 65% and we got 85.",
                    "label": 0
                },
                {
                    "sent": "So I guess it can scale up to more classes.",
                    "label": 0
                },
                {
                    "sent": "We didn't see that it was sensitive to that.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "It's quite surprising that your salience measure is so salient on these objects.",
                    "label": 0
                },
                {
                    "sent": "Have you run it on the Pascal classes where there's a lot more kind of objects in the in the image, and what does it give in that case?",
                    "label": 0
                },
                {
                    "sent": "So when we built our subset of classes so we moved images that contain two classes of the four of the bicycles cars chosen horses, but there are a lot of other objects in those images which may be shared between different images, so we didn't.",
                    "label": 0
                },
                {
                    "sent": "We didn't take images that have just have one class, one class of objects.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the results I've shown.",
                    "label": 0
                },
                {
                    "sent": "You is on images with a lot of object classes.",
                    "label": 0
                },
                {
                    "sent": "But if you run your salience measure on it like you've got those yoga people up there, for example, do you get similar results for the Pascal images?",
                    "label": 0
                },
                {
                    "sent": "So it would usually focus on the object in the image and once we have found a good matches for this objects then we have high affinity between the images so.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is basically how it works.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank the speaker.",
                    "label": 0
                }
            ]
        }
    }
}