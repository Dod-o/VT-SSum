{
    "id": "uvnwvusdgomclnbp5m6mmv3e6vfi3gbp",
    "title": "Sample Complexity for Multiresolution ICA",
    "info": {
        "author": [
            "Doru Balcan, Carnegie Mellon University"
        ],
        "published": "Dec. 20, 2008",
        "recorded": "December 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/wehys08_balcan_scmr/",
    "segmentation": [
        [
            "Morning my name is Laura Bacon and I'm talking here about sample complexity for multiresolution ICA.",
            "This is joint work with Avrim and Nina.",
            "Um?"
        ],
        [
            "The point of this is to study adaptive representation for images.",
            "They are used for lots of things among the many most important ones are efficient encoding and particularly compression of images.",
            "And fix transform like discrete cosine transform of type 2 and wavelets have been used extensively and successfully.",
            "Encoding images in JPEG standards but adapting their representation to the class of signals that you want to encode can only improve the efficiency.",
            "Also, using adaptive representations for images has also been helpful and relevant for explaining how natural encoding mechanism use function, and that has been relevant.",
            "For instance, for simple cells in primary, visual cortex, multiresolution ICA, which is a technique.",
            "Divide by me and my advisor, Michael Wiki is a hybrid method in the sense that it combines the power of multiresolution representations.",
            "The representational power with the adaptivity, and it improves in this sense, over both types of representations of over the linear adaptive methods, because for instance with traditional ICA you can't really hope.",
            "To get the independent components of larger images and therefore you have to block images into small blocks and be happy with that.",
            "Well with multi resolution you can actually.",
            "Compute the representations for much larger images and also as I said earlier, it improves on multiscale transform and multiresolution transfer because it brings in the power of adaptivity.",
            "So it really adopts the representation within the sub bands and then you pass them to the compressor and get much smaller image on your."
        ],
        [
            "Digital camera.",
            "This is just to show you that it works pretty well in Practice 2 and you see here 264 by 64 images drawn from a natural image database.",
            "On the second column you see the result of reconstructing using just the wavelet coefficients, and as you can see there are.",
            "There are some specs here.",
            "The artifacts due to the wavelet errors.",
            "The errors in compressing variable coefficients and with multiresolution ICA, these things don't appear because of the better basis that you use for those subspaces for the sub bands.",
            "OK, these were reconstructed at 20 DB, but in general for a large range of bitrates the advantage of using adaptivity versus not using it is of roughly 4 DB, which is significant in image."
        ],
        [
            "Compression OK, so about the multiresolution ICA.",
            "The setup is this.",
            "You start with data sample number of images assumed to be drawn IID from a common distribution, and then you have multiresolution transform.",
            "Seeing here as a matrix with its rose partitioned according to the sub matrices and for each of the sub bands for each of the.",
            "A projection according to these sub matrices we learn on ICA basis, which produces a vector whose components we want to be as independent as possible, or as least informative about each, uh."
        ],
        [
            "It is possible.",
            "OK.",
            "There are multiple objectives to achieve independent components, and one of them could be too.",
            "To minimize mutual information among the components of the linear combination of the data.",
            "Another one would be to run away from Gaussianity as.",
            "This is reverse reasoning, saying that well, when you have.",
            "Independent random variables and you sum them up.",
            "You combine and linearly.",
            "The result looks like a Gaussian.",
            "Well, if you want to get independent.",
            "Components out of it.",
            "Maybe you want to find something that is as least Gaussian as possible, and the third big family would be to diagonalize certain functionals that depend on the data.",
            "Although not all of these.",
            "Objectives require it.",
            "We will assume that we center and white and the data so that we essentially only need to look for an orthogonal matrix for the."
        ],
        [
            "The matrix.",
            "OK. As for the sample complexity, I'll just mention here 2 results.",
            "One is sample complexity for ICA and this is a paper of summer events back of in 2004.",
            "They use strong assumptions.",
            "They assume that the N dimensional PDF is product of very smooth marginals and they use that in deriving their bounds and with such strong assumptions they also get strong result, namely that the estimated and the true DIMACS matrices are close in value, so the vectors are close, and for that they use the declaration of this function here.",
            "And another relevant.",
            "Now another relevant result refers to kernel PCA and belongs to Taylor and his colleagues and there they look for.",
            "A result that characterizes how close the true and the estimated matrices are in quality.",
            "The quality of the matrices was important, and this is what we want to do."
        ],
        [
            "Shoot for it.",
            "Yeah, yeah.",
            "So this is just.",
            "This is my final slide for the result and what we have so far.",
            "I invite you to our poster.",
            "Thank you so much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Morning my name is Laura Bacon and I'm talking here about sample complexity for multiresolution ICA.",
                    "label": 1
                },
                {
                    "sent": "This is joint work with Avrim and Nina.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The point of this is to study adaptive representation for images.",
                    "label": 0
                },
                {
                    "sent": "They are used for lots of things among the many most important ones are efficient encoding and particularly compression of images.",
                    "label": 0
                },
                {
                    "sent": "And fix transform like discrete cosine transform of type 2 and wavelets have been used extensively and successfully.",
                    "label": 0
                },
                {
                    "sent": "Encoding images in JPEG standards but adapting their representation to the class of signals that you want to encode can only improve the efficiency.",
                    "label": 0
                },
                {
                    "sent": "Also, using adaptive representations for images has also been helpful and relevant for explaining how natural encoding mechanism use function, and that has been relevant.",
                    "label": 0
                },
                {
                    "sent": "For instance, for simple cells in primary, visual cortex, multiresolution ICA, which is a technique.",
                    "label": 1
                },
                {
                    "sent": "Divide by me and my advisor, Michael Wiki is a hybrid method in the sense that it combines the power of multiresolution representations.",
                    "label": 0
                },
                {
                    "sent": "The representational power with the adaptivity, and it improves in this sense, over both types of representations of over the linear adaptive methods, because for instance with traditional ICA you can't really hope.",
                    "label": 0
                },
                {
                    "sent": "To get the independent components of larger images and therefore you have to block images into small blocks and be happy with that.",
                    "label": 0
                },
                {
                    "sent": "Well with multi resolution you can actually.",
                    "label": 0
                },
                {
                    "sent": "Compute the representations for much larger images and also as I said earlier, it improves on multiscale transform and multiresolution transfer because it brings in the power of adaptivity.",
                    "label": 0
                },
                {
                    "sent": "So it really adopts the representation within the sub bands and then you pass them to the compressor and get much smaller image on your.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Digital camera.",
                    "label": 0
                },
                {
                    "sent": "This is just to show you that it works pretty well in Practice 2 and you see here 264 by 64 images drawn from a natural image database.",
                    "label": 1
                },
                {
                    "sent": "On the second column you see the result of reconstructing using just the wavelet coefficients, and as you can see there are.",
                    "label": 0
                },
                {
                    "sent": "There are some specs here.",
                    "label": 0
                },
                {
                    "sent": "The artifacts due to the wavelet errors.",
                    "label": 0
                },
                {
                    "sent": "The errors in compressing variable coefficients and with multiresolution ICA, these things don't appear because of the better basis that you use for those subspaces for the sub bands.",
                    "label": 0
                },
                {
                    "sent": "OK, these were reconstructed at 20 DB, but in general for a large range of bitrates the advantage of using adaptivity versus not using it is of roughly 4 DB, which is significant in image.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compression OK, so about the multiresolution ICA.",
                    "label": 0
                },
                {
                    "sent": "The setup is this.",
                    "label": 0
                },
                {
                    "sent": "You start with data sample number of images assumed to be drawn IID from a common distribution, and then you have multiresolution transform.",
                    "label": 0
                },
                {
                    "sent": "Seeing here as a matrix with its rose partitioned according to the sub matrices and for each of the sub bands for each of the.",
                    "label": 0
                },
                {
                    "sent": "A projection according to these sub matrices we learn on ICA basis, which produces a vector whose components we want to be as independent as possible, or as least informative about each, uh.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is possible.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "There are multiple objectives to achieve independent components, and one of them could be too.",
                    "label": 0
                },
                {
                    "sent": "To minimize mutual information among the components of the linear combination of the data.",
                    "label": 1
                },
                {
                    "sent": "Another one would be to run away from Gaussianity as.",
                    "label": 0
                },
                {
                    "sent": "This is reverse reasoning, saying that well, when you have.",
                    "label": 0
                },
                {
                    "sent": "Independent random variables and you sum them up.",
                    "label": 0
                },
                {
                    "sent": "You combine and linearly.",
                    "label": 0
                },
                {
                    "sent": "The result looks like a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Well, if you want to get independent.",
                    "label": 0
                },
                {
                    "sent": "Components out of it.",
                    "label": 1
                },
                {
                    "sent": "Maybe you want to find something that is as least Gaussian as possible, and the third big family would be to diagonalize certain functionals that depend on the data.",
                    "label": 0
                },
                {
                    "sent": "Although not all of these.",
                    "label": 0
                },
                {
                    "sent": "Objectives require it.",
                    "label": 0
                },
                {
                    "sent": "We will assume that we center and white and the data so that we essentially only need to look for an orthogonal matrix for the.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The matrix.",
                    "label": 0
                },
                {
                    "sent": "OK. As for the sample complexity, I'll just mention here 2 results.",
                    "label": 0
                },
                {
                    "sent": "One is sample complexity for ICA and this is a paper of summer events back of in 2004.",
                    "label": 1
                },
                {
                    "sent": "They use strong assumptions.",
                    "label": 0
                },
                {
                    "sent": "They assume that the N dimensional PDF is product of very smooth marginals and they use that in deriving their bounds and with such strong assumptions they also get strong result, namely that the estimated and the true DIMACS matrices are close in value, so the vectors are close, and for that they use the declaration of this function here.",
                    "label": 1
                },
                {
                    "sent": "And another relevant.",
                    "label": 0
                },
                {
                    "sent": "Now another relevant result refers to kernel PCA and belongs to Taylor and his colleagues and there they look for.",
                    "label": 0
                },
                {
                    "sent": "A result that characterizes how close the true and the estimated matrices are in quality.",
                    "label": 0
                },
                {
                    "sent": "The quality of the matrices was important, and this is what we want to do.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Shoot for it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "So this is just.",
                    "label": 0
                },
                {
                    "sent": "This is my final slide for the result and what we have so far.",
                    "label": 0
                },
                {
                    "sent": "I invite you to our poster.",
                    "label": 0
                },
                {
                    "sent": "Thank you so much.",
                    "label": 0
                }
            ]
        }
    }
}