{
    "id": "hzqhz5v7okfg7uvdnl5wf4ly6qm7magf",
    "title": "Intelligent clients for replicated Triple Pattern Fragments",
    "info": {
        "author": [
            "Thomas Minier, University of Nantes"
        ],
        "published": "July 10, 2018",
        "recorded": "June 2018",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2018_minier_triple_pattern/",
    "segmentation": [
        [
            "So hello everyone, I'm Tom in a PhD student at the University of North and today I'm going to present to my work intelligent clients for replicated triple pattern fragments."
        ],
        [
            "Following the link it open that up principal data provider I've made available more and more RDF data set using GPS server to ensure low cost that ousting.",
            "However, servers availability remain an issue.",
            "The servers can be done or two every loaded which prevents them to answer to user queries, but it should not be a problem since."
        ],
        [
            "Data provider also replicate RDF datasets.",
            "For example, both DB pedia and the Los Alamos National Library replicate.",
            "Several version of the DB Pedia data sets.",
            "This can we use this replicated data set to improve server availability then?",
            "So yes, using load balancing to distribute the load of sparkle query processing between all available replica."
        ],
        [
            "This load balancing have several benefits for both data providers and other consumers.",
            "It's good for data providers because our server are less crowded.",
            "There are more available and it save money on the toasting for providers.",
            "It's also good for that consumers because they are able to tolerate server failures.",
            "If a server is done, I can simply use a replica to continue query processing and a server are less loaded.",
            "Pre processing performance are improved.",
            "So this."
        ],
        [
            "As to our research problem.",
            "How to balance the load of sparkle query processing of a replicated introduce servers owned by autonomous data providers here in our context, attention news means that servers do not have the same processing capabilities and autonomous means that all data providers means that RDF data set are not hosted by the same data providers.",
            "So first thing first."
        ],
        [
            "Let's look at related work."
        ],
        [
            "We could see our set of replica as a Federation, an existing TPF clients allowed to process a Federated sparkle query over Federation of TPS servers.",
            "However they do not support replication or client side load balancing.",
            "To illustrate, consider this STALKER query Q1 which find all software developed by French companies.",
            "If I execute Q1 or the public DBPR server, this query runs in 11.4 second.",
            "But if I use both DA and electric car from a lion and the exacution term is more than double due to transfer of unnecessary intermediate results."
        ],
        [
            "This link it that our application has already already been addressed, but as a source selection problem.",
            "In state of the art approach, proved and then sources to avoid transfer of rendant Wizards.",
            "However, this is far from load balancing.",
            "For example, if I take back my query Q1 and using approach from the state of the art, I will choose to execute it.",
            "Either of the DBP server on on the alignment servers if I choose the first one, creates the showing time even, but if I choose the second one, query execution time is more than is deteriorated because the server is less powerful than the DBPR 1.",
            "So here's what I want to do.",
            "I want to use both DB pedia and an island.",
            "To go faster if possible.",
            "And to do that normally I will use server side load balancing, but as.",
            "I have data set are hosted by autonomous data provider.",
            "I can't so I."
        ],
        [
            "We rely on client side load balancing which is well suited for Entergy new servers.",
            "It fits well in in an intelligent EPF client where query processing is evaluated client side.",
            "And it respects data provider autonomy because you do not require any change from data providers.",
            "Or why this approach is currently only be applied for downloading static file from web servers and not for query processing?",
            "So the."
        ],
        [
            "This leads us to approach called Ulysses at what Ulysses do.",
            "What I want to do."
        ],
        [
            "I want to take this creature on an.",
            "I want to execute it on both DB pedia and replica from Ryan and I want to distribute the cost of this execution between the two servers.",
            "During query processing a GPF client, they compose a sparkle query.",
            "It was set of Subqueries called triple pattern queries and evaluate them using the servers to download intermediate results and process all join locali.",
            "However, during creep."
        ],
        [
            "Missing query processing capabilities of servers evolve here you can see the evolution of the server throughput of my 2 servers during the evaluation of this query.",
            "That stuff should boots are pretty equal, but as time goes on, the DB pedia servers become become slower than the NN one.",
            "So during query processing."
        ],
        [
            "Where should I send my triple pattern queries?",
            "At start sees both servers in.",
            "Equals in capabilities.",
            "Should I use the PRN and later on, since DB pedia is clearly worse than a lion?",
            "And should I use the toilet?",
            "And it's this question that Ulysses and so."
        ],
        [
            "So you did Caesar application aware intelligent EPF clients and rely on three TID.",
            "First, replication aware selection to manage both total and partial replication.",
            "Related costs modella for accessing Entergy news, GPS servers and client side load balancer for distributing the load of sparkle query processing.",
            "So first let's talk."
        ],
        [
            "About replication in our replication model, we consider partial replication, where fragments of RDF data set are replicated.",
            "Here you can see an example of such replication where provider S1 and S2 are replicated several fragments from the DB pedia data set.",
            "A fragment is defined as a triple pattern met by all triple replicated and the source from which the triple were replicated.",
            "And here we can see that both S1 and S2 at replicated the same fragment F3.",
            "To manage this replication."
        ],
        [
            "Ulysses rely on an approach based on the catalog.",
            "This catalog defined replicated fragments and where they are hosted.",
            "A starting time Ulysses.",
            "Load this catalog and use state of the art source selection approach to locate each fragment on each servers and now and whole and now.",
            "Which service can be used to evaluate which triple patterns?",
            "So now we know how to evaluate or triple pattern, but how can we go?"
        ],
        [
            "Host server throughput.",
            "How can we evaluate the processing capabilities of our servers?",
            "It's relatively easy."
        ],
        [
            "Because the server stupid can be deduced from the server access time when access time is defined as the time for client to download one page of results from the server.",
            "And since triple pattern can be evaluated in approximate constant time with a good back end.",
            "The success time with only reflects the latency to access the server.",
            "The actual processing capabilities of the servers and the impact of the load on the server processing capabilities.",
            "Additionally, has during query processing, TPF client execute many queries.",
            "We we have a lot of free problem to keep this access time updated in real time.",
            "So here you have the formula used by your cost model to compute servers, who puts it based on the access time of the server and the number of results server access.",
            "And I will show you how this formula work."
        ],
        [
            "For example.",
            "So we have we have 3 servers as one as two suite where S1 and S2 have the same access time but as to serve more results and as trees serve as much results as two but is far slower.",
            "Using our cosmos."
        ],
        [
            "We compute the server throughput are respectively one triple per minute, Second Fort Reaper Mini, Second Zero Point Entry Permit 2nd.",
            "So here we can see that even if S oneself much is faster to access, some reason S3 since three save more triple pair access, they are pretty close in terms of throughput.",
            "That's why throughput is a better metrics than than the simple access time.",
            "So now."
        ],
        [
            "We can compute our server stupid, but using only this metrics it's prettier to compare server processing capabilities.",
            "So we are going to do a little."
        ],
        [
            "Normalization?",
            "To be able to tell precisely how much this server is powerful compared to another, and to do that, we are going to compute servers capability factors."
        ],
        [
            "So here is the formula used by your cost model to compute such server capabilities.",
            "It's pretty simple.",
            "We normalize each super choosing the lowest throughput.",
            "And how it was in my example."
        ],
        [
            "So we could we have one triple per minute segment for triple permanent and zero point entry permit.",
            "Segunda throughputs using our cost model."
        ],
        [
            "We compute that the slowest server is S3 with the capability factor of 1.",
            "Above is S1 with the capability factor of 1.25, so they are indeed pretty close in terms of processing capabilities.",
            "And finally, as two is a capability factor of 6.25, which means that it is 6.25 more powerful than S3."
        ],
        [
            "So now we can compare precisely and I can answer my problem from earlier."
        ],
        [
            "Using my server capabilities factors.",
            "During query processing, Unisys rely on the weighted random allocation strategy to distribute the load of query processing.",
            "That means that a more powerful server is so more chance it has to get accessed.",
            "So at the start of preprocessing, since DB pedia and iron have equal server capability factors, they have equal chance of being accessed and later on past the 14 second mark.",
            "Since the element servers became five times more powerful than the DBPR one, it has five times merchants to be accessed."
        ],
        [
            "So here is the last formula used to compute this weighted random access of TPS servers.",
            "And I will show you how it works with our example."
        ],
        [
            "So we could we have capability factor of 1.25, six point 25 and one.",
            "And using Archos Modella if I want."
        ],
        [
            "To evaluate the triple pattern against this set of replica S1 and S3 have pretty close chance of being access since they are of equal capabilities and as two of the more chance of being accessed since it's a more powerful server or set of Africa.",
            "So that was Ulysses."
        ],
        [
            "Then we wanted to evaluate its performance during an experimental study."
        ],
        [
            "For that asset, we choose whether loose Packer diversity testsuite synthetic data set with diesel, and we use 100 random with queries for replication.",
            "We consider two configuration, the first total replication, where each server replicates the world data set.",
            "And the second partial replication, where only fragments of the RDF data set are replicated.",
            "These segments are created for more queries and I replicated up to two times.",
            "This means that during query processing Ulysses will be able to balance the load of preprocessing using up to two servers.",
            "This."
        ],
        [
            "Ostade on Amazon EC2 cloud using dimicco instances, so these are real life servers.",
            "And we use HTTP proxies to simulate network latency is an special condition according to two configuration.",
            "First one emotion news where all servers have the same access Latin season.",
            "So of course molded or cast model tell us that they have equal processing capabilities.",
            "And the second one attention News was the first ever as an access latency.",
            "Sweet.",
            "I'm higher than the others, so he or cost model will tell us that our server is that the first server is 3 times less powerful than the others.",
            "So let's show some result."
        ],
        [
            "First, we observe that releases is able to balance the load according to server processing capabilities.",
            "Here you can see an experiment with the average number of HTTP requests received by each server using 123 and four replicated servers.",
            "Servers are homogeneous and replication is total.",
            "And seasons servers have equal processing capabilities according to our cost model.",
            "They all receive an approximate equal share of the road.",
            "Next, we are the same."
        ],
        [
            "Experiment with iteration new servers.",
            "Or again we start application and we see that for two servers, since S one is less powerful than S2, it receive less load for three and four server again, it's one receive less loader, but as according to a cost model, the other servers are equal in capabilities.",
            "They always season approximatively approximative share.",
            "Watch my teacher.",
            "Part of the remaining load, sorry.",
            "No."
        ],
        [
            "A bit more complicated with emotional servers, but partial replications this time, so we called that or fragment are replicated up to two time.",
            "And here we show the average number of HTTP requests for evaluating each triple pattern in the five most expensive queries of our benchmark so we can see that fragment replicated up to two times.",
            "So each triple pattern is balanced between 2 servers here between S1S2 and S3.",
            "And, uh, servers are emotionless.",
            "Each evaluation is Shelby is approximately equally shared between servers.",
            "Now."
        ],
        [
            "Something interesting, Ulysses also improved query execution time under an increasing load.",
            "Here we run an experiment with an increasing number of concurrent client executing queries and we measure the average query execution time.",
            "Offer of the query is the average reaction time or for benchmark?",
            "We use several number of server from one to four.",
            "Here is 1 server.",
            "We see that we observe similar results to the original TPS server.",
            "We shall, which means that the average query execution time is deteriorated proportionally to the increasing load.",
            "But using using replica Ulysses is able to reduce this deterioration.",
            "For example with two servers has each server receive half of the load.",
            "Is our less loaded and they can say so far less from an increasing load and we can see that with three and four servers results are even higher."
        ],
        [
            "Finally.",
            "We observe that releases is able to tolerate server failures.",
            "We run an experiment with three emotional servers where the first one fails at the 52nd Mark and the third one fails at the 22nd Mark.",
            "We measure the average HTTP response time when evaluating a query in this in this context and we can see that Unisys is able to detect failures.",
            "And by rescheduling failed HTTP request to remaining replicas, it's able to continue query processing and even in presence of failure, Ulysses is able to terminate query execution to institution with complete results.",
            "So that was Ulysses on our synthetic benchmarks, but it also."
        ],
        [
            "So walk in real life.",
            "You can see a snapshot of our demos that we will run tomorrow.",
            "And the accessing this link you will be able to use Ulysses on real world data set and on real world servers and see how well it performs.",
            "So to conclude."
        ],
        [
            "If I take back our research question how to balance the load of sparkle query processing of a replicated terminal servers owned by autonomous data providers, we can do that using a client side load balancer based on Unisys Cosmo Della and What's Cool is that it requires no change from data providers.",
            "You can run it on the load as it is.",
            "Some future."
        ],
        [
            "Works to finish.",
            "We made the hypothesis that catalog is provided as an input to the engine.",
            "We could explore how to build this catalog.",
            "Some leader, we could provide it as meta data from data providers or through a central index of replicated data set.",
            "Finally, we also consider synchronize replica, which means that there was no update.",
            "We could consider divisions of a replicated data and when lead to support, that is that we only allow load balancing if data set ensure Catama City or Delta consistency."
        ],
        [
            "So thank you everyone, that was Ulysses.",
            "Don't forget to check out of demo tomorrow and if you have any, any questions, it's time."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So hello everyone, I'm Tom in a PhD student at the University of North and today I'm going to present to my work intelligent clients for replicated triple pattern fragments.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Following the link it open that up principal data provider I've made available more and more RDF data set using GPS server to ensure low cost that ousting.",
                    "label": 0
                },
                {
                    "sent": "However, servers availability remain an issue.",
                    "label": 1
                },
                {
                    "sent": "The servers can be done or two every loaded which prevents them to answer to user queries, but it should not be a problem since.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Data provider also replicate RDF datasets.",
                    "label": 1
                },
                {
                    "sent": "For example, both DB pedia and the Los Alamos National Library replicate.",
                    "label": 0
                },
                {
                    "sent": "Several version of the DB Pedia data sets.",
                    "label": 0
                },
                {
                    "sent": "This can we use this replicated data set to improve server availability then?",
                    "label": 1
                },
                {
                    "sent": "So yes, using load balancing to distribute the load of sparkle query processing between all available replica.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This load balancing have several benefits for both data providers and other consumers.",
                    "label": 0
                },
                {
                    "sent": "It's good for data providers because our server are less crowded.",
                    "label": 1
                },
                {
                    "sent": "There are more available and it save money on the toasting for providers.",
                    "label": 1
                },
                {
                    "sent": "It's also good for that consumers because they are able to tolerate server failures.",
                    "label": 0
                },
                {
                    "sent": "If a server is done, I can simply use a replica to continue query processing and a server are less loaded.",
                    "label": 0
                },
                {
                    "sent": "Pre processing performance are improved.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As to our research problem.",
                    "label": 0
                },
                {
                    "sent": "How to balance the load of sparkle query processing of a replicated introduce servers owned by autonomous data providers here in our context, attention news means that servers do not have the same processing capabilities and autonomous means that all data providers means that RDF data set are not hosted by the same data providers.",
                    "label": 1
                },
                {
                    "sent": "So first thing first.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's look at related work.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We could see our set of replica as a Federation, an existing TPF clients allowed to process a Federated sparkle query over Federation of TPS servers.",
                    "label": 1
                },
                {
                    "sent": "However they do not support replication or client side load balancing.",
                    "label": 0
                },
                {
                    "sent": "To illustrate, consider this STALKER query Q1 which find all software developed by French companies.",
                    "label": 0
                },
                {
                    "sent": "If I execute Q1 or the public DBPR server, this query runs in 11.4 second.",
                    "label": 0
                },
                {
                    "sent": "But if I use both DA and electric car from a lion and the exacution term is more than double due to transfer of unnecessary intermediate results.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This link it that our application has already already been addressed, but as a source selection problem.",
                    "label": 0
                },
                {
                    "sent": "In state of the art approach, proved and then sources to avoid transfer of rendant Wizards.",
                    "label": 0
                },
                {
                    "sent": "However, this is far from load balancing.",
                    "label": 0
                },
                {
                    "sent": "For example, if I take back my query Q1 and using approach from the state of the art, I will choose to execute it.",
                    "label": 0
                },
                {
                    "sent": "Either of the DBP server on on the alignment servers if I choose the first one, creates the showing time even, but if I choose the second one, query execution time is more than is deteriorated because the server is less powerful than the DBPR 1.",
                    "label": 0
                },
                {
                    "sent": "So here's what I want to do.",
                    "label": 0
                },
                {
                    "sent": "I want to use both DB pedia and an island.",
                    "label": 0
                },
                {
                    "sent": "To go faster if possible.",
                    "label": 0
                },
                {
                    "sent": "And to do that normally I will use server side load balancing, but as.",
                    "label": 0
                },
                {
                    "sent": "I have data set are hosted by autonomous data provider.",
                    "label": 0
                },
                {
                    "sent": "I can't so I.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We rely on client side load balancing which is well suited for Entergy new servers.",
                    "label": 1
                },
                {
                    "sent": "It fits well in in an intelligent EPF client where query processing is evaluated client side.",
                    "label": 0
                },
                {
                    "sent": "And it respects data provider autonomy because you do not require any change from data providers.",
                    "label": 0
                },
                {
                    "sent": "Or why this approach is currently only be applied for downloading static file from web servers and not for query processing?",
                    "label": 1
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This leads us to approach called Ulysses at what Ulysses do.",
                    "label": 0
                },
                {
                    "sent": "What I want to do.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I want to take this creature on an.",
                    "label": 0
                },
                {
                    "sent": "I want to execute it on both DB pedia and replica from Ryan and I want to distribute the cost of this execution between the two servers.",
                    "label": 0
                },
                {
                    "sent": "During query processing a GPF client, they compose a sparkle query.",
                    "label": 0
                },
                {
                    "sent": "It was set of Subqueries called triple pattern queries and evaluate them using the servers to download intermediate results and process all join locali.",
                    "label": 0
                },
                {
                    "sent": "However, during creep.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Missing query processing capabilities of servers evolve here you can see the evolution of the server throughput of my 2 servers during the evaluation of this query.",
                    "label": 0
                },
                {
                    "sent": "That stuff should boots are pretty equal, but as time goes on, the DB pedia servers become become slower than the NN one.",
                    "label": 0
                },
                {
                    "sent": "So during query processing.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where should I send my triple pattern queries?",
                    "label": 1
                },
                {
                    "sent": "At start sees both servers in.",
                    "label": 0
                },
                {
                    "sent": "Equals in capabilities.",
                    "label": 0
                },
                {
                    "sent": "Should I use the PRN and later on, since DB pedia is clearly worse than a lion?",
                    "label": 0
                },
                {
                    "sent": "And should I use the toilet?",
                    "label": 0
                },
                {
                    "sent": "And it's this question that Ulysses and so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you did Caesar application aware intelligent EPF clients and rely on three TID.",
                    "label": 0
                },
                {
                    "sent": "First, replication aware selection to manage both total and partial replication.",
                    "label": 0
                },
                {
                    "sent": "Related costs modella for accessing Entergy news, GPS servers and client side load balancer for distributing the load of sparkle query processing.",
                    "label": 0
                },
                {
                    "sent": "So first let's talk.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About replication in our replication model, we consider partial replication, where fragments of RDF data set are replicated.",
                    "label": 1
                },
                {
                    "sent": "Here you can see an example of such replication where provider S1 and S2 are replicated several fragments from the DB pedia data set.",
                    "label": 0
                },
                {
                    "sent": "A fragment is defined as a triple pattern met by all triple replicated and the source from which the triple were replicated.",
                    "label": 0
                },
                {
                    "sent": "And here we can see that both S1 and S2 at replicated the same fragment F3.",
                    "label": 0
                },
                {
                    "sent": "To manage this replication.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ulysses rely on an approach based on the catalog.",
                    "label": 1
                },
                {
                    "sent": "This catalog defined replicated fragments and where they are hosted.",
                    "label": 1
                },
                {
                    "sent": "A starting time Ulysses.",
                    "label": 0
                },
                {
                    "sent": "Load this catalog and use state of the art source selection approach to locate each fragment on each servers and now and whole and now.",
                    "label": 0
                },
                {
                    "sent": "Which service can be used to evaluate which triple patterns?",
                    "label": 0
                },
                {
                    "sent": "So now we know how to evaluate or triple pattern, but how can we go?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Host server throughput.",
                    "label": 0
                },
                {
                    "sent": "How can we evaluate the processing capabilities of our servers?",
                    "label": 0
                },
                {
                    "sent": "It's relatively easy.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because the server stupid can be deduced from the server access time when access time is defined as the time for client to download one page of results from the server.",
                    "label": 0
                },
                {
                    "sent": "And since triple pattern can be evaluated in approximate constant time with a good back end.",
                    "label": 1
                },
                {
                    "sent": "The success time with only reflects the latency to access the server.",
                    "label": 0
                },
                {
                    "sent": "The actual processing capabilities of the servers and the impact of the load on the server processing capabilities.",
                    "label": 1
                },
                {
                    "sent": "Additionally, has during query processing, TPF client execute many queries.",
                    "label": 1
                },
                {
                    "sent": "We we have a lot of free problem to keep this access time updated in real time.",
                    "label": 0
                },
                {
                    "sent": "So here you have the formula used by your cost model to compute servers, who puts it based on the access time of the server and the number of results server access.",
                    "label": 0
                },
                {
                    "sent": "And I will show you how this formula work.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "So we have we have 3 servers as one as two suite where S1 and S2 have the same access time but as to serve more results and as trees serve as much results as two but is far slower.",
                    "label": 0
                },
                {
                    "sent": "Using our cosmos.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We compute the server throughput are respectively one triple per minute, Second Fort Reaper Mini, Second Zero Point Entry Permit 2nd.",
                    "label": 0
                },
                {
                    "sent": "So here we can see that even if S oneself much is faster to access, some reason S3 since three save more triple pair access, they are pretty close in terms of throughput.",
                    "label": 0
                },
                {
                    "sent": "That's why throughput is a better metrics than than the simple access time.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can compute our server stupid, but using only this metrics it's prettier to compare server processing capabilities.",
                    "label": 0
                },
                {
                    "sent": "So we are going to do a little.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Normalization?",
                    "label": 0
                },
                {
                    "sent": "To be able to tell precisely how much this server is powerful compared to another, and to do that, we are going to compute servers capability factors.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the formula used by your cost model to compute such server capabilities.",
                    "label": 0
                },
                {
                    "sent": "It's pretty simple.",
                    "label": 0
                },
                {
                    "sent": "We normalize each super choosing the lowest throughput.",
                    "label": 0
                },
                {
                    "sent": "And how it was in my example.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we could we have one triple per minute segment for triple permanent and zero point entry permit.",
                    "label": 0
                },
                {
                    "sent": "Segunda throughputs using our cost model.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We compute that the slowest server is S3 with the capability factor of 1.",
                    "label": 1
                },
                {
                    "sent": "Above is S1 with the capability factor of 1.25, so they are indeed pretty close in terms of processing capabilities.",
                    "label": 0
                },
                {
                    "sent": "And finally, as two is a capability factor of 6.25, which means that it is 6.25 more powerful than S3.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we can compare precisely and I can answer my problem from earlier.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using my server capabilities factors.",
                    "label": 0
                },
                {
                    "sent": "During query processing, Unisys rely on the weighted random allocation strategy to distribute the load of query processing.",
                    "label": 0
                },
                {
                    "sent": "That means that a more powerful server is so more chance it has to get accessed.",
                    "label": 0
                },
                {
                    "sent": "So at the start of preprocessing, since DB pedia and iron have equal server capability factors, they have equal chance of being accessed and later on past the 14 second mark.",
                    "label": 0
                },
                {
                    "sent": "Since the element servers became five times more powerful than the DBPR one, it has five times merchants to be accessed.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the last formula used to compute this weighted random access of TPS servers.",
                    "label": 0
                },
                {
                    "sent": "And I will show you how it works with our example.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we could we have capability factor of 1.25, six point 25 and one.",
                    "label": 0
                },
                {
                    "sent": "And using Archos Modella if I want.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To evaluate the triple pattern against this set of replica S1 and S3 have pretty close chance of being access since they are of equal capabilities and as two of the more chance of being accessed since it's a more powerful server or set of Africa.",
                    "label": 0
                },
                {
                    "sent": "So that was Ulysses.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we wanted to evaluate its performance during an experimental study.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For that asset, we choose whether loose Packer diversity testsuite synthetic data set with diesel, and we use 100 random with queries for replication.",
                    "label": 0
                },
                {
                    "sent": "We consider two configuration, the first total replication, where each server replicates the world data set.",
                    "label": 1
                },
                {
                    "sent": "And the second partial replication, where only fragments of the RDF data set are replicated.",
                    "label": 0
                },
                {
                    "sent": "These segments are created for more queries and I replicated up to two times.",
                    "label": 1
                },
                {
                    "sent": "This means that during query processing Ulysses will be able to balance the load of preprocessing using up to two servers.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ostade on Amazon EC2 cloud using dimicco instances, so these are real life servers.",
                    "label": 1
                },
                {
                    "sent": "And we use HTTP proxies to simulate network latency is an special condition according to two configuration.",
                    "label": 0
                },
                {
                    "sent": "First one emotion news where all servers have the same access Latin season.",
                    "label": 0
                },
                {
                    "sent": "So of course molded or cast model tell us that they have equal processing capabilities.",
                    "label": 0
                },
                {
                    "sent": "And the second one attention News was the first ever as an access latency.",
                    "label": 0
                },
                {
                    "sent": "Sweet.",
                    "label": 0
                },
                {
                    "sent": "I'm higher than the others, so he or cost model will tell us that our server is that the first server is 3 times less powerful than the others.",
                    "label": 0
                },
                {
                    "sent": "So let's show some result.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First, we observe that releases is able to balance the load according to server processing capabilities.",
                    "label": 0
                },
                {
                    "sent": "Here you can see an experiment with the average number of HTTP requests received by each server using 123 and four replicated servers.",
                    "label": 0
                },
                {
                    "sent": "Servers are homogeneous and replication is total.",
                    "label": 0
                },
                {
                    "sent": "And seasons servers have equal processing capabilities according to our cost model.",
                    "label": 1
                },
                {
                    "sent": "They all receive an approximate equal share of the road.",
                    "label": 0
                },
                {
                    "sent": "Next, we are the same.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Experiment with iteration new servers.",
                    "label": 0
                },
                {
                    "sent": "Or again we start application and we see that for two servers, since S one is less powerful than S2, it receive less load for three and four server again, it's one receive less loader, but as according to a cost model, the other servers are equal in capabilities.",
                    "label": 0
                },
                {
                    "sent": "They always season approximatively approximative share.",
                    "label": 0
                },
                {
                    "sent": "Watch my teacher.",
                    "label": 0
                },
                {
                    "sent": "Part of the remaining load, sorry.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A bit more complicated with emotional servers, but partial replications this time, so we called that or fragment are replicated up to two time.",
                    "label": 0
                },
                {
                    "sent": "And here we show the average number of HTTP requests for evaluating each triple pattern in the five most expensive queries of our benchmark so we can see that fragment replicated up to two times.",
                    "label": 0
                },
                {
                    "sent": "So each triple pattern is balanced between 2 servers here between S1S2 and S3.",
                    "label": 0
                },
                {
                    "sent": "And, uh, servers are emotionless.",
                    "label": 0
                },
                {
                    "sent": "Each evaluation is Shelby is approximately equally shared between servers.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something interesting, Ulysses also improved query execution time under an increasing load.",
                    "label": 0
                },
                {
                    "sent": "Here we run an experiment with an increasing number of concurrent client executing queries and we measure the average query execution time.",
                    "label": 0
                },
                {
                    "sent": "Offer of the query is the average reaction time or for benchmark?",
                    "label": 0
                },
                {
                    "sent": "We use several number of server from one to four.",
                    "label": 0
                },
                {
                    "sent": "Here is 1 server.",
                    "label": 0
                },
                {
                    "sent": "We see that we observe similar results to the original TPS server.",
                    "label": 0
                },
                {
                    "sent": "We shall, which means that the average query execution time is deteriorated proportionally to the increasing load.",
                    "label": 0
                },
                {
                    "sent": "But using using replica Ulysses is able to reduce this deterioration.",
                    "label": 0
                },
                {
                    "sent": "For example with two servers has each server receive half of the load.",
                    "label": 0
                },
                {
                    "sent": "Is our less loaded and they can say so far less from an increasing load and we can see that with three and four servers results are even higher.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally.",
                    "label": 0
                },
                {
                    "sent": "We observe that releases is able to tolerate server failures.",
                    "label": 1
                },
                {
                    "sent": "We run an experiment with three emotional servers where the first one fails at the 52nd Mark and the third one fails at the 22nd Mark.",
                    "label": 1
                },
                {
                    "sent": "We measure the average HTTP response time when evaluating a query in this in this context and we can see that Unisys is able to detect failures.",
                    "label": 0
                },
                {
                    "sent": "And by rescheduling failed HTTP request to remaining replicas, it's able to continue query processing and even in presence of failure, Ulysses is able to terminate query execution to institution with complete results.",
                    "label": 0
                },
                {
                    "sent": "So that was Ulysses on our synthetic benchmarks, but it also.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So walk in real life.",
                    "label": 0
                },
                {
                    "sent": "You can see a snapshot of our demos that we will run tomorrow.",
                    "label": 0
                },
                {
                    "sent": "And the accessing this link you will be able to use Ulysses on real world data set and on real world servers and see how well it performs.",
                    "label": 0
                },
                {
                    "sent": "So to conclude.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If I take back our research question how to balance the load of sparkle query processing of a replicated terminal servers owned by autonomous data providers, we can do that using a client side load balancer based on Unisys Cosmo Della and What's Cool is that it requires no change from data providers.",
                    "label": 1
                },
                {
                    "sent": "You can run it on the load as it is.",
                    "label": 0
                },
                {
                    "sent": "Some future.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Works to finish.",
                    "label": 0
                },
                {
                    "sent": "We made the hypothesis that catalog is provided as an input to the engine.",
                    "label": 0
                },
                {
                    "sent": "We could explore how to build this catalog.",
                    "label": 1
                },
                {
                    "sent": "Some leader, we could provide it as meta data from data providers or through a central index of replicated data set.",
                    "label": 1
                },
                {
                    "sent": "Finally, we also consider synchronize replica, which means that there was no update.",
                    "label": 0
                },
                {
                    "sent": "We could consider divisions of a replicated data and when lead to support, that is that we only allow load balancing if data set ensure Catama City or Delta consistency.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thank you everyone, that was Ulysses.",
                    "label": 0
                },
                {
                    "sent": "Don't forget to check out of demo tomorrow and if you have any, any questions, it's time.",
                    "label": 0
                }
            ]
        }
    }
}