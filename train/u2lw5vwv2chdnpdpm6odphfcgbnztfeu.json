{
    "id": "u2lw5vwv2chdnpdpm6odphfcgbnztfeu",
    "title": "Quality-Biased Ranking of Web Documents",
    "info": {
        "author": [
            "Michael Bendersky, Google, Inc."
        ],
        "published": "Aug. 9, 2011",
        "recorded": "February 2011",
        "category": [
            "Top->Computer Science->Web Search"
        ]
    },
    "url": "http://videolectures.net/wsdm2011_bendersky_qbr/",
    "segmentation": [
        [
            "Good afternoon everyone.",
            "My name is Michael Bendersky and this is joint work with Bruce Croft and Young Lady now and we're from University of Massachusetts in Amherst.",
            "And as David says, it's the talk is going to be about quality bias, ranking of web documents."
        ],
        [
            "So the talk outline will be as follows.",
            "I'll start by brief discussion of document quality in the context of web search.",
            "Then I will introduce a model that allows to do ranking with quality bias.",
            "Then I will talk about some empirical revelation of this model and finally I will conclude with some additional discussion.",
            "So let's die."
        ],
        [
            "Into discussing document quality in the context of web search."
        ],
        [
            "Where was a great resource for information because it's so diverse and decentralized, anyone can publish documents on the web and so web pages really vary by the authority of their authors by their goals, by their credibility and credentials, and by their publishing standards.",
            "And so because there is such a diversity on the web, web search, web search engines have this challenge of facing documents of different quality.",
            "And so the real goal of a search engine is to promote documents that have high content, high quality content and to demote pages that have low quality content."
        ],
        [
            "And in the context of commercial web search, it has been very well understood and it is still far from being sold.",
            "So as an example I give you here a quote from the official Google blog post by Matt Cutts from January 2011 where he says as a pure web storm has decreased, overtime attention has shifted instead to size with shallow or low quality content.",
            "In 2010 we Google in this case launched two major algorithmic changes.",
            "That focus on low quality sites.",
            "And so we see that commercial web search engine still work on this problem and it is not.",
            "It is far from being sold.",
            "Now when we look at the publicly available research, there's surprisingly little publicly available research that actually focuses on evaluation of document quality in the context of retrieval.",
            "As a Christian Davidson point out in the recent survey of Adversarial Web search in 2011 that most research really focuses on spam detection and not on evaluation in the context of retrieval, which is the goal of this paper.",
            "To give."
        ],
        [
            "Example of what I mean by low quality content.",
            "Here's an example from golf to collection, which is a collection from text retrieval conference.",
            "Where we have a query low white blood cell count and this query is targeted toward the Gulf, the Gulf to collection, which is basically a crawl of.gov domain and when we use a state of the art retrieval algorithm that doesn't take into account the quality of a webpage, what we get is the 1st result is a list of violations of.",
            "Medical license is in the in the Texas Department of Health, so this is a very long table long list of names and violations where we have a lot of matches with the query terms white blood cell count.",
            "But however, this document is not really relevant to the query.",
            "And this document is achieved in the first position.",
            "As I said, because of all these matches."
        ],
        [
            "Now when we look at the third position, we actually get a relevant document, highly relevant document which talks about white blood cell count.",
            "And provide some information to the user, and so we would like what we would like to do is we would like to."
        ],
        [
            "Shift or switch the position of these two documents in the rank list.",
            "So as we see here at least provided by the regular search where we don't take into account the quality of the document.",
            "Again, the non relevant document comes out first and the relevant document comes out at the third position.",
            "What we'd like to do is write introduce some quality bias."
        ],
        [
            "That will buy us the ranking towards the more informative document, which will become number one and demote the less relevant document which will drop the position 11.",
            "This is the output of our algorithm for this particular query."
        ],
        [
            "Now this brings us to a connection between document quality and spam.",
            "Now we believe that the quality of a webpage is determined by manufacturers.",
            "These factors have to do with document, document content, originality.",
            "It's up to Dateness.",
            "And how many links?",
            "This document provides two different websites and also its publishing layout.",
            "How well it is to read and browse the page.",
            "Now because of all these factors, we really think that document quality is not a binary variable.",
            "Instead it's a continuous spectrum, where on one hand we can see very low quality sites such as spam pages, which are probably not relevant to any query.",
            "On the other hand inspection, we have this high quality documents which are probably very relevant if they actually match the query terms.",
            "However, most documents reside somewhere in between these two extremes.",
            "On the spectrum, and so we would like to introduce this notion of quality bias where we'd like to favor documents that are more close on the spectrum to the high quality, and then do the low quality and into our ranking function."
        ],
        [
            "This brings up another connection which is the document priors.",
            "So a document prior is a very well known notion in information retrieval, which is basically in a priority probability of document being relevant to the query prior to seeing the query.",
            "So this is basically saying how likely documents to be relevant prior to seeing the query.",
            "And so if we have a document which has high quality, it will probably increase.",
            "It's our priority probability of being relevant that it will increase its document prior.",
            "And so when you combine all this quality factors, we would like to combine them in a way that will create a document prior which will interest increase the retrieval effectiveness, which will increase the relevance of the rank list as measured by measures such as an ECG or map.",
            "Now we have other types of document priors started before.",
            "Some examples are link based priors.",
            "Among those were very well known measures such as page rank, heats, or salsa.",
            "We also have user based priors priors based on browsing or clicking behaviors of users and we also have very well known length based priors which is people in normalization proposed by single and colleagues.",
            "And when we can, we'd like to combine these.",
            "Priors with our content quality prior to create even better model."
        ],
        [
            "So let's talk about ranking with quality bias.",
            "How do we actually introduce this quality bias into our ranking function?"
        ],
        [
            "As a baseline model, as an unbiased model that doesn't take into account the content quality, we take the Markov random field model for information retrieval, first proposed by measuring cross in 2005.",
            "Now I will.",
            "I won't go into much details about this model, but in general this model is representing the score of the document as.",
            "A dependency between document D and all the query terms, and so it will.",
            "Score the document using a joint distribution over the graph that has nodes.",
            "Has his nose, the document node and the query term nodes.",
            "Now what Marco Random Field really does, it is a way to capture the the.",
            "Three types of matches.",
            "One type is single term matches, basically matching single terms of the query.",
            "Second, match type is matching exact phrases and 3rd type is matching proximities.",
            "Now, by combining these three different match types, Marco Random Field really achieves state of the art retrieval effectiveness, and it has been shown to be really, really effective in a variety of domains, especially for web search and also for things like block search.",
            "Has also been one of the leading competitors in the text retrieval conference at track at the TB track.",
            "An lately at the web track."
        ],
        [
            "Now as we can see, the mark of random field ranking is based on again 3 components.",
            "The term matches the exact matches in the proximity matches which are parameterized by some parameters, Lambda, T, Lambda and Lambda U.",
            "Now these are the few parameters that we learn them using some learning trend technique."
        ],
        [
            "What we do when we introduce quality bias into this ranking function.",
            "We basically just add another set of parameters that are parameterized again by three parameters Lambda.",
            "So here we have a set of quality factors, FL.",
            "Each of these is again parameterized by parameter Lambda L, and so again, this is.",
            "The Markov random field ranking with quality bias we now take into account not only the query term and query phrase matches will take into account the quality of the document content."
        ],
        [
            "Now this brings us to two interesting points about this method.",
            "First, you might notice that there is no explicit grading of document by quality.",
            "We're not saying we need to find users that will tell us whether this document is high quality document or a low quality document.",
            "We basically saying there is some set of factors that determine document quality and we can learn their best combination for retrieval effectiveness using some.",
            "Scoring function so in this way we allow ourselves not to use anymore labeled data.",
            "Besides the relevance judgments which we already have.",
            "And also we see the document quality bias is really an integral part of ranking.",
            "It's not done prior or after the ranking is done during the ranking, and so that's why the name bias comes from."
        ],
        [
            "Now it is an integral part of the ranking function.",
            "We can basically optimize the weights Lambda the free parameters that we have for both the exact term.",
            "Sorry for both the query term and query phrase matches.",
            "And the quality factors at the same time.",
            "And we can tune these parameters to optimize retrieval metrics such as map or any CG.",
            "Now in our work we use according to sent algorithm proposed by method across in 2007 which is very efficient for a relatively small number of parameters which we have here and also shows empirically good performance.",
            "However, we can really use any other learning to rank technique for this task.",
            "We can use something like SVM rank, Lambda rank, gradient boost, decision trees, and so on.",
            "We're not really limited to this particular algorithm."
        ],
        [
            "Now let's look a little bit more deeply into the quality factors that we're using.",
            "So in this paper.",
            "We computed 10 basic quality factors.",
            "Which target some aspects of document quality as we see them.",
            "And when we computed this quality factors, we look we took into account basically two major things.",
            "One, we wanted our measures to be very simple to compute, so all the measures that we use in this paper can be computed for a very large web collections in a very short time and they are easily parallelizable because they operate only on document level.",
            "The second factor that we want to take when we actually do this factors is that the factor has to be somehow correlated with document content quality as we define it.",
            "The quality factors of features that we use are.",
            "Inspired heavily by previous work on content spam detection and other work in web search.",
            "One type of features that we use are features or factors based on visible text of the document.",
            "That is, we look at number of visible terms on the page or the fraction of visible text page.",
            "Next we look at readability of the document, and for this we compute very simple factors again.",
            "That include average term length, ratio of stock words on the page, and stop words coverage, how many of the stores in at least this document actually covers.",
            "That is, we assume that more readable documents will contain more stock words and the coverage of the stores will be higher."
        ],
        [
            "We also look at the document cohesiveness.",
            "We look at the entropy of the page content's definition of how focus document isn't specific topic and how easy it will be for user to actually read and comprehend the document.",
            "We also looked at very simple features that can look at either navigation over the document.",
            "We looked at number of terms in the page title, the depths of the URL path of the document, an fraction of table text in a document.",
            "So for instance, for the document that you saw as an example, the fraction of table text will be very large.",
            "We also looked at a very simple feature that looks that link provision for the document.",
            "That is, we looked at the fraction of anchor text and document compared to the size of the entire document text.",
            "So again, as you see, these are very simple features that are very easy to compute and can be stored prior to query execution, so they actually do not take.",
            "A lot of time too.",
            "They don't.",
            "They don't know they do not waste a lot of time when we actually do the quality bias ranking."
        ],
        [
            "Now, now that defined the ranking function in the factors that we use, let's look at the evaluation results that.",
            "Let's look at how this method actually does."
        ],
        [
            "So we looked at 2 document collections.",
            "And in our work, we'd like to focus on collections with no explicit spam, since within the document quality.",
            "Is also important collections where we have no spam, so we looked at Gov 2 collection, which again is a crawl.",
            "Of.gov domain mostly contains documents produced by American government, so it is specialized web collection which is not very likely to contain explicit spam.",
            "But it is likely to contain documents of different quality as we define it.",
            "We also know that clue Web collection Clue Web collection is a 500 million web pages.",
            "Which is the general web collection and contains a lot of spam.",
            "However, to remove the spam we applied spam filter proposed by Cormick an colleagues in 2010 which has been found to be very effective in terms of spam removal and so we apply these filters of the collection and do our experience in the collection with the spam filter applied.",
            "In order to see do our features of that defined document quality contribute when we already removed the documents that are.",
            "Explicitly spam."
        ],
        [
            "So let's look at the results for Gov 2 collection for Gov 2 collection, computed two baselines, first based on the Markov random field, which is again the non biased ranking and the second baseline is our method which is the mark of random field with quality bias.",
            "As you can see for all ranks for an ECG from 3, five and 10 we get significant improvement over the baseline in the area of 10% and these are all significant.",
            "And very impressive improvements.",
            "Give take into account the fact that Mark Reynolds actually very effective model for this collection.",
            "Next you move to."
        ],
        [
            "Clue web.",
            "For Clue Web again, we looked at three baselines.",
            "Now we looked at Markov random field.",
            "Then we also computed paging for Clue Web an.",
            "Since Club is a large collection, we actually.",
            "Hold that Pagerank will find you know interesting and authorative pages, and so it will contribute to the effectiveness of Markov random field.",
            "So Mark over a few plus page rank is our second based on the third.",
            "Based on these, again Mark over field and the quality bias.",
            "So as we see computing paging does help a little bit and especially for any CGI 3 where there is a.",
            "A small gain in energy.",
            "However, when we look at Marco review plus quality bias, there is a significant improvement compared to both Marco Random Field and Macaroni Plus page rank.",
            "We get almost 20% improvement across all.",
            "Ranks for new CG."
        ],
        [
            "Now, now that we saw the results, let's look at let's make some discussion about why this results happen."
        ],
        [
            "So let's talk about the G2 first.",
            "Four goes to collection of what we found is that.",
            "Applying this this quality bias actually demotes a lot of non informative pages pages like the one you saw before pages that contain long tables or least pages that contain a lot of data dumps or link listings.",
            "So these pages might be useful for crawler or for automatic consumption, but they're not really useful for users who want to find information in this collection, so our method does a very good job in demoting these non informative pages.",
            "An promoting page that.",
            "Actually contain useful content that people can read.",
            "For clue where we found another surprising result.",
            "So our method does not explicitly promote page from certain domains.",
            "However, we found that when we actually look at the top 10 results for our method compared to the baseline method, which is the mark of random field, we found that this.",
            "Quality bias method is 5 times more likely to retrieve a Wikipedia page in the top 10 results than the mark of random field.",
            "So what happens really is our method implicitly promotes Wikipedia pages as it learns that Wikipedia pages are actually high quality pages and they should be promoted to the top of the rank list."
        ],
        [
            "So to conclude, there are three simple takeaway messages from this talk.",
            "First, we proposed a very straightforward approach to introduce quality bias into a state of the art retrieval method.",
            "2nd, we showed how to compute very simple content based features that can stand for content quality in this pre.",
            "Features include features that are based on document readability page like page layout and navigation.",
            "Now our model can also be extended to incorporate more sophisticated quality features as well, and this is maybe.",
            "A good direction for future work.",
            "Finally, we show that even with this very simple to compute features, we're able to get really significant improvements for both the specialist web collection that does not contain explicit spambot contains pages of different quality and also for general web collections where we remove spam and also applied Pagerank prior.",
            "And so, with these three takeaway messages messages, I'd like to."
        ],
        [
            "In this talk, I thank you very much for your time and I hope you have some questions.",
            "Thank you.",
            "Questions.",
            "Yeah hi, you've started your investigation on the assumption that you can.",
            "Measure some things in a static way about the document and you had some expectations and they kind of came out and you talk.",
            "You said that things that use short words are likely to be better quality and that one didn't actually resonate with me.",
            "I would expect more literate authorship to be better quality.",
            "So my question is, do you know which of your factors had a positive effect and which ones had a negative affect?",
            "Did you get any surprises from your weights that evolved and did you find that there were some factors that you had thought were going to?",
            "I ask the outcome one way that in fact biased at the other way, and then the supplementary is.",
            "Can the spammers learn the same things, right?",
            "That's a good question, so.",
            "I can't think of features here.",
            "They actually were negatively affecting the results.",
            "I can find.",
            "One surprise was that actually using a stop word features which are soccer coverage and fractional stopwords.",
            "Just these two features was very very helpful in detecting quality documents.",
            "So these two features had consistently high weight in all our collections.",
            "So you know it's surprising, but these two features were actually very, very important for this thing to work.",
            "To the second question, which is can spammers learn this?",
            "Wait, it is true.",
            "But note that our method actually learns this weights to improve retrieval effectiveness, so we can rerun this method once in awhile to actually re learn the weights and you know it's of course it's A kind of arms race, but you know, if spammers learn that certain feature is very helpful and start spamming, we can actually down way this feature or even make it a negative feature in our because as I said.",
            "We learned the weights by looking at the relevance of the rank list.",
            "I hope this answers your question.",
            "Michael, thanks for a nice talk in another great paper.",
            "I have a question actually more about the MRF than the quality measure itself.",
            "So back when I was working with the MRF model, I found that there actually wasn't any benefit from the ordered window that all that was going on was just that you're getting the added weight of basically doing the unordered twice, so the standard MRF model is 85% on the unigram, 10% on the.",
            "Diagrams and then 5% on the unordered.",
            "And if I just did 15% on the unordered, it was the same thing.",
            "Or have you guys seen this anymore of the other experiments are actually getting any benefit from the ordered matching?",
            "Or is it really just this?",
            "Again this case that you just getting the benefit from the ordered component by just adding up the unordered twice.",
            "And do the against the elimination study, where I would remove the other one.",
            "So I can't say if it's actually help or not, but I know that it gets some weight when we actually learn the model.",
            "So it's not.",
            "I mean, we do learn that this is an important feature.",
            "Maybe if we removed it, you know the order window would take over and we won't actually have any drop in performance.",
            "So yeah, so the order would take over and we won't see it not dropping the performance, but we didn't.",
            "The method to give it some weight when we run it so.",
            "So one reason information you know in a lot of information retrieval test collections, I guess you don't have the variation in quality that you have in these in these web test collections.",
            "But have we actually checked?",
            "Like have you done experiments with some non web collections using these kind of features or do you have any plans to do such experiments?",
            "That's a very good point.",
            "So some of these features only applied to web such as anchor text and table text.",
            "But you're right, some of these features can be actually applied to non web collections and maybe there.",
            "Be helpful there as well.",
            "Yeah, we didn't look at it so, but that could be a good thing to look at.",
            "I'll take one, did you will try to connect your your metrics with page rank or yeah yeah, so actually I don't remember which one the slides, but we found that actually there is no significant difference when we add the page rank through the quality bias features.",
            "We really found no significant difference between these two, so when we add the quality bias adding page rank in addition to that doesn't really help that much in our model at least, the way we learn the model.",
            "Maybe there is a more speak about to learn it in a way that actually will help.",
            "But that's what we found.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is Michael Bendersky and this is joint work with Bruce Croft and Young Lady now and we're from University of Massachusetts in Amherst.",
                    "label": 1
                },
                {
                    "sent": "And as David says, it's the talk is going to be about quality bias, ranking of web documents.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the talk outline will be as follows.",
                    "label": 0
                },
                {
                    "sent": "I'll start by brief discussion of document quality in the context of web search.",
                    "label": 1
                },
                {
                    "sent": "Then I will introduce a model that allows to do ranking with quality bias.",
                    "label": 0
                },
                {
                    "sent": "Then I will talk about some empirical revelation of this model and finally I will conclude with some additional discussion.",
                    "label": 0
                },
                {
                    "sent": "So let's die.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Into discussing document quality in the context of web search.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where was a great resource for information because it's so diverse and decentralized, anyone can publish documents on the web and so web pages really vary by the authority of their authors by their goals, by their credibility and credentials, and by their publishing standards.",
                    "label": 1
                },
                {
                    "sent": "And so because there is such a diversity on the web, web search, web search engines have this challenge of facing documents of different quality.",
                    "label": 0
                },
                {
                    "sent": "And so the real goal of a search engine is to promote documents that have high content, high quality content and to demote pages that have low quality content.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in the context of commercial web search, it has been very well understood and it is still far from being sold.",
                    "label": 0
                },
                {
                    "sent": "So as an example I give you here a quote from the official Google blog post by Matt Cutts from January 2011 where he says as a pure web storm has decreased, overtime attention has shifted instead to size with shallow or low quality content.",
                    "label": 1
                },
                {
                    "sent": "In 2010 we Google in this case launched two major algorithmic changes.",
                    "label": 0
                },
                {
                    "sent": "That focus on low quality sites.",
                    "label": 0
                },
                {
                    "sent": "And so we see that commercial web search engine still work on this problem and it is not.",
                    "label": 1
                },
                {
                    "sent": "It is far from being sold.",
                    "label": 0
                },
                {
                    "sent": "Now when we look at the publicly available research, there's surprisingly little publicly available research that actually focuses on evaluation of document quality in the context of retrieval.",
                    "label": 0
                },
                {
                    "sent": "As a Christian Davidson point out in the recent survey of Adversarial Web search in 2011 that most research really focuses on spam detection and not on evaluation in the context of retrieval, which is the goal of this paper.",
                    "label": 0
                },
                {
                    "sent": "To give.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Example of what I mean by low quality content.",
                    "label": 0
                },
                {
                    "sent": "Here's an example from golf to collection, which is a collection from text retrieval conference.",
                    "label": 0
                },
                {
                    "sent": "Where we have a query low white blood cell count and this query is targeted toward the Gulf, the Gulf to collection, which is basically a crawl of.gov domain and when we use a state of the art retrieval algorithm that doesn't take into account the quality of a webpage, what we get is the 1st result is a list of violations of.",
                    "label": 0
                },
                {
                    "sent": "Medical license is in the in the Texas Department of Health, so this is a very long table long list of names and violations where we have a lot of matches with the query terms white blood cell count.",
                    "label": 1
                },
                {
                    "sent": "But however, this document is not really relevant to the query.",
                    "label": 0
                },
                {
                    "sent": "And this document is achieved in the first position.",
                    "label": 0
                },
                {
                    "sent": "As I said, because of all these matches.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now when we look at the third position, we actually get a relevant document, highly relevant document which talks about white blood cell count.",
                    "label": 0
                },
                {
                    "sent": "And provide some information to the user, and so we would like what we would like to do is we would like to.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Shift or switch the position of these two documents in the rank list.",
                    "label": 0
                },
                {
                    "sent": "So as we see here at least provided by the regular search where we don't take into account the quality of the document.",
                    "label": 0
                },
                {
                    "sent": "Again, the non relevant document comes out first and the relevant document comes out at the third position.",
                    "label": 0
                },
                {
                    "sent": "What we'd like to do is write introduce some quality bias.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That will buy us the ranking towards the more informative document, which will become number one and demote the less relevant document which will drop the position 11.",
                    "label": 0
                },
                {
                    "sent": "This is the output of our algorithm for this particular query.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now this brings us to a connection between document quality and spam.",
                    "label": 1
                },
                {
                    "sent": "Now we believe that the quality of a webpage is determined by manufacturers.",
                    "label": 1
                },
                {
                    "sent": "These factors have to do with document, document content, originality.",
                    "label": 0
                },
                {
                    "sent": "It's up to Dateness.",
                    "label": 0
                },
                {
                    "sent": "And how many links?",
                    "label": 0
                },
                {
                    "sent": "This document provides two different websites and also its publishing layout.",
                    "label": 0
                },
                {
                    "sent": "How well it is to read and browse the page.",
                    "label": 0
                },
                {
                    "sent": "Now because of all these factors, we really think that document quality is not a binary variable.",
                    "label": 0
                },
                {
                    "sent": "Instead it's a continuous spectrum, where on one hand we can see very low quality sites such as spam pages, which are probably not relevant to any query.",
                    "label": 0
                },
                {
                    "sent": "On the other hand inspection, we have this high quality documents which are probably very relevant if they actually match the query terms.",
                    "label": 1
                },
                {
                    "sent": "However, most documents reside somewhere in between these two extremes.",
                    "label": 0
                },
                {
                    "sent": "On the spectrum, and so we would like to introduce this notion of quality bias where we'd like to favor documents that are more close on the spectrum to the high quality, and then do the low quality and into our ranking function.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This brings up another connection which is the document priors.",
                    "label": 1
                },
                {
                    "sent": "So a document prior is a very well known notion in information retrieval, which is basically in a priority probability of document being relevant to the query prior to seeing the query.",
                    "label": 0
                },
                {
                    "sent": "So this is basically saying how likely documents to be relevant prior to seeing the query.",
                    "label": 0
                },
                {
                    "sent": "And so if we have a document which has high quality, it will probably increase.",
                    "label": 1
                },
                {
                    "sent": "It's our priority probability of being relevant that it will increase its document prior.",
                    "label": 0
                },
                {
                    "sent": "And so when you combine all this quality factors, we would like to combine them in a way that will create a document prior which will interest increase the retrieval effectiveness, which will increase the relevance of the rank list as measured by measures such as an ECG or map.",
                    "label": 1
                },
                {
                    "sent": "Now we have other types of document priors started before.",
                    "label": 0
                },
                {
                    "sent": "Some examples are link based priors.",
                    "label": 0
                },
                {
                    "sent": "Among those were very well known measures such as page rank, heats, or salsa.",
                    "label": 0
                },
                {
                    "sent": "We also have user based priors priors based on browsing or clicking behaviors of users and we also have very well known length based priors which is people in normalization proposed by single and colleagues.",
                    "label": 0
                },
                {
                    "sent": "And when we can, we'd like to combine these.",
                    "label": 0
                },
                {
                    "sent": "Priors with our content quality prior to create even better model.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's talk about ranking with quality bias.",
                    "label": 0
                },
                {
                    "sent": "How do we actually introduce this quality bias into our ranking function?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As a baseline model, as an unbiased model that doesn't take into account the content quality, we take the Markov random field model for information retrieval, first proposed by measuring cross in 2005.",
                    "label": 0
                },
                {
                    "sent": "Now I will.",
                    "label": 0
                },
                {
                    "sent": "I won't go into much details about this model, but in general this model is representing the score of the document as.",
                    "label": 0
                },
                {
                    "sent": "A dependency between document D and all the query terms, and so it will.",
                    "label": 1
                },
                {
                    "sent": "Score the document using a joint distribution over the graph that has nodes.",
                    "label": 0
                },
                {
                    "sent": "Has his nose, the document node and the query term nodes.",
                    "label": 1
                },
                {
                    "sent": "Now what Marco Random Field really does, it is a way to capture the the.",
                    "label": 1
                },
                {
                    "sent": "Three types of matches.",
                    "label": 0
                },
                {
                    "sent": "One type is single term matches, basically matching single terms of the query.",
                    "label": 1
                },
                {
                    "sent": "Second, match type is matching exact phrases and 3rd type is matching proximities.",
                    "label": 0
                },
                {
                    "sent": "Now, by combining these three different match types, Marco Random Field really achieves state of the art retrieval effectiveness, and it has been shown to be really, really effective in a variety of domains, especially for web search and also for things like block search.",
                    "label": 0
                },
                {
                    "sent": "Has also been one of the leading competitors in the text retrieval conference at track at the TB track.",
                    "label": 0
                },
                {
                    "sent": "An lately at the web track.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now as we can see, the mark of random field ranking is based on again 3 components.",
                    "label": 0
                },
                {
                    "sent": "The term matches the exact matches in the proximity matches which are parameterized by some parameters, Lambda, T, Lambda and Lambda U.",
                    "label": 0
                },
                {
                    "sent": "Now these are the few parameters that we learn them using some learning trend technique.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we do when we introduce quality bias into this ranking function.",
                    "label": 1
                },
                {
                    "sent": "We basically just add another set of parameters that are parameterized again by three parameters Lambda.",
                    "label": 0
                },
                {
                    "sent": "So here we have a set of quality factors, FL.",
                    "label": 0
                },
                {
                    "sent": "Each of these is again parameterized by parameter Lambda L, and so again, this is.",
                    "label": 0
                },
                {
                    "sent": "The Markov random field ranking with quality bias we now take into account not only the query term and query phrase matches will take into account the quality of the document content.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now this brings us to two interesting points about this method.",
                    "label": 0
                },
                {
                    "sent": "First, you might notice that there is no explicit grading of document by quality.",
                    "label": 1
                },
                {
                    "sent": "We're not saying we need to find users that will tell us whether this document is high quality document or a low quality document.",
                    "label": 0
                },
                {
                    "sent": "We basically saying there is some set of factors that determine document quality and we can learn their best combination for retrieval effectiveness using some.",
                    "label": 0
                },
                {
                    "sent": "Scoring function so in this way we allow ourselves not to use anymore labeled data.",
                    "label": 0
                },
                {
                    "sent": "Besides the relevance judgments which we already have.",
                    "label": 0
                },
                {
                    "sent": "And also we see the document quality bias is really an integral part of ranking.",
                    "label": 1
                },
                {
                    "sent": "It's not done prior or after the ranking is done during the ranking, and so that's why the name bias comes from.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now it is an integral part of the ranking function.",
                    "label": 0
                },
                {
                    "sent": "We can basically optimize the weights Lambda the free parameters that we have for both the exact term.",
                    "label": 0
                },
                {
                    "sent": "Sorry for both the query term and query phrase matches.",
                    "label": 0
                },
                {
                    "sent": "And the quality factors at the same time.",
                    "label": 0
                },
                {
                    "sent": "And we can tune these parameters to optimize retrieval metrics such as map or any CG.",
                    "label": 0
                },
                {
                    "sent": "Now in our work we use according to sent algorithm proposed by method across in 2007 which is very efficient for a relatively small number of parameters which we have here and also shows empirically good performance.",
                    "label": 1
                },
                {
                    "sent": "However, we can really use any other learning to rank technique for this task.",
                    "label": 0
                },
                {
                    "sent": "We can use something like SVM rank, Lambda rank, gradient boost, decision trees, and so on.",
                    "label": 0
                },
                {
                    "sent": "We're not really limited to this particular algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let's look a little bit more deeply into the quality factors that we're using.",
                    "label": 0
                },
                {
                    "sent": "So in this paper.",
                    "label": 0
                },
                {
                    "sent": "We computed 10 basic quality factors.",
                    "label": 1
                },
                {
                    "sent": "Which target some aspects of document quality as we see them.",
                    "label": 0
                },
                {
                    "sent": "And when we computed this quality factors, we look we took into account basically two major things.",
                    "label": 0
                },
                {
                    "sent": "One, we wanted our measures to be very simple to compute, so all the measures that we use in this paper can be computed for a very large web collections in a very short time and they are easily parallelizable because they operate only on document level.",
                    "label": 0
                },
                {
                    "sent": "The second factor that we want to take when we actually do this factors is that the factor has to be somehow correlated with document content quality as we define it.",
                    "label": 0
                },
                {
                    "sent": "The quality factors of features that we use are.",
                    "label": 0
                },
                {
                    "sent": "Inspired heavily by previous work on content spam detection and other work in web search.",
                    "label": 0
                },
                {
                    "sent": "One type of features that we use are features or factors based on visible text of the document.",
                    "label": 0
                },
                {
                    "sent": "That is, we look at number of visible terms on the page or the fraction of visible text page.",
                    "label": 1
                },
                {
                    "sent": "Next we look at readability of the document, and for this we compute very simple factors again.",
                    "label": 0
                },
                {
                    "sent": "That include average term length, ratio of stock words on the page, and stop words coverage, how many of the stores in at least this document actually covers.",
                    "label": 0
                },
                {
                    "sent": "That is, we assume that more readable documents will contain more stock words and the coverage of the stores will be higher.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also look at the document cohesiveness.",
                    "label": 0
                },
                {
                    "sent": "We look at the entropy of the page content's definition of how focus document isn't specific topic and how easy it will be for user to actually read and comprehend the document.",
                    "label": 0
                },
                {
                    "sent": "We also looked at very simple features that can look at either navigation over the document.",
                    "label": 0
                },
                {
                    "sent": "We looked at number of terms in the page title, the depths of the URL path of the document, an fraction of table text in a document.",
                    "label": 1
                },
                {
                    "sent": "So for instance, for the document that you saw as an example, the fraction of table text will be very large.",
                    "label": 0
                },
                {
                    "sent": "We also looked at a very simple feature that looks that link provision for the document.",
                    "label": 0
                },
                {
                    "sent": "That is, we looked at the fraction of anchor text and document compared to the size of the entire document text.",
                    "label": 0
                },
                {
                    "sent": "So again, as you see, these are very simple features that are very easy to compute and can be stored prior to query execution, so they actually do not take.",
                    "label": 0
                },
                {
                    "sent": "A lot of time too.",
                    "label": 0
                },
                {
                    "sent": "They don't.",
                    "label": 0
                },
                {
                    "sent": "They don't know they do not waste a lot of time when we actually do the quality bias ranking.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, now that defined the ranking function in the factors that we use, let's look at the evaluation results that.",
                    "label": 0
                },
                {
                    "sent": "Let's look at how this method actually does.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we looked at 2 document collections.",
                    "label": 0
                },
                {
                    "sent": "And in our work, we'd like to focus on collections with no explicit spam, since within the document quality.",
                    "label": 1
                },
                {
                    "sent": "Is also important collections where we have no spam, so we looked at Gov 2 collection, which again is a crawl.",
                    "label": 0
                },
                {
                    "sent": "Of.gov domain mostly contains documents produced by American government, so it is specialized web collection which is not very likely to contain explicit spam.",
                    "label": 0
                },
                {
                    "sent": "But it is likely to contain documents of different quality as we define it.",
                    "label": 1
                },
                {
                    "sent": "We also know that clue Web collection Clue Web collection is a 500 million web pages.",
                    "label": 0
                },
                {
                    "sent": "Which is the general web collection and contains a lot of spam.",
                    "label": 0
                },
                {
                    "sent": "However, to remove the spam we applied spam filter proposed by Cormick an colleagues in 2010 which has been found to be very effective in terms of spam removal and so we apply these filters of the collection and do our experience in the collection with the spam filter applied.",
                    "label": 0
                },
                {
                    "sent": "In order to see do our features of that defined document quality contribute when we already removed the documents that are.",
                    "label": 0
                },
                {
                    "sent": "Explicitly spam.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at the results for Gov 2 collection for Gov 2 collection, computed two baselines, first based on the Markov random field, which is again the non biased ranking and the second baseline is our method which is the mark of random field with quality bias.",
                    "label": 0
                },
                {
                    "sent": "As you can see for all ranks for an ECG from 3, five and 10 we get significant improvement over the baseline in the area of 10% and these are all significant.",
                    "label": 0
                },
                {
                    "sent": "And very impressive improvements.",
                    "label": 0
                },
                {
                    "sent": "Give take into account the fact that Mark Reynolds actually very effective model for this collection.",
                    "label": 0
                },
                {
                    "sent": "Next you move to.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Clue web.",
                    "label": 0
                },
                {
                    "sent": "For Clue Web again, we looked at three baselines.",
                    "label": 0
                },
                {
                    "sent": "Now we looked at Markov random field.",
                    "label": 0
                },
                {
                    "sent": "Then we also computed paging for Clue Web an.",
                    "label": 0
                },
                {
                    "sent": "Since Club is a large collection, we actually.",
                    "label": 0
                },
                {
                    "sent": "Hold that Pagerank will find you know interesting and authorative pages, and so it will contribute to the effectiveness of Markov random field.",
                    "label": 0
                },
                {
                    "sent": "So Mark over a few plus page rank is our second based on the third.",
                    "label": 0
                },
                {
                    "sent": "Based on these, again Mark over field and the quality bias.",
                    "label": 0
                },
                {
                    "sent": "So as we see computing paging does help a little bit and especially for any CGI 3 where there is a.",
                    "label": 0
                },
                {
                    "sent": "A small gain in energy.",
                    "label": 0
                },
                {
                    "sent": "However, when we look at Marco review plus quality bias, there is a significant improvement compared to both Marco Random Field and Macaroni Plus page rank.",
                    "label": 0
                },
                {
                    "sent": "We get almost 20% improvement across all.",
                    "label": 0
                },
                {
                    "sent": "Ranks for new CG.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, now that we saw the results, let's look at let's make some discussion about why this results happen.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's talk about the G2 first.",
                    "label": 0
                },
                {
                    "sent": "Four goes to collection of what we found is that.",
                    "label": 0
                },
                {
                    "sent": "Applying this this quality bias actually demotes a lot of non informative pages pages like the one you saw before pages that contain long tables or least pages that contain a lot of data dumps or link listings.",
                    "label": 0
                },
                {
                    "sent": "So these pages might be useful for crawler or for automatic consumption, but they're not really useful for users who want to find information in this collection, so our method does a very good job in demoting these non informative pages.",
                    "label": 0
                },
                {
                    "sent": "An promoting page that.",
                    "label": 0
                },
                {
                    "sent": "Actually contain useful content that people can read.",
                    "label": 0
                },
                {
                    "sent": "For clue where we found another surprising result.",
                    "label": 0
                },
                {
                    "sent": "So our method does not explicitly promote page from certain domains.",
                    "label": 0
                },
                {
                    "sent": "However, we found that when we actually look at the top 10 results for our method compared to the baseline method, which is the mark of random field, we found that this.",
                    "label": 0
                },
                {
                    "sent": "Quality bias method is 5 times more likely to retrieve a Wikipedia page in the top 10 results than the mark of random field.",
                    "label": 1
                },
                {
                    "sent": "So what happens really is our method implicitly promotes Wikipedia pages as it learns that Wikipedia pages are actually high quality pages and they should be promoted to the top of the rank list.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude, there are three simple takeaway messages from this talk.",
                    "label": 0
                },
                {
                    "sent": "First, we proposed a very straightforward approach to introduce quality bias into a state of the art retrieval method.",
                    "label": 1
                },
                {
                    "sent": "2nd, we showed how to compute very simple content based features that can stand for content quality in this pre.",
                    "label": 1
                },
                {
                    "sent": "Features include features that are based on document readability page like page layout and navigation.",
                    "label": 1
                },
                {
                    "sent": "Now our model can also be extended to incorporate more sophisticated quality features as well, and this is maybe.",
                    "label": 0
                },
                {
                    "sent": "A good direction for future work.",
                    "label": 0
                },
                {
                    "sent": "Finally, we show that even with this very simple to compute features, we're able to get really significant improvements for both the specialist web collection that does not contain explicit spambot contains pages of different quality and also for general web collections where we remove spam and also applied Pagerank prior.",
                    "label": 0
                },
                {
                    "sent": "And so, with these three takeaway messages messages, I'd like to.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this talk, I thank you very much for your time and I hope you have some questions.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Yeah hi, you've started your investigation on the assumption that you can.",
                    "label": 0
                },
                {
                    "sent": "Measure some things in a static way about the document and you had some expectations and they kind of came out and you talk.",
                    "label": 0
                },
                {
                    "sent": "You said that things that use short words are likely to be better quality and that one didn't actually resonate with me.",
                    "label": 0
                },
                {
                    "sent": "I would expect more literate authorship to be better quality.",
                    "label": 0
                },
                {
                    "sent": "So my question is, do you know which of your factors had a positive effect and which ones had a negative affect?",
                    "label": 0
                },
                {
                    "sent": "Did you get any surprises from your weights that evolved and did you find that there were some factors that you had thought were going to?",
                    "label": 0
                },
                {
                    "sent": "I ask the outcome one way that in fact biased at the other way, and then the supplementary is.",
                    "label": 0
                },
                {
                    "sent": "Can the spammers learn the same things, right?",
                    "label": 0
                },
                {
                    "sent": "That's a good question, so.",
                    "label": 0
                },
                {
                    "sent": "I can't think of features here.",
                    "label": 0
                },
                {
                    "sent": "They actually were negatively affecting the results.",
                    "label": 0
                },
                {
                    "sent": "I can find.",
                    "label": 0
                },
                {
                    "sent": "One surprise was that actually using a stop word features which are soccer coverage and fractional stopwords.",
                    "label": 0
                },
                {
                    "sent": "Just these two features was very very helpful in detecting quality documents.",
                    "label": 0
                },
                {
                    "sent": "So these two features had consistently high weight in all our collections.",
                    "label": 0
                },
                {
                    "sent": "So you know it's surprising, but these two features were actually very, very important for this thing to work.",
                    "label": 0
                },
                {
                    "sent": "To the second question, which is can spammers learn this?",
                    "label": 0
                },
                {
                    "sent": "Wait, it is true.",
                    "label": 0
                },
                {
                    "sent": "But note that our method actually learns this weights to improve retrieval effectiveness, so we can rerun this method once in awhile to actually re learn the weights and you know it's of course it's A kind of arms race, but you know, if spammers learn that certain feature is very helpful and start spamming, we can actually down way this feature or even make it a negative feature in our because as I said.",
                    "label": 0
                },
                {
                    "sent": "We learned the weights by looking at the relevance of the rank list.",
                    "label": 0
                },
                {
                    "sent": "I hope this answers your question.",
                    "label": 0
                },
                {
                    "sent": "Michael, thanks for a nice talk in another great paper.",
                    "label": 0
                },
                {
                    "sent": "I have a question actually more about the MRF than the quality measure itself.",
                    "label": 0
                },
                {
                    "sent": "So back when I was working with the MRF model, I found that there actually wasn't any benefit from the ordered window that all that was going on was just that you're getting the added weight of basically doing the unordered twice, so the standard MRF model is 85% on the unigram, 10% on the.",
                    "label": 0
                },
                {
                    "sent": "Diagrams and then 5% on the unordered.",
                    "label": 0
                },
                {
                    "sent": "And if I just did 15% on the unordered, it was the same thing.",
                    "label": 0
                },
                {
                    "sent": "Or have you guys seen this anymore of the other experiments are actually getting any benefit from the ordered matching?",
                    "label": 0
                },
                {
                    "sent": "Or is it really just this?",
                    "label": 0
                },
                {
                    "sent": "Again this case that you just getting the benefit from the ordered component by just adding up the unordered twice.",
                    "label": 0
                },
                {
                    "sent": "And do the against the elimination study, where I would remove the other one.",
                    "label": 0
                },
                {
                    "sent": "So I can't say if it's actually help or not, but I know that it gets some weight when we actually learn the model.",
                    "label": 0
                },
                {
                    "sent": "So it's not.",
                    "label": 0
                },
                {
                    "sent": "I mean, we do learn that this is an important feature.",
                    "label": 0
                },
                {
                    "sent": "Maybe if we removed it, you know the order window would take over and we won't actually have any drop in performance.",
                    "label": 0
                },
                {
                    "sent": "So yeah, so the order would take over and we won't see it not dropping the performance, but we didn't.",
                    "label": 0
                },
                {
                    "sent": "The method to give it some weight when we run it so.",
                    "label": 0
                },
                {
                    "sent": "So one reason information you know in a lot of information retrieval test collections, I guess you don't have the variation in quality that you have in these in these web test collections.",
                    "label": 0
                },
                {
                    "sent": "But have we actually checked?",
                    "label": 0
                },
                {
                    "sent": "Like have you done experiments with some non web collections using these kind of features or do you have any plans to do such experiments?",
                    "label": 0
                },
                {
                    "sent": "That's a very good point.",
                    "label": 0
                },
                {
                    "sent": "So some of these features only applied to web such as anchor text and table text.",
                    "label": 0
                },
                {
                    "sent": "But you're right, some of these features can be actually applied to non web collections and maybe there.",
                    "label": 0
                },
                {
                    "sent": "Be helpful there as well.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we didn't look at it so, but that could be a good thing to look at.",
                    "label": 0
                },
                {
                    "sent": "I'll take one, did you will try to connect your your metrics with page rank or yeah yeah, so actually I don't remember which one the slides, but we found that actually there is no significant difference when we add the page rank through the quality bias features.",
                    "label": 0
                },
                {
                    "sent": "We really found no significant difference between these two, so when we add the quality bias adding page rank in addition to that doesn't really help that much in our model at least, the way we learn the model.",
                    "label": 0
                },
                {
                    "sent": "Maybe there is a more speak about to learn it in a way that actually will help.",
                    "label": 0
                },
                {
                    "sent": "But that's what we found.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}