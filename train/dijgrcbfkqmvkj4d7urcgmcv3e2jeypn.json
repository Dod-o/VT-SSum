{
    "id": "dijgrcbfkqmvkj4d7urcgmcv3e2jeypn",
    "title": "Adaptive Submodularity: A New Approach to Active Learning and Stochastic Optimization",
    "info": {
        "author": [
            "Daniel Golovin, Research at Google, Google, Inc."
        ],
        "published": "Jan. 13, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2010_golovin_asm/",
    "segmentation": [
        [
            "Today I'll be talking about adaptive submodularity, which is a new framework for active learning and stochastic optimization, and this is joint work with undress Kraus and Debre."
        ],
        [
            "OK, so let me start off with an application.",
            "Suppose you are running some viral marketing campaign and you have some new product and you'd like to basically have people, well, you want a lot of people buy it right?",
            "And you should decide to have some kind of viral marketing campaign where you're going to promote this item by sort of giving it away to a few people.",
            "Hope that they really love it and will tell their friends about it and their friends will get it, and their friends will like it and they will tell their friends and so on until it takes over the world.",
            "OK, so this problem was considered in this particular framework of influence in social networks.",
            "Those studied by Kim Kleinberg and Tardos and basically they consider a particular model of social dynamics where you know if I have this network, the social network that I know something about and I have these edges that are kind of annotated with probabilities and the way that demand is assumed to propagate in this graph is kind of as follows.",
            "Imagine maybe I want to give this cell phone to Alice.",
            "And then each of these edges incident on her will be sampled independently.",
            "So with probability 1/3 sample some edge to Bob.",
            "Maybe Bob's not interested.",
            "But you know, Charlie.",
            "Half the time he's interested, so Allison influences him.",
            "He decides he'd like to get this phone and then all the edges on Charlie are then sampled in the same way.",
            "Bob, still having none of it.",
            "But maybe Daria is interested, so will sample the remaining.",
            "She gets the phone and will sample the edges from her to Eric and Fiona.",
            "And maybe neither that of them are interested, and then so the process is now completed.",
            "OK, and so if you know you're running this advertising campaign, so maybe you only have a budget and the number of cell phones you want to give out, and so you get this kind of optimization problem where I have this ground set which is a set of people and I have this objective function F of a which is basically the expected number of people who will kind of want this phone and get it if I initially give it away to the set of people in a.",
            "And one of the major results of this paper by Kemp at all is to show that this function is monotone submodular.",
            "So if you just sort of run the greedy algorithm, you can approximately optimize this function.",
            "You can get 1 -- 1 / E of the kind of optimal value."
        ],
        [
            "OK, but suppose you want to be a little bit more reactive in that right?",
            "You don't want to just sort of.",
            "Give all out all your phones at the same time.",
            "Maybe you really want to sort of give out some.",
            "See how your campaign is going may be adjusted dynamically and so on so we can imagine some adaptive variant of this, right?",
            "So now it's like before the social, the propagation of demand happens exactly as in the previous slide.",
            "But now I'm going to imagine that you sort of get to give a phone out, maybe to Alice watch this kind of demand process unfold, where sort of demand for this product spread throughout the social network and.",
            "You get to see all these edges that are sampled so you can see who buys the phone.",
            "And then after the process has unfolded, then you get to select another person to give a free phone and in the process unfolds and you repeat let's say K Times Now the question is, can you do well in this setting?",
            "So really, what you want is to find an optimal policy, not just an optimal set.",
            "So before we wanted a set of people now really, you know you have a policy that dictates, given what we've already done an whose boughten bought the phones.",
            "What should you do next?"
        ],
        [
            "OK, so we addressed this problem using this new kind of analytic framework called under the rubric of adaptive submodularity developed by myself and Andreas.",
            "The idea here is that we have this objective function which is a function of both, kind of what we did in this case, maybe the set of people a that we gave out free phones too, and some notion of the realization of the world, sort of which edges would actually spread influence or demand for this product.",
            "Kind of including the ones we haven't seen.",
            "So if you fix all those edges in advance, all the coin tosses then and then you fix the set of people that you're going to sort of.",
            "Give these three phones too.",
            "That tells you everything about who will eventually acquire these phones.",
            "OK. And we'll assume you have this prior over this world state.",
            "So in the previous example, this would be these probabilities on these edges.",
            "Now given all this, we can define this quantity.",
            "The conditional expected marginal benefits.",
            "So sort of given some observations.",
            "We've made this exhibe, so we say this sort of encodes all the things we've seen and all the things we've done and is maybe another person, so we imagine giving away the phone to some person E, and this is kind of in expectation.",
            "How many how much more we get for how many more people will buy this phone as a result?",
            "And the adaptive some modularity condition just says that this quantity this expected conditional marginal benefit is not increasing as we do more things and make more observations.",
            "So this is a generalization of submodularity.",
            "In this adaptive realm.",
            "And the actual sort of.",
            "We also need this monotonicity condition because what we're doing is basically a adaptive generalization of kind of monotone submodular optimization, and this just says that these conditional expected marginal benefits are non negative.",
            "OK, no matter what I've seen, no matter what I choose to do next, it can't hurt me.",
            "So you know, if I give a phone to some particularly like, I don't know non hit person.",
            "It's not like everyone else returns their phones, right?"
        ],
        [
            "OK, so this is this new concept.",
            "What's a good for?",
            "Well, basically it's a fundamental new tool for designing and analyzing sort of greedy near optimal algorithms for several problems, active learning and experimental design and several adaptive optimization problems like this viral marketing example.",
            "And sort of.",
            "The key intuition is that it's really powerful because it allows us to lift classic results on submodular optimization into the adaptive realm."
        ],
        [
            "So let me give you an example.",
            "This one is you want to maximize some monotone submodular function under this constraint that you only get to pick K things in your set.",
            "So earlier today Jan Vondrak talked about problems like this.",
            "And sort of a classic approach is a simple greedy algorithm, right?",
            "It's the most the most basic thing you can think of, right?",
            "You just sort of at each time step you pick the thing that maximizes your marginal benefit and sort of a classic result by nemhauser at all.",
            "Is that this algorithm is a 1 -- 1 over approximation.",
            "It gets you about 63% of the best set you could pick."
        ],
        [
            "So we're going to lift that result into the adaptive realm.",
            "What does this mean?",
            "Well, instead of finding a set, we want to find a policy.",
            "If not, if you'd like, you can think of this as a decision tree of depth K. So the policy only picks up K things, no matter what realization of the world we're living in.",
            "And the algorithm we're going to consider is just a generalization of this greedy algorithm called the adaptive greedy algorithm.",
            "And basically, instead of looking at the maximizing the marginal benefit at each step, it will maximize the conditional expected marginal benefit.",
            "And after it picks this element, it will make some observation.",
            "And then that gets added to the sort of our posterior overworlds states that we condition over in the next step.",
            "What can do is generalize this celebrated result and then how's it all into the adaptive case to basically say that if you have a adaptive submodular adaptive monotone function, that and you look at sort of the expected reward of the policy that's generated for kind of represented implicitly by this algorithm.",
            "This greedy policy?",
            "That's 1 -- 1 / E of the optimal policy that picks at most K things that no matter what realization.",
            "So we've generalized from sets to policies.",
            "You know?",
            "Even in cases where these optimal policies can be exponential in K."
        ],
        [
            "So it turns out that in this out of our marketing example, the objective function of how many people eventually buy the phone.",
            "Is adaptive monotone submodular?",
            "So the simple adaptive greedy algorithm gets within 1 -- 1 / E of the optimal policy and this 1 -- 1 / E was kind of the optimal constant we could get in the non adaptive case or also getting it in the adaptive case.",
            "So clearly this is the best we can do short of.",
            "Making exponentially many function calls.",
            "So we also get one free for various other problems.",
            "One that we studied in the past is a thing called stochastic submodular maximization, so we generalize some result by asadpour aside Portal, and I don't have alot of time to talk about that, but there are various other other problems here."
        ],
        [
            "So that's like a maximum budget maximization.",
            "Kind of a problem.",
            "We can also look at kind of in cost cover sort of problems.",
            "So instead of sort of giving out K phones and trying to maximize the total number of people that get it, we could say well now as you're running this viral marketing ad campaign or this viral marketing campaign, and you want to achieve a certain level of market penetration, so you're going to keep giving these things out until you get 25% of the market or 5% of the market or whatever your target is.",
            "And now you want to do it using as few sort of promotions as possible.",
            "If you want to give away as few items as possible in order to do this.",
            "So more generally, you want to reach some threshold value of.",
            "And you want to do with minimum expected sort of number of actions or costs of actions more generally.",
            "It turns out that if you have an adaptive submodular objective, adaptive monotone.",
            "That you get a logarithm approximation for this problem.",
            "So for example, there's this stochastic set cover problem that's been studied before by Goemans and Vondrak and Lou at all, and we get sort of the optimal approximation factor for this, which is the natural log of the number of things we need to cover.",
            "There's some nice work which is similar in spirit to this work on interactive submodular set cover by Gillian Bilmes who are here, but this is more of sort of worst case analysis, and we're considering more average case."
        ],
        [
            "OK, so I told you about adaptive viral marketing.",
            "Let me give you an example of another application just to show that it's not specific to that application.",
            "This is sometimes called the optimal decision tree problem.",
            "Basically, suppose we have a sick puppy and we want to have a machine be sort of play veterinarian and diagnose this puppy.",
            "So we imagine that there's some prior over diseases.",
            "The puppy might have an, then there are various sort of symptoms.",
            "Things we can test for.",
            "Does the puppy have a fever?",
            "Does it have a rash?",
            "Does a coughing and so on.",
            "Does it blood have various proteins?",
            "And we imagine that these tests that we can run and.",
            "We have some sort of prior over the diseases and also this.",
            "Likelihood over the outcome of the tests or the symptoms displayed.",
            "Conditioned on the disease.",
            "So we have this probabilistic model about how diseases create symptoms or testable outcomes.",
            "So in the simplest case.",
            "Sort of, the outcome of a test is deterministic function of what the disease is.",
            "This is the noise free case.",
            "So just for now, let's consider that one.",
            "And in this case, sort of each test based on the outcome will eliminate certain hypothesis.",
            "Certain diseases just get ruled out after you see the outcome of some test.",
            "So for example, you might run some tests and based on the outcome you cut away some things.",
            "Now we have this question well.",
            "OK.",
            "So now we have this question of how we should select these tests, kind of adaptively to eliminate all of the incorrect hypothesis.",
            "And a classic objective here is sort of wait these diseases by their prior probability mass and try to rule out as much mass as possible as quickly as possible.",
            "So we can define this.",
            "Kind of conditional expected marginal benefit of running some test T. Based on the expected probability mass, we rule out sort of conditioned on what we've already seen.",
            "And then once we have this quantity, we can sort of greedily pick the test that maximizes it in each step.",
            "The result of this is called generalized binary search.",
            "It's kind of a classic algorithm.",
            "It also turns out to be equivalent to another classic algorithm, which is discretely maximizing the information gain in this noise free case."
        ],
        [
            "So it turns out that these algorithms actually do pretty well.",
            "This algorithm does very well in this noise free case, and the reason is in some sense is because the subjective probability mass of hypothesis you've ruled out is adaptive submodular.",
            "Let me very briefly go over.",
            "You know why that is or how you would go about proving it.",
            "Well, imagine we're in this situation here.",
            "We have these tests.",
            "We have these diseases and we have some test X which based on the outcome will partition it.",
            "In this case, in the two sets, because there are two outcomes, but in general it could be more than two outcomes.",
            "We get this partition into, say, a blue set of diseases and a green one, and we can look at the initial sort of prior probability mass in the blue region in the green region, call it be not in G nought.",
            "And then it's not too hard to show that the expected conditional marginal benefit of running this test at this point is this quantity.",
            "But imagine now we don't run this test.",
            "So what do we need to do to show it?",
            "At this modularity, we need to show that if we sort of do some more tests and then perform this test that our expected marginal utility is not increasing, it goes down, but not up.",
            "So suppose instead of running test X, we run some other tests on V&W and we eliminate some things and we consider running this test again.",
            "So, similarly I can define sort of the remaining probability mass in the blue region and in the green region called B1 and G1 and I get the same quantity for the conditional expected marginal benefit.",
            "And now all I need to show is that sort of Delta final is no more than Delta initial.",
            "And what do I know about this?",
            "Well, I know that sort of diseases get ruled out.",
            "They never come back, so be not is at least be one.",
            "Angie, not is.",
            "At least the one.",
            "And so it's really not that hard to show that under these constraints this quantity is less than sort of.",
            "Delta final is less than Delta initial.",
            "So it's adaptive so modular."
        ],
        [
            "OK. And kind of the previous state of the art in terms of the analysis of the approximation ratio of this generalized binary search algorithm, which is just a special case of this adaptive greedy algorithm with this objective.",
            "Was that it was a four long 1 / P man approximation where P man is the minimum prior probability of any hypothesis.",
            "This is due to Dasgupta in 2004.",
            "This problem has been studied quite a bit here more some of the some of the more important references on this problem.",
            "So just as a corollary of this kind of more general theorem, we can reduce this to this approximation ratio.",
            "OK, so everything I've told you about this problem is now assumed that these tests are exact.",
            "There's no noise at all.",
            "But that's not really a realistic assumption in most application."
        ],
        [
            "So what do you do if you have a noisy observations, right?",
            "How do you do noisy Bayesian active learning?",
            "And so, well, first is tests don't rule out hypothesis anymore, they just sort of make them less likely.",
            "So now, given a hypothesis, I have a distributed posterior distribution.",
            "Conditional distribution over test outcomes for any given test.",
            "So even if I were to run all of the tests, I still have some uncertainty as to the underlying disease or underlying hypothesis.",
            "OK so I can't.",
            "My criterion before was to identify the true hypothesis with certainty and I don't.",
            "I can't do that anymore.",
            "So what should be the sort of natural criterion?",
            "So one way to think about this is I'm going to I'm gathering this information about this patient to do something I want to treat the patient.",
            "And so really what you care about is identifying what the optimal sort of treatment is, what the optimal intervention is for this patient."
        ],
        [
            "So we imagine that we ran every test imaginable.",
            "We learned as much as we possibly could about this patient, and then we run some kind of optimization problem.",
            "In order to figure out what the best treatment is.",
            "So for example, you can define some utility function which takes an intervention or an act sort of treatment plan and disease and sort of tells you how good or bad it is.",
            "An you can say maximize that an expectation or you can do some more sophisticated things, but the point is, given this posterior over diseases, you can define what the optimal treatment plan is will call a star.",
            "And so sort of the goal of our.",
            "Our information gathering is to figure out what this a star is.",
            "What is the optimal way to treat this patient?",
            "That's what I care about.",
            "So we figure this out well.",
            "We can try various previous approaches like generalized binary search or maximizing the information gain, maximizing the value of information which would be sort of the expected increase in utility.",
            "But these things don't give you adaptive submodular objectives.",
            "And in various kind of very simple noise models with slightly with some correlated noise, they require exponentially more tests than the optimum."
        ],
        [
            "So how should we deal with this well?",
            "Our strategy is going to be reducing the noisy problem to a particular noise free problem, and the key idea is to make these test outcomes sort of the vector of all test outcomes, sort of part of the hypothesis.",
            "So basically now I have sort of.",
            "Diseases with noisy copies, 'cause the symptoms can be different for different people with the same disease, say and I'm going to label them with the observation vectors.",
            "OK, so this is the outcome of all the tests.",
            "And now, given all these observation vectors, I'm going to label them with a color which will correspond to what the best treatment plan is.",
            "So some of these are green, orange, red or blue, and depending on the color that's going to dictate how I should be treating the patient."
        ],
        [
            "So now all I need to do is identify the color of the true outcome vector.",
            "I don't need to determine what it is.",
            "So I'm going to group these by color.",
            "And I just need to figure out what the group is so.",
            "To do so, I'm going to define a graph.",
            "Where?",
            "I have an edge between all pairs of nodes here that are in different groups.",
            "'cause you know an edge means I have to distinguish between the two.",
            "And these are weighted in a particular way.",
            "The weight of this edge is just going to be the prior probability of this times the prior probability of that.",
            "There's technical reasons why it has to be that way, but the idea is I really want to destroy these edges and the way I destroy them is to rule out one of the observation vectors incident on this edge.",
            "And you can kind of see that.",
            "If I get rid of all of the edges, that means that all of the remaining possible observation vectors that are consistent with what I've seen have to lie in the same group.",
            "And this is sort of an if and only if statement if they all line one group, then all these edges must be gone.",
            "If all the edges are gone, they must lie in one group.",
            "So for example, if we have tests like this and then we run the first Test and we observe the outcome of the first Test is a one, well, this disease goes away because its first coordinate of 0.",
            "This one goes away because its first coordinate is a 0.",
            "OK, all the edges incident on them get deleted and we've thrown out a whole bunch of edges.",
            "In kind of."
        ],
        [
            "The criterion we care about is the kind of expected weight of the edges we throw out.",
            "You just sort of greedily optimize this.",
            "Then we get this thing called that we call the edge cutting equivalence class edge cutting algorithm.",
            "And it has this nice theoretical guarantee that says that the cost of this policy is within a tool on 1 / P min plus one approx.",
            "Approximation of the optimal cost of the optimal policy, where payment is now the minimum prior probability of any kind of observation outcome vector.",
            "OK, and note that if you're you know, this optimal policy could be quite could be quite large.",
            "Right, if you wrote it out as a decision tree could be exponentially large.",
            "But we still get this nice approximation factor.",
            "It turns out that.",
            "To the best of my knowledge, this is the very first approximation guarantee for Bayesian active learning with noise.",
            "For sort of any noise model.",
            "And this one gives sort of parameterized guarantees for arbitrary noise models."
        ],
        [
            "So we should try to use this on a particular task.",
            "Basically there are various economic theories about how people assess risk and how they sort of value risk.",
            "And it would be nice to sort of tease apart which one actually which one or ones explain human behavior.",
            "So here are some examples.",
            "Right maximize it, you might choose risks that maximize expected utility or prefer.",
            "Of risks where you have higher expected utility, maybe you care about reducing variance.",
            "There are various criteria that economists have come up with and we'd like to see, sort of which theory is true.",
            "So how can we design tests to do this?",
            "Kind of a natural thing to do.",
            "Is to set people down and give him a choice of two lotteries, so it's a lottery.",
            "Well in this community may be the best way to explain a lottery system random variable where the outcomes are dollar values.",
            "So here maybe 30% of the time I take $10 from you and 70% of the time I give you $10.",
            "So I give you two of these and I just ask well which do you like better?"
        ],
        [
            "So you can think of this as a Bayesian experimental design question.",
            "Where I have these theories?",
            "With some parameters I can parameterise them say by Theta and now a test is two of these lotteries.",
            "Of course there are lots of choices of lotteries.",
            "And sort of.",
            "We will introduce some.",
            "We introduced some error into this or some noise into this process by basically saying that we've given a particular theory.",
            "We can evaluate the utility of a particular lottery with respect to that theory.",
            "Basically, when we're comparing, the two will say essentially that the closer the utilities are, the more likely sort of the algorithm generating these responses is likely to make an error in some sort of logistic was away.",
            "So it's a lot of these are really close, so we're simulating some agent playing trying to optimize its utility with respect to some theory and sort of.",
            "The closer the two utilities are there more likely this agent is to make a mistake."
        ],
        [
            "So in this case you know we have access to the ground truth because we're generating it, and so we can test our algorithm against various competitors.",
            "So it's kind of curious, but a lot of the standard ones like generalized binary search or maximizing value information greedily, or this uncertainty sampling.",
            "Actually they did perform terribly in this case, they're significantly worse than random, and this was initially a bit of a puzzle to us, but sort of figured out that things like uncertainty sampling.",
            "They're kind of learning the noise.",
            "Kind of, Interestingly, information gain does much better.",
            "But our algorithm significantly outperforms it.",
            "And this is a significant increase in accuracy, given that sort of at the very top of this graph is 100%.",
            "Performance so."
        ],
        [
            "We also kind of got some some human subjects, sort of 11 undergraduates and ran this setup with them.",
            "Just try to see which economic theory best explained their sort of preferences or their choices.",
            "And.",
            "It turned out that most of them were following this expected value.",
            "Theory or were best explained.",
            "Their behavior was best explained by this theory that says you just maximize expected value in your lotteries.",
            "But there was heterogeneity in the population, so there were.",
            "Sort of two that were explained by prospect theory and one each that were explained by these other theories.",
            "And.",
            "You know the tests were really quite fast and it was nice to be able to do these sort of user the subject tests."
        ],
        [
            "So in conclusion, I've shown you this sort of fundamental new framework for design analysis of greedy near optimal algorithms for these adaptive optimization problems.",
            "And it sort of generalizes and recovers many known.",
            "Guarantees for various applications in a fairly unified manner.",
            "There are lots of extensions here that I didn't have time to go into.",
            "For example, if you can only approximately evaluate these conditional expected marginal benefits, or you can only evaluate them noisily.",
            "Are there other sort of benefits in terms of speeding it up with lazy evaluations and so on?",
            "But sort of this is the high level idea.",
            "I invite you to take a look at the paper.",
            "And thank you very much.",
            "Yes.",
            "Complicated constraints.",
            "Some of the other.",
            "Right, so we've been working on that, and actually so I can say that they do.",
            "These results do extend into the matroid constraint case.",
            "So the question is.",
            "If you want to maximize one of these functions, but instead of picking K things, you get to pick some independent set in a matroid.",
            "How well can you do?",
            "And it turns out that you can get the same kind of guarantees as the greedy algorithm achieves in the Nonadaptive case.",
            "So for a matroid constraint you'll get half approximation.",
            "OK, so let's think again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Today I'll be talking about adaptive submodularity, which is a new framework for active learning and stochastic optimization, and this is joint work with undress Kraus and Debre.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let me start off with an application.",
                    "label": 0
                },
                {
                    "sent": "Suppose you are running some viral marketing campaign and you have some new product and you'd like to basically have people, well, you want a lot of people buy it right?",
                    "label": 0
                },
                {
                    "sent": "And you should decide to have some kind of viral marketing campaign where you're going to promote this item by sort of giving it away to a few people.",
                    "label": 0
                },
                {
                    "sent": "Hope that they really love it and will tell their friends about it and their friends will get it, and their friends will like it and they will tell their friends and so on until it takes over the world.",
                    "label": 0
                },
                {
                    "sent": "OK, so this problem was considered in this particular framework of influence in social networks.",
                    "label": 1
                },
                {
                    "sent": "Those studied by Kim Kleinberg and Tardos and basically they consider a particular model of social dynamics where you know if I have this network, the social network that I know something about and I have these edges that are kind of annotated with probabilities and the way that demand is assumed to propagate in this graph is kind of as follows.",
                    "label": 0
                },
                {
                    "sent": "Imagine maybe I want to give this cell phone to Alice.",
                    "label": 0
                },
                {
                    "sent": "And then each of these edges incident on her will be sampled independently.",
                    "label": 0
                },
                {
                    "sent": "So with probability 1/3 sample some edge to Bob.",
                    "label": 0
                },
                {
                    "sent": "Maybe Bob's not interested.",
                    "label": 0
                },
                {
                    "sent": "But you know, Charlie.",
                    "label": 0
                },
                {
                    "sent": "Half the time he's interested, so Allison influences him.",
                    "label": 0
                },
                {
                    "sent": "He decides he'd like to get this phone and then all the edges on Charlie are then sampled in the same way.",
                    "label": 0
                },
                {
                    "sent": "Bob, still having none of it.",
                    "label": 0
                },
                {
                    "sent": "But maybe Daria is interested, so will sample the remaining.",
                    "label": 0
                },
                {
                    "sent": "She gets the phone and will sample the edges from her to Eric and Fiona.",
                    "label": 0
                },
                {
                    "sent": "And maybe neither that of them are interested, and then so the process is now completed.",
                    "label": 0
                },
                {
                    "sent": "OK, and so if you know you're running this advertising campaign, so maybe you only have a budget and the number of cell phones you want to give out, and so you get this kind of optimization problem where I have this ground set which is a set of people and I have this objective function F of a which is basically the expected number of people who will kind of want this phone and get it if I initially give it away to the set of people in a.",
                    "label": 0
                },
                {
                    "sent": "And one of the major results of this paper by Kemp at all is to show that this function is monotone submodular.",
                    "label": 0
                },
                {
                    "sent": "So if you just sort of run the greedy algorithm, you can approximately optimize this function.",
                    "label": 0
                },
                {
                    "sent": "You can get 1 -- 1 / E of the kind of optimal value.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, but suppose you want to be a little bit more reactive in that right?",
                    "label": 0
                },
                {
                    "sent": "You don't want to just sort of.",
                    "label": 0
                },
                {
                    "sent": "Give all out all your phones at the same time.",
                    "label": 0
                },
                {
                    "sent": "Maybe you really want to sort of give out some.",
                    "label": 0
                },
                {
                    "sent": "See how your campaign is going may be adjusted dynamically and so on so we can imagine some adaptive variant of this, right?",
                    "label": 0
                },
                {
                    "sent": "So now it's like before the social, the propagation of demand happens exactly as in the previous slide.",
                    "label": 0
                },
                {
                    "sent": "But now I'm going to imagine that you sort of get to give a phone out, maybe to Alice watch this kind of demand process unfold, where sort of demand for this product spread throughout the social network and.",
                    "label": 0
                },
                {
                    "sent": "You get to see all these edges that are sampled so you can see who buys the phone.",
                    "label": 0
                },
                {
                    "sent": "And then after the process has unfolded, then you get to select another person to give a free phone and in the process unfolds and you repeat let's say K Times Now the question is, can you do well in this setting?",
                    "label": 0
                },
                {
                    "sent": "So really, what you want is to find an optimal policy, not just an optimal set.",
                    "label": 0
                },
                {
                    "sent": "So before we wanted a set of people now really, you know you have a policy that dictates, given what we've already done an whose boughten bought the phones.",
                    "label": 0
                },
                {
                    "sent": "What should you do next?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we addressed this problem using this new kind of analytic framework called under the rubric of adaptive submodularity developed by myself and Andreas.",
                    "label": 1
                },
                {
                    "sent": "The idea here is that we have this objective function which is a function of both, kind of what we did in this case, maybe the set of people a that we gave out free phones too, and some notion of the realization of the world, sort of which edges would actually spread influence or demand for this product.",
                    "label": 0
                },
                {
                    "sent": "Kind of including the ones we haven't seen.",
                    "label": 0
                },
                {
                    "sent": "So if you fix all those edges in advance, all the coin tosses then and then you fix the set of people that you're going to sort of.",
                    "label": 0
                },
                {
                    "sent": "Give these three phones too.",
                    "label": 0
                },
                {
                    "sent": "That tells you everything about who will eventually acquire these phones.",
                    "label": 0
                },
                {
                    "sent": "OK. And we'll assume you have this prior over this world state.",
                    "label": 0
                },
                {
                    "sent": "So in the previous example, this would be these probabilities on these edges.",
                    "label": 0
                },
                {
                    "sent": "Now given all this, we can define this quantity.",
                    "label": 0
                },
                {
                    "sent": "The conditional expected marginal benefits.",
                    "label": 0
                },
                {
                    "sent": "So sort of given some observations.",
                    "label": 0
                },
                {
                    "sent": "We've made this exhibe, so we say this sort of encodes all the things we've seen and all the things we've done and is maybe another person, so we imagine giving away the phone to some person E, and this is kind of in expectation.",
                    "label": 0
                },
                {
                    "sent": "How many how much more we get for how many more people will buy this phone as a result?",
                    "label": 0
                },
                {
                    "sent": "And the adaptive some modularity condition just says that this quantity this expected conditional marginal benefit is not increasing as we do more things and make more observations.",
                    "label": 0
                },
                {
                    "sent": "So this is a generalization of submodularity.",
                    "label": 0
                },
                {
                    "sent": "In this adaptive realm.",
                    "label": 0
                },
                {
                    "sent": "And the actual sort of.",
                    "label": 0
                },
                {
                    "sent": "We also need this monotonicity condition because what we're doing is basically a adaptive generalization of kind of monotone submodular optimization, and this just says that these conditional expected marginal benefits are non negative.",
                    "label": 0
                },
                {
                    "sent": "OK, no matter what I've seen, no matter what I choose to do next, it can't hurt me.",
                    "label": 0
                },
                {
                    "sent": "So you know, if I give a phone to some particularly like, I don't know non hit person.",
                    "label": 0
                },
                {
                    "sent": "It's not like everyone else returns their phones, right?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is this new concept.",
                    "label": 0
                },
                {
                    "sent": "What's a good for?",
                    "label": 0
                },
                {
                    "sent": "Well, basically it's a fundamental new tool for designing and analyzing sort of greedy near optimal algorithms for several problems, active learning and experimental design and several adaptive optimization problems like this viral marketing example.",
                    "label": 1
                },
                {
                    "sent": "And sort of.",
                    "label": 1
                },
                {
                    "sent": "The key intuition is that it's really powerful because it allows us to lift classic results on submodular optimization into the adaptive realm.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me give you an example.",
                    "label": 0
                },
                {
                    "sent": "This one is you want to maximize some monotone submodular function under this constraint that you only get to pick K things in your set.",
                    "label": 0
                },
                {
                    "sent": "So earlier today Jan Vondrak talked about problems like this.",
                    "label": 0
                },
                {
                    "sent": "And sort of a classic approach is a simple greedy algorithm, right?",
                    "label": 0
                },
                {
                    "sent": "It's the most the most basic thing you can think of, right?",
                    "label": 0
                },
                {
                    "sent": "You just sort of at each time step you pick the thing that maximizes your marginal benefit and sort of a classic result by nemhauser at all.",
                    "label": 0
                },
                {
                    "sent": "Is that this algorithm is a 1 -- 1 over approximation.",
                    "label": 0
                },
                {
                    "sent": "It gets you about 63% of the best set you could pick.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're going to lift that result into the adaptive realm.",
                    "label": 0
                },
                {
                    "sent": "What does this mean?",
                    "label": 0
                },
                {
                    "sent": "Well, instead of finding a set, we want to find a policy.",
                    "label": 0
                },
                {
                    "sent": "If not, if you'd like, you can think of this as a decision tree of depth K. So the policy only picks up K things, no matter what realization of the world we're living in.",
                    "label": 0
                },
                {
                    "sent": "And the algorithm we're going to consider is just a generalization of this greedy algorithm called the adaptive greedy algorithm.",
                    "label": 0
                },
                {
                    "sent": "And basically, instead of looking at the maximizing the marginal benefit at each step, it will maximize the conditional expected marginal benefit.",
                    "label": 0
                },
                {
                    "sent": "And after it picks this element, it will make some observation.",
                    "label": 0
                },
                {
                    "sent": "And then that gets added to the sort of our posterior overworlds states that we condition over in the next step.",
                    "label": 0
                },
                {
                    "sent": "What can do is generalize this celebrated result and then how's it all into the adaptive case to basically say that if you have a adaptive submodular adaptive monotone function, that and you look at sort of the expected reward of the policy that's generated for kind of represented implicitly by this algorithm.",
                    "label": 0
                },
                {
                    "sent": "This greedy policy?",
                    "label": 0
                },
                {
                    "sent": "That's 1 -- 1 / E of the optimal policy that picks at most K things that no matter what realization.",
                    "label": 0
                },
                {
                    "sent": "So we've generalized from sets to policies.",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "Even in cases where these optimal policies can be exponential in K.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it turns out that in this out of our marketing example, the objective function of how many people eventually buy the phone.",
                    "label": 0
                },
                {
                    "sent": "Is adaptive monotone submodular?",
                    "label": 0
                },
                {
                    "sent": "So the simple adaptive greedy algorithm gets within 1 -- 1 / E of the optimal policy and this 1 -- 1 / E was kind of the optimal constant we could get in the non adaptive case or also getting it in the adaptive case.",
                    "label": 0
                },
                {
                    "sent": "So clearly this is the best we can do short of.",
                    "label": 0
                },
                {
                    "sent": "Making exponentially many function calls.",
                    "label": 0
                },
                {
                    "sent": "So we also get one free for various other problems.",
                    "label": 1
                },
                {
                    "sent": "One that we studied in the past is a thing called stochastic submodular maximization, so we generalize some result by asadpour aside Portal, and I don't have alot of time to talk about that, but there are various other other problems here.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's like a maximum budget maximization.",
                    "label": 0
                },
                {
                    "sent": "Kind of a problem.",
                    "label": 0
                },
                {
                    "sent": "We can also look at kind of in cost cover sort of problems.",
                    "label": 1
                },
                {
                    "sent": "So instead of sort of giving out K phones and trying to maximize the total number of people that get it, we could say well now as you're running this viral marketing ad campaign or this viral marketing campaign, and you want to achieve a certain level of market penetration, so you're going to keep giving these things out until you get 25% of the market or 5% of the market or whatever your target is.",
                    "label": 0
                },
                {
                    "sent": "And now you want to do it using as few sort of promotions as possible.",
                    "label": 0
                },
                {
                    "sent": "If you want to give away as few items as possible in order to do this.",
                    "label": 0
                },
                {
                    "sent": "So more generally, you want to reach some threshold value of.",
                    "label": 0
                },
                {
                    "sent": "And you want to do with minimum expected sort of number of actions or costs of actions more generally.",
                    "label": 1
                },
                {
                    "sent": "It turns out that if you have an adaptive submodular objective, adaptive monotone.",
                    "label": 1
                },
                {
                    "sent": "That you get a logarithm approximation for this problem.",
                    "label": 0
                },
                {
                    "sent": "So for example, there's this stochastic set cover problem that's been studied before by Goemans and Vondrak and Lou at all, and we get sort of the optimal approximation factor for this, which is the natural log of the number of things we need to cover.",
                    "label": 0
                },
                {
                    "sent": "There's some nice work which is similar in spirit to this work on interactive submodular set cover by Gillian Bilmes who are here, but this is more of sort of worst case analysis, and we're considering more average case.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I told you about adaptive viral marketing.",
                    "label": 0
                },
                {
                    "sent": "Let me give you an example of another application just to show that it's not specific to that application.",
                    "label": 0
                },
                {
                    "sent": "This is sometimes called the optimal decision tree problem.",
                    "label": 1
                },
                {
                    "sent": "Basically, suppose we have a sick puppy and we want to have a machine be sort of play veterinarian and diagnose this puppy.",
                    "label": 0
                },
                {
                    "sent": "So we imagine that there's some prior over diseases.",
                    "label": 1
                },
                {
                    "sent": "The puppy might have an, then there are various sort of symptoms.",
                    "label": 0
                },
                {
                    "sent": "Things we can test for.",
                    "label": 0
                },
                {
                    "sent": "Does the puppy have a fever?",
                    "label": 0
                },
                {
                    "sent": "Does it have a rash?",
                    "label": 0
                },
                {
                    "sent": "Does a coughing and so on.",
                    "label": 0
                },
                {
                    "sent": "Does it blood have various proteins?",
                    "label": 0
                },
                {
                    "sent": "And we imagine that these tests that we can run and.",
                    "label": 0
                },
                {
                    "sent": "We have some sort of prior over the diseases and also this.",
                    "label": 0
                },
                {
                    "sent": "Likelihood over the outcome of the tests or the symptoms displayed.",
                    "label": 0
                },
                {
                    "sent": "Conditioned on the disease.",
                    "label": 0
                },
                {
                    "sent": "So we have this probabilistic model about how diseases create symptoms or testable outcomes.",
                    "label": 0
                },
                {
                    "sent": "So in the simplest case.",
                    "label": 0
                },
                {
                    "sent": "Sort of, the outcome of a test is deterministic function of what the disease is.",
                    "label": 1
                },
                {
                    "sent": "This is the noise free case.",
                    "label": 0
                },
                {
                    "sent": "So just for now, let's consider that one.",
                    "label": 0
                },
                {
                    "sent": "And in this case, sort of each test based on the outcome will eliminate certain hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Certain diseases just get ruled out after you see the outcome of some test.",
                    "label": 0
                },
                {
                    "sent": "So for example, you might run some tests and based on the outcome you cut away some things.",
                    "label": 0
                },
                {
                    "sent": "Now we have this question well.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now we have this question of how we should select these tests, kind of adaptively to eliminate all of the incorrect hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And a classic objective here is sort of wait these diseases by their prior probability mass and try to rule out as much mass as possible as quickly as possible.",
                    "label": 0
                },
                {
                    "sent": "So we can define this.",
                    "label": 0
                },
                {
                    "sent": "Kind of conditional expected marginal benefit of running some test T. Based on the expected probability mass, we rule out sort of conditioned on what we've already seen.",
                    "label": 0
                },
                {
                    "sent": "And then once we have this quantity, we can sort of greedily pick the test that maximizes it in each step.",
                    "label": 1
                },
                {
                    "sent": "The result of this is called generalized binary search.",
                    "label": 0
                },
                {
                    "sent": "It's kind of a classic algorithm.",
                    "label": 0
                },
                {
                    "sent": "It also turns out to be equivalent to another classic algorithm, which is discretely maximizing the information gain in this noise free case.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it turns out that these algorithms actually do pretty well.",
                    "label": 0
                },
                {
                    "sent": "This algorithm does very well in this noise free case, and the reason is in some sense is because the subjective probability mass of hypothesis you've ruled out is adaptive submodular.",
                    "label": 1
                },
                {
                    "sent": "Let me very briefly go over.",
                    "label": 0
                },
                {
                    "sent": "You know why that is or how you would go about proving it.",
                    "label": 0
                },
                {
                    "sent": "Well, imagine we're in this situation here.",
                    "label": 0
                },
                {
                    "sent": "We have these tests.",
                    "label": 0
                },
                {
                    "sent": "We have these diseases and we have some test X which based on the outcome will partition it.",
                    "label": 0
                },
                {
                    "sent": "In this case, in the two sets, because there are two outcomes, but in general it could be more than two outcomes.",
                    "label": 0
                },
                {
                    "sent": "We get this partition into, say, a blue set of diseases and a green one, and we can look at the initial sort of prior probability mass in the blue region in the green region, call it be not in G nought.",
                    "label": 0
                },
                {
                    "sent": "And then it's not too hard to show that the expected conditional marginal benefit of running this test at this point is this quantity.",
                    "label": 0
                },
                {
                    "sent": "But imagine now we don't run this test.",
                    "label": 0
                },
                {
                    "sent": "So what do we need to do to show it?",
                    "label": 0
                },
                {
                    "sent": "At this modularity, we need to show that if we sort of do some more tests and then perform this test that our expected marginal utility is not increasing, it goes down, but not up.",
                    "label": 0
                },
                {
                    "sent": "So suppose instead of running test X, we run some other tests on V&W and we eliminate some things and we consider running this test again.",
                    "label": 0
                },
                {
                    "sent": "So, similarly I can define sort of the remaining probability mass in the blue region and in the green region called B1 and G1 and I get the same quantity for the conditional expected marginal benefit.",
                    "label": 0
                },
                {
                    "sent": "And now all I need to show is that sort of Delta final is no more than Delta initial.",
                    "label": 0
                },
                {
                    "sent": "And what do I know about this?",
                    "label": 0
                },
                {
                    "sent": "Well, I know that sort of diseases get ruled out.",
                    "label": 0
                },
                {
                    "sent": "They never come back, so be not is at least be one.",
                    "label": 0
                },
                {
                    "sent": "Angie, not is.",
                    "label": 0
                },
                {
                    "sent": "At least the one.",
                    "label": 0
                },
                {
                    "sent": "And so it's really not that hard to show that under these constraints this quantity is less than sort of.",
                    "label": 0
                },
                {
                    "sent": "Delta final is less than Delta initial.",
                    "label": 1
                },
                {
                    "sent": "So it's adaptive so modular.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. And kind of the previous state of the art in terms of the analysis of the approximation ratio of this generalized binary search algorithm, which is just a special case of this adaptive greedy algorithm with this objective.",
                    "label": 0
                },
                {
                    "sent": "Was that it was a four long 1 / P man approximation where P man is the minimum prior probability of any hypothesis.",
                    "label": 0
                },
                {
                    "sent": "This is due to Dasgupta in 2004.",
                    "label": 0
                },
                {
                    "sent": "This problem has been studied quite a bit here more some of the some of the more important references on this problem.",
                    "label": 0
                },
                {
                    "sent": "So just as a corollary of this kind of more general theorem, we can reduce this to this approximation ratio.",
                    "label": 0
                },
                {
                    "sent": "OK, so everything I've told you about this problem is now assumed that these tests are exact.",
                    "label": 1
                },
                {
                    "sent": "There's no noise at all.",
                    "label": 0
                },
                {
                    "sent": "But that's not really a realistic assumption in most application.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what do you do if you have a noisy observations, right?",
                    "label": 0
                },
                {
                    "sent": "How do you do noisy Bayesian active learning?",
                    "label": 1
                },
                {
                    "sent": "And so, well, first is tests don't rule out hypothesis anymore, they just sort of make them less likely.",
                    "label": 1
                },
                {
                    "sent": "So now, given a hypothesis, I have a distributed posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Conditional distribution over test outcomes for any given test.",
                    "label": 0
                },
                {
                    "sent": "So even if I were to run all of the tests, I still have some uncertainty as to the underlying disease or underlying hypothesis.",
                    "label": 0
                },
                {
                    "sent": "OK so I can't.",
                    "label": 0
                },
                {
                    "sent": "My criterion before was to identify the true hypothesis with certainty and I don't.",
                    "label": 0
                },
                {
                    "sent": "I can't do that anymore.",
                    "label": 0
                },
                {
                    "sent": "So what should be the sort of natural criterion?",
                    "label": 0
                },
                {
                    "sent": "So one way to think about this is I'm going to I'm gathering this information about this patient to do something I want to treat the patient.",
                    "label": 0
                },
                {
                    "sent": "And so really what you care about is identifying what the optimal sort of treatment is, what the optimal intervention is for this patient.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we imagine that we ran every test imaginable.",
                    "label": 0
                },
                {
                    "sent": "We learned as much as we possibly could about this patient, and then we run some kind of optimization problem.",
                    "label": 0
                },
                {
                    "sent": "In order to figure out what the best treatment is.",
                    "label": 0
                },
                {
                    "sent": "So for example, you can define some utility function which takes an intervention or an act sort of treatment plan and disease and sort of tells you how good or bad it is.",
                    "label": 0
                },
                {
                    "sent": "An you can say maximize that an expectation or you can do some more sophisticated things, but the point is, given this posterior over diseases, you can define what the optimal treatment plan is will call a star.",
                    "label": 0
                },
                {
                    "sent": "And so sort of the goal of our.",
                    "label": 0
                },
                {
                    "sent": "Our information gathering is to figure out what this a star is.",
                    "label": 0
                },
                {
                    "sent": "What is the optimal way to treat this patient?",
                    "label": 0
                },
                {
                    "sent": "That's what I care about.",
                    "label": 0
                },
                {
                    "sent": "So we figure this out well.",
                    "label": 0
                },
                {
                    "sent": "We can try various previous approaches like generalized binary search or maximizing the information gain, maximizing the value of information which would be sort of the expected increase in utility.",
                    "label": 1
                },
                {
                    "sent": "But these things don't give you adaptive submodular objectives.",
                    "label": 1
                },
                {
                    "sent": "And in various kind of very simple noise models with slightly with some correlated noise, they require exponentially more tests than the optimum.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how should we deal with this well?",
                    "label": 0
                },
                {
                    "sent": "Our strategy is going to be reducing the noisy problem to a particular noise free problem, and the key idea is to make these test outcomes sort of the vector of all test outcomes, sort of part of the hypothesis.",
                    "label": 1
                },
                {
                    "sent": "So basically now I have sort of.",
                    "label": 0
                },
                {
                    "sent": "Diseases with noisy copies, 'cause the symptoms can be different for different people with the same disease, say and I'm going to label them with the observation vectors.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the outcome of all the tests.",
                    "label": 0
                },
                {
                    "sent": "And now, given all these observation vectors, I'm going to label them with a color which will correspond to what the best treatment plan is.",
                    "label": 0
                },
                {
                    "sent": "So some of these are green, orange, red or blue, and depending on the color that's going to dictate how I should be treating the patient.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now all I need to do is identify the color of the true outcome vector.",
                    "label": 0
                },
                {
                    "sent": "I don't need to determine what it is.",
                    "label": 1
                },
                {
                    "sent": "So I'm going to group these by color.",
                    "label": 0
                },
                {
                    "sent": "And I just need to figure out what the group is so.",
                    "label": 0
                },
                {
                    "sent": "To do so, I'm going to define a graph.",
                    "label": 0
                },
                {
                    "sent": "Where?",
                    "label": 0
                },
                {
                    "sent": "I have an edge between all pairs of nodes here that are in different groups.",
                    "label": 0
                },
                {
                    "sent": "'cause you know an edge means I have to distinguish between the two.",
                    "label": 1
                },
                {
                    "sent": "And these are weighted in a particular way.",
                    "label": 0
                },
                {
                    "sent": "The weight of this edge is just going to be the prior probability of this times the prior probability of that.",
                    "label": 0
                },
                {
                    "sent": "There's technical reasons why it has to be that way, but the idea is I really want to destroy these edges and the way I destroy them is to rule out one of the observation vectors incident on this edge.",
                    "label": 0
                },
                {
                    "sent": "And you can kind of see that.",
                    "label": 0
                },
                {
                    "sent": "If I get rid of all of the edges, that means that all of the remaining possible observation vectors that are consistent with what I've seen have to lie in the same group.",
                    "label": 0
                },
                {
                    "sent": "And this is sort of an if and only if statement if they all line one group, then all these edges must be gone.",
                    "label": 0
                },
                {
                    "sent": "If all the edges are gone, they must lie in one group.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we have tests like this and then we run the first Test and we observe the outcome of the first Test is a one, well, this disease goes away because its first coordinate of 0.",
                    "label": 0
                },
                {
                    "sent": "This one goes away because its first coordinate is a 0.",
                    "label": 0
                },
                {
                    "sent": "OK, all the edges incident on them get deleted and we've thrown out a whole bunch of edges.",
                    "label": 0
                },
                {
                    "sent": "In kind of.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The criterion we care about is the kind of expected weight of the edges we throw out.",
                    "label": 0
                },
                {
                    "sent": "You just sort of greedily optimize this.",
                    "label": 0
                },
                {
                    "sent": "Then we get this thing called that we call the edge cutting equivalence class edge cutting algorithm.",
                    "label": 0
                },
                {
                    "sent": "And it has this nice theoretical guarantee that says that the cost of this policy is within a tool on 1 / P min plus one approx.",
                    "label": 0
                },
                {
                    "sent": "Approximation of the optimal cost of the optimal policy, where payment is now the minimum prior probability of any kind of observation outcome vector.",
                    "label": 0
                },
                {
                    "sent": "OK, and note that if you're you know, this optimal policy could be quite could be quite large.",
                    "label": 0
                },
                {
                    "sent": "Right, if you wrote it out as a decision tree could be exponentially large.",
                    "label": 0
                },
                {
                    "sent": "But we still get this nice approximation factor.",
                    "label": 0
                },
                {
                    "sent": "It turns out that.",
                    "label": 0
                },
                {
                    "sent": "To the best of my knowledge, this is the very first approximation guarantee for Bayesian active learning with noise.",
                    "label": 1
                },
                {
                    "sent": "For sort of any noise model.",
                    "label": 0
                },
                {
                    "sent": "And this one gives sort of parameterized guarantees for arbitrary noise models.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we should try to use this on a particular task.",
                    "label": 0
                },
                {
                    "sent": "Basically there are various economic theories about how people assess risk and how they sort of value risk.",
                    "label": 0
                },
                {
                    "sent": "And it would be nice to sort of tease apart which one actually which one or ones explain human behavior.",
                    "label": 0
                },
                {
                    "sent": "So here are some examples.",
                    "label": 0
                },
                {
                    "sent": "Right maximize it, you might choose risks that maximize expected utility or prefer.",
                    "label": 1
                },
                {
                    "sent": "Of risks where you have higher expected utility, maybe you care about reducing variance.",
                    "label": 0
                },
                {
                    "sent": "There are various criteria that economists have come up with and we'd like to see, sort of which theory is true.",
                    "label": 0
                },
                {
                    "sent": "So how can we design tests to do this?",
                    "label": 1
                },
                {
                    "sent": "Kind of a natural thing to do.",
                    "label": 0
                },
                {
                    "sent": "Is to set people down and give him a choice of two lotteries, so it's a lottery.",
                    "label": 0
                },
                {
                    "sent": "Well in this community may be the best way to explain a lottery system random variable where the outcomes are dollar values.",
                    "label": 0
                },
                {
                    "sent": "So here maybe 30% of the time I take $10 from you and 70% of the time I give you $10.",
                    "label": 0
                },
                {
                    "sent": "So I give you two of these and I just ask well which do you like better?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can think of this as a Bayesian experimental design question.",
                    "label": 0
                },
                {
                    "sent": "Where I have these theories?",
                    "label": 0
                },
                {
                    "sent": "With some parameters I can parameterise them say by Theta and now a test is two of these lotteries.",
                    "label": 0
                },
                {
                    "sent": "Of course there are lots of choices of lotteries.",
                    "label": 0
                },
                {
                    "sent": "And sort of.",
                    "label": 0
                },
                {
                    "sent": "We will introduce some.",
                    "label": 0
                },
                {
                    "sent": "We introduced some error into this or some noise into this process by basically saying that we've given a particular theory.",
                    "label": 0
                },
                {
                    "sent": "We can evaluate the utility of a particular lottery with respect to that theory.",
                    "label": 0
                },
                {
                    "sent": "Basically, when we're comparing, the two will say essentially that the closer the utilities are, the more likely sort of the algorithm generating these responses is likely to make an error in some sort of logistic was away.",
                    "label": 0
                },
                {
                    "sent": "So it's a lot of these are really close, so we're simulating some agent playing trying to optimize its utility with respect to some theory and sort of.",
                    "label": 0
                },
                {
                    "sent": "The closer the two utilities are there more likely this agent is to make a mistake.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this case you know we have access to the ground truth because we're generating it, and so we can test our algorithm against various competitors.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of curious, but a lot of the standard ones like generalized binary search or maximizing value information greedily, or this uncertainty sampling.",
                    "label": 0
                },
                {
                    "sent": "Actually they did perform terribly in this case, they're significantly worse than random, and this was initially a bit of a puzzle to us, but sort of figured out that things like uncertainty sampling.",
                    "label": 0
                },
                {
                    "sent": "They're kind of learning the noise.",
                    "label": 0
                },
                {
                    "sent": "Kind of, Interestingly, information gain does much better.",
                    "label": 0
                },
                {
                    "sent": "But our algorithm significantly outperforms it.",
                    "label": 1
                },
                {
                    "sent": "And this is a significant increase in accuracy, given that sort of at the very top of this graph is 100%.",
                    "label": 0
                },
                {
                    "sent": "Performance so.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also kind of got some some human subjects, sort of 11 undergraduates and ran this setup with them.",
                    "label": 0
                },
                {
                    "sent": "Just try to see which economic theory best explained their sort of preferences or their choices.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "It turned out that most of them were following this expected value.",
                    "label": 0
                },
                {
                    "sent": "Theory or were best explained.",
                    "label": 0
                },
                {
                    "sent": "Their behavior was best explained by this theory that says you just maximize expected value in your lotteries.",
                    "label": 0
                },
                {
                    "sent": "But there was heterogeneity in the population, so there were.",
                    "label": 1
                },
                {
                    "sent": "Sort of two that were explained by prospect theory and one each that were explained by these other theories.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "You know the tests were really quite fast and it was nice to be able to do these sort of user the subject tests.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, I've shown you this sort of fundamental new framework for design analysis of greedy near optimal algorithms for these adaptive optimization problems.",
                    "label": 1
                },
                {
                    "sent": "And it sort of generalizes and recovers many known.",
                    "label": 1
                },
                {
                    "sent": "Guarantees for various applications in a fairly unified manner.",
                    "label": 0
                },
                {
                    "sent": "There are lots of extensions here that I didn't have time to go into.",
                    "label": 0
                },
                {
                    "sent": "For example, if you can only approximately evaluate these conditional expected marginal benefits, or you can only evaluate them noisily.",
                    "label": 0
                },
                {
                    "sent": "Are there other sort of benefits in terms of speeding it up with lazy evaluations and so on?",
                    "label": 0
                },
                {
                    "sent": "But sort of this is the high level idea.",
                    "label": 0
                },
                {
                    "sent": "I invite you to take a look at the paper.",
                    "label": 0
                },
                {
                    "sent": "And thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Complicated constraints.",
                    "label": 0
                },
                {
                    "sent": "Some of the other.",
                    "label": 0
                },
                {
                    "sent": "Right, so we've been working on that, and actually so I can say that they do.",
                    "label": 0
                },
                {
                    "sent": "These results do extend into the matroid constraint case.",
                    "label": 0
                },
                {
                    "sent": "So the question is.",
                    "label": 0
                },
                {
                    "sent": "If you want to maximize one of these functions, but instead of picking K things, you get to pick some independent set in a matroid.",
                    "label": 0
                },
                {
                    "sent": "How well can you do?",
                    "label": 0
                },
                {
                    "sent": "And it turns out that you can get the same kind of guarantees as the greedy algorithm achieves in the Nonadaptive case.",
                    "label": 0
                },
                {
                    "sent": "So for a matroid constraint you'll get half approximation.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's think again.",
                    "label": 0
                }
            ]
        }
    }
}