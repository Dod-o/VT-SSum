{
    "id": "apxgn47y2ntdhwgmmpzkutjvlduidmnk",
    "title": "Sparklify: A Scalable Software Component for Efficient evaluation of SPARQL queries over distributed RDF datasets",
    "info": {
        "author": [
            "Claus Stadler, Agile Knowledge Engineering and Semantic Web (AKSW), University of Leipzig"
        ],
        "published": "Nov. 27, 2019",
        "recorded": "October 2019",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2019_stadler_scalable_software_component/",
    "segmentation": [
        [
            "Thank you, Carla.",
            "Sorry introduction so."
        ],
        [
            "Yes, I so I'm coming from Spotify.",
            "This is a short overview.",
            "I will quickly go into the motivation of our work.",
            "Then I will give a brief introduction about three of the components which are involved in hours in our resource.",
            "Then we present the approach how we accomplish it and in the end we show some evaluation well.",
            "And of course conclusions Utrecht, so the motivation is that when you want to build a sparkle query engine, there is lots of components out there which you can use to build it.",
            "For instance, some of the components like semantic query optimization by property tables what's presented here column stores, dictionary encoding and so on and so on.",
            "There was many little pieces and current research on going on.",
            "Many of those pieces to make them shinier and better than before."
        ],
        [
            "But what we tried to do is to what happens if instead of like building in little pieces.",
            "If you take an existing engine."
        ],
        [
            "An OBD engine and applied to a purchase park so don't get the wrong impression.",
            "We did not integrate all the pieces into one engine.",
            "We take an existing engine is different so.",
            "This basic system, which which we're going to build orbit rebuild, so you give it as a sparkle query and then it translate it to queries over patches park.",
            "So let's give a quick."
        ],
        [
            "Into yeah and motivation is like can we reuse existing obj tooling running spark queries on the part of spark and what is there in regard to performance and scalability?"
        ],
        [
            "So let's come into action, so maybe most."
        ],
        [
            "You probably know a purchase part, but in case you don't know it, just give a brief summary so it's fast and generic purpose cluster computing engine build over Apache Hadoop.",
            "Test and it allows for massive parallel computation of collections records.",
            "So the image.",
            "Basically it's supposed to depict collection of items and you want to have different servers that make up your cluster and what you want to have is basically at each of these nodes in your cluster is working on this collection with 100% of its resources.",
            "There is 3 main components for this remain entities for in a purchase bark for storing this data.",
            "So there's like the RDD, the resilient distributed data set.",
            "That's in essence the collection of serializable objects.",
            "Then there is the data frame that's for us of interest, because this is conceptually a table and then build on top of it.",
            "There's also the data set, which is basically kind of best of both worlds, so you can have object and table view.",
            "Of the records and there is also optimizations in spark that when you write code on the datasets that it will like look at what attributes are you actually referring to and optimize the processing accordingly."
        ],
        [
            "So for this park, if I Spotify, is this parking SQL rewrite which created some years ago, it's it's supports mapping expressed in the WCC standards, out OML, and also in our own specification mapping language, which would publish at L .115 and the main motivation when we developed this was willing to date a project where we served Openstreetmap data as RDF.",
            "And we used.",
            "It also tends to create a dump of 30 billion triples back then yes, drain for three or four weeks.",
            "So it took quite long.",
            "But The thing is that the system was stable enough to like stay.",
            "Stay online for that time.",
            "And yes, this pocket 5 is cool, so that's the core engine and now the combination of our resource we are presenting is now sparkly.",
            "5 is Q on spark with K and that's like a sparkly fighters that I'm behind it."
        ],
        [
            "Then our resources basically integrated into the bigger context with the Census tech.",
            "This basically our open source, big data and semantic Web framework, developed several posters referring to this framework.",
            "Basically, it's a bit of our incubator test pad for all kinds of the research tools or that like not all the things we do reside in different repositories, but we have like 1 one project contributor.",
            "So it has layers for RDF carrying our inference machine learning our resource goes into the is in the querying layer.",
            "It supports bar conflict.",
            "There is 6 releases so far and we have a six month release cycle and there are certain contributors and I've seen there were several presentations as it's referencing sounds like here.",
            "So let's come to the approach.",
            "So this is like a highlight."
        ],
        [
            "Overview of our system.",
            "So it starts with that you want to run as part of query on top of RDF data.",
            "What we do is basically create our DDS.",
            "In Spark which get them partitions and then for each of the partitions we're applying views which are fed to the Fed to the query writing system and then you can run the query on top of these views and which are then processed plus parking parallel and then you get the results out.",
            "This is like a mapping of the example of how bottom you looks like, but I will come to that in a moment again.",
            "Yes, and voter this parking area.",
            "What happens basically that it gets they have to translate this pocket query into an algebra expression tree.",
            "We normalize it and we apply the views to it.",
            "So."
        ],
        [
            "It will be out doing basically is applying vertical partitioning.",
            "So I just give an example of what this looks like.",
            "So here we have three triples, for instance with X observation it has a value and it hasn't label an in order to ingest the data into a purchase park."
        ],
        [
            "We are creating these partitions where vertical teaching pays a means.",
            "Basically that for each predicate you create a table or as I said, at data frame is conceptually table, but we're also doing is that we're being IDF term of there, so we retain the data types.",
            "So for instance, when for the first triple with where we have two our eyes, we note that the subject type is an IRRI, and option Captain IRRI.",
            "And then we just put the strings into the into the actual table of spark.",
            "And this can."
        ],
        [
            "Daniels with preferences values.",
            "So here we actually stored at the value stored in the data frame is a decimal."
        ],
        [
            "The last thing we have a long string.",
            "That means that in this case.",
            "The partition actually has has has 2 columns in order to capture the literal value and language tag of it."
        ],
        [
            "So and then, once we have these partitions then we are creating these views on top of its right hand so you can read it from bottom to top.",
            "So this is like the dataframe name here and the right hand side of the expressions refer to column names with the left hand side are the variables of the RDF triple that is virtually created.",
            "So if you take each row and pipe it through this process, you get the original data set out to cancel it.",
            "For instance, here we have like your ex as an observation.",
            "Both of these strings become our eyes, and so we have a triple based X and observation X is an observation which is basically what we had in the input data."
        ],
        [
            "Then for decimals, it's basically the same."
        ],
        [
            "Yeah, just notice anyway.",
            "And for language strings basically it's also that we can just exploit the string line function tools to express the mapping that we want to create language.",
            "Literal this language tag from the partition.",
            "And based on the partition meta data so that these views which are presented here, they're basically just based on the partition with the data.",
            "So there's like separation between creating the RDP to DF mappings or the ODB obj mappings and the partition management in our system.",
            "So and then we want to query it and it's actually quite simple."
        ],
        [
            "Because you just have to take an obj cyst.",
            "In our cases sparkly fire.",
            "Feed it the mappings.",
            "All these views together with the data frames in our case and then you can give it as bucket query and it will like evaluate it in this context and return the results.",
            "So for evaluation, the research question was how does our approach to scale today?"
        ],
        [
            "Print data sets of different sizes."
        ],
        [
            "How does the runtime change when we add more worker nodes and what is the effect on the runtime for different kinds of queries?",
            "So we use two benchmarks to evaluate that.",
            "One is the Lehigh University benchmark gloom.",
            "This generates synthetic data in according to a University ontologies or that means entities are students, Sheriff's Department and courses, and we scale the data set size from 138 million triples, two 1.4 billion triples.",
            "The other data set we use population is the Waterloo Sparkle Diversity Test suite, so it has different it's query types.",
            "I will show that any moment, but the domain are powerful.",
            "This data is basically commercial.",
            "This product purchases in countries.",
            "Our spark cluster has seven nodes, one master, 6 worker.",
            "Each with 32 cores.",
            "128 gigabyte of Ram connected backing up its network and experiments were all compute executed 3 times and the results are averaged."
        ],
        [
            "So one question we had was what system should be compared to and so Spotify does not perform any data and this is summarization of pre processing.",
            "Besides the vertical positioning so assistant which seemed to be or system which is similar in a way is sparking three XSD which translates Parkers Tool Spark API calls.",
            "So what basically the comparison we are now doing is basically comparing the declaratives approach of generating SQL queries to the imperative approach.",
            "Those pocket cruiser translated to API calls.",
            "And so this is now the.",
            "After death."
        ],
        [
            "Nation results So what we get out for the diversity test with we see that for this for data set size of 10,000,000 triples, sparkly checks Ste.",
            "So the green veins win wins.",
            "So here in these cases.",
            "Total runtime was was faster than the total runtime of Sparky fire, so it's part of IPF to DFF measured values for how long it took the quotation and how long it took to query.",
            "If Waterloo Test Street, it also has like 4 query classes, star pattern queries, linear queries, snowflake trees, complex pattern.",
            "If not familiar that, then you can read it up.",
            "So then the time will shortlisting anyway.",
            "What's the point is that you have a small data set size.",
            "We did not win the contest, but when we also as large data set, then we actually involved case that system ran out of MEM."
        ],
        [
            "And in the other cases, our times were better.",
            "On one 1 billion triples, and in order to compute."
        ],
        [
            "The overview on the loop data set.",
            "The results were quite mixed, so in some cases so it was wrote on six and six time it was sparking.",
            "Five was faster in seven times.",
            "Sparky cheeks SD balls faster and there's 111 case where both of them ran out of memory.",
            "This is now for the for the 1 billion triples.",
            "Later that on loom, so there's a lot of values, and so on.",
            "And this basically now the total sound, the total runtime, so it's all the individual values, because total runtimes.",
            "Also, it's always difficult because it won't ask tech."
        ],
        [
            "Very long then of course it says use a bit of you.",
            "So, but this is now the over the socket she got.",
            "So here you can see that in the for the small data, so that data set size of 10 million, 100 million and one billion and.",
            "Yeah, and for the small data set size, yeah here we lost whereas for smaller smaller is better.",
            "And for the last 30 bond for the medium data set, we've also slightly faster.",
            "This is now."
        ],
        [
            "What happens when we run the?",
            "Run the experiment with also one of the experiments that wanted 100 now with different number of worker nodes and there we see that are sparkly fiery names nearly the same across the face.",
            "With this 1366 workers, whereas post parking cheeks as the there is like a great improvement and more work with you at.",
            "And this is now the pier query type, so we had to stop it and."
        ],
        [
            "In your pattern snowflake and complex pattern results.",
            "So what we can see is that.",
            "Yeah, so that's four.",
            "For the complex pattern and snowflake paper pattern, Spotify is faster also for the star pattern.",
            "But Interestingly, for the linear pattern, yeah, we will lose in this scenario.",
            "Yeah, so we then basically have some use cases where we actually applied this part."
        ],
        [
            "System so it just sickens an impression one is for querying Ethereum blockchain data.",
            "This is in collaboration with company Alessio.",
            "We have basically 100 of 18 billion triples where yeah data set size 18 billion triples and then basically we have two projects.",
            "Special Project heads up out.",
            "Now about transparency and compliance use case for beta.",
            "Gets about analyzing lock information concerning personal data and the other approaches about points of interest information.",
            "So yeah, so the conclusion of our work is that so that you can apply opdal tooling."
        ],
        [
            "On big Data frameworks that it's significantly reduce the amount to build 1, so 'cause you get you can leverage existing technology basically for that.",
            "For one example, which we had is that we got we got RDF type handling working out of the box so we didn't have to like say it's a result of which only supports strings.",
            "Now we can do integers and all the data types."
        ],
        [
            "Verizon Strings as well.",
            "It has promising results in respect of scalability, so the reason that we think that most OK. Second, OK, yeah.",
            "Anyway the future work is that we want to compare is on top.",
            "That's ongoing work.",
            "And if you want to investigate dictionary encoding, thank you very much.",
            "Thanks a lot for the interesting talk.",
            "I have actually 2 questions so one you mentioned the RDF use, but in the query processing I didn't really get where you use.",
            "Actually these are diffuse because you actually convert sparkwell to SQL anyways, so.",
            "Where does this wheels comes in come into play and the second one is whether actually you enabled Spark, SQL spawned query optimizer because if it is so, I'm not sure whether we can attribute these performance to your framework or to spark SQL squared optimizer already.",
            "Yeah, I wanted to say including that we attribute it actually is part SQL optimizer because we're doing a decorative approach, so we're just generating a SQL query and then it's up to spark to the query optimization for that.",
            "If it runs the second question for the first query.",
            "What you're doing is we're loading the RDF data into a spark RDD and the partitioning is then creating the data frames out of the RDF data from an initial RDD.",
            "So that means we have to partitions which are the data frames and.",
            "So in the partitioning process we are creating the data frames plus the meter data and from this on these spaces we're also generating the RDP to defuse.",
            "OK, thanks a lot.",
            "Any other question?",
            "Any other question?",
            "And so I wanted to ask how?",
            "What a life lifetime of the partitions that you create?",
            "Because you compare your total running time with the total runtime of the other approach.",
            "But you're running time includes quizlet partitions, which I imagine can be used for more than a query.",
            "Can you repeat?",
            "Sorry so I was wondering so your partitions can be used for more than a query.",
            "So right now it's just vertical partitioning.",
            "That means we are using for each predicate.",
            "We're creating a partition, so that's what the limiting factor is.",
            "Basically that as soon as you want to try to predicates, then you need like to need to try and two partitions, though there is ongoing work also presented by other groups here where it's about like creating partitions that capture not only a single triple, but Michael triples involved.",
            "So basically for partition, which is a table, but we think that our approach deals could transfer to it 'cause we're having these RDF use or.",
            "Basically you want to have a record in the partition, and this corresponds to the set of triples and.",
            "Yeah, and conceptually basically The thing is that you can have you and an idea on the partition.",
            "It creates multiple triples.",
            "Any other question?",
            "And I do have a question so.",
            "A.",
            "From what from what?",
            "I understood, the data in this park is distributed across across the nodes, right?",
            "It's done, distributed across.",
            "Then all the nodes?",
            "Yes disappeared, yes.",
            "So are there?",
            "This is distributed equally evenly in across the nodes.",
            "Are there some pretty case that are more distributed in a certain nodes?",
            "And if this is the case, to the performance that, for instance, that we've type is just in one on one node instead of the others?",
            "That's a very good question, so we didn't evaluate where the partitions ended up on which on the worker nodes, so that we have to investigate.",
            "But I would say that it's so like because for the for the different predicates, the number of instances of the extension of the predicate various usually creately.",
            "So I will say that.",
            "Yeah, that's we valuated, so I would think that it's not really even distributed, so it depends on the hash key.",
            "Basically where the data ends up.",
            "Thank you all so you see that there are seven nodes running with how many cores it knows, 32 cores each of them.",
            "OK, yeah, no.",
            "I was wondering what is the usual setup for Spark cluster in terms of nodes?",
            "If you know of I don't know actually about, so I can just say, well, using we're using like like this kind of and those other people are using notes with three, but there's also the nucleus Google Papers, so they said like I don't know, a few thousand machines or something.",
            "OK, OK, thank you very much.",
            "Thank you very much, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you, Carla.",
                    "label": 0
                },
                {
                    "sent": "Sorry introduction so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, I so I'm coming from Spotify.",
                    "label": 0
                },
                {
                    "sent": "This is a short overview.",
                    "label": 0
                },
                {
                    "sent": "I will quickly go into the motivation of our work.",
                    "label": 0
                },
                {
                    "sent": "Then I will give a brief introduction about three of the components which are involved in hours in our resource.",
                    "label": 0
                },
                {
                    "sent": "Then we present the approach how we accomplish it and in the end we show some evaluation well.",
                    "label": 0
                },
                {
                    "sent": "And of course conclusions Utrecht, so the motivation is that when you want to build a sparkle query engine, there is lots of components out there which you can use to build it.",
                    "label": 0
                },
                {
                    "sent": "For instance, some of the components like semantic query optimization by property tables what's presented here column stores, dictionary encoding and so on and so on.",
                    "label": 0
                },
                {
                    "sent": "There was many little pieces and current research on going on.",
                    "label": 0
                },
                {
                    "sent": "Many of those pieces to make them shinier and better than before.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But what we tried to do is to what happens if instead of like building in little pieces.",
                    "label": 0
                },
                {
                    "sent": "If you take an existing engine.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An OBD engine and applied to a purchase park so don't get the wrong impression.",
                    "label": 0
                },
                {
                    "sent": "We did not integrate all the pieces into one engine.",
                    "label": 0
                },
                {
                    "sent": "We take an existing engine is different so.",
                    "label": 0
                },
                {
                    "sent": "This basic system, which which we're going to build orbit rebuild, so you give it as a sparkle query and then it translate it to queries over patches park.",
                    "label": 0
                },
                {
                    "sent": "So let's give a quick.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Into yeah and motivation is like can we reuse existing obj tooling running spark queries on the part of spark and what is there in regard to performance and scalability?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's come into action, so maybe most.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You probably know a purchase part, but in case you don't know it, just give a brief summary so it's fast and generic purpose cluster computing engine build over Apache Hadoop.",
                    "label": 1
                },
                {
                    "sent": "Test and it allows for massive parallel computation of collections records.",
                    "label": 1
                },
                {
                    "sent": "So the image.",
                    "label": 0
                },
                {
                    "sent": "Basically it's supposed to depict collection of items and you want to have different servers that make up your cluster and what you want to have is basically at each of these nodes in your cluster is working on this collection with 100% of its resources.",
                    "label": 1
                },
                {
                    "sent": "There is 3 main components for this remain entities for in a purchase bark for storing this data.",
                    "label": 0
                },
                {
                    "sent": "So there's like the RDD, the resilient distributed data set.",
                    "label": 1
                },
                {
                    "sent": "That's in essence the collection of serializable objects.",
                    "label": 1
                },
                {
                    "sent": "Then there is the data frame that's for us of interest, because this is conceptually a table and then build on top of it.",
                    "label": 0
                },
                {
                    "sent": "There's also the data set, which is basically kind of best of both worlds, so you can have object and table view.",
                    "label": 0
                },
                {
                    "sent": "Of the records and there is also optimizations in spark that when you write code on the datasets that it will like look at what attributes are you actually referring to and optimize the processing accordingly.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for this park, if I Spotify, is this parking SQL rewrite which created some years ago, it's it's supports mapping expressed in the WCC standards, out OML, and also in our own specification mapping language, which would publish at L .115 and the main motivation when we developed this was willing to date a project where we served Openstreetmap data as RDF.",
                    "label": 1
                },
                {
                    "sent": "And we used.",
                    "label": 0
                },
                {
                    "sent": "It also tends to create a dump of 30 billion triples back then yes, drain for three or four weeks.",
                    "label": 1
                },
                {
                    "sent": "So it took quite long.",
                    "label": 0
                },
                {
                    "sent": "But The thing is that the system was stable enough to like stay.",
                    "label": 0
                },
                {
                    "sent": "Stay online for that time.",
                    "label": 0
                },
                {
                    "sent": "And yes, this pocket 5 is cool, so that's the core engine and now the combination of our resource we are presenting is now sparkly.",
                    "label": 0
                },
                {
                    "sent": "5 is Q on spark with K and that's like a sparkly fighters that I'm behind it.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then our resources basically integrated into the bigger context with the Census tech.",
                    "label": 0
                },
                {
                    "sent": "This basically our open source, big data and semantic Web framework, developed several posters referring to this framework.",
                    "label": 1
                },
                {
                    "sent": "Basically, it's a bit of our incubator test pad for all kinds of the research tools or that like not all the things we do reside in different repositories, but we have like 1 one project contributor.",
                    "label": 0
                },
                {
                    "sent": "So it has layers for RDF carrying our inference machine learning our resource goes into the is in the querying layer.",
                    "label": 0
                },
                {
                    "sent": "It supports bar conflict.",
                    "label": 0
                },
                {
                    "sent": "There is 6 releases so far and we have a six month release cycle and there are certain contributors and I've seen there were several presentations as it's referencing sounds like here.",
                    "label": 0
                },
                {
                    "sent": "So let's come to the approach.",
                    "label": 0
                },
                {
                    "sent": "So this is like a highlight.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Overview of our system.",
                    "label": 0
                },
                {
                    "sent": "So it starts with that you want to run as part of query on top of RDF data.",
                    "label": 0
                },
                {
                    "sent": "What we do is basically create our DDS.",
                    "label": 0
                },
                {
                    "sent": "In Spark which get them partitions and then for each of the partitions we're applying views which are fed to the Fed to the query writing system and then you can run the query on top of these views and which are then processed plus parking parallel and then you get the results out.",
                    "label": 0
                },
                {
                    "sent": "This is like a mapping of the example of how bottom you looks like, but I will come to that in a moment again.",
                    "label": 0
                },
                {
                    "sent": "Yes, and voter this parking area.",
                    "label": 0
                },
                {
                    "sent": "What happens basically that it gets they have to translate this pocket query into an algebra expression tree.",
                    "label": 0
                },
                {
                    "sent": "We normalize it and we apply the views to it.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It will be out doing basically is applying vertical partitioning.",
                    "label": 1
                },
                {
                    "sent": "So I just give an example of what this looks like.",
                    "label": 0
                },
                {
                    "sent": "So here we have three triples, for instance with X observation it has a value and it hasn't label an in order to ingest the data into a purchase park.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are creating these partitions where vertical teaching pays a means.",
                    "label": 0
                },
                {
                    "sent": "Basically that for each predicate you create a table or as I said, at data frame is conceptually table, but we're also doing is that we're being IDF term of there, so we retain the data types.",
                    "label": 0
                },
                {
                    "sent": "So for instance, when for the first triple with where we have two our eyes, we note that the subject type is an IRRI, and option Captain IRRI.",
                    "label": 0
                },
                {
                    "sent": "And then we just put the strings into the into the actual table of spark.",
                    "label": 0
                },
                {
                    "sent": "And this can.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Daniels with preferences values.",
                    "label": 0
                },
                {
                    "sent": "So here we actually stored at the value stored in the data frame is a decimal.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The last thing we have a long string.",
                    "label": 0
                },
                {
                    "sent": "That means that in this case.",
                    "label": 0
                },
                {
                    "sent": "The partition actually has has has 2 columns in order to capture the literal value and language tag of it.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and then, once we have these partitions then we are creating these views on top of its right hand so you can read it from bottom to top.",
                    "label": 0
                },
                {
                    "sent": "So this is like the dataframe name here and the right hand side of the expressions refer to column names with the left hand side are the variables of the RDF triple that is virtually created.",
                    "label": 0
                },
                {
                    "sent": "So if you take each row and pipe it through this process, you get the original data set out to cancel it.",
                    "label": 0
                },
                {
                    "sent": "For instance, here we have like your ex as an observation.",
                    "label": 0
                },
                {
                    "sent": "Both of these strings become our eyes, and so we have a triple based X and observation X is an observation which is basically what we had in the input data.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then for decimals, it's basically the same.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, just notice anyway.",
                    "label": 0
                },
                {
                    "sent": "And for language strings basically it's also that we can just exploit the string line function tools to express the mapping that we want to create language.",
                    "label": 0
                },
                {
                    "sent": "Literal this language tag from the partition.",
                    "label": 0
                },
                {
                    "sent": "And based on the partition meta data so that these views which are presented here, they're basically just based on the partition with the data.",
                    "label": 0
                },
                {
                    "sent": "So there's like separation between creating the RDP to DF mappings or the ODB obj mappings and the partition management in our system.",
                    "label": 0
                },
                {
                    "sent": "So and then we want to query it and it's actually quite simple.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because you just have to take an obj cyst.",
                    "label": 0
                },
                {
                    "sent": "In our cases sparkly fire.",
                    "label": 0
                },
                {
                    "sent": "Feed it the mappings.",
                    "label": 0
                },
                {
                    "sent": "All these views together with the data frames in our case and then you can give it as bucket query and it will like evaluate it in this context and return the results.",
                    "label": 0
                },
                {
                    "sent": "So for evaluation, the research question was how does our approach to scale today?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Print data sets of different sizes.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How does the runtime change when we add more worker nodes and what is the effect on the runtime for different kinds of queries?",
                    "label": 1
                },
                {
                    "sent": "So we use two benchmarks to evaluate that.",
                    "label": 1
                },
                {
                    "sent": "One is the Lehigh University benchmark gloom.",
                    "label": 0
                },
                {
                    "sent": "This generates synthetic data in according to a University ontologies or that means entities are students, Sheriff's Department and courses, and we scale the data set size from 138 million triples, two 1.4 billion triples.",
                    "label": 0
                },
                {
                    "sent": "The other data set we use population is the Waterloo Sparkle Diversity Test suite, so it has different it's query types.",
                    "label": 0
                },
                {
                    "sent": "I will show that any moment, but the domain are powerful.",
                    "label": 0
                },
                {
                    "sent": "This data is basically commercial.",
                    "label": 0
                },
                {
                    "sent": "This product purchases in countries.",
                    "label": 0
                },
                {
                    "sent": "Our spark cluster has seven nodes, one master, 6 worker.",
                    "label": 0
                },
                {
                    "sent": "Each with 32 cores.",
                    "label": 0
                },
                {
                    "sent": "128 gigabyte of Ram connected backing up its network and experiments were all compute executed 3 times and the results are averaged.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one question we had was what system should be compared to and so Spotify does not perform any data and this is summarization of pre processing.",
                    "label": 0
                },
                {
                    "sent": "Besides the vertical positioning so assistant which seemed to be or system which is similar in a way is sparking three XSD which translates Parkers Tool Spark API calls.",
                    "label": 1
                },
                {
                    "sent": "So what basically the comparison we are now doing is basically comparing the declaratives approach of generating SQL queries to the imperative approach.",
                    "label": 0
                },
                {
                    "sent": "Those pocket cruiser translated to API calls.",
                    "label": 0
                },
                {
                    "sent": "And so this is now the.",
                    "label": 0
                },
                {
                    "sent": "After death.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nation results So what we get out for the diversity test with we see that for this for data set size of 10,000,000 triples, sparkly checks Ste.",
                    "label": 0
                },
                {
                    "sent": "So the green veins win wins.",
                    "label": 0
                },
                {
                    "sent": "So here in these cases.",
                    "label": 0
                },
                {
                    "sent": "Total runtime was was faster than the total runtime of Sparky fire, so it's part of IPF to DFF measured values for how long it took the quotation and how long it took to query.",
                    "label": 0
                },
                {
                    "sent": "If Waterloo Test Street, it also has like 4 query classes, star pattern queries, linear queries, snowflake trees, complex pattern.",
                    "label": 1
                },
                {
                    "sent": "If not familiar that, then you can read it up.",
                    "label": 0
                },
                {
                    "sent": "So then the time will shortlisting anyway.",
                    "label": 0
                },
                {
                    "sent": "What's the point is that you have a small data set size.",
                    "label": 0
                },
                {
                    "sent": "We did not win the contest, but when we also as large data set, then we actually involved case that system ran out of MEM.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in the other cases, our times were better.",
                    "label": 0
                },
                {
                    "sent": "On one 1 billion triples, and in order to compute.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The overview on the loop data set.",
                    "label": 0
                },
                {
                    "sent": "The results were quite mixed, so in some cases so it was wrote on six and six time it was sparking.",
                    "label": 0
                },
                {
                    "sent": "Five was faster in seven times.",
                    "label": 0
                },
                {
                    "sent": "Sparky cheeks SD balls faster and there's 111 case where both of them ran out of memory.",
                    "label": 0
                },
                {
                    "sent": "This is now for the for the 1 billion triples.",
                    "label": 0
                },
                {
                    "sent": "Later that on loom, so there's a lot of values, and so on.",
                    "label": 0
                },
                {
                    "sent": "And this basically now the total sound, the total runtime, so it's all the individual values, because total runtimes.",
                    "label": 0
                },
                {
                    "sent": "Also, it's always difficult because it won't ask tech.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very long then of course it says use a bit of you.",
                    "label": 0
                },
                {
                    "sent": "So, but this is now the over the socket she got.",
                    "label": 0
                },
                {
                    "sent": "So here you can see that in the for the small data, so that data set size of 10 million, 100 million and one billion and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and for the small data set size, yeah here we lost whereas for smaller smaller is better.",
                    "label": 0
                },
                {
                    "sent": "And for the last 30 bond for the medium data set, we've also slightly faster.",
                    "label": 0
                },
                {
                    "sent": "This is now.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What happens when we run the?",
                    "label": 0
                },
                {
                    "sent": "Run the experiment with also one of the experiments that wanted 100 now with different number of worker nodes and there we see that are sparkly fiery names nearly the same across the face.",
                    "label": 1
                },
                {
                    "sent": "With this 1366 workers, whereas post parking cheeks as the there is like a great improvement and more work with you at.",
                    "label": 0
                },
                {
                    "sent": "And this is now the pier query type, so we had to stop it and.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In your pattern snowflake and complex pattern results.",
                    "label": 0
                },
                {
                    "sent": "So what we can see is that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's four.",
                    "label": 0
                },
                {
                    "sent": "For the complex pattern and snowflake paper pattern, Spotify is faster also for the star pattern.",
                    "label": 1
                },
                {
                    "sent": "But Interestingly, for the linear pattern, yeah, we will lose in this scenario.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we then basically have some use cases where we actually applied this part.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "System so it just sickens an impression one is for querying Ethereum blockchain data.",
                    "label": 0
                },
                {
                    "sent": "This is in collaboration with company Alessio.",
                    "label": 1
                },
                {
                    "sent": "We have basically 100 of 18 billion triples where yeah data set size 18 billion triples and then basically we have two projects.",
                    "label": 0
                },
                {
                    "sent": "Special Project heads up out.",
                    "label": 0
                },
                {
                    "sent": "Now about transparency and compliance use case for beta.",
                    "label": 1
                },
                {
                    "sent": "Gets about analyzing lock information concerning personal data and the other approaches about points of interest information.",
                    "label": 0
                },
                {
                    "sent": "So yeah, so the conclusion of our work is that so that you can apply opdal tooling.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On big Data frameworks that it's significantly reduce the amount to build 1, so 'cause you get you can leverage existing technology basically for that.",
                    "label": 0
                },
                {
                    "sent": "For one example, which we had is that we got we got RDF type handling working out of the box so we didn't have to like say it's a result of which only supports strings.",
                    "label": 0
                },
                {
                    "sent": "Now we can do integers and all the data types.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Verizon Strings as well.",
                    "label": 0
                },
                {
                    "sent": "It has promising results in respect of scalability, so the reason that we think that most OK. Second, OK, yeah.",
                    "label": 0
                },
                {
                    "sent": "Anyway the future work is that we want to compare is on top.",
                    "label": 0
                },
                {
                    "sent": "That's ongoing work.",
                    "label": 0
                },
                {
                    "sent": "And if you want to investigate dictionary encoding, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thanks a lot for the interesting talk.",
                    "label": 0
                },
                {
                    "sent": "I have actually 2 questions so one you mentioned the RDF use, but in the query processing I didn't really get where you use.",
                    "label": 0
                },
                {
                    "sent": "Actually these are diffuse because you actually convert sparkwell to SQL anyways, so.",
                    "label": 0
                },
                {
                    "sent": "Where does this wheels comes in come into play and the second one is whether actually you enabled Spark, SQL spawned query optimizer because if it is so, I'm not sure whether we can attribute these performance to your framework or to spark SQL squared optimizer already.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I wanted to say including that we attribute it actually is part SQL optimizer because we're doing a decorative approach, so we're just generating a SQL query and then it's up to spark to the query optimization for that.",
                    "label": 0
                },
                {
                    "sent": "If it runs the second question for the first query.",
                    "label": 0
                },
                {
                    "sent": "What you're doing is we're loading the RDF data into a spark RDD and the partitioning is then creating the data frames out of the RDF data from an initial RDD.",
                    "label": 0
                },
                {
                    "sent": "So that means we have to partitions which are the data frames and.",
                    "label": 0
                },
                {
                    "sent": "So in the partitioning process we are creating the data frames plus the meter data and from this on these spaces we're also generating the RDP to defuse.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks a lot.",
                    "label": 0
                },
                {
                    "sent": "Any other question?",
                    "label": 0
                },
                {
                    "sent": "Any other question?",
                    "label": 0
                },
                {
                    "sent": "And so I wanted to ask how?",
                    "label": 0
                },
                {
                    "sent": "What a life lifetime of the partitions that you create?",
                    "label": 0
                },
                {
                    "sent": "Because you compare your total running time with the total runtime of the other approach.",
                    "label": 0
                },
                {
                    "sent": "But you're running time includes quizlet partitions, which I imagine can be used for more than a query.",
                    "label": 0
                },
                {
                    "sent": "Can you repeat?",
                    "label": 0
                },
                {
                    "sent": "Sorry so I was wondering so your partitions can be used for more than a query.",
                    "label": 0
                },
                {
                    "sent": "So right now it's just vertical partitioning.",
                    "label": 0
                },
                {
                    "sent": "That means we are using for each predicate.",
                    "label": 0
                },
                {
                    "sent": "We're creating a partition, so that's what the limiting factor is.",
                    "label": 0
                },
                {
                    "sent": "Basically that as soon as you want to try to predicates, then you need like to need to try and two partitions, though there is ongoing work also presented by other groups here where it's about like creating partitions that capture not only a single triple, but Michael triples involved.",
                    "label": 0
                },
                {
                    "sent": "So basically for partition, which is a table, but we think that our approach deals could transfer to it 'cause we're having these RDF use or.",
                    "label": 0
                },
                {
                    "sent": "Basically you want to have a record in the partition, and this corresponds to the set of triples and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and conceptually basically The thing is that you can have you and an idea on the partition.",
                    "label": 0
                },
                {
                    "sent": "It creates multiple triples.",
                    "label": 0
                },
                {
                    "sent": "Any other question?",
                    "label": 0
                },
                {
                    "sent": "And I do have a question so.",
                    "label": 0
                },
                {
                    "sent": "A.",
                    "label": 0
                },
                {
                    "sent": "From what from what?",
                    "label": 0
                },
                {
                    "sent": "I understood, the data in this park is distributed across across the nodes, right?",
                    "label": 0
                },
                {
                    "sent": "It's done, distributed across.",
                    "label": 0
                },
                {
                    "sent": "Then all the nodes?",
                    "label": 0
                },
                {
                    "sent": "Yes disappeared, yes.",
                    "label": 0
                },
                {
                    "sent": "So are there?",
                    "label": 0
                },
                {
                    "sent": "This is distributed equally evenly in across the nodes.",
                    "label": 0
                },
                {
                    "sent": "Are there some pretty case that are more distributed in a certain nodes?",
                    "label": 0
                },
                {
                    "sent": "And if this is the case, to the performance that, for instance, that we've type is just in one on one node instead of the others?",
                    "label": 0
                },
                {
                    "sent": "That's a very good question, so we didn't evaluate where the partitions ended up on which on the worker nodes, so that we have to investigate.",
                    "label": 0
                },
                {
                    "sent": "But I would say that it's so like because for the for the different predicates, the number of instances of the extension of the predicate various usually creately.",
                    "label": 0
                },
                {
                    "sent": "So I will say that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's we valuated, so I would think that it's not really even distributed, so it depends on the hash key.",
                    "label": 0
                },
                {
                    "sent": "Basically where the data ends up.",
                    "label": 0
                },
                {
                    "sent": "Thank you all so you see that there are seven nodes running with how many cores it knows, 32 cores each of them.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah, no.",
                    "label": 0
                },
                {
                    "sent": "I was wondering what is the usual setup for Spark cluster in terms of nodes?",
                    "label": 0
                },
                {
                    "sent": "If you know of I don't know actually about, so I can just say, well, using we're using like like this kind of and those other people are using notes with three, but there's also the nucleus Google Papers, so they said like I don't know, a few thousand machines or something.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, thank you very much.",
                    "label": 1
                },
                {
                    "sent": "Thank you very much, thank you.",
                    "label": 0
                }
            ]
        }
    }
}