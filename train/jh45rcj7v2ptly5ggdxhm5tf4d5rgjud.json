{
    "id": "jh45rcj7v2ptly5ggdxhm5tf4d5rgjud",
    "title": "Randomized PCA Algorithms with Regret Bounds that are Logarithmic in the Dimension",
    "info": {
        "author": [
            "Manfred K. Warmuth, Department of Computer Science, University of California Santa Cruz"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "August 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Principal Component Analysis"
        ]
    },
    "url": "http://videolectures.net/mlss06tw_warmuth_rparb/",
    "segmentation": [
        [
            "Vicuna, rach.",
            "Um?",
            "And I will talk about online PCA where I. Generalize this expert algorithms to matrix parameters.",
            "So at first I go over the expert setting.",
            "We've seen that yesterday morning.",
            "Receipts in days predictions of the weather get feedback, incur some loss in each trial.",
            "Down here is the familiar."
        ],
        [
            "Article."
        ],
        [
            "And the total loss of the algorithm which I wrote as an absolute loss is supposed to be close to the total loss of the best expert.",
            "OK, now assume I predict the master algorithm predicts with that product, right?",
            "It keeps weights on the experts, which is a probability vector.",
            "WT Omega T and then it predicts, with a weighted average.",
            "Now in that case, it turns out that this absolute loss if this YT is binary is actually a convex combination of the losses of the experts.",
            "This is the loss of the expert.",
            "And in that case, the model sort of simple."
        ],
        [
            "Device you can hide the prediction.",
            "You can say you pick an expert according to this probability vector.",
            "So you predict pick expert I with probability, WTI you receive a loss vector and the expert occurs.",
            "This loss and the total expected losses this big.",
            "You can write us a dot product and I'm going to generalize that to a trace operation in a moment.",
            "So the total loss of the algorithm is simply.",
            "The average losses produced by the probability vector of the of the algorithm metral T and you want this to be close to the loss of the best expert.",
            "OK.",
            "So this is sort of an abstraction of this absolute loss case.",
            "When the loss is the absolute loss."
        ],
        [
            "And this kind of property holds and you can simplify the whole product."
        ],
        [
            "And make this your goal.",
            "Minimize this loss.",
            "OK, good so the."
        ],
        [
            "Rhythms are very familiar by now.",
            "It's either the minus 8 or loss, right?",
            "This factor.",
            "The softmax.",
            "We've got to generalize to some kind of matrix expression here.",
            "The motivation of the update is again Bregman divergences traded off with the loss.",
            "Here I take the relative entropy and as my loss I take this stop loss WVU under T. If you do this, if you minimize this, you get this update.",
            "Then, using actually a very short proof, you can show that the total loss of the algorithm is as big as the loss of any comparative plus to drop off this drop of potential.",
            "But the potential is the Bregman diversions.",
            "This thing you can then sum over trials.",
            "Totale awesome."
        ],
        [
            "The algorithm in all on the whole sequence is as big as total loss of the comparator has total drop of relative entropy, and this is at most log in.",
            "And then you get this kind of bounds.",
            "Where the loss of the algorithm is as most as big as the loss of the best expert plus square root term times log in.",
            "Hey.",
            "Questions OK, so that's expert setting for the absolute loss.",
            "Again, the."
        ],
        [
            "Warm up, the weights are either the minus eight loss I.",
            "There's alternates to this.",
            "You can add a random permutation to the total loss of the current expert and then pick the minimum.",
            "This is called following the perturb leader that also works.",
            "You can actually set it up so it produces probabilities the same way, but the deterministic algorithm doesn't work.",
            "It's off by a factor of two.",
            "You need to do some kind of probabilistic choice.",
            "So now I want to go."
        ],
        [
            "To its variance."
        ],
        [
            "So far I did small expected loss now seem given in each trial, a covariance matrix.",
            "Assumed this covariance matrix is the covariance of some random cost vector P. It looks like this and then the variance in a certain unit direction.",
            "You can write it as a little bit of simplification as you transpose covariance matrix times you.",
            "I'm going to play."
        ],
        [
            "This in a moment, so I want to minimize the."
        ],
        [
            "Variance on the sphere.",
            "So here the covariance matrix you can depict as an ellipse.",
            "I plotted C times.",
            "You will use the unit vector and now in each direction UI plotted this U times.",
            "You transpose CU the variance.",
            "The variance in this direction is this big.",
            "The variances cause largest in the direction of the largest eigenvector and smallest and direction of the smallest eigenvector."
        ],
        [
            "So now the game is something like this.",
            "You pick a unit vector.",
            "I'm going to refine this.",
            "You receive a covariance matrix and the loss is the variance along this direction.",
            "You're going to pick this probabilistically.",
            "And again, instead of wanting to be as good as the best expert, you want to be as best as the total variance along a fixed direction, the best direction.",
            "OK online you don't know all your data.",
            "You get data online and you want to be as good as this in hindsight.",
            "OK.",
            "So.",
            "The problem is when you have.",
            "These kinds of.",
            "This is these are now replaced experts.",
            "The directions replace the experts and this continuously.",
            "Minions sort of finitely many."
        ],
        [
            "The set of directions the unit ball is not a convex set.",
            "So what we're going to do is we close this convex set.",
            "And we take the convex combinations right of the unit ball, which is the interior of the ball as well.",
            "And now I algorithm will pick a direction with a certain probability.",
            "Oh my guy.",
            "So our algorithm will always do some will incur loss something like this.",
            "I'm going to motivate density matrices that you naturally arrive at density matrices.",
            "If you take.",
            "A convex combination.",
            "Um?",
            "Of these kind of variance terms.",
            "Right, so this is the loss in direction W. You pick this direction with probability Omega I.",
            "Then this number is a trace.",
            "You can write it as this is a trace.",
            "The trace is linear.",
            "You can pull it inside and now here you have a convex combination of these kind of outer products.",
            "I call them dyads.",
            "And convex combinations of these outer products are called density matrices.",
            "Their symmetric positive dense matrices.",
            "This is a dietes symmetric positive definite matrix of trace one and, but this convex combination.",
            "Is density matrix.",
            "It's a symmetric positive definite matrix where the eigenvalues are non negative and sum to one.",
            "It is a generalization of a mixture.",
            "This is a generalization of the mixture vector.",
            "As you will see in a moment."
        ],
        [
            "So what are these density matrices?",
            "Their convex combination of dietze symmetric positive density?",
            "Definite matrices trace one.",
            "The eigenvalue is now former probability vector.",
            "Now many mixtures have lead to the same matrix, so a diet you can write out as one of those straight lines is a degenerate lips that had just as One Direction all other all other eigen directions are zero.",
            "So that's a dyad.",
            "Convex combination of them gives you an ellipse, but any ellipse it decomposes a sum of N dietze the ones that correspond to the eigen directions.",
            "OK, so you can always write as a convex combination of endius corresponding to the eigenvectors.",
            "The old case that we had before was the case when you're.",
            "When your ex, when your directions were the unit directions and the probability vector, you could just write as a diagonal matrix with your probability vector along the diagonal.",
            "So in this new setting, you don't keep the eigensystem fixed.",
            "The old Eigensystem was the unit matrix.",
            "You learn the eigen direction.",
            "The Eigensystem as well."
        ],
        [
            "So here is the setting.",
            "You have the parameter is a density matrix, which is a convex combination of these dyads.",
            "You pick a direction.",
            "With probability corresponding to the eigenvalues.",
            "The covariance is obtained and you incur the variance along that direction and the expected variance this this.",
            "Replaces what we had before we."
        ],
        [
            "Picked an expert.",
            "I according to the probability vector I was picked with probability WT WT.",
            "I'll make a TI.",
            "Then you received a vector of losses.",
            "You incur the itex, but include this loss.",
            "Expected loss was the DOT product, and then you update W. So this one."
        ],
        [
            "Is now this thing?",
            "Again, you pick a direction with probability Omega T. Covariance is obtained you punished by the variance along this direction.",
            "And then the expected variance is this trace with the density matrix.",
            "So you want to do as well as the best density matrix.",
            "While the best density matrix that minimizes these kinds of the minimizes the.",
            "The variance of this thing is the.",
            "Single Dyett corresponding to the smallest eigenvalue of the total covariance."
        ],
        [
            "OK. Again, the old case occurs as a special case where your density matrix is always diagonal and your covariance matrix is almost diagonal.",
            "The Lambda vector is along the diagonal.",
            "OK, and the expert corresponds to this Dyett EI transpose.",
            "So in the matrix setting we have continuously many diots not just finitely many, but continuously many."
        ],
        [
            "Hey, here's the pretty thing.",
            "We motivate updates the same way you take the generalization of the relative entropy, which is the quantum relative entropy order.",
            "Mega versions.",
            "You trade this off against the loss that generalization of that loss, which is this trace, and then you end up with the following kind of update, which generalizes the softmax update.",
            "You take a log.",
            "This is now a matrix log.",
            "That's why it's written in bold.",
            "The matrix log of a matrix is of a density matrix.",
            "The following was symmetric matrix, the following it to the eigendecomposition you take the log of the eigenvalues of the diagonal.",
            "So you take the matrix log.",
            "Of your.",
            "Parameter matrix.",
            "That becomes a symmetric matrix.",
            "You add the covariance matrix.",
            "Minus 8 attempts to covariance matrix exponentially to get a symmetric positive definite matrix right by the trace and you get trace one again.",
            "This is because matrix products are not closed on the as positive definite matrices are not closed on the matrix product.",
            "So you have to do this kind of rigamarole.",
            "By using this link functions.",
            "And surprisingly, this kind of going to the other domain to the log domain.",
            "Subtracting the covariance mates in going back is derived using this Bregman to virgins tradeoff thing.",
            "OK, so before we had weights of the type, I'll make it easy to the minus loss of the expert.",
            "Now this is generalized.",
            "Two density matrices which maintain direction maintain uncertainty about all possible directions and it becomes this generalization of the softmax using matrix logs and matrix exponentials.",
            "Questions.",
            "OK."
        ],
        [
            "Good, so you gain.",
            "You can prove some kind of inequality and then you sum over trials tune and you get this kind of bound.",
            "So you can do as well as the best.",
            "This is the smallest direction in hindsight."
        ],
        [
            "How does it?"
        ],
        [
            "Related to online PCA.",
            "So in online PCA you want to direct project the data into a low dimensional subspace, you want to be as good as the best.",
            "Subspace in hindsight.",
            "Which are the top eigenvectors of the covariance matrix?"
        ],
        [
            "OK, so actually we're going to inversion.",
            "We're going to learn the N -- K lowest direction and this let me write down the loss that you would use for.",
            "For for PCA, if you have a rank K matrix.",
            "Just K directions.",
            "It would be a projection matrix because the eigenvalues along those directions are one in all the other directions.",
            "001 valued eigenvalues.",
            "So here is your rank projection matrix.",
            "And you want to project your points on those directions.",
            "Now this point I decomposed into two pieces into PX and I'm minus P * X.",
            "This first piece cancels and.",
            "I get I -- P times the outer product, so here it's typically looks quadratic and he had simply looks linear linear in quadratically many variables.",
            "So we want to choose an N -- K dimensional subspace of minimum variance.",
            "You see, this was the variance.",
            "OK, how do we do that?",
            "We project.",
            "This is a definition of projection matrices."
        ],
        [
            "OK.",
            "So the variance of the algorithm is close to the variance of small axes.",
            "In hindsight, that's what we did so far.",
            "An so minimizing the variance along One Direction is equivalent.",
            "The maximum is equivalent to maximizing the variance along N -- 1 directions.",
            "So in PCA we want to maximize the variance along K directions or minimize the variance along N -- K directions.",
            "So I'm going to do this kind of game first in the expert setting and then just say, oh I can lift it to the matrix setting."
        ],
        [
            "So in the expert setting, let instead of writing N -- K directions or I always use Em Now.",
            "So what corresponds to this is you want to pick a set of EM experts in minus K experts based on your probability vector.",
            "Choose them randomly somehow and where you want to receive a loss vector, and then your total loss is the total loss of all M experts, not just a single one that you picked, but all any of them.",
            "And the total expected loss is going to be this big.",
            "M Times the dot product and then you want to update WT.",
            "K. OK, so our goal is we want to minimize the.",
            "We want to get an algorithm whose total loss total expected loss is close to the total loss.",
            "The smallest total loss of the best set.",
            "OK, so instead of being as good as the best single expert, we want to good be as good as the best set of EM experts.",
            "OK, how do you do this?"
        ],
        [
            "Well.",
            "You can, we can lose an algorithm that is motivated by biology.",
            "I gave this talk 1st at the cold community and we went to a museum.",
            "The antiwar Hall museum there was a beautiful lion, so we stole it, took a picture, and then we put it in the talk.",
            "So what happens is?",
            "If you want to, if you do this kind of exponential updates, even minus eight loss, they always saturate.",
            "They go into the corner of the simplex.",
            "And one guy wins.",
            "So you have to prevent that this guy wins.",
            "So what you do is you want to cap the weights and in nature what happens is this is guaranteed by a predator.",
            "So the lion can.",
            "Eat about 13 grass eating species in the Serengeti and what it does.",
            "What the pride does.",
            "It specializes on the currently most abundant species, therefore capping.",
            "The concentration of the highest once because it always nibbles away on the top bar of the histogram, and it essentially has a capping effect on the histogram keeping everybody in check keeping everybody below a certain amount.",
            "And this has an amazing effect.",
            "It has the effect that it preserves variety.",
            "You see the individual species, they observe a multiplicative update.",
            "Why?",
            "Because the survival rate is.",
            "Current concentration times a factor, right?",
            "Now, if you would let this algorithm run.",
            "One species would win.",
            "At least in a simplified, if you simplify everything and they all would be very closely.",
            "You know these other constraints, but in the ideal case, one species would win.",
            "But if you have a predator, it will cap the concentration of everybody and a lot can survive.",
            "So if you take the lion away from the Serengeti, the number of grass eating species will collapse to a very small number.",
            "Two or three.",
            "In the ideal case it would be 1.",
            "And people have done these experiments.",
            "You can super predator setups happen all over nature to happen in fish and all kinds of things in birds.",
            "And they have done setups where they took the predator away an actually the system collapsed.",
            "And the total number of species that were surviving was much smaller.",
            "Curiously enough, I'm using the same philosophy, same philosophy to design online algorithms.",
            "I kept the weights from the top.",
            "To prevent.",
            "That it picks one best expert."
        ],
        [
            "So the update goes like this.",
            "It's very intuitive.",
            "You take your softmax.",
            "If I would just do this update alone, it would go into the corner of the simplex.",
            "Right, lots of variety.",
            "Now comes the predator, the Predator says.",
            "You project your weight vector onto the closest weight vector in the cap simplex, which restricts every every weight to be at most."
        ],
        [
            "1 / M, which caps the weights.",
            "I."
        ],
        [
            "Yeah, capital weights, so it's a capped simplex.",
            "These corners correspond to the M sets.",
            "Pick and now you can show that this algorithm for this algorithm the expected loss of the algorithm in the proof you're going to use the generalized Pythagorean theorem in an elementary way.",
            "The expected loss of the algorithm is at most speakers, the last of the best M set.",
            "Plus some square returns, but M + M log in.",
            "Notice the number of M sets, the number of sets of size M subsets of M experts is huge.",
            "It's N choose M, But the only punished by log of that which is still be well behaved.",
            "It grows logarithmically in the dimension."
        ],
        [
            "OK, so the M sets.",
            "You can encode them this way.",
            "They called em corners the convex Hull of em corners is actually equal to the capped a convex.",
            "All of Em corners is equal to the probability simplex.",
            "And actually if you give me one vector in the cap probability simplex, I can effectively decompose it as a convex combination of end corners.",
            "This is promised by the current Aradori theorem, but you actually can effectively effectively do it.",
            "So we choose a name corner according to this document decomposition.",
            "There's alternates to capping.",
            "You can do follow the leader.",
            "It's cheap but inferior bounds.",
            "You can also do a dynamic programming, which seems to be which is more expensive.",
            "And some of these don't generalize to the Matrix case."
        ],
        [
            "OK.",
            "So now so you lift this algorithm.",
            "Did you just develop for the experts, adding to the matrix setting using the usual trick of generalizing?",
            "Convex combinations, mixture vectors 2.",
            "Density matrices, so you pick N -- K dimensional subspace based on the current density matrix you choose to comment a complementary subspace.",
            "You receive an instance and then you incur this loss, which is equal to this trace and it's this.",
            "Expect which corresponds to this expected loss, and then you update your thing.",
            "And.",
            "The app."
        ],
        [
            "It again has the same flavor, but except now with matrices, matrix logs and matrix exponentials and projections.",
            "And these are very efficient to implement except for this step.",
            "That's very expensive.",
            "And we're looking for ways to make it more efficient.",
            "Expected loss of the algorithm is now as good as the loss of the best case space chosen in hindsight hindsight.",
            "Plus some square term plus K log N so PCA.",
            "You can do it with millions of dimension.",
            "It doesn't really matter the algorithm if you have time to run these algorithms, the generalization bounds are still extremely good.",
            "They only pinned on the leg arhythmic on the dimension.",
            "If you run PCA with this type of algorithm.",
            "And W the dimension you're only going to, it's the amount of resources only go up by a constant, essentially very small, because if you if you do the additive."
        ],
        [
            "Items you in trouble again, so there's again two families of updates you can regularize this way.",
            "Then the weight vector is a linear combination of these outer product.",
            "These are fast and kernel isable.",
            "Again, this is another family of updates.",
            "It's now E to the linear where this is the matrix exponential of this outer product.",
            "OK. And.",
            "And you get to this updates by Regularising with a quantum relative entropy, right?",
            "And we're going to predict with a random project projection, mate, random projection matrix and the bounds of this here grow logarithmically with end was here.",
            "They grow linear with at least linear within."
        ],
        [
            "So I."
        ],
        [
            "I'm very much fascinated by this by online updates for matrix parameters, in particular, generalizations of entropy and so forth, I think they're going to become important.",
            "Basically, I'm trying to lift.",
            "Machine learning from using vector parameters to matrix parameters.",
            "The shifting methodology carries over that.",
            "I talked about this morning in the context of caching.",
            "Um?",
            "Um?",
            "For example, you can do it for this case immediately, so if you do online PCA and your data shifts overtime, everything carries over.",
            "I need to do extensive experiments and I'm kind of fascinated by sort of the blessing and the curse of the multiplicative update.",
            "They're very fast, but they lose variety very fast and you need to do tricks.",
            "This morning I talked about lower bounds on the weights.",
            "Right for shifting?",
            "Here talk about upper bounds of the weights to preserve variety to do it.",
            "They do as well as a variety of different things.",
            "OK. And actually, underlying all of this is a probability calculus for density matrices, which generalizes the normal probability calculus.",
            "It was done already in quantum physics to some to some extent, but I invented a Bayes rule that goes along with it, and now I think we have the beginnings of abrasion.",
            "Probability theory for density matrices and I'm going to talk about that tomorrow, so you will get a sense of where this is headed.",
            "That's it.",
            "Questions.",
            "Yes.",
            "So I started taking compression on one of the previous sites.",
            "We have Jager isms for the online PCA.",
            "Think about 2 three steps.",
            "First, when here first compute the value happens key.",
            "I would."
        ],
        [
            "Just as an aside, the result of a mutation.",
            "Yes, it's a softmax.",
            "A generalization of softmax.",
            "Yes, yes.",
            "This is that that the projection matrix is done at.",
            "The projection is done as follows.",
            "You do you do the eigendecomposition of this and then you do the projection algorithm based just on that eigenvector.",
            "And what you do is you look at the eigen vector and assume.",
            "Let's say you're capping at half and you have one vector that is bigger than 1/2.",
            "Then let's say 1/3.",
            "Then it's more interesting you have two ones that are bigger than 1/3, you push them down.",
            "And then sum up the remaining weights.",
            "Have to be really normalized, and essentially there's a little bit of a binary search, because sometimes when you push some things down, other things pop up over the limit, so you need to find sort of the minimum number of things that you have to push down so that everybody stays below.",
            "It's a very intuitive algorithm.",
            "You can do it with binary search or with something like that, or you can actually do it in linear using linear time using the median algorithm.",
            "So it's not a complicated thing you do kind of.",
            "The most obvious thing you look at, the eigenvectors, eigenvalues, and you the topmost guy.",
            "If it's above the limit, push it down, maybe an renormalizing if it's.",
            "If it's still if everybody stays below you, keep on going and not be load and keep on going until you have the right number.",
            "This is sort of this is the kind of algorithm you need.",
            "It's not very complicated.",
            "I can show you on a piece of paper very quickly.",
            "So this projection algorithm is not very expensive once you have the icon decomposition.",
            "But this is extremely expensive because you have to compute eigen decompositions.",
            "And at this point I don't know how to avoid it yet we're working on it.",
            "It might not be possible, I don't know.",
            "It's a very sophisticated thing.",
            "You have to keep track of uncertainty in all possible directions.",
            "Maybe it cannot be simplified, I don't know.",
            "It certainly is completely mathematically elegant.",
            "I was extremely surprised that there is this generalization and the bounds sort of rather immediately generalizes.",
            "You have to.",
            "Look for this generalizations of Jensen's inequality and there's something called a Golden Thompson inequality.",
            "But to do statistical physicists, this is rather standard, we just had to learn it.",
            "Other questions.",
            "OK, thank you very much.",
            "No.",
            "Here comes cooner."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vicuna, rach.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And I will talk about online PCA where I. Generalize this expert algorithms to matrix parameters.",
                    "label": 0
                },
                {
                    "sent": "So at first I go over the expert setting.",
                    "label": 0
                },
                {
                    "sent": "We've seen that yesterday morning.",
                    "label": 0
                },
                {
                    "sent": "Receipts in days predictions of the weather get feedback, incur some loss in each trial.",
                    "label": 0
                },
                {
                    "sent": "Down here is the familiar.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Article.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the total loss of the algorithm which I wrote as an absolute loss is supposed to be close to the total loss of the best expert.",
                    "label": 1
                },
                {
                    "sent": "OK, now assume I predict the master algorithm predicts with that product, right?",
                    "label": 1
                },
                {
                    "sent": "It keeps weights on the experts, which is a probability vector.",
                    "label": 0
                },
                {
                    "sent": "WT Omega T and then it predicts, with a weighted average.",
                    "label": 0
                },
                {
                    "sent": "Now in that case, it turns out that this absolute loss if this YT is binary is actually a convex combination of the losses of the experts.",
                    "label": 0
                },
                {
                    "sent": "This is the loss of the expert.",
                    "label": 0
                },
                {
                    "sent": "And in that case, the model sort of simple.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Device you can hide the prediction.",
                    "label": 0
                },
                {
                    "sent": "You can say you pick an expert according to this probability vector.",
                    "label": 0
                },
                {
                    "sent": "So you predict pick expert I with probability, WTI you receive a loss vector and the expert occurs.",
                    "label": 1
                },
                {
                    "sent": "This loss and the total expected losses this big.",
                    "label": 0
                },
                {
                    "sent": "You can write us a dot product and I'm going to generalize that to a trace operation in a moment.",
                    "label": 0
                },
                {
                    "sent": "So the total loss of the algorithm is simply.",
                    "label": 0
                },
                {
                    "sent": "The average losses produced by the probability vector of the of the algorithm metral T and you want this to be close to the loss of the best expert.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of an abstraction of this absolute loss case.",
                    "label": 0
                },
                {
                    "sent": "When the loss is the absolute loss.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this kind of property holds and you can simplify the whole product.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And make this your goal.",
                    "label": 0
                },
                {
                    "sent": "Minimize this loss.",
                    "label": 0
                },
                {
                    "sent": "OK, good so the.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rhythms are very familiar by now.",
                    "label": 0
                },
                {
                    "sent": "It's either the minus 8 or loss, right?",
                    "label": 0
                },
                {
                    "sent": "This factor.",
                    "label": 0
                },
                {
                    "sent": "The softmax.",
                    "label": 0
                },
                {
                    "sent": "We've got to generalize to some kind of matrix expression here.",
                    "label": 0
                },
                {
                    "sent": "The motivation of the update is again Bregman divergences traded off with the loss.",
                    "label": 0
                },
                {
                    "sent": "Here I take the relative entropy and as my loss I take this stop loss WVU under T. If you do this, if you minimize this, you get this update.",
                    "label": 0
                },
                {
                    "sent": "Then, using actually a very short proof, you can show that the total loss of the algorithm is as big as the loss of any comparative plus to drop off this drop of potential.",
                    "label": 0
                },
                {
                    "sent": "But the potential is the Bregman diversions.",
                    "label": 0
                },
                {
                    "sent": "This thing you can then sum over trials.",
                    "label": 0
                },
                {
                    "sent": "Totale awesome.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The algorithm in all on the whole sequence is as big as total loss of the comparator has total drop of relative entropy, and this is at most log in.",
                    "label": 0
                },
                {
                    "sent": "And then you get this kind of bounds.",
                    "label": 0
                },
                {
                    "sent": "Where the loss of the algorithm is as most as big as the loss of the best expert plus square root term times log in.",
                    "label": 0
                },
                {
                    "sent": "Hey.",
                    "label": 0
                },
                {
                    "sent": "Questions OK, so that's expert setting for the absolute loss.",
                    "label": 0
                },
                {
                    "sent": "Again, the.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Warm up, the weights are either the minus eight loss I.",
                    "label": 0
                },
                {
                    "sent": "There's alternates to this.",
                    "label": 0
                },
                {
                    "sent": "You can add a random permutation to the total loss of the current expert and then pick the minimum.",
                    "label": 1
                },
                {
                    "sent": "This is called following the perturb leader that also works.",
                    "label": 0
                },
                {
                    "sent": "You can actually set it up so it produces probabilities the same way, but the deterministic algorithm doesn't work.",
                    "label": 1
                },
                {
                    "sent": "It's off by a factor of two.",
                    "label": 0
                },
                {
                    "sent": "You need to do some kind of probabilistic choice.",
                    "label": 0
                },
                {
                    "sent": "So now I want to go.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To its variance.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So far I did small expected loss now seem given in each trial, a covariance matrix.",
                    "label": 1
                },
                {
                    "sent": "Assumed this covariance matrix is the covariance of some random cost vector P. It looks like this and then the variance in a certain unit direction.",
                    "label": 1
                },
                {
                    "sent": "You can write it as a little bit of simplification as you transpose covariance matrix times you.",
                    "label": 0
                },
                {
                    "sent": "I'm going to play.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This in a moment, so I want to minimize the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Variance on the sphere.",
                    "label": 0
                },
                {
                    "sent": "So here the covariance matrix you can depict as an ellipse.",
                    "label": 0
                },
                {
                    "sent": "I plotted C times.",
                    "label": 0
                },
                {
                    "sent": "You will use the unit vector and now in each direction UI plotted this U times.",
                    "label": 1
                },
                {
                    "sent": "You transpose CU the variance.",
                    "label": 1
                },
                {
                    "sent": "The variance in this direction is this big.",
                    "label": 0
                },
                {
                    "sent": "The variances cause largest in the direction of the largest eigenvector and smallest and direction of the smallest eigenvector.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now the game is something like this.",
                    "label": 0
                },
                {
                    "sent": "You pick a unit vector.",
                    "label": 1
                },
                {
                    "sent": "I'm going to refine this.",
                    "label": 0
                },
                {
                    "sent": "You receive a covariance matrix and the loss is the variance along this direction.",
                    "label": 1
                },
                {
                    "sent": "You're going to pick this probabilistically.",
                    "label": 0
                },
                {
                    "sent": "And again, instead of wanting to be as good as the best expert, you want to be as best as the total variance along a fixed direction, the best direction.",
                    "label": 0
                },
                {
                    "sent": "OK online you don't know all your data.",
                    "label": 0
                },
                {
                    "sent": "You get data online and you want to be as good as this in hindsight.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The problem is when you have.",
                    "label": 0
                },
                {
                    "sent": "These kinds of.",
                    "label": 0
                },
                {
                    "sent": "This is these are now replaced experts.",
                    "label": 0
                },
                {
                    "sent": "The directions replace the experts and this continuously.",
                    "label": 0
                },
                {
                    "sent": "Minions sort of finitely many.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The set of directions the unit ball is not a convex set.",
                    "label": 1
                },
                {
                    "sent": "So what we're going to do is we close this convex set.",
                    "label": 0
                },
                {
                    "sent": "And we take the convex combinations right of the unit ball, which is the interior of the ball as well.",
                    "label": 1
                },
                {
                    "sent": "And now I algorithm will pick a direction with a certain probability.",
                    "label": 0
                },
                {
                    "sent": "Oh my guy.",
                    "label": 0
                },
                {
                    "sent": "So our algorithm will always do some will incur loss something like this.",
                    "label": 0
                },
                {
                    "sent": "I'm going to motivate density matrices that you naturally arrive at density matrices.",
                    "label": 0
                },
                {
                    "sent": "If you take.",
                    "label": 0
                },
                {
                    "sent": "A convex combination.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "Of these kind of variance terms.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is the loss in direction W. You pick this direction with probability Omega I.",
                    "label": 0
                },
                {
                    "sent": "Then this number is a trace.",
                    "label": 0
                },
                {
                    "sent": "You can write it as this is a trace.",
                    "label": 0
                },
                {
                    "sent": "The trace is linear.",
                    "label": 0
                },
                {
                    "sent": "You can pull it inside and now here you have a convex combination of these kind of outer products.",
                    "label": 0
                },
                {
                    "sent": "I call them dyads.",
                    "label": 0
                },
                {
                    "sent": "And convex combinations of these outer products are called density matrices.",
                    "label": 0
                },
                {
                    "sent": "Their symmetric positive dense matrices.",
                    "label": 0
                },
                {
                    "sent": "This is a dietes symmetric positive definite matrix of trace one and, but this convex combination.",
                    "label": 1
                },
                {
                    "sent": "Is density matrix.",
                    "label": 0
                },
                {
                    "sent": "It's a symmetric positive definite matrix where the eigenvalues are non negative and sum to one.",
                    "label": 0
                },
                {
                    "sent": "It is a generalization of a mixture.",
                    "label": 0
                },
                {
                    "sent": "This is a generalization of the mixture vector.",
                    "label": 0
                },
                {
                    "sent": "As you will see in a moment.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are these density matrices?",
                    "label": 1
                },
                {
                    "sent": "Their convex combination of dietze symmetric positive density?",
                    "label": 0
                },
                {
                    "sent": "Definite matrices trace one.",
                    "label": 1
                },
                {
                    "sent": "The eigenvalue is now former probability vector.",
                    "label": 0
                },
                {
                    "sent": "Now many mixtures have lead to the same matrix, so a diet you can write out as one of those straight lines is a degenerate lips that had just as One Direction all other all other eigen directions are zero.",
                    "label": 0
                },
                {
                    "sent": "So that's a dyad.",
                    "label": 0
                },
                {
                    "sent": "Convex combination of them gives you an ellipse, but any ellipse it decomposes a sum of N dietze the ones that correspond to the eigen directions.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can always write as a convex combination of endius corresponding to the eigenvectors.",
                    "label": 1
                },
                {
                    "sent": "The old case that we had before was the case when you're.",
                    "label": 0
                },
                {
                    "sent": "When your ex, when your directions were the unit directions and the probability vector, you could just write as a diagonal matrix with your probability vector along the diagonal.",
                    "label": 0
                },
                {
                    "sent": "So in this new setting, you don't keep the eigensystem fixed.",
                    "label": 0
                },
                {
                    "sent": "The old Eigensystem was the unit matrix.",
                    "label": 0
                },
                {
                    "sent": "You learn the eigen direction.",
                    "label": 0
                },
                {
                    "sent": "The Eigensystem as well.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is the setting.",
                    "label": 0
                },
                {
                    "sent": "You have the parameter is a density matrix, which is a convex combination of these dyads.",
                    "label": 1
                },
                {
                    "sent": "You pick a direction.",
                    "label": 0
                },
                {
                    "sent": "With probability corresponding to the eigenvalues.",
                    "label": 1
                },
                {
                    "sent": "The covariance is obtained and you incur the variance along that direction and the expected variance this this.",
                    "label": 0
                },
                {
                    "sent": "Replaces what we had before we.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Picked an expert.",
                    "label": 0
                },
                {
                    "sent": "I according to the probability vector I was picked with probability WT WT.",
                    "label": 0
                },
                {
                    "sent": "I'll make a TI.",
                    "label": 0
                },
                {
                    "sent": "Then you received a vector of losses.",
                    "label": 0
                },
                {
                    "sent": "You incur the itex, but include this loss.",
                    "label": 0
                },
                {
                    "sent": "Expected loss was the DOT product, and then you update W. So this one.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is now this thing?",
                    "label": 0
                },
                {
                    "sent": "Again, you pick a direction with probability Omega T. Covariance is obtained you punished by the variance along this direction.",
                    "label": 0
                },
                {
                    "sent": "And then the expected variance is this trace with the density matrix.",
                    "label": 0
                },
                {
                    "sent": "So you want to do as well as the best density matrix.",
                    "label": 1
                },
                {
                    "sent": "While the best density matrix that minimizes these kinds of the minimizes the.",
                    "label": 0
                },
                {
                    "sent": "The variance of this thing is the.",
                    "label": 1
                },
                {
                    "sent": "Single Dyett corresponding to the smallest eigenvalue of the total covariance.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Again, the old case occurs as a special case where your density matrix is always diagonal and your covariance matrix is almost diagonal.",
                    "label": 0
                },
                {
                    "sent": "The Lambda vector is along the diagonal.",
                    "label": 0
                },
                {
                    "sent": "OK, and the expert corresponds to this Dyett EI transpose.",
                    "label": 0
                },
                {
                    "sent": "So in the matrix setting we have continuously many diots not just finitely many, but continuously many.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hey, here's the pretty thing.",
                    "label": 0
                },
                {
                    "sent": "We motivate updates the same way you take the generalization of the relative entropy, which is the quantum relative entropy order.",
                    "label": 1
                },
                {
                    "sent": "Mega versions.",
                    "label": 0
                },
                {
                    "sent": "You trade this off against the loss that generalization of that loss, which is this trace, and then you end up with the following kind of update, which generalizes the softmax update.",
                    "label": 0
                },
                {
                    "sent": "You take a log.",
                    "label": 0
                },
                {
                    "sent": "This is now a matrix log.",
                    "label": 0
                },
                {
                    "sent": "That's why it's written in bold.",
                    "label": 0
                },
                {
                    "sent": "The matrix log of a matrix is of a density matrix.",
                    "label": 0
                },
                {
                    "sent": "The following was symmetric matrix, the following it to the eigendecomposition you take the log of the eigenvalues of the diagonal.",
                    "label": 0
                },
                {
                    "sent": "So you take the matrix log.",
                    "label": 0
                },
                {
                    "sent": "Of your.",
                    "label": 0
                },
                {
                    "sent": "Parameter matrix.",
                    "label": 0
                },
                {
                    "sent": "That becomes a symmetric matrix.",
                    "label": 0
                },
                {
                    "sent": "You add the covariance matrix.",
                    "label": 1
                },
                {
                    "sent": "Minus 8 attempts to covariance matrix exponentially to get a symmetric positive definite matrix right by the trace and you get trace one again.",
                    "label": 0
                },
                {
                    "sent": "This is because matrix products are not closed on the as positive definite matrices are not closed on the matrix product.",
                    "label": 0
                },
                {
                    "sent": "So you have to do this kind of rigamarole.",
                    "label": 0
                },
                {
                    "sent": "By using this link functions.",
                    "label": 0
                },
                {
                    "sent": "And surprisingly, this kind of going to the other domain to the log domain.",
                    "label": 0
                },
                {
                    "sent": "Subtracting the covariance mates in going back is derived using this Bregman to virgins tradeoff thing.",
                    "label": 0
                },
                {
                    "sent": "OK, so before we had weights of the type, I'll make it easy to the minus loss of the expert.",
                    "label": 0
                },
                {
                    "sent": "Now this is generalized.",
                    "label": 0
                },
                {
                    "sent": "Two density matrices which maintain direction maintain uncertainty about all possible directions and it becomes this generalization of the softmax using matrix logs and matrix exponentials.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good, so you gain.",
                    "label": 0
                },
                {
                    "sent": "You can prove some kind of inequality and then you sum over trials tune and you get this kind of bound.",
                    "label": 0
                },
                {
                    "sent": "So you can do as well as the best.",
                    "label": 0
                },
                {
                    "sent": "This is the smallest direction in hindsight.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How does it?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Related to online PCA.",
                    "label": 0
                },
                {
                    "sent": "So in online PCA you want to direct project the data into a low dimensional subspace, you want to be as good as the best.",
                    "label": 0
                },
                {
                    "sent": "Subspace in hindsight.",
                    "label": 0
                },
                {
                    "sent": "Which are the top eigenvectors of the covariance matrix?",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so actually we're going to inversion.",
                    "label": 0
                },
                {
                    "sent": "We're going to learn the N -- K lowest direction and this let me write down the loss that you would use for.",
                    "label": 0
                },
                {
                    "sent": "For for PCA, if you have a rank K matrix.",
                    "label": 0
                },
                {
                    "sent": "Just K directions.",
                    "label": 0
                },
                {
                    "sent": "It would be a projection matrix because the eigenvalues along those directions are one in all the other directions.",
                    "label": 0
                },
                {
                    "sent": "001 valued eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "So here is your rank projection matrix.",
                    "label": 0
                },
                {
                    "sent": "And you want to project your points on those directions.",
                    "label": 0
                },
                {
                    "sent": "Now this point I decomposed into two pieces into PX and I'm minus P * X.",
                    "label": 0
                },
                {
                    "sent": "This first piece cancels and.",
                    "label": 0
                },
                {
                    "sent": "I get I -- P times the outer product, so here it's typically looks quadratic and he had simply looks linear linear in quadratically many variables.",
                    "label": 0
                },
                {
                    "sent": "So we want to choose an N -- K dimensional subspace of minimum variance.",
                    "label": 1
                },
                {
                    "sent": "You see, this was the variance.",
                    "label": 0
                },
                {
                    "sent": "OK, how do we do that?",
                    "label": 0
                },
                {
                    "sent": "We project.",
                    "label": 0
                },
                {
                    "sent": "This is a definition of projection matrices.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the variance of the algorithm is close to the variance of small axes.",
                    "label": 0
                },
                {
                    "sent": "In hindsight, that's what we did so far.",
                    "label": 0
                },
                {
                    "sent": "An so minimizing the variance along One Direction is equivalent.",
                    "label": 0
                },
                {
                    "sent": "The maximum is equivalent to maximizing the variance along N -- 1 directions.",
                    "label": 0
                },
                {
                    "sent": "So in PCA we want to maximize the variance along K directions or minimize the variance along N -- K directions.",
                    "label": 1
                },
                {
                    "sent": "So I'm going to do this kind of game first in the expert setting and then just say, oh I can lift it to the matrix setting.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the expert setting, let instead of writing N -- K directions or I always use Em Now.",
                    "label": 0
                },
                {
                    "sent": "So what corresponds to this is you want to pick a set of EM experts in minus K experts based on your probability vector.",
                    "label": 1
                },
                {
                    "sent": "Choose them randomly somehow and where you want to receive a loss vector, and then your total loss is the total loss of all M experts, not just a single one that you picked, but all any of them.",
                    "label": 1
                },
                {
                    "sent": "And the total expected loss is going to be this big.",
                    "label": 0
                },
                {
                    "sent": "M Times the dot product and then you want to update WT.",
                    "label": 0
                },
                {
                    "sent": "K. OK, so our goal is we want to minimize the.",
                    "label": 1
                },
                {
                    "sent": "We want to get an algorithm whose total loss total expected loss is close to the total loss.",
                    "label": 1
                },
                {
                    "sent": "The smallest total loss of the best set.",
                    "label": 0
                },
                {
                    "sent": "OK, so instead of being as good as the best single expert, we want to good be as good as the best set of EM experts.",
                    "label": 0
                },
                {
                    "sent": "OK, how do you do this?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "You can, we can lose an algorithm that is motivated by biology.",
                    "label": 0
                },
                {
                    "sent": "I gave this talk 1st at the cold community and we went to a museum.",
                    "label": 0
                },
                {
                    "sent": "The antiwar Hall museum there was a beautiful lion, so we stole it, took a picture, and then we put it in the talk.",
                    "label": 0
                },
                {
                    "sent": "So what happens is?",
                    "label": 0
                },
                {
                    "sent": "If you want to, if you do this kind of exponential updates, even minus eight loss, they always saturate.",
                    "label": 0
                },
                {
                    "sent": "They go into the corner of the simplex.",
                    "label": 0
                },
                {
                    "sent": "And one guy wins.",
                    "label": 0
                },
                {
                    "sent": "So you have to prevent that this guy wins.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you want to cap the weights and in nature what happens is this is guaranteed by a predator.",
                    "label": 0
                },
                {
                    "sent": "So the lion can.",
                    "label": 0
                },
                {
                    "sent": "Eat about 13 grass eating species in the Serengeti and what it does.",
                    "label": 0
                },
                {
                    "sent": "What the pride does.",
                    "label": 0
                },
                {
                    "sent": "It specializes on the currently most abundant species, therefore capping.",
                    "label": 0
                },
                {
                    "sent": "The concentration of the highest once because it always nibbles away on the top bar of the histogram, and it essentially has a capping effect on the histogram keeping everybody in check keeping everybody below a certain amount.",
                    "label": 0
                },
                {
                    "sent": "And this has an amazing effect.",
                    "label": 0
                },
                {
                    "sent": "It has the effect that it preserves variety.",
                    "label": 1
                },
                {
                    "sent": "You see the individual species, they observe a multiplicative update.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because the survival rate is.",
                    "label": 0
                },
                {
                    "sent": "Current concentration times a factor, right?",
                    "label": 0
                },
                {
                    "sent": "Now, if you would let this algorithm run.",
                    "label": 0
                },
                {
                    "sent": "One species would win.",
                    "label": 0
                },
                {
                    "sent": "At least in a simplified, if you simplify everything and they all would be very closely.",
                    "label": 0
                },
                {
                    "sent": "You know these other constraints, but in the ideal case, one species would win.",
                    "label": 0
                },
                {
                    "sent": "But if you have a predator, it will cap the concentration of everybody and a lot can survive.",
                    "label": 0
                },
                {
                    "sent": "So if you take the lion away from the Serengeti, the number of grass eating species will collapse to a very small number.",
                    "label": 0
                },
                {
                    "sent": "Two or three.",
                    "label": 0
                },
                {
                    "sent": "In the ideal case it would be 1.",
                    "label": 0
                },
                {
                    "sent": "And people have done these experiments.",
                    "label": 1
                },
                {
                    "sent": "You can super predator setups happen all over nature to happen in fish and all kinds of things in birds.",
                    "label": 0
                },
                {
                    "sent": "And they have done setups where they took the predator away an actually the system collapsed.",
                    "label": 0
                },
                {
                    "sent": "And the total number of species that were surviving was much smaller.",
                    "label": 0
                },
                {
                    "sent": "Curiously enough, I'm using the same philosophy, same philosophy to design online algorithms.",
                    "label": 0
                },
                {
                    "sent": "I kept the weights from the top.",
                    "label": 0
                },
                {
                    "sent": "To prevent.",
                    "label": 0
                },
                {
                    "sent": "That it picks one best expert.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the update goes like this.",
                    "label": 0
                },
                {
                    "sent": "It's very intuitive.",
                    "label": 0
                },
                {
                    "sent": "You take your softmax.",
                    "label": 0
                },
                {
                    "sent": "If I would just do this update alone, it would go into the corner of the simplex.",
                    "label": 0
                },
                {
                    "sent": "Right, lots of variety.",
                    "label": 0
                },
                {
                    "sent": "Now comes the predator, the Predator says.",
                    "label": 0
                },
                {
                    "sent": "You project your weight vector onto the closest weight vector in the cap simplex, which restricts every every weight to be at most.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1 / M, which caps the weights.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, capital weights, so it's a capped simplex.",
                    "label": 0
                },
                {
                    "sent": "These corners correspond to the M sets.",
                    "label": 0
                },
                {
                    "sent": "Pick and now you can show that this algorithm for this algorithm the expected loss of the algorithm in the proof you're going to use the generalized Pythagorean theorem in an elementary way.",
                    "label": 0
                },
                {
                    "sent": "The expected loss of the algorithm is at most speakers, the last of the best M set.",
                    "label": 0
                },
                {
                    "sent": "Plus some square returns, but M + M log in.",
                    "label": 0
                },
                {
                    "sent": "Notice the number of M sets, the number of sets of size M subsets of M experts is huge.",
                    "label": 0
                },
                {
                    "sent": "It's N choose M, But the only punished by log of that which is still be well behaved.",
                    "label": 0
                },
                {
                    "sent": "It grows logarithmically in the dimension.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the M sets.",
                    "label": 0
                },
                {
                    "sent": "You can encode them this way.",
                    "label": 0
                },
                {
                    "sent": "They called em corners the convex Hull of em corners is actually equal to the capped a convex.",
                    "label": 1
                },
                {
                    "sent": "All of Em corners is equal to the probability simplex.",
                    "label": 0
                },
                {
                    "sent": "And actually if you give me one vector in the cap probability simplex, I can effectively decompose it as a convex combination of end corners.",
                    "label": 1
                },
                {
                    "sent": "This is promised by the current Aradori theorem, but you actually can effectively effectively do it.",
                    "label": 0
                },
                {
                    "sent": "So we choose a name corner according to this document decomposition.",
                    "label": 0
                },
                {
                    "sent": "There's alternates to capping.",
                    "label": 0
                },
                {
                    "sent": "You can do follow the leader.",
                    "label": 1
                },
                {
                    "sent": "It's cheap but inferior bounds.",
                    "label": 0
                },
                {
                    "sent": "You can also do a dynamic programming, which seems to be which is more expensive.",
                    "label": 0
                },
                {
                    "sent": "And some of these don't generalize to the Matrix case.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now so you lift this algorithm.",
                    "label": 0
                },
                {
                    "sent": "Did you just develop for the experts, adding to the matrix setting using the usual trick of generalizing?",
                    "label": 0
                },
                {
                    "sent": "Convex combinations, mixture vectors 2.",
                    "label": 0
                },
                {
                    "sent": "Density matrices, so you pick N -- K dimensional subspace based on the current density matrix you choose to comment a complementary subspace.",
                    "label": 1
                },
                {
                    "sent": "You receive an instance and then you incur this loss, which is equal to this trace and it's this.",
                    "label": 0
                },
                {
                    "sent": "Expect which corresponds to this expected loss, and then you update your thing.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The app.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It again has the same flavor, but except now with matrices, matrix logs and matrix exponentials and projections.",
                    "label": 0
                },
                {
                    "sent": "And these are very efficient to implement except for this step.",
                    "label": 0
                },
                {
                    "sent": "That's very expensive.",
                    "label": 0
                },
                {
                    "sent": "And we're looking for ways to make it more efficient.",
                    "label": 0
                },
                {
                    "sent": "Expected loss of the algorithm is now as good as the loss of the best case space chosen in hindsight hindsight.",
                    "label": 1
                },
                {
                    "sent": "Plus some square term plus K log N so PCA.",
                    "label": 0
                },
                {
                    "sent": "You can do it with millions of dimension.",
                    "label": 0
                },
                {
                    "sent": "It doesn't really matter the algorithm if you have time to run these algorithms, the generalization bounds are still extremely good.",
                    "label": 0
                },
                {
                    "sent": "They only pinned on the leg arhythmic on the dimension.",
                    "label": 0
                },
                {
                    "sent": "If you run PCA with this type of algorithm.",
                    "label": 0
                },
                {
                    "sent": "And W the dimension you're only going to, it's the amount of resources only go up by a constant, essentially very small, because if you if you do the additive.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Items you in trouble again, so there's again two families of updates you can regularize this way.",
                    "label": 1
                },
                {
                    "sent": "Then the weight vector is a linear combination of these outer product.",
                    "label": 0
                },
                {
                    "sent": "These are fast and kernel isable.",
                    "label": 1
                },
                {
                    "sent": "Again, this is another family of updates.",
                    "label": 0
                },
                {
                    "sent": "It's now E to the linear where this is the matrix exponential of this outer product.",
                    "label": 0
                },
                {
                    "sent": "OK. And.",
                    "label": 0
                },
                {
                    "sent": "And you get to this updates by Regularising with a quantum relative entropy, right?",
                    "label": 1
                },
                {
                    "sent": "And we're going to predict with a random project projection, mate, random projection matrix and the bounds of this here grow logarithmically with end was here.",
                    "label": 1
                },
                {
                    "sent": "They grow linear with at least linear within.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm very much fascinated by this by online updates for matrix parameters, in particular, generalizations of entropy and so forth, I think they're going to become important.",
                    "label": 0
                },
                {
                    "sent": "Basically, I'm trying to lift.",
                    "label": 0
                },
                {
                    "sent": "Machine learning from using vector parameters to matrix parameters.",
                    "label": 0
                },
                {
                    "sent": "The shifting methodology carries over that.",
                    "label": 1
                },
                {
                    "sent": "I talked about this morning in the context of caching.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "For example, you can do it for this case immediately, so if you do online PCA and your data shifts overtime, everything carries over.",
                    "label": 0
                },
                {
                    "sent": "I need to do extensive experiments and I'm kind of fascinated by sort of the blessing and the curse of the multiplicative update.",
                    "label": 1
                },
                {
                    "sent": "They're very fast, but they lose variety very fast and you need to do tricks.",
                    "label": 0
                },
                {
                    "sent": "This morning I talked about lower bounds on the weights.",
                    "label": 0
                },
                {
                    "sent": "Right for shifting?",
                    "label": 0
                },
                {
                    "sent": "Here talk about upper bounds of the weights to preserve variety to do it.",
                    "label": 0
                },
                {
                    "sent": "They do as well as a variety of different things.",
                    "label": 1
                },
                {
                    "sent": "OK. And actually, underlying all of this is a probability calculus for density matrices, which generalizes the normal probability calculus.",
                    "label": 0
                },
                {
                    "sent": "It was done already in quantum physics to some to some extent, but I invented a Bayes rule that goes along with it, and now I think we have the beginnings of abrasion.",
                    "label": 0
                },
                {
                    "sent": "Probability theory for density matrices and I'm going to talk about that tomorrow, so you will get a sense of where this is headed.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 1
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So I started taking compression on one of the previous sites.",
                    "label": 0
                },
                {
                    "sent": "We have Jager isms for the online PCA.",
                    "label": 0
                },
                {
                    "sent": "Think about 2 three steps.",
                    "label": 0
                },
                {
                    "sent": "First, when here first compute the value happens key.",
                    "label": 0
                },
                {
                    "sent": "I would.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just as an aside, the result of a mutation.",
                    "label": 0
                },
                {
                    "sent": "Yes, it's a softmax.",
                    "label": 0
                },
                {
                    "sent": "A generalization of softmax.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes.",
                    "label": 0
                },
                {
                    "sent": "This is that that the projection matrix is done at.",
                    "label": 0
                },
                {
                    "sent": "The projection is done as follows.",
                    "label": 0
                },
                {
                    "sent": "You do you do the eigendecomposition of this and then you do the projection algorithm based just on that eigenvector.",
                    "label": 0
                },
                {
                    "sent": "And what you do is you look at the eigen vector and assume.",
                    "label": 0
                },
                {
                    "sent": "Let's say you're capping at half and you have one vector that is bigger than 1/2.",
                    "label": 0
                },
                {
                    "sent": "Then let's say 1/3.",
                    "label": 0
                },
                {
                    "sent": "Then it's more interesting you have two ones that are bigger than 1/3, you push them down.",
                    "label": 0
                },
                {
                    "sent": "And then sum up the remaining weights.",
                    "label": 0
                },
                {
                    "sent": "Have to be really normalized, and essentially there's a little bit of a binary search, because sometimes when you push some things down, other things pop up over the limit, so you need to find sort of the minimum number of things that you have to push down so that everybody stays below.",
                    "label": 0
                },
                {
                    "sent": "It's a very intuitive algorithm.",
                    "label": 0
                },
                {
                    "sent": "You can do it with binary search or with something like that, or you can actually do it in linear using linear time using the median algorithm.",
                    "label": 0
                },
                {
                    "sent": "So it's not a complicated thing you do kind of.",
                    "label": 0
                },
                {
                    "sent": "The most obvious thing you look at, the eigenvectors, eigenvalues, and you the topmost guy.",
                    "label": 0
                },
                {
                    "sent": "If it's above the limit, push it down, maybe an renormalizing if it's.",
                    "label": 0
                },
                {
                    "sent": "If it's still if everybody stays below you, keep on going and not be load and keep on going until you have the right number.",
                    "label": 0
                },
                {
                    "sent": "This is sort of this is the kind of algorithm you need.",
                    "label": 0
                },
                {
                    "sent": "It's not very complicated.",
                    "label": 0
                },
                {
                    "sent": "I can show you on a piece of paper very quickly.",
                    "label": 0
                },
                {
                    "sent": "So this projection algorithm is not very expensive once you have the icon decomposition.",
                    "label": 0
                },
                {
                    "sent": "But this is extremely expensive because you have to compute eigen decompositions.",
                    "label": 0
                },
                {
                    "sent": "And at this point I don't know how to avoid it yet we're working on it.",
                    "label": 0
                },
                {
                    "sent": "It might not be possible, I don't know.",
                    "label": 0
                },
                {
                    "sent": "It's a very sophisticated thing.",
                    "label": 0
                },
                {
                    "sent": "You have to keep track of uncertainty in all possible directions.",
                    "label": 0
                },
                {
                    "sent": "Maybe it cannot be simplified, I don't know.",
                    "label": 0
                },
                {
                    "sent": "It certainly is completely mathematically elegant.",
                    "label": 0
                },
                {
                    "sent": "I was extremely surprised that there is this generalization and the bounds sort of rather immediately generalizes.",
                    "label": 0
                },
                {
                    "sent": "You have to.",
                    "label": 0
                },
                {
                    "sent": "Look for this generalizations of Jensen's inequality and there's something called a Golden Thompson inequality.",
                    "label": 0
                },
                {
                    "sent": "But to do statistical physicists, this is rather standard, we just had to learn it.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Here comes cooner.",
                    "label": 0
                }
            ]
        }
    }
}