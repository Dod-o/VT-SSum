{
    "id": "loeve6lyuh4fj5ee23uhv6dqwhs2tgws",
    "title": "Group-level Arousal and Valence Recognition in Static Images: Face, Body and Context",
    "info": {
        "author": [
            "Wenxuan Mou, School of Electronics Engineering and Computer Science, Peking University"
        ],
        "published": "July 2, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis"
        ]
    },
    "url": "http://videolectures.net/fgconference2015_mou_static_images/",
    "segmentation": [
        [
            "I'm wishing from Queen Mary, University of London.",
            "This is my master's work and with Doctor Oil and Hartage.",
            "Today I'm going to talk about growth level, arousal and valence recognition is dirty static images, face, body and context.",
            "As we all know, there meant a lot of applications for emotion recognition, for example."
        ],
        [
            "In the learning context, teacher can know whether students are fair bought in the retail context.",
            "Supermarket wants to know whether.",
            "Customers are satisfied with this product.",
            "Also for image retrieval.",
            "Recently there are some work mode for."
        ],
        [
            "The individual emotion to group emotion recognition.",
            "Adore at all.",
            "Did group hapiness intense intensity analysis.",
            "Here they did like analyzed the group hapiness intensity.",
            "They also."
        ],
        [
            "Another work which is similar to our work and Roland, I think have presented it Wednesday.",
            "So we all collected a new data set for a group emotion analyze this and we all use the face features and content feature, but also there's some differences.",
            "For example, the context, different and.",
            "We did an analysis in both arousal and balance dimensions.",
            "The classifier also different."
        ],
        [
            "Why are we going to collect a data set?",
            "Cause as we are going to do group emotions, so for emotion regulation we need various emotions in the database and for group emotion we need multiple people on each image.",
            "We tried to collect images that emotion that are as spontaneous as possible.",
            "There are quite a few of databases that are used for emotion recognition, for example.",
            "Take facial expression in the wild, but it it has various emotions but only single person on each image and annotated facing the wild multiple people that know various emotions for happy people images the same problem, multiple people, but all people are happy a so we."
        ],
        [
            "So we collected the new database from the Internet.",
            "Here are two in."
        ],
        [
            "Examples from this database may consider the most we trust.",
            "We said we try to make it as spontaneous as possible for each image was annotated by 15 Reuters along arousal and valence dimensions here."
        ],
        [
            "On sample for the questionnaire to do annotation, they were asked to choose one from violence and one from activity.",
            "Violence include positive, neutral, negative and activity from high medium to low.",
            "After we collected the.",
            "Feedback we did because we have 15 laborers in for each image we did the interrater agreement.",
            "We can see from here the."
        ],
        [
            "Result is quite good, especially for violence is better than arousal.",
            "Yeah, because for violence for negative or positive is much easier to get agreement for different people, but for arousal may different people may have different ideas.",
            "Specially we have media.",
            "Some people may claim this is high, some people may say this is media."
        ],
        [
            "Four theories for group emotion.",
            "Unless we have unit can be divided into 2.",
            "First one is top down, once bottom up for top down we take group as a whole.",
            "Use group level information, bottom up its group emotion as some of the parts.",
            "So start from individuals.",
            "Into the group."
        ],
        [
            "Our method, so we have images with multiple people and we first did face detection with using interface.",
            "After we hear."
        ],
        [
            "We have four faces and then we did fish."
        ],
        [
            "Is alignment and normalization extracted?"
        ],
        [
            "Features from faces and we also."
        ],
        [
            "Health."
        ],
        [
            "In"
        ],
        [
            "Body features after we get the body up, body is like this.",
            "My rectangle in this figure we extracted low level body feature from the upper body and we also get the context feature.",
            "The detail will be given about the context feature later.",
            "Uh, after?"
        ],
        [
            "Feature is her traction.",
            "We have the classification using the K nearest number."
        ],
        [
            "02 feature extraction.",
            "We we have three kind of features, face, body and context.",
            "First full face."
        ],
        [
            "We have appearance and geometric feature.",
            "Appearance feature is divided into global and local global feature experience feature is extracted from the whole face for local on because most of facial expressions can be got from the from I under mouse.",
            "So we also extracted local appearance feature for geometric.",
            "We have the official we have already got the Fishel points using interface.",
            "So we calculated 11 distance distances as our geometric feature.",
            "The next."
        ],
        [
            "What is body feature for?",
            "First we get the upper body, we get the upper body like this one we based on the face detector detection without gather upper body and then we expect."
        ],
        [
            "Dictated the heist."
        ],
        [
            "Drama oriented gradients from each upper body.",
            "After"
        ],
        [
            "And then it's the context contact."
        ],
        [
            "Feature here as we already have the upper body, we first get the regular bounding box, which is the minimum.",
            "Box that can include all upper body upper bodies.",
            "This feature can be divided into 2 parts.",
            "The first one is the.",
            "Each body is relative location and scale with respect to bounding box.",
            "The second one is the bounding box relative scale and location with respect to the whole image."
        ],
        [
            "So after feature extraction within the classification, we divided all images into three groups based on number of faces.",
            "Associates two faces, three faces and formal faces, and we do it in this way to guarantee that we have the same size of feature in each group and we also want to see whether different features will performance different performed different in in.",
            "With with the images with different number of faces for classifier we use the key news number.",
            "We did.",
            "Experiments can be divided into 2 parts.",
            "The first one is individual dimension valence.",
            "All arousal the 2nd way.",
            "The combined of these two dimensions.",
            "In the first part it can we have three experiments, each each feature separately and pairwise feature with decision Fusion or features with decision Fusion."
        ],
        [
            "From this is the first experiment result.",
            "We can see different feature performance performs different.",
            "Different groups.",
            "Then we consider the pairwise."
        ],
        [
            "This feature it is still not that easy to get a conclusion, but we can see the context feature context feature like.",
            "Improved a little bit from the performance.",
            "Then with all fish."
        ],
        [
            "Shirts, decision field and we have face feature content featuring body face features.",
            "Are geometric and local appearance and global appearance.",
            "We can see the most of the best result is from after we added the body or context or both of them."
        ],
        [
            "To the combined dimension.",
            "We also did the feature face feature content feature Board feature.",
            "First we do it separately and then we combine each to the adult content feature and then body feature and then combine them together.",
            "We can see after Adda one body feature or context feature of them together they all improve the performance from the mean value we can see.",
            "Oh, here is."
        ],
        [
            "Two representative results for the.",
            "Recognition result.",
            "The first one is high arousal and positive balance.",
            "Here is one is high arousal and negative balance.",
            "We also tested on Anthem video.",
            "We trained it with a static image but this was detected, tested with frame by frame.",
            "We can see if it's not very clear.",
            "We detect the face of different number of people.",
            "We can see the result from the left top corner.",
            "Here is more people.",
            "OK.",
            "I want to show you some result OK, like this one.",
            "We can see the medium point positive there even we have more people later.",
            "We can help three or four people, but here I can't take drag it to the end.",
            "OK."
        ],
        [
            "Oh, conclusion and future work for conclusion we we collected in you database for group emotion detection and we did a group automatic group emotion detection along arousal and valence dimensions.",
            "We used a context and body hog.",
            "Feature was used for grouping motion detection for future work.",
            "Um?",
            "We can do feature Fusion before we can do feature selection before filling and classification and experiment with more sophisticated classifier will be tried.",
            "The last one will we need to?",
            "We will test it on the larger database.",
            "Thing."
        ],
        [
            "Cute."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm wishing from Queen Mary, University of London.",
                    "label": 1
                },
                {
                    "sent": "This is my master's work and with Doctor Oil and Hartage.",
                    "label": 0
                },
                {
                    "sent": "Today I'm going to talk about growth level, arousal and valence recognition is dirty static images, face, body and context.",
                    "label": 1
                },
                {
                    "sent": "As we all know, there meant a lot of applications for emotion recognition, for example.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the learning context, teacher can know whether students are fair bought in the retail context.",
                    "label": 1
                },
                {
                    "sent": "Supermarket wants to know whether.",
                    "label": 0
                },
                {
                    "sent": "Customers are satisfied with this product.",
                    "label": 0
                },
                {
                    "sent": "Also for image retrieval.",
                    "label": 0
                },
                {
                    "sent": "Recently there are some work mode for.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The individual emotion to group emotion recognition.",
                    "label": 1
                },
                {
                    "sent": "Adore at all.",
                    "label": 0
                },
                {
                    "sent": "Did group hapiness intense intensity analysis.",
                    "label": 0
                },
                {
                    "sent": "Here they did like analyzed the group hapiness intensity.",
                    "label": 0
                },
                {
                    "sent": "They also.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another work which is similar to our work and Roland, I think have presented it Wednesday.",
                    "label": 0
                },
                {
                    "sent": "So we all collected a new data set for a group emotion analyze this and we all use the face features and content feature, but also there's some differences.",
                    "label": 0
                },
                {
                    "sent": "For example, the context, different and.",
                    "label": 0
                },
                {
                    "sent": "We did an analysis in both arousal and balance dimensions.",
                    "label": 0
                },
                {
                    "sent": "The classifier also different.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why are we going to collect a data set?",
                    "label": 0
                },
                {
                    "sent": "Cause as we are going to do group emotions, so for emotion regulation we need various emotions in the database and for group emotion we need multiple people on each image.",
                    "label": 1
                },
                {
                    "sent": "We tried to collect images that emotion that are as spontaneous as possible.",
                    "label": 0
                },
                {
                    "sent": "There are quite a few of databases that are used for emotion recognition, for example.",
                    "label": 0
                },
                {
                    "sent": "Take facial expression in the wild, but it it has various emotions but only single person on each image and annotated facing the wild multiple people that know various emotions for happy people images the same problem, multiple people, but all people are happy a so we.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we collected the new database from the Internet.",
                    "label": 0
                },
                {
                    "sent": "Here are two in.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Examples from this database may consider the most we trust.",
                    "label": 0
                },
                {
                    "sent": "We said we try to make it as spontaneous as possible for each image was annotated by 15 Reuters along arousal and valence dimensions here.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On sample for the questionnaire to do annotation, they were asked to choose one from violence and one from activity.",
                    "label": 0
                },
                {
                    "sent": "Violence include positive, neutral, negative and activity from high medium to low.",
                    "label": 0
                },
                {
                    "sent": "After we collected the.",
                    "label": 0
                },
                {
                    "sent": "Feedback we did because we have 15 laborers in for each image we did the interrater agreement.",
                    "label": 0
                },
                {
                    "sent": "We can see from here the.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Result is quite good, especially for violence is better than arousal.",
                    "label": 0
                },
                {
                    "sent": "Yeah, because for violence for negative or positive is much easier to get agreement for different people, but for arousal may different people may have different ideas.",
                    "label": 0
                },
                {
                    "sent": "Specially we have media.",
                    "label": 0
                },
                {
                    "sent": "Some people may claim this is high, some people may say this is media.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Four theories for group emotion.",
                    "label": 1
                },
                {
                    "sent": "Unless we have unit can be divided into 2.",
                    "label": 0
                },
                {
                    "sent": "First one is top down, once bottom up for top down we take group as a whole.",
                    "label": 0
                },
                {
                    "sent": "Use group level information, bottom up its group emotion as some of the parts.",
                    "label": 0
                },
                {
                    "sent": "So start from individuals.",
                    "label": 0
                },
                {
                    "sent": "Into the group.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our method, so we have images with multiple people and we first did face detection with using interface.",
                    "label": 0
                },
                {
                    "sent": "After we hear.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have four faces and then we did fish.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is alignment and normalization extracted?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Features from faces and we also.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Health.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Body features after we get the body up, body is like this.",
                    "label": 0
                },
                {
                    "sent": "My rectangle in this figure we extracted low level body feature from the upper body and we also get the context feature.",
                    "label": 0
                },
                {
                    "sent": "The detail will be given about the context feature later.",
                    "label": 0
                },
                {
                    "sent": "Uh, after?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Feature is her traction.",
                    "label": 0
                },
                {
                    "sent": "We have the classification using the K nearest number.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "02 feature extraction.",
                    "label": 0
                },
                {
                    "sent": "We we have three kind of features, face, body and context.",
                    "label": 1
                },
                {
                    "sent": "First full face.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have appearance and geometric feature.",
                    "label": 0
                },
                {
                    "sent": "Appearance feature is divided into global and local global feature experience feature is extracted from the whole face for local on because most of facial expressions can be got from the from I under mouse.",
                    "label": 0
                },
                {
                    "sent": "So we also extracted local appearance feature for geometric.",
                    "label": 0
                },
                {
                    "sent": "We have the official we have already got the Fishel points using interface.",
                    "label": 0
                },
                {
                    "sent": "So we calculated 11 distance distances as our geometric feature.",
                    "label": 0
                },
                {
                    "sent": "The next.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is body feature for?",
                    "label": 0
                },
                {
                    "sent": "First we get the upper body, we get the upper body like this one we based on the face detector detection without gather upper body and then we expect.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dictated the heist.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Drama oriented gradients from each upper body.",
                    "label": 0
                },
                {
                    "sent": "After",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then it's the context contact.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Feature here as we already have the upper body, we first get the regular bounding box, which is the minimum.",
                    "label": 0
                },
                {
                    "sent": "Box that can include all upper body upper bodies.",
                    "label": 0
                },
                {
                    "sent": "This feature can be divided into 2 parts.",
                    "label": 0
                },
                {
                    "sent": "The first one is the.",
                    "label": 0
                },
                {
                    "sent": "Each body is relative location and scale with respect to bounding box.",
                    "label": 0
                },
                {
                    "sent": "The second one is the bounding box relative scale and location with respect to the whole image.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So after feature extraction within the classification, we divided all images into three groups based on number of faces.",
                    "label": 1
                },
                {
                    "sent": "Associates two faces, three faces and formal faces, and we do it in this way to guarantee that we have the same size of feature in each group and we also want to see whether different features will performance different performed different in in.",
                    "label": 0
                },
                {
                    "sent": "With with the images with different number of faces for classifier we use the key news number.",
                    "label": 0
                },
                {
                    "sent": "We did.",
                    "label": 0
                },
                {
                    "sent": "Experiments can be divided into 2 parts.",
                    "label": 0
                },
                {
                    "sent": "The first one is individual dimension valence.",
                    "label": 0
                },
                {
                    "sent": "All arousal the 2nd way.",
                    "label": 0
                },
                {
                    "sent": "The combined of these two dimensions.",
                    "label": 0
                },
                {
                    "sent": "In the first part it can we have three experiments, each each feature separately and pairwise feature with decision Fusion or features with decision Fusion.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From this is the first experiment result.",
                    "label": 0
                },
                {
                    "sent": "We can see different feature performance performs different.",
                    "label": 0
                },
                {
                    "sent": "Different groups.",
                    "label": 0
                },
                {
                    "sent": "Then we consider the pairwise.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This feature it is still not that easy to get a conclusion, but we can see the context feature context feature like.",
                    "label": 0
                },
                {
                    "sent": "Improved a little bit from the performance.",
                    "label": 0
                },
                {
                    "sent": "Then with all fish.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Shirts, decision field and we have face feature content featuring body face features.",
                    "label": 0
                },
                {
                    "sent": "Are geometric and local appearance and global appearance.",
                    "label": 0
                },
                {
                    "sent": "We can see the most of the best result is from after we added the body or context or both of them.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To the combined dimension.",
                    "label": 0
                },
                {
                    "sent": "We also did the feature face feature content feature Board feature.",
                    "label": 0
                },
                {
                    "sent": "First we do it separately and then we combine each to the adult content feature and then body feature and then combine them together.",
                    "label": 0
                },
                {
                    "sent": "We can see after Adda one body feature or context feature of them together they all improve the performance from the mean value we can see.",
                    "label": 0
                },
                {
                    "sent": "Oh, here is.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two representative results for the.",
                    "label": 0
                },
                {
                    "sent": "Recognition result.",
                    "label": 0
                },
                {
                    "sent": "The first one is high arousal and positive balance.",
                    "label": 0
                },
                {
                    "sent": "Here is one is high arousal and negative balance.",
                    "label": 0
                },
                {
                    "sent": "We also tested on Anthem video.",
                    "label": 0
                },
                {
                    "sent": "We trained it with a static image but this was detected, tested with frame by frame.",
                    "label": 0
                },
                {
                    "sent": "We can see if it's not very clear.",
                    "label": 0
                },
                {
                    "sent": "We detect the face of different number of people.",
                    "label": 0
                },
                {
                    "sent": "We can see the result from the left top corner.",
                    "label": 0
                },
                {
                    "sent": "Here is more people.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I want to show you some result OK, like this one.",
                    "label": 0
                },
                {
                    "sent": "We can see the medium point positive there even we have more people later.",
                    "label": 0
                },
                {
                    "sent": "We can help three or four people, but here I can't take drag it to the end.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh, conclusion and future work for conclusion we we collected in you database for group emotion detection and we did a group automatic group emotion detection along arousal and valence dimensions.",
                    "label": 0
                },
                {
                    "sent": "We used a context and body hog.",
                    "label": 0
                },
                {
                    "sent": "Feature was used for grouping motion detection for future work.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We can do feature Fusion before we can do feature selection before filling and classification and experiment with more sophisticated classifier will be tried.",
                    "label": 0
                },
                {
                    "sent": "The last one will we need to?",
                    "label": 0
                },
                {
                    "sent": "We will test it on the larger database.",
                    "label": 0
                },
                {
                    "sent": "Thing.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cute.",
                    "label": 0
                }
            ]
        }
    }
}