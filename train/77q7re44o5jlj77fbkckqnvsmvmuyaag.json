{
    "id": "77q7re44o5jlj77fbkckqnvsmvmuyaag",
    "title": "Geographica: A Benchmark for Geospatial RDF Stores",
    "info": {
        "author": [
            "George Garbis, Department of Informatics and Telecommunications, National and Kapodistrian University of Athens Panepistimiopolis"
        ],
        "published": "Nov. 28, 2013",
        "recorded": "October 2013",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Databases"
        ]
    },
    "url": "http://videolectures.net/iswc2013_garbis_geographica/",
    "segmentation": [
        [
            "And those are base and I will present you geographica.",
            "Benchmark forager specialty stores that they have developed with my colleagues.",
            "Discuss Rocco's who sits over there and manage barracks, who, unfortunately, is not with us.",
            "So first I will discuss."
        ],
        [
            "Motivation of creating such a benchmark.",
            "Then I will describe geographica and how it was used to evaluate three well known RDF stores.",
            "And finally I will summarize their presentation."
        ],
        [
            "So the web of data has recently started being populated with a lot of Ledger, special data and lots of it is transformed into a link to data and used to build applications.",
            "Additional sparkle has been extended to support the spatial queries with Spark standard or other extensions like Estes Park and that these stores have started their providing support for Edge Park or a limited the special functionality."
        ],
        [
            "However, these advances have not yet been matched with a lot of work in evaluating and the benchmarking of RDF source.",
            "So to evaluate this new generation of hardware stores, we have implemented geographica that is organized around two workloads with their queries in their data sets.",
            "The real workload that is based on existing a link for spatial datasets and the typical application scenarios and the synthetic workloads that.",
            "Good generates data set so far, better says and allows us to play with the selectivity of the tested queries."
        ],
        [
            "So let's continue with describing the real world work."
        ],
        [
            "Code it consists of real datasets about David Geographic Area of Greece that either play an important role in a linked open data cloud, like a link to date as your names in the pedia, or they have complex geometry's like a administrative geography or the land cover of Greece or fire hot spots that have been detected by the National Observatory of Athens."
        ],
        [
            "Every data set has a specific geometry type, so John aims at the pedia have only points links of data.",
            "We keep only the lines of the data set well.",
            "The rest three datasets have polygons of a various complexity and cardinalities."
        ],
        [
            "This workload is organized into two parts, the micro part that tests primitive special functions, naturalization, and the macro part that tests the performance.",
            "In a typical application scenarios."
        ],
        [
            "The real part consists of 29 queries that have only one or two triple patterns, and the special function that we want to test the tested functions include non topological functions, for example, compute the boundary of a Polygon.",
            "Topological functions such as check if two polygons intersect with each other and special aggregates.",
            "For example, I compute the union of many polygons.",
            "The topological functions have also been tested both for special selections and special joins."
        ],
        [
            "Let's see some examples of these queries to understand better this part of the benchmark.",
            "This is a typical query testing and on topological function that retrieves geometries from the core in land cover data set and computes the boundaries of this polygons."
        ],
        [
            "Another example of this parcel selection query asks for points in the geonames data set that are within a given Polygon."
        ],
        [
            "And finally, a special joint example that asks for a polygons from the data set of the datasets of the Greek administrative geography and the code in land cover that overlaps with each other."
        ],
        [
            "Just to get an idea, these are the special functions that we have tested and combinations between the geometry types.",
            "Of course we couldn't check all the possible combinations because they are too many, but we tried to select a representative subset of the combinations that are possible."
        ],
        [
            "Continuing with the macro part of the real world workload, we have defined the test three scenarios.",
            "The first is reversible coding, which refers to the process of attributing a place name and the street address to a given point.",
            "The."
        ],
        [
            "Second scenario tests a queries that are typically used in web based map Asian map applications."
        ],
        [
            "And the file on a scenario is a bit more complex and tasks typical rapid mapping tasks that are carried by by space agencies during emergencies.",
            "Now."
        ],
        [
            "Now, let's continue with the synthetic workload."
        ],
        [
            "The goal of this workload is to evaluate the performance of our dev stores in a controlled environment when we can play around with pneumatic and the spatial selectivity of queries, we define thematic selectivity as the fraction of the total geographical features of a data set that satisfy the non special part of the query.",
            "While we define spatial selectivity as the fraction of the features that satisfy at topological relation in the final close of querying."
        ],
        [
            "For this workload we have developed a generator that produces datasets that resemble a geographic feature and synthetic map.",
            "So we have four datasets.",
            "The first 2 have hexagons that resembles states in a country and land ownerships, and we also have a data set with lines that resembles the roads and data set for a point of interest."
        ],
        [
            "And we have also developed a minimal ontology.",
            "For a for its data set that the follows, the scheme of Openstreetmap using Cages Park vocabulary according to the schema of Openstreetmap, every feature is target with some key value pairs of strings and actually we tag every feature with key one.",
            "Every second feature with key 2, every fourth with key four and so on.",
            "And this a tagging allows us to select in a uniform way part of the data sets and so form queries of various arithmetical selectivities.",
            "For example, if we set it to equals to one, we select the whole data set.",
            "If we set, it equals to two, we select half of the data set and so on."
        ],
        [
            "For this workload we have tested this partial selection queries that are created based to this template.",
            "The parameters of the template allows us to select a specific data set, which means a specific geometry type that we want to examine.",
            "The function that we're going to examine and also the parameters Thelma and Zero allows us to define the thematic and this possibility for query and we also."
        ],
        [
            "I've tested this partial joins an according to this template, which is similar to the previous allows us to select two datasets and define the mattick selectivity of its data set.",
            "And of course the function to examine."
        ],
        [
            "Now let's continue with how the benchmark was used to evaluate three RDF stores and some results of evaluating."
        ],
        [
            "We used it to evaluate this trouble in Parliament and user came for the micro part of the real world workload and the synthetic workload.",
            "We measured the response time for its query.",
            "We run its query 3 times and compute the median of the response times.",
            "We also set the time out of one hour for the evaluation of each query and we took measurements both for warm and cold cases.",
            "Well for the macro part we run many instantiation to fix query for run now.",
            "Without cleaning the gases and we measured the average time for a complete execution of its query."
        ],
        [
            "So these are a response times of the micro part of the benchmark.",
            "In general, we observe that the user comments Robin have a similar response times regarding evaluation of non topological functions and special selections in specific user came is is faster in evaluating and topological functions and this is reasonable because it uses the native store of Sesame which is known to be more efficient for small datasets than implementations of sesame oil.",
            "For a DBMS likes trouble.",
            "While there for their special selections, you see, Kim evaluates the special part of the query imposture yes, and the thematic part in in size.",
            "How many native services coming so this adds a small overhead in comparison to struggle, who evaluates the whole query in Bossier, yes, unit utilizing a unified dictionary scheme both for a thematic and spatial informations.",
            "An while the optimizer of Parliament focuses only on.",
            "The graph patterns and doesn't optimize filters with just park layer functions, so its response times is about an order of magnitude higher.",
            "While there for joint use equipment, Parliament evaluates the Cartesian product of the graph patterns and then they check the topological relation exhaustively over the over the intermediate results.",
            "So they didn't answer the majority of special joins within the time limit of 1 now.",
            "And finally, special aggregates are tested only in trouble because they are not defined by George Park but by the Estes Park query language which is supported only by Straubel."
        ],
        [
            "These are the results of the macro part of every benchmark in general.",
            "Again, we can observe that use it came is the fastest system for the scenarios.",
            "Reverser coding, entire map search and browsing well, while the final scenario, which is more complex and has a complex spatial joins, he can only be served by trouble because the other systems need more than one hour to answer some queries."
        ],
        [
            "Now, let's continue with the.",
            "With the results of the synthetic workload, we generated the data set of about four million triples that contains around 300,000 geometry's."
        ],
        [
            "These are resume.",
            "These are some results of this partial selection queries that we have tested.",
            "We tested the topological relation intersect for the left graph of the left graph.",
            "We use the queries that have non special part that selects the whole data set so they have a low thematic selectivity well for the right graph we have queries with high selectivity, highly thematic selectivity that selects two per thousand of am of the data set.",
            "And the the this partial selective the queries is depicted on the X axis of the images.",
            "So we observe that the response times of usage game increases, while in this partial selectivity of the greatest increase and this happened 'cause you see, Kim always starts by evaluating the special part of the query and then continues with mathematic.",
            "On the other hand.",
            "It's Robin which exploits fully exploits the selectivity.",
            "Estimation of posteriors is able to alter the evaluation plans of a query when the non special part of the query becomes more selective than this partial and so that saves a better response times."
        ],
        [
            "Continuing with some results of a special joints of the synthetic workload, we can see again that the strategy that you scam and Parliament follows of evaluating the Cartesian product of the active stores has as a result to have high response times.",
            "For example, a Parliament answers within the time limit of one hour only.",
            "The joints that have very high thematic selectivity.",
            "While you see Kim has response times about one order.",
            "Wanted more than Scrabble, however, we can see that there are some cases that this strategy becomes efficient.",
            "For example, when the thematic selectivity becomes very high.",
            "Struggled with stores.",
            "Also mattress in a single table produces many intermediate results that later will be discarded by the by the graph patterns.",
            "So the strategy that you seek, Amy follows becomes better and outperforms.",
            "Performance is trouble.",
            "Soto."
        ],
        [
            "To summarize the presentation, we have defined the geographic a comprehensive benchmark for edge, especially if source.",
            "The benchmark consists of two workloads.",
            "The first one gives us an inside of how the RDF stores could perform in real cases where the second workload.",
            "Gives us a better inside for implementation details of the other stores.",
            "We use the Benchmarker also to compare three relevant active stores struggle in Parliament and use them."
        ],
        [
            "As a future work, we could consider expanding the benchmark to capture the full edges Parker Standard.",
            "We could also start the scaling keys you save with larger datasets or add more application scenarios.",
            "And another thing that could be done is to extend it generator to produce datasets that do not allow.",
            "Do not follow a uniform distribution, but something more special.",
            "And finally extend the benchmark to include not only simple the special data but time evolving their special data.",
            "If you want to find more information and specifically in limitation details about the benchmark, you can visit our side.",
            "This work has been done in the context of the European project values that has just finished.",
            "And."
        ],
        [
            "Are all invited to visit us to show our demo about visualizing time evolving, telling to special data.",
            "Thank you very much for going soon."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And those are base and I will present you geographica.",
                    "label": 0
                },
                {
                    "sent": "Benchmark forager specialty stores that they have developed with my colleagues.",
                    "label": 0
                },
                {
                    "sent": "Discuss Rocco's who sits over there and manage barracks, who, unfortunately, is not with us.",
                    "label": 0
                },
                {
                    "sent": "So first I will discuss.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Motivation of creating such a benchmark.",
                    "label": 0
                },
                {
                    "sent": "Then I will describe geographica and how it was used to evaluate three well known RDF stores.",
                    "label": 1
                },
                {
                    "sent": "And finally I will summarize their presentation.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the web of data has recently started being populated with a lot of Ledger, special data and lots of it is transformed into a link to data and used to build applications.",
                    "label": 0
                },
                {
                    "sent": "Additional sparkle has been extended to support the spatial queries with Spark standard or other extensions like Estes Park and that these stores have started their providing support for Edge Park or a limited the special functionality.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, these advances have not yet been matched with a lot of work in evaluating and the benchmarking of RDF source.",
                    "label": 0
                },
                {
                    "sent": "So to evaluate this new generation of hardware stores, we have implemented geographica that is organized around two workloads with their queries in their data sets.",
                    "label": 1
                },
                {
                    "sent": "The real workload that is based on existing a link for spatial datasets and the typical application scenarios and the synthetic workloads that.",
                    "label": 1
                },
                {
                    "sent": "Good generates data set so far, better says and allows us to play with the selectivity of the tested queries.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's continue with describing the real world work.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Code it consists of real datasets about David Geographic Area of Greece that either play an important role in a linked open data cloud, like a link to date as your names in the pedia, or they have complex geometry's like a administrative geography or the land cover of Greece or fire hot spots that have been detected by the National Observatory of Athens.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Every data set has a specific geometry type, so John aims at the pedia have only points links of data.",
                    "label": 0
                },
                {
                    "sent": "We keep only the lines of the data set well.",
                    "label": 0
                },
                {
                    "sent": "The rest three datasets have polygons of a various complexity and cardinalities.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This workload is organized into two parts, the micro part that tests primitive special functions, naturalization, and the macro part that tests the performance.",
                    "label": 0
                },
                {
                    "sent": "In a typical application scenarios.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The real part consists of 29 queries that have only one or two triple patterns, and the special function that we want to test the tested functions include non topological functions, for example, compute the boundary of a Polygon.",
                    "label": 1
                },
                {
                    "sent": "Topological functions such as check if two polygons intersect with each other and special aggregates.",
                    "label": 0
                },
                {
                    "sent": "For example, I compute the union of many polygons.",
                    "label": 1
                },
                {
                    "sent": "The topological functions have also been tested both for special selections and special joins.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see some examples of these queries to understand better this part of the benchmark.",
                    "label": 0
                },
                {
                    "sent": "This is a typical query testing and on topological function that retrieves geometries from the core in land cover data set and computes the boundaries of this polygons.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another example of this parcel selection query asks for points in the geonames data set that are within a given Polygon.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, a special joint example that asks for a polygons from the data set of the datasets of the Greek administrative geography and the code in land cover that overlaps with each other.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to get an idea, these are the special functions that we have tested and combinations between the geometry types.",
                    "label": 0
                },
                {
                    "sent": "Of course we couldn't check all the possible combinations because they are too many, but we tried to select a representative subset of the combinations that are possible.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Continuing with the macro part of the real world workload, we have defined the test three scenarios.",
                    "label": 1
                },
                {
                    "sent": "The first is reversible coding, which refers to the process of attributing a place name and the street address to a given point.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Second scenario tests a queries that are typically used in web based map Asian map applications.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the file on a scenario is a bit more complex and tasks typical rapid mapping tasks that are carried by by space agencies during emergencies.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, let's continue with the synthetic workload.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The goal of this workload is to evaluate the performance of our dev stores in a controlled environment when we can play around with pneumatic and the spatial selectivity of queries, we define thematic selectivity as the fraction of the total geographical features of a data set that satisfy the non special part of the query.",
                    "label": 0
                },
                {
                    "sent": "While we define spatial selectivity as the fraction of the features that satisfy at topological relation in the final close of querying.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For this workload we have developed a generator that produces datasets that resemble a geographic feature and synthetic map.",
                    "label": 1
                },
                {
                    "sent": "So we have four datasets.",
                    "label": 0
                },
                {
                    "sent": "The first 2 have hexagons that resembles states in a country and land ownerships, and we also have a data set with lines that resembles the roads and data set for a point of interest.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we have also developed a minimal ontology.",
                    "label": 0
                },
                {
                    "sent": "For a for its data set that the follows, the scheme of Openstreetmap using Cages Park vocabulary according to the schema of Openstreetmap, every feature is target with some key value pairs of strings and actually we tag every feature with key one.",
                    "label": 0
                },
                {
                    "sent": "Every second feature with key 2, every fourth with key four and so on.",
                    "label": 0
                },
                {
                    "sent": "And this a tagging allows us to select in a uniform way part of the data sets and so form queries of various arithmetical selectivities.",
                    "label": 1
                },
                {
                    "sent": "For example, if we set it to equals to one, we select the whole data set.",
                    "label": 0
                },
                {
                    "sent": "If we set, it equals to two, we select half of the data set and so on.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For this workload we have tested this partial selection queries that are created based to this template.",
                    "label": 0
                },
                {
                    "sent": "The parameters of the template allows us to select a specific data set, which means a specific geometry type that we want to examine.",
                    "label": 1
                },
                {
                    "sent": "The function that we're going to examine and also the parameters Thelma and Zero allows us to define the thematic and this possibility for query and we also.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've tested this partial joins an according to this template, which is similar to the previous allows us to select two datasets and define the mattick selectivity of its data set.",
                    "label": 0
                },
                {
                    "sent": "And of course the function to examine.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's continue with how the benchmark was used to evaluate three RDF stores and some results of evaluating.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We used it to evaluate this trouble in Parliament and user came for the micro part of the real world workload and the synthetic workload.",
                    "label": 0
                },
                {
                    "sent": "We measured the response time for its query.",
                    "label": 1
                },
                {
                    "sent": "We run its query 3 times and compute the median of the response times.",
                    "label": 1
                },
                {
                    "sent": "We also set the time out of one hour for the evaluation of each query and we took measurements both for warm and cold cases.",
                    "label": 0
                },
                {
                    "sent": "Well for the macro part we run many instantiation to fix query for run now.",
                    "label": 0
                },
                {
                    "sent": "Without cleaning the gases and we measured the average time for a complete execution of its query.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these are a response times of the micro part of the benchmark.",
                    "label": 1
                },
                {
                    "sent": "In general, we observe that the user comments Robin have a similar response times regarding evaluation of non topological functions and special selections in specific user came is is faster in evaluating and topological functions and this is reasonable because it uses the native store of Sesame which is known to be more efficient for small datasets than implementations of sesame oil.",
                    "label": 0
                },
                {
                    "sent": "For a DBMS likes trouble.",
                    "label": 0
                },
                {
                    "sent": "While there for their special selections, you see, Kim evaluates the special part of the query imposture yes, and the thematic part in in size.",
                    "label": 0
                },
                {
                    "sent": "How many native services coming so this adds a small overhead in comparison to struggle, who evaluates the whole query in Bossier, yes, unit utilizing a unified dictionary scheme both for a thematic and spatial informations.",
                    "label": 0
                },
                {
                    "sent": "An while the optimizer of Parliament focuses only on.",
                    "label": 0
                },
                {
                    "sent": "The graph patterns and doesn't optimize filters with just park layer functions, so its response times is about an order of magnitude higher.",
                    "label": 0
                },
                {
                    "sent": "While there for joint use equipment, Parliament evaluates the Cartesian product of the graph patterns and then they check the topological relation exhaustively over the over the intermediate results.",
                    "label": 0
                },
                {
                    "sent": "So they didn't answer the majority of special joins within the time limit of 1 now.",
                    "label": 0
                },
                {
                    "sent": "And finally, special aggregates are tested only in trouble because they are not defined by George Park but by the Estes Park query language which is supported only by Straubel.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These are the results of the macro part of every benchmark in general.",
                    "label": 1
                },
                {
                    "sent": "Again, we can observe that use it came is the fastest system for the scenarios.",
                    "label": 0
                },
                {
                    "sent": "Reverser coding, entire map search and browsing well, while the final scenario, which is more complex and has a complex spatial joins, he can only be served by trouble because the other systems need more than one hour to answer some queries.",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, let's continue with the.",
                    "label": 0
                },
                {
                    "sent": "With the results of the synthetic workload, we generated the data set of about four million triples that contains around 300,000 geometry's.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are resume.",
                    "label": 0
                },
                {
                    "sent": "These are some results of this partial selection queries that we have tested.",
                    "label": 0
                },
                {
                    "sent": "We tested the topological relation intersect for the left graph of the left graph.",
                    "label": 0
                },
                {
                    "sent": "We use the queries that have non special part that selects the whole data set so they have a low thematic selectivity well for the right graph we have queries with high selectivity, highly thematic selectivity that selects two per thousand of am of the data set.",
                    "label": 0
                },
                {
                    "sent": "And the the this partial selective the queries is depicted on the X axis of the images.",
                    "label": 0
                },
                {
                    "sent": "So we observe that the response times of usage game increases, while in this partial selectivity of the greatest increase and this happened 'cause you see, Kim always starts by evaluating the special part of the query and then continues with mathematic.",
                    "label": 0
                },
                {
                    "sent": "On the other hand.",
                    "label": 0
                },
                {
                    "sent": "It's Robin which exploits fully exploits the selectivity.",
                    "label": 0
                },
                {
                    "sent": "Estimation of posteriors is able to alter the evaluation plans of a query when the non special part of the query becomes more selective than this partial and so that saves a better response times.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Continuing with some results of a special joints of the synthetic workload, we can see again that the strategy that you scam and Parliament follows of evaluating the Cartesian product of the active stores has as a result to have high response times.",
                    "label": 0
                },
                {
                    "sent": "For example, a Parliament answers within the time limit of one hour only.",
                    "label": 0
                },
                {
                    "sent": "The joints that have very high thematic selectivity.",
                    "label": 0
                },
                {
                    "sent": "While you see Kim has response times about one order.",
                    "label": 0
                },
                {
                    "sent": "Wanted more than Scrabble, however, we can see that there are some cases that this strategy becomes efficient.",
                    "label": 0
                },
                {
                    "sent": "For example, when the thematic selectivity becomes very high.",
                    "label": 0
                },
                {
                    "sent": "Struggled with stores.",
                    "label": 0
                },
                {
                    "sent": "Also mattress in a single table produces many intermediate results that later will be discarded by the by the graph patterns.",
                    "label": 0
                },
                {
                    "sent": "So the strategy that you seek, Amy follows becomes better and outperforms.",
                    "label": 0
                },
                {
                    "sent": "Performance is trouble.",
                    "label": 0
                },
                {
                    "sent": "Soto.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To summarize the presentation, we have defined the geographic a comprehensive benchmark for edge, especially if source.",
                    "label": 1
                },
                {
                    "sent": "The benchmark consists of two workloads.",
                    "label": 0
                },
                {
                    "sent": "The first one gives us an inside of how the RDF stores could perform in real cases where the second workload.",
                    "label": 1
                },
                {
                    "sent": "Gives us a better inside for implementation details of the other stores.",
                    "label": 0
                },
                {
                    "sent": "We use the Benchmarker also to compare three relevant active stores struggle in Parliament and use them.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As a future work, we could consider expanding the benchmark to capture the full edges Parker Standard.",
                    "label": 1
                },
                {
                    "sent": "We could also start the scaling keys you save with larger datasets or add more application scenarios.",
                    "label": 0
                },
                {
                    "sent": "And another thing that could be done is to extend it generator to produce datasets that do not allow.",
                    "label": 1
                },
                {
                    "sent": "Do not follow a uniform distribution, but something more special.",
                    "label": 0
                },
                {
                    "sent": "And finally extend the benchmark to include not only simple the special data but time evolving their special data.",
                    "label": 0
                },
                {
                    "sent": "If you want to find more information and specifically in limitation details about the benchmark, you can visit our side.",
                    "label": 0
                },
                {
                    "sent": "This work has been done in the context of the European project values that has just finished.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are all invited to visit us to show our demo about visualizing time evolving, telling to special data.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for going soon.",
                    "label": 0
                }
            ]
        }
    }
}