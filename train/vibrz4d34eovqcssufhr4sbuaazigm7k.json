{
    "id": "vibrz4d34eovqcssufhr4sbuaazigm7k",
    "title": "What limits performance in decision making?",
    "info": {
        "author": [
            "Alexandre Pouget, Geneva Neuroscience Center, University of Geneva"
        ],
        "published": "July 28, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Artificial Intelligence",
            "Top->Social Sciences->Psychology",
            "Top->Medicine->Neuroscience",
            "Top->Technology->Engineering->Electrical Engineering->Control Engineering",
            "Top->Social Sciences->Economics"
        ]
    },
    "url": "http://videolectures.net/rldm2015_pouget_decision_making/",
    "segmentation": [
        [
            "So of course, thanks a lot to the organizers and to the program chairs for inviting me.",
            "In this talk, I'm going to address a central question in cognitive neuroscience, and in particular in the context of decision-making, namely, what limits performance when you're making a decision, and I want to be very specific about what I'm going to study in here.",
            "I want to know what."
        ],
        [
            "Performance when you fully attentive and when you're well trained in task.",
            "'cause obviously when you don't know anything about the task then very different mechanism might be a play.",
            "Or if you cannot pay attention because you had a rough night the night before, or because like me, you're dealing with eight hours of jet lag then."
        ],
        [
            "And your brain is dysfunctional, and the reason for that might be very different from what limited performance when you're on top of your game.",
            "And that's what I want to talk about.",
            "Today is what happens when you're on top of your games."
        ],
        [
            "OK, so obviously there is a lot of literature on this topic and there is one hypothesis that's very popular in neuroscience that performance is limited by now."
        ],
        [
            "Lucinda Brain, Interestingly, this is a popular hypothesis.",
            "Not only neuroscience but also in the music industry.",
            "If you actually type noise in the brain in Google, you."
        ],
        [
            "Lots of hits that I have to do is different albums and books and it's so popular that those guys even have their annual gathering on this and it's called."
        ],
        [
            "Noise Brain Fest, which was last held in 2013 and judging by the traditional picture of the workshop attendees, it looks a lot more lively than any conference I ever attended.",
            "In fact, I take that back if she organized a workshop on this topic in neuroscience, and you invite the proponents and opponents of the theory.",
            "This is what you're going to get."
        ],
        [
            "In fact, this guy very much looks like Mike Shadle, and if you tell him there is no noise in the brain.",
            "OK, so that's one hypothesis that there is noise in the brain, but there's an alternative to this which."
        ],
        [
            "Is that really your limit?"
        ],
        [
            "By a combination of suboptimal inference and variability in the sensory inputs and sensors, so variability in the periphery, not variability in the central nervous system.",
            "If you type this in Google, you don't get anything too exciting."
        ],
        [
            "First thing you're going to get is actually to a paper that came out of my lab two years ago, in which we explore exactly this hypothesis that your main problem is sub optimal inference, not noise in your brain.",
            "And today I'm not going to go over this paper.",
            "It's published.",
            "You can go through all the different arguments are in there.",
            "You can go read it.",
            "I just want to show you 2 new experiments that just bring further supports.",
            "The notion that suboptimal inference is really the problem."
        ],
        [
            "So here's."
        ],
        [
            "Road map I'm going to go through two experiments.",
            "At first one I'm going to try to show you that sometimes when you see variability in your subject, whether they are rats or humans, it's tempting to think that this variability is caused by stochastic fluctuation in the response of the neurons.",
            "But I'll show you that instead it might come from suboptimal inference."
        ],
        [
            "And then the second experiment.",
            "I'll describe an experiment in which we try to assess what is impact of noise on behavioral performance, and you'll see that it's much smaller than you might imagine.",
            "If you think that noise is really the main limitation."
        ],
        [
            "So here's the first experiment that was done in the context of olfactory processing, and this is a collaboration with."
        ],
        [
            "Those guys Andrea Mendoza.",
            "Mario Vicente, Erick DeWitt, Zach made and we're all enlistment at the shop.",
            "Alamo Institute for the unknown.",
            "So in this experiment, those guys trained rats on true task, olfactory detection and or factory categorisation task."
        ],
        [
            "So this is just standard rodent type of experiments.",
            "You have three ports.",
            "The animal has to poke its nose in the central port where an odor is being delivered and then has to respond by going either right or left.",
            "And if it's correct it gets a drop of water.",
            "If it's incorrect, nothing happens, and then the animal has to initiate a new trial.",
            "And as I said, there are really 2 task there."
        ],
        [
            "Stretchable detection task, in which the animal is presented with either order A or odor B but not both at the same time and they're presented in increasing concentration."
        ],
        [
            "Then we have a categorization task in which we now present mixture of A&B together.",
            "So we go from one extreme which is a loan to be alone with a variety of ratios in between and the animal of course has to decide is a mixture dominated by a or is it dominated by B and has to respond accordingly."
        ],
        [
            "So if you think of the sensory space for this experiment, what we're doing here is we're really spanning two different directions when we."
        ],
        [
            "Thing that detection task in this space where you have the concentration of odor be here and concentration of odorhei along this axis in the detection task which."
        ],
        [
            "This going along the Y axis and then the X axis.",
            "With the."
        ],
        [
            "Categorisation task with just moving along different directions indicated by the green box here, which correspond to all the."
        ],
        [
            "Mixture that are being tested in this experiment.",
            "And the diagonal line here the Unity line is the categorisation boundary for both task.",
            "If you're on the upper left side of the boundary, you basically have to respond one way, and if you're on the lower right side of the boundary, you have to respond the other way."
        ],
        [
            "Alright, so we're going to collect on this experiment, standard reaction times and percentage, correct?",
            "And then we're going to fit with the model.",
            "This is your standard two FC kind of task, so there's basically only one game in town.",
            "You guys are very familiar with this, but we're going to use just a drift diffusion model, and this is our version of the drift diffusion model.",
            "We're going to assume that there are receptors order A and receptor for OB.",
            "Those receptor produces momentary evidence for either of the orders that are drawn from a normal distribution at every time step.",
            "Whose mean is determined by the concentration of the odor.",
            "The higher the concentration, the higher the value of those sensors.",
            "So you see here series of samples from order N series of sample for ODB and then on next stage we're just going to take the temporal integral of the samples were just going to accumulate the evidence.",
            "So you start seeing that indeed we have kind of a longer time constant here and then.",
            "Finally in the in that stage we're going to take the difference between the accumulated evidence for A&B.",
            "And that gives us a diffusion process an whenever we hit the bound, either the upper bound of the lower bound we stop and will respond according to which bound we hit.",
            "Nothing very fancy here, very from new type of models.",
            "We have also some parameters and we're going to use that to fit our data."
        ],
        [
            "So we're going to start with the detection task at the top you have percentage correct as a function of the concentration of the order.",
            "You see.",
            "Typical pattern animal gets better.",
            "Anna reach almost 100% for high concentration and for reaction time we see that ration kit times gets faster as a task gets easier.",
            "OK."
        ],
        [
            "Right so.",
            "Yes, so the dots is the data and the line is a fit through the model.",
            "We can capture the data very well in the detection task.",
            "That's nothing really particularly impressive.",
            "We have more than enough parameters to capture this particular data set here.",
            "What's interesting is that if you take the model that would just fit it to detection and you now apply it without any further tuning to the other task to the detection task.",
            "And when you do."
        ],
        [
            "You get this.",
            "This is a prediction.",
            "This is not fitted.",
            "You find that the reaction time I in the right ballpark, but the performance is not at all like you observed in the data.",
            "The model predicts that performance should be pretty much at 1% correct except at the last.",
            "The last data point will be here at .5, but it would collapse just at the last minute, whereas in the case of what the rat is doing, you see that performance degrade slowly toward 50%.",
            "So there's a big gap here in performance that we need to explain.",
            "This is something that Adam Capec Zach Maine and observe quite awhile ago."
        ],
        [
            "Anne."
        ],
        [
            "Our first idea was that there must be some extra source of variability in the categorisation task that would explain why is it that the animal is doing worse than the model.",
            "There must be some variability in the animal that doesn't exist in the model right now."
        ],
        [
            "And their hypothesis with that?",
            "Well, perhaps what's happening at the animal can't remember the categorization boundary.",
            "Remember, they hear the animal has to determine whether the the mixture is more than 50% a or more than 50% B.",
            "That's 5050 boundary is complete arbitrary.",
            "Then we'll have to learning through the task.",
            "We could just as well trained the animal in 6040, so the animal has to learn it through the task and then stick to it for the rest of the task."
        ],
        [
            "Well, what if the animal cannot remember that?",
            "What if instead of using on every trial, the perfect boundary, which will be the black line that boundary?"
        ],
        [
            "Trades from 12."
        ],
        [
            "Troll."
        ],
        [
            "Then that may."
        ],
        [
            "Explain why we."
        ],
        [
            "This drop in performance in the."
        ],
        [
            "Animals.",
            "OK."
        ],
        [
            "Very well, but then that begs of course another question, which is why."
        ],
        [
            "With this boundary be variable and again we have two possible hypothesis maybe."
        ],
        [
            "But hardware again, neurons flood traits that can't quite remember the boundary on a travel trial basis, and that creates extra noise."
        ],
        [
            "There's another possibility that."
        ],
        [
            "Instead, they had the wrong assumption about the environment, and that's going to lead them to perform a suboptimal inference.",
            "What could be the wrong assumption in this?"
        ],
        [
            "Case, what we're going to explore is whether the animals wrongly assume that the task changes overtime.",
            "So in this particular experiment, the rules of the tasks are set invents.",
            "They're not going to change for the entire duration of the experiment for all the different weeks you train those animal in this task, it's always the same rule.",
            "So this situation in which you should have a learning rate that's very high at the beginning, you're learning the task, and then it should decay to zero, and then you should stick to whatever you've learned at that point and always behave in the same way.",
            "But of course those are rats.",
            "They have no particular reason to believe that their environment where nothing changed their entire life that always in the environment were changed.",
            "So you might imagine that they're constantly exploring and making sure the task is not changing, but these are constantly learning and adjusting their bounds."
        ],
        [
            "That may be what's going on here.",
            "Is that the bound fluctuates not because there is noise in the brain, but because they're changing in a deterministic way on a trial by trial basis, the boundary they're using to classify their input.",
            "OK."
        ],
        [
            "So how are we going to tell which one is correct?",
            "What turned out there is another piece of data I haven't told you about which are choice biases?",
            "They're going to help us constrain the different model?",
            "The choice biases are represented here, and for me, the first time I saw those figures are always found them confusing, and yet they convey very simple message what those guys found in that.",
            "If the rats are confronted with a hard trial on the current route, so it's data can't quite tell what's going on, they tend to rely on what they did on the previous trial.",
            "If it was rewarded.",
            "So it's kind of win state.",
            "OK, there are ordered by going writing last trial and the current trial is hard.",
            "They're going to tend to go right more than they should.",
            "And that's basically indicated by having points that are above 0.",
            "Here positive value means they're just doing Wednesday.",
            "I don't know if they're doing loose shift, by the way in this experiment, because we don't have enough data to really tell, but they're doing Wednesday and they're doing it only if the current trial is hard.",
            "Which are the red dots here?",
            "If the current trial is is very easy so they can tell right away from the data what's going on.",
            "They don't rely on what they did on the previous trial, and that's what is indicated by the black dots here.",
            "In addition, I didn't tell you yet what is the X axis here.",
            "The X axis, the previous trial difficulty, and this is actually where this task and this data becomes difficult to internalize.",
            "But it turns out that the choice bias also depends on how difficult the previous route was, and it depends in different ways depending on detection and categorization in a detection task, the choice biases are not very dependent on the previous trial difficulty worth in the categorisation task they are.",
            "I'm not going to go into details of this.",
            "All I want to say here that's in a sense that was good news for us because that's really going to help us constrain the model.",
            "Whatever model would develop, it has to actually fit this deal.",
            "Oak."
        ],
        [
            "So now let's go back to our hypothesis.",
            "First idea is that can't quite remember the boundary because of bad hardware."
        ],
        [
            "So we're going to go back to the DM and we're going to expand that DM.",
            "First, we're going to add."
        ],
        [
            "Bias unit, that's a unit that's always on it has a weight onto the drift process here, and the weights is basically going to now correspond to the prior probability that the animal thinks that right is rewarded versus left.",
            "In this experiment, it's all balanced exactly the same, but then we'll have to learn it, and we're going to assume that it's done through that bias unit."
        ],
        [
            "Second thing is we're going to let the noise that sorry, we're going to let the weights here vary from trial to trial so the."
        ],
        [
            "Important thing to realize is that those weights here the determine the categorisation boundary.",
            "They determined this particular line here.",
            "The line the Unity line."
        ],
        [
            "Correspond to the weights being set to 1 -- 1 and 0.",
            "And if the weights set, the boundary then went."
        ],
        [
            "Add noise to those ways here, then."
        ],
        [
            "I'm doing that effectively making this boundary fluctuates, so that's what we're going to do next.",
            "We're going to expand the model by adding on the troubled by on every trial we're going to draw the weight from a normal distribution centered at 1 -- 1 zero with some variance Sigma squared Sigma Square is going to be free parameter, which we're going to fit to the data.",
            "So we just added one free parameter."
        ],
        [
            "So we go into our task and we first we're going to take the detection task and we're going to use a detection task to fit all the parameters except for the amount of noise that we inject into the weights, and the reason is because the detection test doesn't actually constrain it at all.",
            "This parameter we can fit it, but we get huge error bars, so we don't really trust it so."
        ],
        [
            "So what we realized is we can fit it by using the categorization data.",
            "So we're going to use the categorization data just to constrain that particular parameter.",
            "The amount of noise that we inject in the weights.",
            "So if we do that, if we could do this double step fitting procedure, we find that now we can fit the data, the performance, the accuracy, and the reaction time from both task, and particularly that now performance has indeed dropped for the categorisation task, which is due to this injection of noise in the weights.",
            "But remember that we also have the choice biases, and the question is what do we predict for the choice?"
        ],
        [
            "Vice is well, what we find with this particular model is that basically we don't see any choice biases, and that's not so surprising because we re drawn every trial the weights here, so we don't have any temporal dependencies between trials.",
            "So of course we cannot get the choice biases with them all like this.",
            "So this tells us that it cannot just be noise, it cannot be just fluctuation in the noise has to be something."
        ],
        [
            "So how about learning?",
            "So what we're going to do next?",
            "Now is we're going to just use standard learning rule for learning those weights on the trial by trial basis, and in particular for the way."
        ],
        [
            "Coming from the accumulated evidence, we're going to use just a standard Delta rule, so we're not reinventing the wheel here, and we have a new free parameter which is just a learning rate, which we're going to adjust to fit the data."
        ],
        [
            "So when you do this using exactly the same procedures before fit all the parameters, But the learning rate onto detection you."
        ],
        [
            "The category categorization just to constrain the learning rate we can once again fit the accuracy and the reaction time.",
            "But what's really nice is that now we freezer model and we just ask what does it predict for the choice bias?"
        ],
        [
            "And where did predict exactly the pattern that we see in the data, and in particular the fact that the dependency on the previous trial difficulty is different in both tasks?",
            "So."
        ],
        [
            "This kind of data kind of suggests to us quite strongly that we're not dealing with just pure stochastic noise, and that it's quite possible that the fluctuation we see are due to deterministic learning just."
        ],
        [
            "To convince us that the model is really on the right track, we tried one more manipulation.",
            "Currently the model is trained on this particular data points here that you're seeing indicated on the plot, but of course we could easily train the app."
        ],
        [
            "On any other categorisation task where we're going to change the baseline level of order concentration.",
            "And we're going to ask if I train the model on the identification and the outside categorisation, how well does it do it predicting the other conditions?",
            "And so in this particular experiment we actually trained the rats and interleave trials where they go through all those different trials and we just like go back and forth between those different tasks."
        ],
        [
            "And it turns out that we don't have to readjust any of the parameters if we just train again on the extreme conditions, we find that the model generalizes for accuracy and for reaction time to all the other conditions.",
            "So of course I can tell you for sure that it's absolutely learning.",
            "More tests are needed, but only given the data we have so far, it looks like learning can explain why we have this drop in performance without to invoke some kind of more noise.",
            "Magical noise that's supposedly stopping the animal from performing any better."
        ],
        [
            "So once again."
        ],
        [
            "Principle here, the general principle is that if you don't know how the data were generated, then you can possibly be optimal.",
            "You're going to make approximation, and those approximations are going to appear as extra variability.",
            "So in this case, if you don't know that the task is static, and you assume that it's not, you pay a price by having extra variability."
        ],
        [
            "And I would argue that for most problems with interest, especially things like object recognition, there's no way you can know the model the.",
            "The optimal model for sure, so you're going to make approximations and those approximations are always going to result in extra variability, and so for most problems interest.",
            "That's the biggest problem that the brain has to face."
        ],
        [
            "And that's effectively what we argue in this particular paper, we offer just more argument than the one you just heard here.",
            "OK."
        ],
        [
            "So I'm done with the first experiment.",
            "Now I want to quickly tell you about the second one, which is that as far as we can tell, noise doesn't seem to have that big of an impact on your performance.",
            "So what is it based on?"
        ],
        [
            "So this time I'm going to tell you about experiments."
        ],
        [
            "I'm doing in collaboration with this guy, Zach Pico Kaushik, something I can't use pronounce this name too complicated for me.",
            "We call you Kaushik.",
            "Very nice guy Greg Deangelis and or Angelocci and Zach Kaushik and Dora are all three are Valley College of Medicine in Houston.",
            "I see some people are trying to read the name.",
            "It's not that easy, right?",
            "And Greg Dangelis, that University of Rochester."
        ],
        [
            "OK, and what we ask with those guys is, does internal noise actually affects behavioral performance?",
            "And to enter this, here is a dream experiments that I'd like to do one day and then in front is not the experiment I'm going to describe next, but here's what we wanted to do."
        ],
        [
            "What I'd like to do is you start with your favorite stimulus, whatever.",
            "If you're doing decision-making, let's say you do the random dot motion task and you're trying to ask subject whether the dots are moving to write some."
        ],
        [
            "We know that this particular stimulus activates this V12 empty pathway, so we stick thousands and thousands of electrodes, hundreds of thousands of electrodes in empty to try to see the overall population activity in empty.",
            "That's the step that right now we can do, but we're not that far away from being able to do that one, but right now we can do that.",
            "So we record from all the neurons in emptying during the task."
        ],
        [
            "And then we developed an optimal decoder of area empty to figure out what is the performance in the optimal decoder, how much information is there effectively in area, empty and we compare."
        ],
        [
            "That to the performance we get from the behavior that's going to be the goal.",
            "And I can imagine now two scenarios."
        ],
        [
            "One is that the brain between empty and the motor cortex of brain implements a noiseless optimal decoder.",
            "If that's the case, then the decoder's performance and the behavioral performance should be comp."
        ],
        [
            "If."
        ],
        [
            "On the other hand, you think that the brain is noisy and there's tons of noise in those circuits, and that's really what's constraining your performance than the presence of the noise."
        ],
        [
            "Means that your behavioral performance will be much smaller than you would predict by decoding area empty, right so?"
        ],
        [
            "Roughly what you would expect that the information in the behavior here should be a tiny fraction, perhaps less than 5% of the information that you recovered from the decoder.",
            "That would indicate that noise is really the bottleneck here, and that's the problem for the system.",
            "OK, so as I told you, we can quite do this experiment in Fortnite, but we did the second best thing that we can do with the kind of data we have, which is single cell recording from area MTN from other areas, so."
        ],
        [
            "First of all, let me tell you briefly the test that we're using.",
            "We're using here test that was designed by Greg Deangelis and Orange Lucky that they've been using for a variety of experiments.",
            "And here what's happening is you have a monkey.",
            "You can't quite tell, but that's supposed to be a monkey that's sitting in this big thing here, which is a vestibular platform.",
            "It's a mechanical things that actually can move the monkey, and whatever is sitting on this platform in any direction in space.",
            "So this activates the vestibular system.",
            "You sense of acceleration.",
            "And in this particular case we use a platform to move the monkey forward, and as we move the monkey forward, we move them slightly to the left or slightly to the right, and the task is a monkey in any given trial is to tell in which direction we're moving, right or left.",
            "So we do this while we record the activity of neurons in a variety of areas, and then we're going."
        ],
        [
            "Look at what we call choice correlations.",
            "We're going to look at the fluctuation between the the fluctuation of 1 neuron wild animal is performing the task and the fluctuation in the response of the animal from trial to trial right?",
            "So this is a concept that was first introduced by Ken Britain, Bill Newsome and colleagues quite awhile ago they called the choice probability.",
            "I think mathematically it makes more sense to look for choice correlations, which is what I'm going to look at here and their argument was like look if a neuron is contributing to the behavior, then fluctuation that neuron should have an influence on the behavior.",
            "Until they realize that, well, it depends, because if all the neurons are independent and there are thousands, or there's a million neurons involved in the task, then each neurons is contributing one in a million's to the decision.",
            "So you're unlikely to see the effect until they realize that Oh no, is the neurons are correlated?",
            "Then perhaps a single neurons might have an influence on behavior, and that's what they reported in the mid 90s that there's a significant correlation between fluctuation neurons and empty, and the decision of the animal.",
            "So we're going to do the same thing here.",
            "We're going to track those choice correlations.",
            "OK."
        ],
        [
            "So with Zach people realize as we were doing those experiments is that indeed we can predict what Choice Coalition are going to look like for single neurons.",
            "If the read out of the area that we're recording from is optimal, and that optimal decoder is linear if those conditions are met, then it's possible to allergically figure out what the choice correlations are going to look like.",
            "An expression is incredibly simple."
        ],
        [
            "The choice correlation of neuron K have to be equal to this ratio."
        ],
        [
            "Where it's a ratio of the behavioral threshold of the model or the animal, there are the same here.",
            "That's the optimal model."
        ],
        [
            "Over the threshold for neuron K, so this is how well you can discriminate right from left based on the activity or just one of that particular neuron.",
            "OK, so choice correlation is given by this ratio.",
            "If the area is decoded optimally, so we are great because we can measure all those things.",
            "We can measure the behavioral threshold.",
            "That's easy, we can analyze the response of each neurons and figure out how well we can discriminate heading from single neurons.",
            "And we can see whether this ratio correspond to the measured choice correlations.",
            "So."
        ],
        [
            "Is what the data looks like the bad user choice?",
            "Correlations are incredibly noisy, they're very hard to get.",
            "It takes times of trials, so we only have mag noisy measurement.",
            "My hunch when we started this is we wouldn't see much, but it turns out that we do see a trend, so this is here along.",
            "the Y axis is a measured correlation along the X axis is a predicted correlation for an optimal decoder, and if we were correct, then all of these plots the data should line up along the Unity line.",
            "The different colors by the way.",
            "Respond to different brain areas and the letters correspond to different monkeys and I'm going to tell you more about this in a second.",
            "But you see this kind of like in the right direction, so we did some stats on this."
        ],
        [
            "Pretty simple, we just did.",
            "We regressed it over theory against CK and looked at what kind of regression coefficient we got.",
            "So here I'm plotting beta regression coefficient and you can see that, at least for the 6th first 6 bars.",
            "Here we hovering around one as expected for optimal decoding.",
            "Um?",
            "I should have labeled that a bit, but you see, like their little bars here that correspond to large shades of Gray.",
            "This is actually the coefficient of regression we get if we try a suboptimal decoder.",
            "In this case, it's called a factorized decoder.",
            "What we find is we can explain the data with this large class of sub optimal decoder optimal decoder.",
            "On the other hand, does a pretty good job at explaining what we see.",
            "Well, except."
        ],
        [
            "Course for those bars here, so I forgot to say the green bars.",
            "Here are the vestibular nucleus and the cerebellar Nicholas where you see a lot of vestibular responses and the orange one is empty, which is the visual area, which also respond to better signals.",
            "But VIP, which is yet another area in parallel cortex, shows a very weird pattern, which is an instead of finding."
        ],
        [
            "One we find correlation coefficient up to three, and it's not like very suboptimal decoder like factorized would explain the data because it doesn't explain the data at all.",
            "This stops us in our tracks for quite awhile because we also use something else."
        ],
        [
            "VIP, so I'm going back here.",
            "The choice correlation for VIP Ann here along the Y axis is the actual choice correlation that we measure in VIP an if you look at the."
        ],
        [
            "There's something very bizarre.",
            "Those neurons here.",
            "Each dot is 1 neurons.",
            "Those neurons have choice correlation of 1.",
            "If you're recording from that neuron, you know in every trial with the animal is going to do.",
            "You should know that if you do that, experiments in empty, you know maybe on 5% of the trial with the animal is going to do an average.",
            "Here it's 100% of the trial.",
            "It's as if we're right at the output of the system.",
            "And choose correlations often are thought to be kind of an indication of how much a particular area contributes to task.",
            "So here that seems to say, well, it's contributing as much as you can possibly contribute to a task like this.",
            "This is very unusual data for anybody who is recorded from neurons like this."
        ],
        [
            "And yet the decoding of area VIP suboptimal in some sense because we didn't get a regression coefficient of what, so that's really stopped us for many, many months, because wondering under which scenario can you possibly get this?",
            "And eventually we found a scenario where you get this and the sonar."
        ],
        [
            "As if this is possible, if one first of all VIP is highly redundant with other areas.",
            "Whatever information you have in VIP, you already have somewhere else, so VIP is getting a copy of what's going on, maybe in STD.",
            "And say."
        ],
        [
            "And it's not right out.",
            "And that was kind of surprising because we just saw that the choice correlation are very, very high, but that's the only scenario we could think of where we could explain this.",
            "Well long we hold at the same."
        ],
        [
            "Time door into like he was doing inactivation experiments of area, STD and VIP.",
            "In this task they were injecting usable in VIP or MC D to shut it down while the animal is performing the task.",
            "And here's the result that she had obtained.",
            "So it's completely different set of experiments.",
            "We had no idea list.",
            "Two things were going to be connected and what you see here.",
            "The threshold increase after his injections and four M STD you see that there is a 3 three fold increase in the behavioral threshold.",
            "The animal as a result of.",
            "In activating STD.",
            "And eventually the animal recovers.",
            "If we do the same experiment VIP, nothing happens.",
            "There's not no change whatsoever, suggesting that vaping is just not contributing in this particular experiment.",
            "So."
        ],
        [
            "Looks like this makes sense now.",
            "VIP is highly redundant and indeed it's not being read out.",
            "The fact that it's highly redundant is very interesting because it's telling us that even though VIP is not being read out optimally.",
            "That's not a big deal because the information that's in VIP's already available in STD, and the CN in the VN and those areas appears to be read out optimally.",
            "So in fact we build a big model of all of this."
        ],
        [
            "Based on all this data set and our current estimate."
        ],
        [
            "Is that about 80% of the information available in MSDN VIP is actually driving the behavior.",
            "And so that."
        ],
        [
            "At least only about 20% for noise.",
            "If noise is playing a role in this experiment, it's only constraining 20%, not 95%.",
            "Only a small fraction, but even then, remember that whenever you see noise, you should worry that perhaps it's suboptimal behavior, so perhaps there are more suboptimal steps here that we haven't identified yet."
        ],
        [
            "So to conclude."
        ],
        [
            "We started with the Noise Brain Fest in the first half of the talk.",
            "I tried to convince you that we should."
        ],
        [
            "Replace it with a sub optimal brain fast that this is really where the problem is and the second half I was trying to show you that yeah, maybe there is noise in your brain, but the good news is that it doesn't seem to be affecting your performance and I want is just one less thing on noise in the brain.",
            "I actually believe there is noise in the brain.",
            "Just plenty of evidence that there is noise in the brain that there are fluctuations, stochastic fluctuation, response of the animal and it might be good for things like sampling.",
            "This is a theme that came up several times starting with Allison's talk this morning.",
            "It might be good for exploring, of course, but again the good news and I think that anybody who uses sampling would agree with this that you wanted to learn things, but once you perform you don't want the noise to affect your performance, and that appears to be what we're finding.",
            "At least it doesn't have a big impact on your performance.",
            "Thank you very much.",
            "I just have a question about your first experiment.",
            "I was just curious how long you had between each of your rat trials and just maybe if could it be possible.",
            "If there was overstimulation of the nose and that could be reason I have a hard time hearing you so I was just wondering.",
            "How far apart with each of your trials in the rats in the first experiment and if it was maybe short, could there be overstimulation of the nose and that could be a reason for your discrepancy between the rats in the model that their nose was just over stimulated from so much odors?",
            "And if there was enough time to recover from that, or if you had like something like coffee beans to kind of cleanse the nose palette, I don't know.",
            "One big worry in this experiment.",
            "If you for instance show like 100% at a high concentration, then the nodes will adapt to 100% A and that when you show another mixture, it's basically subtracting subtracting a from the mixture and the animal would tend to go before instance.",
            "Those other can think that we worried about, but the wind stays strategy is exactly the opposite.",
            "If you actually smelled a on the previous trial, you tend to actually respond again on next row, so I probably can tell there is no adaptation problems, but.",
            "Maybe there are other things we haven't thought about, but it should be.",
            "Yeah, there's so much ages left in there because it's just over stimulated with that type of odor.",
            "I mean, if it means that they're the ones are in steady state only a fraction of the receptors are really being active.",
            "That's fine, we're in steady state, so we don't worry too much about this.",
            "What we really worried about interaction between trials that we don't think can be explained just by simple adaptation explanations.",
            "A great talk.",
            "So suppose I want behavioral variability and you kind of alluded.",
            "This eluded to this at the end with the randomness for exploration.",
            "For example, should I be looking for in my experimental data?",
            "And I mean actually, my experimental data should be looking for.",
            "That coming from say, just my inference gets worse when I want to be more random or my.",
            "I should be looking for it in the neuron noise.",
            "Do you think there's space in the neural noise to generate noise for exploration?",
            "And for other cases where you want to be random?",
            "It could be, I mean right.",
            "As you probably know, there is several people who are arguing that noise in the brain is a form of sampling.",
            "I think right now it's the jury's out as to whether that's really the way we we explore, and whether it's true stochastic exploration due to stochastic noise in the neurons.",
            "I'm open to the idea I have myself a paper showing that bistable perception is complete, consistent with the sampling mechanism.",
            "So it's quite possible, but I think we're just at the beginning of this particular hypothesis, yeah, so, so it's still an open question.",
            "Then we can still as a hypothesis have it can be in the neural noise.",
            "Yeah, and it's an experiment.",
            "In fact, have gone math was sitting somewhere I can't see him anymore, but I'm involved in glasses.",
            "Who is here at this conference was right by you.",
            "It's 1 one of the people who been pushing quite hard.",
            "The idea that this is what it's about.",
            "I think the proper experiments have not been done yet.",
            "To really prove that this is the case, the only group that's pushing really hard is metal angle, and Joseph Fisher in V1 and there is already a lively debate, almost as lively as this one going on, and we've shown some stuff in decision making with that for explore, exploit decision-making, there's seems to be a random component that yeah, but whether it's related to whether it's related to noise, yeah?",
            "That's that's that's a big question."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So of course, thanks a lot to the organizers and to the program chairs for inviting me.",
                    "label": 0
                },
                {
                    "sent": "In this talk, I'm going to address a central question in cognitive neuroscience, and in particular in the context of decision-making, namely, what limits performance when you're making a decision, and I want to be very specific about what I'm going to study in here.",
                    "label": 1
                },
                {
                    "sent": "I want to know what.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Performance when you fully attentive and when you're well trained in task.",
                    "label": 0
                },
                {
                    "sent": "'cause obviously when you don't know anything about the task then very different mechanism might be a play.",
                    "label": 0
                },
                {
                    "sent": "Or if you cannot pay attention because you had a rough night the night before, or because like me, you're dealing with eight hours of jet lag then.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And your brain is dysfunctional, and the reason for that might be very different from what limited performance when you're on top of your game.",
                    "label": 0
                },
                {
                    "sent": "And that's what I want to talk about.",
                    "label": 0
                },
                {
                    "sent": "Today is what happens when you're on top of your games.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so obviously there is a lot of literature on this topic and there is one hypothesis that's very popular in neuroscience that performance is limited by now.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lucinda Brain, Interestingly, this is a popular hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Not only neuroscience but also in the music industry.",
                    "label": 0
                },
                {
                    "sent": "If you actually type noise in the brain in Google, you.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lots of hits that I have to do is different albums and books and it's so popular that those guys even have their annual gathering on this and it's called.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Noise Brain Fest, which was last held in 2013 and judging by the traditional picture of the workshop attendees, it looks a lot more lively than any conference I ever attended.",
                    "label": 0
                },
                {
                    "sent": "In fact, I take that back if she organized a workshop on this topic in neuroscience, and you invite the proponents and opponents of the theory.",
                    "label": 0
                },
                {
                    "sent": "This is what you're going to get.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In fact, this guy very much looks like Mike Shadle, and if you tell him there is no noise in the brain.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's one hypothesis that there is noise in the brain, but there's an alternative to this which.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that really your limit?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By a combination of suboptimal inference and variability in the sensory inputs and sensors, so variability in the periphery, not variability in the central nervous system.",
                    "label": 0
                },
                {
                    "sent": "If you type this in Google, you don't get anything too exciting.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First thing you're going to get is actually to a paper that came out of my lab two years ago, in which we explore exactly this hypothesis that your main problem is sub optimal inference, not noise in your brain.",
                    "label": 0
                },
                {
                    "sent": "And today I'm not going to go over this paper.",
                    "label": 0
                },
                {
                    "sent": "It's published.",
                    "label": 0
                },
                {
                    "sent": "You can go through all the different arguments are in there.",
                    "label": 0
                },
                {
                    "sent": "You can go read it.",
                    "label": 0
                },
                {
                    "sent": "I just want to show you 2 new experiments that just bring further supports.",
                    "label": 0
                },
                {
                    "sent": "The notion that suboptimal inference is really the problem.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Road map I'm going to go through two experiments.",
                    "label": 0
                },
                {
                    "sent": "At first one I'm going to try to show you that sometimes when you see variability in your subject, whether they are rats or humans, it's tempting to think that this variability is caused by stochastic fluctuation in the response of the neurons.",
                    "label": 0
                },
                {
                    "sent": "But I'll show you that instead it might come from suboptimal inference.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the second experiment.",
                    "label": 0
                },
                {
                    "sent": "I'll describe an experiment in which we try to assess what is impact of noise on behavioral performance, and you'll see that it's much smaller than you might imagine.",
                    "label": 0
                },
                {
                    "sent": "If you think that noise is really the main limitation.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's the first experiment that was done in the context of olfactory processing, and this is a collaboration with.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Those guys Andrea Mendoza.",
                    "label": 0
                },
                {
                    "sent": "Mario Vicente, Erick DeWitt, Zach made and we're all enlistment at the shop.",
                    "label": 0
                },
                {
                    "sent": "Alamo Institute for the unknown.",
                    "label": 0
                },
                {
                    "sent": "So in this experiment, those guys trained rats on true task, olfactory detection and or factory categorisation task.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is just standard rodent type of experiments.",
                    "label": 0
                },
                {
                    "sent": "You have three ports.",
                    "label": 0
                },
                {
                    "sent": "The animal has to poke its nose in the central port where an odor is being delivered and then has to respond by going either right or left.",
                    "label": 0
                },
                {
                    "sent": "And if it's correct it gets a drop of water.",
                    "label": 0
                },
                {
                    "sent": "If it's incorrect, nothing happens, and then the animal has to initiate a new trial.",
                    "label": 0
                },
                {
                    "sent": "And as I said, there are really 2 task there.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stretchable detection task, in which the animal is presented with either order A or odor B but not both at the same time and they're presented in increasing concentration.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we have a categorization task in which we now present mixture of A&B together.",
                    "label": 0
                },
                {
                    "sent": "So we go from one extreme which is a loan to be alone with a variety of ratios in between and the animal of course has to decide is a mixture dominated by a or is it dominated by B and has to respond accordingly.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you think of the sensory space for this experiment, what we're doing here is we're really spanning two different directions when we.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing that detection task in this space where you have the concentration of odor be here and concentration of odorhei along this axis in the detection task which.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This going along the Y axis and then the X axis.",
                    "label": 0
                },
                {
                    "sent": "With the.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Categorisation task with just moving along different directions indicated by the green box here, which correspond to all the.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mixture that are being tested in this experiment.",
                    "label": 0
                },
                {
                    "sent": "And the diagonal line here the Unity line is the categorisation boundary for both task.",
                    "label": 0
                },
                {
                    "sent": "If you're on the upper left side of the boundary, you basically have to respond one way, and if you're on the lower right side of the boundary, you have to respond the other way.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so we're going to collect on this experiment, standard reaction times and percentage, correct?",
                    "label": 0
                },
                {
                    "sent": "And then we're going to fit with the model.",
                    "label": 0
                },
                {
                    "sent": "This is your standard two FC kind of task, so there's basically only one game in town.",
                    "label": 0
                },
                {
                    "sent": "You guys are very familiar with this, but we're going to use just a drift diffusion model, and this is our version of the drift diffusion model.",
                    "label": 1
                },
                {
                    "sent": "We're going to assume that there are receptors order A and receptor for OB.",
                    "label": 0
                },
                {
                    "sent": "Those receptor produces momentary evidence for either of the orders that are drawn from a normal distribution at every time step.",
                    "label": 0
                },
                {
                    "sent": "Whose mean is determined by the concentration of the odor.",
                    "label": 0
                },
                {
                    "sent": "The higher the concentration, the higher the value of those sensors.",
                    "label": 0
                },
                {
                    "sent": "So you see here series of samples from order N series of sample for ODB and then on next stage we're just going to take the temporal integral of the samples were just going to accumulate the evidence.",
                    "label": 0
                },
                {
                    "sent": "So you start seeing that indeed we have kind of a longer time constant here and then.",
                    "label": 0
                },
                {
                    "sent": "Finally in the in that stage we're going to take the difference between the accumulated evidence for A&B.",
                    "label": 0
                },
                {
                    "sent": "And that gives us a diffusion process an whenever we hit the bound, either the upper bound of the lower bound we stop and will respond according to which bound we hit.",
                    "label": 0
                },
                {
                    "sent": "Nothing very fancy here, very from new type of models.",
                    "label": 0
                },
                {
                    "sent": "We have also some parameters and we're going to use that to fit our data.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we're going to start with the detection task at the top you have percentage correct as a function of the concentration of the order.",
                    "label": 0
                },
                {
                    "sent": "You see.",
                    "label": 0
                },
                {
                    "sent": "Typical pattern animal gets better.",
                    "label": 0
                },
                {
                    "sent": "Anna reach almost 100% for high concentration and for reaction time we see that ration kit times gets faster as a task gets easier.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "Yes, so the dots is the data and the line is a fit through the model.",
                    "label": 0
                },
                {
                    "sent": "We can capture the data very well in the detection task.",
                    "label": 0
                },
                {
                    "sent": "That's nothing really particularly impressive.",
                    "label": 0
                },
                {
                    "sent": "We have more than enough parameters to capture this particular data set here.",
                    "label": 0
                },
                {
                    "sent": "What's interesting is that if you take the model that would just fit it to detection and you now apply it without any further tuning to the other task to the detection task.",
                    "label": 0
                },
                {
                    "sent": "And when you do.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You get this.",
                    "label": 0
                },
                {
                    "sent": "This is a prediction.",
                    "label": 0
                },
                {
                    "sent": "This is not fitted.",
                    "label": 0
                },
                {
                    "sent": "You find that the reaction time I in the right ballpark, but the performance is not at all like you observed in the data.",
                    "label": 1
                },
                {
                    "sent": "The model predicts that performance should be pretty much at 1% correct except at the last.",
                    "label": 0
                },
                {
                    "sent": "The last data point will be here at .5, but it would collapse just at the last minute, whereas in the case of what the rat is doing, you see that performance degrade slowly toward 50%.",
                    "label": 0
                },
                {
                    "sent": "So there's a big gap here in performance that we need to explain.",
                    "label": 0
                },
                {
                    "sent": "This is something that Adam Capec Zach Maine and observe quite awhile ago.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our first idea was that there must be some extra source of variability in the categorisation task that would explain why is it that the animal is doing worse than the model.",
                    "label": 0
                },
                {
                    "sent": "There must be some variability in the animal that doesn't exist in the model right now.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And their hypothesis with that?",
                    "label": 0
                },
                {
                    "sent": "Well, perhaps what's happening at the animal can't remember the categorization boundary.",
                    "label": 1
                },
                {
                    "sent": "Remember, they hear the animal has to determine whether the the mixture is more than 50% a or more than 50% B.",
                    "label": 1
                },
                {
                    "sent": "That's 5050 boundary is complete arbitrary.",
                    "label": 0
                },
                {
                    "sent": "Then we'll have to learning through the task.",
                    "label": 0
                },
                {
                    "sent": "We could just as well trained the animal in 6040, so the animal has to learn it through the task and then stick to it for the rest of the task.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, what if the animal cannot remember that?",
                    "label": 0
                },
                {
                    "sent": "What if instead of using on every trial, the perfect boundary, which will be the black line that boundary?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Trades from 12.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Troll.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then that may.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Explain why we.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This drop in performance in the.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Animals.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very well, but then that begs of course another question, which is why.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With this boundary be variable and again we have two possible hypothesis maybe.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But hardware again, neurons flood traits that can't quite remember the boundary on a travel trial basis, and that creates extra noise.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's another possibility that.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Instead, they had the wrong assumption about the environment, and that's going to lead them to perform a suboptimal inference.",
                    "label": 0
                },
                {
                    "sent": "What could be the wrong assumption in this?",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Case, what we're going to explore is whether the animals wrongly assume that the task changes overtime.",
                    "label": 0
                },
                {
                    "sent": "So in this particular experiment, the rules of the tasks are set invents.",
                    "label": 1
                },
                {
                    "sent": "They're not going to change for the entire duration of the experiment for all the different weeks you train those animal in this task, it's always the same rule.",
                    "label": 0
                },
                {
                    "sent": "So this situation in which you should have a learning rate that's very high at the beginning, you're learning the task, and then it should decay to zero, and then you should stick to whatever you've learned at that point and always behave in the same way.",
                    "label": 0
                },
                {
                    "sent": "But of course those are rats.",
                    "label": 0
                },
                {
                    "sent": "They have no particular reason to believe that their environment where nothing changed their entire life that always in the environment were changed.",
                    "label": 1
                },
                {
                    "sent": "So you might imagine that they're constantly exploring and making sure the task is not changing, but these are constantly learning and adjusting their bounds.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That may be what's going on here.",
                    "label": 0
                },
                {
                    "sent": "Is that the bound fluctuates not because there is noise in the brain, but because they're changing in a deterministic way on a trial by trial basis, the boundary they're using to classify their input.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how are we going to tell which one is correct?",
                    "label": 0
                },
                {
                    "sent": "What turned out there is another piece of data I haven't told you about which are choice biases?",
                    "label": 0
                },
                {
                    "sent": "They're going to help us constrain the different model?",
                    "label": 0
                },
                {
                    "sent": "The choice biases are represented here, and for me, the first time I saw those figures are always found them confusing, and yet they convey very simple message what those guys found in that.",
                    "label": 0
                },
                {
                    "sent": "If the rats are confronted with a hard trial on the current route, so it's data can't quite tell what's going on, they tend to rely on what they did on the previous trial.",
                    "label": 0
                },
                {
                    "sent": "If it was rewarded.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of win state.",
                    "label": 0
                },
                {
                    "sent": "OK, there are ordered by going writing last trial and the current trial is hard.",
                    "label": 0
                },
                {
                    "sent": "They're going to tend to go right more than they should.",
                    "label": 0
                },
                {
                    "sent": "And that's basically indicated by having points that are above 0.",
                    "label": 0
                },
                {
                    "sent": "Here positive value means they're just doing Wednesday.",
                    "label": 0
                },
                {
                    "sent": "I don't know if they're doing loose shift, by the way in this experiment, because we don't have enough data to really tell, but they're doing Wednesday and they're doing it only if the current trial is hard.",
                    "label": 0
                },
                {
                    "sent": "Which are the red dots here?",
                    "label": 0
                },
                {
                    "sent": "If the current trial is is very easy so they can tell right away from the data what's going on.",
                    "label": 0
                },
                {
                    "sent": "They don't rely on what they did on the previous trial, and that's what is indicated by the black dots here.",
                    "label": 0
                },
                {
                    "sent": "In addition, I didn't tell you yet what is the X axis here.",
                    "label": 0
                },
                {
                    "sent": "The X axis, the previous trial difficulty, and this is actually where this task and this data becomes difficult to internalize.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that the choice bias also depends on how difficult the previous route was, and it depends in different ways depending on detection and categorization in a detection task, the choice biases are not very dependent on the previous trial difficulty worth in the categorisation task they are.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go into details of this.",
                    "label": 0
                },
                {
                    "sent": "All I want to say here that's in a sense that was good news for us because that's really going to help us constrain the model.",
                    "label": 0
                },
                {
                    "sent": "Whatever model would develop, it has to actually fit this deal.",
                    "label": 0
                },
                {
                    "sent": "Oak.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let's go back to our hypothesis.",
                    "label": 0
                },
                {
                    "sent": "First idea is that can't quite remember the boundary because of bad hardware.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're going to go back to the DM and we're going to expand that DM.",
                    "label": 0
                },
                {
                    "sent": "First, we're going to add.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bias unit, that's a unit that's always on it has a weight onto the drift process here, and the weights is basically going to now correspond to the prior probability that the animal thinks that right is rewarded versus left.",
                    "label": 0
                },
                {
                    "sent": "In this experiment, it's all balanced exactly the same, but then we'll have to learn it, and we're going to assume that it's done through that bias unit.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Second thing is we're going to let the noise that sorry, we're going to let the weights here vary from trial to trial so the.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Important thing to realize is that those weights here the determine the categorisation boundary.",
                    "label": 0
                },
                {
                    "sent": "They determined this particular line here.",
                    "label": 0
                },
                {
                    "sent": "The line the Unity line.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Correspond to the weights being set to 1 -- 1 and 0.",
                    "label": 0
                },
                {
                    "sent": "And if the weights set, the boundary then went.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Add noise to those ways here, then.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm doing that effectively making this boundary fluctuates, so that's what we're going to do next.",
                    "label": 0
                },
                {
                    "sent": "We're going to expand the model by adding on the troubled by on every trial we're going to draw the weight from a normal distribution centered at 1 -- 1 zero with some variance Sigma squared Sigma Square is going to be free parameter, which we're going to fit to the data.",
                    "label": 1
                },
                {
                    "sent": "So we just added one free parameter.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we go into our task and we first we're going to take the detection task and we're going to use a detection task to fit all the parameters except for the amount of noise that we inject into the weights, and the reason is because the detection test doesn't actually constrain it at all.",
                    "label": 0
                },
                {
                    "sent": "This parameter we can fit it, but we get huge error bars, so we don't really trust it so.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we realized is we can fit it by using the categorization data.",
                    "label": 0
                },
                {
                    "sent": "So we're going to use the categorization data just to constrain that particular parameter.",
                    "label": 0
                },
                {
                    "sent": "The amount of noise that we inject in the weights.",
                    "label": 0
                },
                {
                    "sent": "So if we do that, if we could do this double step fitting procedure, we find that now we can fit the data, the performance, the accuracy, and the reaction time from both task, and particularly that now performance has indeed dropped for the categorisation task, which is due to this injection of noise in the weights.",
                    "label": 0
                },
                {
                    "sent": "But remember that we also have the choice biases, and the question is what do we predict for the choice?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vice is well, what we find with this particular model is that basically we don't see any choice biases, and that's not so surprising because we re drawn every trial the weights here, so we don't have any temporal dependencies between trials.",
                    "label": 0
                },
                {
                    "sent": "So of course we cannot get the choice biases with them all like this.",
                    "label": 0
                },
                {
                    "sent": "So this tells us that it cannot just be noise, it cannot be just fluctuation in the noise has to be something.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how about learning?",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do next?",
                    "label": 0
                },
                {
                    "sent": "Now is we're going to just use standard learning rule for learning those weights on the trial by trial basis, and in particular for the way.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Coming from the accumulated evidence, we're going to use just a standard Delta rule, so we're not reinventing the wheel here, and we have a new free parameter which is just a learning rate, which we're going to adjust to fit the data.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when you do this using exactly the same procedures before fit all the parameters, But the learning rate onto detection you.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The category categorization just to constrain the learning rate we can once again fit the accuracy and the reaction time.",
                    "label": 0
                },
                {
                    "sent": "But what's really nice is that now we freezer model and we just ask what does it predict for the choice bias?",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And where did predict exactly the pattern that we see in the data, and in particular the fact that the dependency on the previous trial difficulty is different in both tasks?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This kind of data kind of suggests to us quite strongly that we're not dealing with just pure stochastic noise, and that it's quite possible that the fluctuation we see are due to deterministic learning just.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To convince us that the model is really on the right track, we tried one more manipulation.",
                    "label": 0
                },
                {
                    "sent": "Currently the model is trained on this particular data points here that you're seeing indicated on the plot, but of course we could easily train the app.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On any other categorisation task where we're going to change the baseline level of order concentration.",
                    "label": 0
                },
                {
                    "sent": "And we're going to ask if I train the model on the identification and the outside categorisation, how well does it do it predicting the other conditions?",
                    "label": 0
                },
                {
                    "sent": "And so in this particular experiment we actually trained the rats and interleave trials where they go through all those different trials and we just like go back and forth between those different tasks.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it turns out that we don't have to readjust any of the parameters if we just train again on the extreme conditions, we find that the model generalizes for accuracy and for reaction time to all the other conditions.",
                    "label": 0
                },
                {
                    "sent": "So of course I can tell you for sure that it's absolutely learning.",
                    "label": 0
                },
                {
                    "sent": "More tests are needed, but only given the data we have so far, it looks like learning can explain why we have this drop in performance without to invoke some kind of more noise.",
                    "label": 0
                },
                {
                    "sent": "Magical noise that's supposedly stopping the animal from performing any better.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So once again.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Principle here, the general principle is that if you don't know how the data were generated, then you can possibly be optimal.",
                    "label": 0
                },
                {
                    "sent": "You're going to make approximation, and those approximations are going to appear as extra variability.",
                    "label": 0
                },
                {
                    "sent": "So in this case, if you don't know that the task is static, and you assume that it's not, you pay a price by having extra variability.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I would argue that for most problems with interest, especially things like object recognition, there's no way you can know the model the.",
                    "label": 0
                },
                {
                    "sent": "The optimal model for sure, so you're going to make approximations and those approximations are always going to result in extra variability, and so for most problems interest.",
                    "label": 0
                },
                {
                    "sent": "That's the biggest problem that the brain has to face.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's effectively what we argue in this particular paper, we offer just more argument than the one you just heard here.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm done with the first experiment.",
                    "label": 0
                },
                {
                    "sent": "Now I want to quickly tell you about the second one, which is that as far as we can tell, noise doesn't seem to have that big of an impact on your performance.",
                    "label": 0
                },
                {
                    "sent": "So what is it based on?",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this time I'm going to tell you about experiments.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm doing in collaboration with this guy, Zach Pico Kaushik, something I can't use pronounce this name too complicated for me.",
                    "label": 0
                },
                {
                    "sent": "We call you Kaushik.",
                    "label": 0
                },
                {
                    "sent": "Very nice guy Greg Deangelis and or Angelocci and Zach Kaushik and Dora are all three are Valley College of Medicine in Houston.",
                    "label": 0
                },
                {
                    "sent": "I see some people are trying to read the name.",
                    "label": 0
                },
                {
                    "sent": "It's not that easy, right?",
                    "label": 0
                },
                {
                    "sent": "And Greg Dangelis, that University of Rochester.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and what we ask with those guys is, does internal noise actually affects behavioral performance?",
                    "label": 0
                },
                {
                    "sent": "And to enter this, here is a dream experiments that I'd like to do one day and then in front is not the experiment I'm going to describe next, but here's what we wanted to do.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What I'd like to do is you start with your favorite stimulus, whatever.",
                    "label": 0
                },
                {
                    "sent": "If you're doing decision-making, let's say you do the random dot motion task and you're trying to ask subject whether the dots are moving to write some.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We know that this particular stimulus activates this V12 empty pathway, so we stick thousands and thousands of electrodes, hundreds of thousands of electrodes in empty to try to see the overall population activity in empty.",
                    "label": 0
                },
                {
                    "sent": "That's the step that right now we can do, but we're not that far away from being able to do that one, but right now we can do that.",
                    "label": 0
                },
                {
                    "sent": "So we record from all the neurons in emptying during the task.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we developed an optimal decoder of area empty to figure out what is the performance in the optimal decoder, how much information is there effectively in area, empty and we compare.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That to the performance we get from the behavior that's going to be the goal.",
                    "label": 0
                },
                {
                    "sent": "And I can imagine now two scenarios.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One is that the brain between empty and the motor cortex of brain implements a noiseless optimal decoder.",
                    "label": 0
                },
                {
                    "sent": "If that's the case, then the decoder's performance and the behavioral performance should be comp.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the other hand, you think that the brain is noisy and there's tons of noise in those circuits, and that's really what's constraining your performance than the presence of the noise.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Means that your behavioral performance will be much smaller than you would predict by decoding area empty, right so?",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Roughly what you would expect that the information in the behavior here should be a tiny fraction, perhaps less than 5% of the information that you recovered from the decoder.",
                    "label": 0
                },
                {
                    "sent": "That would indicate that noise is really the bottleneck here, and that's the problem for the system.",
                    "label": 0
                },
                {
                    "sent": "OK, so as I told you, we can quite do this experiment in Fortnite, but we did the second best thing that we can do with the kind of data we have, which is single cell recording from area MTN from other areas, so.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First of all, let me tell you briefly the test that we're using.",
                    "label": 0
                },
                {
                    "sent": "We're using here test that was designed by Greg Deangelis and Orange Lucky that they've been using for a variety of experiments.",
                    "label": 0
                },
                {
                    "sent": "And here what's happening is you have a monkey.",
                    "label": 0
                },
                {
                    "sent": "You can't quite tell, but that's supposed to be a monkey that's sitting in this big thing here, which is a vestibular platform.",
                    "label": 0
                },
                {
                    "sent": "It's a mechanical things that actually can move the monkey, and whatever is sitting on this platform in any direction in space.",
                    "label": 0
                },
                {
                    "sent": "So this activates the vestibular system.",
                    "label": 0
                },
                {
                    "sent": "You sense of acceleration.",
                    "label": 0
                },
                {
                    "sent": "And in this particular case we use a platform to move the monkey forward, and as we move the monkey forward, we move them slightly to the left or slightly to the right, and the task is a monkey in any given trial is to tell in which direction we're moving, right or left.",
                    "label": 0
                },
                {
                    "sent": "So we do this while we record the activity of neurons in a variety of areas, and then we're going.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at what we call choice correlations.",
                    "label": 0
                },
                {
                    "sent": "We're going to look at the fluctuation between the the fluctuation of 1 neuron wild animal is performing the task and the fluctuation in the response of the animal from trial to trial right?",
                    "label": 0
                },
                {
                    "sent": "So this is a concept that was first introduced by Ken Britain, Bill Newsome and colleagues quite awhile ago they called the choice probability.",
                    "label": 0
                },
                {
                    "sent": "I think mathematically it makes more sense to look for choice correlations, which is what I'm going to look at here and their argument was like look if a neuron is contributing to the behavior, then fluctuation that neuron should have an influence on the behavior.",
                    "label": 0
                },
                {
                    "sent": "Until they realize that, well, it depends, because if all the neurons are independent and there are thousands, or there's a million neurons involved in the task, then each neurons is contributing one in a million's to the decision.",
                    "label": 0
                },
                {
                    "sent": "So you're unlikely to see the effect until they realize that Oh no, is the neurons are correlated?",
                    "label": 0
                },
                {
                    "sent": "Then perhaps a single neurons might have an influence on behavior, and that's what they reported in the mid 90s that there's a significant correlation between fluctuation neurons and empty, and the decision of the animal.",
                    "label": 0
                },
                {
                    "sent": "So we're going to do the same thing here.",
                    "label": 0
                },
                {
                    "sent": "We're going to track those choice correlations.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with Zach people realize as we were doing those experiments is that indeed we can predict what Choice Coalition are going to look like for single neurons.",
                    "label": 0
                },
                {
                    "sent": "If the read out of the area that we're recording from is optimal, and that optimal decoder is linear if those conditions are met, then it's possible to allergically figure out what the choice correlations are going to look like.",
                    "label": 0
                },
                {
                    "sent": "An expression is incredibly simple.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The choice correlation of neuron K have to be equal to this ratio.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where it's a ratio of the behavioral threshold of the model or the animal, there are the same here.",
                    "label": 0
                },
                {
                    "sent": "That's the optimal model.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Over the threshold for neuron K, so this is how well you can discriminate right from left based on the activity or just one of that particular neuron.",
                    "label": 0
                },
                {
                    "sent": "OK, so choice correlation is given by this ratio.",
                    "label": 0
                },
                {
                    "sent": "If the area is decoded optimally, so we are great because we can measure all those things.",
                    "label": 1
                },
                {
                    "sent": "We can measure the behavioral threshold.",
                    "label": 1
                },
                {
                    "sent": "That's easy, we can analyze the response of each neurons and figure out how well we can discriminate heading from single neurons.",
                    "label": 1
                },
                {
                    "sent": "And we can see whether this ratio correspond to the measured choice correlations.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is what the data looks like the bad user choice?",
                    "label": 0
                },
                {
                    "sent": "Correlations are incredibly noisy, they're very hard to get.",
                    "label": 0
                },
                {
                    "sent": "It takes times of trials, so we only have mag noisy measurement.",
                    "label": 0
                },
                {
                    "sent": "My hunch when we started this is we wouldn't see much, but it turns out that we do see a trend, so this is here along.",
                    "label": 0
                },
                {
                    "sent": "the Y axis is a measured correlation along the X axis is a predicted correlation for an optimal decoder, and if we were correct, then all of these plots the data should line up along the Unity line.",
                    "label": 0
                },
                {
                    "sent": "The different colors by the way.",
                    "label": 0
                },
                {
                    "sent": "Respond to different brain areas and the letters correspond to different monkeys and I'm going to tell you more about this in a second.",
                    "label": 0
                },
                {
                    "sent": "But you see this kind of like in the right direction, so we did some stats on this.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pretty simple, we just did.",
                    "label": 0
                },
                {
                    "sent": "We regressed it over theory against CK and looked at what kind of regression coefficient we got.",
                    "label": 0
                },
                {
                    "sent": "So here I'm plotting beta regression coefficient and you can see that, at least for the 6th first 6 bars.",
                    "label": 0
                },
                {
                    "sent": "Here we hovering around one as expected for optimal decoding.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I should have labeled that a bit, but you see, like their little bars here that correspond to large shades of Gray.",
                    "label": 0
                },
                {
                    "sent": "This is actually the coefficient of regression we get if we try a suboptimal decoder.",
                    "label": 0
                },
                {
                    "sent": "In this case, it's called a factorized decoder.",
                    "label": 0
                },
                {
                    "sent": "What we find is we can explain the data with this large class of sub optimal decoder optimal decoder.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, does a pretty good job at explaining what we see.",
                    "label": 0
                },
                {
                    "sent": "Well, except.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Course for those bars here, so I forgot to say the green bars.",
                    "label": 0
                },
                {
                    "sent": "Here are the vestibular nucleus and the cerebellar Nicholas where you see a lot of vestibular responses and the orange one is empty, which is the visual area, which also respond to better signals.",
                    "label": 0
                },
                {
                    "sent": "But VIP, which is yet another area in parallel cortex, shows a very weird pattern, which is an instead of finding.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One we find correlation coefficient up to three, and it's not like very suboptimal decoder like factorized would explain the data because it doesn't explain the data at all.",
                    "label": 0
                },
                {
                    "sent": "This stops us in our tracks for quite awhile because we also use something else.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "VIP, so I'm going back here.",
                    "label": 0
                },
                {
                    "sent": "The choice correlation for VIP Ann here along the Y axis is the actual choice correlation that we measure in VIP an if you look at the.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's something very bizarre.",
                    "label": 0
                },
                {
                    "sent": "Those neurons here.",
                    "label": 0
                },
                {
                    "sent": "Each dot is 1 neurons.",
                    "label": 0
                },
                {
                    "sent": "Those neurons have choice correlation of 1.",
                    "label": 0
                },
                {
                    "sent": "If you're recording from that neuron, you know in every trial with the animal is going to do.",
                    "label": 0
                },
                {
                    "sent": "You should know that if you do that, experiments in empty, you know maybe on 5% of the trial with the animal is going to do an average.",
                    "label": 0
                },
                {
                    "sent": "Here it's 100% of the trial.",
                    "label": 0
                },
                {
                    "sent": "It's as if we're right at the output of the system.",
                    "label": 0
                },
                {
                    "sent": "And choose correlations often are thought to be kind of an indication of how much a particular area contributes to task.",
                    "label": 0
                },
                {
                    "sent": "So here that seems to say, well, it's contributing as much as you can possibly contribute to a task like this.",
                    "label": 0
                },
                {
                    "sent": "This is very unusual data for anybody who is recorded from neurons like this.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And yet the decoding of area VIP suboptimal in some sense because we didn't get a regression coefficient of what, so that's really stopped us for many, many months, because wondering under which scenario can you possibly get this?",
                    "label": 0
                },
                {
                    "sent": "And eventually we found a scenario where you get this and the sonar.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As if this is possible, if one first of all VIP is highly redundant with other areas.",
                    "label": 1
                },
                {
                    "sent": "Whatever information you have in VIP, you already have somewhere else, so VIP is getting a copy of what's going on, maybe in STD.",
                    "label": 0
                },
                {
                    "sent": "And say.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's not right out.",
                    "label": 0
                },
                {
                    "sent": "And that was kind of surprising because we just saw that the choice correlation are very, very high, but that's the only scenario we could think of where we could explain this.",
                    "label": 0
                },
                {
                    "sent": "Well long we hold at the same.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time door into like he was doing inactivation experiments of area, STD and VIP.",
                    "label": 0
                },
                {
                    "sent": "In this task they were injecting usable in VIP or MC D to shut it down while the animal is performing the task.",
                    "label": 0
                },
                {
                    "sent": "And here's the result that she had obtained.",
                    "label": 0
                },
                {
                    "sent": "So it's completely different set of experiments.",
                    "label": 0
                },
                {
                    "sent": "We had no idea list.",
                    "label": 0
                },
                {
                    "sent": "Two things were going to be connected and what you see here.",
                    "label": 0
                },
                {
                    "sent": "The threshold increase after his injections and four M STD you see that there is a 3 three fold increase in the behavioral threshold.",
                    "label": 0
                },
                {
                    "sent": "The animal as a result of.",
                    "label": 0
                },
                {
                    "sent": "In activating STD.",
                    "label": 0
                },
                {
                    "sent": "And eventually the animal recovers.",
                    "label": 0
                },
                {
                    "sent": "If we do the same experiment VIP, nothing happens.",
                    "label": 0
                },
                {
                    "sent": "There's not no change whatsoever, suggesting that vaping is just not contributing in this particular experiment.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Looks like this makes sense now.",
                    "label": 0
                },
                {
                    "sent": "VIP is highly redundant and indeed it's not being read out.",
                    "label": 0
                },
                {
                    "sent": "The fact that it's highly redundant is very interesting because it's telling us that even though VIP is not being read out optimally.",
                    "label": 0
                },
                {
                    "sent": "That's not a big deal because the information that's in VIP's already available in STD, and the CN in the VN and those areas appears to be read out optimally.",
                    "label": 0
                },
                {
                    "sent": "So in fact we build a big model of all of this.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Based on all this data set and our current estimate.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that about 80% of the information available in MSDN VIP is actually driving the behavior.",
                    "label": 0
                },
                {
                    "sent": "And so that.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At least only about 20% for noise.",
                    "label": 0
                },
                {
                    "sent": "If noise is playing a role in this experiment, it's only constraining 20%, not 95%.",
                    "label": 0
                },
                {
                    "sent": "Only a small fraction, but even then, remember that whenever you see noise, you should worry that perhaps it's suboptimal behavior, so perhaps there are more suboptimal steps here that we haven't identified yet.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to conclude.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We started with the Noise Brain Fest in the first half of the talk.",
                    "label": 0
                },
                {
                    "sent": "I tried to convince you that we should.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Replace it with a sub optimal brain fast that this is really where the problem is and the second half I was trying to show you that yeah, maybe there is noise in your brain, but the good news is that it doesn't seem to be affecting your performance and I want is just one less thing on noise in the brain.",
                    "label": 0
                },
                {
                    "sent": "I actually believe there is noise in the brain.",
                    "label": 0
                },
                {
                    "sent": "Just plenty of evidence that there is noise in the brain that there are fluctuations, stochastic fluctuation, response of the animal and it might be good for things like sampling.",
                    "label": 0
                },
                {
                    "sent": "This is a theme that came up several times starting with Allison's talk this morning.",
                    "label": 0
                },
                {
                    "sent": "It might be good for exploring, of course, but again the good news and I think that anybody who uses sampling would agree with this that you wanted to learn things, but once you perform you don't want the noise to affect your performance, and that appears to be what we're finding.",
                    "label": 0
                },
                {
                    "sent": "At least it doesn't have a big impact on your performance.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "I just have a question about your first experiment.",
                    "label": 0
                },
                {
                    "sent": "I was just curious how long you had between each of your rat trials and just maybe if could it be possible.",
                    "label": 0
                },
                {
                    "sent": "If there was overstimulation of the nose and that could be reason I have a hard time hearing you so I was just wondering.",
                    "label": 0
                },
                {
                    "sent": "How far apart with each of your trials in the rats in the first experiment and if it was maybe short, could there be overstimulation of the nose and that could be a reason for your discrepancy between the rats in the model that their nose was just over stimulated from so much odors?",
                    "label": 0
                },
                {
                    "sent": "And if there was enough time to recover from that, or if you had like something like coffee beans to kind of cleanse the nose palette, I don't know.",
                    "label": 0
                },
                {
                    "sent": "One big worry in this experiment.",
                    "label": 0
                },
                {
                    "sent": "If you for instance show like 100% at a high concentration, then the nodes will adapt to 100% A and that when you show another mixture, it's basically subtracting subtracting a from the mixture and the animal would tend to go before instance.",
                    "label": 0
                },
                {
                    "sent": "Those other can think that we worried about, but the wind stays strategy is exactly the opposite.",
                    "label": 0
                },
                {
                    "sent": "If you actually smelled a on the previous trial, you tend to actually respond again on next row, so I probably can tell there is no adaptation problems, but.",
                    "label": 0
                },
                {
                    "sent": "Maybe there are other things we haven't thought about, but it should be.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there's so much ages left in there because it's just over stimulated with that type of odor.",
                    "label": 0
                },
                {
                    "sent": "I mean, if it means that they're the ones are in steady state only a fraction of the receptors are really being active.",
                    "label": 0
                },
                {
                    "sent": "That's fine, we're in steady state, so we don't worry too much about this.",
                    "label": 0
                },
                {
                    "sent": "What we really worried about interaction between trials that we don't think can be explained just by simple adaptation explanations.",
                    "label": 0
                },
                {
                    "sent": "A great talk.",
                    "label": 0
                },
                {
                    "sent": "So suppose I want behavioral variability and you kind of alluded.",
                    "label": 0
                },
                {
                    "sent": "This eluded to this at the end with the randomness for exploration.",
                    "label": 0
                },
                {
                    "sent": "For example, should I be looking for in my experimental data?",
                    "label": 0
                },
                {
                    "sent": "And I mean actually, my experimental data should be looking for.",
                    "label": 0
                },
                {
                    "sent": "That coming from say, just my inference gets worse when I want to be more random or my.",
                    "label": 0
                },
                {
                    "sent": "I should be looking for it in the neuron noise.",
                    "label": 0
                },
                {
                    "sent": "Do you think there's space in the neural noise to generate noise for exploration?",
                    "label": 0
                },
                {
                    "sent": "And for other cases where you want to be random?",
                    "label": 0
                },
                {
                    "sent": "It could be, I mean right.",
                    "label": 0
                },
                {
                    "sent": "As you probably know, there is several people who are arguing that noise in the brain is a form of sampling.",
                    "label": 0
                },
                {
                    "sent": "I think right now it's the jury's out as to whether that's really the way we we explore, and whether it's true stochastic exploration due to stochastic noise in the neurons.",
                    "label": 0
                },
                {
                    "sent": "I'm open to the idea I have myself a paper showing that bistable perception is complete, consistent with the sampling mechanism.",
                    "label": 0
                },
                {
                    "sent": "So it's quite possible, but I think we're just at the beginning of this particular hypothesis, yeah, so, so it's still an open question.",
                    "label": 0
                },
                {
                    "sent": "Then we can still as a hypothesis have it can be in the neural noise.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and it's an experiment.",
                    "label": 0
                },
                {
                    "sent": "In fact, have gone math was sitting somewhere I can't see him anymore, but I'm involved in glasses.",
                    "label": 0
                },
                {
                    "sent": "Who is here at this conference was right by you.",
                    "label": 0
                },
                {
                    "sent": "It's 1 one of the people who been pushing quite hard.",
                    "label": 0
                },
                {
                    "sent": "The idea that this is what it's about.",
                    "label": 0
                },
                {
                    "sent": "I think the proper experiments have not been done yet.",
                    "label": 0
                },
                {
                    "sent": "To really prove that this is the case, the only group that's pushing really hard is metal angle, and Joseph Fisher in V1 and there is already a lively debate, almost as lively as this one going on, and we've shown some stuff in decision making with that for explore, exploit decision-making, there's seems to be a random component that yeah, but whether it's related to whether it's related to noise, yeah?",
                    "label": 0
                },
                {
                    "sent": "That's that's that's a big question.",
                    "label": 0
                }
            ]
        }
    }
}