{
    "id": "af2ufchojp2vbycdytkbii3ev4yuu4gc",
    "title": "Filter-based Mean-Field Inference for Random Fields with Higher Order Terms and Product Label-Spaces",
    "info": {
        "author": [
            "Vibhav Vineet, Oxford Brookes University"
        ],
        "chairman": [
            "Ramin Zabih, Department of Computer Science, Cornell University",
            "Laurent Itti, University of Southern California"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2012_vineet_filter/",
    "segmentation": [
        [
            "In this work, our focus is on dense image labeling problems.",
            "For example, object segmentation, stereo or optical flow problem.",
            "In computer vision, generally these problems are solved using graph cuts and that has been the method of choice."
        ],
        [
            "So far."
        ],
        [
            "For inference recently, message passing methods have started to achieve same accuracy but at much faster than times.",
            "But they model only pairwise sheriff's."
        ],
        [
            "However, from our past experience, we know that many problems in computer vision require higher order information.",
            "For example, Coca systems and product level spaces.",
            "Thus in this work."
        ],
        [
            "Our main contribution is to develop efficient message passing based methods for certain classes of these higher order terms."
        ],
        [
            "In order to highlight the importance of context and Co occurrence, I'm showing here very one example.",
            "Let's take this cropped image.",
            "Identify the object inside this subject.",
            "I had asked this same question to one of my friends and he said there is a car and many people might make us it wrongly like car or chair or something."
        ],
        [
            "But from the context of scene, we know there is a keyboard in the image and that's what contexts where context is very important for scene."
        ],
        [
            "Understanding.",
            "We use these kinds of global Co occurrence cost to enforce these kinds of Co occurrence of objects in the scene and these kinds of costs have been shown to improve the accuracy in some of our past works and we are able to this we are able to enforce that keyboard table and monitor off and cook it together in this."
        ],
        [
            "Sing another kind of higher order information can be in terms of being parts which enforce this consistency over region, and one instance can be detected based potential where we try to enforce the consistency over the pixel of objects inside this bounding box, and I'm showing one example where this this bounding box is able to help help in recovering the object.",
            "So we use this."
        ],
        [
            "Kinds of higher order information to improve the object class segmentation problem as well."
        ],
        [
            "Also, to improve the quality of joint object, Listeria estimation for product level spaces."
        ],
        [
            "Generally, these problems are formulated in Seattle framework, where we have a per pixel unit demand pairwise smoothness term."
        ],
        [
            "And also, as I discussed, we also have this higher order information in terms of region based consistency and Co occurrence defined over the whole image click."
        ],
        [
            "Generally, inference in these higher order with these higher order model are done using graph cut based Alpha expansion method.",
            "But one thing like we all have come across that graph cut based methods for with cooccurrence.",
            "Another hard models are almost 10 times slower than only with pairwise terms.",
            "So in the."
        ],
        [
            "Work with develop filter based mean field approach which is almost 10 to 40 times faster depending on the problem.",
            "Faster than graph cut based self expansion method."
        ],
        [
            "Mean Field has been started to be used in some of our recent works and one of the one of very interesting work was by grand.",
            "Well at all last year, Nips who propose efficient inference method for proposed efficient method for influencing this pairwise CRF, but they make two assumptions.",
            "One is that they take mean filler approximation to CRF, and another is that their pairwise terms take only the.",
            "A linear combination of Gaussian kernels."
        ],
        [
            "So with these two assumptions, they are able to achieve almost five times speedup compared to graph cut based method.",
            "And another important factor with their model is that they are able to handle this dense connectivity between variables and we can see here I'm showing one example that these kinds of dense connectivity can be useful in recovery, useful in discovering the final bond, dis around the objects."
        ],
        [
            "I'll go into some of the related works which are very important.",
            "I like what, what, what we do in mean field in France is we take a tractable family of distribution and we tried to approximate the true distribution P by one approximate distribution from this family Q.",
            "And one family of distribution can be when we assume complete factorization over marginals of the variables.",
            "Then we minimize we minimize the kelda vergence distance between Q distribution and P distribution to get the best Q which approximate DPD."
        ],
        [
            "Tuition.",
            "When we minimize the scale distance, we get the fixed point solution, which looks something like this.",
            "Here the with this we evaluate the marginal for a variable I getting labeled L, which involves the evaluating the expectation of cost.",
            "Here it is unit in pairwise cost under Q distribution."
        ],
        [
            "As we had seen, the term in Blue Box is very expensive.",
            "One of the contribution of Granville was to show that this can be represented as a Gaussian convolution step and once they do present this as a Gaussian convolution step, they used this efficient filtering step to do this expensive message passing."
        ],
        [
            "3rd efficiently and in their work they use this parameter header lattice based filtering approach and in this work we try to evaluate the efficiency offered by some other methods as well, like domain transfer based."
        ],
        [
            "Filtering.",
            "Now I'll go through so some of the QQ distribution for some of the classes looks across iteration and will see that as we move across hydration, the confidence of variable taking our label keeps on in."
        ],
        [
            "Crazy and."
        ],
        [
            "At the end, what we do?"
        ],
        [
            "This will get the maximum posterior marginal solution by taking the label for a variable which maximizes the marginal for that variable.",
            "Now I'll get into how we added this higher order information into fully connected pairwise CRF.",
            "As we can see this box terms in this red box is still computationally expensive."
        ],
        [
            "2 holiday emphasize the complexity.",
            "I've taken one the strike sample.",
            "Let's say this.",
            "Here is a click with three variable and each variable is taking a level from level set of three levels and to evaluate the marginal for this variable, one taking level one we can see we need to evaluate 9 terms which are shown in this block black boxes.",
            "Similarly we need to evaluate another name terms to for this variable, taking level 2 as well as we need another nine times for this variable taking Level 3.",
            "So."
        ],
        [
            "Angel, the complexity for adding higher order information in this mean field framework will be exponentially.",
            "Number of labels and size of clicks, but we now I'll show we solve these problems for PN potsane.",
            "Cocoran storm sufficiently."
        ],
        [
            "Now I'll jump into this paean parts model again.",
            "I'll show using one toy example.",
            "Let's take let's take a click with Subs, size, size 6, and each variable is still again taking label from level set of size 3.",
            "And here we enforce that level configuration of click is dependent on whether all variable in that click takes same label or not.",
            "So here the states are configuration of label.",
            "Valid configurations are only three and we.",
            "Attach associative cost to each of these valid configuration, like Gamma Zero, Gamma one, and gamma 2.",
            "And we also have our gamma Max cost for all other invalid configuration.",
            "Now as you can see the since we have the."
        ],
        [
            "Stricted the number of configuration of the evaluation of expectation across the configuration of this click can be done efficiently.",
            "As we can see these on reusing the expectation or here will be able to see that complexity from exponential comes down to linear in number of labels and size of variable.",
            "Number of variables are model can also be extended to other pattern based potential which were which are defined by common to kiss and other authors decently."
        ],
        [
            "Now I'll get into the Co occurrence terms cokers model should favor the second model which is in this case, which is better than the first model."
        ],
        [
            "So what Cokers model tries to do is test to attach a cost to each of these sub set of labels present in the image.",
            "So here Lambda is the Lambda access.",
            "This subset of labels and C is the costs associated with that.",
            "We make two assumptions to this cost fir."
        ],
        [
            "It is that we take second order function for the cost function, where we assume that our cost factorizes into unity and Paris terms."
        ],
        [
            "2nd, we represent this cost by set of binary latent variable Y12Y L the semantic of this.",
            "These latent variables are that when?",
            "Why Ellis zero?",
            "We assume that there should not be any variable in image domain taking that label L and when while is one, we assume that there should not be.",
            "There should be some variable image domain taking that label L."
        ],
        [
            "No, we enforce the global constraint by saying that went with this constant that when YL is zero, there should not be must not be any variable in image domain.",
            "Taking that level L. Otherwise we pay a cost of fixed cost of K for every violation of this constraint.",
            "With these two assumptions, we are able to again reduce the complexity in polynomial exponential to number polynomial in number of variables an labels."
        ],
        [
            "Novy also Deb these higher order information to do inference for influencing product level space.",
            "Here we are showing we did experiments for jointly estimating object and stereo for each of the label.",
            "So we defined and joint energy function over this product label space where we have joint unity joint pairwise and joint higher order terms or this space."
        ],
        [
            "Now I'll go into details of this sum of experiments.",
            "1st, I'll show the experimental Pascal view seating segmentation data set and our results are on the last column and we can see some of the qualitative we are able to do better than some of the.",
            "Decently complex models developed recently, like models of Alpha logically at all based on graph based."
        ],
        [
            "Limited.",
            "Quantitatively, we observe an improvement of almost 2.5%.",
            "Intersection Union is code than the model of Ladakhi, which is again without code based."
        ],
        [
            "And also we are certain speed up of almost 10 times compared to their model."
        ],
        [
            "Here we didn't experiment for joint object in studio labeling on 11 data set there are seven object labels and hundred disparity labels.",
            "Here's some of the quantitative results, but."
        ],
        [
            "Main impact is here, qualitatively quantitatively we see slight improvement in its accuracy of studio results, but the main impact is we observe in 3235 times speedup compared to this radical model, which is graph cut based Alpha expansion method."
        ],
        [
            "So with this I would like to conclude that we in this work we tried to develop efficient message passing based method and we tried to incorporate higher order information in this CRF fully connected pairwise here framework.",
            "And we demonstrated the efficiency and accuracy offered by our model on object segmentation and Joint Object Studio estimation problem.",
            "And good thing is that code is online.",
            "I would like you guys to download and try on your favorite vision problems.",
            "Thank you.",
            "Do you find that your method is sensitive to noise in the input images, given that you have these high order terms?",
            "I have not tried whether it is sensitive to noise, but method is slightly sensitive to initialization.",
            "If you have good initialization, will get the good results, but all these in all these experiments we have kept the same.",
            "Starting point, even with the graph cut and our model, and there is another paper we had returned.",
            "How to make it even there's some other methods.",
            "Publishing it on 2000.",
            "How to make the mean field methods more robust to initialization?",
            "But in all these experiments we do not find any that bigger issue with initialization or any other noise.",
            "So why were the results not considerably better?",
            "Could it be that like the like, the fully connected and the PN pots are quite similar effects?",
            "They all go for detail on the boundaries.",
            "Is that why there is like combining all of it didn't improve so much or?",
            "Actually, I think one of the reasons as far as I believe, is that in order to improve a big improvement in accuracy, we need better unit potential.",
            "These pairwise terms or even higher order terms, tries to incorporate some consistency or some smoothness across boundaries.",
            "But the actual benefit when we have better unit potential, like in this work, our starting unit potential was around 1314% accuracy.",
            "We used some better unit potential and our baseline was like 28%, so I think better unit potential will be will give more impact, better accuracy, a lot, better accuracy.",
            "Great, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this work, our focus is on dense image labeling problems.",
                    "label": 0
                },
                {
                    "sent": "For example, object segmentation, stereo or optical flow problem.",
                    "label": 0
                },
                {
                    "sent": "In computer vision, generally these problems are solved using graph cuts and that has been the method of choice.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So far.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For inference recently, message passing methods have started to achieve same accuracy but at much faster than times.",
                    "label": 0
                },
                {
                    "sent": "But they model only pairwise sheriff's.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, from our past experience, we know that many problems in computer vision require higher order information.",
                    "label": 0
                },
                {
                    "sent": "For example, Coca systems and product level spaces.",
                    "label": 0
                },
                {
                    "sent": "Thus in this work.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our main contribution is to develop efficient message passing based methods for certain classes of these higher order terms.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In order to highlight the importance of context and Co occurrence, I'm showing here very one example.",
                    "label": 0
                },
                {
                    "sent": "Let's take this cropped image.",
                    "label": 0
                },
                {
                    "sent": "Identify the object inside this subject.",
                    "label": 0
                },
                {
                    "sent": "I had asked this same question to one of my friends and he said there is a car and many people might make us it wrongly like car or chair or something.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But from the context of scene, we know there is a keyboard in the image and that's what contexts where context is very important for scene.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Understanding.",
                    "label": 0
                },
                {
                    "sent": "We use these kinds of global Co occurrence cost to enforce these kinds of Co occurrence of objects in the scene and these kinds of costs have been shown to improve the accuracy in some of our past works and we are able to this we are able to enforce that keyboard table and monitor off and cook it together in this.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sing another kind of higher order information can be in terms of being parts which enforce this consistency over region, and one instance can be detected based potential where we try to enforce the consistency over the pixel of objects inside this bounding box, and I'm showing one example where this this bounding box is able to help help in recovering the object.",
                    "label": 0
                },
                {
                    "sent": "So we use this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kinds of higher order information to improve the object class segmentation problem as well.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, to improve the quality of joint object, Listeria estimation for product level spaces.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Generally, these problems are formulated in Seattle framework, where we have a per pixel unit demand pairwise smoothness term.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also, as I discussed, we also have this higher order information in terms of region based consistency and Co occurrence defined over the whole image click.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Generally, inference in these higher order with these higher order model are done using graph cut based Alpha expansion method.",
                    "label": 1
                },
                {
                    "sent": "But one thing like we all have come across that graph cut based methods for with cooccurrence.",
                    "label": 0
                },
                {
                    "sent": "Another hard models are almost 10 times slower than only with pairwise terms.",
                    "label": 0
                },
                {
                    "sent": "So in the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work with develop filter based mean field approach which is almost 10 to 40 times faster depending on the problem.",
                    "label": 0
                },
                {
                    "sent": "Faster than graph cut based self expansion method.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mean Field has been started to be used in some of our recent works and one of the one of very interesting work was by grand.",
                    "label": 0
                },
                {
                    "sent": "Well at all last year, Nips who propose efficient inference method for proposed efficient method for influencing this pairwise CRF, but they make two assumptions.",
                    "label": 0
                },
                {
                    "sent": "One is that they take mean filler approximation to CRF, and another is that their pairwise terms take only the.",
                    "label": 0
                },
                {
                    "sent": "A linear combination of Gaussian kernels.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with these two assumptions, they are able to achieve almost five times speedup compared to graph cut based method.",
                    "label": 0
                },
                {
                    "sent": "And another important factor with their model is that they are able to handle this dense connectivity between variables and we can see here I'm showing one example that these kinds of dense connectivity can be useful in recovery, useful in discovering the final bond, dis around the objects.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll go into some of the related works which are very important.",
                    "label": 0
                },
                {
                    "sent": "I like what, what, what we do in mean field in France is we take a tractable family of distribution and we tried to approximate the true distribution P by one approximate distribution from this family Q.",
                    "label": 0
                },
                {
                    "sent": "And one family of distribution can be when we assume complete factorization over marginals of the variables.",
                    "label": 0
                },
                {
                    "sent": "Then we minimize we minimize the kelda vergence distance between Q distribution and P distribution to get the best Q which approximate DPD.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tuition.",
                    "label": 0
                },
                {
                    "sent": "When we minimize the scale distance, we get the fixed point solution, which looks something like this.",
                    "label": 0
                },
                {
                    "sent": "Here the with this we evaluate the marginal for a variable I getting labeled L, which involves the evaluating the expectation of cost.",
                    "label": 0
                },
                {
                    "sent": "Here it is unit in pairwise cost under Q distribution.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As we had seen, the term in Blue Box is very expensive.",
                    "label": 0
                },
                {
                    "sent": "One of the contribution of Granville was to show that this can be represented as a Gaussian convolution step and once they do present this as a Gaussian convolution step, they used this efficient filtering step to do this expensive message passing.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "3rd efficiently and in their work they use this parameter header lattice based filtering approach and in this work we try to evaluate the efficiency offered by some other methods as well, like domain transfer based.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Filtering.",
                    "label": 0
                },
                {
                    "sent": "Now I'll go through so some of the QQ distribution for some of the classes looks across iteration and will see that as we move across hydration, the confidence of variable taking our label keeps on in.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Crazy and.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the end, what we do?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This will get the maximum posterior marginal solution by taking the label for a variable which maximizes the marginal for that variable.",
                    "label": 0
                },
                {
                    "sent": "Now I'll get into how we added this higher order information into fully connected pairwise CRF.",
                    "label": 0
                },
                {
                    "sent": "As we can see this box terms in this red box is still computationally expensive.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2 holiday emphasize the complexity.",
                    "label": 0
                },
                {
                    "sent": "I've taken one the strike sample.",
                    "label": 0
                },
                {
                    "sent": "Let's say this.",
                    "label": 0
                },
                {
                    "sent": "Here is a click with three variable and each variable is taking a level from level set of three levels and to evaluate the marginal for this variable, one taking level one we can see we need to evaluate 9 terms which are shown in this block black boxes.",
                    "label": 0
                },
                {
                    "sent": "Similarly we need to evaluate another name terms to for this variable, taking level 2 as well as we need another nine times for this variable taking Level 3.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Angel, the complexity for adding higher order information in this mean field framework will be exponentially.",
                    "label": 1
                },
                {
                    "sent": "Number of labels and size of clicks, but we now I'll show we solve these problems for PN potsane.",
                    "label": 0
                },
                {
                    "sent": "Cocoran storm sufficiently.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'll jump into this paean parts model again.",
                    "label": 0
                },
                {
                    "sent": "I'll show using one toy example.",
                    "label": 0
                },
                {
                    "sent": "Let's take let's take a click with Subs, size, size 6, and each variable is still again taking label from level set of size 3.",
                    "label": 0
                },
                {
                    "sent": "And here we enforce that level configuration of click is dependent on whether all variable in that click takes same label or not.",
                    "label": 0
                },
                {
                    "sent": "So here the states are configuration of label.",
                    "label": 0
                },
                {
                    "sent": "Valid configurations are only three and we.",
                    "label": 0
                },
                {
                    "sent": "Attach associative cost to each of these valid configuration, like Gamma Zero, Gamma one, and gamma 2.",
                    "label": 0
                },
                {
                    "sent": "And we also have our gamma Max cost for all other invalid configuration.",
                    "label": 0
                },
                {
                    "sent": "Now as you can see the since we have the.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stricted the number of configuration of the evaluation of expectation across the configuration of this click can be done efficiently.",
                    "label": 0
                },
                {
                    "sent": "As we can see these on reusing the expectation or here will be able to see that complexity from exponential comes down to linear in number of labels and size of variable.",
                    "label": 0
                },
                {
                    "sent": "Number of variables are model can also be extended to other pattern based potential which were which are defined by common to kiss and other authors decently.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'll get into the Co occurrence terms cokers model should favor the second model which is in this case, which is better than the first model.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what Cokers model tries to do is test to attach a cost to each of these sub set of labels present in the image.",
                    "label": 0
                },
                {
                    "sent": "So here Lambda is the Lambda access.",
                    "label": 0
                },
                {
                    "sent": "This subset of labels and C is the costs associated with that.",
                    "label": 0
                },
                {
                    "sent": "We make two assumptions to this cost fir.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is that we take second order function for the cost function, where we assume that our cost factorizes into unity and Paris terms.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2nd, we represent this cost by set of binary latent variable Y12Y L the semantic of this.",
                    "label": 0
                },
                {
                    "sent": "These latent variables are that when?",
                    "label": 0
                },
                {
                    "sent": "Why Ellis zero?",
                    "label": 0
                },
                {
                    "sent": "We assume that there should not be any variable in image domain taking that label L and when while is one, we assume that there should not be.",
                    "label": 0
                },
                {
                    "sent": "There should be some variable image domain taking that label L.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, we enforce the global constraint by saying that went with this constant that when YL is zero, there should not be must not be any variable in image domain.",
                    "label": 0
                },
                {
                    "sent": "Taking that level L. Otherwise we pay a cost of fixed cost of K for every violation of this constraint.",
                    "label": 1
                },
                {
                    "sent": "With these two assumptions, we are able to again reduce the complexity in polynomial exponential to number polynomial in number of variables an labels.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Novy also Deb these higher order information to do inference for influencing product level space.",
                    "label": 0
                },
                {
                    "sent": "Here we are showing we did experiments for jointly estimating object and stereo for each of the label.",
                    "label": 0
                },
                {
                    "sent": "So we defined and joint energy function over this product label space where we have joint unity joint pairwise and joint higher order terms or this space.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'll go into details of this sum of experiments.",
                    "label": 0
                },
                {
                    "sent": "1st, I'll show the experimental Pascal view seating segmentation data set and our results are on the last column and we can see some of the qualitative we are able to do better than some of the.",
                    "label": 0
                },
                {
                    "sent": "Decently complex models developed recently, like models of Alpha logically at all based on graph based.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Limited.",
                    "label": 0
                },
                {
                    "sent": "Quantitatively, we observe an improvement of almost 2.5%.",
                    "label": 0
                },
                {
                    "sent": "Intersection Union is code than the model of Ladakhi, which is again without code based.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also we are certain speed up of almost 10 times compared to their model.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we didn't experiment for joint object in studio labeling on 11 data set there are seven object labels and hundred disparity labels.",
                    "label": 0
                },
                {
                    "sent": "Here's some of the quantitative results, but.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Main impact is here, qualitatively quantitatively we see slight improvement in its accuracy of studio results, but the main impact is we observe in 3235 times speedup compared to this radical model, which is graph cut based Alpha expansion method.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with this I would like to conclude that we in this work we tried to develop efficient message passing based method and we tried to incorporate higher order information in this CRF fully connected pairwise here framework.",
                    "label": 0
                },
                {
                    "sent": "And we demonstrated the efficiency and accuracy offered by our model on object segmentation and Joint Object Studio estimation problem.",
                    "label": 0
                },
                {
                    "sent": "And good thing is that code is online.",
                    "label": 0
                },
                {
                    "sent": "I would like you guys to download and try on your favorite vision problems.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Do you find that your method is sensitive to noise in the input images, given that you have these high order terms?",
                    "label": 0
                },
                {
                    "sent": "I have not tried whether it is sensitive to noise, but method is slightly sensitive to initialization.",
                    "label": 0
                },
                {
                    "sent": "If you have good initialization, will get the good results, but all these in all these experiments we have kept the same.",
                    "label": 0
                },
                {
                    "sent": "Starting point, even with the graph cut and our model, and there is another paper we had returned.",
                    "label": 0
                },
                {
                    "sent": "How to make it even there's some other methods.",
                    "label": 0
                },
                {
                    "sent": "Publishing it on 2000.",
                    "label": 0
                },
                {
                    "sent": "How to make the mean field methods more robust to initialization?",
                    "label": 0
                },
                {
                    "sent": "But in all these experiments we do not find any that bigger issue with initialization or any other noise.",
                    "label": 0
                },
                {
                    "sent": "So why were the results not considerably better?",
                    "label": 0
                },
                {
                    "sent": "Could it be that like the like, the fully connected and the PN pots are quite similar effects?",
                    "label": 0
                },
                {
                    "sent": "They all go for detail on the boundaries.",
                    "label": 0
                },
                {
                    "sent": "Is that why there is like combining all of it didn't improve so much or?",
                    "label": 0
                },
                {
                    "sent": "Actually, I think one of the reasons as far as I believe, is that in order to improve a big improvement in accuracy, we need better unit potential.",
                    "label": 0
                },
                {
                    "sent": "These pairwise terms or even higher order terms, tries to incorporate some consistency or some smoothness across boundaries.",
                    "label": 0
                },
                {
                    "sent": "But the actual benefit when we have better unit potential, like in this work, our starting unit potential was around 1314% accuracy.",
                    "label": 0
                },
                {
                    "sent": "We used some better unit potential and our baseline was like 28%, so I think better unit potential will be will give more impact, better accuracy, a lot, better accuracy.",
                    "label": 0
                },
                {
                    "sent": "Great, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}