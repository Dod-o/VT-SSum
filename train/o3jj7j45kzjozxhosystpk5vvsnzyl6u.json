{
    "id": "o3jj7j45kzjozxhosystpk5vvsnzyl6u",
    "title": "Learning Convolutional Feature Hierarchies for Visual Recognition",
    "info": {
        "author": [
            "Y-Lan Boureau, Computer Science Department, New York University (NYU)"
        ],
        "published": "March 25, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/nips2010_boureau_lcf/",
    "segmentation": [
        [
            "So sparse coding is a popular method for learning features in an unsupervised manner by minimizing the error between input data and a reconstruction form by linear combination of a few features.",
            "Dictionary useful, sparse coding are usually trained on isolated patches, so this has invented because it's easy, but the problem is that it produces.",
            "Representation which is highly redundant since each pixel has been represented several times.",
            "When you use overlapping patches, so the dictionary you obtain when doing this is what you can see on the left of this feature of this figure.",
            "So basically these are gabl filters of various orientations at different positions on the Patch.",
            "Instead, what we decided to use is to use a convolutional procedure to train the dictionary using larger image sections, and when you do this, the representation is much less redundant and you obtain a much richer variety of features.",
            "So if you look on the right you can see corner detectors centers around filters and junction detectors, so another feature of our architecture is that instead of just producing a dictionary to reconstruct.",
            "The image we also produce, we also train an efficient feature encoder.",
            "Which produce which predicts quasi sparse features in a very efficient manner.",
            "So this allows for real time processing which sparse coding can usually not do."
        ],
        [
            "This can now be used to train the filters in a convolutional networks, So what you can see here is a two stage convolutional architecture.",
            "Each stage is formed by three steps.",
            "The first step is a linear filtering step where we can use our convolutional filters.",
            "The second step is a nonlinearity in which the output of the filters is run and the third step is a pooling and subsampling step that reduces the dimensionality of the features and increases their invariants.",
            "So how do our I forget?",
            "There's also a supervised refinement that can be used to refine all our filters using supervised criterion.",
            "So how do our filters perform on various visual tasks?",
            "So the 1st result that we are going to present our our results on the Caltech."
        ],
        [
            "No one object recognition benchmark.",
            "So here you see two types of architecture.",
            "The two pairs of bars on the left are architecture using a single stage of.",
            "Single stage architecture.",
            "And the two pairs of bars on the right are two stage architecture where we have two 2 modules stacked, one on top of the other.",
            "So what you can see is that the convolutional training shown in blue always performs better than the Patch Braintree touch based training shown in purple.",
            "And another thing to observe is that this improvement is more significant when you have a single stage architecture and the second thing to observe is that when you do the supervised fine tuning.",
            "So this is the when what you what's written as unsupervised supervised.",
            "This reduces the difference between patchbays and convolutional training, but it should be noted that supervised mentioning is always a convolutional procedure.",
            "Anne."
        ],
        [
            "Now we're showing results on pedestrian detection using the Internet data set.",
            "So result plotted here is the miss rate plotted against the number of false positive pair images.",
            "So lower is better and our results are the pink lines.",
            "The numbers you see is the number is the miss rate for one false positive per image, so the solid pink line shows the result that we obtain with a two stage architecture when the filters have been randomly initialized.",
            "An the supervised function is performed so you see that this achieves 14.8% miss rate, But then this result drops to just 11.5.",
            "That is more than 20% drop when instead of initializing randomly, you use our convolutional unsupervised training procedure to initialize the filter and we even have better results using a few more tricks.",
            "So come to our poster T-70 to hear more.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So sparse coding is a popular method for learning features in an unsupervised manner by minimizing the error between input data and a reconstruction form by linear combination of a few features.",
                    "label": 0
                },
                {
                    "sent": "Dictionary useful, sparse coding are usually trained on isolated patches, so this has invented because it's easy, but the problem is that it produces.",
                    "label": 0
                },
                {
                    "sent": "Representation which is highly redundant since each pixel has been represented several times.",
                    "label": 0
                },
                {
                    "sent": "When you use overlapping patches, so the dictionary you obtain when doing this is what you can see on the left of this feature of this figure.",
                    "label": 0
                },
                {
                    "sent": "So basically these are gabl filters of various orientations at different positions on the Patch.",
                    "label": 0
                },
                {
                    "sent": "Instead, what we decided to use is to use a convolutional procedure to train the dictionary using larger image sections, and when you do this, the representation is much less redundant and you obtain a much richer variety of features.",
                    "label": 0
                },
                {
                    "sent": "So if you look on the right you can see corner detectors centers around filters and junction detectors, so another feature of our architecture is that instead of just producing a dictionary to reconstruct.",
                    "label": 0
                },
                {
                    "sent": "The image we also produce, we also train an efficient feature encoder.",
                    "label": 0
                },
                {
                    "sent": "Which produce which predicts quasi sparse features in a very efficient manner.",
                    "label": 0
                },
                {
                    "sent": "So this allows for real time processing which sparse coding can usually not do.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This can now be used to train the filters in a convolutional networks, So what you can see here is a two stage convolutional architecture.",
                    "label": 0
                },
                {
                    "sent": "Each stage is formed by three steps.",
                    "label": 0
                },
                {
                    "sent": "The first step is a linear filtering step where we can use our convolutional filters.",
                    "label": 0
                },
                {
                    "sent": "The second step is a nonlinearity in which the output of the filters is run and the third step is a pooling and subsampling step that reduces the dimensionality of the features and increases their invariants.",
                    "label": 0
                },
                {
                    "sent": "So how do our I forget?",
                    "label": 0
                },
                {
                    "sent": "There's also a supervised refinement that can be used to refine all our filters using supervised criterion.",
                    "label": 0
                },
                {
                    "sent": "So how do our filters perform on various visual tasks?",
                    "label": 0
                },
                {
                    "sent": "So the 1st result that we are going to present our our results on the Caltech.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No one object recognition benchmark.",
                    "label": 0
                },
                {
                    "sent": "So here you see two types of architecture.",
                    "label": 0
                },
                {
                    "sent": "The two pairs of bars on the left are architecture using a single stage of.",
                    "label": 0
                },
                {
                    "sent": "Single stage architecture.",
                    "label": 0
                },
                {
                    "sent": "And the two pairs of bars on the right are two stage architecture where we have two 2 modules stacked, one on top of the other.",
                    "label": 0
                },
                {
                    "sent": "So what you can see is that the convolutional training shown in blue always performs better than the Patch Braintree touch based training shown in purple.",
                    "label": 1
                },
                {
                    "sent": "And another thing to observe is that this improvement is more significant when you have a single stage architecture and the second thing to observe is that when you do the supervised fine tuning.",
                    "label": 1
                },
                {
                    "sent": "So this is the when what you what's written as unsupervised supervised.",
                    "label": 0
                },
                {
                    "sent": "This reduces the difference between patchbays and convolutional training, but it should be noted that supervised mentioning is always a convolutional procedure.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we're showing results on pedestrian detection using the Internet data set.",
                    "label": 1
                },
                {
                    "sent": "So result plotted here is the miss rate plotted against the number of false positive pair images.",
                    "label": 0
                },
                {
                    "sent": "So lower is better and our results are the pink lines.",
                    "label": 0
                },
                {
                    "sent": "The numbers you see is the number is the miss rate for one false positive per image, so the solid pink line shows the result that we obtain with a two stage architecture when the filters have been randomly initialized.",
                    "label": 1
                },
                {
                    "sent": "An the supervised function is performed so you see that this achieves 14.8% miss rate, But then this result drops to just 11.5.",
                    "label": 1
                },
                {
                    "sent": "That is more than 20% drop when instead of initializing randomly, you use our convolutional unsupervised training procedure to initialize the filter and we even have better results using a few more tricks.",
                    "label": 0
                },
                {
                    "sent": "So come to our poster T-70 to hear more.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}