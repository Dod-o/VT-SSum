{
    "id": "orhrhusnyacbrlpyc5neqfpnlizwuggv",
    "title": "Optimal Support Vector Selection for Kernel Perceptrons",
    "info": {
        "author": [
            "Daniel Garc\u00eda, Autonomous University of Madrid"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "October 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines"
        ]
    },
    "url": "http://videolectures.net/learning06_garcia_osvsk/",
    "segmentation": [
        [
            "I'm going to talk about our work that was researched by Hostetter on sonar and sell it on myself.",
            "Anne, it's entitled optimal bug on support vector selection for color perceptrons."
        ],
        [
            "OK. A common problem with their support vector machines is there you need a high amount of support vectors in order to generate the output, and the output is the order of the number of support vectors or kernel operations.",
            "So in this work will try to obtain a new method to reduce the number of support vector machines in an also.",
            "Keep a good accuracy results.",
            "In order to achieve this task, we study the support vector machines training method and how it performs their margin maximization."
        ],
        [
            "OK. Let's start with a brief review of support vector machines method.",
            "This apartment support vector material, sorry support vector machines goal, is to construct a linear classifier in order to classify training sets.",
            "With keeping our maximum margin, we can see the margin as the distance between the the separator hyperplane and the nearest pattern to it to it.",
            "We have seen in before that we have to solve this quadratic.",
            "Oh, problem.",
            "But which also is constrained by the series of equations that this all equation means that all patterns has to be good classified an we haven't seen that this problem is quite complex, so.",
            "We like another method to avoid this computation."
        ],
        [
            "And this other medal stays in the convex Hull normalization.",
            "1st.",
            "We change the input space just by applying the sign for its pattern.",
            "And then we have that the optimum weight vector verifies that is the IT has the lowest norm of all the vectors in their combat role of the input space.",
            "Moreover the optimal weight verifies that its margin is equal to its norm.",
            "That is, for any other way better in the convex Hull we have.",
            "That is margin is less or equal that the optimal margin and also it's norm is greater or equal that the optimal load.",
            "We have this language we can stay on UG function that is the difference between the norm and emerging and states this function optimal criterion.",
            "Function.",
            "OK, now."
        ],
        [
            "I announced that Slessinger casino, Calgary.",
            "This algorithm 6 to minify this function into a step first is select the pattern.",
            "We have a minimum margin.",
            "What is means that if the pattern is wrong classified, it tries to to correct the worst wrong classified pattern?",
            "And also if all patterns are good classified, just the one who have minimum margin.",
            "OK then instead is update the weight vector in a fashion that is similar to Debrecen Battle rule, but we have to keep the weight vector in its combat Hall.",
            "Then we have also have a Lambda parameter that ensures that the new weight vector is.",
            "Is there a minimum with a chosen pattern?",
            "The Slesinger casinos algorithm assumes that in each iteration, the weight norm is going to be reduced, or at least keep equal."
        ],
        [
            "OK, what problem with Sling Selinger goes in there?",
            "Calgary is that is a linear classification, but the we we use kernel.",
            "We can avoid this problem, just a.",
            "Put in all the.",
            "The the products in terms of the kernel.",
            "Then we can write their weight vector in its dual form and perform the.",
            "The update in terms only of this Alpha that does the dual coefficients.",
            "And the update of this dual coefficients are in custom the number of patterns."
        ],
        [
            "Also, to speed up the new pattern selection, we keep margin vector for each pattern.",
            "So it's very easy to choose the new pattern to be.",
            "To be a.",
            "To be trained.",
            "Also, this Lambda parameter is very easy to compute and the update of this margin, the vector and all the number 2."
        ],
        [
            "Very are in the order of the number of patterns and the cost of a kernel computation.",
            "This means that the cost of the theater is an escargot algorithm training.",
            "Is in the order of the time of the iteration, number of iteration per the number of patterns per the cost of 1 kernel computation.",
            "But on the other hand, the resulting perfect run if it's going to apply to a test set.",
            "It cost will be the number of support vectors per the size of the test set for the order of the per the kernel computation cost.",
            "And this may be similar to the whole training.",
            "If we have that number.",
            "Supervector is similar to the whole training patterns."
        ],
        [
            "OK, so we.",
            "We have to try to reduce the amount of support vectors.",
            "One good thing that we are working in that combats all, it's that they would vector.",
            "In the convex Hull, have this property that all these Alpha coefficients sum 1.",
            "So the question is, is it possible to see this a probabilistic distribution?"
        ],
        [
            "We can, we can see these Alpha coefficients to be about the relative relevance in order to correct classify.",
            "On also, is this Alpha coefficients should be around the same for all the go for all their support vectors?",
            "Then we can use this setup to pronounce supervector removal method.",
            "We consider just remove those patterns.",
            "We have a low Alpha coefficients.",
            "Now.",
            "The first idea is rather than trying computation, we just iterate the algorithm, remove those support vectors with low Alpha values and then return again using as our new.",
            "Training set just by all the support vectors that we are we have kept."
        ],
        [
            "OK so I started answering the method.",
            "We start with initial training sample.",
            "We have our initial factor Delta that must be lower than one.",
            "On after the whole training finished, we keep only those.",
            "Those patterns will have a Alpha upper Danzo threshold, that is threshold is in terms of the tax and the number of buttons.",
            "Then we will literally apply the salaries.",
            "With increasing Delta values up to one, so the result is a decreasing sequence of the training set.",
            "Additionally, we can use the remote vector as a validation set in order to try to know when is.",
            "We have to stop this.",
            "This procedure.",
            "We can see this as just stop reduce removing support vectors when the accuracy goes quite low."
        ],
        [
            "OK, now I'll explain how we will experiment.",
            "We have done an.",
            "How we go?",
            "OK, we have worked with the data set from the well known you see repository.",
            "We have used our goes all kernel with an arbitrary value of Sigma square of 50.",
            "This may be important.",
            "This value of Sigma, but we only want to know if this support removal method works.",
            "We think that it's OK."
        ],
        [
            "Also to Valentina security we have extended project patterns in this way.",
            "This is adding new dimensions which all values are zero except in the index for each pattern that is designed into two and this contact constancy.",
            "This is very easy to work with and all the work you only required to extend the kernel adding this term."
        ],
        [
            "OK. No.",
            "For each data set we have performed our term growth for validation.",
            "Also, for each data set we have performed out to 20 returns which equals four it.",
            "We have seen that it.",
            "This number of epochs is sufficient to obtain a gold optimal margin.",
            "Then we have to start with Delta value of .5 and use a fixed increment.",
            "Then given increasing thresholds.",
            "Then after its removal and retraining state, we shall compute their validation, accurate accuracy and the test accuracy.",
            "And then as I stop criterion, we have.",
            "This the procedure ends when already trying that completed or when the difference between the accuracy of correlative retraining are greater than the standard deviation.",
            "So.",
            "We have the this May assure that when the accuracy is going too low we will stop."
        ],
        [
            "OK.",
            "This table summarizes the results for each data set.",
            "We have the number of patterns, the initial support vectors they have, and the final supervector we have achieved.",
            "Also, we have some, so here the ratio between the final supervector and initial to perfect your number.",
            "We can see that this ratio is about 50, about 70%.",
            "Which is quite good."
        ],
        [
            "Now in detail from some data sets, starting with the Hardy says data set.",
            "Mr Criterion is met where its value gets positive.",
            "So in this example the secretary is met with at the factor of .7.",
            "We can see that the test accuracy is a little bit worse than the original test accuracy, but we have.",
            "Some.",
            "In some degree, a good reduccion vector.",
            "Would a supervisor?"
        ],
        [
            "Well, in this other sample.",
            "The stop criterion is never met, so we have performed the whole returnees.",
            "This example is very similar to the last in the terms that they support vector are decreasing the number of super vectors, but Interestingly the accuracy is get improved after the removal.",
            "Step."
        ],
        [
            "For this other data set.",
            "This tablet area is met that deserve the final Test.",
            "Accuracy is equal to the original security or very similar, and again there is a good reflection of the support vectors."
        ],
        [
            "And finally another example.",
            "That is quite similar to the Deluxe sample.",
            "The final currency is almost the same as the original 1, and we have a reduction in the number of a pattern.",
            "So in light of this, we can see that these methods provide a good reduction of the support vector number.",
            "And also a the accuracy doesn't get.",
            "A worsening alert.",
            "No."
        ],
        [
            "I saw you some wraps.",
            "These brows are the evolution of the accuracy both in validation set an intestate.",
            "Anybody since it is the upper line and.",
            "That said, the lower line we can see that at the Delta value gets increasing the.",
            "The accuracies are starting to go low.",
            "And at that point we have stop.",
            "It's maybe a good point."
        ],
        [
            "Now for the Wisconsin data set.",
            "We have the same constant accuracy, so we have seen that we can keep removing vectors until the end and accuracy is just OK."
        ],
        [
            "From this case.",
            "It's very.",
            "Strange, because the validation accuracy starts getting low but the test accuracy stays at the same level, more or less.",
            "We have stopped at this factor .75, but we maybe can continue until the end.",
            "That this shows that maybe our stop criterion isn't the best."
        ],
        [
            "Finally, again, for another data set that they separate, Arian is quite.",
            "But soon, but it may be OK because then after the retraining the accuracy starts going down."
        ],
        [
            "So finally as conclusion, we can see that a common problem for Kinder classifiers is the high number of support vector machines.",
            "They must have used, resulting in a very high cost of the new Python classification.",
            "We have shown that the number of support vectors can be considerably reduced while retaining a good accuracy.",
            "Also, they were presented here has to be seen as as priority natures in terms that we have announced the problem.",
            "We have the problem and trying to look something to up to obtain a good result.",
            "Finally as future work.",
            "We have looking for a better stopping criterion.",
            "And also investigate other methods in order to minimize the number of support vectors.",
            "Maybe some of these other methods as it could be a budget algorithm or.",
            "Some other kinds to training with a fixed amount of support vectors.",
            "OK, and that's all any question.",
            "I have a question, yes.",
            "In your procedure to reduce the number of support vectors you're doing, what we call in feature selection or backward elimination.",
            "So you start with the full set of support, yes?",
            "In in doing that.",
            "I don't know, but you could be eliminating a support vector.",
            "Then later point would become useful.",
            "So you could be doing a backward and forward.",
            "Have you tried looking back and?",
            "Yes, that's true that this method is in this.",
            "In this fashion is a greedy algorithm and it has.",
            "Maybe we can try to do something like, but we can retrain and then continue to forest to take back some remove vector.",
            "This could be good.",
            "You can you stop it.",
            "Criterion doesn't help you stop and sometimes you can go to the end.",
            "You mean that you can have it in the end 0 support vector and still are no the the end is keeping only those vector.",
            "The Alpha well do supervector we have the same Alpha that is a one in two 9.",
            "In the end, where N is the number of parameters.",
            "But of course we can take out all the support vectors, so we have to stop or or as the stopping Criterion series.",
            "Or then when all the whole retraining and perform.",
            "And then you find that once you have something written that you stop when all the coefficients are the same.",
            "Does not conserve too many supporters.",
            "We couldn't still remove some.",
            "Yes, maybe you could still remove some Bud us.",
            "We have starting the process is like the important.",
            "The relevance of each pattern is in in the Alpha values, so we have no evidence that removing them will increase the classification.",
            "I think that new coaches are.",
            "Was is a mining something which you might find interesting, which is the fact that this is an online algorithm.",
            "Typically I keep the vectors.",
            "As far as they are misclassified.",
            "And I mean there are aseptic results showing that this works well.",
            "So basically you do it interactively and at each point you see whether the parent vector is misclassified.",
            "If so, you keep it.",
            "Otherwise you will.",
            "This may be another approach.",
            "Baseline.",
            "OK, thank you.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to talk about our work that was researched by Hostetter on sonar and sell it on myself.",
                    "label": 0
                },
                {
                    "sent": "Anne, it's entitled optimal bug on support vector selection for color perceptrons.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. A common problem with their support vector machines is there you need a high amount of support vectors in order to generate the output, and the output is the order of the number of support vectors or kernel operations.",
                    "label": 1
                },
                {
                    "sent": "So in this work will try to obtain a new method to reduce the number of support vector machines in an also.",
                    "label": 0
                },
                {
                    "sent": "Keep a good accuracy results.",
                    "label": 0
                },
                {
                    "sent": "In order to achieve this task, we study the support vector machines training method and how it performs their margin maximization.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. Let's start with a brief review of support vector machines method.",
                    "label": 1
                },
                {
                    "sent": "This apartment support vector material, sorry support vector machines goal, is to construct a linear classifier in order to classify training sets.",
                    "label": 1
                },
                {
                    "sent": "With keeping our maximum margin, we can see the margin as the distance between the the separator hyperplane and the nearest pattern to it to it.",
                    "label": 1
                },
                {
                    "sent": "We have seen in before that we have to solve this quadratic.",
                    "label": 0
                },
                {
                    "sent": "Oh, problem.",
                    "label": 0
                },
                {
                    "sent": "But which also is constrained by the series of equations that this all equation means that all patterns has to be good classified an we haven't seen that this problem is quite complex, so.",
                    "label": 0
                },
                {
                    "sent": "We like another method to avoid this computation.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this other medal stays in the convex Hull normalization.",
                    "label": 1
                },
                {
                    "sent": "1st.",
                    "label": 0
                },
                {
                    "sent": "We change the input space just by applying the sign for its pattern.",
                    "label": 0
                },
                {
                    "sent": "And then we have that the optimum weight vector verifies that is the IT has the lowest norm of all the vectors in their combat role of the input space.",
                    "label": 1
                },
                {
                    "sent": "Moreover the optimal weight verifies that its margin is equal to its norm.",
                    "label": 1
                },
                {
                    "sent": "That is, for any other way better in the convex Hull we have.",
                    "label": 1
                },
                {
                    "sent": "That is margin is less or equal that the optimal margin and also it's norm is greater or equal that the optimal load.",
                    "label": 0
                },
                {
                    "sent": "We have this language we can stay on UG function that is the difference between the norm and emerging and states this function optimal criterion.",
                    "label": 0
                },
                {
                    "sent": "Function.",
                    "label": 0
                },
                {
                    "sent": "OK, now.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I announced that Slessinger casino, Calgary.",
                    "label": 0
                },
                {
                    "sent": "This algorithm 6 to minify this function into a step first is select the pattern.",
                    "label": 0
                },
                {
                    "sent": "We have a minimum margin.",
                    "label": 0
                },
                {
                    "sent": "What is means that if the pattern is wrong classified, it tries to to correct the worst wrong classified pattern?",
                    "label": 0
                },
                {
                    "sent": "And also if all patterns are good classified, just the one who have minimum margin.",
                    "label": 0
                },
                {
                    "sent": "OK then instead is update the weight vector in a fashion that is similar to Debrecen Battle rule, but we have to keep the weight vector in its combat Hall.",
                    "label": 0
                },
                {
                    "sent": "Then we have also have a Lambda parameter that ensures that the new weight vector is.",
                    "label": 0
                },
                {
                    "sent": "Is there a minimum with a chosen pattern?",
                    "label": 0
                },
                {
                    "sent": "The Slesinger casinos algorithm assumes that in each iteration, the weight norm is going to be reduced, or at least keep equal.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, what problem with Sling Selinger goes in there?",
                    "label": 0
                },
                {
                    "sent": "Calgary is that is a linear classification, but the we we use kernel.",
                    "label": 0
                },
                {
                    "sent": "We can avoid this problem, just a.",
                    "label": 0
                },
                {
                    "sent": "Put in all the.",
                    "label": 0
                },
                {
                    "sent": "The the products in terms of the kernel.",
                    "label": 0
                },
                {
                    "sent": "Then we can write their weight vector in its dual form and perform the.",
                    "label": 0
                },
                {
                    "sent": "The update in terms only of this Alpha that does the dual coefficients.",
                    "label": 0
                },
                {
                    "sent": "And the update of this dual coefficients are in custom the number of patterns.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also, to speed up the new pattern selection, we keep margin vector for each pattern.",
                    "label": 1
                },
                {
                    "sent": "So it's very easy to choose the new pattern to be.",
                    "label": 0
                },
                {
                    "sent": "To be a.",
                    "label": 0
                },
                {
                    "sent": "To be trained.",
                    "label": 0
                },
                {
                    "sent": "Also, this Lambda parameter is very easy to compute and the update of this margin, the vector and all the number 2.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very are in the order of the number of patterns and the cost of a kernel computation.",
                    "label": 1
                },
                {
                    "sent": "This means that the cost of the theater is an escargot algorithm training.",
                    "label": 0
                },
                {
                    "sent": "Is in the order of the time of the iteration, number of iteration per the number of patterns per the cost of 1 kernel computation.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, the resulting perfect run if it's going to apply to a test set.",
                    "label": 1
                },
                {
                    "sent": "It cost will be the number of support vectors per the size of the test set for the order of the per the kernel computation cost.",
                    "label": 0
                },
                {
                    "sent": "And this may be similar to the whole training.",
                    "label": 0
                },
                {
                    "sent": "If we have that number.",
                    "label": 0
                },
                {
                    "sent": "Supervector is similar to the whole training patterns.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we.",
                    "label": 0
                },
                {
                    "sent": "We have to try to reduce the amount of support vectors.",
                    "label": 0
                },
                {
                    "sent": "One good thing that we are working in that combats all, it's that they would vector.",
                    "label": 0
                },
                {
                    "sent": "In the convex Hull, have this property that all these Alpha coefficients sum 1.",
                    "label": 0
                },
                {
                    "sent": "So the question is, is it possible to see this a probabilistic distribution?",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can, we can see these Alpha coefficients to be about the relative relevance in order to correct classify.",
                    "label": 1
                },
                {
                    "sent": "On also, is this Alpha coefficients should be around the same for all the go for all their support vectors?",
                    "label": 0
                },
                {
                    "sent": "Then we can use this setup to pronounce supervector removal method.",
                    "label": 1
                },
                {
                    "sent": "We consider just remove those patterns.",
                    "label": 0
                },
                {
                    "sent": "We have a low Alpha coefficients.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "The first idea is rather than trying computation, we just iterate the algorithm, remove those support vectors with low Alpha values and then return again using as our new.",
                    "label": 1
                },
                {
                    "sent": "Training set just by all the support vectors that we are we have kept.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so I started answering the method.",
                    "label": 0
                },
                {
                    "sent": "We start with initial training sample.",
                    "label": 1
                },
                {
                    "sent": "We have our initial factor Delta that must be lower than one.",
                    "label": 1
                },
                {
                    "sent": "On after the whole training finished, we keep only those.",
                    "label": 0
                },
                {
                    "sent": "Those patterns will have a Alpha upper Danzo threshold, that is threshold is in terms of the tax and the number of buttons.",
                    "label": 1
                },
                {
                    "sent": "Then we will literally apply the salaries.",
                    "label": 1
                },
                {
                    "sent": "With increasing Delta values up to one, so the result is a decreasing sequence of the training set.",
                    "label": 0
                },
                {
                    "sent": "Additionally, we can use the remote vector as a validation set in order to try to know when is.",
                    "label": 1
                },
                {
                    "sent": "We have to stop this.",
                    "label": 0
                },
                {
                    "sent": "This procedure.",
                    "label": 0
                },
                {
                    "sent": "We can see this as just stop reduce removing support vectors when the accuracy goes quite low.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now I'll explain how we will experiment.",
                    "label": 0
                },
                {
                    "sent": "We have done an.",
                    "label": 0
                },
                {
                    "sent": "How we go?",
                    "label": 0
                },
                {
                    "sent": "OK, we have worked with the data set from the well known you see repository.",
                    "label": 1
                },
                {
                    "sent": "We have used our goes all kernel with an arbitrary value of Sigma square of 50.",
                    "label": 1
                },
                {
                    "sent": "This may be important.",
                    "label": 0
                },
                {
                    "sent": "This value of Sigma, but we only want to know if this support removal method works.",
                    "label": 0
                },
                {
                    "sent": "We think that it's OK.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also to Valentina security we have extended project patterns in this way.",
                    "label": 0
                },
                {
                    "sent": "This is adding new dimensions which all values are zero except in the index for each pattern that is designed into two and this contact constancy.",
                    "label": 0
                },
                {
                    "sent": "This is very easy to work with and all the work you only required to extend the kernel adding this term.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. No.",
                    "label": 0
                },
                {
                    "sent": "For each data set we have performed our term growth for validation.",
                    "label": 0
                },
                {
                    "sent": "Also, for each data set we have performed out to 20 returns which equals four it.",
                    "label": 1
                },
                {
                    "sent": "We have seen that it.",
                    "label": 0
                },
                {
                    "sent": "This number of epochs is sufficient to obtain a gold optimal margin.",
                    "label": 0
                },
                {
                    "sent": "Then we have to start with Delta value of .5 and use a fixed increment.",
                    "label": 1
                },
                {
                    "sent": "Then given increasing thresholds.",
                    "label": 0
                },
                {
                    "sent": "Then after its removal and retraining state, we shall compute their validation, accurate accuracy and the test accuracy.",
                    "label": 1
                },
                {
                    "sent": "And then as I stop criterion, we have.",
                    "label": 1
                },
                {
                    "sent": "This the procedure ends when already trying that completed or when the difference between the accuracy of correlative retraining are greater than the standard deviation.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We have the this May assure that when the accuracy is going too low we will stop.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "This table summarizes the results for each data set.",
                    "label": 0
                },
                {
                    "sent": "We have the number of patterns, the initial support vectors they have, and the final supervector we have achieved.",
                    "label": 0
                },
                {
                    "sent": "Also, we have some, so here the ratio between the final supervector and initial to perfect your number.",
                    "label": 0
                },
                {
                    "sent": "We can see that this ratio is about 50, about 70%.",
                    "label": 0
                },
                {
                    "sent": "Which is quite good.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now in detail from some data sets, starting with the Hardy says data set.",
                    "label": 0
                },
                {
                    "sent": "Mr Criterion is met where its value gets positive.",
                    "label": 0
                },
                {
                    "sent": "So in this example the secretary is met with at the factor of .7.",
                    "label": 0
                },
                {
                    "sent": "We can see that the test accuracy is a little bit worse than the original test accuracy, but we have.",
                    "label": 0
                },
                {
                    "sent": "Some.",
                    "label": 0
                },
                {
                    "sent": "In some degree, a good reduccion vector.",
                    "label": 0
                },
                {
                    "sent": "Would a supervisor?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, in this other sample.",
                    "label": 0
                },
                {
                    "sent": "The stop criterion is never met, so we have performed the whole returnees.",
                    "label": 0
                },
                {
                    "sent": "This example is very similar to the last in the terms that they support vector are decreasing the number of super vectors, but Interestingly the accuracy is get improved after the removal.",
                    "label": 0
                },
                {
                    "sent": "Step.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this other data set.",
                    "label": 0
                },
                {
                    "sent": "This tablet area is met that deserve the final Test.",
                    "label": 0
                },
                {
                    "sent": "Accuracy is equal to the original security or very similar, and again there is a good reflection of the support vectors.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally another example.",
                    "label": 0
                },
                {
                    "sent": "That is quite similar to the Deluxe sample.",
                    "label": 0
                },
                {
                    "sent": "The final currency is almost the same as the original 1, and we have a reduction in the number of a pattern.",
                    "label": 0
                },
                {
                    "sent": "So in light of this, we can see that these methods provide a good reduction of the support vector number.",
                    "label": 0
                },
                {
                    "sent": "And also a the accuracy doesn't get.",
                    "label": 0
                },
                {
                    "sent": "A worsening alert.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I saw you some wraps.",
                    "label": 0
                },
                {
                    "sent": "These brows are the evolution of the accuracy both in validation set an intestate.",
                    "label": 0
                },
                {
                    "sent": "Anybody since it is the upper line and.",
                    "label": 0
                },
                {
                    "sent": "That said, the lower line we can see that at the Delta value gets increasing the.",
                    "label": 0
                },
                {
                    "sent": "The accuracies are starting to go low.",
                    "label": 0
                },
                {
                    "sent": "And at that point we have stop.",
                    "label": 0
                },
                {
                    "sent": "It's maybe a good point.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now for the Wisconsin data set.",
                    "label": 0
                },
                {
                    "sent": "We have the same constant accuracy, so we have seen that we can keep removing vectors until the end and accuracy is just OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From this case.",
                    "label": 0
                },
                {
                    "sent": "It's very.",
                    "label": 0
                },
                {
                    "sent": "Strange, because the validation accuracy starts getting low but the test accuracy stays at the same level, more or less.",
                    "label": 0
                },
                {
                    "sent": "We have stopped at this factor .75, but we maybe can continue until the end.",
                    "label": 0
                },
                {
                    "sent": "That this shows that maybe our stop criterion isn't the best.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, again, for another data set that they separate, Arian is quite.",
                    "label": 0
                },
                {
                    "sent": "But soon, but it may be OK because then after the retraining the accuracy starts going down.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So finally as conclusion, we can see that a common problem for Kinder classifiers is the high number of support vector machines.",
                    "label": 1
                },
                {
                    "sent": "They must have used, resulting in a very high cost of the new Python classification.",
                    "label": 1
                },
                {
                    "sent": "We have shown that the number of support vectors can be considerably reduced while retaining a good accuracy.",
                    "label": 1
                },
                {
                    "sent": "Also, they were presented here has to be seen as as priority natures in terms that we have announced the problem.",
                    "label": 0
                },
                {
                    "sent": "We have the problem and trying to look something to up to obtain a good result.",
                    "label": 1
                },
                {
                    "sent": "Finally as future work.",
                    "label": 0
                },
                {
                    "sent": "We have looking for a better stopping criterion.",
                    "label": 1
                },
                {
                    "sent": "And also investigate other methods in order to minimize the number of support vectors.",
                    "label": 0
                },
                {
                    "sent": "Maybe some of these other methods as it could be a budget algorithm or.",
                    "label": 0
                },
                {
                    "sent": "Some other kinds to training with a fixed amount of support vectors.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's all any question.",
                    "label": 0
                },
                {
                    "sent": "I have a question, yes.",
                    "label": 0
                },
                {
                    "sent": "In your procedure to reduce the number of support vectors you're doing, what we call in feature selection or backward elimination.",
                    "label": 0
                },
                {
                    "sent": "So you start with the full set of support, yes?",
                    "label": 0
                },
                {
                    "sent": "In in doing that.",
                    "label": 0
                },
                {
                    "sent": "I don't know, but you could be eliminating a support vector.",
                    "label": 0
                },
                {
                    "sent": "Then later point would become useful.",
                    "label": 0
                },
                {
                    "sent": "So you could be doing a backward and forward.",
                    "label": 0
                },
                {
                    "sent": "Have you tried looking back and?",
                    "label": 0
                },
                {
                    "sent": "Yes, that's true that this method is in this.",
                    "label": 0
                },
                {
                    "sent": "In this fashion is a greedy algorithm and it has.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can try to do something like, but we can retrain and then continue to forest to take back some remove vector.",
                    "label": 0
                },
                {
                    "sent": "This could be good.",
                    "label": 0
                },
                {
                    "sent": "You can you stop it.",
                    "label": 0
                },
                {
                    "sent": "Criterion doesn't help you stop and sometimes you can go to the end.",
                    "label": 0
                },
                {
                    "sent": "You mean that you can have it in the end 0 support vector and still are no the the end is keeping only those vector.",
                    "label": 0
                },
                {
                    "sent": "The Alpha well do supervector we have the same Alpha that is a one in two 9.",
                    "label": 0
                },
                {
                    "sent": "In the end, where N is the number of parameters.",
                    "label": 0
                },
                {
                    "sent": "But of course we can take out all the support vectors, so we have to stop or or as the stopping Criterion series.",
                    "label": 0
                },
                {
                    "sent": "Or then when all the whole retraining and perform.",
                    "label": 0
                },
                {
                    "sent": "And then you find that once you have something written that you stop when all the coefficients are the same.",
                    "label": 0
                },
                {
                    "sent": "Does not conserve too many supporters.",
                    "label": 0
                },
                {
                    "sent": "We couldn't still remove some.",
                    "label": 0
                },
                {
                    "sent": "Yes, maybe you could still remove some Bud us.",
                    "label": 0
                },
                {
                    "sent": "We have starting the process is like the important.",
                    "label": 0
                },
                {
                    "sent": "The relevance of each pattern is in in the Alpha values, so we have no evidence that removing them will increase the classification.",
                    "label": 0
                },
                {
                    "sent": "I think that new coaches are.",
                    "label": 0
                },
                {
                    "sent": "Was is a mining something which you might find interesting, which is the fact that this is an online algorithm.",
                    "label": 0
                },
                {
                    "sent": "Typically I keep the vectors.",
                    "label": 0
                },
                {
                    "sent": "As far as they are misclassified.",
                    "label": 0
                },
                {
                    "sent": "And I mean there are aseptic results showing that this works well.",
                    "label": 0
                },
                {
                    "sent": "So basically you do it interactively and at each point you see whether the parent vector is misclassified.",
                    "label": 0
                },
                {
                    "sent": "If so, you keep it.",
                    "label": 0
                },
                {
                    "sent": "Otherwise you will.",
                    "label": 0
                },
                {
                    "sent": "This may be another approach.",
                    "label": 0
                },
                {
                    "sent": "Baseline.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}