{
    "id": "4qfudqb6bbecnuzbjgzi55gyslhohryx",
    "title": "Rapid Stochastic Gradient Descent: Accelerating Machine Learning",
    "info": {
        "author": [
            "Nicol Schraudolph, National ICT Australia"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "February 2006",
        "category": [
            "Top->Mathematics->Operations Research"
        ]
    },
    "url": "http://videolectures.net/mlss06au_schraudolph_aml/",
    "segmentation": [
        [
            "My name is Nick struggle.",
            "I'm originally from Germany.",
            "And studied in my undergraduate degree in England back in the 80s.",
            "And that was when Realnetworks.",
            "I've done the scene machine learning and that was when at UCSD, the PDP research group wrote what used to be known as the Bible, and it's no more like the Old Testament.",
            "The basically put neural networks on the map and that started a revolution in machine learning and I was over in England and I was really fascinated by neural networks.",
            "So then for my PhD I went to UCSD.",
            "By the time I arrived there, most of that research group had left two other places, but there were still some people left.",
            "I did my PhD, then at the Salk Institute in San Diego with Harrison Joeski.",
            "Then went post talking around the world a bit and ended up here about one year ago.",
            "Needless to say, nobody calls their machine learning.",
            "Gives most neural networks anymore.",
            "But actually not all that much has changed.",
            "It's just the buzzwords are different.",
            "There's some new techniques around, but under the hood it's still pretty much the same.",
            "I think it's as back when I studied these things OK before I launch into my talk, I actually want to give you an introduction about the things I don't want to talk about.",
            "So I'll talk about them at length.",
            "Basically what I'm concerned with is.",
            "The engine that drives machine learning.",
            "So Bernard in his talk has told you about empirical risk minimization right so that the typical way you set up a machine learning problem is you find a function that measures how much error you're making on some training data, and you try to minimize that function.",
            "What interests me is how do you actually do that minimization?",
            "Right, how do you?",
            "How do you run that and how can we make that engine that drives machine learning efficient?",
            "How can we get answers fast right so?",
            "Optimization methods.",
            "Is what I'm concerned with and.",
            "We can distinguish optimization methods.",
            "We can classify them by whether they're using gradient information and what kind of gradient information they are using.",
            "Does everybody know what a gradient is?",
            "Yeah anybody doesn't?",
            "I mean I'm I can go back and explain.",
            "OK quick introduction.",
            "We have a function.",
            "And let's say it's the kind of function we would want to minimize in machine learning, so it could be an empirical risk function, so I'll just call it F. And I'll say there's some parameters Theta over which we want to optimize it.",
            "And maybe it depends also on some inputs X, right?",
            "Now the gradient of that function if that function is smooth and differentiable, we can take the gradient.",
            "The gradient is defined.",
            "As the limit.",
            "For some age going to 0.",
            "Of F. Theta.",
            "Plus H. Times.",
            "Also, this is a directional gradient.",
            "Yeah, that's OK. Out, stick in here a unit vector in direction I OK so the unit vector in direction I.",
            "Is all zeros except it has one.",
            "A single one, and this is in the eye position.",
            "OK, this is the unit vector in direction I, so we add to the parameters H times the unit vector in direction I and we measure the function at that point.",
            "Let me stick in the input.",
            "We subtract from that the function at the original point.",
            "And divide by H. If you take the limit as H goes to 0, this is the gradient of F. Theater X with respect to the I've component.",
            "Of the parameter vector, the ice component, because that's the component we're perturbing here.",
            "So this is a definition.",
            "Graphically, it looks like this if this is your function.",
            "We are, at a certain point, Theta.",
            "Right, what we're taking is now.",
            "I only have one coordinate, so this is my coordinate an perturbing.",
            "I'm going to add a little bit H to that coordinate.",
            "I'll measure the function at that point.",
            "Subtract from that the original function.",
            "So I'm taking this difference here.",
            "And divide by H and what that actually gives me is the slope of the tangent.",
            "At that point, the tangent on the function.",
            "Now.",
            "How could that be useful for minimizing a function?",
            "Well, if we know the slope of the tangent, we know which way is downhill, right?",
            "We know that if we go in this case to the left, we're going to reduce the function.",
            "If we just have function values, it's harder to tell.",
            "So you can classify optimization methods into.",
            "Direct methods.",
            "And these use function values only.",
            "And.",
            "The next one will would be indirect or gradient methods.",
            "Which use this this gradient information as well, and I would.",
            "Add as a third category, 2nd order.",
            "Gradient methods.",
            "These are methods that also use the second derivative.",
            "It's the derivative of the derivative, so the gradient of that gradient.",
            "And what that gives you is it's a measure of the curvature of the function.",
            "So.",
            "In rough terms, if you have a direct method.",
            "You have to sample your function in many places and then you just try to move towards the samples that look better, right?",
            "And that's for instance, what evolutionary algorithms do?",
            "And there's many, many other methods, simplex method and other methods that do this.",
            "I should say the nelder Mead simplex method right?",
            "There's two simplex methods.",
            "If you have gradient information, you can actually look at a single point and know which direction is downhill and in multi dimensions the gradient actually tells you that the direction in which is you have the steepest slope downhill.",
            "OK, it gives you the steepest descent direction, so that's very useful.",
            "If you have a second order gradient information.",
            "It not only tells you which direction is downhill, but it also tells you the curvature of the function in that direction.",
            "Which tells you how far a step you should be taking, right?",
            "Because if there's a high curvature and you take a step in the downhill direction, but you're going too far, then you're overshooting the minimum annual and on the opposite slope.",
            "If you're not going far enough, well, obviously you could take a bigger step.",
            "So 2nd order methods have the big advantage that they tell you also how far to go.",
            "The 1st Order gradient methods only tell you which direction to go in, and the stepsize that you pick is then something that's very ad hoc that you have to worry about it.",
            "OK. Now.",
            "We have all these possibilities, so why hasn't anybody come up and sort of decided?",
            "OK, this is the best optimization method.",
            "And we don't worry about the other ones anymore.",
            "That is because.",
            "It's sort of like different kinds of car, right?",
            "They're very cheap, simple cars, and they're very fancy expensive cars.",
            "So the direct methods.",
            "Make no assumption about your function.",
            "It doesn't have to be smooth, differentiable or anything.",
            "Right, they always work.",
            "That makes them very easy to use, and that's one of the reasons why evolutionary algorithms, for instance, are so popular.",
            "You don't need to know anything about what you're optimizing.",
            "And you know you can just.",
            "Go plug it into your plug function into your code, minimize it.",
            "But they are very, very inefficient.",
            "Because they have no information about which direction is downhill.",
            "So the only way you can make progress is by sort of random mutations and recombination's, right?",
            "So you need a lot of cycles to optimize a function that way.",
            "Nature does it.",
            "Hey works, works great, but nature has had you know 5 billion years to do its job.",
            "And so if you can't wait that long and you know something about your function, for instance, that it's differentiable.",
            "Then you can get a huge speedup by actually giving your optimizer the gradient information, letting it work more efficiently.",
            "So typically we can express that in order notation right, there's something that computer scientists like to do.",
            "Are you familiar with that big O notation?",
            "Who isn't?",
            "Somebody, OK, I'll briefly explain if I say something takes.",
            "Order N. Time to compute.",
            "What I mean is there exists a finite constant K. Such that the actual time taken is K * N. Plus some other constant actually.",
            "So.",
            "This is basically saying it roughly takes in time.",
            "The actual time could be like any factor times N plus any constant.",
            "Because obviously these factors and this constant, they all depend on the implementation, right?",
            "You may write more efficient code you may have compiled code or something else, but the important thing is that.",
            "If two algorithms differ in the order of time or memory that they require?",
            "Then this will override any of these constants.",
            "For large enough problems.",
            "So if I have two algorithms and one is order N and one is order N ^2.",
            "Then you can see that no matter what K&C are, since they are finite, there will be a value of N. Beyond which, if N gets larger than that.",
            "This will always be slower than that.",
            "Right, I don't know what that end is, but if I worry about optimizing large problems, I just worry about the order of the algorithms because I'll say at some point and will be large enough that the order is all that matters.",
            "So what we have here for these three methods we can also associate an order with them, the direct methods.",
            "Our order one to order N where N is the number of dimensions of the problem.",
            "The function we are minimizing.",
            "And that means it's the size of this parameter vector, right?",
            "It's the number of parameters that we're trying to optimize.",
            "The size of the search space, really.",
            "And the direct methods typically normally there order in.",
            "But if you have efficient sort of incremental evaluation methods so that it's very cheap to evaluate.",
            "A mutation of a solution that you've already evaluated.",
            "Then you can actually go down to order one.",
            "So then can get very, very fast.",
            "But order N is also quite good.",
            "The 1st Order gradient methods are all generally order North.",
            "2nd order gradient methods depending on the implementation order N squared to order N ^3.",
            "I should add that for kernel methods.",
            "Since you go into this Hilbert space, the N actually winds up including the size of your training set.",
            "So so those methods actually then can become squared.",
            "For instance, in the size of the training set.",
            "But that's that's for me.",
            "That's sort of already on the implementation side.",
            "How you do your machine learning, right?",
            "If I look at the underlying optimization problem, I just used to stand for the dimensionality of the search space and optimizing over.",
            "And here we see now way why all these different methods are still around be cause for smaller problems.",
            "Maybe you can afford order N cubed and if you have a well behaved function that you know a lot about, you can calculate the gradient.",
            "You can calculate the Hessian which is the matrix of 2nd derivatives.",
            "You can give all this information to an algorithm and get very efficient optimization out of it.",
            "For larger problems, however, you cannot afford order N ^3.",
            "It just means you know you take a 1010 times larger problem.",
            "It takes 1000 times longer to compute.",
            "It will very quickly get too slow.",
            "So then you have to fall back on 1st order gradient methods.",
            "And eventually you have to fall back on direct methods.",
            "If you have really humongous problems or you have search spaces that you know nothing about.",
            "Things like combinatorial search spaces, right?",
            "Where you searching over combinations of Boolean values there is no.",
            "Rich metric in such spaces as opposed to Euclidean space, where we have, you know we have a triangular inequality and all these things.",
            "In those Boolean search spaces, things are much harder, so the direct search methods really are shine in those on those problems, because that's the only thing you can use there.",
            "What I work on.",
            "Is gradient methods.",
            "And I in particular work.",
            "In this area.",
            "Which is kind of funny, but I'm going to motivate that because generally the evolution of gradient optimization algorithms has been in this direction, right?",
            "Obviously, you know when you come up and you have to do your PhD thesis, you have to do something nobody's done before, so you know this has been pretty much covered by Gaussian Newton and those guys you know many centuries ago, so you attempt to end up somewhere here and doing horrendously complicated.",
            "You know high order methods for special cases and this and that and the other, however.",
            "There's a reason why I believe these high order methods.",
            "Will actually.",
            "Become less important in the future in machine learning, not in optimization in general, but in machine learning and why I believe these methods are very, very important.",
            "And that has to do with the amount of data that we're getting.",
            "So it's not the dimensionality of the search space, but it's just the number.",
            "The size of the training set, the number of observations we have.",
            "That number increases dramatically these days, right?",
            "I mean with.",
            "All these new networked webcams and everything we get in huge amounts of data.",
            "And it turns out that with these huge amounts of data, you get another problem.",
            "And I will describe that now.",
            "So this function here that I've written down as.",
            "As a sort of prototypical loss function, it's actually too simplistic, right?",
            "I have some data here, but I should really say, well, this is XI.",
            "This is my observation.",
            "And what I really want to minimize is the sum.",
            "From I = 1 to N of these things, right?",
            "So I have a training set.",
            "OK, I'll let's not use NI used N for the dimensionality.",
            "So let me just use L here.",
            "So I have a training set of size L. And now I want to minimize this function.",
            "With respect to Theta OK. Now if I use a gradient method to do that, I need the gradient of this function.",
            "I need the derivative and if you remember your sort of basic calculus, the derivative of a sum is the sum of the derivatives, right?",
            "So my gradient will actually inherit this structure.",
            "It will also be a sum from I = 1 to L. Of the derivative.",
            "Of the.",
            "Loss on the individual data.",
            "The problem that we're hitting as L gets large.",
            "Is that a single measurement of my function and also a single measurement of my gradient requires a loop through the entire training set.",
            "We have to loop through an, add it all up.",
            "And this is fine if L is 1000.",
            "And actually, when I did my PhD 1000 was considered huge.",
            "I mean, people did training sets of you know 16 examples and if you were ambitious 100.",
            "Now 1000 is nothing, million is.",
            "Typical.",
            "In real applications it can go up to anything.",
            "I mean it can go up to you know 10 to the 710 to the 8th.",
            "And now these loops become huge and slow.",
            "You basically have to go through all your data before you can even take the first step in your optimization procedure.",
            "And.",
            "If you if your data, for instance is larger than fits in memory in your computer, then you are in trouble.",
            "So what I'll talk about today.",
            "Is a trick to speed this up and the trick is simply instead of waiting for all the data before we start the optimization.",
            "What we'll do is we'll just look at some of the data.",
            "And that's some of the data that could be like a single data point.",
            "Or it could be five data points.",
            "Or it could be 1000 data points.",
            "That's that's a parameter that I can choose, but I'll only look at some sort of a sense of current observations, right?",
            "I'll look at the current batch of observations.",
            "Then I perform an optimization step on that.",
            "Then I grab some new observations, optimize on that, and I keep going like that.",
            "This is called stochastic approximation.",
            "And what So what we're approximating is this function.",
            "Our true objective.",
            "And we approximating it stochastically by stochastic.",
            "Here is meant this subsampling of the data, because when you try to model analytically, what's going on there, the assumption that you make is that your data is sort of IID, it's it's identically independently distributed on your picking.",
            "Random data in practice.",
            "Of course, that's not what you do.",
            "You pick the data that you have at the moment, right?",
            "So typically say if you have an online learning system where data comes in all the time and you try to adapt to that.",
            "You don't have the choice of picking your samples IID because you just have to take what's there.",
            "Nonetheless, that's sort of the label that's been attached to this.",
            "These techniques why is it an approximation?",
            "Well, if my parameters theater would be constant.",
            "Then actually it would be exact, right?",
            "I could just take Subsamples and if I then go and add up all the subsamples or all the gradients of the subsamples I would get.",
            "The original function or the original gradient back, but that's not what I'm doing.",
            "I'm taking a subsample.",
            "And then I'm doing my optimization and the optimizer changes the parameter vector becausw.",
            "I'm searching in parameter space.",
            "So now what I'm adding up overtime is actually slightly inconsistent because it's all these gradient measurements done on different data and slightly different parameter values.",
            "And I'm going to pretend that overall, that corresponds to some sort of gradient of the entire objective function, and people have done analysis on that and derive conditions under which that works.",
            "It seems to me that the on each step you recognizing at kind of a different.",
            "Function so you get some data that you get some fresh and you have thanks to get this close to the meme of this function of this.",
            "Suddenly you get more data.",
            "Kind of.",
            "Get from.",
            "One is transmitted from nothing to do with what you get from another instance.",
            "Nothing to do is too strong, but you're very right in pointing out the problem.",
            "That's exactly the problem and.",
            "There's The upshot of all of that is that you don't want to do too much optimization on this little sample of data, because yes, it's poor information.",
            "You only have some of the data, not all of it, and so you don't want to expand a huge effort, for instance, and do like a full, you know Gauss Newton or living Bergmark word or whatever optimization step, because the minimum that you find in that step actually has very little to do with the true minimum is that's true.",
            "And that's why I'm interested in these kinds of methods, because these are cheaper and less efficient optimization methods.",
            "And it turns out that if on this small data sample you just do a little step in the right direction.",
            "And you keep doing that for fresh samples.",
            "Overtime, if you set this up in the right way, it will actually converge to the right answer.",
            "So yes, you can't be too overaggressive in optimizing on these small subsamples.",
            "That's part of the.",
            "Part of the game here.",
            "Is nutrition position continue?",
            "You are using all the data that were accumulated at any given time, so you have data grows.",
            "There's various scenarios, so.",
            "One scenario would be what I would call online learning, where the data just keeps coming in, so you never see the same data twice because it's just I don't know you have a video feed, you know you're trying to learn from that as it goes, but there's always fresh images coming, so you never recycle that data.",
            "That's online learning.",
            "In that scenario, you actually have to use stochastic approximation because you cannot wait for the end of the training data for the end of this loop, because there is no end, right?",
            "However, it turns out stochastic approximation algorithms can be very efficient optimizers, and so people use them even when the training set is finite.",
            "And what you would typically do is you say you have your training set.",
            "So let's say each of these vectors is 1 observation and they keep coming in, and this is here, you're set, right?",
            "And let's say, OK, you pick three and you say that's my little mini batch on which I do the first optimization step and then you take the next three, then the next.",
            "What you would typically do?",
            "If you have a finite training set and you won't use stochastic approximation, is.",
            "You would cycle through the training set with these.",
            "Little batches and when you hit the end you would go back to the beginning and sample again.",
            "But and here's another little trick that's important here.",
            "As you rap around, you permute the training data.",
            "You shuffle it.",
            "Becaused one problem that you can have with stochastic approximation is if there are a lot of local correlations in your data.",
            "Then it can lead your optimizer really astray because say all the data over here points in One Direction and all the data over here points in the other direction.",
            "You'll get these big oscillations and to avoid that you randomly shuffle all your data before you split it up into these little benches.",
            "So that's typically what you would do.",
            "I should go back.",
            "So before I launch into the talk proper, let me just go back and just to make sure everybody has the background talk a little bit about what I mean.",
            "You know, but repeatedly optimizing and finding a minimum with the gradient method, so I'll just sort of very quickly describe 1st order gradient descent.",
            "So here we have our function.",
            "This is our parameter.",
            "And say we're starting at a value here.",
            "Right?",
            "What we do is we take the gradient which gives us the slope.",
            "Of the tangent in that point.",
            "And now the simple 1st order gradient descent update rule would say.",
            "Theta T + 1 my new parameter values.",
            "Are the previous ones minus some small constant ETA times the gradient?",
            "So this is partial F?",
            "With respect to Theta.",
            "And this is called gradient descent.",
            "1st Order simple gradient descent.",
            "What does this do in this case?",
            "So here we are at a point Theta.",
            "The slope here is positive, right?",
            "We will have a positive gradient here.",
            "Which means because of the - Here it is a small positive constant.",
            "I have to add because of the - Here it means we will subtract a little bit from our parameter value, so we will go to the left.",
            "Pick the next point, right?",
            "Again, we have the tangent here.",
            "The slope is steeper now, so actually will subtract more.",
            "We go here.",
            "Now we have a more shallow slow.",
            "So we'll subtract less.",
            "Now the slope is very very shallow.",
            "And you can see that because if we land on the other side, the slope will go negative and we'll start adding to the parameter value.",
            "You'll see that this will converge to the minimum here.",
            "If we have started out over here.",
            "We would have started going to the right.",
            "We would have added to the parameter value until we hit the same minimum.",
            "Now one point to make here is gradient methods are local optimizers.",
            "That means if there's another minimum somewhere else, we're not finding it.",
            "So if that function actually has a better minimum over here.",
            "If we start here, we'll still go and find that minimum.",
            "That's a problem that's not addressed by gradient methods.",
            "If you take like a full course in optimization, there's lots of standard techniques to turn.",
            "Basically a global optimization problem into a local optimization problem.",
            "And so you put some machinery on top of this local gradient optimizer and at the top level you have a global optimizer, so this can be done.",
            "I'm not going to talk about that machinery, right?",
            "That's sort of the car and I'm talking about the engine.",
            "So.",
            "Keep in mind this is roughly what what's going on.",
            "And I think we should now be at the point where we can just give the talk the way I normally do it, and this is called rapid stochastic gradient descent accelerating machine learning."
        ],
        [
            "Well, this is the overview.",
            "I'll talk a little bit more.",
            "I've already started on that.",
            "Why we want stochastic approximation and then I'll talk about my favorite stochastic approximation algorithm, which is my own.",
            "I'll talk about that at length.",
            "I'll give you the derivation as some properties in benchmark results and what we're using it for and summarize it."
        ],
        [
            "Um, this is by way of motivation.",
            "I've really seen this over the last five years or so.",
            "It's been extremely explosion of data available for machine learning.",
            "I mean, it used to be that you had to sort of look for datasets to use, and especially if you wanted to use large datasets, it was actually not easy to get large datasets.",
            "Now everybody actually is coming and asking if you're a machine learner.",
            "Everybody is coming.",
            "I have these huge amounts of data.",
            "I have no idea what to do with them.",
            "I don't even have time to look at it once.",
            "Do something with it, right?",
            "This is the typical scenario now so.",
            "One nice example I have is a friend of mine is a whale researcher in the Saint Lawrence in Canada and what she does every summer is she sticks hydrophones into the water and records the whale communication.",
            "And there's actually very little known.",
            "Surprisingly little is known about that so.",
            "What they study is especially the interaction between ships and whales.",
            "You know, how much do the ships disturb whales and how much does the noise from the ships disturb the whale communication and all that?",
            "And a couple of years ago she started out and they had one hydrophone and it was recording for like 5 hours.",
            "And then they had to retrieve it and analyze the data.",
            "Nowadays she has about on the order of 10 hydrophones.",
            "They go in in the spring.",
            "They have a huge hard disk on them.",
            "They record 24 hours continuously until the fall.",
            "So now every fall she gets like only order of five years worth of audio recordings.",
            "And she has three months to analyze them, right?",
            "So now you know, you really have this situation.",
            "You cannot even look at the data once.",
            "And this is a typical situation nowadays, right?",
            "So you need some fast method to just scan through, throw away the uninteresting portions, and so on.",
            "And that's of course a machine learning problem because it's hard to tell what's interesting, specially if there's the potential for things that you didn't look for new things.",
            "There's some species of whale out in the Saint Lawrence where it's not even known if they have localizations and what they are.",
            "So you know if you throw away too much, you're missing that.",
            "So this is the typical problem nowadays, and that's really the current problem for machine learning.",
            "OK, these are some other random examples.",
            "One pulsar survey at erasable, the huge radio dish right in Costa Rico, produces one terabyte of data a day.",
            "And that's one survey out of half a dozen that are running concurrently on that dish.",
            "OK, the Dell website over 100 page requests a second.",
            "Probably Google would be on two orders of magnitude more than that, but Google doesn't do as much adaptation to a customer's other sites to Amazon is maybe a good example because Amazon actually remembers you and customizes the pages for you, and they probably get on the order of 1000 page requests.",
            "A second London has over 500,000 security cameras, and again nobody has time to watch all that video.",
            "So we clear."
        ],
        [
            "We need something to cope with that.",
            "We need machine learning algorithms, but not just any algorithm.",
            "We need algorithms that can handle large, complex nonlinear models because the datasets are large, complex and nonlinear and.",
            "By that I mean up to millions of degrees of freedom, so I'm happily considering problems where N here is on the order of 10,000,000.",
            "OK, and now this is something 10 years ago that would have been considered insane and it's still a bit out on the link, but it can actually be done.",
            "Um?",
            "We need to be able to deal with large volumes of very low quality data.",
            "We may have noisy correlated data.",
            "Nonstationary data, outliers, all kinds of nasty things in there.",
            "And we need real time online adaptation.",
            "We want the answers basically as the data rolls in.",
            "That's the typical scenario nowadays, so we cannot actually sort of.",
            "Collect the training set.",
            "You know, clean it up, preprocess it, run the algorithm for a couple days, then publish the result.",
            "If the mode nowadays is data comes in answers go out and the learning has to happen online in between.",
            "Now my claim is that.",
            "A lot of the current machine learning techniques have difficulty with that.",
            "Or I should maybe say the current optimization techniques tend to have difficulty with that."
        ],
        [
            "And here's the problem.",
            "So a classical optimizer.",
            "Is this iterative process right?",
            "You loop over and at each iteration in the loop you take a function and gradient measurement.",
            "And that measurement consists also of a loop.",
            "Namely, overall your data.",
            "So you have two nested loops and if your data set gets big, this becomes very, very slow.",
            "What you need is online learning here.",
            "So you need to use stochastic approximation so that you're interleaving your optimizer with a sampling of the training data, and it all happens in a single loop, right?",
            "Now this is also the scenario that people in signal processing.",
            "You know adaptive filtering and so on consider.",
            "So as far as I'm concerned, these are all near synonyms, adaptive control, adaptive signal processing, filtering, stochastic approximation, online learning.",
            "These are all people from different backgrounds talking about more or less the same thing, but bringing different tools and techniques to the enterprise."
        ],
        [
            "Now, here's a little bit what I've already elaborated.",
            "What I've thrown on the whiteboard, right?",
            "You want to typically minimize with respect to some parameter vector Theta.",
            "Now this is the.",
            "A scenario where I'm making a statistical assumption, I'm talking about the expectation over the data of some loss function that is defined over the data, right?",
            "So this is actually the true risk, and we approximate that by the empirical risk where we have some sort of training set from which we sample the data and we average over the training set.",
            "Right, so this is.",
            "Probably burnout has covered this pretty well, so this is sort of the classical setup in machine learning, but it contains this loop over the training set.",
            "And for large sets of data, that loop is inefficient.",
            "An if your data never ends, then or, it's nonstationary.",
            "So as you go through the data that the underlying statistics of the data change on you.",
            "Right then this becomes an inappropriate formalism.",
            "So what we really need to do is stochastic approximation whereby we just take the loss on the current data and the current value of these parameters.",
            "And we do some quick and dirty optimization over that to get the next set of parameter values.",
            "And then we iterate that so the next batch of data is going to be evaluated on the fresh parameters.",
            "Now.",
            "So these are, I gather some of these equations are missing on the slides.",
            "I apologize that's a font problem, so if you want I'll leave those slides on a little bit longer if you want to enter them.",
            "This one is fine.",
            "Now.",
            "On the other ones, don't start writing too early because I have animated equations, so they're going to change on you, so I'll tell you when the last version is up and you can start writing OK.",
            "So now.",
            "We come to the key problem.",
            "Up sorry you were not done.",
            "OK let's.",
            "Go.",
            "No.",
            "Let me do that.",
            "OK.",
            "The key problem is that people for.",
            "Centuries really have developed these fancy optimization methods, so this first order gradient descent.",
            "I should say that I explained to you right, this is sort of.",
            "Very, very low level, right?",
            "It's almost as bad as evolutionary algorithms if you talk to anybody in a math Department that does optimization, they're going to laugh at you if you come with that, right?",
            "What everybody does is, you know, 2nd order with lots of bells and whistles, and this, that, and the other machinery on top right?",
            "Really heavy, heavy duty hardcore stuff.",
            "So actually hundreds of years of mathematical expertise have gone into pushing things in this direction.",
            "No more and more complex machinery to be more and more efficient at solving these problems.",
            "Now, the key problem that we're getting here now, so everybody done.",
            "Yeah.",
            "Using either at time step T is the initial condition for your.",
            "Yeah, so the idea is that at time T will take the parameter values at that time and the current data, and we're going to change the parameter values based on that.",
            "If we're going to do a little optimization step and then we take those new values and at the next time step.",
            "We're going to measure the gradient, for instance on the new data using those new values at that new point already.",
            "So we're taking the measurements always at the current point.",
            "So if our optimizer hops around, those measurements will also help around.",
            "That's that's what that's why.",
            "It's sort of an approximation.",
            "That's why it's not not an exact thing to do this.",
            "OK."
        ],
        [
            "Now.",
            "So here's a here's a little picture of the hierarchy of optimization algorithms, right?",
            "So at the bottom you have evolutionary algorithms, which is really what all the amateurs do that don't know anything about.",
            "Optimization, right one level up is what I'm doing, and then the real algorithms are all up here, right?",
            "And the two axis here that I've plotted the order of the algorithm in terms of the dimensionality of the search space.",
            "So this is order one or the N order in squared order in cube.",
            "So it gets more and more expensive as you go out to the right.",
            "And on the other axis is the convergence speed.",
            "So it's kind of the inverse of how many iterations you have to run your optimizer for until you get a good solution.",
            "Evolutionary algorithms you have to run forever gradient descent slightly less than forever, and here they start getting really fast.",
            "Now the problem is when you do stochastic approximation, which I've said you need when you deal with a large data set, because otherwise even the first iteration takes too long.",
            "You cannot wait for even just one pass through the data.",
            "If you use stochastic approximation.",
            "That approximation unfortunately screws up all this advanced machinery up here.",
            "So actually what happens is?",
            "When you go online, you're just left with that.",
            "Conjugate gradients are completely hopeless with stochastic approximation.",
            "Never tried to do that, it's just.",
            "It can't work.",
            "The other algorithms, typically what happens is they're too expensive, so levenberg Marquardt for instance is order N ^3.",
            "You don't want to run an order in cubed algorithm on so little evidence, right?",
            "You just have sort of a little batch of current data and you don't really want to do this.",
            "Bring this heavy machinery to bear on this data because the minimum that you'll find will be a different one every time.",
            "Depending on which data you happen to have an, it's very costly.",
            "It's very expensive, so those algorithms pretty much are out of the question.",
            "And now.",
            "What we're left with is basically those simple methods, and then things like common filtering.",
            "I use it as a generic term for these sort of 2nd order online maximum likelihood methods from signal processing.",
            "Those work they explicitly incorporate a model of the stochastic nature of the data.",
            "But they typically make strong assumptions about what the nature of the data is.",
            "So if your actual data violates these assumptions, they don't work anymore.",
            "So if you have a good knowledge of how your data looks like, this may be the way to go.",
            "However, these things are order N squared, and so if your end gets big, if your parameter space gets gets very large, then you can't use that either.",
            "And so then you just left with those two.",
            "And now I finally explained why I do the research I'm doing cause.",
            "If you set it up just right, if you set up your problem just right, then this is the best thing on Earth.",
            "And what I'm working on is trying to make this converge faster.",
            "So one key problem that you have with first order simple gradient descent is that it can be very, very slow.",
            "It can take many iterations to converge.",
            "And.",
            "Actually, I think I have that picture later.",
            "So yeah, I'll show you later why exactly?",
            "So what I'm working on is it's methods to speed that up."
        ],
        [
            "OK, here this is actually the same thing in words.",
            "Um?",
            "Particular conjugate directions breakdown, so this is the reason there's a technical reason why conjugate gradient methods don't work with stochastic approximation.",
            "The other ones are just simply too expensive.",
            "This leaves evolutionary algorithms very inefficient and simple gradient descent slightly less inefficient, I would say.",
            "OK, now."
        ],
        [
            "Now let's go into techniques for speeding up gradient descent.",
            "Alright, so on this one.",
            "This you can copy already.",
            "So here's I just set up the notation.",
            "I'll I'll call the gradient at time T GT.",
            "And what I mean by that is it's the gradient of the loss.",
            "On the current parameter values and the current data.",
            "So this is a stochastic quantity even at the same point in parameter space.",
            "If I pick some fresh data, I would get a different answer.",
            "OK, think of it as a stochastic function.",
            "A non deterministic function.",
            "It gives me a different answer every time.",
            "But somehow overtime these answers all average out right?",
            "Because if you average all these answers and you keep the parameters fixed, then in the limit.",
            "By the by the Central limit theorem of statistics you will actually get the true gradient on the entire data.",
            "But we'll never actually do that because we'll keep changing the parameters.",
            "So now we do a first order gradient descent.",
            "New parameters are the old ones minus some step size.",
            "Some gain times the gradient.",
            "And the first thing that I'll do that's non standard is I'll make this gain A to a vector.",
            "And I'll use here as I'll use this central little dot to stand for Hadamard multiplication or it's elementwise multiplication OK?",
            "So it just means every element of the Zeta vector is multiplied with the corresponding element of the gradient.",
            "So this means I can set the gain differently for each direction in parameter space for each dimension in parameter space.",
            "Now what do we do with these gains?",
            "The key idea is that.",
            "Instead of setting them explicitly, which is what many standard gradient methods require.",
            "What we can do is we can learn the gains from the data as we go along and we learn them at the same time while we're learning the parameters.",
            "And the trick is the following we.",
            "We will adapt the gains.",
            "But actually will go into lock space, will take the log pointwise elementwise of the gains.",
            "And when we then do a gradient descent in the log games.",
            "So the new log gains are the old ones, minus this is a meta gain.",
            "This is the step size for the step sizes.",
            "Times.",
            "The gradient with respect to the log gain of the same objective function that we have up here.",
            "So the idea is that just like we are learning the parameters that minimize the function will also learn the step sizes that most efficiently minimize the function.",
            "And the neat thing is we can actually do this and we can do it at the same time.",
            "Now, why do we go to the to the lock space?",
            "I've told you that the gains have to be positive, right?",
            "And they can also range over long many orders of magnitude.",
            "So in a practical application you may set again to like 10 to the minus 6.",
            "Or to 10 to the minus two or to one.",
            "So you have this scaling over many orders of magnitude.",
            "And the values are not allowed to go negative.",
            "So.",
            "How do we ensure that in a gradient descent scenario it's actually hard to do because gradient descent takes these finite steps and so if the gradient indicates we should go towards 0?",
            "And because the correct value is maybe 10 to the minus six, it's very easy to step too far and landed a negative value and then suddenly instead of minimizing, we would be maximizing, right?",
            "So it would completely blow up the algorithm.",
            "So the trick is by.",
            "Performing gradient dissent in the log gains.",
            "So just think of this as a variable name, right?",
            "So not a variable that happens to be the log of the haters.",
            "We can allow negative values.",
            "Alright, so now the values can go anywhere in our end.",
            "And.",
            "To get the gain back will exponentiate those values.",
            "And that will give us first of all strictly positive values and they will nicely scale geometrically, so we can actually ramp them up and down by orders of magnitude without problems.",
            "Yes.",
            "Huh, that is a free parameter so you have to set it by trial and error.",
            "It's not hard to tune.",
            "It typically winds up being something like 0.1, but.",
            "It's a magic number.",
            "Yes, an this is a good point and this is something I have to convince you yet off that all this machinery actually helps you, right?",
            "Because in first order gradient descent you have this ETA this game that you have to set an it's a magic number.",
            "You have to just try out what works.",
            "And here I have the same magic number, just one level down.",
            "So.",
            "It's not clear upfront that this actually gives you anything.",
            "OK.",
            "So now we adapt the logins by.",
            "Gradient descent.",
            "So, OK, I've said that already.",
            "And.",
            "What you then do is you can exponentiate both sides of this equation.",
            "Here you just get the game back.",
            "And here you know, the addition here turns into a multiplication and you have to exponentiate this part.",
            "The other thing I've done here is I've used the chain rule for gradients to split this gradient up into the gradient of the loss with respect to the parameters.",
            "Times the gradient of the parameters with respect to the log gain.",
            "OK, just just straightforward chain rule of different station.",
            "Now this part here is obviously.",
            "Just the standard gradient, so that's exactly what I've called GT up here, right?",
            "So will get GT times something else.",
            "And I'll just call that something else, Viti.",
            "Just as a definition.",
            "And.",
            "I'll do so.",
            "This is just Vt. OK, this is ready to be copied.",
            "The other thing I've done here is I've approximated the exponential function here and the reason for that is this is in the innermost loop of our machine learning algorithm.",
            "And this exponential function.",
            "Actually, if we have a system with a million parameters and we're going through thousand data points a second.",
            "It means that we will have 1 billion exponentiations per second.",
            "In our algorithm, and this is actually a very slow function to compute, so you will find that you actually spend 90% of your computation in the exponential function.",
            "So what I've done is a really really hairy approximation.",
            "Basically, I'm pretending that.",
            "E to EU.",
            "Is approximately the Max of 1/2 and 1 + U. OK, so.",
            "E to EU looks like this.",
            "1 + U.",
            "Is the tangent in the origin?",
            "It looks like this and I cut it at 1/2.",
            "I go flat.",
            "So by linear approximation, it's really atrocious.",
            "But all that matters to me is near the origin.",
            "It matches the exponential in the in the value and in the slope in the first derivative.",
            "And that's all I need because my mu.",
            "The meta step size will be relatively small.",
            "And so all these terms that I'm exponentiating will be near 0 here.",
            "And in fact.",
            "This approximation deliberately.",
            "It is done this way in order to make the algorithm robust to outliers.",
            "Because the other problem with an exponentiation in your algorithm is if you get an outlier.",
            "And what you're exponentiating happens to be 50, which doesn't sound too bad.",
            "Well, E, to the 50 is very bad.",
            "It's a huge number.",
            "So what this does is it dampens very large positive values down.",
            "And elevates very small, very negative values.",
            "Very small values basically to 1/2, so it makes the algorithm more conservative.",
            "While near 0, it still preserves the properties so.",
            "This is a completely ad hoc, but this is what works in practice in this algorithm.",
            "Now what I haven't told you yet.",
            "Is what this sweetie?",
            "Exactly is, I've just written here very glibly the partial of.",
            "The current parameter Theta T with respect to log data, but note that I've cunningly left out anytime index here, log it, or what you know is it a T?",
            "Is it a?",
            "T -- 1 whatever so.",
            "We'll now talk about exactly what we mean by this, and this will actually be a crucial piece of the algorithm.",
            "So."
        ],
        [
            "What people have done before is they've defined V T + 1.",
            "To be the partial of Theta T plus one with respect to log data T. Note that there's like a one time step difference here.",
            "You need to change.",
            "OK. Quick break while we change.",
            "Should be some hold.",
            "Something annoying.",
            "So conventionally people have defined the V parameter to be this.",
            "And the reason to define it that way, it's just that you get a simple answer for what we should be, because if you recall data, T + 1 is better T -- 8010 GP.",
            "So this partial you can read off directly from here, right?",
            "The partial of Theta T plus one with respect to 8 P would just be minus GT.",
            "And now, since we're taking the partial with respect to log into peanut 8:30, we will pick up an additional 830.",
            "That basically is because the derivative of the log of X is 1 / X.",
            "And so if we're taking a partial with respect to that, we'll have to multiply by 1 /, 1 / X.",
            "Next, in this case, being that.",
            "So this derivative is very easy to take and gives you this simple answer.",
            "And."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My name is Nick struggle.",
                    "label": 0
                },
                {
                    "sent": "I'm originally from Germany.",
                    "label": 0
                },
                {
                    "sent": "And studied in my undergraduate degree in England back in the 80s.",
                    "label": 0
                },
                {
                    "sent": "And that was when Realnetworks.",
                    "label": 0
                },
                {
                    "sent": "I've done the scene machine learning and that was when at UCSD, the PDP research group wrote what used to be known as the Bible, and it's no more like the Old Testament.",
                    "label": 0
                },
                {
                    "sent": "The basically put neural networks on the map and that started a revolution in machine learning and I was over in England and I was really fascinated by neural networks.",
                    "label": 0
                },
                {
                    "sent": "So then for my PhD I went to UCSD.",
                    "label": 0
                },
                {
                    "sent": "By the time I arrived there, most of that research group had left two other places, but there were still some people left.",
                    "label": 0
                },
                {
                    "sent": "I did my PhD, then at the Salk Institute in San Diego with Harrison Joeski.",
                    "label": 0
                },
                {
                    "sent": "Then went post talking around the world a bit and ended up here about one year ago.",
                    "label": 0
                },
                {
                    "sent": "Needless to say, nobody calls their machine learning.",
                    "label": 0
                },
                {
                    "sent": "Gives most neural networks anymore.",
                    "label": 0
                },
                {
                    "sent": "But actually not all that much has changed.",
                    "label": 0
                },
                {
                    "sent": "It's just the buzzwords are different.",
                    "label": 0
                },
                {
                    "sent": "There's some new techniques around, but under the hood it's still pretty much the same.",
                    "label": 0
                },
                {
                    "sent": "I think it's as back when I studied these things OK before I launch into my talk, I actually want to give you an introduction about the things I don't want to talk about.",
                    "label": 0
                },
                {
                    "sent": "So I'll talk about them at length.",
                    "label": 0
                },
                {
                    "sent": "Basically what I'm concerned with is.",
                    "label": 0
                },
                {
                    "sent": "The engine that drives machine learning.",
                    "label": 1
                },
                {
                    "sent": "So Bernard in his talk has told you about empirical risk minimization right so that the typical way you set up a machine learning problem is you find a function that measures how much error you're making on some training data, and you try to minimize that function.",
                    "label": 0
                },
                {
                    "sent": "What interests me is how do you actually do that minimization?",
                    "label": 0
                },
                {
                    "sent": "Right, how do you?",
                    "label": 0
                },
                {
                    "sent": "How do you run that and how can we make that engine that drives machine learning efficient?",
                    "label": 0
                },
                {
                    "sent": "How can we get answers fast right so?",
                    "label": 0
                },
                {
                    "sent": "Optimization methods.",
                    "label": 0
                },
                {
                    "sent": "Is what I'm concerned with and.",
                    "label": 0
                },
                {
                    "sent": "We can distinguish optimization methods.",
                    "label": 0
                },
                {
                    "sent": "We can classify them by whether they're using gradient information and what kind of gradient information they are using.",
                    "label": 0
                },
                {
                    "sent": "Does everybody know what a gradient is?",
                    "label": 0
                },
                {
                    "sent": "Yeah anybody doesn't?",
                    "label": 0
                },
                {
                    "sent": "I mean I'm I can go back and explain.",
                    "label": 0
                },
                {
                    "sent": "OK quick introduction.",
                    "label": 0
                },
                {
                    "sent": "We have a function.",
                    "label": 0
                },
                {
                    "sent": "And let's say it's the kind of function we would want to minimize in machine learning, so it could be an empirical risk function, so I'll just call it F. And I'll say there's some parameters Theta over which we want to optimize it.",
                    "label": 0
                },
                {
                    "sent": "And maybe it depends also on some inputs X, right?",
                    "label": 0
                },
                {
                    "sent": "Now the gradient of that function if that function is smooth and differentiable, we can take the gradient.",
                    "label": 0
                },
                {
                    "sent": "The gradient is defined.",
                    "label": 0
                },
                {
                    "sent": "As the limit.",
                    "label": 0
                },
                {
                    "sent": "For some age going to 0.",
                    "label": 0
                },
                {
                    "sent": "Of F. Theta.",
                    "label": 0
                },
                {
                    "sent": "Plus H. Times.",
                    "label": 0
                },
                {
                    "sent": "Also, this is a directional gradient.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's OK. Out, stick in here a unit vector in direction I OK so the unit vector in direction I.",
                    "label": 0
                },
                {
                    "sent": "Is all zeros except it has one.",
                    "label": 0
                },
                {
                    "sent": "A single one, and this is in the eye position.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the unit vector in direction I, so we add to the parameters H times the unit vector in direction I and we measure the function at that point.",
                    "label": 0
                },
                {
                    "sent": "Let me stick in the input.",
                    "label": 0
                },
                {
                    "sent": "We subtract from that the function at the original point.",
                    "label": 0
                },
                {
                    "sent": "And divide by H. If you take the limit as H goes to 0, this is the gradient of F. Theater X with respect to the I've component.",
                    "label": 0
                },
                {
                    "sent": "Of the parameter vector, the ice component, because that's the component we're perturbing here.",
                    "label": 0
                },
                {
                    "sent": "So this is a definition.",
                    "label": 0
                },
                {
                    "sent": "Graphically, it looks like this if this is your function.",
                    "label": 0
                },
                {
                    "sent": "We are, at a certain point, Theta.",
                    "label": 0
                },
                {
                    "sent": "Right, what we're taking is now.",
                    "label": 0
                },
                {
                    "sent": "I only have one coordinate, so this is my coordinate an perturbing.",
                    "label": 0
                },
                {
                    "sent": "I'm going to add a little bit H to that coordinate.",
                    "label": 0
                },
                {
                    "sent": "I'll measure the function at that point.",
                    "label": 0
                },
                {
                    "sent": "Subtract from that the original function.",
                    "label": 0
                },
                {
                    "sent": "So I'm taking this difference here.",
                    "label": 0
                },
                {
                    "sent": "And divide by H and what that actually gives me is the slope of the tangent.",
                    "label": 0
                },
                {
                    "sent": "At that point, the tangent on the function.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "How could that be useful for minimizing a function?",
                    "label": 0
                },
                {
                    "sent": "Well, if we know the slope of the tangent, we know which way is downhill, right?",
                    "label": 0
                },
                {
                    "sent": "We know that if we go in this case to the left, we're going to reduce the function.",
                    "label": 0
                },
                {
                    "sent": "If we just have function values, it's harder to tell.",
                    "label": 0
                },
                {
                    "sent": "So you can classify optimization methods into.",
                    "label": 0
                },
                {
                    "sent": "Direct methods.",
                    "label": 0
                },
                {
                    "sent": "And these use function values only.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The next one will would be indirect or gradient methods.",
                    "label": 0
                },
                {
                    "sent": "Which use this this gradient information as well, and I would.",
                    "label": 0
                },
                {
                    "sent": "Add as a third category, 2nd order.",
                    "label": 0
                },
                {
                    "sent": "Gradient methods.",
                    "label": 0
                },
                {
                    "sent": "These are methods that also use the second derivative.",
                    "label": 0
                },
                {
                    "sent": "It's the derivative of the derivative, so the gradient of that gradient.",
                    "label": 0
                },
                {
                    "sent": "And what that gives you is it's a measure of the curvature of the function.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In rough terms, if you have a direct method.",
                    "label": 0
                },
                {
                    "sent": "You have to sample your function in many places and then you just try to move towards the samples that look better, right?",
                    "label": 0
                },
                {
                    "sent": "And that's for instance, what evolutionary algorithms do?",
                    "label": 0
                },
                {
                    "sent": "And there's many, many other methods, simplex method and other methods that do this.",
                    "label": 0
                },
                {
                    "sent": "I should say the nelder Mead simplex method right?",
                    "label": 0
                },
                {
                    "sent": "There's two simplex methods.",
                    "label": 0
                },
                {
                    "sent": "If you have gradient information, you can actually look at a single point and know which direction is downhill and in multi dimensions the gradient actually tells you that the direction in which is you have the steepest slope downhill.",
                    "label": 0
                },
                {
                    "sent": "OK, it gives you the steepest descent direction, so that's very useful.",
                    "label": 0
                },
                {
                    "sent": "If you have a second order gradient information.",
                    "label": 0
                },
                {
                    "sent": "It not only tells you which direction is downhill, but it also tells you the curvature of the function in that direction.",
                    "label": 0
                },
                {
                    "sent": "Which tells you how far a step you should be taking, right?",
                    "label": 0
                },
                {
                    "sent": "Because if there's a high curvature and you take a step in the downhill direction, but you're going too far, then you're overshooting the minimum annual and on the opposite slope.",
                    "label": 0
                },
                {
                    "sent": "If you're not going far enough, well, obviously you could take a bigger step.",
                    "label": 0
                },
                {
                    "sent": "So 2nd order methods have the big advantage that they tell you also how far to go.",
                    "label": 0
                },
                {
                    "sent": "The 1st Order gradient methods only tell you which direction to go in, and the stepsize that you pick is then something that's very ad hoc that you have to worry about it.",
                    "label": 0
                },
                {
                    "sent": "OK. Now.",
                    "label": 0
                },
                {
                    "sent": "We have all these possibilities, so why hasn't anybody come up and sort of decided?",
                    "label": 0
                },
                {
                    "sent": "OK, this is the best optimization method.",
                    "label": 0
                },
                {
                    "sent": "And we don't worry about the other ones anymore.",
                    "label": 0
                },
                {
                    "sent": "That is because.",
                    "label": 0
                },
                {
                    "sent": "It's sort of like different kinds of car, right?",
                    "label": 0
                },
                {
                    "sent": "They're very cheap, simple cars, and they're very fancy expensive cars.",
                    "label": 0
                },
                {
                    "sent": "So the direct methods.",
                    "label": 0
                },
                {
                    "sent": "Make no assumption about your function.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have to be smooth, differentiable or anything.",
                    "label": 0
                },
                {
                    "sent": "Right, they always work.",
                    "label": 0
                },
                {
                    "sent": "That makes them very easy to use, and that's one of the reasons why evolutionary algorithms, for instance, are so popular.",
                    "label": 0
                },
                {
                    "sent": "You don't need to know anything about what you're optimizing.",
                    "label": 0
                },
                {
                    "sent": "And you know you can just.",
                    "label": 0
                },
                {
                    "sent": "Go plug it into your plug function into your code, minimize it.",
                    "label": 0
                },
                {
                    "sent": "But they are very, very inefficient.",
                    "label": 0
                },
                {
                    "sent": "Because they have no information about which direction is downhill.",
                    "label": 0
                },
                {
                    "sent": "So the only way you can make progress is by sort of random mutations and recombination's, right?",
                    "label": 0
                },
                {
                    "sent": "So you need a lot of cycles to optimize a function that way.",
                    "label": 0
                },
                {
                    "sent": "Nature does it.",
                    "label": 0
                },
                {
                    "sent": "Hey works, works great, but nature has had you know 5 billion years to do its job.",
                    "label": 0
                },
                {
                    "sent": "And so if you can't wait that long and you know something about your function, for instance, that it's differentiable.",
                    "label": 0
                },
                {
                    "sent": "Then you can get a huge speedup by actually giving your optimizer the gradient information, letting it work more efficiently.",
                    "label": 0
                },
                {
                    "sent": "So typically we can express that in order notation right, there's something that computer scientists like to do.",
                    "label": 0
                },
                {
                    "sent": "Are you familiar with that big O notation?",
                    "label": 0
                },
                {
                    "sent": "Who isn't?",
                    "label": 0
                },
                {
                    "sent": "Somebody, OK, I'll briefly explain if I say something takes.",
                    "label": 0
                },
                {
                    "sent": "Order N. Time to compute.",
                    "label": 0
                },
                {
                    "sent": "What I mean is there exists a finite constant K. Such that the actual time taken is K * N. Plus some other constant actually.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is basically saying it roughly takes in time.",
                    "label": 0
                },
                {
                    "sent": "The actual time could be like any factor times N plus any constant.",
                    "label": 0
                },
                {
                    "sent": "Because obviously these factors and this constant, they all depend on the implementation, right?",
                    "label": 0
                },
                {
                    "sent": "You may write more efficient code you may have compiled code or something else, but the important thing is that.",
                    "label": 0
                },
                {
                    "sent": "If two algorithms differ in the order of time or memory that they require?",
                    "label": 0
                },
                {
                    "sent": "Then this will override any of these constants.",
                    "label": 0
                },
                {
                    "sent": "For large enough problems.",
                    "label": 0
                },
                {
                    "sent": "So if I have two algorithms and one is order N and one is order N ^2.",
                    "label": 0
                },
                {
                    "sent": "Then you can see that no matter what K&C are, since they are finite, there will be a value of N. Beyond which, if N gets larger than that.",
                    "label": 0
                },
                {
                    "sent": "This will always be slower than that.",
                    "label": 0
                },
                {
                    "sent": "Right, I don't know what that end is, but if I worry about optimizing large problems, I just worry about the order of the algorithms because I'll say at some point and will be large enough that the order is all that matters.",
                    "label": 0
                },
                {
                    "sent": "So what we have here for these three methods we can also associate an order with them, the direct methods.",
                    "label": 0
                },
                {
                    "sent": "Our order one to order N where N is the number of dimensions of the problem.",
                    "label": 0
                },
                {
                    "sent": "The function we are minimizing.",
                    "label": 0
                },
                {
                    "sent": "And that means it's the size of this parameter vector, right?",
                    "label": 0
                },
                {
                    "sent": "It's the number of parameters that we're trying to optimize.",
                    "label": 0
                },
                {
                    "sent": "The size of the search space, really.",
                    "label": 0
                },
                {
                    "sent": "And the direct methods typically normally there order in.",
                    "label": 0
                },
                {
                    "sent": "But if you have efficient sort of incremental evaluation methods so that it's very cheap to evaluate.",
                    "label": 0
                },
                {
                    "sent": "A mutation of a solution that you've already evaluated.",
                    "label": 0
                },
                {
                    "sent": "Then you can actually go down to order one.",
                    "label": 0
                },
                {
                    "sent": "So then can get very, very fast.",
                    "label": 0
                },
                {
                    "sent": "But order N is also quite good.",
                    "label": 0
                },
                {
                    "sent": "The 1st Order gradient methods are all generally order North.",
                    "label": 0
                },
                {
                    "sent": "2nd order gradient methods depending on the implementation order N squared to order N ^3.",
                    "label": 0
                },
                {
                    "sent": "I should add that for kernel methods.",
                    "label": 0
                },
                {
                    "sent": "Since you go into this Hilbert space, the N actually winds up including the size of your training set.",
                    "label": 0
                },
                {
                    "sent": "So so those methods actually then can become squared.",
                    "label": 0
                },
                {
                    "sent": "For instance, in the size of the training set.",
                    "label": 0
                },
                {
                    "sent": "But that's that's for me.",
                    "label": 0
                },
                {
                    "sent": "That's sort of already on the implementation side.",
                    "label": 0
                },
                {
                    "sent": "How you do your machine learning, right?",
                    "label": 0
                },
                {
                    "sent": "If I look at the underlying optimization problem, I just used to stand for the dimensionality of the search space and optimizing over.",
                    "label": 0
                },
                {
                    "sent": "And here we see now way why all these different methods are still around be cause for smaller problems.",
                    "label": 0
                },
                {
                    "sent": "Maybe you can afford order N cubed and if you have a well behaved function that you know a lot about, you can calculate the gradient.",
                    "label": 0
                },
                {
                    "sent": "You can calculate the Hessian which is the matrix of 2nd derivatives.",
                    "label": 0
                },
                {
                    "sent": "You can give all this information to an algorithm and get very efficient optimization out of it.",
                    "label": 0
                },
                {
                    "sent": "For larger problems, however, you cannot afford order N ^3.",
                    "label": 0
                },
                {
                    "sent": "It just means you know you take a 1010 times larger problem.",
                    "label": 0
                },
                {
                    "sent": "It takes 1000 times longer to compute.",
                    "label": 0
                },
                {
                    "sent": "It will very quickly get too slow.",
                    "label": 0
                },
                {
                    "sent": "So then you have to fall back on 1st order gradient methods.",
                    "label": 0
                },
                {
                    "sent": "And eventually you have to fall back on direct methods.",
                    "label": 0
                },
                {
                    "sent": "If you have really humongous problems or you have search spaces that you know nothing about.",
                    "label": 0
                },
                {
                    "sent": "Things like combinatorial search spaces, right?",
                    "label": 0
                },
                {
                    "sent": "Where you searching over combinations of Boolean values there is no.",
                    "label": 0
                },
                {
                    "sent": "Rich metric in such spaces as opposed to Euclidean space, where we have, you know we have a triangular inequality and all these things.",
                    "label": 0
                },
                {
                    "sent": "In those Boolean search spaces, things are much harder, so the direct search methods really are shine in those on those problems, because that's the only thing you can use there.",
                    "label": 0
                },
                {
                    "sent": "What I work on.",
                    "label": 0
                },
                {
                    "sent": "Is gradient methods.",
                    "label": 0
                },
                {
                    "sent": "And I in particular work.",
                    "label": 0
                },
                {
                    "sent": "In this area.",
                    "label": 0
                },
                {
                    "sent": "Which is kind of funny, but I'm going to motivate that because generally the evolution of gradient optimization algorithms has been in this direction, right?",
                    "label": 0
                },
                {
                    "sent": "Obviously, you know when you come up and you have to do your PhD thesis, you have to do something nobody's done before, so you know this has been pretty much covered by Gaussian Newton and those guys you know many centuries ago, so you attempt to end up somewhere here and doing horrendously complicated.",
                    "label": 0
                },
                {
                    "sent": "You know high order methods for special cases and this and that and the other, however.",
                    "label": 0
                },
                {
                    "sent": "There's a reason why I believe these high order methods.",
                    "label": 0
                },
                {
                    "sent": "Will actually.",
                    "label": 0
                },
                {
                    "sent": "Become less important in the future in machine learning, not in optimization in general, but in machine learning and why I believe these methods are very, very important.",
                    "label": 0
                },
                {
                    "sent": "And that has to do with the amount of data that we're getting.",
                    "label": 0
                },
                {
                    "sent": "So it's not the dimensionality of the search space, but it's just the number.",
                    "label": 0
                },
                {
                    "sent": "The size of the training set, the number of observations we have.",
                    "label": 0
                },
                {
                    "sent": "That number increases dramatically these days, right?",
                    "label": 0
                },
                {
                    "sent": "I mean with.",
                    "label": 0
                },
                {
                    "sent": "All these new networked webcams and everything we get in huge amounts of data.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that with these huge amounts of data, you get another problem.",
                    "label": 0
                },
                {
                    "sent": "And I will describe that now.",
                    "label": 0
                },
                {
                    "sent": "So this function here that I've written down as.",
                    "label": 0
                },
                {
                    "sent": "As a sort of prototypical loss function, it's actually too simplistic, right?",
                    "label": 0
                },
                {
                    "sent": "I have some data here, but I should really say, well, this is XI.",
                    "label": 0
                },
                {
                    "sent": "This is my observation.",
                    "label": 0
                },
                {
                    "sent": "And what I really want to minimize is the sum.",
                    "label": 0
                },
                {
                    "sent": "From I = 1 to N of these things, right?",
                    "label": 0
                },
                {
                    "sent": "So I have a training set.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll let's not use NI used N for the dimensionality.",
                    "label": 0
                },
                {
                    "sent": "So let me just use L here.",
                    "label": 0
                },
                {
                    "sent": "So I have a training set of size L. And now I want to minimize this function.",
                    "label": 0
                },
                {
                    "sent": "With respect to Theta OK. Now if I use a gradient method to do that, I need the gradient of this function.",
                    "label": 0
                },
                {
                    "sent": "I need the derivative and if you remember your sort of basic calculus, the derivative of a sum is the sum of the derivatives, right?",
                    "label": 0
                },
                {
                    "sent": "So my gradient will actually inherit this structure.",
                    "label": 0
                },
                {
                    "sent": "It will also be a sum from I = 1 to L. Of the derivative.",
                    "label": 0
                },
                {
                    "sent": "Of the.",
                    "label": 0
                },
                {
                    "sent": "Loss on the individual data.",
                    "label": 0
                },
                {
                    "sent": "The problem that we're hitting as L gets large.",
                    "label": 0
                },
                {
                    "sent": "Is that a single measurement of my function and also a single measurement of my gradient requires a loop through the entire training set.",
                    "label": 0
                },
                {
                    "sent": "We have to loop through an, add it all up.",
                    "label": 0
                },
                {
                    "sent": "And this is fine if L is 1000.",
                    "label": 0
                },
                {
                    "sent": "And actually, when I did my PhD 1000 was considered huge.",
                    "label": 0
                },
                {
                    "sent": "I mean, people did training sets of you know 16 examples and if you were ambitious 100.",
                    "label": 0
                },
                {
                    "sent": "Now 1000 is nothing, million is.",
                    "label": 0
                },
                {
                    "sent": "Typical.",
                    "label": 0
                },
                {
                    "sent": "In real applications it can go up to anything.",
                    "label": 0
                },
                {
                    "sent": "I mean it can go up to you know 10 to the 710 to the 8th.",
                    "label": 0
                },
                {
                    "sent": "And now these loops become huge and slow.",
                    "label": 0
                },
                {
                    "sent": "You basically have to go through all your data before you can even take the first step in your optimization procedure.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "If you if your data, for instance is larger than fits in memory in your computer, then you are in trouble.",
                    "label": 0
                },
                {
                    "sent": "So what I'll talk about today.",
                    "label": 0
                },
                {
                    "sent": "Is a trick to speed this up and the trick is simply instead of waiting for all the data before we start the optimization.",
                    "label": 0
                },
                {
                    "sent": "What we'll do is we'll just look at some of the data.",
                    "label": 0
                },
                {
                    "sent": "And that's some of the data that could be like a single data point.",
                    "label": 0
                },
                {
                    "sent": "Or it could be five data points.",
                    "label": 0
                },
                {
                    "sent": "Or it could be 1000 data points.",
                    "label": 0
                },
                {
                    "sent": "That's that's a parameter that I can choose, but I'll only look at some sort of a sense of current observations, right?",
                    "label": 0
                },
                {
                    "sent": "I'll look at the current batch of observations.",
                    "label": 0
                },
                {
                    "sent": "Then I perform an optimization step on that.",
                    "label": 0
                },
                {
                    "sent": "Then I grab some new observations, optimize on that, and I keep going like that.",
                    "label": 0
                },
                {
                    "sent": "This is called stochastic approximation.",
                    "label": 0
                },
                {
                    "sent": "And what So what we're approximating is this function.",
                    "label": 0
                },
                {
                    "sent": "Our true objective.",
                    "label": 0
                },
                {
                    "sent": "And we approximating it stochastically by stochastic.",
                    "label": 0
                },
                {
                    "sent": "Here is meant this subsampling of the data, because when you try to model analytically, what's going on there, the assumption that you make is that your data is sort of IID, it's it's identically independently distributed on your picking.",
                    "label": 0
                },
                {
                    "sent": "Random data in practice.",
                    "label": 0
                },
                {
                    "sent": "Of course, that's not what you do.",
                    "label": 0
                },
                {
                    "sent": "You pick the data that you have at the moment, right?",
                    "label": 0
                },
                {
                    "sent": "So typically say if you have an online learning system where data comes in all the time and you try to adapt to that.",
                    "label": 0
                },
                {
                    "sent": "You don't have the choice of picking your samples IID because you just have to take what's there.",
                    "label": 0
                },
                {
                    "sent": "Nonetheless, that's sort of the label that's been attached to this.",
                    "label": 0
                },
                {
                    "sent": "These techniques why is it an approximation?",
                    "label": 0
                },
                {
                    "sent": "Well, if my parameters theater would be constant.",
                    "label": 0
                },
                {
                    "sent": "Then actually it would be exact, right?",
                    "label": 0
                },
                {
                    "sent": "I could just take Subsamples and if I then go and add up all the subsamples or all the gradients of the subsamples I would get.",
                    "label": 0
                },
                {
                    "sent": "The original function or the original gradient back, but that's not what I'm doing.",
                    "label": 0
                },
                {
                    "sent": "I'm taking a subsample.",
                    "label": 0
                },
                {
                    "sent": "And then I'm doing my optimization and the optimizer changes the parameter vector becausw.",
                    "label": 0
                },
                {
                    "sent": "I'm searching in parameter space.",
                    "label": 0
                },
                {
                    "sent": "So now what I'm adding up overtime is actually slightly inconsistent because it's all these gradient measurements done on different data and slightly different parameter values.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to pretend that overall, that corresponds to some sort of gradient of the entire objective function, and people have done analysis on that and derive conditions under which that works.",
                    "label": 0
                },
                {
                    "sent": "It seems to me that the on each step you recognizing at kind of a different.",
                    "label": 0
                },
                {
                    "sent": "Function so you get some data that you get some fresh and you have thanks to get this close to the meme of this function of this.",
                    "label": 0
                },
                {
                    "sent": "Suddenly you get more data.",
                    "label": 0
                },
                {
                    "sent": "Kind of.",
                    "label": 0
                },
                {
                    "sent": "Get from.",
                    "label": 0
                },
                {
                    "sent": "One is transmitted from nothing to do with what you get from another instance.",
                    "label": 0
                },
                {
                    "sent": "Nothing to do is too strong, but you're very right in pointing out the problem.",
                    "label": 0
                },
                {
                    "sent": "That's exactly the problem and.",
                    "label": 0
                },
                {
                    "sent": "There's The upshot of all of that is that you don't want to do too much optimization on this little sample of data, because yes, it's poor information.",
                    "label": 0
                },
                {
                    "sent": "You only have some of the data, not all of it, and so you don't want to expand a huge effort, for instance, and do like a full, you know Gauss Newton or living Bergmark word or whatever optimization step, because the minimum that you find in that step actually has very little to do with the true minimum is that's true.",
                    "label": 0
                },
                {
                    "sent": "And that's why I'm interested in these kinds of methods, because these are cheaper and less efficient optimization methods.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that if on this small data sample you just do a little step in the right direction.",
                    "label": 0
                },
                {
                    "sent": "And you keep doing that for fresh samples.",
                    "label": 0
                },
                {
                    "sent": "Overtime, if you set this up in the right way, it will actually converge to the right answer.",
                    "label": 0
                },
                {
                    "sent": "So yes, you can't be too overaggressive in optimizing on these small subsamples.",
                    "label": 0
                },
                {
                    "sent": "That's part of the.",
                    "label": 0
                },
                {
                    "sent": "Part of the game here.",
                    "label": 0
                },
                {
                    "sent": "Is nutrition position continue?",
                    "label": 0
                },
                {
                    "sent": "You are using all the data that were accumulated at any given time, so you have data grows.",
                    "label": 0
                },
                {
                    "sent": "There's various scenarios, so.",
                    "label": 0
                },
                {
                    "sent": "One scenario would be what I would call online learning, where the data just keeps coming in, so you never see the same data twice because it's just I don't know you have a video feed, you know you're trying to learn from that as it goes, but there's always fresh images coming, so you never recycle that data.",
                    "label": 0
                },
                {
                    "sent": "That's online learning.",
                    "label": 0
                },
                {
                    "sent": "In that scenario, you actually have to use stochastic approximation because you cannot wait for the end of the training data for the end of this loop, because there is no end, right?",
                    "label": 0
                },
                {
                    "sent": "However, it turns out stochastic approximation algorithms can be very efficient optimizers, and so people use them even when the training set is finite.",
                    "label": 0
                },
                {
                    "sent": "And what you would typically do is you say you have your training set.",
                    "label": 0
                },
                {
                    "sent": "So let's say each of these vectors is 1 observation and they keep coming in, and this is here, you're set, right?",
                    "label": 0
                },
                {
                    "sent": "And let's say, OK, you pick three and you say that's my little mini batch on which I do the first optimization step and then you take the next three, then the next.",
                    "label": 0
                },
                {
                    "sent": "What you would typically do?",
                    "label": 0
                },
                {
                    "sent": "If you have a finite training set and you won't use stochastic approximation, is.",
                    "label": 0
                },
                {
                    "sent": "You would cycle through the training set with these.",
                    "label": 0
                },
                {
                    "sent": "Little batches and when you hit the end you would go back to the beginning and sample again.",
                    "label": 0
                },
                {
                    "sent": "But and here's another little trick that's important here.",
                    "label": 0
                },
                {
                    "sent": "As you rap around, you permute the training data.",
                    "label": 0
                },
                {
                    "sent": "You shuffle it.",
                    "label": 0
                },
                {
                    "sent": "Becaused one problem that you can have with stochastic approximation is if there are a lot of local correlations in your data.",
                    "label": 0
                },
                {
                    "sent": "Then it can lead your optimizer really astray because say all the data over here points in One Direction and all the data over here points in the other direction.",
                    "label": 0
                },
                {
                    "sent": "You'll get these big oscillations and to avoid that you randomly shuffle all your data before you split it up into these little benches.",
                    "label": 0
                },
                {
                    "sent": "So that's typically what you would do.",
                    "label": 0
                },
                {
                    "sent": "I should go back.",
                    "label": 0
                },
                {
                    "sent": "So before I launch into the talk proper, let me just go back and just to make sure everybody has the background talk a little bit about what I mean.",
                    "label": 0
                },
                {
                    "sent": "You know, but repeatedly optimizing and finding a minimum with the gradient method, so I'll just sort of very quickly describe 1st order gradient descent.",
                    "label": 0
                },
                {
                    "sent": "So here we have our function.",
                    "label": 0
                },
                {
                    "sent": "This is our parameter.",
                    "label": 0
                },
                {
                    "sent": "And say we're starting at a value here.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "What we do is we take the gradient which gives us the slope.",
                    "label": 0
                },
                {
                    "sent": "Of the tangent in that point.",
                    "label": 0
                },
                {
                    "sent": "And now the simple 1st order gradient descent update rule would say.",
                    "label": 0
                },
                {
                    "sent": "Theta T + 1 my new parameter values.",
                    "label": 0
                },
                {
                    "sent": "Are the previous ones minus some small constant ETA times the gradient?",
                    "label": 0
                },
                {
                    "sent": "So this is partial F?",
                    "label": 0
                },
                {
                    "sent": "With respect to Theta.",
                    "label": 0
                },
                {
                    "sent": "And this is called gradient descent.",
                    "label": 0
                },
                {
                    "sent": "1st Order simple gradient descent.",
                    "label": 0
                },
                {
                    "sent": "What does this do in this case?",
                    "label": 0
                },
                {
                    "sent": "So here we are at a point Theta.",
                    "label": 0
                },
                {
                    "sent": "The slope here is positive, right?",
                    "label": 0
                },
                {
                    "sent": "We will have a positive gradient here.",
                    "label": 0
                },
                {
                    "sent": "Which means because of the - Here it is a small positive constant.",
                    "label": 0
                },
                {
                    "sent": "I have to add because of the - Here it means we will subtract a little bit from our parameter value, so we will go to the left.",
                    "label": 0
                },
                {
                    "sent": "Pick the next point, right?",
                    "label": 0
                },
                {
                    "sent": "Again, we have the tangent here.",
                    "label": 0
                },
                {
                    "sent": "The slope is steeper now, so actually will subtract more.",
                    "label": 0
                },
                {
                    "sent": "We go here.",
                    "label": 0
                },
                {
                    "sent": "Now we have a more shallow slow.",
                    "label": 0
                },
                {
                    "sent": "So we'll subtract less.",
                    "label": 0
                },
                {
                    "sent": "Now the slope is very very shallow.",
                    "label": 0
                },
                {
                    "sent": "And you can see that because if we land on the other side, the slope will go negative and we'll start adding to the parameter value.",
                    "label": 0
                },
                {
                    "sent": "You'll see that this will converge to the minimum here.",
                    "label": 0
                },
                {
                    "sent": "If we have started out over here.",
                    "label": 0
                },
                {
                    "sent": "We would have started going to the right.",
                    "label": 0
                },
                {
                    "sent": "We would have added to the parameter value until we hit the same minimum.",
                    "label": 0
                },
                {
                    "sent": "Now one point to make here is gradient methods are local optimizers.",
                    "label": 0
                },
                {
                    "sent": "That means if there's another minimum somewhere else, we're not finding it.",
                    "label": 0
                },
                {
                    "sent": "So if that function actually has a better minimum over here.",
                    "label": 0
                },
                {
                    "sent": "If we start here, we'll still go and find that minimum.",
                    "label": 0
                },
                {
                    "sent": "That's a problem that's not addressed by gradient methods.",
                    "label": 0
                },
                {
                    "sent": "If you take like a full course in optimization, there's lots of standard techniques to turn.",
                    "label": 0
                },
                {
                    "sent": "Basically a global optimization problem into a local optimization problem.",
                    "label": 0
                },
                {
                    "sent": "And so you put some machinery on top of this local gradient optimizer and at the top level you have a global optimizer, so this can be done.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to talk about that machinery, right?",
                    "label": 0
                },
                {
                    "sent": "That's sort of the car and I'm talking about the engine.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Keep in mind this is roughly what what's going on.",
                    "label": 0
                },
                {
                    "sent": "And I think we should now be at the point where we can just give the talk the way I normally do it, and this is called rapid stochastic gradient descent accelerating machine learning.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, this is the overview.",
                    "label": 0
                },
                {
                    "sent": "I'll talk a little bit more.",
                    "label": 0
                },
                {
                    "sent": "I've already started on that.",
                    "label": 0
                },
                {
                    "sent": "Why we want stochastic approximation and then I'll talk about my favorite stochastic approximation algorithm, which is my own.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about that at length.",
                    "label": 0
                },
                {
                    "sent": "I'll give you the derivation as some properties in benchmark results and what we're using it for and summarize it.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, this is by way of motivation.",
                    "label": 0
                },
                {
                    "sent": "I've really seen this over the last five years or so.",
                    "label": 0
                },
                {
                    "sent": "It's been extremely explosion of data available for machine learning.",
                    "label": 1
                },
                {
                    "sent": "I mean, it used to be that you had to sort of look for datasets to use, and especially if you wanted to use large datasets, it was actually not easy to get large datasets.",
                    "label": 0
                },
                {
                    "sent": "Now everybody actually is coming and asking if you're a machine learner.",
                    "label": 0
                },
                {
                    "sent": "Everybody is coming.",
                    "label": 0
                },
                {
                    "sent": "I have these huge amounts of data.",
                    "label": 0
                },
                {
                    "sent": "I have no idea what to do with them.",
                    "label": 0
                },
                {
                    "sent": "I don't even have time to look at it once.",
                    "label": 0
                },
                {
                    "sent": "Do something with it, right?",
                    "label": 0
                },
                {
                    "sent": "This is the typical scenario now so.",
                    "label": 0
                },
                {
                    "sent": "One nice example I have is a friend of mine is a whale researcher in the Saint Lawrence in Canada and what she does every summer is she sticks hydrophones into the water and records the whale communication.",
                    "label": 0
                },
                {
                    "sent": "And there's actually very little known.",
                    "label": 0
                },
                {
                    "sent": "Surprisingly little is known about that so.",
                    "label": 0
                },
                {
                    "sent": "What they study is especially the interaction between ships and whales.",
                    "label": 0
                },
                {
                    "sent": "You know, how much do the ships disturb whales and how much does the noise from the ships disturb the whale communication and all that?",
                    "label": 0
                },
                {
                    "sent": "And a couple of years ago she started out and they had one hydrophone and it was recording for like 5 hours.",
                    "label": 0
                },
                {
                    "sent": "And then they had to retrieve it and analyze the data.",
                    "label": 0
                },
                {
                    "sent": "Nowadays she has about on the order of 10 hydrophones.",
                    "label": 0
                },
                {
                    "sent": "They go in in the spring.",
                    "label": 0
                },
                {
                    "sent": "They have a huge hard disk on them.",
                    "label": 0
                },
                {
                    "sent": "They record 24 hours continuously until the fall.",
                    "label": 0
                },
                {
                    "sent": "So now every fall she gets like only order of five years worth of audio recordings.",
                    "label": 0
                },
                {
                    "sent": "And she has three months to analyze them, right?",
                    "label": 0
                },
                {
                    "sent": "So now you know, you really have this situation.",
                    "label": 0
                },
                {
                    "sent": "You cannot even look at the data once.",
                    "label": 0
                },
                {
                    "sent": "And this is a typical situation nowadays, right?",
                    "label": 0
                },
                {
                    "sent": "So you need some fast method to just scan through, throw away the uninteresting portions, and so on.",
                    "label": 0
                },
                {
                    "sent": "And that's of course a machine learning problem because it's hard to tell what's interesting, specially if there's the potential for things that you didn't look for new things.",
                    "label": 0
                },
                {
                    "sent": "There's some species of whale out in the Saint Lawrence where it's not even known if they have localizations and what they are.",
                    "label": 0
                },
                {
                    "sent": "So you know if you throw away too much, you're missing that.",
                    "label": 0
                },
                {
                    "sent": "So this is the typical problem nowadays, and that's really the current problem for machine learning.",
                    "label": 0
                },
                {
                    "sent": "OK, these are some other random examples.",
                    "label": 0
                },
                {
                    "sent": "One pulsar survey at erasable, the huge radio dish right in Costa Rico, produces one terabyte of data a day.",
                    "label": 1
                },
                {
                    "sent": "And that's one survey out of half a dozen that are running concurrently on that dish.",
                    "label": 0
                },
                {
                    "sent": "OK, the Dell website over 100 page requests a second.",
                    "label": 1
                },
                {
                    "sent": "Probably Google would be on two orders of magnitude more than that, but Google doesn't do as much adaptation to a customer's other sites to Amazon is maybe a good example because Amazon actually remembers you and customizes the pages for you, and they probably get on the order of 1000 page requests.",
                    "label": 1
                },
                {
                    "sent": "A second London has over 500,000 security cameras, and again nobody has time to watch all that video.",
                    "label": 0
                },
                {
                    "sent": "So we clear.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We need something to cope with that.",
                    "label": 0
                },
                {
                    "sent": "We need machine learning algorithms, but not just any algorithm.",
                    "label": 0
                },
                {
                    "sent": "We need algorithms that can handle large, complex nonlinear models because the datasets are large, complex and nonlinear and.",
                    "label": 1
                },
                {
                    "sent": "By that I mean up to millions of degrees of freedom, so I'm happily considering problems where N here is on the order of 10,000,000.",
                    "label": 1
                },
                {
                    "sent": "OK, and now this is something 10 years ago that would have been considered insane and it's still a bit out on the link, but it can actually be done.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "We need to be able to deal with large volumes of very low quality data.",
                    "label": 0
                },
                {
                    "sent": "We may have noisy correlated data.",
                    "label": 0
                },
                {
                    "sent": "Nonstationary data, outliers, all kinds of nasty things in there.",
                    "label": 0
                },
                {
                    "sent": "And we need real time online adaptation.",
                    "label": 0
                },
                {
                    "sent": "We want the answers basically as the data rolls in.",
                    "label": 0
                },
                {
                    "sent": "That's the typical scenario nowadays, so we cannot actually sort of.",
                    "label": 0
                },
                {
                    "sent": "Collect the training set.",
                    "label": 0
                },
                {
                    "sent": "You know, clean it up, preprocess it, run the algorithm for a couple days, then publish the result.",
                    "label": 0
                },
                {
                    "sent": "If the mode nowadays is data comes in answers go out and the learning has to happen online in between.",
                    "label": 0
                },
                {
                    "sent": "Now my claim is that.",
                    "label": 0
                },
                {
                    "sent": "A lot of the current machine learning techniques have difficulty with that.",
                    "label": 1
                },
                {
                    "sent": "Or I should maybe say the current optimization techniques tend to have difficulty with that.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here's the problem.",
                    "label": 0
                },
                {
                    "sent": "So a classical optimizer.",
                    "label": 0
                },
                {
                    "sent": "Is this iterative process right?",
                    "label": 0
                },
                {
                    "sent": "You loop over and at each iteration in the loop you take a function and gradient measurement.",
                    "label": 0
                },
                {
                    "sent": "And that measurement consists also of a loop.",
                    "label": 0
                },
                {
                    "sent": "Namely, overall your data.",
                    "label": 0
                },
                {
                    "sent": "So you have two nested loops and if your data set gets big, this becomes very, very slow.",
                    "label": 1
                },
                {
                    "sent": "What you need is online learning here.",
                    "label": 0
                },
                {
                    "sent": "So you need to use stochastic approximation so that you're interleaving your optimizer with a sampling of the training data, and it all happens in a single loop, right?",
                    "label": 1
                },
                {
                    "sent": "Now this is also the scenario that people in signal processing.",
                    "label": 0
                },
                {
                    "sent": "You know adaptive filtering and so on consider.",
                    "label": 0
                },
                {
                    "sent": "So as far as I'm concerned, these are all near synonyms, adaptive control, adaptive signal processing, filtering, stochastic approximation, online learning.",
                    "label": 1
                },
                {
                    "sent": "These are all people from different backgrounds talking about more or less the same thing, but bringing different tools and techniques to the enterprise.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, here's a little bit what I've already elaborated.",
                    "label": 0
                },
                {
                    "sent": "What I've thrown on the whiteboard, right?",
                    "label": 0
                },
                {
                    "sent": "You want to typically minimize with respect to some parameter vector Theta.",
                    "label": 0
                },
                {
                    "sent": "Now this is the.",
                    "label": 0
                },
                {
                    "sent": "A scenario where I'm making a statistical assumption, I'm talking about the expectation over the data of some loss function that is defined over the data, right?",
                    "label": 0
                },
                {
                    "sent": "So this is actually the true risk, and we approximate that by the empirical risk where we have some sort of training set from which we sample the data and we average over the training set.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is.",
                    "label": 0
                },
                {
                    "sent": "Probably burnout has covered this pretty well, so this is sort of the classical setup in machine learning, but it contains this loop over the training set.",
                    "label": 0
                },
                {
                    "sent": "And for large sets of data, that loop is inefficient.",
                    "label": 0
                },
                {
                    "sent": "An if your data never ends, then or, it's nonstationary.",
                    "label": 0
                },
                {
                    "sent": "So as you go through the data that the underlying statistics of the data change on you.",
                    "label": 0
                },
                {
                    "sent": "Right then this becomes an inappropriate formalism.",
                    "label": 0
                },
                {
                    "sent": "So what we really need to do is stochastic approximation whereby we just take the loss on the current data and the current value of these parameters.",
                    "label": 0
                },
                {
                    "sent": "And we do some quick and dirty optimization over that to get the next set of parameter values.",
                    "label": 0
                },
                {
                    "sent": "And then we iterate that so the next batch of data is going to be evaluated on the fresh parameters.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "So these are, I gather some of these equations are missing on the slides.",
                    "label": 0
                },
                {
                    "sent": "I apologize that's a font problem, so if you want I'll leave those slides on a little bit longer if you want to enter them.",
                    "label": 0
                },
                {
                    "sent": "This one is fine.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "On the other ones, don't start writing too early because I have animated equations, so they're going to change on you, so I'll tell you when the last version is up and you can start writing OK.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "We come to the key problem.",
                    "label": 0
                },
                {
                    "sent": "Up sorry you were not done.",
                    "label": 0
                },
                {
                    "sent": "OK let's.",
                    "label": 0
                },
                {
                    "sent": "Go.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Let me do that.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "The key problem is that people for.",
                    "label": 0
                },
                {
                    "sent": "Centuries really have developed these fancy optimization methods, so this first order gradient descent.",
                    "label": 0
                },
                {
                    "sent": "I should say that I explained to you right, this is sort of.",
                    "label": 0
                },
                {
                    "sent": "Very, very low level, right?",
                    "label": 0
                },
                {
                    "sent": "It's almost as bad as evolutionary algorithms if you talk to anybody in a math Department that does optimization, they're going to laugh at you if you come with that, right?",
                    "label": 0
                },
                {
                    "sent": "What everybody does is, you know, 2nd order with lots of bells and whistles, and this, that, and the other machinery on top right?",
                    "label": 0
                },
                {
                    "sent": "Really heavy, heavy duty hardcore stuff.",
                    "label": 0
                },
                {
                    "sent": "So actually hundreds of years of mathematical expertise have gone into pushing things in this direction.",
                    "label": 0
                },
                {
                    "sent": "No more and more complex machinery to be more and more efficient at solving these problems.",
                    "label": 0
                },
                {
                    "sent": "Now, the key problem that we're getting here now, so everybody done.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Using either at time step T is the initial condition for your.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the idea is that at time T will take the parameter values at that time and the current data, and we're going to change the parameter values based on that.",
                    "label": 0
                },
                {
                    "sent": "If we're going to do a little optimization step and then we take those new values and at the next time step.",
                    "label": 0
                },
                {
                    "sent": "We're going to measure the gradient, for instance on the new data using those new values at that new point already.",
                    "label": 0
                },
                {
                    "sent": "So we're taking the measurements always at the current point.",
                    "label": 0
                },
                {
                    "sent": "So if our optimizer hops around, those measurements will also help around.",
                    "label": 0
                },
                {
                    "sent": "That's that's what that's why.",
                    "label": 0
                },
                {
                    "sent": "It's sort of an approximation.",
                    "label": 0
                },
                {
                    "sent": "That's why it's not not an exact thing to do this.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "So here's a here's a little picture of the hierarchy of optimization algorithms, right?",
                    "label": 0
                },
                {
                    "sent": "So at the bottom you have evolutionary algorithms, which is really what all the amateurs do that don't know anything about.",
                    "label": 0
                },
                {
                    "sent": "Optimization, right one level up is what I'm doing, and then the real algorithms are all up here, right?",
                    "label": 0
                },
                {
                    "sent": "And the two axis here that I've plotted the order of the algorithm in terms of the dimensionality of the search space.",
                    "label": 0
                },
                {
                    "sent": "So this is order one or the N order in squared order in cube.",
                    "label": 0
                },
                {
                    "sent": "So it gets more and more expensive as you go out to the right.",
                    "label": 0
                },
                {
                    "sent": "And on the other axis is the convergence speed.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of the inverse of how many iterations you have to run your optimizer for until you get a good solution.",
                    "label": 0
                },
                {
                    "sent": "Evolutionary algorithms you have to run forever gradient descent slightly less than forever, and here they start getting really fast.",
                    "label": 0
                },
                {
                    "sent": "Now the problem is when you do stochastic approximation, which I've said you need when you deal with a large data set, because otherwise even the first iteration takes too long.",
                    "label": 0
                },
                {
                    "sent": "You cannot wait for even just one pass through the data.",
                    "label": 0
                },
                {
                    "sent": "If you use stochastic approximation.",
                    "label": 1
                },
                {
                    "sent": "That approximation unfortunately screws up all this advanced machinery up here.",
                    "label": 0
                },
                {
                    "sent": "So actually what happens is?",
                    "label": 0
                },
                {
                    "sent": "When you go online, you're just left with that.",
                    "label": 0
                },
                {
                    "sent": "Conjugate gradients are completely hopeless with stochastic approximation.",
                    "label": 0
                },
                {
                    "sent": "Never tried to do that, it's just.",
                    "label": 0
                },
                {
                    "sent": "It can't work.",
                    "label": 0
                },
                {
                    "sent": "The other algorithms, typically what happens is they're too expensive, so levenberg Marquardt for instance is order N ^3.",
                    "label": 0
                },
                {
                    "sent": "You don't want to run an order in cubed algorithm on so little evidence, right?",
                    "label": 0
                },
                {
                    "sent": "You just have sort of a little batch of current data and you don't really want to do this.",
                    "label": 0
                },
                {
                    "sent": "Bring this heavy machinery to bear on this data because the minimum that you'll find will be a different one every time.",
                    "label": 0
                },
                {
                    "sent": "Depending on which data you happen to have an, it's very costly.",
                    "label": 0
                },
                {
                    "sent": "It's very expensive, so those algorithms pretty much are out of the question.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                },
                {
                    "sent": "What we're left with is basically those simple methods, and then things like common filtering.",
                    "label": 0
                },
                {
                    "sent": "I use it as a generic term for these sort of 2nd order online maximum likelihood methods from signal processing.",
                    "label": 0
                },
                {
                    "sent": "Those work they explicitly incorporate a model of the stochastic nature of the data.",
                    "label": 0
                },
                {
                    "sent": "But they typically make strong assumptions about what the nature of the data is.",
                    "label": 0
                },
                {
                    "sent": "So if your actual data violates these assumptions, they don't work anymore.",
                    "label": 0
                },
                {
                    "sent": "So if you have a good knowledge of how your data looks like, this may be the way to go.",
                    "label": 0
                },
                {
                    "sent": "However, these things are order N squared, and so if your end gets big, if your parameter space gets gets very large, then you can't use that either.",
                    "label": 0
                },
                {
                    "sent": "And so then you just left with those two.",
                    "label": 0
                },
                {
                    "sent": "And now I finally explained why I do the research I'm doing cause.",
                    "label": 0
                },
                {
                    "sent": "If you set it up just right, if you set up your problem just right, then this is the best thing on Earth.",
                    "label": 0
                },
                {
                    "sent": "And what I'm working on is trying to make this converge faster.",
                    "label": 1
                },
                {
                    "sent": "So one key problem that you have with first order simple gradient descent is that it can be very, very slow.",
                    "label": 1
                },
                {
                    "sent": "It can take many iterations to converge.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Actually, I think I have that picture later.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I'll show you later why exactly?",
                    "label": 0
                },
                {
                    "sent": "So what I'm working on is it's methods to speed that up.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, here this is actually the same thing in words.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Particular conjugate directions breakdown, so this is the reason there's a technical reason why conjugate gradient methods don't work with stochastic approximation.",
                    "label": 1
                },
                {
                    "sent": "The other ones are just simply too expensive.",
                    "label": 0
                },
                {
                    "sent": "This leaves evolutionary algorithms very inefficient and simple gradient descent slightly less inefficient, I would say.",
                    "label": 1
                },
                {
                    "sent": "OK, now.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let's go into techniques for speeding up gradient descent.",
                    "label": 0
                },
                {
                    "sent": "Alright, so on this one.",
                    "label": 0
                },
                {
                    "sent": "This you can copy already.",
                    "label": 0
                },
                {
                    "sent": "So here's I just set up the notation.",
                    "label": 0
                },
                {
                    "sent": "I'll I'll call the gradient at time T GT.",
                    "label": 0
                },
                {
                    "sent": "And what I mean by that is it's the gradient of the loss.",
                    "label": 0
                },
                {
                    "sent": "On the current parameter values and the current data.",
                    "label": 0
                },
                {
                    "sent": "So this is a stochastic quantity even at the same point in parameter space.",
                    "label": 0
                },
                {
                    "sent": "If I pick some fresh data, I would get a different answer.",
                    "label": 0
                },
                {
                    "sent": "OK, think of it as a stochastic function.",
                    "label": 0
                },
                {
                    "sent": "A non deterministic function.",
                    "label": 0
                },
                {
                    "sent": "It gives me a different answer every time.",
                    "label": 0
                },
                {
                    "sent": "But somehow overtime these answers all average out right?",
                    "label": 0
                },
                {
                    "sent": "Because if you average all these answers and you keep the parameters fixed, then in the limit.",
                    "label": 0
                },
                {
                    "sent": "By the by the Central limit theorem of statistics you will actually get the true gradient on the entire data.",
                    "label": 0
                },
                {
                    "sent": "But we'll never actually do that because we'll keep changing the parameters.",
                    "label": 0
                },
                {
                    "sent": "So now we do a first order gradient descent.",
                    "label": 1
                },
                {
                    "sent": "New parameters are the old ones minus some step size.",
                    "label": 0
                },
                {
                    "sent": "Some gain times the gradient.",
                    "label": 0
                },
                {
                    "sent": "And the first thing that I'll do that's non standard is I'll make this gain A to a vector.",
                    "label": 0
                },
                {
                    "sent": "And I'll use here as I'll use this central little dot to stand for Hadamard multiplication or it's elementwise multiplication OK?",
                    "label": 0
                },
                {
                    "sent": "So it just means every element of the Zeta vector is multiplied with the corresponding element of the gradient.",
                    "label": 0
                },
                {
                    "sent": "So this means I can set the gain differently for each direction in parameter space for each dimension in parameter space.",
                    "label": 0
                },
                {
                    "sent": "Now what do we do with these gains?",
                    "label": 0
                },
                {
                    "sent": "The key idea is that.",
                    "label": 1
                },
                {
                    "sent": "Instead of setting them explicitly, which is what many standard gradient methods require.",
                    "label": 0
                },
                {
                    "sent": "What we can do is we can learn the gains from the data as we go along and we learn them at the same time while we're learning the parameters.",
                    "label": 0
                },
                {
                    "sent": "And the trick is the following we.",
                    "label": 0
                },
                {
                    "sent": "We will adapt the gains.",
                    "label": 0
                },
                {
                    "sent": "But actually will go into lock space, will take the log pointwise elementwise of the gains.",
                    "label": 0
                },
                {
                    "sent": "And when we then do a gradient descent in the log games.",
                    "label": 0
                },
                {
                    "sent": "So the new log gains are the old ones, minus this is a meta gain.",
                    "label": 0
                },
                {
                    "sent": "This is the step size for the step sizes.",
                    "label": 0
                },
                {
                    "sent": "Times.",
                    "label": 0
                },
                {
                    "sent": "The gradient with respect to the log gain of the same objective function that we have up here.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that just like we are learning the parameters that minimize the function will also learn the step sizes that most efficiently minimize the function.",
                    "label": 0
                },
                {
                    "sent": "And the neat thing is we can actually do this and we can do it at the same time.",
                    "label": 0
                },
                {
                    "sent": "Now, why do we go to the to the lock space?",
                    "label": 0
                },
                {
                    "sent": "I've told you that the gains have to be positive, right?",
                    "label": 0
                },
                {
                    "sent": "And they can also range over long many orders of magnitude.",
                    "label": 0
                },
                {
                    "sent": "So in a practical application you may set again to like 10 to the minus 6.",
                    "label": 0
                },
                {
                    "sent": "Or to 10 to the minus two or to one.",
                    "label": 0
                },
                {
                    "sent": "So you have this scaling over many orders of magnitude.",
                    "label": 0
                },
                {
                    "sent": "And the values are not allowed to go negative.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "How do we ensure that in a gradient descent scenario it's actually hard to do because gradient descent takes these finite steps and so if the gradient indicates we should go towards 0?",
                    "label": 0
                },
                {
                    "sent": "And because the correct value is maybe 10 to the minus six, it's very easy to step too far and landed a negative value and then suddenly instead of minimizing, we would be maximizing, right?",
                    "label": 0
                },
                {
                    "sent": "So it would completely blow up the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the trick is by.",
                    "label": 0
                },
                {
                    "sent": "Performing gradient dissent in the log gains.",
                    "label": 0
                },
                {
                    "sent": "So just think of this as a variable name, right?",
                    "label": 0
                },
                {
                    "sent": "So not a variable that happens to be the log of the haters.",
                    "label": 0
                },
                {
                    "sent": "We can allow negative values.",
                    "label": 0
                },
                {
                    "sent": "Alright, so now the values can go anywhere in our end.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "To get the gain back will exponentiate those values.",
                    "label": 0
                },
                {
                    "sent": "And that will give us first of all strictly positive values and they will nicely scale geometrically, so we can actually ramp them up and down by orders of magnitude without problems.",
                    "label": 1
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Huh, that is a free parameter so you have to set it by trial and error.",
                    "label": 0
                },
                {
                    "sent": "It's not hard to tune.",
                    "label": 0
                },
                {
                    "sent": "It typically winds up being something like 0.1, but.",
                    "label": 0
                },
                {
                    "sent": "It's a magic number.",
                    "label": 0
                },
                {
                    "sent": "Yes, an this is a good point and this is something I have to convince you yet off that all this machinery actually helps you, right?",
                    "label": 0
                },
                {
                    "sent": "Because in first order gradient descent you have this ETA this game that you have to set an it's a magic number.",
                    "label": 0
                },
                {
                    "sent": "You have to just try out what works.",
                    "label": 0
                },
                {
                    "sent": "And here I have the same magic number, just one level down.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It's not clear upfront that this actually gives you anything.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now we adapt the logins by.",
                    "label": 0
                },
                {
                    "sent": "Gradient descent.",
                    "label": 0
                },
                {
                    "sent": "So, OK, I've said that already.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "What you then do is you can exponentiate both sides of this equation.",
                    "label": 0
                },
                {
                    "sent": "Here you just get the game back.",
                    "label": 0
                },
                {
                    "sent": "And here you know, the addition here turns into a multiplication and you have to exponentiate this part.",
                    "label": 0
                },
                {
                    "sent": "The other thing I've done here is I've used the chain rule for gradients to split this gradient up into the gradient of the loss with respect to the parameters.",
                    "label": 0
                },
                {
                    "sent": "Times the gradient of the parameters with respect to the log gain.",
                    "label": 0
                },
                {
                    "sent": "OK, just just straightforward chain rule of different station.",
                    "label": 0
                },
                {
                    "sent": "Now this part here is obviously.",
                    "label": 0
                },
                {
                    "sent": "Just the standard gradient, so that's exactly what I've called GT up here, right?",
                    "label": 0
                },
                {
                    "sent": "So will get GT times something else.",
                    "label": 0
                },
                {
                    "sent": "And I'll just call that something else, Viti.",
                    "label": 0
                },
                {
                    "sent": "Just as a definition.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "I'll do so.",
                    "label": 0
                },
                {
                    "sent": "This is just Vt. OK, this is ready to be copied.",
                    "label": 0
                },
                {
                    "sent": "The other thing I've done here is I've approximated the exponential function here and the reason for that is this is in the innermost loop of our machine learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "And this exponential function.",
                    "label": 0
                },
                {
                    "sent": "Actually, if we have a system with a million parameters and we're going through thousand data points a second.",
                    "label": 0
                },
                {
                    "sent": "It means that we will have 1 billion exponentiations per second.",
                    "label": 0
                },
                {
                    "sent": "In our algorithm, and this is actually a very slow function to compute, so you will find that you actually spend 90% of your computation in the exponential function.",
                    "label": 0
                },
                {
                    "sent": "So what I've done is a really really hairy approximation.",
                    "label": 0
                },
                {
                    "sent": "Basically, I'm pretending that.",
                    "label": 0
                },
                {
                    "sent": "E to EU.",
                    "label": 0
                },
                {
                    "sent": "Is approximately the Max of 1/2 and 1 + U. OK, so.",
                    "label": 0
                },
                {
                    "sent": "E to EU looks like this.",
                    "label": 0
                },
                {
                    "sent": "1 + U.",
                    "label": 0
                },
                {
                    "sent": "Is the tangent in the origin?",
                    "label": 0
                },
                {
                    "sent": "It looks like this and I cut it at 1/2.",
                    "label": 0
                },
                {
                    "sent": "I go flat.",
                    "label": 0
                },
                {
                    "sent": "So by linear approximation, it's really atrocious.",
                    "label": 0
                },
                {
                    "sent": "But all that matters to me is near the origin.",
                    "label": 0
                },
                {
                    "sent": "It matches the exponential in the in the value and in the slope in the first derivative.",
                    "label": 0
                },
                {
                    "sent": "And that's all I need because my mu.",
                    "label": 0
                },
                {
                    "sent": "The meta step size will be relatively small.",
                    "label": 0
                },
                {
                    "sent": "And so all these terms that I'm exponentiating will be near 0 here.",
                    "label": 0
                },
                {
                    "sent": "And in fact.",
                    "label": 0
                },
                {
                    "sent": "This approximation deliberately.",
                    "label": 0
                },
                {
                    "sent": "It is done this way in order to make the algorithm robust to outliers.",
                    "label": 0
                },
                {
                    "sent": "Because the other problem with an exponentiation in your algorithm is if you get an outlier.",
                    "label": 0
                },
                {
                    "sent": "And what you're exponentiating happens to be 50, which doesn't sound too bad.",
                    "label": 0
                },
                {
                    "sent": "Well, E, to the 50 is very bad.",
                    "label": 0
                },
                {
                    "sent": "It's a huge number.",
                    "label": 0
                },
                {
                    "sent": "So what this does is it dampens very large positive values down.",
                    "label": 0
                },
                {
                    "sent": "And elevates very small, very negative values.",
                    "label": 0
                },
                {
                    "sent": "Very small values basically to 1/2, so it makes the algorithm more conservative.",
                    "label": 0
                },
                {
                    "sent": "While near 0, it still preserves the properties so.",
                    "label": 0
                },
                {
                    "sent": "This is a completely ad hoc, but this is what works in practice in this algorithm.",
                    "label": 0
                },
                {
                    "sent": "Now what I haven't told you yet.",
                    "label": 0
                },
                {
                    "sent": "Is what this sweetie?",
                    "label": 0
                },
                {
                    "sent": "Exactly is, I've just written here very glibly the partial of.",
                    "label": 0
                },
                {
                    "sent": "The current parameter Theta T with respect to log data, but note that I've cunningly left out anytime index here, log it, or what you know is it a T?",
                    "label": 0
                },
                {
                    "sent": "Is it a?",
                    "label": 0
                },
                {
                    "sent": "T -- 1 whatever so.",
                    "label": 0
                },
                {
                    "sent": "We'll now talk about exactly what we mean by this, and this will actually be a crucial piece of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What people have done before is they've defined V T + 1.",
                    "label": 0
                },
                {
                    "sent": "To be the partial of Theta T plus one with respect to log data T. Note that there's like a one time step difference here.",
                    "label": 0
                },
                {
                    "sent": "You need to change.",
                    "label": 0
                },
                {
                    "sent": "OK. Quick break while we change.",
                    "label": 0
                },
                {
                    "sent": "Should be some hold.",
                    "label": 0
                },
                {
                    "sent": "Something annoying.",
                    "label": 0
                },
                {
                    "sent": "So conventionally people have defined the V parameter to be this.",
                    "label": 0
                },
                {
                    "sent": "And the reason to define it that way, it's just that you get a simple answer for what we should be, because if you recall data, T + 1 is better T -- 8010 GP.",
                    "label": 0
                },
                {
                    "sent": "So this partial you can read off directly from here, right?",
                    "label": 0
                },
                {
                    "sent": "The partial of Theta T plus one with respect to 8 P would just be minus GT.",
                    "label": 0
                },
                {
                    "sent": "And now, since we're taking the partial with respect to log into peanut 8:30, we will pick up an additional 830.",
                    "label": 0
                },
                {
                    "sent": "That basically is because the derivative of the log of X is 1 / X.",
                    "label": 0
                },
                {
                    "sent": "And so if we're taking a partial with respect to that, we'll have to multiply by 1 /, 1 / X.",
                    "label": 0
                },
                {
                    "sent": "Next, in this case, being that.",
                    "label": 0
                },
                {
                    "sent": "So this derivative is very easy to take and gives you this simple answer.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        }
    }
}