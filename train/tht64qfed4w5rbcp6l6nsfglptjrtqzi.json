{
    "id": "tht64qfed4w5rbcp6l6nsfglptjrtqzi",
    "title": "BGP-lens: Patterns and Anomalies in Internet Routing Updates",
    "info": {
        "author": [
            "B. Aditya Prakash, Department of Computer Science, Virginia Polytechnic Institute and State University"
        ],
        "published": "Sept. 14, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Data Mining->Anomaly Detection"
        ]
    },
    "url": "http://videolectures.net/kdd09_prakash_bgplpairu/",
    "segmentation": [
        [
            "Hi everyone, I'm out there and today I'll be talking about BGP lens which is joint work with Nicholas Dave Nicholson Crystals between CMU and UC Riverside."
        ],
        [
            "So, uh, this talk deals with broader broader gateway protocol, which is, in other words, BGP.",
            "It's an Internet routing protocol in which routers are sending messages to each other.",
            "The message is basically consists of path information and this helps in keeping the path information up today.",
            "So conceptually it can be represented as a database, where with many different columns which correspond to the fields in the update packets.",
            "So for example, an each row is basically an update, so the originators in this example depends.",
            "Depicts the origin autonomous system for the update and prefix depends the depicts the path.",
            "So in an ideal setting, you wouldn't expect any BGP updates in the network, but what happens is that there are a millions of updates flowing through because of link failures, router restarts, malicious behavior, and so."
        ],
        [
            "So a basic question which can be asked is, are there any inherent patterns or anomalies in such a database?",
            "The key challenges for this problem would be that the large size of the database, the data, Moreover, the data also has multiple dimensions like you can look and group by the prefixes which is being passed or the originators and so on.",
            "They're noisy measurements.",
            "There may be missing values, in fact an it's basically impossible for a human to sift through these updates, so an automated tool is needed for such a task.",
            "So the data which we have in this paper is basically from the data positive or a net website.",
            "It collects data from the billing research network, which is a collection of Leuven."
        ],
        [
            "Voters all across the US.",
            "So for example, Seattle, Los Angeles, Kansas City, etc.",
            "And we have almost 18,000,000 update messages or spread over a period of two years.",
            "That's that gives us enough scope for actually figuring out real anomalies and patterns."
        ],
        [
            "So our approach is basically this.",
            "So we look at a simple time series from the database.",
            "So we suggest that just focus on just the timestamp so we have a list of timestamps which we gather from the repository, and we been the number of updates received every be seconds.",
            "So what this means is that if you have the time axis which is depicted by the black line and you have black squares, is consisting of the updates before every B seconds, you count the number of updates in that bin and bucketized them.",
            "So in a sense you get the bin Zero bin one bin two and the count is below.",
            "So if you do all this and you get a time series which is depicted on the right.",
            "So, given such a time series, the specific problem we are ultimately tackling is reporting patterns and anomalies on them and also using some auxiliary fields which we had in the original database.",
            "You can find some suspicious entities for society."
        ],
        [
            "It's.",
            "So how does the data look like?",
            "So we plotted the extractor time series for the Washington router with the bin size of 600 seconds.",
            "That's 10 minutes, so the number of updates and the bin number is on the X axis, so the one of the 1st way easy things to see is that it's very bursty.",
            "Their huge spikes there, small spikes, and everything is basically being washed out due to that one anomaly at 2 into 4 bin.",
            "So what makes is that the traditional tools like 15 autoregression don't really work here because of the spikes align you you will get a high score without, which is pretty much meaningless."
        ],
        [
            "So that was basically the outline and the problem introduction.",
            "So right now I go into temporal analysis, which is one of."
        ],
        [
            "Techniques which we applied so the first cut is because the linear linear plot is not really very helpful.",
            "We took a log linear plot which emphasizes small values over high ones.",
            "So for example, this is a log linear plot for a bin size of 10 seconds.",
            "So as you can see that there are a lot of just a second.",
            "Yeah there are a lot of missing values in the system which was not really observed and assignments didn't even know about this, so this just emphasizes that how noisy the data is."
        ],
        [
            "It is.",
            "So, but the key thing here is the bin size is very."
        ],
        [
            "Important, so if you take the same plot for a bin size of 600 seconds, you can see some interesting things.",
            "So for example, there are two really denoted two really important observations which are denoted by the red lines.",
            "So these look like near constant number of updates for a long period of time, and because they look like hanging bed sheets, we term them as close lines."
        ],
        [
            "So why are clotheslines important?",
            "So they represent.",
            "As I said, near consecutive updates over a long period of time and they can be attributed to route route flap dampening in the system.",
            "So what it means is that you're advertising and withdrawing the same path repeatedly, and it points to an inefficiency in the system, so it's a very important phenomenon to identify.",
            "So how do we automate this discovery?"
        ],
        [
            "So what we propose is take the probability distribution function of the volume of updates, that is, the number of times with the given volume.",
            "So so if you look at this plot which is for the same plot for a bin size of 600 seconds, the two points which are denoted by the red lines are look anomalous.",
            "So in a sense you would expect these points.",
            "These volume of updates to be very frequent in the real time series.",
            "So in other words, the extreme should be equal to the height of the clothesline."
        ],
        [
            "To understand this better, let's just rotate the plot a little so that the Y axis now corresponds to the number of updates, and we bring the clothesline plot, which is just the time log in the log linear dimension with on the right hand side.",
            "So if you look closely, the first enormous point actually corresponds to one of the clothesline which we had seen earlier, and similar for the second case.",
            "So what I've given here is a simple example of how exactly we can discover such close lines, so you can go ahead and even formalize this intuition and.",
            "So the basic idea in the algorithm is that you have to use some kind of approach to find out these red points.",
            "As noted in the left.",
            "So we use a median filtering approach where you have a moving window to determine these outliers and for each time interval we find in the time series plot you report the most persistent aces or the IP's which are more likely to be the suspicious."
        ],
        [
            "Once.",
            "So."
        ],
        [
            "Just a high level idea.",
            "The details are in the paper, so next we move on to frequency analysis.",
            "So the key thing is that things like 50.",
            "So for example, given a time series, one of the basic things people say it's just plotted.",
            "So we did 50 and even leaner linear plot.",
            "As you can see there 50 doesn't really give me much information.",
            "We also found that the data was actually self similar by self similarity mean that the data looked similar as several scales.",
            "We perform many statistical."
        ],
        [
            "Yes, for this.",
            "So what we propose is use a multi resolution technique like wavelets for this.",
            "So this is like a small crash course in wavelets as in.",
            "So instead of giving the mathematical equations we so I've given a simple artificial time series on the bottom and the corresponding kilogram on the top.",
            "This kilogram is plots, basically the absolute values of the wavelet coefficients overtime.",
            "So the Y axis represents the scales, so the lower frequencies are on the top and the higher frequencies are on the bottom that is fast moving cycles on the bottom and lower.",
            "Long short cycle long cycles on the top, so if you see the highest and the darker color darker colors represent high energy, whereas the lower energy is represented by lighter colors.",
            "So if you see the huge spike corresponds to high energy overall coefficients, that is, you can see we term it as a tornado.",
            "So you can see a tornado touching down similar case for the short spike just with a lower energy.",
            "But for a prolonged spike, which is like a short burst of traffic for a short period of time, you can see that there's a tornado, but it doesn't touchdown, so this is the key motivation of actually going ahead and.",
            "For."
        ],
        [
            "Realizing this intuition, so we did the same thing for a real for the real signal which we have seen before.",
            "So the real signal is on the bottom, so you can see the long spike corresponds to a tornado which touched down and the E2, which is the main tornado, which doesn't touchdown.",
            "It actually corresponds to prolong Spike on the real signal."
        ],
        [
            "Just magnify the ellipse E2, which is which is being shown on this slide.",
            "You can see that it corresponds to about 20,000 updates or period of eight hours on January 6th for, so this was completely invisible in the real data.",
            "But you can look at it up with the scale."
        ],
        [
            "Blood.",
            "So again, why exactly prolonged spikes?",
            "So these represent both of short duration, which can represent malicious behavior like IP space hijacking etc.",
            "Or even simple phenomena like router restarts.",
            "Somebody just shut down the route and restarted it and he has to update the whole table.",
            "So the exact cause itself is very hard to find an answer an open problem, but it's very important for assignments to actually detect these."
        ],
        [
            "So that they can take corrective action so the algorithm is essentially finding tornadoes from this kaligram plot.",
            "That is these... so you find suitable points at higher levels and then extend downward as much as possible to the finer scale where a tornado would stop and the shortest time period where you stop is like the finest scale.",
            "So it is the shortest time period for which you can look at approx pipe, so."
        ],
        [
            "Again, the details are in this paper.",
            "We also did so if you look look at the two techniques which I presented.",
            "Both are very linear in the number of time ticks, and we ended a scalability analysis and it's linear so."
        ],
        [
            "He's happy.",
            "And then the next thing is, uh, we also built, went ahead and built a tool for sysadmins, which is.",
            "This is the basic user interface.",
            "So note that we don't really need any input from the user.",
            "We have a reasonable defaults, but we also provide some easy to use knobs for expert users, which are optional, so the two knobs are basically sensitivity and duration.",
            "The sensitivity deals with the number of suspicious, even as admin wants to check, whereas the duration is the length of the events you want to check, like monthly versus Weekly or.",
            "Yearly."
        ],
        [
            "So next we actually deal into some case study."
        ],
        [
            "But we used we form some real events like for example the 50 close line which I showed before or do not have the red line.",
            "So when we went ahead and did analyze the prefixes and the origin is it pointed to an Alabama Social supercomputer network.",
            "When we contacted sysadmins they attributed the anomaly to route flap dampening of some particular prefix, so it's surprising that anomaly such as this went undetected and resolve for almost."
        ],
        [
            "Month so the other interesting phenomena which found was a prolonged spike on May May 12th.",
            "So this was the... to which we magnified again.",
            "So it was an 8 hour spike and the most persistent IPS and aces pointed to some primary schools and middle schools.",
            "So it's surprising that middle schoolers has such an intense burst of traffic for a short period of time.",
            "So we also find several other."
        ],
        [
            "Such events.",
            "So just to wrap up, we started huge real data on comprising over two years.",
            "We developed 2 new techniques which are effective in spotting subtle phenomena like clothesline and prolong spikes.",
            "They're scalable, their linear and we also developed a user friendly tool which provides reasonable defaults, easy to use knobs and even very useful leads like IPS analysis to the."
        ],
        [
            "Thanks a lot and that's my opinion.",
            "Here are the culprits."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everyone, I'm out there and today I'll be talking about BGP lens which is joint work with Nicholas Dave Nicholson Crystals between CMU and UC Riverside.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, uh, this talk deals with broader broader gateway protocol, which is, in other words, BGP.",
                    "label": 0
                },
                {
                    "sent": "It's an Internet routing protocol in which routers are sending messages to each other.",
                    "label": 1
                },
                {
                    "sent": "The message is basically consists of path information and this helps in keeping the path information up today.",
                    "label": 0
                },
                {
                    "sent": "So conceptually it can be represented as a database, where with many different columns which correspond to the fields in the update packets.",
                    "label": 1
                },
                {
                    "sent": "So for example, an each row is basically an update, so the originators in this example depends.",
                    "label": 0
                },
                {
                    "sent": "Depicts the origin autonomous system for the update and prefix depends the depicts the path.",
                    "label": 1
                },
                {
                    "sent": "So in an ideal setting, you wouldn't expect any BGP updates in the network, but what happens is that there are a millions of updates flowing through because of link failures, router restarts, malicious behavior, and so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a basic question which can be asked is, are there any inherent patterns or anomalies in such a database?",
                    "label": 0
                },
                {
                    "sent": "The key challenges for this problem would be that the large size of the database, the data, Moreover, the data also has multiple dimensions like you can look and group by the prefixes which is being passed or the originators and so on.",
                    "label": 0
                },
                {
                    "sent": "They're noisy measurements.",
                    "label": 0
                },
                {
                    "sent": "There may be missing values, in fact an it's basically impossible for a human to sift through these updates, so an automated tool is needed for such a task.",
                    "label": 1
                },
                {
                    "sent": "So the data which we have in this paper is basically from the data positive or a net website.",
                    "label": 0
                },
                {
                    "sent": "It collects data from the billing research network, which is a collection of Leuven.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Voters all across the US.",
                    "label": 0
                },
                {
                    "sent": "So for example, Seattle, Los Angeles, Kansas City, etc.",
                    "label": 0
                },
                {
                    "sent": "And we have almost 18,000,000 update messages or spread over a period of two years.",
                    "label": 1
                },
                {
                    "sent": "That's that gives us enough scope for actually figuring out real anomalies and patterns.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our approach is basically this.",
                    "label": 1
                },
                {
                    "sent": "So we look at a simple time series from the database.",
                    "label": 1
                },
                {
                    "sent": "So we suggest that just focus on just the timestamp so we have a list of timestamps which we gather from the repository, and we been the number of updates received every be seconds.",
                    "label": 1
                },
                {
                    "sent": "So what this means is that if you have the time axis which is depicted by the black line and you have black squares, is consisting of the updates before every B seconds, you count the number of updates in that bin and bucketized them.",
                    "label": 1
                },
                {
                    "sent": "So in a sense you get the bin Zero bin one bin two and the count is below.",
                    "label": 0
                },
                {
                    "sent": "So if you do all this and you get a time series which is depicted on the right.",
                    "label": 0
                },
                {
                    "sent": "So, given such a time series, the specific problem we are ultimately tackling is reporting patterns and anomalies on them and also using some auxiliary fields which we had in the original database.",
                    "label": 1
                },
                {
                    "sent": "You can find some suspicious entities for society.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "So how does the data look like?",
                    "label": 0
                },
                {
                    "sent": "So we plotted the extractor time series for the Washington router with the bin size of 600 seconds.",
                    "label": 1
                },
                {
                    "sent": "That's 10 minutes, so the number of updates and the bin number is on the X axis, so the one of the 1st way easy things to see is that it's very bursty.",
                    "label": 1
                },
                {
                    "sent": "Their huge spikes there, small spikes, and everything is basically being washed out due to that one anomaly at 2 into 4 bin.",
                    "label": 0
                },
                {
                    "sent": "So what makes is that the traditional tools like 15 autoregression don't really work here because of the spikes align you you will get a high score without, which is pretty much meaningless.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that was basically the outline and the problem introduction.",
                    "label": 0
                },
                {
                    "sent": "So right now I go into temporal analysis, which is one of.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Techniques which we applied so the first cut is because the linear linear plot is not really very helpful.",
                    "label": 0
                },
                {
                    "sent": "We took a log linear plot which emphasizes small values over high ones.",
                    "label": 1
                },
                {
                    "sent": "So for example, this is a log linear plot for a bin size of 10 seconds.",
                    "label": 0
                },
                {
                    "sent": "So as you can see that there are a lot of just a second.",
                    "label": 0
                },
                {
                    "sent": "Yeah there are a lot of missing values in the system which was not really observed and assignments didn't even know about this, so this just emphasizes that how noisy the data is.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is.",
                    "label": 0
                },
                {
                    "sent": "So, but the key thing here is the bin size is very.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Important, so if you take the same plot for a bin size of 600 seconds, you can see some interesting things.",
                    "label": 1
                },
                {
                    "sent": "So for example, there are two really denoted two really important observations which are denoted by the red lines.",
                    "label": 0
                },
                {
                    "sent": "So these look like near constant number of updates for a long period of time, and because they look like hanging bed sheets, we term them as close lines.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why are clotheslines important?",
                    "label": 0
                },
                {
                    "sent": "So they represent.",
                    "label": 0
                },
                {
                    "sent": "As I said, near consecutive updates over a long period of time and they can be attributed to route route flap dampening in the system.",
                    "label": 1
                },
                {
                    "sent": "So what it means is that you're advertising and withdrawing the same path repeatedly, and it points to an inefficiency in the system, so it's a very important phenomenon to identify.",
                    "label": 1
                },
                {
                    "sent": "So how do we automate this discovery?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we propose is take the probability distribution function of the volume of updates, that is, the number of times with the given volume.",
                    "label": 1
                },
                {
                    "sent": "So so if you look at this plot which is for the same plot for a bin size of 600 seconds, the two points which are denoted by the red lines are look anomalous.",
                    "label": 0
                },
                {
                    "sent": "So in a sense you would expect these points.",
                    "label": 0
                },
                {
                    "sent": "These volume of updates to be very frequent in the real time series.",
                    "label": 0
                },
                {
                    "sent": "So in other words, the extreme should be equal to the height of the clothesline.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To understand this better, let's just rotate the plot a little so that the Y axis now corresponds to the number of updates, and we bring the clothesline plot, which is just the time log in the log linear dimension with on the right hand side.",
                    "label": 1
                },
                {
                    "sent": "So if you look closely, the first enormous point actually corresponds to one of the clothesline which we had seen earlier, and similar for the second case.",
                    "label": 0
                },
                {
                    "sent": "So what I've given here is a simple example of how exactly we can discover such close lines, so you can go ahead and even formalize this intuition and.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea in the algorithm is that you have to use some kind of approach to find out these red points.",
                    "label": 0
                },
                {
                    "sent": "As noted in the left.",
                    "label": 0
                },
                {
                    "sent": "So we use a median filtering approach where you have a moving window to determine these outliers and for each time interval we find in the time series plot you report the most persistent aces or the IP's which are more likely to be the suspicious.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just a high level idea.",
                    "label": 0
                },
                {
                    "sent": "The details are in the paper, so next we move on to frequency analysis.",
                    "label": 1
                },
                {
                    "sent": "So the key thing is that things like 50.",
                    "label": 0
                },
                {
                    "sent": "So for example, given a time series, one of the basic things people say it's just plotted.",
                    "label": 0
                },
                {
                    "sent": "So we did 50 and even leaner linear plot.",
                    "label": 0
                },
                {
                    "sent": "As you can see there 50 doesn't really give me much information.",
                    "label": 0
                },
                {
                    "sent": "We also found that the data was actually self similar by self similarity mean that the data looked similar as several scales.",
                    "label": 0
                },
                {
                    "sent": "We perform many statistical.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes, for this.",
                    "label": 0
                },
                {
                    "sent": "So what we propose is use a multi resolution technique like wavelets for this.",
                    "label": 0
                },
                {
                    "sent": "So this is like a small crash course in wavelets as in.",
                    "label": 0
                },
                {
                    "sent": "So instead of giving the mathematical equations we so I've given a simple artificial time series on the bottom and the corresponding kilogram on the top.",
                    "label": 0
                },
                {
                    "sent": "This kilogram is plots, basically the absolute values of the wavelet coefficients overtime.",
                    "label": 0
                },
                {
                    "sent": "So the Y axis represents the scales, so the lower frequencies are on the top and the higher frequencies are on the bottom that is fast moving cycles on the bottom and lower.",
                    "label": 0
                },
                {
                    "sent": "Long short cycle long cycles on the top, so if you see the highest and the darker color darker colors represent high energy, whereas the lower energy is represented by lighter colors.",
                    "label": 0
                },
                {
                    "sent": "So if you see the huge spike corresponds to high energy overall coefficients, that is, you can see we term it as a tornado.",
                    "label": 1
                },
                {
                    "sent": "So you can see a tornado touching down similar case for the short spike just with a lower energy.",
                    "label": 0
                },
                {
                    "sent": "But for a prolonged spike, which is like a short burst of traffic for a short period of time, you can see that there's a tornado, but it doesn't touchdown, so this is the key motivation of actually going ahead and.",
                    "label": 0
                },
                {
                    "sent": "For.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Realizing this intuition, so we did the same thing for a real for the real signal which we have seen before.",
                    "label": 0
                },
                {
                    "sent": "So the real signal is on the bottom, so you can see the long spike corresponds to a tornado which touched down and the E2, which is the main tornado, which doesn't touchdown.",
                    "label": 0
                },
                {
                    "sent": "It actually corresponds to prolong Spike on the real signal.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just magnify the ellipse E2, which is which is being shown on this slide.",
                    "label": 0
                },
                {
                    "sent": "You can see that it corresponds to about 20,000 updates or period of eight hours on January 6th for, so this was completely invisible in the real data.",
                    "label": 1
                },
                {
                    "sent": "But you can look at it up with the scale.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Blood.",
                    "label": 0
                },
                {
                    "sent": "So again, why exactly prolonged spikes?",
                    "label": 0
                },
                {
                    "sent": "So these represent both of short duration, which can represent malicious behavior like IP space hijacking etc.",
                    "label": 1
                },
                {
                    "sent": "Or even simple phenomena like router restarts.",
                    "label": 0
                },
                {
                    "sent": "Somebody just shut down the route and restarted it and he has to update the whole table.",
                    "label": 1
                },
                {
                    "sent": "So the exact cause itself is very hard to find an answer an open problem, but it's very important for assignments to actually detect these.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that they can take corrective action so the algorithm is essentially finding tornadoes from this kaligram plot.",
                    "label": 0
                },
                {
                    "sent": "That is these... so you find suitable points at higher levels and then extend downward as much as possible to the finer scale where a tornado would stop and the shortest time period where you stop is like the finest scale.",
                    "label": 1
                },
                {
                    "sent": "So it is the shortest time period for which you can look at approx pipe, so.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, the details are in this paper.",
                    "label": 0
                },
                {
                    "sent": "We also did so if you look look at the two techniques which I presented.",
                    "label": 0
                },
                {
                    "sent": "Both are very linear in the number of time ticks, and we ended a scalability analysis and it's linear so.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "He's happy.",
                    "label": 0
                },
                {
                    "sent": "And then the next thing is, uh, we also built, went ahead and built a tool for sysadmins, which is.",
                    "label": 0
                },
                {
                    "sent": "This is the basic user interface.",
                    "label": 1
                },
                {
                    "sent": "So note that we don't really need any input from the user.",
                    "label": 0
                },
                {
                    "sent": "We have a reasonable defaults, but we also provide some easy to use knobs for expert users, which are optional, so the two knobs are basically sensitivity and duration.",
                    "label": 0
                },
                {
                    "sent": "The sensitivity deals with the number of suspicious, even as admin wants to check, whereas the duration is the length of the events you want to check, like monthly versus Weekly or.",
                    "label": 1
                },
                {
                    "sent": "Yearly.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So next we actually deal into some case study.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But we used we form some real events like for example the 50 close line which I showed before or do not have the red line.",
                    "label": 0
                },
                {
                    "sent": "So when we went ahead and did analyze the prefixes and the origin is it pointed to an Alabama Social supercomputer network.",
                    "label": 0
                },
                {
                    "sent": "When we contacted sysadmins they attributed the anomaly to route flap dampening of some particular prefix, so it's surprising that anomaly such as this went undetected and resolve for almost.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Month so the other interesting phenomena which found was a prolonged spike on May May 12th.",
                    "label": 1
                },
                {
                    "sent": "So this was the... to which we magnified again.",
                    "label": 0
                },
                {
                    "sent": "So it was an 8 hour spike and the most persistent IPS and aces pointed to some primary schools and middle schools.",
                    "label": 1
                },
                {
                    "sent": "So it's surprising that middle schoolers has such an intense burst of traffic for a short period of time.",
                    "label": 0
                },
                {
                    "sent": "So we also find several other.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Such events.",
                    "label": 0
                },
                {
                    "sent": "So just to wrap up, we started huge real data on comprising over two years.",
                    "label": 1
                },
                {
                    "sent": "We developed 2 new techniques which are effective in spotting subtle phenomena like clothesline and prolong spikes.",
                    "label": 1
                },
                {
                    "sent": "They're scalable, their linear and we also developed a user friendly tool which provides reasonable defaults, easy to use knobs and even very useful leads like IPS analysis to the.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thanks a lot and that's my opinion.",
                    "label": 0
                },
                {
                    "sent": "Here are the culprits.",
                    "label": 0
                }
            ]
        }
    }
}