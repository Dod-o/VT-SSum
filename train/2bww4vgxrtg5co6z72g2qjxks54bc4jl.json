{
    "id": "2bww4vgxrtg5co6z72g2qjxks54bc4jl",
    "title": "Hierarchical Hybrid Statistic based Video Binary Code and Its Application to Face Retrieval in TV-Series",
    "info": {
        "author": [
            "Xilin Chen, Institute of Computing Technology, Chinese Academy of Sciences"
        ],
        "published": "July 2, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis"
        ]
    },
    "url": "http://videolectures.net/fgconference2015_chen_face_retrieval/",
    "segmentation": [
        [
            "Hi everyone, I'm shooting from Chinese Academy of Sciences as the 1st order yearly is now rightly his visiting student in United States and he has some trouble in visa so he cannot come here and I present this OK.",
            "This paper it's about.",
            "Video based face retrieval."
        ],
        [
            "It's quite different, may be quite different topic with other directly recognition.",
            "Adding or community.",
            "We always talking about recognition.",
            "We seldom use the retrieval.",
            "What's the difference between recognition and retrieval?",
            "We know OK for recognition we will compare the problem with Gallery 1 by 1.",
            "So the complex city at least is alright so, but for retrieval, you as you as we know we have 10s of people right?",
            "So for recognition it will cost a lot of time and.",
            "But in the community of the database or some other community?",
            "OK, they use the words retrieval.",
            "That means OK, we try to get the information in almost constant time cost.",
            "OK, that's a different.",
            "For example.",
            "OK, we have some correct source travel from maybe TV series.",
            "Maybe movie Anne home video.",
            "Yesterday we have 10s of home video.",
            "Maybe you need to just get a clip of your OK family friend, family or friends or some other people.",
            "So that's one kind of application in.",
            "On the other hands."
        ],
        [
            "OK, yeah probably yeah.",
            "Today we feel we have to face a big challenge from video surveillance system right now because we have 10s of Camel in all over the city and once what happened?",
            "OK we have a lot of time.",
            "How to take a lot of time even thousands of people will take thousands of hours to find suspects.",
            "OK if we can do some retrieval, maybe it's much more faster.",
            "That's the basic background."
        ],
        [
            "So for the retrieval, what's the difference between face recognition we have to face three different questions problems.",
            "The first one is we need to OK represent each face frame we need to model each face clip right?",
            "Not one face, but clip offices.",
            "And we also need to conduct the retrieval efficiently.",
            "That's the challenge.",
            "And how can we do that?",
            "OK this way."
        ],
        [
            "Work we use Fishel vector to you tonight with the feature vector is useless to model the face images, and the reason why we use the facial vector is its first.",
            "It's like a bag of words and it also can be used as soft assignment, so it's not a hard one and it can seem simultaneously encoding zero 1st and 2nd order static information.",
            "That's, uh, quite useful for we to embed all this information together."
        ],
        [
            "And Meanwhile.",
            "We how could we get their official vector is including major, including two steps.",
            "The first is we need to do the Gaussian mixture model training does means OK. We training the face model.",
            "It's training from all the training physics and here we're using with dense shift as local feature and all this dense shift extracted from the training that sets.",
            "And then using this one too.",
            "Change the Gaussian mixture model after we have this model.",
            "That's a general model.",
            "It's for the whole people.",
            "We need to get the specific model for the specific person specific face image."
        ],
        [
            "And so the second step we training the specific model and for this step we using the same almost same steps as in the training in the Gaussian mixture model training stage.",
            "And we also extract local feature off that we we calculate their statistic information like First 1st order and 2nd order ones.",
            "OK like this and this.",
            "I think you're quite familiar with this one.",
            "And here come on, you soft assignments and double K is from the Gaussian mixture model and T is the number of features.",
            "And then we combining all these statistics as the whole feature for one face image.",
            "That's for one face image.",
            "After we got this modeling for one image, then we have the next.",
            "Yeah."
        ],
        [
            "The next is we tried to modeling a face clip.",
            "That means OK silver images from one face.",
            "We using the simple colors metrics to modeling the face clip.",
            "For this one we know that.",
            "Tricks it's not in Euclidean space is seeing remain space, so to measure the distance between two matrix, it cannot be cannot using the usually Euclidean distance.",
            "So we either using the long distance or we using the OK.",
            "This trace OK.",
            "In this work we try to get the hybrid stick hybrid state statistic.",
            "Here the FI is there OK the official actor and we also call this course metrics as the facial covers metrics.",
            "OK, this is the basically to get the information and modeling the face clip.",
            "Then we have all this information.",
            "What's next?",
            "The challenges in the."
        ],
        [
            "Next step, OK, it's very.",
            "Where lunch OK what so for this large vector?",
            "How we could get the cake get determined key for Gaussian mixture model.",
            "OK, it can be maybe a 32 or even 100 ten 24.",
            "So here we're using a hierarchical hybrid status.",
            "That means way from 2032 by 32 to 1024.",
            "By 10:24 we have six layers that this six level statistics naturally form our reputation from coarse to fine.",
            "So then you can travel your image from Coast to find that means OK, you can get their large set and then a small set and then refine the Federal one.",
            "That's the."
        ],
        [
            "Basically idea and once we have what's next, OK, once we have this clip we can.",
            "OK, let's see I OK can have the different.",
            "Images for facial covariance.",
            "Yeah."
        ],
        [
            "And the next challenge is the.",
            "The HS with huge dimension.",
            "As as you say, OK, it's from 22 by 22 to 10,000, ten 24 by 10:24.",
            "So it's very high dimension.",
            "For image retrieval.",
            "We don't want to such a very high dimension one, so we try to form the error code.",
            "That means OK, hashcode.",
            "And how about the hash code?",
            "And we know even 32 bits it can index modern.",
            "OK, so sorry there's something wrong.",
            "It should be one gigger image, one gigger images, and OK, it's almost 1 gigabyte for giga OK, but four giga images, so Tim Pool 9 images and it's almost the whole image is uploaded in the flick last year so it can encoding lot of images and.",
            "In this case."
        ],
        [
            "OK, How could we training their vehicle as we want to get barakel we want to have it has the capability of discriminating and also the state stability.",
            "So for these two constraints.",
            "OK the first one we want to get enough discriminant ability and for this purpose maybe.",
            "This one."
        ],
        [
            "Should be a good one.",
            "OK, but it's very sensitive because for example for this for this image is if it has some noisy, maybe it divide it in another side.",
            "And so we're probably too considering the stability, and in this case this is.",
            "Yeah, this margin is larger enough, but the same person is divided into."
        ],
        [
            "Different sites, and in this case OK, it's only has enough stability but not enough disk compatibility.",
            "So we have the third one.",
            "This is what we want.",
            "OK, for this purpose we have the formulation like this."
        ],
        [
            "This.",
            "OK, so just the object function in this one we have the two constraints.",
            "Why is the discriminant ability like LDA?",
            "Just like LDA?",
            "Another one is stability, just like SVM.",
            "OK, we have in the margin larger enough OK?"
        ],
        [
            "Then after the training we get the final get, the BI, the opii is the barraco what we want.",
            "OK, so."
        ],
        [
            "So.",
            "Let's just quickly summarize the steps.",
            "The first one we tried to your modeling, the face clip we modeling face image frame with Fisher Vector.",
            "Then we with modeling the clip with coerce matrix and finally we got the Fishel covariance matrix and then we training with OK Barco learning.",
            "The."
        ],
        [
            "See how we for this work.",
            "We take a long time to working on two TV series.",
            "OK, the first one is The Big Bang theory and the second one is the pricing break.",
            "OK, we using we are using some basic tools including building short boarding, bounding detection, face detection and face tracking.",
            "And also we use or landmark localization.",
            "To get the images and for the accuracy, we ask 5 farms."
        ],
        [
            "5 fans for each TV TV series.",
            "OK to your clear to carefully and notation all the corrects."
        ],
        [
            "And the image size in our work finally get the 8080 by 64 and the average frame numbers 414 per clip is roughly 4545 frames and totally 4000 Model 4000.",
            "Video clips for The Big Bang Theory and for the prison break we have more than 9000 clips.",
            "OK, all this data I means the label data is available right now, but originally movie OK, It's I mean, TV series is not our Copyright, so we cannot give any people that data but label data.",
            "If you want we can provide.",
            "And.",
            "We the testing put Coco is like this we have OK for training for training set.",
            "We have a 1414 corrects and each one we have 10 clips and for the PB we have 19 corrects and each one also has 10 each one has 10 video clips for the query we have five major crap corrects for each TV series.",
            "And the measurement is the MAP and also the precision recall curve.",
            "That's very, very popular as in other fields like multimedia retrieval and so on."
        ],
        [
            "Here the results.",
            "OK, we compare with the different of front end face frame modeling methods like grayscale Image, plus course metrics, LBP metrics and so on.",
            "And here this is the final results for all method.",
            "So the result compared to the original one is quite higher.",
            "And even for one scale OK, we can find even for one scale that's one scale.",
            "That's 432 by 3264 by 6, four and ten 1024 by 1024.",
            "OK, even for one scale is still better than the others.",
            "And then."
        ],
        [
            "When you compare with the different very cold any method, this means the same front front end and we just change the banner cool learning stage and results still better than others.",
            "OK."
        ],
        [
            "So the conclusion?",
            "OK, we propose a basic method with hybrid statistic to modeling a face clip image and we extend to hierarchical one and more stable and more robust, and the LDA like and SVM like constraints are used for barraco lending.",
            "We also have a database available, that means only label data.",
            "And before."
        ],
        [
            "In this talk, OK, I show you a video demo.",
            "OK, this is the result with different methods.",
            "Here the red Green 1 means correctly retrieval and the red one is something wrong.",
            "OK, this is another clip on prison break.",
            "There's only this one is only using one scale.",
            "This scale is 512.",
            "OK, that's it.",
            "Sick."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hi everyone, I'm shooting from Chinese Academy of Sciences as the 1st order yearly is now rightly his visiting student in United States and he has some trouble in visa so he cannot come here and I present this OK.",
                    "label": 1
                },
                {
                    "sent": "This paper it's about.",
                    "label": 0
                },
                {
                    "sent": "Video based face retrieval.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's quite different, may be quite different topic with other directly recognition.",
                    "label": 0
                },
                {
                    "sent": "Adding or community.",
                    "label": 0
                },
                {
                    "sent": "We always talking about recognition.",
                    "label": 0
                },
                {
                    "sent": "We seldom use the retrieval.",
                    "label": 0
                },
                {
                    "sent": "What's the difference between recognition and retrieval?",
                    "label": 0
                },
                {
                    "sent": "We know OK for recognition we will compare the problem with Gallery 1 by 1.",
                    "label": 0
                },
                {
                    "sent": "So the complex city at least is alright so, but for retrieval, you as you as we know we have 10s of people right?",
                    "label": 0
                },
                {
                    "sent": "So for recognition it will cost a lot of time and.",
                    "label": 0
                },
                {
                    "sent": "But in the community of the database or some other community?",
                    "label": 0
                },
                {
                    "sent": "OK, they use the words retrieval.",
                    "label": 0
                },
                {
                    "sent": "That means OK, we try to get the information in almost constant time cost.",
                    "label": 0
                },
                {
                    "sent": "OK, that's a different.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "OK, we have some correct source travel from maybe TV series.",
                    "label": 0
                },
                {
                    "sent": "Maybe movie Anne home video.",
                    "label": 0
                },
                {
                    "sent": "Yesterday we have 10s of home video.",
                    "label": 0
                },
                {
                    "sent": "Maybe you need to just get a clip of your OK family friend, family or friends or some other people.",
                    "label": 0
                },
                {
                    "sent": "So that's one kind of application in.",
                    "label": 0
                },
                {
                    "sent": "On the other hands.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, yeah probably yeah.",
                    "label": 0
                },
                {
                    "sent": "Today we feel we have to face a big challenge from video surveillance system right now because we have 10s of Camel in all over the city and once what happened?",
                    "label": 1
                },
                {
                    "sent": "OK we have a lot of time.",
                    "label": 0
                },
                {
                    "sent": "How to take a lot of time even thousands of people will take thousands of hours to find suspects.",
                    "label": 0
                },
                {
                    "sent": "OK if we can do some retrieval, maybe it's much more faster.",
                    "label": 0
                },
                {
                    "sent": "That's the basic background.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the retrieval, what's the difference between face recognition we have to face three different questions problems.",
                    "label": 0
                },
                {
                    "sent": "The first one is we need to OK represent each face frame we need to model each face clip right?",
                    "label": 1
                },
                {
                    "sent": "Not one face, but clip offices.",
                    "label": 1
                },
                {
                    "sent": "And we also need to conduct the retrieval efficiently.",
                    "label": 0
                },
                {
                    "sent": "That's the challenge.",
                    "label": 0
                },
                {
                    "sent": "And how can we do that?",
                    "label": 0
                },
                {
                    "sent": "OK this way.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work we use Fishel vector to you tonight with the feature vector is useless to model the face images, and the reason why we use the facial vector is its first.",
                    "label": 0
                },
                {
                    "sent": "It's like a bag of words and it also can be used as soft assignment, so it's not a hard one and it can seem simultaneously encoding zero 1st and 2nd order static information.",
                    "label": 0
                },
                {
                    "sent": "That's, uh, quite useful for we to embed all this information together.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And Meanwhile.",
                    "label": 0
                },
                {
                    "sent": "We how could we get their official vector is including major, including two steps.",
                    "label": 0
                },
                {
                    "sent": "The first is we need to do the Gaussian mixture model training does means OK. We training the face model.",
                    "label": 0
                },
                {
                    "sent": "It's training from all the training physics and here we're using with dense shift as local feature and all this dense shift extracted from the training that sets.",
                    "label": 0
                },
                {
                    "sent": "And then using this one too.",
                    "label": 0
                },
                {
                    "sent": "Change the Gaussian mixture model after we have this model.",
                    "label": 0
                },
                {
                    "sent": "That's a general model.",
                    "label": 0
                },
                {
                    "sent": "It's for the whole people.",
                    "label": 0
                },
                {
                    "sent": "We need to get the specific model for the specific person specific face image.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so the second step we training the specific model and for this step we using the same almost same steps as in the training in the Gaussian mixture model training stage.",
                    "label": 0
                },
                {
                    "sent": "And we also extract local feature off that we we calculate their statistic information like First 1st order and 2nd order ones.",
                    "label": 1
                },
                {
                    "sent": "OK like this and this.",
                    "label": 0
                },
                {
                    "sent": "I think you're quite familiar with this one.",
                    "label": 0
                },
                {
                    "sent": "And here come on, you soft assignments and double K is from the Gaussian mixture model and T is the number of features.",
                    "label": 0
                },
                {
                    "sent": "And then we combining all these statistics as the whole feature for one face image.",
                    "label": 1
                },
                {
                    "sent": "That's for one face image.",
                    "label": 0
                },
                {
                    "sent": "After we got this modeling for one image, then we have the next.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The next is we tried to modeling a face clip.",
                    "label": 1
                },
                {
                    "sent": "That means OK silver images from one face.",
                    "label": 1
                },
                {
                    "sent": "We using the simple colors metrics to modeling the face clip.",
                    "label": 0
                },
                {
                    "sent": "For this one we know that.",
                    "label": 0
                },
                {
                    "sent": "Tricks it's not in Euclidean space is seeing remain space, so to measure the distance between two matrix, it cannot be cannot using the usually Euclidean distance.",
                    "label": 0
                },
                {
                    "sent": "So we either using the long distance or we using the OK.",
                    "label": 0
                },
                {
                    "sent": "This trace OK.",
                    "label": 0
                },
                {
                    "sent": "In this work we try to get the hybrid stick hybrid state statistic.",
                    "label": 1
                },
                {
                    "sent": "Here the FI is there OK the official actor and we also call this course metrics as the facial covers metrics.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the basically to get the information and modeling the face clip.",
                    "label": 0
                },
                {
                    "sent": "Then we have all this information.",
                    "label": 0
                },
                {
                    "sent": "What's next?",
                    "label": 0
                },
                {
                    "sent": "The challenges in the.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next step, OK, it's very.",
                    "label": 0
                },
                {
                    "sent": "Where lunch OK what so for this large vector?",
                    "label": 0
                },
                {
                    "sent": "How we could get the cake get determined key for Gaussian mixture model.",
                    "label": 0
                },
                {
                    "sent": "OK, it can be maybe a 32 or even 100 ten 24.",
                    "label": 0
                },
                {
                    "sent": "So here we're using a hierarchical hybrid status.",
                    "label": 0
                },
                {
                    "sent": "That means way from 2032 by 32 to 1024.",
                    "label": 0
                },
                {
                    "sent": "By 10:24 we have six layers that this six level statistics naturally form our reputation from coarse to fine.",
                    "label": 0
                },
                {
                    "sent": "So then you can travel your image from Coast to find that means OK, you can get their large set and then a small set and then refine the Federal one.",
                    "label": 0
                },
                {
                    "sent": "That's the.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically idea and once we have what's next, OK, once we have this clip we can.",
                    "label": 0
                },
                {
                    "sent": "OK, let's see I OK can have the different.",
                    "label": 0
                },
                {
                    "sent": "Images for facial covariance.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the next challenge is the.",
                    "label": 0
                },
                {
                    "sent": "The HS with huge dimension.",
                    "label": 0
                },
                {
                    "sent": "As as you say, OK, it's from 22 by 22 to 10,000, ten 24 by 10:24.",
                    "label": 0
                },
                {
                    "sent": "So it's very high dimension.",
                    "label": 1
                },
                {
                    "sent": "For image retrieval.",
                    "label": 0
                },
                {
                    "sent": "We don't want to such a very high dimension one, so we try to form the error code.",
                    "label": 0
                },
                {
                    "sent": "That means OK, hashcode.",
                    "label": 1
                },
                {
                    "sent": "And how about the hash code?",
                    "label": 0
                },
                {
                    "sent": "And we know even 32 bits it can index modern.",
                    "label": 0
                },
                {
                    "sent": "OK, so sorry there's something wrong.",
                    "label": 0
                },
                {
                    "sent": "It should be one gigger image, one gigger images, and OK, it's almost 1 gigabyte for giga OK, but four giga images, so Tim Pool 9 images and it's almost the whole image is uploaded in the flick last year so it can encoding lot of images and.",
                    "label": 0
                },
                {
                    "sent": "In this case.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, How could we training their vehicle as we want to get barakel we want to have it has the capability of discriminating and also the state stability.",
                    "label": 0
                },
                {
                    "sent": "So for these two constraints.",
                    "label": 0
                },
                {
                    "sent": "OK the first one we want to get enough discriminant ability and for this purpose maybe.",
                    "label": 0
                },
                {
                    "sent": "This one.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Should be a good one.",
                    "label": 0
                },
                {
                    "sent": "OK, but it's very sensitive because for example for this for this image is if it has some noisy, maybe it divide it in another side.",
                    "label": 0
                },
                {
                    "sent": "And so we're probably too considering the stability, and in this case this is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this margin is larger enough, but the same person is divided into.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different sites, and in this case OK, it's only has enough stability but not enough disk compatibility.",
                    "label": 0
                },
                {
                    "sent": "So we have the third one.",
                    "label": 0
                },
                {
                    "sent": "This is what we want.",
                    "label": 0
                },
                {
                    "sent": "OK, for this purpose we have the formulation like this.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "OK, so just the object function in this one we have the two constraints.",
                    "label": 0
                },
                {
                    "sent": "Why is the discriminant ability like LDA?",
                    "label": 0
                },
                {
                    "sent": "Just like LDA?",
                    "label": 0
                },
                {
                    "sent": "Another one is stability, just like SVM.",
                    "label": 0
                },
                {
                    "sent": "OK, we have in the margin larger enough OK?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then after the training we get the final get, the BI, the opii is the barraco what we want.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let's just quickly summarize the steps.",
                    "label": 0
                },
                {
                    "sent": "The first one we tried to your modeling, the face clip we modeling face image frame with Fisher Vector.",
                    "label": 1
                },
                {
                    "sent": "Then we with modeling the clip with coerce matrix and finally we got the Fishel covariance matrix and then we training with OK Barco learning.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See how we for this work.",
                    "label": 0
                },
                {
                    "sent": "We take a long time to working on two TV series.",
                    "label": 0
                },
                {
                    "sent": "OK, the first one is The Big Bang theory and the second one is the pricing break.",
                    "label": 1
                },
                {
                    "sent": "OK, we using we are using some basic tools including building short boarding, bounding detection, face detection and face tracking.",
                    "label": 0
                },
                {
                    "sent": "And also we use or landmark localization.",
                    "label": 0
                },
                {
                    "sent": "To get the images and for the accuracy, we ask 5 farms.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "5 fans for each TV TV series.",
                    "label": 0
                },
                {
                    "sent": "OK to your clear to carefully and notation all the corrects.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the image size in our work finally get the 8080 by 64 and the average frame numbers 414 per clip is roughly 4545 frames and totally 4000 Model 4000.",
                    "label": 1
                },
                {
                    "sent": "Video clips for The Big Bang Theory and for the prison break we have more than 9000 clips.",
                    "label": 0
                },
                {
                    "sent": "OK, all this data I means the label data is available right now, but originally movie OK, It's I mean, TV series is not our Copyright, so we cannot give any people that data but label data.",
                    "label": 0
                },
                {
                    "sent": "If you want we can provide.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We the testing put Coco is like this we have OK for training for training set.",
                    "label": 1
                },
                {
                    "sent": "We have a 1414 corrects and each one we have 10 clips and for the PB we have 19 corrects and each one also has 10 each one has 10 video clips for the query we have five major crap corrects for each TV series.",
                    "label": 0
                },
                {
                    "sent": "And the measurement is the MAP and also the precision recall curve.",
                    "label": 1
                },
                {
                    "sent": "That's very, very popular as in other fields like multimedia retrieval and so on.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here the results.",
                    "label": 0
                },
                {
                    "sent": "OK, we compare with the different of front end face frame modeling methods like grayscale Image, plus course metrics, LBP metrics and so on.",
                    "label": 0
                },
                {
                    "sent": "And here this is the final results for all method.",
                    "label": 0
                },
                {
                    "sent": "So the result compared to the original one is quite higher.",
                    "label": 0
                },
                {
                    "sent": "And even for one scale OK, we can find even for one scale that's one scale.",
                    "label": 0
                },
                {
                    "sent": "That's 432 by 3264 by 6, four and ten 1024 by 1024.",
                    "label": 0
                },
                {
                    "sent": "OK, even for one scale is still better than the others.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When you compare with the different very cold any method, this means the same front front end and we just change the banner cool learning stage and results still better than others.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the conclusion?",
                    "label": 0
                },
                {
                    "sent": "OK, we propose a basic method with hybrid statistic to modeling a face clip image and we extend to hierarchical one and more stable and more robust, and the LDA like and SVM like constraints are used for barraco lending.",
                    "label": 1
                },
                {
                    "sent": "We also have a database available, that means only label data.",
                    "label": 0
                },
                {
                    "sent": "And before.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this talk, OK, I show you a video demo.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the result with different methods.",
                    "label": 0
                },
                {
                    "sent": "Here the red Green 1 means correctly retrieval and the red one is something wrong.",
                    "label": 0
                },
                {
                    "sent": "OK, this is another clip on prison break.",
                    "label": 0
                },
                {
                    "sent": "There's only this one is only using one scale.",
                    "label": 0
                },
                {
                    "sent": "This scale is 512.",
                    "label": 0
                },
                {
                    "sent": "OK, that's it.",
                    "label": 0
                },
                {
                    "sent": "Sick.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}