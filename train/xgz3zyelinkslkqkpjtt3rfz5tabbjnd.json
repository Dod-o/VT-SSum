{
    "id": "xgz3zyelinkslkqkpjtt3rfz5tabbjnd",
    "title": "On-line linear learning algorithms",
    "info": {
        "author": [
            "Nicol\u00f2 Cesa-Bianchi, University of Milan"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "November 2005",
        "category": [
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/aop05_bianchi_llla/",
    "segmentation": [
        [
            "Open file location.",
            "So if you could right now.",
            "Thanks, can you hear me?",
            "OK. OK. Alright.",
            "So."
        ],
        [
            "I'm going to talk about.",
            "A model of learning which is maybe a little unusual at first.",
            "Since is a model that does not assume any statistical hypothesis on the generation of the data.",
            "Indeed, the research in.",
            "Let's say non non statistical's no statistical learning models.",
            "Is something that has emerged in several areas in the last 60 years.",
            "So we cannot trace the first roots of the research in this field in the theory of repeated games.",
            "Which is a branch of game theory that started with Richard researchers started in the mid 50s by their work of with the work of Hannan, Ann Blackwell.",
            "OK.",
            "So these people were looking at the problem of.",
            "Playing again against an adversary against an opponent several times, so playing the same game several times.",
            "And that with this viewpoint, the difference with respect to the classical game theory that deals with one shots game games that are played just once.",
            "The difference with that is that you can basically can learn something about your opponent and for instance, if you find out that your opponent is weak, then you can.",
            "Improve on what you could get, what you could gain in in the case the game is played just once.",
            "So, so you see that the ideas of learning already fit kind of naturally in this.",
            "In this game theoretic sense scenario.",
            "But another area in which this field started to be investigated is information theory.",
            "And especially in the research around the compression.",
            "Problem of compressing sequence is indeed that you can.",
            "Kind of easily make a natural analogy between compression and learning or prediction.",
            "It did the kind of dual of each other or opposite of each other if you can.",
            "If you can compress, sorry.",
            "They are, they are.",
            "I don't.",
            "Maybe they're not dual, but they are similar.",
            "If you can compress well, then it means that the sequence has some nice structure.",
            "So that means that you can learn the structure and use it to predict well the sequence.",
            "And this this equivalence is goes beyond the intuition.",
            "You can put it down to formal details an actually you cannot derive for instance, from the Lampel diva well known compression algorithm that the compressor zip, and on Unix systems you can derive predictor.",
            "Four able to predict the next elements of an arbitrary sequence.",
            "And as a kind of side research that is still in the air of information theory, but not mainstream is the is the study of gambling and portfolio selection problems that was carried out by Tom Cover and other people in starting from the mid 60s.",
            "So again, you can imagine that if you can.",
            "Predict well the future.",
            "Then you should be able to invest your money well so you gain that.",
            "You should be able to gain a lot of money.",
            "So.",
            "And as before, as with the compression, you can build a formal relationship within the problem of investing in the market and predicting the next elements of a sequence.",
            "And user investment strategies strategies to do prediction or prediction strategies to do investment.",
            "And this equivalence actually carries over to the compression problem, so there is a sort of a.",
            "A sort of a full equivalence between good compressors, good predictors, and good invent investment strategies.",
            "And I repeat it all.",
            "This kind of research was done in this game theoretic under this game theoretic assumption that where we did we don't have any statistical assumption on the generation of the data I forgot.",
            "Sorry, I forgot to do.",
            "Kill this screensaver.",
            "Excuse me, Sir.",
            "Oh OK, none.",
            "So.",
            "And the 3rd or the 4th, the 4th area.",
            "Where this theme of game theoretic prediction or adversarial predictions arose is the area of pattern classification.",
            "And indeed, the initial analysis of the Perceptron algorithm done by Novikov in the 60s.",
            "Again, you see that the timing is kind of similar mid 50s, sixties and early 70s.",
            "Research in perception algorithm is was originally done for individual sequences of attribute vectors and binary labels.",
            "So the proof of the perception convergence theorem does not require any statistical assumption on the data.",
            "You can prove that the algorithm will converge on any sequence that has a certain simple property which is not statistical.",
            "And later on Nick Littlestone in the end of the 90s, derive the generalizations of the perception of variance of the perception algorithm, whose properties whose behavior?",
            "Was it proven under the same non statistical or adversarial assumptions on the generation of the data?",
            "So in this talk my.",
            "My goal is trying to give you an idea of the different problems and the different solutions that have been divided in all these fields, but I will concentrate especially in the.",
            "In the area of general prediction problem and pattern classification, Ann will mention a little bit.",
            "D problem of playing repeated games.",
            "I won't cover portfolio or compression since it would require more time and I will do this.",
            "Anne.",
            "This explanation using a unifying framework which encompasses all the all these different scenarios, which is the framework of prediction with expert advice?",
            "This is something that.",
            "Has been?",
            "I mean, it's I'm a computer scientist and this framework was proposed the initial in computer science.",
            "And computer Sciences weren't aware of all these research.",
            "That was all these results that were proven before, so they thought they re proven several of the theorems that I'm listing in here.",
            "And but they did it in a slightly more general scenario that is general enough to be for us convenient.",
            "To use for describing everything.",
            "OK, so this is the outline of the talk, so I will start out by describing this prediction with expert advice which is general."
        ],
        [
            "Scenario for studying prediction problem with non statistical assumption.",
            "And this will take.",
            "A good chunk of our time.",
            "And we will show several algorithms, several position algorithms and results, and then always start by explaining a little bit of connections with game theory.",
            "Not really a lot.",
            "I don't want to get into too much into game theory.",
            "And then I will move towards the problem of pattern classification.",
            "An investigator in this non statistical scenario.",
            "So we talk about linear experts that are very much related with linear learning algorithms for pattern classification like perception and the variance in extensions that they will cover.",
            "And then I will show how the results in the framework of prediction with experts advise can be easily carried out.",
            "To the pattern classification framework, and we derive as a corollary is some analysis.",
            "I mean we will recover the original perception, convergence algorithm, perception, convergence theorem, and some more general results, which are usually called a mistake bounds.",
            "Because basically you bound the number of mistakes that your algorithm you're planning classification algorithm is going to do on an arbitrary sequence of data.",
            "Then I will briefly mention will try to connect with what has been.",
            "Done with what has been covered in the other classes by explaining a little bit how these online learning algorithms can be applied to.",
            "Canon based learning and how you can use this results that hold for any individual sequence of data.",
            "You can basically.",
            "Use them to derive risk bounds in the statistical learning theory scenario.",
            "OK, and the advantage of doing that is that we want.",
            "For deriving that, the risk bounds in the statistical scenario, we want use a lot of statistics.",
            "We will use a very little statistic.",
            "It would be very simple because we will have the all the power of the adversarial bounds that we have proven in this game theoretic scenario.",
            "OK, so let me start with something very basic, very simple, so simple that.",
            "It's even misleading, so I'm."
        ],
        [
            "I'm looking at maybe the most basic prediction problem I can think of on a sequence.",
            "So our our guy is is the forecaster.",
            "This is the.",
            "The agent that wants to make the prediction and we want to predict the binary sequence.",
            "One bit at a time, one bit after the other so we don't know this sequence is unknown to us is arbitrary.",
            "We don't know anything about the device that is generating the sequence.",
            "It can be a statistical device or a deterministic device can be an adversary that wants to hurt us as much as it can.",
            "And then at each step on time, so time is discrete here.",
            "The forecaster predicts that the TS bit.",
            "With the knowledge of the previous beats.",
            "OK, so at any point in time the forecaster face faces the following problem.",
            "He knows the prefix of the sequence, maybe that one and has to predict the next bit.",
            "And then the next bit is revealed.",
            "We after we made our guests.",
            "The the environment or the adversary gives us the next bit, so we know whether we made a mistake or not.",
            "And our goal, I mean in general, of course, in general what we would like to do is to bound the number of prediction mistakes.",
            "Without knowing anything about it, this mechanism is generating the sequence.",
            "OK, is this?",
            "Please do interrupt me if something is unclear.",
            "I mean I, I'm not really keen on covering everything I have but more keen on trying to.",
            "Make you understand as much as I can.",
            "So.",
            "Of course, this is.",
            "This doesn't sound good, right?",
            "I mean, it's you can do much.",
            "It's easy.",
            "So I.",
            "It's not very useful.",
            "A scenario like this becausw what we would really like to have is a scenario in which you can.",
            "We cannot derive good prediction algorithm."
        ],
        [
            "So we know there are good prediction algorithms are around.",
            "And we would like to have a formal framework that is useful to derive good algorithms able to forecast, for instance binary sequences.",
            "And maybe this is this is not the right one, just the way we said.",
            "Because I mean.",
            "Unless we assume that the forecaster has access to some unknown source of knowledge.",
            "But this is metaphysics, so the forecaster is something that only observes this bits.",
            "And must use the knowledge of these bits to predict the next one.",
            "So the forecaster is a map from at the end of the day, the forecaster is a map from past observations to predictions to binary predictions.",
            "That's it.",
            "There's no way around this this this formalization.",
            "And of course, if if the adversary I am now the adversary, if I mean I'm able to pick the sequence at my will.",
            "The sequence it has to predict.",
            "For any forecaster you give me, I can pick a sequence such that on that sequence the forecaster will make a mistake at every step.",
            "It's obvious.",
            "I simply compliment.",
            "I simply choose the next bit as a compliment of the prediction.",
            "Given that the prediction is a map of that so.",
            "This is not really an interesting setup, but we can make it interesting with very little work.",
            "With a nice idea that.",
            "I mean, I view it as borrowed from the competitive analysis of algorithms, which is an area of the computer science area.",
            "But this is really a common.",
            "A common idea you don't want to prove an absolute bound you want to prove a relative bound.",
            "So you want to show that your algorithm is good, then not on an absolute scale?",
            "Because this is impossible, we have.",
            "We have seen that this is impossible.",
            "We want to prove that this is our agony is good relatively to a given set of forecasting algorithms.",
            "So I buy all forecasting problem programs that are sold on the Internet.",
            "I collect them all and I give you some some algorithm that is better than any one of them.",
            "That's a good proof.",
            "OK, maybe on some sequence?",
            "All of these algorithm will be bad, and my algorithm will be bad as well.",
            "For instance, if the sequence is purely random, of course there's nothing to predict, so we can pretend we do well on a random sequence but not.",
            "No forecasting algorithm will do well on a random sequence, so if our goal is relative now we are fine.",
            "We can make sense out of this scenario.",
            "So now.",
            "We say that we want to compare the performance of the forecaster to that of a set of reference forecasters that are Giza.",
            "Guys in the pool that we're competing against and we call this reference forecasters just to avoid repeating reference forecasters every time we call them experts.",
            "But they are the same beasts.",
            "As the forecaster, they're forecasting themselves.",
            "Questions.",
            "OK, so let's do an example to see how this goes."
        ],
        [
            "So like in this example, the forecaster is competing against the tree experts on and some sequence some binary sequence which we know, but they don't.",
            "Is 1101.",
            "So on day one.",
            "The the experts.",
            "Make their predictions for inside express one.",
            "Produce one expert Superdish Zero expertise predicts one.",
            "The forecaster.",
            "In also predicts one.",
            "In the.",
            "Of course it makes sense to assume I mean if this if we assume we have a pool of forecasters against against which we are competing, it makes sense to give access.",
            "To the forecasters make sense that the forecasters as hax access to the predictions of the experts so the forecasters is watching the experts make their predictions?",
            "And is trying to beat the best of them the best of the fork out of this express in the pool.",
            "OK, so in this case the forecasters is watching the prediction of the experts on day one and it decides to predict one, then the true first bit of the sequence is revealed.",
            "And the forecast is was right.",
            "Express one was right.",
            "Esper two was incorrect as three was correct.",
            "Then on day 2.",
            "Again, we have at the two first to express that one, and then the third place zero.",
            "The forecast is 0.",
            "The true bit is 1, and now the forecaster and III expert mistake.",
            "And he's gone.",
            "And at the end of our monitoring.",
            "Our horizon of time, which is in this case is just four days.",
            "We look at the total number of mistakes made by the three experts.",
            "And by the forecaster.",
            "And now we can set a relative goal, which sounds like this.",
            "We want to predict each sequence almost as well as the best expert for that sequence.",
            "So we want to be good as the best as per experts, but not on typical sequences on any binary sequence.",
            "OK. Of course, we don't know at the beginning we don't know which which aspect is going to be the best one, so we can sort of watch them and try to, you know, track somehow.",
            "The best.",
            "The one that we will be will result will turn out to be the best at the end of our horizon.",
            "OK, so now we can formalize this prediction with expert advice."
        ],
        [
            "Set up, which is likely more general.",
            "Maybe we don't want to predict just binary sequences, but we want to predict.",
            "More complex sequences.",
            "So we imagine the sequence is now the element of the sequence come from some space Y script Y.",
            "Can be anything good for now.",
            "We call it outcome space and predictions of the forecaster P hat.",
            "We assume are chosen from possibly different space, so outcomes and predictions don't do not necessarily have to come from the same space they come from may come from different spaces.",
            "OK. And.",
            "So Script X is this decision space.",
            "And now we score the forecaster with the function, which we call the loss function L. And this loss function is measuring the discrepancy between each prediction of the forecaster and the true outcome in the sequence.",
            "For every element of the sequence.",
            "So we are summing up.",
            "The losses incured by the forecaster on each prediction at each time step.",
            "The time step.",
            "OK, so this loss function is real value loss function which is typically non negative.",
            "And.",
            "Popular loss functions are.",
            "These ones at 01 loss.",
            "Which is the one that we used for predicting binary sequences, which is counting just the number of mistakes.",
            "So in this case X&Y are just the set of binary sets 01.",
            "And the last is just the indicator function of the event that the prediction is different from the true bit.",
            "So the bit that is bit predicted, P hat is different from the true, but why?",
            "In you may also assume that X&Y are the unit.",
            "Interval of the real line, and in this case the natural law says the quadratic loss.",
            "P -- P hat minus y ^2.",
            "Or in case, for instance.",
            "The axes are reals in the unit interval and wise are either real or maybe binary.",
            "You also have the absolute loss.",
            "Alright.",
            "He said these are just examples.",
            "Different examples.",
            "Well, these losses might be differentiable everywhere, like the quadratic loss.",
            "Might be convex, like the quadratic of the absolute loss or my body not differentiable, not convex like the 01 loss, so they are very different from each other.",
            "Then OK, now here is the here.",
            "How this protocol?"
        ],
        [
            "Is defined of prediction with expert advice.",
            "So.",
            "We fixed the set of experts or set of experts a set of N reference forecasters.",
            "An we predict it in sequential in time steps.",
            "But every time step T. The forecaster gets the prediction of all the experts in the pool.",
            "So he asks each expert how will you predict the theater element of this sequence?",
            "How will you predict Whitey and he gets?",
            "A prediction for each expert F1, F1, TF2 committee up to F Capital N, T These are leaving the same space as the forecasters predictions and collectively are called the expert advice, so they spent the devices this vector.",
            "Of predictions of the experts.",
            "No visit that on this information and on the knowledge of what happened before.",
            "The forecast of computer prediction PT hat.",
            "And afterwards, after he has committed to a specific prediction.",
            "The World environment nature is revealing the tidbit of the sequence Whitey.",
            "And now the forecaster knows if you made a mistake and also knows.",
            "How how can you compute his loss in general?",
            "And it can also compute the loss of all the experts.",
            "Because he knows the loss of experts.",
            "I will be just L of FI, TYT.",
            "And this goes on goes on OK. And.",
            "Right now you see whatever you may think, OK, but what are you assuming about these experts?",
            "Where do where do these numbers come from?",
            "But where does the advice come from?",
            "Right, we don't want to make any assumption on this.",
            "So for as experts are really black boxes.",
            "They can be programs that can be humans.",
            "That can be magicians.",
            "They can be dogs, whatever you like.",
            "If you want to predict the stock market with the dog, you know you can do it, maybe even better than.",
            "Then very smart people.",
            "And we just.",
            "Want to use their advice?",
            "To compute useful prediction and of course I mean our criterion will be the one that I said before.",
            "At the end of the day, I want to be.",
            "As good as bad as the best of my experts.",
            "Measure it with this loss function.",
            "No matter what was the sequence of wise, if the sequence of wise is such that everybody is bad, I can be as bad as any of the experts like with random sequences, But if the sequence has some structure and one of the experts is able to capture these structures, just maybe by chance.",
            "OK. One of these experts.",
            "Then we really want to to.",
            "To focus on that good expert and then at the end to have a total accumulative loss.",
            "Very close, very close to his loss.",
            "OK, so let's introduce some notation.",
            "So it's useful."
        ],
        [
            "In this case, since we are interested in comparing.",
            "Our performance with the with the all the experts performances.",
            "It's useful to lose to look at differences between performances between the performance of the forecaster, the performance of the experts, and we call these differences.",
            "Regrets Becausw somehow they tell us.",
            "How?",
            "How much regret we feel for not having followed the advice of a certain expert.",
            "So, concretely, look at the first line little R. Sub.",
            "IT is the difference between the loss of the forecaster at empty and the loss of the expert.",
            "I at time T. So this is how bad I was at time T with respect to expert I, the bigger is the difference, the bigger is my regret for not having followed the prediction of expertise.",
            "Now we also define the cumulative losses.",
            "Of the forecaster, which is which is this L hat, so the hats are for the forecasters.",
            "L had some man is the loss on the 1st N time steps.",
            "Encouraged by the forecaster, I have a pointer OK. OK. And the Elsa by end is the cumulative loss of expert I on the 1st on the first time time steps.",
            "And now we can define the regrets after N time steps of the forecaster with respect to the expert as the difference.",
            "Between the loss of the cumulative loss of the forecaster and the cumulative loss of the expert, which is just by definition, the sum of these instantaneous regrets.",
            "Every time.",
            "OK, and what we are really interested in in is in bounding this quantity here.",
            "So in after any point after any number of predictions.",
            "We want this maximum regret, which is the difference between the forecasters loss and the loss of the best experts.",
            "We want to bound it.",
            "We want to make it as small as possible.",
            "So this is the key.",
            "This is the key quantity in our analysis for the first part of this class.",
            "Which is the difference between the forecast is loss and loss of the best expert on that specific sequence.",
            "You see the sequences.",
            "Is this?",
            "Here is an arbitrary sequence and we want to bound this on any specific sequence.",
            "So you might say you might now introduce just for a short hand the notion of.",
            "Consistency we say that the forecast is consistent if the poor.",
            "Per timestep, regret converges to zero as time goes to Infinity.",
            "So in other words.",
            "We want that the on average.",
            "With respect to time.",
            "I do the difference between my performance at the performance on the of the best expert on that sequence goes to zero banishes.",
            "OK.",
            "This clear for everybody.",
            "And we want to do this for any sequence of outcomes, our wise, but also for all choices of access device.",
            "So we don't want to make assumption on the experts.",
            "So these places are just black boxes, so we cannot open up this block but these boxes.",
            "That just there, they spit out predictions at every time step.",
            "We can't.",
            "We can't do anything, just we can look those predictions that are spat out but use them.",
            "But we don't know how these positions are computed.",
            "So we want to be.",
            "We want to University quantify also the choice of the experts advice.",
            "So we are really dependent only on the number of them and on the performance, possibly on their performance.",
            "Numbers here.",
            "OK.",
            "So.",
            "Now how do you go about this problem?",
            "How would you?",
            "How would you design A forecaster for this problem?",
            "So again, this is the."
        ],
        [
            "This is the protocol.",
            "So you you know the past, you know the the current advice and you have to compute this number.",
            "How would you compute this number?",
            "What's this natural way of computing numbers?",
            "So that so that."
        ],
        [
            "You can guarantee this.",
            "OK.",
            "Anybody has an idea?",
            "Is just to check that you are awake.",
            "Is anybody's awake.",
            "OK, so OK."
        ],
        [
            "Not clear, so first of all that I make an assumption to simplify my life.",
            "Maybe also yours your life.",
            "I will assume that decision space is a convex subset of Lena space.",
            "This means that that I can take convex combinations of the prediction of experts and the convex combination is still a valid prediction.",
            "So the prediction space is convex.",
            "I can make I can mix predictions and I still get predictions.",
            "OK, this is a reasonable assumption.",
            "So now.",
            "The idea is that if you want to have a small regret if you want to minimize this maximum.",
            "This means that you regret us to be small.",
            "This means that if you have a big regret against a certain expert.",
            "That's really bad.",
            "It means that you should have followed that expert more than you did, so that your loss is closer to the loss of that expert and you'll regret is a consequence you regret with respect to that expert is more.",
            "So a sensible way to do that, OK, I take a weighted average of the expert advice here is the actor expert advisor Tempete.",
            "I get that you remember, I get that empty before I have to compute my PT hat and at a takeaway to weighted average, which means a convex combination.",
            "So now this this is meaningful, so these are the prediction of the express.",
            "It takes some point in the convex Hull of this prediction.",
            "No.",
            "How do I take?",
            "How do I choose the coefficients of these convex combination?",
            "It makes sense since I want to minimize the largest of the regrets with respectable experts.",
            "No, it makes sense that I weigh an expert.",
            "I give more weight to an expert.",
            "I guess which I have a big regret at that point of time.",
            "OK, so this is the regret I have a time up to time T -- 1.",
            "I'm now at time T and I choose my weight proportional to this and to be just flexible.",
            "I introduce a function new which is a positive monotone increasing function, so it's not doing a stranger games here.",
            "So this can be the square for instance.",
            "OK. And I can and I.",
            "If these are positives, the square of the positive part of this, for instance OK, and this is a reasonable assumption, this is sorry is a reasonable strategy, so it's a general strategy for.",
            "Computing predictions based on the expert advice and on the past performance of the expert relatively to us so it sort of takes into account all the ingredients in of our protocol.",
            "And I called this that weighted average forecaster.",
            "OK. No.",
            "OK, so let me take another assumption.",
            "Let's assume that the loss is convex.",
            "Also, this makes things really nice.",
            "Maybe you don't like this assumption, but I tell you, this makes things really nice.",
            "And this doesn't work for the count of mistakes.",
            "The counter mistakes is not convex.",
            "Is a step function, so I can't apply this theory.",
            "If I make this assumption to the to the mistake count, but then I will use other tricks later on to deal with non convex loss functions.",
            "But for now let's concentrate on convex loss functions.",
            "So we're interested in comics convexity in this argument.",
            "Here.",
            "So now if this loss function is convex then I can write this equal."
        ],
        [
            "City.",
            "Sorry I can.",
            "I can write the lawsuit empty.",
            "Of the forecaster.",
            "Now if I'm using the weighted average forecaster, now expand the PT hat using the definition.",
            "And now since Alice comics by Jen's inequality, I can pull the loss inside the average and get this.",
            "So I have the loss of time T of this weighted average forecaster is at most this convex combination.",
            "Here is the cosmos the convex combination of the losses of the experts.",
            "OK, well why is this interesting?",
            "OK, now we know that the difference between these two things one appears here and one appears here is the instantaneous regret at time T with respect to expect.",
            "I now if I take this on this side and rearrange and you can see it, I get something like this.",
            "This is what this is, a property that holds for.",
            "The weighted average forecaster irrespective to the choice of Y of the element.",
            "I have to predict at time T and irrespective to the way the experts behave, behave.",
            "This is really an invariant of this weighted average forecasting strategy.",
            "So now the idea is, can we use this invariant to prove something interesting about the behavior of this weighted average forecaster?",
            "Of course the answer is yes.",
            "And now I'm going to.",
            "I'm going to show how to use this invariant to prove things about this, the forecaster.",
            "OK, we're still general.",
            "We're in a variable generation scenario and now I'm getting a little bit more general.",
            "But afterwards I will make a concrete examples of things."
        ],
        [
            "So let me be a little more general now, becausw.",
            "I I have I can afford it, so why not?",
            "So first of all, for some reason that will be clear hopefully later.",
            "I am you remember this function knew this function you."
        ],
        [
            "Is the is the flexibility that we have introduced the in waiting they regret of the computing?",
            "The weights of the experts.",
            "So we are our prediction is proportional to the regret but proportional to a function mu.",
            "No, because I'm because I like it.",
            "I would like to write this function new as a derivative of a function 5.",
            "Which is a function on the reals which are assumed to be non negative.",
            "Nondecreasing and such that it has a it is twice differentiable everywhere.",
            "OK. Now of course I can rewrite the weighted average forecaster with the five primes, replacing the news.",
            "No, no big deal.",
            "But now I can see this as an instance of a more general thing.",
            "Indeed I can.",
            "I can introduce what is called the potential functions.",
            "So introducing potentials is always nice becausw you know that many smart people prove it into the interesting things using potentials, so you're hoping to be in the same good group of people and you have some analogies.",
            "You can draw analogies from dynamical systems, physics and stuff.",
            "So I'm kidding of course, but maybe a little bit I will do, and so I can define this potential function, which is a function defined on the space of regret.",
            "So now let's see.",
            "You see, you see these are.",
            "You can view these things as component of a big vector.",
            "A vector of of elements I.",
            "So I can view now, a picture will come to show you I can view.",
            "The regret against each individual expert as a vector.",
            "In a space air are capital N, where N is the number of experts.",
            "And I can define this function on this space which is made up of our face whose derivatives appear here, and another guy's eye, which is again affection on the real non non decreasing stick, strictly increasing and concave.",
            "Note this is not convex, but this has to be concave form.",
            "So why is this OK?",
            "So now with this definition, just because I made things a little bit more complicated, I can write.",
            "The prediction.",
            "Of the weighted average forecaster, as.",
            "Using the gradients of this potential function Phi.",
            "So this is the IAST component of the gradient.",
            "And this is the JS component of the grant.",
            "You say, why?",
            "What now the grid?",
            "You get the gradient.",
            "I get the gradient because before I had the five primes.",
            "Now if I take the gradient of this I get side prime and then I get 5 prime.",
            "But the fight primes simplify because I get a five prime here and define prime of the same thing.",
            "Up here I simplify those M left it with this.",
            "So now you say, but why do we introduce the file if they don't?",
            "If they simplify in the prediction because they will be useful in the analysis.",
            "OK, analysis is should be simple, simple enough so that you can appreciate that.",
            "So now I can write these weighted average forecaster using this gradient of the regrets.",
            "And this condition here, because the the invariant I had before.",
            "Now we run."
        ],
        [
            "Rights in this way.",
            "So basically says that the inner product between the gradient of the of the potential of the regret at time T -- 1 and the the vector of distant enemies regret that empty is more than zero.",
            "So this vector here is the vector whose components are these, so this is the vector of the cumulative regrets.",
            "And this is the vector of instantaneous regrets.",
            "OK, and this is called for historical reasons, is called Blackwell condition, but it's not really condition.",
            "Now is the property is a property of the weighted average forecasters forecaster using these.",
            "These potential functions.",
            "OK, so now.",
            "Comes a picture.",
            "So this is a picture showing a little bit of the geometrical intuition you see now.",
            "Things boil down to geometry here, so now I can hope to draw geometrical intuition from this writing at this notion of potential, so that I can come up with a sensible analysis of this forecast."
        ],
        [
            "After so, now here is the case in which I have two experts.",
            "So I have two coordinates in my vectors and this is the regret space.",
            "So this is my cumulative regret at some time T which is not shown.",
            "This is the cumulative regret.",
            "And this is the well, is the potential the isopotential line passing through this regret.",
            "So you can imagine at this stage you can imagine the potential as a bowl.",
            "Is a bowl in this space?",
            "Is it also it's it's the value of the potential is the third coordinate that sticks out, so you have a bowl.",
            "This is the contour of the ball, the zero.",
            "The ball is here.",
            "And your.",
            "The idea is that you want to keep these things as close to as possible to the negative part.",
            "Of the system of coordinate, why you remember?",
            "Your goal is.",
            "Your goal is to keep these things small so that the average of these things goes to zero asymptotically.",
            "So these are now are the coordinates in our space, so this thing."
        ],
        [
            "This vector, if you write it as a vector has to be small in each coordinate.",
            "So this means that."
        ],
        [
            "I want to have this point as close as possible to the zero or to the negative orthant of this system.",
            "Accordingly, because this is very great, so it's really has to be pushed down, but.",
            "So what does now?",
            "What is the geometrical significance significance of the black hole condition?",
            "So I can take the gradient, the value of the gradient vector at this point will point in this direction.",
            "Because this is the the orthogonal to the tangent of the potential at this point.",
            "And now the fact that.",
            "The increment in the cumulative regret, which is the older cumulative regret plus the new regret I'm going to.",
            "I'm going to get after the prediction Attende has to live in this half space over here.",
            "Why is that becausw?"
        ],
        [
            "The fact that this inner product is negative means that the angle between the gradient vector and the new instantaneous regret vector is bigger than a 90 degrees.",
            "The angle between these two vectors so."
        ],
        [
            "This new vector should point below here, so the potential can grow with time because it can be over here.",
            "But can grow too much, can grow like crazy like this.",
            "So this is how we can may hope to use."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Open file location.",
                    "label": 0
                },
                {
                    "sent": "So if you could right now.",
                    "label": 0
                },
                {
                    "sent": "Thanks, can you hear me?",
                    "label": 0
                },
                {
                    "sent": "OK. OK. Alright.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to talk about.",
                    "label": 0
                },
                {
                    "sent": "A model of learning which is maybe a little unusual at first.",
                    "label": 0
                },
                {
                    "sent": "Since is a model that does not assume any statistical hypothesis on the generation of the data.",
                    "label": 0
                },
                {
                    "sent": "Indeed, the research in.",
                    "label": 0
                },
                {
                    "sent": "Let's say non non statistical's no statistical learning models.",
                    "label": 0
                },
                {
                    "sent": "Is something that has emerged in several areas in the last 60 years.",
                    "label": 0
                },
                {
                    "sent": "So we cannot trace the first roots of the research in this field in the theory of repeated games.",
                    "label": 1
                },
                {
                    "sent": "Which is a branch of game theory that started with Richard researchers started in the mid 50s by their work of with the work of Hannan, Ann Blackwell.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So these people were looking at the problem of.",
                    "label": 0
                },
                {
                    "sent": "Playing again against an adversary against an opponent several times, so playing the same game several times.",
                    "label": 0
                },
                {
                    "sent": "And that with this viewpoint, the difference with respect to the classical game theory that deals with one shots game games that are played just once.",
                    "label": 0
                },
                {
                    "sent": "The difference with that is that you can basically can learn something about your opponent and for instance, if you find out that your opponent is weak, then you can.",
                    "label": 0
                },
                {
                    "sent": "Improve on what you could get, what you could gain in in the case the game is played just once.",
                    "label": 0
                },
                {
                    "sent": "So, so you see that the ideas of learning already fit kind of naturally in this.",
                    "label": 0
                },
                {
                    "sent": "In this game theoretic sense scenario.",
                    "label": 0
                },
                {
                    "sent": "But another area in which this field started to be investigated is information theory.",
                    "label": 0
                },
                {
                    "sent": "And especially in the research around the compression.",
                    "label": 0
                },
                {
                    "sent": "Problem of compressing sequence is indeed that you can.",
                    "label": 0
                },
                {
                    "sent": "Kind of easily make a natural analogy between compression and learning or prediction.",
                    "label": 0
                },
                {
                    "sent": "It did the kind of dual of each other or opposite of each other if you can.",
                    "label": 0
                },
                {
                    "sent": "If you can compress, sorry.",
                    "label": 0
                },
                {
                    "sent": "They are, they are.",
                    "label": 0
                },
                {
                    "sent": "I don't.",
                    "label": 0
                },
                {
                    "sent": "Maybe they're not dual, but they are similar.",
                    "label": 0
                },
                {
                    "sent": "If you can compress well, then it means that the sequence has some nice structure.",
                    "label": 0
                },
                {
                    "sent": "So that means that you can learn the structure and use it to predict well the sequence.",
                    "label": 0
                },
                {
                    "sent": "And this this equivalence is goes beyond the intuition.",
                    "label": 0
                },
                {
                    "sent": "You can put it down to formal details an actually you cannot derive for instance, from the Lampel diva well known compression algorithm that the compressor zip, and on Unix systems you can derive predictor.",
                    "label": 0
                },
                {
                    "sent": "Four able to predict the next elements of an arbitrary sequence.",
                    "label": 0
                },
                {
                    "sent": "And as a kind of side research that is still in the air of information theory, but not mainstream is the is the study of gambling and portfolio selection problems that was carried out by Tom Cover and other people in starting from the mid 60s.",
                    "label": 0
                },
                {
                    "sent": "So again, you can imagine that if you can.",
                    "label": 0
                },
                {
                    "sent": "Predict well the future.",
                    "label": 0
                },
                {
                    "sent": "Then you should be able to invest your money well so you gain that.",
                    "label": 0
                },
                {
                    "sent": "You should be able to gain a lot of money.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And as before, as with the compression, you can build a formal relationship within the problem of investing in the market and predicting the next elements of a sequence.",
                    "label": 0
                },
                {
                    "sent": "And user investment strategies strategies to do prediction or prediction strategies to do investment.",
                    "label": 0
                },
                {
                    "sent": "And this equivalence actually carries over to the compression problem, so there is a sort of a.",
                    "label": 0
                },
                {
                    "sent": "A sort of a full equivalence between good compressors, good predictors, and good invent investment strategies.",
                    "label": 0
                },
                {
                    "sent": "And I repeat it all.",
                    "label": 0
                },
                {
                    "sent": "This kind of research was done in this game theoretic under this game theoretic assumption that where we did we don't have any statistical assumption on the generation of the data I forgot.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I forgot to do.",
                    "label": 0
                },
                {
                    "sent": "Kill this screensaver.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, Sir.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, none.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And the 3rd or the 4th, the 4th area.",
                    "label": 0
                },
                {
                    "sent": "Where this theme of game theoretic prediction or adversarial predictions arose is the area of pattern classification.",
                    "label": 0
                },
                {
                    "sent": "And indeed, the initial analysis of the Perceptron algorithm done by Novikov in the 60s.",
                    "label": 0
                },
                {
                    "sent": "Again, you see that the timing is kind of similar mid 50s, sixties and early 70s.",
                    "label": 0
                },
                {
                    "sent": "Research in perception algorithm is was originally done for individual sequences of attribute vectors and binary labels.",
                    "label": 0
                },
                {
                    "sent": "So the proof of the perception convergence theorem does not require any statistical assumption on the data.",
                    "label": 0
                },
                {
                    "sent": "You can prove that the algorithm will converge on any sequence that has a certain simple property which is not statistical.",
                    "label": 0
                },
                {
                    "sent": "And later on Nick Littlestone in the end of the 90s, derive the generalizations of the perception of variance of the perception algorithm, whose properties whose behavior?",
                    "label": 0
                },
                {
                    "sent": "Was it proven under the same non statistical or adversarial assumptions on the generation of the data?",
                    "label": 0
                },
                {
                    "sent": "So in this talk my.",
                    "label": 0
                },
                {
                    "sent": "My goal is trying to give you an idea of the different problems and the different solutions that have been divided in all these fields, but I will concentrate especially in the.",
                    "label": 0
                },
                {
                    "sent": "In the area of general prediction problem and pattern classification, Ann will mention a little bit.",
                    "label": 0
                },
                {
                    "sent": "D problem of playing repeated games.",
                    "label": 0
                },
                {
                    "sent": "I won't cover portfolio or compression since it would require more time and I will do this.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "This explanation using a unifying framework which encompasses all the all these different scenarios, which is the framework of prediction with expert advice?",
                    "label": 1
                },
                {
                    "sent": "This is something that.",
                    "label": 0
                },
                {
                    "sent": "Has been?",
                    "label": 0
                },
                {
                    "sent": "I mean, it's I'm a computer scientist and this framework was proposed the initial in computer science.",
                    "label": 0
                },
                {
                    "sent": "And computer Sciences weren't aware of all these research.",
                    "label": 0
                },
                {
                    "sent": "That was all these results that were proven before, so they thought they re proven several of the theorems that I'm listing in here.",
                    "label": 0
                },
                {
                    "sent": "And but they did it in a slightly more general scenario that is general enough to be for us convenient.",
                    "label": 0
                },
                {
                    "sent": "To use for describing everything.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the outline of the talk, so I will start out by describing this prediction with expert advice which is general.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Scenario for studying prediction problem with non statistical assumption.",
                    "label": 0
                },
                {
                    "sent": "And this will take.",
                    "label": 0
                },
                {
                    "sent": "A good chunk of our time.",
                    "label": 0
                },
                {
                    "sent": "And we will show several algorithms, several position algorithms and results, and then always start by explaining a little bit of connections with game theory.",
                    "label": 1
                },
                {
                    "sent": "Not really a lot.",
                    "label": 0
                },
                {
                    "sent": "I don't want to get into too much into game theory.",
                    "label": 0
                },
                {
                    "sent": "And then I will move towards the problem of pattern classification.",
                    "label": 0
                },
                {
                    "sent": "An investigator in this non statistical scenario.",
                    "label": 1
                },
                {
                    "sent": "So we talk about linear experts that are very much related with linear learning algorithms for pattern classification like perception and the variance in extensions that they will cover.",
                    "label": 0
                },
                {
                    "sent": "And then I will show how the results in the framework of prediction with experts advise can be easily carried out.",
                    "label": 0
                },
                {
                    "sent": "To the pattern classification framework, and we derive as a corollary is some analysis.",
                    "label": 0
                },
                {
                    "sent": "I mean we will recover the original perception, convergence algorithm, perception, convergence theorem, and some more general results, which are usually called a mistake bounds.",
                    "label": 0
                },
                {
                    "sent": "Because basically you bound the number of mistakes that your algorithm you're planning classification algorithm is going to do on an arbitrary sequence of data.",
                    "label": 0
                },
                {
                    "sent": "Then I will briefly mention will try to connect with what has been.",
                    "label": 0
                },
                {
                    "sent": "Done with what has been covered in the other classes by explaining a little bit how these online learning algorithms can be applied to.",
                    "label": 0
                },
                {
                    "sent": "Canon based learning and how you can use this results that hold for any individual sequence of data.",
                    "label": 1
                },
                {
                    "sent": "You can basically.",
                    "label": 0
                },
                {
                    "sent": "Use them to derive risk bounds in the statistical learning theory scenario.",
                    "label": 0
                },
                {
                    "sent": "OK, and the advantage of doing that is that we want.",
                    "label": 0
                },
                {
                    "sent": "For deriving that, the risk bounds in the statistical scenario, we want use a lot of statistics.",
                    "label": 0
                },
                {
                    "sent": "We will use a very little statistic.",
                    "label": 0
                },
                {
                    "sent": "It would be very simple because we will have the all the power of the adversarial bounds that we have proven in this game theoretic scenario.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me start with something very basic, very simple, so simple that.",
                    "label": 0
                },
                {
                    "sent": "It's even misleading, so I'm.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm looking at maybe the most basic prediction problem I can think of on a sequence.",
                    "label": 0
                },
                {
                    "sent": "So our our guy is is the forecaster.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                },
                {
                    "sent": "The agent that wants to make the prediction and we want to predict the binary sequence.",
                    "label": 0
                },
                {
                    "sent": "One bit at a time, one bit after the other so we don't know this sequence is unknown to us is arbitrary.",
                    "label": 1
                },
                {
                    "sent": "We don't know anything about the device that is generating the sequence.",
                    "label": 0
                },
                {
                    "sent": "It can be a statistical device or a deterministic device can be an adversary that wants to hurt us as much as it can.",
                    "label": 0
                },
                {
                    "sent": "And then at each step on time, so time is discrete here.",
                    "label": 1
                },
                {
                    "sent": "The forecaster predicts that the TS bit.",
                    "label": 0
                },
                {
                    "sent": "With the knowledge of the previous beats.",
                    "label": 0
                },
                {
                    "sent": "OK, so at any point in time the forecaster face faces the following problem.",
                    "label": 0
                },
                {
                    "sent": "He knows the prefix of the sequence, maybe that one and has to predict the next bit.",
                    "label": 0
                },
                {
                    "sent": "And then the next bit is revealed.",
                    "label": 0
                },
                {
                    "sent": "We after we made our guests.",
                    "label": 0
                },
                {
                    "sent": "The the environment or the adversary gives us the next bit, so we know whether we made a mistake or not.",
                    "label": 0
                },
                {
                    "sent": "And our goal, I mean in general, of course, in general what we would like to do is to bound the number of prediction mistakes.",
                    "label": 1
                },
                {
                    "sent": "Without knowing anything about it, this mechanism is generating the sequence.",
                    "label": 0
                },
                {
                    "sent": "OK, is this?",
                    "label": 0
                },
                {
                    "sent": "Please do interrupt me if something is unclear.",
                    "label": 0
                },
                {
                    "sent": "I mean I, I'm not really keen on covering everything I have but more keen on trying to.",
                    "label": 0
                },
                {
                    "sent": "Make you understand as much as I can.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Of course, this is.",
                    "label": 0
                },
                {
                    "sent": "This doesn't sound good, right?",
                    "label": 0
                },
                {
                    "sent": "I mean, it's you can do much.",
                    "label": 0
                },
                {
                    "sent": "It's easy.",
                    "label": 0
                },
                {
                    "sent": "So I.",
                    "label": 0
                },
                {
                    "sent": "It's not very useful.",
                    "label": 0
                },
                {
                    "sent": "A scenario like this becausw what we would really like to have is a scenario in which you can.",
                    "label": 0
                },
                {
                    "sent": "We cannot derive good prediction algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we know there are good prediction algorithms are around.",
                    "label": 0
                },
                {
                    "sent": "And we would like to have a formal framework that is useful to derive good algorithms able to forecast, for instance binary sequences.",
                    "label": 0
                },
                {
                    "sent": "And maybe this is this is not the right one, just the way we said.",
                    "label": 0
                },
                {
                    "sent": "Because I mean.",
                    "label": 0
                },
                {
                    "sent": "Unless we assume that the forecaster has access to some unknown source of knowledge.",
                    "label": 0
                },
                {
                    "sent": "But this is metaphysics, so the forecaster is something that only observes this bits.",
                    "label": 0
                },
                {
                    "sent": "And must use the knowledge of these bits to predict the next one.",
                    "label": 0
                },
                {
                    "sent": "So the forecaster is a map from at the end of the day, the forecaster is a map from past observations to predictions to binary predictions.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "There's no way around this this this formalization.",
                    "label": 0
                },
                {
                    "sent": "And of course, if if the adversary I am now the adversary, if I mean I'm able to pick the sequence at my will.",
                    "label": 0
                },
                {
                    "sent": "The sequence it has to predict.",
                    "label": 0
                },
                {
                    "sent": "For any forecaster you give me, I can pick a sequence such that on that sequence the forecaster will make a mistake at every step.",
                    "label": 0
                },
                {
                    "sent": "It's obvious.",
                    "label": 0
                },
                {
                    "sent": "I simply compliment.",
                    "label": 0
                },
                {
                    "sent": "I simply choose the next bit as a compliment of the prediction.",
                    "label": 0
                },
                {
                    "sent": "Given that the prediction is a map of that so.",
                    "label": 0
                },
                {
                    "sent": "This is not really an interesting setup, but we can make it interesting with very little work.",
                    "label": 0
                },
                {
                    "sent": "With a nice idea that.",
                    "label": 0
                },
                {
                    "sent": "I mean, I view it as borrowed from the competitive analysis of algorithms, which is an area of the computer science area.",
                    "label": 0
                },
                {
                    "sent": "But this is really a common.",
                    "label": 0
                },
                {
                    "sent": "A common idea you don't want to prove an absolute bound you want to prove a relative bound.",
                    "label": 0
                },
                {
                    "sent": "So you want to show that your algorithm is good, then not on an absolute scale?",
                    "label": 0
                },
                {
                    "sent": "Because this is impossible, we have.",
                    "label": 0
                },
                {
                    "sent": "We have seen that this is impossible.",
                    "label": 0
                },
                {
                    "sent": "We want to prove that this is our agony is good relatively to a given set of forecasting algorithms.",
                    "label": 0
                },
                {
                    "sent": "So I buy all forecasting problem programs that are sold on the Internet.",
                    "label": 0
                },
                {
                    "sent": "I collect them all and I give you some some algorithm that is better than any one of them.",
                    "label": 0
                },
                {
                    "sent": "That's a good proof.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe on some sequence?",
                    "label": 0
                },
                {
                    "sent": "All of these algorithm will be bad, and my algorithm will be bad as well.",
                    "label": 0
                },
                {
                    "sent": "For instance, if the sequence is purely random, of course there's nothing to predict, so we can pretend we do well on a random sequence but not.",
                    "label": 0
                },
                {
                    "sent": "No forecasting algorithm will do well on a random sequence, so if our goal is relative now we are fine.",
                    "label": 0
                },
                {
                    "sent": "We can make sense out of this scenario.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "We say that we want to compare the performance of the forecaster to that of a set of reference forecasters that are Giza.",
                    "label": 1
                },
                {
                    "sent": "Guys in the pool that we're competing against and we call this reference forecasters just to avoid repeating reference forecasters every time we call them experts.",
                    "label": 0
                },
                {
                    "sent": "But they are the same beasts.",
                    "label": 0
                },
                {
                    "sent": "As the forecaster, they're forecasting themselves.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's do an example to see how this goes.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So like in this example, the forecaster is competing against the tree experts on and some sequence some binary sequence which we know, but they don't.",
                    "label": 0
                },
                {
                    "sent": "Is 1101.",
                    "label": 0
                },
                {
                    "sent": "So on day one.",
                    "label": 0
                },
                {
                    "sent": "The the experts.",
                    "label": 0
                },
                {
                    "sent": "Make their predictions for inside express one.",
                    "label": 0
                },
                {
                    "sent": "Produce one expert Superdish Zero expertise predicts one.",
                    "label": 0
                },
                {
                    "sent": "The forecaster.",
                    "label": 0
                },
                {
                    "sent": "In also predicts one.",
                    "label": 0
                },
                {
                    "sent": "In the.",
                    "label": 0
                },
                {
                    "sent": "Of course it makes sense to assume I mean if this if we assume we have a pool of forecasters against against which we are competing, it makes sense to give access.",
                    "label": 0
                },
                {
                    "sent": "To the forecasters make sense that the forecasters as hax access to the predictions of the experts so the forecasters is watching the experts make their predictions?",
                    "label": 0
                },
                {
                    "sent": "And is trying to beat the best of them the best of the fork out of this express in the pool.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case the forecasters is watching the prediction of the experts on day one and it decides to predict one, then the true first bit of the sequence is revealed.",
                    "label": 0
                },
                {
                    "sent": "And the forecast is was right.",
                    "label": 0
                },
                {
                    "sent": "Express one was right.",
                    "label": 0
                },
                {
                    "sent": "Esper two was incorrect as three was correct.",
                    "label": 0
                },
                {
                    "sent": "Then on day 2.",
                    "label": 0
                },
                {
                    "sent": "Again, we have at the two first to express that one, and then the third place zero.",
                    "label": 0
                },
                {
                    "sent": "The forecast is 0.",
                    "label": 0
                },
                {
                    "sent": "The true bit is 1, and now the forecaster and III expert mistake.",
                    "label": 0
                },
                {
                    "sent": "And he's gone.",
                    "label": 0
                },
                {
                    "sent": "And at the end of our monitoring.",
                    "label": 0
                },
                {
                    "sent": "Our horizon of time, which is in this case is just four days.",
                    "label": 0
                },
                {
                    "sent": "We look at the total number of mistakes made by the three experts.",
                    "label": 0
                },
                {
                    "sent": "And by the forecaster.",
                    "label": 0
                },
                {
                    "sent": "And now we can set a relative goal, which sounds like this.",
                    "label": 0
                },
                {
                    "sent": "We want to predict each sequence almost as well as the best expert for that sequence.",
                    "label": 1
                },
                {
                    "sent": "So we want to be good as the best as per experts, but not on typical sequences on any binary sequence.",
                    "label": 0
                },
                {
                    "sent": "OK. Of course, we don't know at the beginning we don't know which which aspect is going to be the best one, so we can sort of watch them and try to, you know, track somehow.",
                    "label": 0
                },
                {
                    "sent": "The best.",
                    "label": 0
                },
                {
                    "sent": "The one that we will be will result will turn out to be the best at the end of our horizon.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we can formalize this prediction with expert advice.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Set up, which is likely more general.",
                    "label": 1
                },
                {
                    "sent": "Maybe we don't want to predict just binary sequences, but we want to predict.",
                    "label": 0
                },
                {
                    "sent": "More complex sequences.",
                    "label": 0
                },
                {
                    "sent": "So we imagine the sequence is now the element of the sequence come from some space Y script Y.",
                    "label": 0
                },
                {
                    "sent": "Can be anything good for now.",
                    "label": 1
                },
                {
                    "sent": "We call it outcome space and predictions of the forecaster P hat.",
                    "label": 0
                },
                {
                    "sent": "We assume are chosen from possibly different space, so outcomes and predictions don't do not necessarily have to come from the same space they come from may come from different spaces.",
                    "label": 1
                },
                {
                    "sent": "OK. And.",
                    "label": 0
                },
                {
                    "sent": "So Script X is this decision space.",
                    "label": 0
                },
                {
                    "sent": "And now we score the forecaster with the function, which we call the loss function L. And this loss function is measuring the discrepancy between each prediction of the forecaster and the true outcome in the sequence.",
                    "label": 0
                },
                {
                    "sent": "For every element of the sequence.",
                    "label": 1
                },
                {
                    "sent": "So we are summing up.",
                    "label": 0
                },
                {
                    "sent": "The losses incured by the forecaster on each prediction at each time step.",
                    "label": 0
                },
                {
                    "sent": "The time step.",
                    "label": 0
                },
                {
                    "sent": "OK, so this loss function is real value loss function which is typically non negative.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Popular loss functions are.",
                    "label": 0
                },
                {
                    "sent": "These ones at 01 loss.",
                    "label": 0
                },
                {
                    "sent": "Which is the one that we used for predicting binary sequences, which is counting just the number of mistakes.",
                    "label": 0
                },
                {
                    "sent": "So in this case X&Y are just the set of binary sets 01.",
                    "label": 0
                },
                {
                    "sent": "And the last is just the indicator function of the event that the prediction is different from the true bit.",
                    "label": 0
                },
                {
                    "sent": "So the bit that is bit predicted, P hat is different from the true, but why?",
                    "label": 0
                },
                {
                    "sent": "In you may also assume that X&Y are the unit.",
                    "label": 0
                },
                {
                    "sent": "Interval of the real line, and in this case the natural law says the quadratic loss.",
                    "label": 0
                },
                {
                    "sent": "P -- P hat minus y ^2.",
                    "label": 0
                },
                {
                    "sent": "Or in case, for instance.",
                    "label": 0
                },
                {
                    "sent": "The axes are reals in the unit interval and wise are either real or maybe binary.",
                    "label": 1
                },
                {
                    "sent": "You also have the absolute loss.",
                    "label": 1
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "He said these are just examples.",
                    "label": 0
                },
                {
                    "sent": "Different examples.",
                    "label": 0
                },
                {
                    "sent": "Well, these losses might be differentiable everywhere, like the quadratic loss.",
                    "label": 0
                },
                {
                    "sent": "Might be convex, like the quadratic of the absolute loss or my body not differentiable, not convex like the 01 loss, so they are very different from each other.",
                    "label": 0
                },
                {
                    "sent": "Then OK, now here is the here.",
                    "label": 0
                },
                {
                    "sent": "How this protocol?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is defined of prediction with expert advice.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "We fixed the set of experts or set of experts a set of N reference forecasters.",
                    "label": 0
                },
                {
                    "sent": "An we predict it in sequential in time steps.",
                    "label": 0
                },
                {
                    "sent": "But every time step T. The forecaster gets the prediction of all the experts in the pool.",
                    "label": 0
                },
                {
                    "sent": "So he asks each expert how will you predict the theater element of this sequence?",
                    "label": 0
                },
                {
                    "sent": "How will you predict Whitey and he gets?",
                    "label": 1
                },
                {
                    "sent": "A prediction for each expert F1, F1, TF2 committee up to F Capital N, T These are leaving the same space as the forecasters predictions and collectively are called the expert advice, so they spent the devices this vector.",
                    "label": 1
                },
                {
                    "sent": "Of predictions of the experts.",
                    "label": 0
                },
                {
                    "sent": "No visit that on this information and on the knowledge of what happened before.",
                    "label": 0
                },
                {
                    "sent": "The forecast of computer prediction PT hat.",
                    "label": 0
                },
                {
                    "sent": "And afterwards, after he has committed to a specific prediction.",
                    "label": 0
                },
                {
                    "sent": "The World environment nature is revealing the tidbit of the sequence Whitey.",
                    "label": 0
                },
                {
                    "sent": "And now the forecaster knows if you made a mistake and also knows.",
                    "label": 0
                },
                {
                    "sent": "How how can you compute his loss in general?",
                    "label": 0
                },
                {
                    "sent": "And it can also compute the loss of all the experts.",
                    "label": 0
                },
                {
                    "sent": "Because he knows the loss of experts.",
                    "label": 0
                },
                {
                    "sent": "I will be just L of FI, TYT.",
                    "label": 0
                },
                {
                    "sent": "And this goes on goes on OK. And.",
                    "label": 0
                },
                {
                    "sent": "Right now you see whatever you may think, OK, but what are you assuming about these experts?",
                    "label": 0
                },
                {
                    "sent": "Where do where do these numbers come from?",
                    "label": 0
                },
                {
                    "sent": "But where does the advice come from?",
                    "label": 0
                },
                {
                    "sent": "Right, we don't want to make any assumption on this.",
                    "label": 0
                },
                {
                    "sent": "So for as experts are really black boxes.",
                    "label": 0
                },
                {
                    "sent": "They can be programs that can be humans.",
                    "label": 0
                },
                {
                    "sent": "That can be magicians.",
                    "label": 0
                },
                {
                    "sent": "They can be dogs, whatever you like.",
                    "label": 0
                },
                {
                    "sent": "If you want to predict the stock market with the dog, you know you can do it, maybe even better than.",
                    "label": 0
                },
                {
                    "sent": "Then very smart people.",
                    "label": 0
                },
                {
                    "sent": "And we just.",
                    "label": 0
                },
                {
                    "sent": "Want to use their advice?",
                    "label": 0
                },
                {
                    "sent": "To compute useful prediction and of course I mean our criterion will be the one that I said before.",
                    "label": 0
                },
                {
                    "sent": "At the end of the day, I want to be.",
                    "label": 0
                },
                {
                    "sent": "As good as bad as the best of my experts.",
                    "label": 0
                },
                {
                    "sent": "Measure it with this loss function.",
                    "label": 0
                },
                {
                    "sent": "No matter what was the sequence of wise, if the sequence of wise is such that everybody is bad, I can be as bad as any of the experts like with random sequences, But if the sequence has some structure and one of the experts is able to capture these structures, just maybe by chance.",
                    "label": 0
                },
                {
                    "sent": "OK. One of these experts.",
                    "label": 0
                },
                {
                    "sent": "Then we really want to to.",
                    "label": 0
                },
                {
                    "sent": "To focus on that good expert and then at the end to have a total accumulative loss.",
                    "label": 0
                },
                {
                    "sent": "Very close, very close to his loss.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's introduce some notation.",
                    "label": 0
                },
                {
                    "sent": "So it's useful.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this case, since we are interested in comparing.",
                    "label": 0
                },
                {
                    "sent": "Our performance with the with the all the experts performances.",
                    "label": 0
                },
                {
                    "sent": "It's useful to lose to look at differences between performances between the performance of the forecaster, the performance of the experts, and we call these differences.",
                    "label": 0
                },
                {
                    "sent": "Regrets Becausw somehow they tell us.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "How much regret we feel for not having followed the advice of a certain expert.",
                    "label": 0
                },
                {
                    "sent": "So, concretely, look at the first line little R. Sub.",
                    "label": 0
                },
                {
                    "sent": "IT is the difference between the loss of the forecaster at empty and the loss of the expert.",
                    "label": 0
                },
                {
                    "sent": "I at time T. So this is how bad I was at time T with respect to expert I, the bigger is the difference, the bigger is my regret for not having followed the prediction of expertise.",
                    "label": 0
                },
                {
                    "sent": "Now we also define the cumulative losses.",
                    "label": 0
                },
                {
                    "sent": "Of the forecaster, which is which is this L hat, so the hats are for the forecasters.",
                    "label": 0
                },
                {
                    "sent": "L had some man is the loss on the 1st N time steps.",
                    "label": 0
                },
                {
                    "sent": "Encouraged by the forecaster, I have a pointer OK. OK. And the Elsa by end is the cumulative loss of expert I on the 1st on the first time time steps.",
                    "label": 0
                },
                {
                    "sent": "And now we can define the regrets after N time steps of the forecaster with respect to the expert as the difference.",
                    "label": 0
                },
                {
                    "sent": "Between the loss of the cumulative loss of the forecaster and the cumulative loss of the expert, which is just by definition, the sum of these instantaneous regrets.",
                    "label": 0
                },
                {
                    "sent": "Every time.",
                    "label": 0
                },
                {
                    "sent": "OK, and what we are really interested in in is in bounding this quantity here.",
                    "label": 0
                },
                {
                    "sent": "So in after any point after any number of predictions.",
                    "label": 0
                },
                {
                    "sent": "We want this maximum regret, which is the difference between the forecasters loss and the loss of the best experts.",
                    "label": 0
                },
                {
                    "sent": "We want to bound it.",
                    "label": 0
                },
                {
                    "sent": "We want to make it as small as possible.",
                    "label": 0
                },
                {
                    "sent": "So this is the key.",
                    "label": 0
                },
                {
                    "sent": "This is the key quantity in our analysis for the first part of this class.",
                    "label": 0
                },
                {
                    "sent": "Which is the difference between the forecast is loss and loss of the best expert on that specific sequence.",
                    "label": 0
                },
                {
                    "sent": "You see the sequences.",
                    "label": 0
                },
                {
                    "sent": "Is this?",
                    "label": 0
                },
                {
                    "sent": "Here is an arbitrary sequence and we want to bound this on any specific sequence.",
                    "label": 0
                },
                {
                    "sent": "So you might say you might now introduce just for a short hand the notion of.",
                    "label": 0
                },
                {
                    "sent": "Consistency we say that the forecast is consistent if the poor.",
                    "label": 0
                },
                {
                    "sent": "Per timestep, regret converges to zero as time goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So in other words.",
                    "label": 0
                },
                {
                    "sent": "We want that the on average.",
                    "label": 0
                },
                {
                    "sent": "With respect to time.",
                    "label": 0
                },
                {
                    "sent": "I do the difference between my performance at the performance on the of the best expert on that sequence goes to zero banishes.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "This clear for everybody.",
                    "label": 0
                },
                {
                    "sent": "And we want to do this for any sequence of outcomes, our wise, but also for all choices of access device.",
                    "label": 1
                },
                {
                    "sent": "So we don't want to make assumption on the experts.",
                    "label": 0
                },
                {
                    "sent": "So these places are just black boxes, so we cannot open up this block but these boxes.",
                    "label": 0
                },
                {
                    "sent": "That just there, they spit out predictions at every time step.",
                    "label": 0
                },
                {
                    "sent": "We can't.",
                    "label": 0
                },
                {
                    "sent": "We can't do anything, just we can look those predictions that are spat out but use them.",
                    "label": 0
                },
                {
                    "sent": "But we don't know how these positions are computed.",
                    "label": 0
                },
                {
                    "sent": "So we want to be.",
                    "label": 0
                },
                {
                    "sent": "We want to University quantify also the choice of the experts advice.",
                    "label": 0
                },
                {
                    "sent": "So we are really dependent only on the number of them and on the performance, possibly on their performance.",
                    "label": 0
                },
                {
                    "sent": "Numbers here.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now how do you go about this problem?",
                    "label": 0
                },
                {
                    "sent": "How would you?",
                    "label": 0
                },
                {
                    "sent": "How would you design A forecaster for this problem?",
                    "label": 0
                },
                {
                    "sent": "So again, this is the.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the protocol.",
                    "label": 0
                },
                {
                    "sent": "So you you know the past, you know the the current advice and you have to compute this number.",
                    "label": 0
                },
                {
                    "sent": "How would you compute this number?",
                    "label": 0
                },
                {
                    "sent": "What's this natural way of computing numbers?",
                    "label": 0
                },
                {
                    "sent": "So that so that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can guarantee this.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Anybody has an idea?",
                    "label": 0
                },
                {
                    "sent": "Is just to check that you are awake.",
                    "label": 0
                },
                {
                    "sent": "Is anybody's awake.",
                    "label": 0
                },
                {
                    "sent": "OK, so OK.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not clear, so first of all that I make an assumption to simplify my life.",
                    "label": 0
                },
                {
                    "sent": "Maybe also yours your life.",
                    "label": 0
                },
                {
                    "sent": "I will assume that decision space is a convex subset of Lena space.",
                    "label": 1
                },
                {
                    "sent": "This means that that I can take convex combinations of the prediction of experts and the convex combination is still a valid prediction.",
                    "label": 0
                },
                {
                    "sent": "So the prediction space is convex.",
                    "label": 0
                },
                {
                    "sent": "I can make I can mix predictions and I still get predictions.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a reasonable assumption.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "The idea is that if you want to have a small regret if you want to minimize this maximum.",
                    "label": 0
                },
                {
                    "sent": "This means that you regret us to be small.",
                    "label": 0
                },
                {
                    "sent": "This means that if you have a big regret against a certain expert.",
                    "label": 0
                },
                {
                    "sent": "That's really bad.",
                    "label": 0
                },
                {
                    "sent": "It means that you should have followed that expert more than you did, so that your loss is closer to the loss of that expert and you'll regret is a consequence you regret with respect to that expert is more.",
                    "label": 0
                },
                {
                    "sent": "So a sensible way to do that, OK, I take a weighted average of the expert advice here is the actor expert advisor Tempete.",
                    "label": 0
                },
                {
                    "sent": "I get that you remember, I get that empty before I have to compute my PT hat and at a takeaway to weighted average, which means a convex combination.",
                    "label": 0
                },
                {
                    "sent": "So now this this is meaningful, so these are the prediction of the express.",
                    "label": 0
                },
                {
                    "sent": "It takes some point in the convex Hull of this prediction.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "How do I take?",
                    "label": 0
                },
                {
                    "sent": "How do I choose the coefficients of these convex combination?",
                    "label": 0
                },
                {
                    "sent": "It makes sense since I want to minimize the largest of the regrets with respectable experts.",
                    "label": 0
                },
                {
                    "sent": "No, it makes sense that I weigh an expert.",
                    "label": 0
                },
                {
                    "sent": "I give more weight to an expert.",
                    "label": 0
                },
                {
                    "sent": "I guess which I have a big regret at that point of time.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is the regret I have a time up to time T -- 1.",
                    "label": 0
                },
                {
                    "sent": "I'm now at time T and I choose my weight proportional to this and to be just flexible.",
                    "label": 1
                },
                {
                    "sent": "I introduce a function new which is a positive monotone increasing function, so it's not doing a stranger games here.",
                    "label": 0
                },
                {
                    "sent": "So this can be the square for instance.",
                    "label": 0
                },
                {
                    "sent": "OK. And I can and I.",
                    "label": 0
                },
                {
                    "sent": "If these are positives, the square of the positive part of this, for instance OK, and this is a reasonable assumption, this is sorry is a reasonable strategy, so it's a general strategy for.",
                    "label": 0
                },
                {
                    "sent": "Computing predictions based on the expert advice and on the past performance of the expert relatively to us so it sort of takes into account all the ingredients in of our protocol.",
                    "label": 1
                },
                {
                    "sent": "And I called this that weighted average forecaster.",
                    "label": 0
                },
                {
                    "sent": "OK. No.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me take another assumption.",
                    "label": 0
                },
                {
                    "sent": "Let's assume that the loss is convex.",
                    "label": 0
                },
                {
                    "sent": "Also, this makes things really nice.",
                    "label": 0
                },
                {
                    "sent": "Maybe you don't like this assumption, but I tell you, this makes things really nice.",
                    "label": 0
                },
                {
                    "sent": "And this doesn't work for the count of mistakes.",
                    "label": 0
                },
                {
                    "sent": "The counter mistakes is not convex.",
                    "label": 0
                },
                {
                    "sent": "Is a step function, so I can't apply this theory.",
                    "label": 0
                },
                {
                    "sent": "If I make this assumption to the to the mistake count, but then I will use other tricks later on to deal with non convex loss functions.",
                    "label": 0
                },
                {
                    "sent": "But for now let's concentrate on convex loss functions.",
                    "label": 0
                },
                {
                    "sent": "So we're interested in comics convexity in this argument.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "So now if this loss function is convex then I can write this equal.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "City.",
                    "label": 0
                },
                {
                    "sent": "Sorry I can.",
                    "label": 0
                },
                {
                    "sent": "I can write the lawsuit empty.",
                    "label": 0
                },
                {
                    "sent": "Of the forecaster.",
                    "label": 0
                },
                {
                    "sent": "Now if I'm using the weighted average forecaster, now expand the PT hat using the definition.",
                    "label": 0
                },
                {
                    "sent": "And now since Alice comics by Jen's inequality, I can pull the loss inside the average and get this.",
                    "label": 0
                },
                {
                    "sent": "So I have the loss of time T of this weighted average forecaster is at most this convex combination.",
                    "label": 0
                },
                {
                    "sent": "Here is the cosmos the convex combination of the losses of the experts.",
                    "label": 0
                },
                {
                    "sent": "OK, well why is this interesting?",
                    "label": 0
                },
                {
                    "sent": "OK, now we know that the difference between these two things one appears here and one appears here is the instantaneous regret at time T with respect to expect.",
                    "label": 0
                },
                {
                    "sent": "I now if I take this on this side and rearrange and you can see it, I get something like this.",
                    "label": 0
                },
                {
                    "sent": "This is what this is, a property that holds for.",
                    "label": 0
                },
                {
                    "sent": "The weighted average forecaster irrespective to the choice of Y of the element.",
                    "label": 0
                },
                {
                    "sent": "I have to predict at time T and irrespective to the way the experts behave, behave.",
                    "label": 0
                },
                {
                    "sent": "This is really an invariant of this weighted average forecasting strategy.",
                    "label": 0
                },
                {
                    "sent": "So now the idea is, can we use this invariant to prove something interesting about the behavior of this weighted average forecaster?",
                    "label": 0
                },
                {
                    "sent": "Of course the answer is yes.",
                    "label": 0
                },
                {
                    "sent": "And now I'm going to.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show how to use this invariant to prove things about this, the forecaster.",
                    "label": 0
                },
                {
                    "sent": "OK, we're still general.",
                    "label": 0
                },
                {
                    "sent": "We're in a variable generation scenario and now I'm getting a little bit more general.",
                    "label": 0
                },
                {
                    "sent": "But afterwards I will make a concrete examples of things.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me be a little more general now, becausw.",
                    "label": 0
                },
                {
                    "sent": "I I have I can afford it, so why not?",
                    "label": 0
                },
                {
                    "sent": "So first of all, for some reason that will be clear hopefully later.",
                    "label": 0
                },
                {
                    "sent": "I am you remember this function knew this function you.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the is the flexibility that we have introduced the in waiting they regret of the computing?",
                    "label": 0
                },
                {
                    "sent": "The weights of the experts.",
                    "label": 0
                },
                {
                    "sent": "So we are our prediction is proportional to the regret but proportional to a function mu.",
                    "label": 0
                },
                {
                    "sent": "No, because I'm because I like it.",
                    "label": 0
                },
                {
                    "sent": "I would like to write this function new as a derivative of a function 5.",
                    "label": 0
                },
                {
                    "sent": "Which is a function on the reals which are assumed to be non negative.",
                    "label": 0
                },
                {
                    "sent": "Nondecreasing and such that it has a it is twice differentiable everywhere.",
                    "label": 0
                },
                {
                    "sent": "OK. Now of course I can rewrite the weighted average forecaster with the five primes, replacing the news.",
                    "label": 0
                },
                {
                    "sent": "No, no big deal.",
                    "label": 0
                },
                {
                    "sent": "But now I can see this as an instance of a more general thing.",
                    "label": 0
                },
                {
                    "sent": "Indeed I can.",
                    "label": 0
                },
                {
                    "sent": "I can introduce what is called the potential functions.",
                    "label": 0
                },
                {
                    "sent": "So introducing potentials is always nice becausw you know that many smart people prove it into the interesting things using potentials, so you're hoping to be in the same good group of people and you have some analogies.",
                    "label": 0
                },
                {
                    "sent": "You can draw analogies from dynamical systems, physics and stuff.",
                    "label": 0
                },
                {
                    "sent": "So I'm kidding of course, but maybe a little bit I will do, and so I can define this potential function, which is a function defined on the space of regret.",
                    "label": 0
                },
                {
                    "sent": "So now let's see.",
                    "label": 0
                },
                {
                    "sent": "You see, you see these are.",
                    "label": 0
                },
                {
                    "sent": "You can view these things as component of a big vector.",
                    "label": 0
                },
                {
                    "sent": "A vector of of elements I.",
                    "label": 0
                },
                {
                    "sent": "So I can view now, a picture will come to show you I can view.",
                    "label": 0
                },
                {
                    "sent": "The regret against each individual expert as a vector.",
                    "label": 0
                },
                {
                    "sent": "In a space air are capital N, where N is the number of experts.",
                    "label": 0
                },
                {
                    "sent": "And I can define this function on this space which is made up of our face whose derivatives appear here, and another guy's eye, which is again affection on the real non non decreasing stick, strictly increasing and concave.",
                    "label": 0
                },
                {
                    "sent": "Note this is not convex, but this has to be concave form.",
                    "label": 0
                },
                {
                    "sent": "So why is this OK?",
                    "label": 0
                },
                {
                    "sent": "So now with this definition, just because I made things a little bit more complicated, I can write.",
                    "label": 0
                },
                {
                    "sent": "The prediction.",
                    "label": 0
                },
                {
                    "sent": "Of the weighted average forecaster, as.",
                    "label": 0
                },
                {
                    "sent": "Using the gradients of this potential function Phi.",
                    "label": 0
                },
                {
                    "sent": "So this is the IAST component of the gradient.",
                    "label": 0
                },
                {
                    "sent": "And this is the JS component of the grant.",
                    "label": 0
                },
                {
                    "sent": "You say, why?",
                    "label": 0
                },
                {
                    "sent": "What now the grid?",
                    "label": 0
                },
                {
                    "sent": "You get the gradient.",
                    "label": 0
                },
                {
                    "sent": "I get the gradient because before I had the five primes.",
                    "label": 0
                },
                {
                    "sent": "Now if I take the gradient of this I get side prime and then I get 5 prime.",
                    "label": 0
                },
                {
                    "sent": "But the fight primes simplify because I get a five prime here and define prime of the same thing.",
                    "label": 0
                },
                {
                    "sent": "Up here I simplify those M left it with this.",
                    "label": 0
                },
                {
                    "sent": "So now you say, but why do we introduce the file if they don't?",
                    "label": 0
                },
                {
                    "sent": "If they simplify in the prediction because they will be useful in the analysis.",
                    "label": 0
                },
                {
                    "sent": "OK, analysis is should be simple, simple enough so that you can appreciate that.",
                    "label": 0
                },
                {
                    "sent": "So now I can write these weighted average forecaster using this gradient of the regrets.",
                    "label": 0
                },
                {
                    "sent": "And this condition here, because the the invariant I had before.",
                    "label": 0
                },
                {
                    "sent": "Now we run.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rights in this way.",
                    "label": 0
                },
                {
                    "sent": "So basically says that the inner product between the gradient of the of the potential of the regret at time T -- 1 and the the vector of distant enemies regret that empty is more than zero.",
                    "label": 1
                },
                {
                    "sent": "So this vector here is the vector whose components are these, so this is the vector of the cumulative regrets.",
                    "label": 0
                },
                {
                    "sent": "And this is the vector of instantaneous regrets.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is called for historical reasons, is called Blackwell condition, but it's not really condition.",
                    "label": 0
                },
                {
                    "sent": "Now is the property is a property of the weighted average forecasters forecaster using these.",
                    "label": 0
                },
                {
                    "sent": "These potential functions.",
                    "label": 0
                },
                {
                    "sent": "OK, so now.",
                    "label": 0
                },
                {
                    "sent": "Comes a picture.",
                    "label": 0
                },
                {
                    "sent": "So this is a picture showing a little bit of the geometrical intuition you see now.",
                    "label": 0
                },
                {
                    "sent": "Things boil down to geometry here, so now I can hope to draw geometrical intuition from this writing at this notion of potential, so that I can come up with a sensible analysis of this forecast.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After so, now here is the case in which I have two experts.",
                    "label": 0
                },
                {
                    "sent": "So I have two coordinates in my vectors and this is the regret space.",
                    "label": 0
                },
                {
                    "sent": "So this is my cumulative regret at some time T which is not shown.",
                    "label": 0
                },
                {
                    "sent": "This is the cumulative regret.",
                    "label": 0
                },
                {
                    "sent": "And this is the well, is the potential the isopotential line passing through this regret.",
                    "label": 0
                },
                {
                    "sent": "So you can imagine at this stage you can imagine the potential as a bowl.",
                    "label": 0
                },
                {
                    "sent": "Is a bowl in this space?",
                    "label": 0
                },
                {
                    "sent": "Is it also it's it's the value of the potential is the third coordinate that sticks out, so you have a bowl.",
                    "label": 0
                },
                {
                    "sent": "This is the contour of the ball, the zero.",
                    "label": 0
                },
                {
                    "sent": "The ball is here.",
                    "label": 0
                },
                {
                    "sent": "And your.",
                    "label": 0
                },
                {
                    "sent": "The idea is that you want to keep these things as close to as possible to the negative part.",
                    "label": 0
                },
                {
                    "sent": "Of the system of coordinate, why you remember?",
                    "label": 0
                },
                {
                    "sent": "Your goal is.",
                    "label": 0
                },
                {
                    "sent": "Your goal is to keep these things small so that the average of these things goes to zero asymptotically.",
                    "label": 0
                },
                {
                    "sent": "So these are now are the coordinates in our space, so this thing.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This vector, if you write it as a vector has to be small in each coordinate.",
                    "label": 0
                },
                {
                    "sent": "So this means that.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I want to have this point as close as possible to the zero or to the negative orthant of this system.",
                    "label": 0
                },
                {
                    "sent": "Accordingly, because this is very great, so it's really has to be pushed down, but.",
                    "label": 0
                },
                {
                    "sent": "So what does now?",
                    "label": 0
                },
                {
                    "sent": "What is the geometrical significance significance of the black hole condition?",
                    "label": 0
                },
                {
                    "sent": "So I can take the gradient, the value of the gradient vector at this point will point in this direction.",
                    "label": 0
                },
                {
                    "sent": "Because this is the the orthogonal to the tangent of the potential at this point.",
                    "label": 0
                },
                {
                    "sent": "And now the fact that.",
                    "label": 0
                },
                {
                    "sent": "The increment in the cumulative regret, which is the older cumulative regret plus the new regret I'm going to.",
                    "label": 0
                },
                {
                    "sent": "I'm going to get after the prediction Attende has to live in this half space over here.",
                    "label": 0
                },
                {
                    "sent": "Why is that becausw?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The fact that this inner product is negative means that the angle between the gradient vector and the new instantaneous regret vector is bigger than a 90 degrees.",
                    "label": 0
                },
                {
                    "sent": "The angle between these two vectors so.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This new vector should point below here, so the potential can grow with time because it can be over here.",
                    "label": 0
                },
                {
                    "sent": "But can grow too much, can grow like crazy like this.",
                    "label": 0
                },
                {
                    "sent": "So this is how we can may hope to use.",
                    "label": 0
                }
            ]
        }
    }
}