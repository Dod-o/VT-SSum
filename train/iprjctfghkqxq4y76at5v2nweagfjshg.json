{
    "id": "iprjctfghkqxq4y76at5v2nweagfjshg",
    "title": "Graph mincut, transductive inference and spectral clustering: some new elements",
    "info": {
        "author": [
            "Kristiaan Pelckmans, KU Leuven"
        ],
        "published": "July 28, 2007",
        "recorded": "July 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Clustering"
        ]
    },
    "url": "http://videolectures.net/srmc07_pelckmans_kristiaan_gmti/",
    "segmentation": [
        [
            "Hi there, so my name is Christian Appelmans.",
            "I'm from the University also of living in Belgium and I'm happy to present my work here so my work area is really transductive inference, but I think there are lots of things to learn from constructive inference.",
            "If you talk about clustering, and in particular towards stability for clustering.",
            "OK, so."
        ],
        [
            "We got a little bit an overview of the other doctor.",
            "I will start with some generalities which I think might be interesting to consider, and then I will start off with a more specific setting so the settings you know rather specific.",
            "It's not like clustering in very general way, but it goes through with respect to transductive inference, or then I will talk a little bit about OK. What's hypothesis space with a good hypothesis space?",
            "What's hypothesis based for clustering?",
            "Is there something you know related going on there?",
            "Some things about stability and I will of course end up with.",
            "I grafman cut things so that's really the bottom line at the end."
        ],
        [
            "I'm.",
            "OK, so yes, my very general slide so hearing all these discussions I think I have to make I can.",
            "I mean summarizing discussion by saying OK if you think about clustering, there's of course this issue of reproducibility, which is basically stability in this setting.",
            "But there should be also a notion counteracting disability, because of course I mean otherwise you can end up with trivial things.",
            "So let's keep the notion of falsifiability is really.",
            "Counter Force to reproducibility.",
            "And I think if you study like stability, falsifiability should be somewhere into the picture there.",
            "So for me, this.",
            "Let's say, um, um.",
            "Notion is a falsifiability.",
            "You can produce.",
            "Ability is really underlying most of the things.",
            "Um, and then I took this notation so falsifiability is property of only an hypothesis.",
            "Reproducibility is a property of the hypothesis.",
            "Break that on the data operated on the distribution generating the data.",
            "You can think of crap with disability.",
            "Also boost evidence, but I think our next talk will talk more about reboost, robustness and stability in relation there.",
            "So falsifiability is basically how surprising the result is.",
            "So there's an easy example of K means where have case one.",
            "Then you know only one single blob.",
            "So the result is not surprising at all.",
            "But if K is fairly large, then I mean then you have some information we so.",
            "Innocence cake captures this falsifiability, but is of course a much broader concept.",
            "But then this notion is very general and notes that it not only includes like clustering, but learning setting in general.",
            "So in order to say something in order to make things form, you have to specify bit.",
            "So I will do that."
        ],
        [
            "The next slide.",
            "So of course if you talk about dusting there, all this nice approaches towards clustering, like vector quantization like negative models, and each one has its own language.",
            "So I think if you want to make things more formal, just pick specific setting.",
            "So in this position I will take the setting of a little bit of image segmentation with image between brackets, because I mean there are many other examples there.",
            "I will, I think it's also worth mentioning that there is this new emerging view on clustering, like like multiple view prediction game where for example many features describing the same effects and you want to do cluster each feature individually and you want to have consistency over features.",
            "So if you have two views on the same object then you can talk about associative clustering.",
            "You want to find rules which reduced from one picture to another.",
            "But if you have many, like many features in your sample, basically features, then you have of course this paper coupon and HB which describes the setting, so I think that's a new other new view on clustering and they of course also other notions like OK.",
            "Question is just organization good for it?",
            "I mean there are many others.",
            "So the basic question I think I think we should be both OK. What's a good tax on me?",
            "It should be made made in order to pick a language too.",
            "Former results.",
            "OK."
        ],
        [
            "So image segmentation, that's really the view and I take a particular view on image segmentation.",
            "I want to relate it at the end to a transductive inference, so learning like supervised learning.",
            "So how do we do it?",
            "OK, you hear this example of a picture, so there are clearly two objects on the picture.",
            "Like to you know camels.",
            "And if you look at the picture you see immediately these two clusters which come up so.",
            "But thinking about this a little bit and you know.",
            "A cautious about what you're doing, so if you look at the picture you focus for the first moment, maybe on the 1st Camel and the second moment you focus on the second demo.",
            "And if you do so, you neglect all the background the other background so.",
            "But the problem of focusing on a particular block like a particular object on the on the picture is basically.",
            "Only problem like OK, I want to classify things as relevant for my focus or not.",
            "So it's basically a learning problem there.",
            "So in this sense you can re late posting to add constructive two to learning and because your work in a final environment.",
            "I mean the pictures there, but there's nothing out there.",
            "So of course you're in the realm of transductive inference.",
            "So this makes sense."
        ],
        [
            "So as I said, is the color particular setting, but it allows us to give us nice formal results.",
            "So what's the intuition there?",
            "So clustering else adjusting as finding apparent structure so apparent structure is something which you can learn fast.",
            "For example, the picture, it's clear that you have two 2 relevant blocks in the picture.",
            "So if you say OK, say something about the first block, then you know you're picking just this particular.",
            "When I lived.",
            "Focus on the objects in the picture I learned from other pictures, but here my.",
            "Import pictures there, not other pictures, so it's a different model which seems to be you're mixing two different models.",
            "When when I learn as a human being.",
            "I want to class in my.",
            "A objects are just fixes here.",
            "Any other pictures?",
            "So they learning is a different level or different.",
            "Yes no, I think there's an answer to this am I think you're right in the sense that you have an intuition of how a picture looks like and you have an intuition of how a cluster looks like, and you gain this intuition by looking at previous pictures so.",
            "Really, I mean, that's that's.",
            "I mean, that's really prior knowledge.",
            "I consider this as prior knowledge.",
            "That's something you have.",
            "In what sense do I?",
            "Look at this picture.",
            "Usually I try to do some sample awesome.",
            "I have the whole day.",
            "Yep.",
            "Yep, that's really the setting of constructive inference in some admitting the distribution free case.",
            "But I mean the classical example.",
            "Say OK, you observe.",
            "So we said OK, this let's zoom in a little bit on this on the environment, and the environment is something you know, because a pixels are related.",
            "I mean you have this this rule basically of pixels which are related should be the same should have the same labeling.",
            "So suppose you zoom in focus on this guy, then you say OK for example here you have a plus one which is pixel which is relevant and then you go to the neighborhood that you follow the lines and that's basically what you learn and you so you don't have to have.",
            "Explicits arm assembly mechanism underlying distinct but you have to have car knowledge.",
            "So, is this distinction really one or?",
            "Is something you can assume.",
            "As I said, OK, I'm in particular setting.",
            "Yep."
        ],
        [
            "OK, so maybe the the.",
            "The intuition a bit further.",
            "So well, OK, I want to see clustering as finding hypothesis and hypothesis space.",
            "So I don't see any labels, so I can't decide which hypothesis to pick.",
            "But clustering is basically looking at the universe and coming up with some possible hypothesis before learning.",
            "So that's my setting.",
            "Um?",
            "So how do I put the space should be interpretable?",
            "Meaning that OK, there are various ways to construct hypothesis space.",
            "But in the cluster environment you want a hypothesis to be to have the same labels over the same clusters.",
            "So there's a notion of cluster wise.",
            "Let's say.",
            "Customize constant hypothesis so if the pixels plus one then hold the whole cluster should be plus one.",
            "So there's this notion of Lost device Constance, please.",
            "OK, so as I said I'm testing this week, yeah?",
            "Focus.",
            "Innocence.",
            "I can learn.",
            "Who?",
            "I will take things more formal in a minute, so I guess you can discuss that, but the basic thing is OK if you are translated setting, it's quite different from the inductive setting, so the inductive setting where your sample really knew points but translate if you have a known universe you have, like a finite number of samples and you have labels which are relevant not relevant.",
            "For example in the case of focus and you observe a few labels and then you want to predict the other guys.",
            "And in the universe.",
            "So in that sense, but I will dig, make things more for monuments.",
            "So you have labeled pixels here, some neighbor pixels, which tells you what is relevant.",
            "No, you don't have.",
            "So in clustering you don't have.",
            "You know labels, right?",
            "Two in an unsupervised way.",
            "Learn figure backgrounds no.",
            "Sure, but the work possibly elect some from your work, so you want to find possible relevant objects.",
            "That's what's about makes sense.",
            "OK."
        ],
        [
            "OK, I got another example just to say OK, it's not specific to image segmentation.",
            "Suppose if Alice and Bob and have a fairly good knowledge on the safe link structure in the world, so they know how counties are related.",
            "They know about Europe then all about USA about for another form, license and so on.",
            "And suppose Alice knows something about about the specific group at the specific flow.",
            "And how is this in?",
            "For example, in Spain, and you know, in Belgium or something and he knows I was in some parts of dealers in USA.",
            "So if both Alice and Bob Cluster the, you know the countries in a certain way they say OK, you have your cluster.",
            "This USA cluster of this Asian cluster.",
            "Then it's fairly easy to communicate about this low.",
            "So that's really the setting.",
            "So you want to learn something.",
            "But clustering is a setting before learning.",
            "Actually, the the actual outcome."
        ],
        [
            "Um?",
            "So, OK, clustering as a stage just before prediction.",
            "So in that case let's we can learn a lot from transductive inference.",
            "So I will go now a little bit more form into the transit constructive inference case and I hope I can answer some of your."
        ],
        [
            "Shooter OK, so as I mentioned you have a fixed amount of notes at OK. We worked with weighted graph, so that's a particular setting so we have for example a fixed amount of nodes and there are organized in Death Mystic graph.",
            "So imagine this image you have only one image, you have only a finite number of nodes.",
            "There are no other images out there, but you can represent this figure as this picture as a graph of course.",
            "So weighted edges no loops mean the classical.",
            "Assumptions and introspective inference.",
            "You say you sample labels from the from the graph, and you want it remaining labels.",
            "So the important issue is that there's no randomness coming into the graph.",
            "The graph is fixed and is out there.",
            "Also, the labels are fixed and out there.",
            "The only randomness is coming in the way you sample nodes.",
            "You sample labels which observe South is a random set of this.",
            "You know of this finite universe, and as is commonly sampled without replacement, so and that helps you with giving you a formal results."
        ],
        [
            "OK, yes, my example environment for metrics.",
            "OK, you have this migrating so every gene hasn't expression profile in some way.",
            "I mean, you can escalate this based on expression profiles of your experiments and you can come up with a big graph.",
            "And suppose you sample a few objects like here.",
            "This one is not relevant.",
            "For example, this one is not Kevin and this one is relevant, so we can try to come up OK.",
            "Which genes which genes are relevant or not.",
            "So in a sense that's really the focus problem.",
            "You said OK, don't focus on this guy.",
            "Don't focus on this guy but focus on this guy and then you have an intuition of your hypothesis space which OK.",
            "But also, neighborhoods should be elephant there."
        ],
        [
            "OK, and now the important thing is of course the hypothesis.",
            "So the hypothesis is really all possible labelings of relevant and not relevant over the finite universe.",
            "So it's a string of minus one.",
            "Once over the universe.",
            "But I mean in general without prior knowledge this set is clearly much to what I mean.",
            "You have to do the end hypothesis which account learn.",
            "So you want to impose some restrictions on prior knowledge which you gain from seeing previous pictures.",
            "As maybe maybe some other prior knowledge on how to restrict this hypothesis really, and so this restriction of iPods set is more or less similar to what people are doing in clustering."
        ],
        [
            "OK, so you want to find a small hypothesis set.",
            "And then you come up can come up with the notion of actual risk and empirical risk.",
            "So actual risk is just the prediction.",
            "OK, the mismatch between your hypothesis and the actual labeling.",
            "The empirical risk is the mismatch, which you observe.",
            "So over South and transactive risk is that.",
            "Those functions is in the indicator, just a mismatch, just the number of bits which are different between your hypothesis in between your actual label.",
            "We talk about clustering.",
            "Sure, OK, most my setting is OK, cluster is.",
            "Incense the stage before learning, so without seeing labels, OK, you want to come up with a plausible hypothesis, and that's really in my setting.",
            "I mean this particular setting that's clustering is about, but it's a particular setting, so it's not in general so, but this gives me some formal results.",
            "That's the line of thinking.",
            "The disk is this one, so the expected mismatch you know.",
            "OK, so go back to the image thing so.",
            "OK, if you.",
            "If you're with people and we talking about this image, then we see clearly two.",
            "You know two blocks.",
            "So if some you know if I say OK, I want to focus on the first one that you say immediately.",
            "You know Bob also say OK, the first one.",
            "This means you know this this block and these are the contours so is fairly good knowledge about if somebody is talking about the first one.",
            "The first one looks like, so that's the loss.",
            "But basically in clustering you don't have labels, so it's the stage before seeing the labels.",
            "But as you know."
        ],
        [
            "I mean, that's the next thing.",
            "So if you come up with a generalization bound then you have, you know you say something about.",
            "Difference between the actual risk transductive risk and tourists and observed risk and sales in terms of the size of the hypothesis.",
            "So if you can cluster fairly well then this hypothesis sets which you which originates from your clustering is fairly plausible hypothesis, which is very convenient under people when talking about you know.",
            "About specific cases like this image.",
            "Sure.",
            "No, no, I mean a follow up.",
            "This statement is really saying OK, yeah, you need small hypothesis set, so let's find an intelligent one.",
            "Let's do clustering.",
            "Because this gives me like a very small hypothesis.",
            "And then I have no labels, so I don't bother about.",
            "You know the term here, but I say OK if you consider clustering as a stage before learning, then this is good thing to do.",
            "Makes sense."
        ],
        [
            "I well and of course you have to know about this.",
            "Basically surfing's inequality.",
            "So the nice thing is that it's not like have this inequality, but here's an correction done for the case that you're working with finite universes.",
            "OK.",
            "So now also in transductive inference.",
            "So we have to we are.",
            "We have to find a good hypothesis.",
            "So what's a good hypothesis set for a given graph?"
        ],
        [
            "These are quite generally marks for the transductive case, but OK, you can come up with a hypothesis which is locally consistent, or which you can predict from your neighborhoods, or you know you will find some hypothesis which can be compressed fairly good to a few.",
            "Labels.",
            "I have other things.",
            "For example, you have also hypothesis which should be stable, meaning that if you sub sample labels you come up at the end with the same hypothesis."
        ],
        [
            "OK, these are fairly general notions.",
            "And so I mean, this is really a matter and attack method.",
            "I mean, it's just up to you."
        ],
        [
            "Which one you pick?",
            "But there are far more measures to do.",
            "You know, to measure the riches of your hypothesis set.",
            "So just you working with finite universes.",
            "So let's consider the cardinality.",
            "Well, it does it fairly good job, but you can do better by considering covering both.",
            "For the you know the hypothesis."
        ],
        [
            "And then you have also like the VC dimension, which is basically the number of.",
            "How notes which can be sheltered and OK, I will give you connection with clustering in a minute."
        ],
        [
            "And the other guy which is, I think, also fairly available to the discussion here, is the other market complexity, which is basically which measure basically how well you can fit noise.",
            "So I will come back."
        ],
        [
            "For that in a minute.",
            "OK, so back to the question story bit.",
            "So OK, there are different ways to construct hypothesis sets and I will mention a few other in minutes, but if you talk about clustering you really want to have that.",
            "Your hypothesis is can be separated in different blocks which can be labeled independently.",
            "So remember the picture.",
            "You have two cameras, you can say the first camera is is irrelevant, I mean irrelevant, it's independent of whether the second camera is relevant or irrelevant.",
            "So you have a notion of.",
            "Digitising your hypothesis over the complete universe.",
            "In in a constant way, so you have a notion of customized constant hypothesis.",
            "So OK this."
        ],
        [
            "Seems quite, you know.",
            "How well do you feel thing to do?",
            "But the nice thing is that if you start considering this hypothesis, then really the PC dimension is the number of clusters you have, so that makes things already a bit more.",
            "I will follow.",
            "I get plus one if you consider the background as another.",
            "Think of it, you can shut up.",
            "No, you don't assume anything for the moment so.",
            "So you can say this hypothesis.",
            "This is this is correct.",
            "If you fix the class.",
            "If I fix the customer and now all I want to do is say which cluster is plus and which cluster is minus, then maybe it's dimensions and number of classes.",
            "This is if we fix the classes.",
            "Zero point.",
            "Search for this doesn't fix it.",
            "I fixed the set of class and then.",
            "Exactly how do I find this cluster and not?",
            "Once I fix this.",
            "Sure, that's after clustering, so I really talking about the stage after you know, I guess you have a pointer.",
            "Space.",
            "Functions as you see I mentioned, which is fine.",
            "Classes.",
            "Can you find out what letters are still out?",
            "So all the points in the same class that should get the same thing.",
            "So now if you want to shuffle a set of points, they have to come from the contract.",
            "Or in other words.",
            "Cyrus but this is another.",
            "Classes will be there already.",
            "Guess your pointer.",
            "But also want to pinpoint the use of the other marker complex in this setting and what's interesting is that the hard market complexity is not the same as the VC dimension, which is just.",
            "I mean in this particular setting, but is dependent on the cluster size.",
            "So and if you think a little bit on the other market complexity, it's really like finding the best assignment of labels in your clustering which fit noise well.",
            "So it's kind of related to the normalization factor us.",
            "You guys, so instead of coming up with this notion of OK uniform random over the convex set which is at work.",
            "So maybe a good idea to consider the other market complexity as a normalization factor.",
            "Just a side remark.",
            "Confusing.",
            "Want to leave clusters in the notion that.",
            "Yep.",
            "Yeah.",
            "Because.",
            "Yep.",
            "But um."
        ],
        [
            "OK, so I'm really talking about the transactive setting and you know, and the connection with the link between crossing.",
            "So I'm not talking about the three innocents.",
            "Because you're correct.",
            "OK, this notion seems arbitrary, but well, it also seems quite deep notion in the sense that OK, if you talk about the graph, there is this notion of VC dimension of a graph which was proposed by house.",
            "Again wells.",
            "I mean, in many people like until I mean many people are investigation investigating this notion and they talk about the notion of a VC dimension of a graph."
        ],
        [
            "But I talk about VC dimension of our hypothesis class, but you easily can come up with a hypothesis class, which is basically the neighborhoods.",
            "Have I put this cost so that the VC dimension corresponds with the notion we use for the fees.",
            "So if we see dimension of hypothesis there.",
            "Um, well, maybe as interesting side teamwork.",
            "So considering like random.",
            "I come across so in this setting only, for example, considering recent papers you have this interesting relation between connectivity of graph.",
            "Basically measuring the expected number of links you make between two nodes and the VC dimension, and then you see that the VC dimension is this entropy like from.",
            "Relation is in this way, so if you have a connectivity which is 0 then you clearly have no VC dimension is like one.",
            "OK, this normalization factors one, but if everything is correct together we have a click and also the VC dimension is fun, but the connectivity really relates to the VC dimension.",
            "So this is interesting if you consider, for example gain nearest neighbor graph.",
            "So you want to determine K in a certain way."
        ],
        [
            "OK so um I I talked about discussed device.",
            "Hypothesis it, but you have also other notions you can say you have this consistency notion, so people in transductive inference like designing algorithm, they come up with this notion of OK, my hypothesis should be locally consistent so but in a graph there's no, you know.",
            "I mean, if you don't consider embedding, you can talk about parameters about things.",
            "So let's just consider.",
            "Locally, consistency based on the nearest neighbor thing.",
            "And the nice thing is that I mean you can consider your graph.",
            "You can execute crisscross minimal spanning Twitter and you have to disconnect at the top level and they just counted number of disconnected parts and then you basically your clusters.",
            "So this really gives you disconnected parts, so this really gives you clusters.",
            "So this is one way to proceed.",
            "I mean, if you think the nearest neighbor one is a good intuition of how to construct a hypothesis that then, well, I think this is the way to go."
        ],
        [
            "But of course, people prefer using them in cut, so let's consider them in cat form for example, and we have a nice result there.",
            "So basically the main cuts is OK in previous slides I said something about one years neighbor graph, But if you consider the average nearest neighbor graph so not to get nearest neighbor but the average nearest neighbor just with the right connections, then doing the multi come up with the algorithm minutes I cartoon.",
            "So your hypothesis is this.",
            "When you consider all labelings over the graph.",
            "Such that you cut the smaller monkey and then there was nice bounds of client work and achieve your bank saying OK the VC dimension of HK is gay plus one or it can be expressed in terms of the.",
            "I had the second and third value, but we came up recently together.",
            "I mean, John basically camped there and I wrote things up.",
            "With another band, which is basically counting the number of eggs values of your Capital plus which is small, lanky, and that's your PC dimension, and the proof is quite simple.",
            "But it gives you an alternative to this classical notion of VC dimension of min cut."
        ],
        [
            "Market.",
            "And to end the story of constructive inference, I want to put your attention on a recent results like stability results of finite universes.",
            "So there's this paper of Leon if and he ran in this year and last year quotes and they really talk about stability results.",
            "For finite universes, which is basically this one, so it looks a bit like her things.",
            "But there's is that of the I mean, the classical ratio.",
            "There's be parameter, which is basically the stability between you know any permutation.",
            "Overall, if you're training set and test it.",
            "Gay is basically a measure.",
            "Generating the number of you know independent samples you have."
        ],
        [
            "OK, so I guess many of you are more familiar there.",
            "Now with this result, but there's this nice application towards other matching complexity for transductive inference problem.",
            "So OK, what the hell market complexity in this special setting?",
            "I consider other market complexity as expected value of the supremum of over your hypothesis space and the correlation between your nose and your hypothesis.",
            "Your best hypothesis.",
            "So he marked it in the paper of a young.",
            "If they consider a slightly different hypothesis definition of problematic complexity.",
            "They say the Sigma can be 01 or minus one so but I consider one and minus one only, so the classical setting."
        ],
        [
            "And then you come up, come up with about that.",
            "So basically say OK, you put constructive prediction occurs, can be bounded in terms of allometric complexity plastic correction term.",
            "But there's a negative term there.",
            "And here is also a correction term for the fact that you work in infant universes.",
            "So it is quite different from the results in bitter bottles.",
            "And I mean the source paper because of the correction terms.",
            "They really worked in an inductive setting.",
            "But this gives bound gives you an opportunity to work in the finite universe setting."
        ],
        [
            "So I want to make some remarks for going back to the clustering story there.",
            "So yeah, we have this view on stability of clustering.",
            "As already mentioned a few times that suppose you sample.",
            "Now, let's say you have a data set, or you have a finite universe and your sample randomly.",
            "Then if you can guarantee that you had the distance between the result of your algorithm is smaller than the beta, then you want to have some results.",
            "OK, OK, you also not too far from the expected what you expect to get if you sample.",
            "So this week notion of of.",
            "Stability for clustering.",
            "So it doesn't say something about if it's you know for and going to effect, but it just says something about expected question for this final simple things.",
            "So OK, if you consider that the question in stability for clustering then."
        ],
        [
            "We can of course also apply previous results there, so image disability results.",
            "Basically, the idea is that OK you have this dysfunction between two clusters.",
            "Can you go back home?",
            "So so is expectation over ASM.",
            "Over the counter variable.",
            "So the S and also because of this.",
            "You try to estimate the instability from samples showing you converge.",
            "SMS by distance and you want you to lose it to approximate the expected value.",
            "So.",
            "Finally, sexism.",
            "It's not the expected distance, but OK.",
            "It's the distance from the expected guy.",
            "OK, epsilon.",
            "Sir.",
            "So if you take like expectation is over your draw of your set of labels which you input to the algorithm.",
            "The expectation goes over the OK, it's just a mapping, right?",
            "So the expectation goes over the input, so and then it's not the expected.",
            "Yeah, well, it's.",
            "Is 2 arguments, 2 + 2.",
            "Expectation, so why isn't expectation over?",
            "If you do it expectation for the phone.",
            "Expectation.",
            "Yeah add, I think.",
            "Are you using the clustering which is closest to the expected last night?",
            "How do you?",
            "How do you in order to complete this expectation of country needs some operating?",
            "How to put together we can cluster.",
            "Yes, and I think the result is.",
            "Check.",
            "OK, I think the answer is here.",
            "So you have this D which is the distance between clustering.",
            "So but now we can make things a bit more formal, so I don't say I got to the end, but a bit more formal by considering AC, which is basically coding function which includes your clustering in a bit string and then you can talk about.",
            "You can compare 2 bit strings in certain norm that you can start talking.",
            "However, it will not be translated.",
            "David won't be adjusting, but it's what you expect to get right.",
            "The distance of the question from something which is not, so you're just saying you're converting to what you expect, so you do not say what the expected guys.",
            "We talking about the distance between a of SM which is.",
            "Expectation, which is not the question.",
            "Did you find this?",
            "I'm sure it's the expected.",
            "You know it's the expected value of your the output of your clustering.",
            "Chuck.",
            "This week Yep, Yep.",
            "It is something that will not give me classroom.",
            "Yep, Yep.",
            "Your century does not have to be a validated sure, but then it's not clear whether you want to have a clustering at the end.",
            "You want just convergence results.",
            "Find the distance between something which is a clustering to something which may not be exactly right.",
            "So how do you define?",
            "OK, so you have to assume that you can compare anything of the convex combination of anything which is a cluster, right?",
            "So you have to extend your distance matrix a bit.",
            "Your dear, but that's basically what you're missing, right?",
            "So you can compare essentially what's your expected a?",
            "I mean, if D is brought in, if you can do that.",
            "Brides.",
            "So I think it's.",
            "If you want to use this kind of stability results that you know a way to go, I'm not saying that's the way to go.",
            "I think that's something which can be learned from, you know, the stability results in learning and transductive inference in particular.",
            "OK. Um, yeah, well and then.",
            "So suppose you can come up with a bit string decoding your clustering and this bitstream has some metric meaning.",
            "That's OK. You can essentially talk about not only 0 ones, but also like something in between, which is expected value of certain bit.",
            "So then you can really talk about.",
            "This kind of stability results, but I think that's really the core problem.",
            "Yeah, I guess you're right, you're pinpointing the.",
            "So just say just this way."
        ],
        [
            "Receipt's daughter this one.",
            "OK, so well, and then there's a natural way to encode maybe a clustering by assigned to each point the cluster identity in account go away.",
            "Town.",
            "And of course, if you go to the inductive setting so not finite universe setting, you can use my diamonds.",
            "It's also interesting to note that this paper, an alien, if, as some notions of weak stability, which not, I mean, that should be not a bitter for all possible random draws, but you know, in majority there should be such a bit, so notion which you come up there.",
            "OK."
        ],
        [
            "OK, let's maybe concludes with a smaller example, so this is an example from transductive inference, but I think it shows somehow that you're really really very close to the clustering ID.",
            "So suppose you have like 1000 samples in the organized graph.",
            "You have neighborhood graph, for example.",
            "Add rolled from made from, you know.",
            "But suppose the graph speaks for a moment and suppose you label this guys plus one in this minus one transductive inference finds you all the labels of the other, and it makes a few mistakes of course.",
            "That's classical setting, but you can go even further.",
            "You can say OK, this guys plus one and I only know that there are like 70% of minus one guys and then you can do your also a minute algorithm incorporating this prior knowledge and then you can come up with a division of your.",
            "It's a of your graph which is.",
            "About which is is good.",
            "You also separate both you know.",
            "Clouds so you really learning from 1 sample innocence.",
            "So, and I mean just iterating over.",
            "I mean, just picking a random sample that you see immediately that you're doing closely somehow and imposing some some notion of how big clusters should be."
        ],
        [
            "I think that concludes my arm.",
            "Yeah, my presentation.",
            "Of course, many open topics, and I mean Spain parts, already many issues to be resolved in orders."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hi there, so my name is Christian Appelmans.",
                    "label": 0
                },
                {
                    "sent": "I'm from the University also of living in Belgium and I'm happy to present my work here so my work area is really transductive inference, but I think there are lots of things to learn from constructive inference.",
                    "label": 0
                },
                {
                    "sent": "If you talk about clustering, and in particular towards stability for clustering.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We got a little bit an overview of the other doctor.",
                    "label": 0
                },
                {
                    "sent": "I will start with some generalities which I think might be interesting to consider, and then I will start off with a more specific setting so the settings you know rather specific.",
                    "label": 0
                },
                {
                    "sent": "It's not like clustering in very general way, but it goes through with respect to transductive inference, or then I will talk a little bit about OK. What's hypothesis space with a good hypothesis space?",
                    "label": 0
                },
                {
                    "sent": "What's hypothesis based for clustering?",
                    "label": 0
                },
                {
                    "sent": "Is there something you know related going on there?",
                    "label": 0
                },
                {
                    "sent": "Some things about stability and I will of course end up with.",
                    "label": 0
                },
                {
                    "sent": "I grafman cut things so that's really the bottom line at the end.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "OK, so yes, my very general slide so hearing all these discussions I think I have to make I can.",
                    "label": 1
                },
                {
                    "sent": "I mean summarizing discussion by saying OK if you think about clustering, there's of course this issue of reproducibility, which is basically stability in this setting.",
                    "label": 0
                },
                {
                    "sent": "But there should be also a notion counteracting disability, because of course I mean otherwise you can end up with trivial things.",
                    "label": 0
                },
                {
                    "sent": "So let's keep the notion of falsifiability is really.",
                    "label": 0
                },
                {
                    "sent": "Counter Force to reproducibility.",
                    "label": 0
                },
                {
                    "sent": "And I think if you study like stability, falsifiability should be somewhere into the picture there.",
                    "label": 0
                },
                {
                    "sent": "So for me, this.",
                    "label": 0
                },
                {
                    "sent": "Let's say, um, um.",
                    "label": 0
                },
                {
                    "sent": "Notion is a falsifiability.",
                    "label": 0
                },
                {
                    "sent": "You can produce.",
                    "label": 0
                },
                {
                    "sent": "Ability is really underlying most of the things.",
                    "label": 0
                },
                {
                    "sent": "Um, and then I took this notation so falsifiability is property of only an hypothesis.",
                    "label": 1
                },
                {
                    "sent": "Reproducibility is a property of the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Break that on the data operated on the distribution generating the data.",
                    "label": 1
                },
                {
                    "sent": "You can think of crap with disability.",
                    "label": 0
                },
                {
                    "sent": "Also boost evidence, but I think our next talk will talk more about reboost, robustness and stability in relation there.",
                    "label": 0
                },
                {
                    "sent": "So falsifiability is basically how surprising the result is.",
                    "label": 0
                },
                {
                    "sent": "So there's an easy example of K means where have case one.",
                    "label": 0
                },
                {
                    "sent": "Then you know only one single blob.",
                    "label": 0
                },
                {
                    "sent": "So the result is not surprising at all.",
                    "label": 0
                },
                {
                    "sent": "But if K is fairly large, then I mean then you have some information we so.",
                    "label": 0
                },
                {
                    "sent": "Innocence cake captures this falsifiability, but is of course a much broader concept.",
                    "label": 0
                },
                {
                    "sent": "But then this notion is very general and notes that it not only includes like clustering, but learning setting in general.",
                    "label": 0
                },
                {
                    "sent": "So in order to say something in order to make things form, you have to specify bit.",
                    "label": 0
                },
                {
                    "sent": "So I will do that.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The next slide.",
                    "label": 0
                },
                {
                    "sent": "So of course if you talk about dusting there, all this nice approaches towards clustering, like vector quantization like negative models, and each one has its own language.",
                    "label": 0
                },
                {
                    "sent": "So I think if you want to make things more formal, just pick specific setting.",
                    "label": 0
                },
                {
                    "sent": "So in this position I will take the setting of a little bit of image segmentation with image between brackets, because I mean there are many other examples there.",
                    "label": 1
                },
                {
                    "sent": "I will, I think it's also worth mentioning that there is this new emerging view on clustering, like like multiple view prediction game where for example many features describing the same effects and you want to do cluster each feature individually and you want to have consistency over features.",
                    "label": 1
                },
                {
                    "sent": "So if you have two views on the same object then you can talk about associative clustering.",
                    "label": 0
                },
                {
                    "sent": "You want to find rules which reduced from one picture to another.",
                    "label": 0
                },
                {
                    "sent": "But if you have many, like many features in your sample, basically features, then you have of course this paper coupon and HB which describes the setting, so I think that's a new other new view on clustering and they of course also other notions like OK.",
                    "label": 0
                },
                {
                    "sent": "Question is just organization good for it?",
                    "label": 1
                },
                {
                    "sent": "I mean there are many others.",
                    "label": 0
                },
                {
                    "sent": "So the basic question I think I think we should be both OK. What's a good tax on me?",
                    "label": 0
                },
                {
                    "sent": "It should be made made in order to pick a language too.",
                    "label": 0
                },
                {
                    "sent": "Former results.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So image segmentation, that's really the view and I take a particular view on image segmentation.",
                    "label": 0
                },
                {
                    "sent": "I want to relate it at the end to a transductive inference, so learning like supervised learning.",
                    "label": 0
                },
                {
                    "sent": "So how do we do it?",
                    "label": 0
                },
                {
                    "sent": "OK, you hear this example of a picture, so there are clearly two objects on the picture.",
                    "label": 0
                },
                {
                    "sent": "Like to you know camels.",
                    "label": 0
                },
                {
                    "sent": "And if you look at the picture you see immediately these two clusters which come up so.",
                    "label": 0
                },
                {
                    "sent": "But thinking about this a little bit and you know.",
                    "label": 0
                },
                {
                    "sent": "A cautious about what you're doing, so if you look at the picture you focus for the first moment, maybe on the 1st Camel and the second moment you focus on the second demo.",
                    "label": 0
                },
                {
                    "sent": "And if you do so, you neglect all the background the other background so.",
                    "label": 0
                },
                {
                    "sent": "But the problem of focusing on a particular block like a particular object on the on the picture is basically.",
                    "label": 0
                },
                {
                    "sent": "Only problem like OK, I want to classify things as relevant for my focus or not.",
                    "label": 0
                },
                {
                    "sent": "So it's basically a learning problem there.",
                    "label": 0
                },
                {
                    "sent": "So in this sense you can re late posting to add constructive two to learning and because your work in a final environment.",
                    "label": 0
                },
                {
                    "sent": "I mean the pictures there, but there's nothing out there.",
                    "label": 0
                },
                {
                    "sent": "So of course you're in the realm of transductive inference.",
                    "label": 1
                },
                {
                    "sent": "So this makes sense.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I said, is the color particular setting, but it allows us to give us nice formal results.",
                    "label": 0
                },
                {
                    "sent": "So what's the intuition there?",
                    "label": 0
                },
                {
                    "sent": "So clustering else adjusting as finding apparent structure so apparent structure is something which you can learn fast.",
                    "label": 1
                },
                {
                    "sent": "For example, the picture, it's clear that you have two 2 relevant blocks in the picture.",
                    "label": 0
                },
                {
                    "sent": "So if you say OK, say something about the first block, then you know you're picking just this particular.",
                    "label": 0
                },
                {
                    "sent": "When I lived.",
                    "label": 0
                },
                {
                    "sent": "Focus on the objects in the picture I learned from other pictures, but here my.",
                    "label": 0
                },
                {
                    "sent": "Import pictures there, not other pictures, so it's a different model which seems to be you're mixing two different models.",
                    "label": 0
                },
                {
                    "sent": "When when I learn as a human being.",
                    "label": 0
                },
                {
                    "sent": "I want to class in my.",
                    "label": 0
                },
                {
                    "sent": "A objects are just fixes here.",
                    "label": 0
                },
                {
                    "sent": "Any other pictures?",
                    "label": 0
                },
                {
                    "sent": "So they learning is a different level or different.",
                    "label": 0
                },
                {
                    "sent": "Yes no, I think there's an answer to this am I think you're right in the sense that you have an intuition of how a picture looks like and you have an intuition of how a cluster looks like, and you gain this intuition by looking at previous pictures so.",
                    "label": 0
                },
                {
                    "sent": "Really, I mean, that's that's.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's really prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "I consider this as prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "That's something you have.",
                    "label": 0
                },
                {
                    "sent": "In what sense do I?",
                    "label": 0
                },
                {
                    "sent": "Look at this picture.",
                    "label": 0
                },
                {
                    "sent": "Usually I try to do some sample awesome.",
                    "label": 0
                },
                {
                    "sent": "I have the whole day.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Yep, that's really the setting of constructive inference in some admitting the distribution free case.",
                    "label": 0
                },
                {
                    "sent": "But I mean the classical example.",
                    "label": 0
                },
                {
                    "sent": "Say OK, you observe.",
                    "label": 0
                },
                {
                    "sent": "So we said OK, this let's zoom in a little bit on this on the environment, and the environment is something you know, because a pixels are related.",
                    "label": 0
                },
                {
                    "sent": "I mean you have this this rule basically of pixels which are related should be the same should have the same labeling.",
                    "label": 0
                },
                {
                    "sent": "So suppose you zoom in focus on this guy, then you say OK for example here you have a plus one which is pixel which is relevant and then you go to the neighborhood that you follow the lines and that's basically what you learn and you so you don't have to have.",
                    "label": 0
                },
                {
                    "sent": "Explicits arm assembly mechanism underlying distinct but you have to have car knowledge.",
                    "label": 0
                },
                {
                    "sent": "So, is this distinction really one or?",
                    "label": 0
                },
                {
                    "sent": "Is something you can assume.",
                    "label": 0
                },
                {
                    "sent": "As I said, OK, I'm in particular setting.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so maybe the the.",
                    "label": 0
                },
                {
                    "sent": "The intuition a bit further.",
                    "label": 0
                },
                {
                    "sent": "So well, OK, I want to see clustering as finding hypothesis and hypothesis space.",
                    "label": 1
                },
                {
                    "sent": "So I don't see any labels, so I can't decide which hypothesis to pick.",
                    "label": 1
                },
                {
                    "sent": "But clustering is basically looking at the universe and coming up with some possible hypothesis before learning.",
                    "label": 0
                },
                {
                    "sent": "So that's my setting.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So how do I put the space should be interpretable?",
                    "label": 0
                },
                {
                    "sent": "Meaning that OK, there are various ways to construct hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "But in the cluster environment you want a hypothesis to be to have the same labels over the same clusters.",
                    "label": 0
                },
                {
                    "sent": "So there's a notion of cluster wise.",
                    "label": 0
                },
                {
                    "sent": "Let's say.",
                    "label": 0
                },
                {
                    "sent": "Customize constant hypothesis so if the pixels plus one then hold the whole cluster should be plus one.",
                    "label": 0
                },
                {
                    "sent": "So there's this notion of Lost device Constance, please.",
                    "label": 0
                },
                {
                    "sent": "OK, so as I said I'm testing this week, yeah?",
                    "label": 0
                },
                {
                    "sent": "Focus.",
                    "label": 0
                },
                {
                    "sent": "Innocence.",
                    "label": 0
                },
                {
                    "sent": "I can learn.",
                    "label": 0
                },
                {
                    "sent": "Who?",
                    "label": 0
                },
                {
                    "sent": "I will take things more formal in a minute, so I guess you can discuss that, but the basic thing is OK if you are translated setting, it's quite different from the inductive setting, so the inductive setting where your sample really knew points but translate if you have a known universe you have, like a finite number of samples and you have labels which are relevant not relevant.",
                    "label": 0
                },
                {
                    "sent": "For example in the case of focus and you observe a few labels and then you want to predict the other guys.",
                    "label": 0
                },
                {
                    "sent": "And in the universe.",
                    "label": 0
                },
                {
                    "sent": "So in that sense, but I will dig, make things more for monuments.",
                    "label": 0
                },
                {
                    "sent": "So you have labeled pixels here, some neighbor pixels, which tells you what is relevant.",
                    "label": 0
                },
                {
                    "sent": "No, you don't have.",
                    "label": 0
                },
                {
                    "sent": "So in clustering you don't have.",
                    "label": 0
                },
                {
                    "sent": "You know labels, right?",
                    "label": 0
                },
                {
                    "sent": "Two in an unsupervised way.",
                    "label": 0
                },
                {
                    "sent": "Learn figure backgrounds no.",
                    "label": 0
                },
                {
                    "sent": "Sure, but the work possibly elect some from your work, so you want to find possible relevant objects.",
                    "label": 0
                },
                {
                    "sent": "That's what's about makes sense.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, I got another example just to say OK, it's not specific to image segmentation.",
                    "label": 0
                },
                {
                    "sent": "Suppose if Alice and Bob and have a fairly good knowledge on the safe link structure in the world, so they know how counties are related.",
                    "label": 1
                },
                {
                    "sent": "They know about Europe then all about USA about for another form, license and so on.",
                    "label": 0
                },
                {
                    "sent": "And suppose Alice knows something about about the specific group at the specific flow.",
                    "label": 0
                },
                {
                    "sent": "And how is this in?",
                    "label": 0
                },
                {
                    "sent": "For example, in Spain, and you know, in Belgium or something and he knows I was in some parts of dealers in USA.",
                    "label": 0
                },
                {
                    "sent": "So if both Alice and Bob Cluster the, you know the countries in a certain way they say OK, you have your cluster.",
                    "label": 0
                },
                {
                    "sent": "This USA cluster of this Asian cluster.",
                    "label": 0
                },
                {
                    "sent": "Then it's fairly easy to communicate about this low.",
                    "label": 0
                },
                {
                    "sent": "So that's really the setting.",
                    "label": 0
                },
                {
                    "sent": "So you want to learn something.",
                    "label": 0
                },
                {
                    "sent": "But clustering is a setting before learning.",
                    "label": 0
                },
                {
                    "sent": "Actually, the the actual outcome.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So, OK, clustering as a stage just before prediction.",
                    "label": 0
                },
                {
                    "sent": "So in that case let's we can learn a lot from transductive inference.",
                    "label": 0
                },
                {
                    "sent": "So I will go now a little bit more form into the transit constructive inference case and I hope I can answer some of your.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Shooter OK, so as I mentioned you have a fixed amount of notes at OK. We worked with weighted graph, so that's a particular setting so we have for example a fixed amount of nodes and there are organized in Death Mystic graph.",
                    "label": 1
                },
                {
                    "sent": "So imagine this image you have only one image, you have only a finite number of nodes.",
                    "label": 0
                },
                {
                    "sent": "There are no other images out there, but you can represent this figure as this picture as a graph of course.",
                    "label": 1
                },
                {
                    "sent": "So weighted edges no loops mean the classical.",
                    "label": 1
                },
                {
                    "sent": "Assumptions and introspective inference.",
                    "label": 0
                },
                {
                    "sent": "You say you sample labels from the from the graph, and you want it remaining labels.",
                    "label": 0
                },
                {
                    "sent": "So the important issue is that there's no randomness coming into the graph.",
                    "label": 0
                },
                {
                    "sent": "The graph is fixed and is out there.",
                    "label": 0
                },
                {
                    "sent": "Also, the labels are fixed and out there.",
                    "label": 0
                },
                {
                    "sent": "The only randomness is coming in the way you sample nodes.",
                    "label": 0
                },
                {
                    "sent": "You sample labels which observe South is a random set of this.",
                    "label": 0
                },
                {
                    "sent": "You know of this finite universe, and as is commonly sampled without replacement, so and that helps you with giving you a formal results.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, yes, my example environment for metrics.",
                    "label": 0
                },
                {
                    "sent": "OK, you have this migrating so every gene hasn't expression profile in some way.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can escalate this based on expression profiles of your experiments and you can come up with a big graph.",
                    "label": 0
                },
                {
                    "sent": "And suppose you sample a few objects like here.",
                    "label": 0
                },
                {
                    "sent": "This one is not relevant.",
                    "label": 0
                },
                {
                    "sent": "For example, this one is not Kevin and this one is relevant, so we can try to come up OK.",
                    "label": 0
                },
                {
                    "sent": "Which genes which genes are relevant or not.",
                    "label": 0
                },
                {
                    "sent": "So in a sense that's really the focus problem.",
                    "label": 0
                },
                {
                    "sent": "You said OK, don't focus on this guy.",
                    "label": 0
                },
                {
                    "sent": "Don't focus on this guy but focus on this guy and then you have an intuition of your hypothesis space which OK.",
                    "label": 0
                },
                {
                    "sent": "But also, neighborhoods should be elephant there.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and now the important thing is of course the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So the hypothesis is really all possible labelings of relevant and not relevant over the finite universe.",
                    "label": 0
                },
                {
                    "sent": "So it's a string of minus one.",
                    "label": 0
                },
                {
                    "sent": "Once over the universe.",
                    "label": 0
                },
                {
                    "sent": "But I mean in general without prior knowledge this set is clearly much to what I mean.",
                    "label": 0
                },
                {
                    "sent": "You have to do the end hypothesis which account learn.",
                    "label": 0
                },
                {
                    "sent": "So you want to impose some restrictions on prior knowledge which you gain from seeing previous pictures.",
                    "label": 0
                },
                {
                    "sent": "As maybe maybe some other prior knowledge on how to restrict this hypothesis really, and so this restriction of iPods set is more or less similar to what people are doing in clustering.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so you want to find a small hypothesis set.",
                    "label": 1
                },
                {
                    "sent": "And then you come up can come up with the notion of actual risk and empirical risk.",
                    "label": 1
                },
                {
                    "sent": "So actual risk is just the prediction.",
                    "label": 0
                },
                {
                    "sent": "OK, the mismatch between your hypothesis and the actual labeling.",
                    "label": 0
                },
                {
                    "sent": "The empirical risk is the mismatch, which you observe.",
                    "label": 0
                },
                {
                    "sent": "So over South and transactive risk is that.",
                    "label": 0
                },
                {
                    "sent": "Those functions is in the indicator, just a mismatch, just the number of bits which are different between your hypothesis in between your actual label.",
                    "label": 0
                },
                {
                    "sent": "We talk about clustering.",
                    "label": 0
                },
                {
                    "sent": "Sure, OK, most my setting is OK, cluster is.",
                    "label": 0
                },
                {
                    "sent": "Incense the stage before learning, so without seeing labels, OK, you want to come up with a plausible hypothesis, and that's really in my setting.",
                    "label": 0
                },
                {
                    "sent": "I mean this particular setting that's clustering is about, but it's a particular setting, so it's not in general so, but this gives me some formal results.",
                    "label": 0
                },
                {
                    "sent": "That's the line of thinking.",
                    "label": 0
                },
                {
                    "sent": "The disk is this one, so the expected mismatch you know.",
                    "label": 0
                },
                {
                    "sent": "OK, so go back to the image thing so.",
                    "label": 0
                },
                {
                    "sent": "OK, if you.",
                    "label": 0
                },
                {
                    "sent": "If you're with people and we talking about this image, then we see clearly two.",
                    "label": 0
                },
                {
                    "sent": "You know two blocks.",
                    "label": 0
                },
                {
                    "sent": "So if some you know if I say OK, I want to focus on the first one that you say immediately.",
                    "label": 0
                },
                {
                    "sent": "You know Bob also say OK, the first one.",
                    "label": 0
                },
                {
                    "sent": "This means you know this this block and these are the contours so is fairly good knowledge about if somebody is talking about the first one.",
                    "label": 0
                },
                {
                    "sent": "The first one looks like, so that's the loss.",
                    "label": 0
                },
                {
                    "sent": "But basically in clustering you don't have labels, so it's the stage before seeing the labels.",
                    "label": 0
                },
                {
                    "sent": "But as you know.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean, that's the next thing.",
                    "label": 0
                },
                {
                    "sent": "So if you come up with a generalization bound then you have, you know you say something about.",
                    "label": 0
                },
                {
                    "sent": "Difference between the actual risk transductive risk and tourists and observed risk and sales in terms of the size of the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So if you can cluster fairly well then this hypothesis sets which you which originates from your clustering is fairly plausible hypothesis, which is very convenient under people when talking about you know.",
                    "label": 0
                },
                {
                    "sent": "About specific cases like this image.",
                    "label": 0
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "No, no, I mean a follow up.",
                    "label": 0
                },
                {
                    "sent": "This statement is really saying OK, yeah, you need small hypothesis set, so let's find an intelligent one.",
                    "label": 0
                },
                {
                    "sent": "Let's do clustering.",
                    "label": 0
                },
                {
                    "sent": "Because this gives me like a very small hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And then I have no labels, so I don't bother about.",
                    "label": 0
                },
                {
                    "sent": "You know the term here, but I say OK if you consider clustering as a stage before learning, then this is good thing to do.",
                    "label": 0
                },
                {
                    "sent": "Makes sense.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I well and of course you have to know about this.",
                    "label": 0
                },
                {
                    "sent": "Basically surfing's inequality.",
                    "label": 0
                },
                {
                    "sent": "So the nice thing is that it's not like have this inequality, but here's an correction done for the case that you're working with finite universes.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now also in transductive inference.",
                    "label": 0
                },
                {
                    "sent": "So we have to we are.",
                    "label": 0
                },
                {
                    "sent": "We have to find a good hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So what's a good hypothesis set for a given graph?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These are quite generally marks for the transductive case, but OK, you can come up with a hypothesis which is locally consistent, or which you can predict from your neighborhoods, or you know you will find some hypothesis which can be compressed fairly good to a few.",
                    "label": 1
                },
                {
                    "sent": "Labels.",
                    "label": 0
                },
                {
                    "sent": "I have other things.",
                    "label": 1
                },
                {
                    "sent": "For example, you have also hypothesis which should be stable, meaning that if you sub sample labels you come up at the end with the same hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, these are fairly general notions.",
                    "label": 0
                },
                {
                    "sent": "And so I mean, this is really a matter and attack method.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's just up to you.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which one you pick?",
                    "label": 0
                },
                {
                    "sent": "But there are far more measures to do.",
                    "label": 0
                },
                {
                    "sent": "You know, to measure the riches of your hypothesis set.",
                    "label": 0
                },
                {
                    "sent": "So just you working with finite universes.",
                    "label": 0
                },
                {
                    "sent": "So let's consider the cardinality.",
                    "label": 0
                },
                {
                    "sent": "Well, it does it fairly good job, but you can do better by considering covering both.",
                    "label": 0
                },
                {
                    "sent": "For the you know the hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you have also like the VC dimension, which is basically the number of.",
                    "label": 0
                },
                {
                    "sent": "How notes which can be sheltered and OK, I will give you connection with clustering in a minute.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the other guy which is, I think, also fairly available to the discussion here, is the other market complexity, which is basically which measure basically how well you can fit noise.",
                    "label": 0
                },
                {
                    "sent": "So I will come back.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For that in a minute.",
                    "label": 0
                },
                {
                    "sent": "OK, so back to the question story bit.",
                    "label": 0
                },
                {
                    "sent": "So OK, there are different ways to construct hypothesis sets and I will mention a few other in minutes, but if you talk about clustering you really want to have that.",
                    "label": 0
                },
                {
                    "sent": "Your hypothesis is can be separated in different blocks which can be labeled independently.",
                    "label": 0
                },
                {
                    "sent": "So remember the picture.",
                    "label": 0
                },
                {
                    "sent": "You have two cameras, you can say the first camera is is irrelevant, I mean irrelevant, it's independent of whether the second camera is relevant or irrelevant.",
                    "label": 0
                },
                {
                    "sent": "So you have a notion of.",
                    "label": 0
                },
                {
                    "sent": "Digitising your hypothesis over the complete universe.",
                    "label": 0
                },
                {
                    "sent": "In in a constant way, so you have a notion of customized constant hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So OK this.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Seems quite, you know.",
                    "label": 0
                },
                {
                    "sent": "How well do you feel thing to do?",
                    "label": 0
                },
                {
                    "sent": "But the nice thing is that if you start considering this hypothesis, then really the PC dimension is the number of clusters you have, so that makes things already a bit more.",
                    "label": 0
                },
                {
                    "sent": "I will follow.",
                    "label": 0
                },
                {
                    "sent": "I get plus one if you consider the background as another.",
                    "label": 0
                },
                {
                    "sent": "Think of it, you can shut up.",
                    "label": 0
                },
                {
                    "sent": "No, you don't assume anything for the moment so.",
                    "label": 0
                },
                {
                    "sent": "So you can say this hypothesis.",
                    "label": 0
                },
                {
                    "sent": "This is this is correct.",
                    "label": 0
                },
                {
                    "sent": "If you fix the class.",
                    "label": 0
                },
                {
                    "sent": "If I fix the customer and now all I want to do is say which cluster is plus and which cluster is minus, then maybe it's dimensions and number of classes.",
                    "label": 0
                },
                {
                    "sent": "This is if we fix the classes.",
                    "label": 0
                },
                {
                    "sent": "Zero point.",
                    "label": 0
                },
                {
                    "sent": "Search for this doesn't fix it.",
                    "label": 0
                },
                {
                    "sent": "I fixed the set of class and then.",
                    "label": 0
                },
                {
                    "sent": "Exactly how do I find this cluster and not?",
                    "label": 0
                },
                {
                    "sent": "Once I fix this.",
                    "label": 0
                },
                {
                    "sent": "Sure, that's after clustering, so I really talking about the stage after you know, I guess you have a pointer.",
                    "label": 0
                },
                {
                    "sent": "Space.",
                    "label": 0
                },
                {
                    "sent": "Functions as you see I mentioned, which is fine.",
                    "label": 0
                },
                {
                    "sent": "Classes.",
                    "label": 0
                },
                {
                    "sent": "Can you find out what letters are still out?",
                    "label": 0
                },
                {
                    "sent": "So all the points in the same class that should get the same thing.",
                    "label": 0
                },
                {
                    "sent": "So now if you want to shuffle a set of points, they have to come from the contract.",
                    "label": 0
                },
                {
                    "sent": "Or in other words.",
                    "label": 0
                },
                {
                    "sent": "Cyrus but this is another.",
                    "label": 0
                },
                {
                    "sent": "Classes will be there already.",
                    "label": 0
                },
                {
                    "sent": "Guess your pointer.",
                    "label": 0
                },
                {
                    "sent": "But also want to pinpoint the use of the other marker complex in this setting and what's interesting is that the hard market complexity is not the same as the VC dimension, which is just.",
                    "label": 0
                },
                {
                    "sent": "I mean in this particular setting, but is dependent on the cluster size.",
                    "label": 1
                },
                {
                    "sent": "So and if you think a little bit on the other market complexity, it's really like finding the best assignment of labels in your clustering which fit noise well.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of related to the normalization factor us.",
                    "label": 1
                },
                {
                    "sent": "You guys, so instead of coming up with this notion of OK uniform random over the convex set which is at work.",
                    "label": 0
                },
                {
                    "sent": "So maybe a good idea to consider the other market complexity as a normalization factor.",
                    "label": 0
                },
                {
                    "sent": "Just a side remark.",
                    "label": 0
                },
                {
                    "sent": "Confusing.",
                    "label": 0
                },
                {
                    "sent": "Want to leave clusters in the notion that.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Because.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "But um.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm really talking about the transactive setting and you know, and the connection with the link between crossing.",
                    "label": 0
                },
                {
                    "sent": "So I'm not talking about the three innocents.",
                    "label": 0
                },
                {
                    "sent": "Because you're correct.",
                    "label": 0
                },
                {
                    "sent": "OK, this notion seems arbitrary, but well, it also seems quite deep notion in the sense that OK, if you talk about the graph, there is this notion of VC dimension of a graph which was proposed by house.",
                    "label": 0
                },
                {
                    "sent": "Again wells.",
                    "label": 0
                },
                {
                    "sent": "I mean, in many people like until I mean many people are investigation investigating this notion and they talk about the notion of a VC dimension of a graph.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I talk about VC dimension of our hypothesis class, but you easily can come up with a hypothesis class, which is basically the neighborhoods.",
                    "label": 0
                },
                {
                    "sent": "Have I put this cost so that the VC dimension corresponds with the notion we use for the fees.",
                    "label": 0
                },
                {
                    "sent": "So if we see dimension of hypothesis there.",
                    "label": 0
                },
                {
                    "sent": "Um, well, maybe as interesting side teamwork.",
                    "label": 0
                },
                {
                    "sent": "So considering like random.",
                    "label": 0
                },
                {
                    "sent": "I come across so in this setting only, for example, considering recent papers you have this interesting relation between connectivity of graph.",
                    "label": 0
                },
                {
                    "sent": "Basically measuring the expected number of links you make between two nodes and the VC dimension, and then you see that the VC dimension is this entropy like from.",
                    "label": 0
                },
                {
                    "sent": "Relation is in this way, so if you have a connectivity which is 0 then you clearly have no VC dimension is like one.",
                    "label": 0
                },
                {
                    "sent": "OK, this normalization factors one, but if everything is correct together we have a click and also the VC dimension is fun, but the connectivity really relates to the VC dimension.",
                    "label": 0
                },
                {
                    "sent": "So this is interesting if you consider, for example gain nearest neighbor graph.",
                    "label": 0
                },
                {
                    "sent": "So you want to determine K in a certain way.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so um I I talked about discussed device.",
                    "label": 0
                },
                {
                    "sent": "Hypothesis it, but you have also other notions you can say you have this consistency notion, so people in transductive inference like designing algorithm, they come up with this notion of OK, my hypothesis should be locally consistent so but in a graph there's no, you know.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you don't consider embedding, you can talk about parameters about things.",
                    "label": 0
                },
                {
                    "sent": "So let's just consider.",
                    "label": 0
                },
                {
                    "sent": "Locally, consistency based on the nearest neighbor thing.",
                    "label": 0
                },
                {
                    "sent": "And the nice thing is that I mean you can consider your graph.",
                    "label": 0
                },
                {
                    "sent": "You can execute crisscross minimal spanning Twitter and you have to disconnect at the top level and they just counted number of disconnected parts and then you basically your clusters.",
                    "label": 0
                },
                {
                    "sent": "So this really gives you disconnected parts, so this really gives you clusters.",
                    "label": 0
                },
                {
                    "sent": "So this is one way to proceed.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you think the nearest neighbor one is a good intuition of how to construct a hypothesis that then, well, I think this is the way to go.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But of course, people prefer using them in cut, so let's consider them in cat form for example, and we have a nice result there.",
                    "label": 0
                },
                {
                    "sent": "So basically the main cuts is OK in previous slides I said something about one years neighbor graph, But if you consider the average nearest neighbor graph so not to get nearest neighbor but the average nearest neighbor just with the right connections, then doing the multi come up with the algorithm minutes I cartoon.",
                    "label": 0
                },
                {
                    "sent": "So your hypothesis is this.",
                    "label": 0
                },
                {
                    "sent": "When you consider all labelings over the graph.",
                    "label": 0
                },
                {
                    "sent": "Such that you cut the smaller monkey and then there was nice bounds of client work and achieve your bank saying OK the VC dimension of HK is gay plus one or it can be expressed in terms of the.",
                    "label": 0
                },
                {
                    "sent": "I had the second and third value, but we came up recently together.",
                    "label": 0
                },
                {
                    "sent": "I mean, John basically camped there and I wrote things up.",
                    "label": 0
                },
                {
                    "sent": "With another band, which is basically counting the number of eggs values of your Capital plus which is small, lanky, and that's your PC dimension, and the proof is quite simple.",
                    "label": 0
                },
                {
                    "sent": "But it gives you an alternative to this classical notion of VC dimension of min cut.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Market.",
                    "label": 0
                },
                {
                    "sent": "And to end the story of constructive inference, I want to put your attention on a recent results like stability results of finite universes.",
                    "label": 0
                },
                {
                    "sent": "So there's this paper of Leon if and he ran in this year and last year quotes and they really talk about stability results.",
                    "label": 0
                },
                {
                    "sent": "For finite universes, which is basically this one, so it looks a bit like her things.",
                    "label": 0
                },
                {
                    "sent": "But there's is that of the I mean, the classical ratio.",
                    "label": 0
                },
                {
                    "sent": "There's be parameter, which is basically the stability between you know any permutation.",
                    "label": 0
                },
                {
                    "sent": "Overall, if you're training set and test it.",
                    "label": 0
                },
                {
                    "sent": "Gay is basically a measure.",
                    "label": 0
                },
                {
                    "sent": "Generating the number of you know independent samples you have.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I guess many of you are more familiar there.",
                    "label": 0
                },
                {
                    "sent": "Now with this result, but there's this nice application towards other matching complexity for transductive inference problem.",
                    "label": 1
                },
                {
                    "sent": "So OK, what the hell market complexity in this special setting?",
                    "label": 0
                },
                {
                    "sent": "I consider other market complexity as expected value of the supremum of over your hypothesis space and the correlation between your nose and your hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Your best hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So he marked it in the paper of a young.",
                    "label": 0
                },
                {
                    "sent": "If they consider a slightly different hypothesis definition of problematic complexity.",
                    "label": 0
                },
                {
                    "sent": "They say the Sigma can be 01 or minus one so but I consider one and minus one only, so the classical setting.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you come up, come up with about that.",
                    "label": 0
                },
                {
                    "sent": "So basically say OK, you put constructive prediction occurs, can be bounded in terms of allometric complexity plastic correction term.",
                    "label": 0
                },
                {
                    "sent": "But there's a negative term there.",
                    "label": 0
                },
                {
                    "sent": "And here is also a correction term for the fact that you work in infant universes.",
                    "label": 0
                },
                {
                    "sent": "So it is quite different from the results in bitter bottles.",
                    "label": 0
                },
                {
                    "sent": "And I mean the source paper because of the correction terms.",
                    "label": 0
                },
                {
                    "sent": "They really worked in an inductive setting.",
                    "label": 0
                },
                {
                    "sent": "But this gives bound gives you an opportunity to work in the finite universe setting.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I want to make some remarks for going back to the clustering story there.",
                    "label": 0
                },
                {
                    "sent": "So yeah, we have this view on stability of clustering.",
                    "label": 0
                },
                {
                    "sent": "As already mentioned a few times that suppose you sample.",
                    "label": 0
                },
                {
                    "sent": "Now, let's say you have a data set, or you have a finite universe and your sample randomly.",
                    "label": 0
                },
                {
                    "sent": "Then if you can guarantee that you had the distance between the result of your algorithm is smaller than the beta, then you want to have some results.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, you also not too far from the expected what you expect to get if you sample.",
                    "label": 0
                },
                {
                    "sent": "So this week notion of of.",
                    "label": 0
                },
                {
                    "sent": "Stability for clustering.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't say something about if it's you know for and going to effect, but it just says something about expected question for this final simple things.",
                    "label": 0
                },
                {
                    "sent": "So OK, if you consider that the question in stability for clustering then.",
                    "label": 1
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can of course also apply previous results there, so image disability results.",
                    "label": 0
                },
                {
                    "sent": "Basically, the idea is that OK you have this dysfunction between two clusters.",
                    "label": 0
                },
                {
                    "sent": "Can you go back home?",
                    "label": 0
                },
                {
                    "sent": "So so is expectation over ASM.",
                    "label": 0
                },
                {
                    "sent": "Over the counter variable.",
                    "label": 0
                },
                {
                    "sent": "So the S and also because of this.",
                    "label": 0
                },
                {
                    "sent": "You try to estimate the instability from samples showing you converge.",
                    "label": 0
                },
                {
                    "sent": "SMS by distance and you want you to lose it to approximate the expected value.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Finally, sexism.",
                    "label": 0
                },
                {
                    "sent": "It's not the expected distance, but OK.",
                    "label": 0
                },
                {
                    "sent": "It's the distance from the expected guy.",
                    "label": 0
                },
                {
                    "sent": "OK, epsilon.",
                    "label": 0
                },
                {
                    "sent": "Sir.",
                    "label": 0
                },
                {
                    "sent": "So if you take like expectation is over your draw of your set of labels which you input to the algorithm.",
                    "label": 0
                },
                {
                    "sent": "The expectation goes over the OK, it's just a mapping, right?",
                    "label": 0
                },
                {
                    "sent": "So the expectation goes over the input, so and then it's not the expected.",
                    "label": 0
                },
                {
                    "sent": "Yeah, well, it's.",
                    "label": 0
                },
                {
                    "sent": "Is 2 arguments, 2 + 2.",
                    "label": 0
                },
                {
                    "sent": "Expectation, so why isn't expectation over?",
                    "label": 0
                },
                {
                    "sent": "If you do it expectation for the phone.",
                    "label": 0
                },
                {
                    "sent": "Expectation.",
                    "label": 0
                },
                {
                    "sent": "Yeah add, I think.",
                    "label": 0
                },
                {
                    "sent": "Are you using the clustering which is closest to the expected last night?",
                    "label": 0
                },
                {
                    "sent": "How do you?",
                    "label": 0
                },
                {
                    "sent": "How do you in order to complete this expectation of country needs some operating?",
                    "label": 0
                },
                {
                    "sent": "How to put together we can cluster.",
                    "label": 0
                },
                {
                    "sent": "Yes, and I think the result is.",
                    "label": 0
                },
                {
                    "sent": "Check.",
                    "label": 0
                },
                {
                    "sent": "OK, I think the answer is here.",
                    "label": 0
                },
                {
                    "sent": "So you have this D which is the distance between clustering.",
                    "label": 0
                },
                {
                    "sent": "So but now we can make things a bit more formal, so I don't say I got to the end, but a bit more formal by considering AC, which is basically coding function which includes your clustering in a bit string and then you can talk about.",
                    "label": 0
                },
                {
                    "sent": "You can compare 2 bit strings in certain norm that you can start talking.",
                    "label": 0
                },
                {
                    "sent": "However, it will not be translated.",
                    "label": 0
                },
                {
                    "sent": "David won't be adjusting, but it's what you expect to get right.",
                    "label": 0
                },
                {
                    "sent": "The distance of the question from something which is not, so you're just saying you're converting to what you expect, so you do not say what the expected guys.",
                    "label": 0
                },
                {
                    "sent": "We talking about the distance between a of SM which is.",
                    "label": 0
                },
                {
                    "sent": "Expectation, which is not the question.",
                    "label": 0
                },
                {
                    "sent": "Did you find this?",
                    "label": 0
                },
                {
                    "sent": "I'm sure it's the expected.",
                    "label": 0
                },
                {
                    "sent": "You know it's the expected value of your the output of your clustering.",
                    "label": 0
                },
                {
                    "sent": "Chuck.",
                    "label": 0
                },
                {
                    "sent": "This week Yep, Yep.",
                    "label": 0
                },
                {
                    "sent": "It is something that will not give me classroom.",
                    "label": 0
                },
                {
                    "sent": "Yep, Yep.",
                    "label": 0
                },
                {
                    "sent": "Your century does not have to be a validated sure, but then it's not clear whether you want to have a clustering at the end.",
                    "label": 0
                },
                {
                    "sent": "You want just convergence results.",
                    "label": 0
                },
                {
                    "sent": "Find the distance between something which is a clustering to something which may not be exactly right.",
                    "label": 0
                },
                {
                    "sent": "So how do you define?",
                    "label": 0
                },
                {
                    "sent": "OK, so you have to assume that you can compare anything of the convex combination of anything which is a cluster, right?",
                    "label": 0
                },
                {
                    "sent": "So you have to extend your distance matrix a bit.",
                    "label": 0
                },
                {
                    "sent": "Your dear, but that's basically what you're missing, right?",
                    "label": 0
                },
                {
                    "sent": "So you can compare essentially what's your expected a?",
                    "label": 0
                },
                {
                    "sent": "I mean, if D is brought in, if you can do that.",
                    "label": 0
                },
                {
                    "sent": "Brides.",
                    "label": 0
                },
                {
                    "sent": "So I think it's.",
                    "label": 0
                },
                {
                    "sent": "If you want to use this kind of stability results that you know a way to go, I'm not saying that's the way to go.",
                    "label": 0
                },
                {
                    "sent": "I think that's something which can be learned from, you know, the stability results in learning and transductive inference in particular.",
                    "label": 0
                },
                {
                    "sent": "OK. Um, yeah, well and then.",
                    "label": 0
                },
                {
                    "sent": "So suppose you can come up with a bit string decoding your clustering and this bitstream has some metric meaning.",
                    "label": 0
                },
                {
                    "sent": "That's OK. You can essentially talk about not only 0 ones, but also like something in between, which is expected value of certain bit.",
                    "label": 0
                },
                {
                    "sent": "So then you can really talk about.",
                    "label": 0
                },
                {
                    "sent": "This kind of stability results, but I think that's really the core problem.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I guess you're right, you're pinpointing the.",
                    "label": 0
                },
                {
                    "sent": "So just say just this way.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Receipt's daughter this one.",
                    "label": 0
                },
                {
                    "sent": "OK, so well, and then there's a natural way to encode maybe a clustering by assigned to each point the cluster identity in account go away.",
                    "label": 1
                },
                {
                    "sent": "Town.",
                    "label": 0
                },
                {
                    "sent": "And of course, if you go to the inductive setting so not finite universe setting, you can use my diamonds.",
                    "label": 0
                },
                {
                    "sent": "It's also interesting to note that this paper, an alien, if, as some notions of weak stability, which not, I mean, that should be not a bitter for all possible random draws, but you know, in majority there should be such a bit, so notion which you come up there.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let's maybe concludes with a smaller example, so this is an example from transductive inference, but I think it shows somehow that you're really really very close to the clustering ID.",
                    "label": 0
                },
                {
                    "sent": "So suppose you have like 1000 samples in the organized graph.",
                    "label": 0
                },
                {
                    "sent": "You have neighborhood graph, for example.",
                    "label": 0
                },
                {
                    "sent": "Add rolled from made from, you know.",
                    "label": 0
                },
                {
                    "sent": "But suppose the graph speaks for a moment and suppose you label this guys plus one in this minus one transductive inference finds you all the labels of the other, and it makes a few mistakes of course.",
                    "label": 0
                },
                {
                    "sent": "That's classical setting, but you can go even further.",
                    "label": 0
                },
                {
                    "sent": "You can say OK, this guys plus one and I only know that there are like 70% of minus one guys and then you can do your also a minute algorithm incorporating this prior knowledge and then you can come up with a division of your.",
                    "label": 0
                },
                {
                    "sent": "It's a of your graph which is.",
                    "label": 0
                },
                {
                    "sent": "About which is is good.",
                    "label": 0
                },
                {
                    "sent": "You also separate both you know.",
                    "label": 0
                },
                {
                    "sent": "Clouds so you really learning from 1 sample innocence.",
                    "label": 0
                },
                {
                    "sent": "So, and I mean just iterating over.",
                    "label": 0
                },
                {
                    "sent": "I mean, just picking a random sample that you see immediately that you're doing closely somehow and imposing some some notion of how big clusters should be.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think that concludes my arm.",
                    "label": 0
                },
                {
                    "sent": "Yeah, my presentation.",
                    "label": 0
                },
                {
                    "sent": "Of course, many open topics, and I mean Spain parts, already many issues to be resolved in orders.",
                    "label": 0
                }
            ]
        }
    }
}