{
    "id": "eewdonp3btxrmawjxrqscuj26z23ci3g",
    "title": "Supervised Translation-Invariant Sparse Coding",
    "info": {
        "author": [
            "Jianchao (John) Yang, Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Semi-supervised Learning",
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_yang_stis/",
    "segmentation": [
        [
            "Thank you for the introduction.",
            "I'm gentle young.",
            "From yesterday we did not add a banner champagne to the joint work with KU from NEC Laboratories America at Cupertino and my advisor Thomas Wong.",
            "The main."
        ],
        [
            "Talk about this.",
            "The main task of the talk is about imitation, where we are.",
            "We want to assign class labels to the images given depending on the specific task, it can be optical recognition, face recognition.",
            "Then the recognition or digital recognition and the goal of our work is to find out generic image representation and Furthermore we want to.",
            "We require that our feature representation fits linear model linear model well."
        ],
        [
            "So this work is a extension of our CPR online work.",
            "In in that in the Cpl Network, we propose a healthy model based on bad coding that achieves translation invariants.",
            "And this is a framework of our ICS PM algorithm.",
            "We have input image here.",
            "In the first step we do local descriptor extraction to get the back of coordinate local descriptors.",
            "It can be in the patches or safety descriptors.",
            "In the second step we will start coding to convert.",
            "This caters to sparkles and finally and then we use a hierarchal Max pooling to pull this passcode together to get.",
            "Fixed amounts of feature vector and finally throw this feature vector into linear classifier like FM and get the cat can result."
        ],
        [
            "To make this model easier to follow, we can compare with this."
        ],
        [
            "It's a histogram based at GM feature, so for comparison, instead of using the vector conversation, we use spot coding to model the local descriptors."
        ],
        [
            "And instead of the average pooling for histogram, we use multiple."
        ],
        [
            "And it turns out that our feature fits a linear model much better than the.",
            "With Gram features."
        ],
        [
            "So here's a illustration of this this algorithm.",
            "So you have an input X.",
            "It's a set of descriptors extracted from the input image, and you do you perform smart coding by solving a problem.",
            "Here B is a dictionary for spot coding.",
            "And then you do multiple Ng over increasingly larger spatial regions and concatenate this multiple features so that this feature actually achieves translation invariants over different spatial scales.",
            "And for Max pooling, I want to notice you that it's much more important than you think, and Furthermore I want to refer you to two recent publications by Lambari.",
            "01 is published in this conference and also another one FML.",
            "2010 they have some very interesting analysis about the multiple.",
            "And for the dictionary.",
            "People usually trend this in reconstruction manner where you want to find a dictionary B that can.",
            "Sparsely represent your training descriptors.",
            "And the optimization is performed in a MM type manner and then the question is.",
            "It be the dictionary training this way optimal for your classification."
        ],
        [
            "So.",
            "There are quite a few works applying, spotting for image classifications recently so people have tried better.",
            "Try applies by putting on holistic images like face recognition, data recognition, text recognition and about this kind of method.",
            "Actually limited by the linear model assumption and they are also sensitive to image miss Lamp.",
            "Another that why this left coding.",
            "On local descriptors and build a hierarchy based on the sparse codes.",
            "And it so they can measure the break linear model assumption and also robust to image misalignment.",
            "Therefore they are applicable to more generic image classification like operate recognitions in classification etc.",
            "And depending on how do you do the spot coding this?",
            "So this algorithm can be classified into two categories, unsurprised or surprised, and our work in this talk is try to fail this black."
        ],
        [
            "OK, so.",
            "So this is the for the SPMS limitation we.",
            "We will we will come with image feature by Max pooling by spot coding and multiple Lincoln write.",
            "Write it down as a function will into the image I and the dictionary be.",
            "But know that this is not in analytical form and we want to support training so it's straightforward to write this cost function.",
            "This will be familiar to most of you, and so the xiy here are the labeled training examples with outside the set of features for the IC image.",
            "And why is the label.",
            "And we want to we want to use a linear prediction model F. Here W is a parameter and we also use a loss function, so hopefully we try to minimize over W the classifier parameter and also the dictionary.",
            "We can.",
            "We can find a dictionary that is more effective for classification tasks.",
            "An organization over the.",
            "Over W is straightforward 'cause you're just trying to learn a linear classifier, so."
        ],
        [
            "For learning the dictionary B, we use backpropagation and very similar idea is also president by Yellen Boreal.",
            "I strongly encourage you to read it but also you will find very some very interesting stuff there."
        ],
        [
            "And let you know that the cost function at E. And for backpropagation we want to find the gradient of the function with respect to the dictionary and we can we can find the gradient union rules.",
            "And if you look at the first term, visit very easy because your loss function.",
            "You can choose any."
        ],
        [
            "Differentiable not function here we use US squared hinge loss function."
        ],
        [
            "And the second term, we just use a linear prediction model and.",
            "Pretty straightforward."
        ],
        [
            "And the third line that little tricky because my coding is not differentiable and the trick here is that we we only care about the poor, the maximum maximum values and then fix those locations."
        ],
        [
            "And for the last one is the problem because we don't have a analytical link between the specification and the dictionary because.",
            "You got this presentation from this organization.",
            "So."
        ],
        [
            "The solution is that we want to.",
            "We can use implicit differentiation or technique previously used in NIPS 2008.",
            "OK, here's the spot coding formulation.",
            "If we take the derivative over this, but mentation at a minimum at the optimum.",
            "Then then you gotta fix up on equations where you link to your plantation at the optimum with the dictionary and use differential.",
            "An implicit differentiation will take the derivative of your of the dictionary on both sides.",
            "And then you got here and."
        ],
        [
            "Here we assume that B is close to optimal and thus the corresponding segmentation will not change them.",
            "And thus the right hand right hand side of the equation can be set to."
        ],
        [
            "In this way we can compute the gradient of your non duraspark coefficients with replica of each element of a dictionary.",
            "OK."
        ],
        [
            "So I would.",
            "I would say that the innovation is important because.",
            "Because the cost function is highly nonconvex, an in our work we use a dictionary trend in unsupervised manner.",
            "And this figure shows the convergence property of the learning process.",
            "But you can see the cost function value decreases an also the classic in classification error on the validate validation set decreases at the cost function decreases.",
            "This is what we want.",
            "So here I showed an example dictionary trend from your patches from the CMU pie, but this is unsurprising dictionary it's very smooth, so it captures the edits.",
            "Connors eyes some features an on the right is the Super Training Dictionary and they can see the Super traditional actually contained mode details and also adjust the shape or additional items from the enterprise from.",
            "Brother training so which makes that extremely more effective for your classification."
        ],
        [
            "And here comes to our experiment evaluation.",
            "So we are.",
            "We tried this on three clicking tasks including face recognition, data recognition and general recognition.",
            "So for all these tasks, the image local descriptors were tried, just rolling the patches and the parameter settings here.",
            "Just chosen empirically so we didn't didn't search for the optimal setting.",
            "And for the prediction model we use one words or linear FM with squared hinge loss function and the stochastic optimization usually converges in less than 10 iterations.",
            "Get."
        ],
        [
            "First experiment on face recognition is conducted on Samuel Pie, so well known they said we are.",
            "We take just a subset of five near front views, including all the impression expressions and illuminations.",
            "The way USC denotes the unsurprised particle model and SSE, which is not a surprise vertical model, and we also showed the improvement, will show that how much improvement performance again we can get from the supplier training over the interval training."
        ],
        [
            "So here the result on this, they said.",
            "So we compared with some little result on this data set.",
            "And if you can see it, you can see the unsurprised particle model, the OSC.",
            "It's already doing a much better job than the than the literature results and the Super training further improve the performance.",
            "Significantly."
        ],
        [
            "And the second experiment is conducted on.",
            "Female multiply, which contains 337 subjects across some 10 years.",
            "Variation, pose expressions eliminations and again we we take a subset just handled near front view faces."
        ],
        [
            "And in this index experiment, we compared with the sponsor Mentation work published last year in CPR online.",
            "Basically, the user smart coding over the over the whole whole faces holistically faces so.",
            "If they compare with their work.",
            "About coding on the local patches.",
            "The unsupervised unsupervised.",
            "The unsupervised model already.",
            "Perform very good and a supervised training.",
            "Further reduce the error rate and which we can achieve much better than results than the holistic spot coding.",
            "Once you know that.",
            "For this work, they not only handle factorization but also face alignment.",
            "So our work only cares about face recognition."
        ],
        [
            "So the third experiment is 400 ignition.",
            "We conducted this an analyst.",
            "So compared with the.",
            "It's about coding on on the whole image there once about coding here and we also compare with two results published in 2000, 2008 in this paper.",
            "And as you can see, so the supervisor training again improved performance a lot.",
            "And also we can achieve similar performance at the Convolutional neural network."
        ],
        [
            "And the last experiment.",
            "It on gender recognition.",
            "We we try this on the FGC FGC aniway take 451 in videos at the training and the rest 114% at the at the testing.",
            "So, compared with the Community Network published in NIPS 2008.",
            "Again, this here and as you can see.",
            "So all work actually can perform a little better than the convolutional inner network, OK?"
        ],
        [
            "So in conclusion, in conclusion are.",
            "We propose a supervisor translation invariance model model for email classification, and the feature is very generic, can be applied to many tasks.",
            "And the marketing freighter is really translation invariant.",
            "You don't have to image it, don't have to be aligned perfectly and we also show that spot coding on local descriptors is promising compared to start coding on holistic images and also surprised spotting improved performance significantly all these tasks.",
            "So for the next steps.",
            "I think connections with hierarchical models in deep deep belief networks to be investigated and more theoretical analysis of polling functions are needed and deep hierarchical models based on Sparta coding should be started.",
            "That's about it, thank you."
        ],
        [
            "OK, so I actually have a question so so how different would you say the architecture that you use in the end is from a convolutional neural net which you compare your results with.",
            "In terms of architecture, the idea of having we called on that side based on.",
            "Filters convolutionally apply convolutional eplus nonlinearities and pooling.",
            "Now that's essentially what you're doing as well.",
            "The training is different.",
            "No, I think it's different from the Community network, so we are, well, we are doing the coding using optimization.",
            "We don't have.",
            "We don't have a shared shared weights actually.",
            "Yeah so.",
            "But we do.",
            "We do have much pulling over spatial regions, increasing larger regions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you for the introduction.",
                    "label": 0
                },
                {
                    "sent": "I'm gentle young.",
                    "label": 0
                },
                {
                    "sent": "From yesterday we did not add a banner champagne to the joint work with KU from NEC Laboratories America at Cupertino and my advisor Thomas Wong.",
                    "label": 1
                },
                {
                    "sent": "The main.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Talk about this.",
                    "label": 0
                },
                {
                    "sent": "The main task of the talk is about imitation, where we are.",
                    "label": 0
                },
                {
                    "sent": "We want to assign class labels to the images given depending on the specific task, it can be optical recognition, face recognition.",
                    "label": 0
                },
                {
                    "sent": "Then the recognition or digital recognition and the goal of our work is to find out generic image representation and Furthermore we want to.",
                    "label": 1
                },
                {
                    "sent": "We require that our feature representation fits linear model linear model well.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this work is a extension of our CPR online work.",
                    "label": 0
                },
                {
                    "sent": "In in that in the Cpl Network, we propose a healthy model based on bad coding that achieves translation invariants.",
                    "label": 0
                },
                {
                    "sent": "And this is a framework of our ICS PM algorithm.",
                    "label": 1
                },
                {
                    "sent": "We have input image here.",
                    "label": 0
                },
                {
                    "sent": "In the first step we do local descriptor extraction to get the back of coordinate local descriptors.",
                    "label": 1
                },
                {
                    "sent": "It can be in the patches or safety descriptors.",
                    "label": 1
                },
                {
                    "sent": "In the second step we will start coding to convert.",
                    "label": 0
                },
                {
                    "sent": "This caters to sparkles and finally and then we use a hierarchal Max pooling to pull this passcode together to get.",
                    "label": 0
                },
                {
                    "sent": "Fixed amounts of feature vector and finally throw this feature vector into linear classifier like FM and get the cat can result.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To make this model easier to follow, we can compare with this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a histogram based at GM feature, so for comparison, instead of using the vector conversation, we use spot coding to model the local descriptors.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And instead of the average pooling for histogram, we use multiple.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it turns out that our feature fits a linear model much better than the.",
                    "label": 0
                },
                {
                    "sent": "With Gram features.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a illustration of this this algorithm.",
                    "label": 0
                },
                {
                    "sent": "So you have an input X.",
                    "label": 0
                },
                {
                    "sent": "It's a set of descriptors extracted from the input image, and you do you perform smart coding by solving a problem.",
                    "label": 0
                },
                {
                    "sent": "Here B is a dictionary for spot coding.",
                    "label": 0
                },
                {
                    "sent": "And then you do multiple Ng over increasingly larger spatial regions and concatenate this multiple features so that this feature actually achieves translation invariants over different spatial scales.",
                    "label": 0
                },
                {
                    "sent": "And for Max pooling, I want to notice you that it's much more important than you think, and Furthermore I want to refer you to two recent publications by Lambari.",
                    "label": 0
                },
                {
                    "sent": "01 is published in this conference and also another one FML.",
                    "label": 1
                },
                {
                    "sent": "2010 they have some very interesting analysis about the multiple.",
                    "label": 0
                },
                {
                    "sent": "And for the dictionary.",
                    "label": 0
                },
                {
                    "sent": "People usually trend this in reconstruction manner where you want to find a dictionary B that can.",
                    "label": 0
                },
                {
                    "sent": "Sparsely represent your training descriptors.",
                    "label": 0
                },
                {
                    "sent": "And the optimization is performed in a MM type manner and then the question is.",
                    "label": 0
                },
                {
                    "sent": "It be the dictionary training this way optimal for your classification.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There are quite a few works applying, spotting for image classifications recently so people have tried better.",
                    "label": 0
                },
                {
                    "sent": "Try applies by putting on holistic images like face recognition, data recognition, text recognition and about this kind of method.",
                    "label": 0
                },
                {
                    "sent": "Actually limited by the linear model assumption and they are also sensitive to image miss Lamp.",
                    "label": 1
                },
                {
                    "sent": "Another that why this left coding.",
                    "label": 1
                },
                {
                    "sent": "On local descriptors and build a hierarchy based on the sparse codes.",
                    "label": 1
                },
                {
                    "sent": "And it so they can measure the break linear model assumption and also robust to image misalignment.",
                    "label": 1
                },
                {
                    "sent": "Therefore they are applicable to more generic image classification like operate recognitions in classification etc.",
                    "label": 0
                },
                {
                    "sent": "And depending on how do you do the spot coding this?",
                    "label": 0
                },
                {
                    "sent": "So this algorithm can be classified into two categories, unsurprised or surprised, and our work in this talk is try to fail this black.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So this is the for the SPMS limitation we.",
                    "label": 0
                },
                {
                    "sent": "We will we will come with image feature by Max pooling by spot coding and multiple Lincoln write.",
                    "label": 0
                },
                {
                    "sent": "Write it down as a function will into the image I and the dictionary be.",
                    "label": 0
                },
                {
                    "sent": "But know that this is not in analytical form and we want to support training so it's straightforward to write this cost function.",
                    "label": 1
                },
                {
                    "sent": "This will be familiar to most of you, and so the xiy here are the labeled training examples with outside the set of features for the IC image.",
                    "label": 0
                },
                {
                    "sent": "And why is the label.",
                    "label": 0
                },
                {
                    "sent": "And we want to we want to use a linear prediction model F. Here W is a parameter and we also use a loss function, so hopefully we try to minimize over W the classifier parameter and also the dictionary.",
                    "label": 0
                },
                {
                    "sent": "We can.",
                    "label": 0
                },
                {
                    "sent": "We can find a dictionary that is more effective for classification tasks.",
                    "label": 0
                },
                {
                    "sent": "An organization over the.",
                    "label": 0
                },
                {
                    "sent": "Over W is straightforward 'cause you're just trying to learn a linear classifier, so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For learning the dictionary B, we use backpropagation and very similar idea is also president by Yellen Boreal.",
                    "label": 0
                },
                {
                    "sent": "I strongly encourage you to read it but also you will find very some very interesting stuff there.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And let you know that the cost function at E. And for backpropagation we want to find the gradient of the function with respect to the dictionary and we can we can find the gradient union rules.",
                    "label": 1
                },
                {
                    "sent": "And if you look at the first term, visit very easy because your loss function.",
                    "label": 0
                },
                {
                    "sent": "You can choose any.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Differentiable not function here we use US squared hinge loss function.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the second term, we just use a linear prediction model and.",
                    "label": 0
                },
                {
                    "sent": "Pretty straightforward.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the third line that little tricky because my coding is not differentiable and the trick here is that we we only care about the poor, the maximum maximum values and then fix those locations.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for the last one is the problem because we don't have a analytical link between the specification and the dictionary because.",
                    "label": 0
                },
                {
                    "sent": "You got this presentation from this organization.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The solution is that we want to.",
                    "label": 0
                },
                {
                    "sent": "We can use implicit differentiation or technique previously used in NIPS 2008.",
                    "label": 1
                },
                {
                    "sent": "OK, here's the spot coding formulation.",
                    "label": 0
                },
                {
                    "sent": "If we take the derivative over this, but mentation at a minimum at the optimum.",
                    "label": 0
                },
                {
                    "sent": "Then then you gotta fix up on equations where you link to your plantation at the optimum with the dictionary and use differential.",
                    "label": 0
                },
                {
                    "sent": "An implicit differentiation will take the derivative of your of the dictionary on both sides.",
                    "label": 0
                },
                {
                    "sent": "And then you got here and.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we assume that B is close to optimal and thus the corresponding segmentation will not change them.",
                    "label": 0
                },
                {
                    "sent": "And thus the right hand right hand side of the equation can be set to.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this way we can compute the gradient of your non duraspark coefficients with replica of each element of a dictionary.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I would.",
                    "label": 0
                },
                {
                    "sent": "I would say that the innovation is important because.",
                    "label": 1
                },
                {
                    "sent": "Because the cost function is highly nonconvex, an in our work we use a dictionary trend in unsupervised manner.",
                    "label": 1
                },
                {
                    "sent": "And this figure shows the convergence property of the learning process.",
                    "label": 0
                },
                {
                    "sent": "But you can see the cost function value decreases an also the classic in classification error on the validate validation set decreases at the cost function decreases.",
                    "label": 0
                },
                {
                    "sent": "This is what we want.",
                    "label": 0
                },
                {
                    "sent": "So here I showed an example dictionary trend from your patches from the CMU pie, but this is unsurprising dictionary it's very smooth, so it captures the edits.",
                    "label": 0
                },
                {
                    "sent": "Connors eyes some features an on the right is the Super Training Dictionary and they can see the Super traditional actually contained mode details and also adjust the shape or additional items from the enterprise from.",
                    "label": 0
                },
                {
                    "sent": "Brother training so which makes that extremely more effective for your classification.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here comes to our experiment evaluation.",
                    "label": 1
                },
                {
                    "sent": "So we are.",
                    "label": 0
                },
                {
                    "sent": "We tried this on three clicking tasks including face recognition, data recognition and general recognition.",
                    "label": 1
                },
                {
                    "sent": "So for all these tasks, the image local descriptors were tried, just rolling the patches and the parameter settings here.",
                    "label": 0
                },
                {
                    "sent": "Just chosen empirically so we didn't didn't search for the optimal setting.",
                    "label": 0
                },
                {
                    "sent": "And for the prediction model we use one words or linear FM with squared hinge loss function and the stochastic optimization usually converges in less than 10 iterations.",
                    "label": 1
                },
                {
                    "sent": "Get.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First experiment on face recognition is conducted on Samuel Pie, so well known they said we are.",
                    "label": 0
                },
                {
                    "sent": "We take just a subset of five near front views, including all the impression expressions and illuminations.",
                    "label": 1
                },
                {
                    "sent": "The way USC denotes the unsurprised particle model and SSE, which is not a surprise vertical model, and we also showed the improvement, will show that how much improvement performance again we can get from the supplier training over the interval training.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here the result on this, they said.",
                    "label": 0
                },
                {
                    "sent": "So we compared with some little result on this data set.",
                    "label": 0
                },
                {
                    "sent": "And if you can see it, you can see the unsurprised particle model, the OSC.",
                    "label": 0
                },
                {
                    "sent": "It's already doing a much better job than the than the literature results and the Super training further improve the performance.",
                    "label": 0
                },
                {
                    "sent": "Significantly.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the second experiment is conducted on.",
                    "label": 0
                },
                {
                    "sent": "Female multiply, which contains 337 subjects across some 10 years.",
                    "label": 1
                },
                {
                    "sent": "Variation, pose expressions eliminations and again we we take a subset just handled near front view faces.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this index experiment, we compared with the sponsor Mentation work published last year in CPR online.",
                    "label": 0
                },
                {
                    "sent": "Basically, the user smart coding over the over the whole whole faces holistically faces so.",
                    "label": 0
                },
                {
                    "sent": "If they compare with their work.",
                    "label": 0
                },
                {
                    "sent": "About coding on the local patches.",
                    "label": 0
                },
                {
                    "sent": "The unsupervised unsupervised.",
                    "label": 0
                },
                {
                    "sent": "The unsupervised model already.",
                    "label": 0
                },
                {
                    "sent": "Perform very good and a supervised training.",
                    "label": 0
                },
                {
                    "sent": "Further reduce the error rate and which we can achieve much better than results than the holistic spot coding.",
                    "label": 0
                },
                {
                    "sent": "Once you know that.",
                    "label": 0
                },
                {
                    "sent": "For this work, they not only handle factorization but also face alignment.",
                    "label": 0
                },
                {
                    "sent": "So our work only cares about face recognition.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the third experiment is 400 ignition.",
                    "label": 0
                },
                {
                    "sent": "We conducted this an analyst.",
                    "label": 0
                },
                {
                    "sent": "So compared with the.",
                    "label": 0
                },
                {
                    "sent": "It's about coding on on the whole image there once about coding here and we also compare with two results published in 2000, 2008 in this paper.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, so the supervisor training again improved performance a lot.",
                    "label": 0
                },
                {
                    "sent": "And also we can achieve similar performance at the Convolutional neural network.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the last experiment.",
                    "label": 0
                },
                {
                    "sent": "It on gender recognition.",
                    "label": 0
                },
                {
                    "sent": "We we try this on the FGC FGC aniway take 451 in videos at the training and the rest 114% at the at the testing.",
                    "label": 0
                },
                {
                    "sent": "So, compared with the Community Network published in NIPS 2008.",
                    "label": 0
                },
                {
                    "sent": "Again, this here and as you can see.",
                    "label": 0
                },
                {
                    "sent": "So all work actually can perform a little better than the convolutional inner network, OK?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, in conclusion are.",
                    "label": 0
                },
                {
                    "sent": "We propose a supervisor translation invariance model model for email classification, and the feature is very generic, can be applied to many tasks.",
                    "label": 0
                },
                {
                    "sent": "And the marketing freighter is really translation invariant.",
                    "label": 0
                },
                {
                    "sent": "You don't have to image it, don't have to be aligned perfectly and we also show that spot coding on local descriptors is promising compared to start coding on holistic images and also surprised spotting improved performance significantly all these tasks.",
                    "label": 1
                },
                {
                    "sent": "So for the next steps.",
                    "label": 0
                },
                {
                    "sent": "I think connections with hierarchical models in deep deep belief networks to be investigated and more theoretical analysis of polling functions are needed and deep hierarchical models based on Sparta coding should be started.",
                    "label": 1
                },
                {
                    "sent": "That's about it, thank you.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I actually have a question so so how different would you say the architecture that you use in the end is from a convolutional neural net which you compare your results with.",
                    "label": 0
                },
                {
                    "sent": "In terms of architecture, the idea of having we called on that side based on.",
                    "label": 0
                },
                {
                    "sent": "Filters convolutionally apply convolutional eplus nonlinearities and pooling.",
                    "label": 0
                },
                {
                    "sent": "Now that's essentially what you're doing as well.",
                    "label": 0
                },
                {
                    "sent": "The training is different.",
                    "label": 0
                },
                {
                    "sent": "No, I think it's different from the Community network, so we are, well, we are doing the coding using optimization.",
                    "label": 0
                },
                {
                    "sent": "We don't have.",
                    "label": 0
                },
                {
                    "sent": "We don't have a shared shared weights actually.",
                    "label": 0
                },
                {
                    "sent": "Yeah so.",
                    "label": 0
                },
                {
                    "sent": "But we do.",
                    "label": 0
                },
                {
                    "sent": "We do have much pulling over spatial regions, increasing larger regions.",
                    "label": 0
                }
            ]
        }
    }
}