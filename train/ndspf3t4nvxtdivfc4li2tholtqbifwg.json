{
    "id": "ndspf3t4nvxtdivfc4li2tholtqbifwg",
    "title": "Open City Data Pipeline: Collecting, Integrating, and Predicting Open City Data",
    "info": {
        "author": [
            "Patrik Schneider, Faculty of Informatics, Vienna University of Technology"
        ],
        "published": "July 15, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2015_schneider_city_data/",
    "segmentation": [
        [
            "This is joint work with Axel Polar.",
            "Essentially for Bishop actually Sir Professor Edwin Stefanowicz office is at Siemens and there's a.",
            "It's actually work of a Masters Mercer student, Christopher Martin, who is now a job at Google, so it was very rewarding for him to do this.",
            "And I introduced this open city data pipeline.",
            "It's a progress report on work and on some issues and problems and problems we solved.",
            "I will give an introduction is or give a overview."
        ],
        [
            "So the motivation of this open city data apply Avalon, so following Siemens is actually sponsoring this Green City Index, which measures the quality of life and the quality of environmental indicators in in European cities.",
            "I mean for them once humans Kayden told me it's not, this is not really very very.",
            "It's not for Republic day.",
            "For them it's marketing instrument because if they can say a city has in certain indicators very like like low values.",
            "They can sell the technology to improve this, so it's not for the public good is further interest too, but this is done by The Economist, which is a very serious organization, is very well done.",
            "So our motivation was the following.",
            "Why shouldn't actually like like universities or public organizations, be able to do this?",
            "Their own Green City indexes and an hour starting point was actually providing a framework for people who want to do this.",
            "So we want to actually provide them the data to actually build.",
            "This index is, but we're at this point we're not at at far that we actually want to do it ourselves.",
            "So our aim."
        ],
        [
            "It's very following.",
            "We want to have this framework for smart city applications.",
            "I mean, for example Screen City index.",
            "We what we do is gathering performance in KP eyes for cities and it's just for city is not for countries and so it's a bit deferring to your work.",
            "And I like you, I guess your focuses more channel for our focus is really just an urban areas and cities and it should be timely which is important.",
            "So if a statistical organization is publishing it should be then republished as open data.",
            "So that I mean this is a very important factor.",
            "We use open standards, obviously partly because this is Professor Polar's main focus, so it should be it's part of it, and the collection is semi automatically, so we we still what we heard before.",
            "It's not possible to a complete automatic crawling and collecting of this data.",
            "We had a local DB pedia, Euro starter noted UN statistically vision US sensors and integration of the data is on teologi based which I will show."
        ],
        [
            "So obviously, like all research tells a lot of challenges, and I mean one the heterogenea T is to peak challenge in our field.",
            "So we have a lot of indicators, alot of specifications, but they vary by time by unit.",
            "They even sometimes you can't even understand what their semantics or their meaning is and there in different formats, often in CSV, sometimes in RDF there is a run on different licenses.",
            "And the access points are also like like, really, every organization has their own way of getting this data and this is for us really, a motivation to have a central access point for open data which relates to cities and statistically and also another one.",
            "Another problem which I will discuss later is there will be.",
            "We discovered a lot of missing values.",
            "So."
        ],
        [
            "Here is quickly the pipeline.",
            "I mean, the talk is not mainly pipelines, just on certain issues on it, so this is quickly I wrap it up.",
            "We have the crawler which gets the websites, then it reads the files, it converts it and annotate it to an ontology.",
            "And it stores it in a triple store.",
            "In our case, it's now it's Gina, but we're agnostic towards Triplestores.",
            "Any trips or could work and then we run like in our case like predictions on top of this data.",
            "So in our case it's like computing missing values.",
            "And the motivation of this pipeline is that we actually want to.",
            "In reach statistical data, by using this pipeline so the enrichment could be like like like filling in missing values, but enrich enrichment could also be like like geographical information to our data and even at your graphical relations to it.",
            "So it's A kind of enhancing the existing data and republishing it.",
            "So."
        ],
        [
            "Here is tautology.",
            "I mean, it's a very simple and told you to be honest and it's mainly Tessa spatial context, temporal context indicators, and I mean the data itself.",
            "There are F3 precita data context is blank node and on this blank nodes at a different context and the indicator center values and the indicator itself.",
            "I mean is a kind of background information.",
            "We store, you need category data type and so on, and even value ranges will come in the future.",
            "And I mean then tolerated Description, Logic a let's AH, which means that we don't do too much reasoning, it's just concept, an concept in the role hierarchies.",
            "So it's very.",
            "It's a simple ontology, but we use.",
            "So the data."
        ],
        [
            "Sources I will quick claims on two of the main data sources view we use.",
            "One is urban audit.",
            "I mean this is for us the main source of data and is the most appealing and interesting one.",
            "It's actually initiative to increase quality of life.",
            "In Europe it's by the collected by euro start, but provided by the statistical institutes it's a huge range of topics and it has around 2:15 indicators.",
            "Here are some statistical numbers on it, so for 2010 we have 900 cities with 202 indicators.",
            "End which is for us, very, very promising.",
            "They just have around 50% of missing values, so you can really see there's a progress and there is an effort of the European Union to fill out these datasets.",
            "And."
        ],
        [
            "So a second data set is the United Nations artistically division.",
            "And here the outlook is much Creamer.",
            "I mean here we can see that for the whole data set there's just 0.5% of values available, which makes sense.",
            "I mean they collect the collect data from all matrices of the whole world, and I mean as suspected, many cities I don't know, like maybe in in.",
            "Like in Asia or in Africa, there just not so much data available, so the UN is not able to publish them.",
            "This is a guess.",
            "But this is not even our main concern."
        ],
        [
            "So our main concern is now we merge datasets.",
            "So what what is happening?",
            "We merge already sparse data set what's happening?",
            "We even add more sparsity.",
            "So this this rate caps are happening by there's two reasons for this.",
            "First of all, often there's three disjoint cities and as a second problem we are not always able to do proper entity recognition.",
            "Align the same city and the second one is by default we assume indicators are disjoint.",
            "We can't really say that like population A from UN is the same as population from euro start.",
            "So we say actually they're just joined and just in a second step we can decide if they are not disjoint.",
            "So in this as you can see, this makes this situation inverse, so we start."
        ],
        [
            "I'd like.",
            "Like having a look at this problem, like how do we fill out this caps so we so?"
        ],
        [
            "What we did is we developed some based methods to predict missing or impute missing values and.",
            "So our our approach is the following.",
            "I mean, we are our group is not.",
            "We're not really machine learning, specially.",
            "So what we said we just set on really well known techniques and apply them in a basket basket based.",
            "So we collect like simply machine learning methods collected and let them run on our on our data set.",
            "And one assumption is that every indicator has be treated by its own, so we don't really run it on the on the entire huge datasets we take every indicator.",
            "And two for this indicator, the predictions.",
            "And obviously this is the standard like way it's a predictor.",
            "We to have a regression model and then we predict the target.",
            "We use normalized root mean square error normalized.",
            "So we include the value ranges which is important for averaging immediate needed and we used stratified 10 fold cross validation.",
            "I mean this is all standard machine learning techniques.",
            "It's not very very."
        ],
        [
            "Special I would say so.",
            "We developed two approaches.",
            "One is like the more intuitive one.",
            "The first one is actually we assume that some of the existing indicators are able.",
            "We are able one indicated with a set of indicators to predict the target indicator.",
            "So we choose like using a correlation matrix.",
            "The best fitted indicators and use these three methods methods to predict the target and then we choose the best model.",
            "By using this our embassy, but this may I mean, this approach has one drawback.",
            "We need a complete matrix, so it means that a lot of cities are actually dropped out.",
            "And here I mean this is the result of this approach.",
            "We get our MSE with 10 predictors of 0.3 which is.",
            "Very good.",
            "So."
        ],
        [
            "So by having this problem of deleting or not being able to predict like like a lot of cities, we developed the second approach.",
            "So this is actually instead of taking the indicators in the self, we can we perform a principle component analysis on top of all the indicators.",
            "So in principle component is like roughly speaking at dimension reduction method we change the coordinate system and extract principle components.",
            "Which 10 are enriched.",
            "So the matrix of this print principle components and rich with all the missing data points are filled with neutral values for this PCA.",
            "And so now we have this nice situation that we have a complete matrix and we can again do the same, run our three methods and choose the best one.",
            "And this now gives us the possibility to pre predict every single missing value in our data set.",
            "Obviously what you would expect this to performance is dropping and it's around 3.2%.",
            "Of these are messy."
        ],
        [
            "Anne."
        ],
        [
            "So results approaches could approach one is good, but it just doesn't predict us enough value, so we dropped it.",
            "So this is gone and now we're will investigate further approach to this PCI PCA based method and I think we figured out there's still a lot of room for improvement, so one improvement is by just at one point we started.",
            "Replacing linear regression with robust linear regression and already the overall performance improved by 1%.",
            "So it went to 2.29.",
            "So by adding more and more methods we actually might push our results down and so so for future use.",
            "Now problem will be an approach to.",
            "But one drawback is the calculation of the whole data set needs at this point 12 hours, so it's very slow.",
            "We have implemented everything now so.",
            "It's so maybe there's some kind of chance of parallelization."
        ],
        [
            "And all our results are published as linked data.",
            "There's a sparkle endpoint for everybody to use end as well, like.",
            "Like you can use actually the Uriah facility and access all the collected and predicted data, including the quality as well.",
            "So this is like a kind of an idea to feed it back into the Elodie cloud, so other people or other developers can reuse our our in particular predictions.",
            "And."
        ],
        [
            "So this is now actually more for discussion, so I introduced like a framework for filling in missing values and pipeline for publishing them, and we already have some ongoing work, so this is already working progress, so we added new datasets, so USN sources, one of the datasets we added, which is not very.",
            "I mean I was very disappointed as I expect more from the Americans to have like more data on their cities, but it's very spa.",
            "It's also very sparse and it doesn't cover any environmental and any.",
            "Not too many social aspects so the comparing urban audit and you and you and census.",
            "It's a huge difference.",
            "I mean I must say and a second, but this is a whole line of research.",
            "I mean, a lot of cities published their own data is open data, so might be interesting to crawl this single cities open data portals to add this to our portal.",
            "But this is, I mean this rappers is a lot of work cause a rapper would have to be written for every single city.",
            "But there is approaching his curiosity.",
            "Which actually tries to address this problem, and we're also adding you method method, so support vector machines is one of our candidates which might be interesting for the predictions.",
            "Robust linear regressions we have evaluated already.",
            "And the.",
            "Working on what we call Crostata set prediction.",
            "The idea of cross data set prediction is the following, so we have already our base data set and now we we add a new data set.",
            "So we want to actually use the existing data set to predict into the new one.",
            "So we actually have two separate datasets and predict from one into the order.",
            "And this is like we did I SWC paper we don't know if it's going to be accepted on this topic and the second one is Learning Ontology mappings which is probably related to your work as well.",
            "So what we what I said before we had this problem of disjoint indicators, but often these are the same indicators.",
            "So what we try to do is like using regression methods to find relations between two indicators.",
            "I mean the best one is a linear like it's one to one.",
            "But there's also maybe equations involved so there's a conversion from one indicator.",
            "Another and future work there is lot to do, so it's like the story with this.",
            "How is it called is Fatima when you open one wheel like 10 orders come come after.",
            "So one is.",
            "I mean we haven't investigated at all.",
            "Is time series analysis and this is obviously a peak.",
            "I mean an important point because now we're actually.",
            "Do not consider time.",
            "We just take time as a as a kind of variable and time series will obviously connect or or use the relation in the time itself with time series.",
            "So this might be combined with the existing approach, but we don't really know yet what we're going to do, and this is related to politics work.",
            "Our aim is also to connect it to the RDF data cube.",
            "I mean this is obviously on hand.",
            "You know if you collect this data it might be.",
            "The vocabulary MIP interesting that we either make power Ontology or will use.",
            "Actually there are Def Datacube vocabulary and.",
            "Another point is validation and correction of predictions.",
            "So we have this example.",
            "We predict cinema seats and often our predicted values are 0.56 point 7, but there is no 6.7 cinema seats in a city or cinemas as well.",
            "There's no half cinema so often we could actually use our ontology to correct the value.",
            "So if you have 6.7 we would round.",
            "It would assume that we have 7 cinemas.",
            "So this sometimes the our predictions are a bit strange.",
            "I would say, and another one will be using the untold to speed up the process so we remember the paramaters, enter methods which we used for an indicator.",
            "So in future like predictions we would actually use the data in the ontology to do the prediction.",
            "And this is also nothing new but this might be nice and the last one we might be really linking our or integrating link to your data and open street map.",
            "In Open Street, Map itself could be a nice data source because there's a lot of of like regarding Rd network.",
            "Screen areas will be actually might be interesting to extract the Openstreetmap data and convert it into indicators which hasn't been done yet.",
            "I mean this is still very.",
            "I think that's a very promising direction to go, so thank you very much for your attention and."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is joint work with Axel Polar.",
                    "label": 0
                },
                {
                    "sent": "Essentially for Bishop actually Sir Professor Edwin Stefanowicz office is at Siemens and there's a.",
                    "label": 0
                },
                {
                    "sent": "It's actually work of a Masters Mercer student, Christopher Martin, who is now a job at Google, so it was very rewarding for him to do this.",
                    "label": 0
                },
                {
                    "sent": "And I introduced this open city data pipeline.",
                    "label": 1
                },
                {
                    "sent": "It's a progress report on work and on some issues and problems and problems we solved.",
                    "label": 0
                },
                {
                    "sent": "I will give an introduction is or give a overview.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the motivation of this open city data apply Avalon, so following Siemens is actually sponsoring this Green City Index, which measures the quality of life and the quality of environmental indicators in in European cities.",
                    "label": 1
                },
                {
                    "sent": "I mean for them once humans Kayden told me it's not, this is not really very very.",
                    "label": 0
                },
                {
                    "sent": "It's not for Republic day.",
                    "label": 0
                },
                {
                    "sent": "For them it's marketing instrument because if they can say a city has in certain indicators very like like low values.",
                    "label": 0
                },
                {
                    "sent": "They can sell the technology to improve this, so it's not for the public good is further interest too, but this is done by The Economist, which is a very serious organization, is very well done.",
                    "label": 0
                },
                {
                    "sent": "So our motivation was the following.",
                    "label": 0
                },
                {
                    "sent": "Why shouldn't actually like like universities or public organizations, be able to do this?",
                    "label": 0
                },
                {
                    "sent": "Their own Green City indexes and an hour starting point was actually providing a framework for people who want to do this.",
                    "label": 0
                },
                {
                    "sent": "So we want to actually provide them the data to actually build.",
                    "label": 0
                },
                {
                    "sent": "This index is, but we're at this point we're not at at far that we actually want to do it ourselves.",
                    "label": 0
                },
                {
                    "sent": "So our aim.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's very following.",
                    "label": 0
                },
                {
                    "sent": "We want to have this framework for smart city applications.",
                    "label": 1
                },
                {
                    "sent": "I mean, for example Screen City index.",
                    "label": 1
                },
                {
                    "sent": "We what we do is gathering performance in KP eyes for cities and it's just for city is not for countries and so it's a bit deferring to your work.",
                    "label": 1
                },
                {
                    "sent": "And I like you, I guess your focuses more channel for our focus is really just an urban areas and cities and it should be timely which is important.",
                    "label": 0
                },
                {
                    "sent": "So if a statistical organization is publishing it should be then republished as open data.",
                    "label": 0
                },
                {
                    "sent": "So that I mean this is a very important factor.",
                    "label": 0
                },
                {
                    "sent": "We use open standards, obviously partly because this is Professor Polar's main focus, so it should be it's part of it, and the collection is semi automatically, so we we still what we heard before.",
                    "label": 0
                },
                {
                    "sent": "It's not possible to a complete automatic crawling and collecting of this data.",
                    "label": 0
                },
                {
                    "sent": "We had a local DB pedia, Euro starter noted UN statistically vision US sensors and integration of the data is on teologi based which I will show.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So obviously, like all research tells a lot of challenges, and I mean one the heterogenea T is to peak challenge in our field.",
                    "label": 0
                },
                {
                    "sent": "So we have a lot of indicators, alot of specifications, but they vary by time by unit.",
                    "label": 0
                },
                {
                    "sent": "They even sometimes you can't even understand what their semantics or their meaning is and there in different formats, often in CSV, sometimes in RDF there is a run on different licenses.",
                    "label": 0
                },
                {
                    "sent": "And the access points are also like like, really, every organization has their own way of getting this data and this is for us really, a motivation to have a central access point for open data which relates to cities and statistically and also another one.",
                    "label": 1
                },
                {
                    "sent": "Another problem which I will discuss later is there will be.",
                    "label": 1
                },
                {
                    "sent": "We discovered a lot of missing values.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is quickly the pipeline.",
                    "label": 0
                },
                {
                    "sent": "I mean, the talk is not mainly pipelines, just on certain issues on it, so this is quickly I wrap it up.",
                    "label": 0
                },
                {
                    "sent": "We have the crawler which gets the websites, then it reads the files, it converts it and annotate it to an ontology.",
                    "label": 0
                },
                {
                    "sent": "And it stores it in a triple store.",
                    "label": 0
                },
                {
                    "sent": "In our case, it's now it's Gina, but we're agnostic towards Triplestores.",
                    "label": 0
                },
                {
                    "sent": "Any trips or could work and then we run like in our case like predictions on top of this data.",
                    "label": 0
                },
                {
                    "sent": "So in our case it's like computing missing values.",
                    "label": 0
                },
                {
                    "sent": "And the motivation of this pipeline is that we actually want to.",
                    "label": 0
                },
                {
                    "sent": "In reach statistical data, by using this pipeline so the enrichment could be like like like filling in missing values, but enrich enrichment could also be like like geographical information to our data and even at your graphical relations to it.",
                    "label": 0
                },
                {
                    "sent": "So it's A kind of enhancing the existing data and republishing it.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is tautology.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's a very simple and told you to be honest and it's mainly Tessa spatial context, temporal context indicators, and I mean the data itself.",
                    "label": 1
                },
                {
                    "sent": "There are F3 precita data context is blank node and on this blank nodes at a different context and the indicator center values and the indicator itself.",
                    "label": 0
                },
                {
                    "sent": "I mean is a kind of background information.",
                    "label": 0
                },
                {
                    "sent": "We store, you need category data type and so on, and even value ranges will come in the future.",
                    "label": 0
                },
                {
                    "sent": "And I mean then tolerated Description, Logic a let's AH, which means that we don't do too much reasoning, it's just concept, an concept in the role hierarchies.",
                    "label": 0
                },
                {
                    "sent": "So it's very.",
                    "label": 0
                },
                {
                    "sent": "It's a simple ontology, but we use.",
                    "label": 0
                },
                {
                    "sent": "So the data.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sources I will quick claims on two of the main data sources view we use.",
                    "label": 0
                },
                {
                    "sent": "One is urban audit.",
                    "label": 0
                },
                {
                    "sent": "I mean this is for us the main source of data and is the most appealing and interesting one.",
                    "label": 0
                },
                {
                    "sent": "It's actually initiative to increase quality of life.",
                    "label": 1
                },
                {
                    "sent": "In Europe it's by the collected by euro start, but provided by the statistical institutes it's a huge range of topics and it has around 2:15 indicators.",
                    "label": 1
                },
                {
                    "sent": "Here are some statistical numbers on it, so for 2010 we have 900 cities with 202 indicators.",
                    "label": 1
                },
                {
                    "sent": "End which is for us, very, very promising.",
                    "label": 0
                },
                {
                    "sent": "They just have around 50% of missing values, so you can really see there's a progress and there is an effort of the European Union to fill out these datasets.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So a second data set is the United Nations artistically division.",
                    "label": 0
                },
                {
                    "sent": "And here the outlook is much Creamer.",
                    "label": 0
                },
                {
                    "sent": "I mean here we can see that for the whole data set there's just 0.5% of values available, which makes sense.",
                    "label": 0
                },
                {
                    "sent": "I mean they collect the collect data from all matrices of the whole world, and I mean as suspected, many cities I don't know, like maybe in in.",
                    "label": 0
                },
                {
                    "sent": "Like in Asia or in Africa, there just not so much data available, so the UN is not able to publish them.",
                    "label": 0
                },
                {
                    "sent": "This is a guess.",
                    "label": 0
                },
                {
                    "sent": "But this is not even our main concern.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our main concern is now we merge datasets.",
                    "label": 0
                },
                {
                    "sent": "So what what is happening?",
                    "label": 0
                },
                {
                    "sent": "We merge already sparse data set what's happening?",
                    "label": 1
                },
                {
                    "sent": "We even add more sparsity.",
                    "label": 0
                },
                {
                    "sent": "So this this rate caps are happening by there's two reasons for this.",
                    "label": 0
                },
                {
                    "sent": "First of all, often there's three disjoint cities and as a second problem we are not always able to do proper entity recognition.",
                    "label": 1
                },
                {
                    "sent": "Align the same city and the second one is by default we assume indicators are disjoint.",
                    "label": 1
                },
                {
                    "sent": "We can't really say that like population A from UN is the same as population from euro start.",
                    "label": 0
                },
                {
                    "sent": "So we say actually they're just joined and just in a second step we can decide if they are not disjoint.",
                    "label": 0
                },
                {
                    "sent": "So in this as you can see, this makes this situation inverse, so we start.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'd like.",
                    "label": 0
                },
                {
                    "sent": "Like having a look at this problem, like how do we fill out this caps so we so?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we did is we developed some based methods to predict missing or impute missing values and.",
                    "label": 0
                },
                {
                    "sent": "So our our approach is the following.",
                    "label": 0
                },
                {
                    "sent": "I mean, we are our group is not.",
                    "label": 0
                },
                {
                    "sent": "We're not really machine learning, specially.",
                    "label": 0
                },
                {
                    "sent": "So what we said we just set on really well known techniques and apply them in a basket basket based.",
                    "label": 0
                },
                {
                    "sent": "So we collect like simply machine learning methods collected and let them run on our on our data set.",
                    "label": 0
                },
                {
                    "sent": "And one assumption is that every indicator has be treated by its own, so we don't really run it on the on the entire huge datasets we take every indicator.",
                    "label": 1
                },
                {
                    "sent": "And two for this indicator, the predictions.",
                    "label": 0
                },
                {
                    "sent": "And obviously this is the standard like way it's a predictor.",
                    "label": 0
                },
                {
                    "sent": "We to have a regression model and then we predict the target.",
                    "label": 1
                },
                {
                    "sent": "We use normalized root mean square error normalized.",
                    "label": 0
                },
                {
                    "sent": "So we include the value ranges which is important for averaging immediate needed and we used stratified 10 fold cross validation.",
                    "label": 0
                },
                {
                    "sent": "I mean this is all standard machine learning techniques.",
                    "label": 0
                },
                {
                    "sent": "It's not very very.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Special I would say so.",
                    "label": 0
                },
                {
                    "sent": "We developed two approaches.",
                    "label": 0
                },
                {
                    "sent": "One is like the more intuitive one.",
                    "label": 0
                },
                {
                    "sent": "The first one is actually we assume that some of the existing indicators are able.",
                    "label": 0
                },
                {
                    "sent": "We are able one indicated with a set of indicators to predict the target indicator.",
                    "label": 0
                },
                {
                    "sent": "So we choose like using a correlation matrix.",
                    "label": 0
                },
                {
                    "sent": "The best fitted indicators and use these three methods methods to predict the target and then we choose the best model.",
                    "label": 1
                },
                {
                    "sent": "By using this our embassy, but this may I mean, this approach has one drawback.",
                    "label": 0
                },
                {
                    "sent": "We need a complete matrix, so it means that a lot of cities are actually dropped out.",
                    "label": 1
                },
                {
                    "sent": "And here I mean this is the result of this approach.",
                    "label": 0
                },
                {
                    "sent": "We get our MSE with 10 predictors of 0.3 which is.",
                    "label": 0
                },
                {
                    "sent": "Very good.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So by having this problem of deleting or not being able to predict like like a lot of cities, we developed the second approach.",
                    "label": 0
                },
                {
                    "sent": "So this is actually instead of taking the indicators in the self, we can we perform a principle component analysis on top of all the indicators.",
                    "label": 0
                },
                {
                    "sent": "So in principle component is like roughly speaking at dimension reduction method we change the coordinate system and extract principle components.",
                    "label": 0
                },
                {
                    "sent": "Which 10 are enriched.",
                    "label": 0
                },
                {
                    "sent": "So the matrix of this print principle components and rich with all the missing data points are filled with neutral values for this PCA.",
                    "label": 1
                },
                {
                    "sent": "And so now we have this nice situation that we have a complete matrix and we can again do the same, run our three methods and choose the best one.",
                    "label": 0
                },
                {
                    "sent": "And this now gives us the possibility to pre predict every single missing value in our data set.",
                    "label": 0
                },
                {
                    "sent": "Obviously what you would expect this to performance is dropping and it's around 3.2%.",
                    "label": 0
                },
                {
                    "sent": "Of these are messy.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So results approaches could approach one is good, but it just doesn't predict us enough value, so we dropped it.",
                    "label": 0
                },
                {
                    "sent": "So this is gone and now we're will investigate further approach to this PCI PCA based method and I think we figured out there's still a lot of room for improvement, so one improvement is by just at one point we started.",
                    "label": 0
                },
                {
                    "sent": "Replacing linear regression with robust linear regression and already the overall performance improved by 1%.",
                    "label": 0
                },
                {
                    "sent": "So it went to 2.29.",
                    "label": 0
                },
                {
                    "sent": "So by adding more and more methods we actually might push our results down and so so for future use.",
                    "label": 0
                },
                {
                    "sent": "Now problem will be an approach to.",
                    "label": 0
                },
                {
                    "sent": "But one drawback is the calculation of the whole data set needs at this point 12 hours, so it's very slow.",
                    "label": 0
                },
                {
                    "sent": "We have implemented everything now so.",
                    "label": 0
                },
                {
                    "sent": "It's so maybe there's some kind of chance of parallelization.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And all our results are published as linked data.",
                    "label": 1
                },
                {
                    "sent": "There's a sparkle endpoint for everybody to use end as well, like.",
                    "label": 0
                },
                {
                    "sent": "Like you can use actually the Uriah facility and access all the collected and predicted data, including the quality as well.",
                    "label": 0
                },
                {
                    "sent": "So this is like a kind of an idea to feed it back into the Elodie cloud, so other people or other developers can reuse our our in particular predictions.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is now actually more for discussion, so I introduced like a framework for filling in missing values and pipeline for publishing them, and we already have some ongoing work, so this is already working progress, so we added new datasets, so USN sources, one of the datasets we added, which is not very.",
                    "label": 1
                },
                {
                    "sent": "I mean I was very disappointed as I expect more from the Americans to have like more data on their cities, but it's very spa.",
                    "label": 0
                },
                {
                    "sent": "It's also very sparse and it doesn't cover any environmental and any.",
                    "label": 0
                },
                {
                    "sent": "Not too many social aspects so the comparing urban audit and you and you and census.",
                    "label": 0
                },
                {
                    "sent": "It's a huge difference.",
                    "label": 0
                },
                {
                    "sent": "I mean I must say and a second, but this is a whole line of research.",
                    "label": 0
                },
                {
                    "sent": "I mean, a lot of cities published their own data is open data, so might be interesting to crawl this single cities open data portals to add this to our portal.",
                    "label": 0
                },
                {
                    "sent": "But this is, I mean this rappers is a lot of work cause a rapper would have to be written for every single city.",
                    "label": 0
                },
                {
                    "sent": "But there is approaching his curiosity.",
                    "label": 0
                },
                {
                    "sent": "Which actually tries to address this problem, and we're also adding you method method, so support vector machines is one of our candidates which might be interesting for the predictions.",
                    "label": 0
                },
                {
                    "sent": "Robust linear regressions we have evaluated already.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "Working on what we call Crostata set prediction.",
                    "label": 1
                },
                {
                    "sent": "The idea of cross data set prediction is the following, so we have already our base data set and now we we add a new data set.",
                    "label": 0
                },
                {
                    "sent": "So we want to actually use the existing data set to predict into the new one.",
                    "label": 0
                },
                {
                    "sent": "So we actually have two separate datasets and predict from one into the order.",
                    "label": 0
                },
                {
                    "sent": "And this is like we did I SWC paper we don't know if it's going to be accepted on this topic and the second one is Learning Ontology mappings which is probably related to your work as well.",
                    "label": 0
                },
                {
                    "sent": "So what we what I said before we had this problem of disjoint indicators, but often these are the same indicators.",
                    "label": 0
                },
                {
                    "sent": "So what we try to do is like using regression methods to find relations between two indicators.",
                    "label": 0
                },
                {
                    "sent": "I mean the best one is a linear like it's one to one.",
                    "label": 0
                },
                {
                    "sent": "But there's also maybe equations involved so there's a conversion from one indicator.",
                    "label": 0
                },
                {
                    "sent": "Another and future work there is lot to do, so it's like the story with this.",
                    "label": 0
                },
                {
                    "sent": "How is it called is Fatima when you open one wheel like 10 orders come come after.",
                    "label": 0
                },
                {
                    "sent": "So one is.",
                    "label": 1
                },
                {
                    "sent": "I mean we haven't investigated at all.",
                    "label": 0
                },
                {
                    "sent": "Is time series analysis and this is obviously a peak.",
                    "label": 0
                },
                {
                    "sent": "I mean an important point because now we're actually.",
                    "label": 0
                },
                {
                    "sent": "Do not consider time.",
                    "label": 1
                },
                {
                    "sent": "We just take time as a as a kind of variable and time series will obviously connect or or use the relation in the time itself with time series.",
                    "label": 0
                },
                {
                    "sent": "So this might be combined with the existing approach, but we don't really know yet what we're going to do, and this is related to politics work.",
                    "label": 0
                },
                {
                    "sent": "Our aim is also to connect it to the RDF data cube.",
                    "label": 0
                },
                {
                    "sent": "I mean this is obviously on hand.",
                    "label": 0
                },
                {
                    "sent": "You know if you collect this data it might be.",
                    "label": 0
                },
                {
                    "sent": "The vocabulary MIP interesting that we either make power Ontology or will use.",
                    "label": 0
                },
                {
                    "sent": "Actually there are Def Datacube vocabulary and.",
                    "label": 1
                },
                {
                    "sent": "Another point is validation and correction of predictions.",
                    "label": 0
                },
                {
                    "sent": "So we have this example.",
                    "label": 0
                },
                {
                    "sent": "We predict cinema seats and often our predicted values are 0.56 point 7, but there is no 6.7 cinema seats in a city or cinemas as well.",
                    "label": 0
                },
                {
                    "sent": "There's no half cinema so often we could actually use our ontology to correct the value.",
                    "label": 0
                },
                {
                    "sent": "So if you have 6.7 we would round.",
                    "label": 0
                },
                {
                    "sent": "It would assume that we have 7 cinemas.",
                    "label": 0
                },
                {
                    "sent": "So this sometimes the our predictions are a bit strange.",
                    "label": 0
                },
                {
                    "sent": "I would say, and another one will be using the untold to speed up the process so we remember the paramaters, enter methods which we used for an indicator.",
                    "label": 0
                },
                {
                    "sent": "So in future like predictions we would actually use the data in the ontology to do the prediction.",
                    "label": 0
                },
                {
                    "sent": "And this is also nothing new but this might be nice and the last one we might be really linking our or integrating link to your data and open street map.",
                    "label": 0
                },
                {
                    "sent": "In Open Street, Map itself could be a nice data source because there's a lot of of like regarding Rd network.",
                    "label": 0
                },
                {
                    "sent": "Screen areas will be actually might be interesting to extract the Openstreetmap data and convert it into indicators which hasn't been done yet.",
                    "label": 0
                },
                {
                    "sent": "I mean this is still very.",
                    "label": 0
                },
                {
                    "sent": "I think that's a very promising direction to go, so thank you very much for your attention and.",
                    "label": 0
                }
            ]
        }
    }
}