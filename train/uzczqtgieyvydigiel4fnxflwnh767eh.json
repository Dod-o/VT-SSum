{
    "id": "uzczqtgieyvydigiel4fnxflwnh767eh",
    "title": "Optimizing Two-Dimensional Search Results Presentation",
    "info": {
        "author": [
            "Flavio Chierichetti, Dipartimento di Informatica, Sapienza University of Rome"
        ],
        "published": "Jan. 13, 2012",
        "recorded": "February 2011",
        "category": [
            "Top->Computer Science->Web Search"
        ]
    },
    "url": "http://videolectures.net/wsdm2011_chierichetti_otd/",
    "segmentation": [
        [
            "So height is, you know.",
            "Giant worker Ravikumar barragan at Yahoo Research and you have lots so."
        ],
        [
            "So let me start with an example.",
            "So here is what you would see on an image or product search, say on the Yahoo engine or or some other engine you look for anything.",
            "Say you know some kind of furniture, an well the search engine will compute a score for each possible result and then say the best result will be placed here in the top left, the second best on its right, the third here, and so on and so forth.",
            "So basically your player search engines are placing results.",
            "Left to right and top to bottom, this is called a row major order, so that's what I say.",
            "As you know, people are doing right now."
        ],
        [
            "But so there are plenty of evidence.",
            "Evidence is the users do not serial measure, so we can get this evidence from eye tracking data where we see that user don't actually go this way, but you do something different.",
            "We're not taking into account the fact that users can understand visual cues placed by search engines in different ways, and we're not taking into account diversity of users."
        ],
        [
            "So for instance, this is an eye gaze pattern from from Yao.",
            "I guess some years ago, so we see that you know we have the usual so called Golden triangle here.",
            "Many people will look on the say top left corner of the screen.",
            "But I want say before looking here that will go down reasonably high probability.",
            "So that's something that row measure hoarder doesn't capture when presenting results."
        ],
        [
            "So, so we can't really try to guess our user.",
            "Look at web pages using this.",
            "I guess data because I guess getting I guess data is very very expensive.",
            "So we propose a new approach which is which is penalize click logs where the user click on the page and in which order they will click on pictures on the page and infer users scan patterns according to this clicks, right?",
            "So a user might look at a page.",
            "This way or this other way, we don't know exactly where they will look, but we know where they click and say what time they click on each page on each picture in the page so we have hundreds of millions of users in our logs and now can we infer users Cam patterns?",
            "Of course to do that."
        ],
        [
            "You have kind of to postulate a user model.",
            "How do users actually look at our page right?",
            "So for instance, say that the user is looking at this picture.",
            "OK, now we're saying that there exist some probability that the user would go left, so probably they will go down and some probability that we go right.",
            "So basically, if the user is here, anyone stop looking at a page altogether, it will flip a coin and you know we probably point to go left or .5 down and .3, right?",
            "Now."
        ],
        [
            "Now, of course, you might say that well, of course we don't have user side positions, but we don't even have transition probabilities.",
            "So how can we guess transition probabilities given the data?",
            "We have just a click logs.",
            "Well, we have click position and click sequence.",
            "Can we infer this probabilities from from these two from these two?",
            "Beta, right?"
        ],
        [
            "In this data.",
            "So here's what we actually can see in our logs, so this is kind of the input of our first problem.",
            "We have this grid, say, in this case 5 * 3 grid and say the first user do the following, click here, then here and then here.",
            "We don't have any idea on what the probabilities where the transition probabilities where, but we know that the user clicked here and now, and now we're also assuming that user Markovian in the sense that.",
            "What they do?",
            "You know you know when looking at a slot only depends on that slot an on the picture that that's in the slot.",
            "So."
        ],
        [
            "For instance, in this case, in this case, this three clicks here could have been.",
            "Determined by at least by many different scan patterns, in fact, exponentially many so the user could have taken, say, the red path, or maybe the green one.",
            "Right, and as we see here, if the user say took the red pad, then what's happening is it didn't click in the first pic on the first picture, it click on the second, the third not on the 4th and the 5th.",
            "So here we have some kind of hidden Markov model.",
            "OK, the user moves on this Markov chain and sometimes we get some output on the Markov chain with some probability.",
            "We will get, you know the event that the user clicked on this picture.",
            "In which case we will know that the user was looking at a picture, but of course there's some probability that he was looking at his picture and we want know about that.",
            "We have to infer this."
        ],
        [
            "So so this this kind of gives us the problems.",
            "The one that we just talked about out to infer the Markov chain probabilities of this.",
            "This kind of hidden Markov model type of problem and then the original problem.",
            "How should we place objects in the Markov chain given the Markov chain probabilities that we infer?",
            "Right?"
        ],
        [
            "So let's let's look 1st at this one problem here."
        ],
        [
            "So can we infer the maximum likelihood probabilities so this problem is known to be hard for general graphs, so you can do anything and showing that it's hard for general graphs is kind of easy.",
            "You can reduce from you know, usual problems like independent set or or click.",
            "So we were able to show NP hardness for the grid.",
            "Was non trivial because of the very little constraints involved.",
            "We just have no this I guess list of clicks and we had to kind of construct an NPR instances just based on them so we can show NPR nessan.",
            "We believe that one could also push the proof to showing strong inapproximability results, but we didn't do that.",
            "So that's an open question."
        ],
        [
            "So, given given this NP hardness, we know we this was kind of disappointing, but we still wanted to solve the problem.",
            "So we start looking for you Ristic San.",
            "We find some that appears to be efficient an of equality in practice, and they're kind of Boo Boo struck bootstrap like methods one get into details, but you can find them in the paper."
        ],
        [
            "So, so the probabilities that we infer by running our best heuristics on the data we had is RDS.",
            "So for instance, you see that you know from the top left position there is reasonably high probability of going left, and I'm going down.",
            "But the probability that you go from here back to 00 is very small, at least in a single step.",
            "You might take a longer pets to go back there, but probably going from zero 1200 is, you know like 2 / 1000, so it's very small."
        ],
        [
            "Now what do we mean by the fact that the probability is this?",
            "But this is this was our best heuristics.",
            "Well, we did the following.",
            "We computed the stationary distribution of this Markov chain and all of the Markov chain produced by our different heuristics.",
            "And we computed the variational distance that's some form of probability distances between the stationary distribution of the Markov chains and empirical quick fraction.",
            "We were kind of heuristically saying that if a user kind of has time to mixes, makes some steps on the Markov chain, then.",
            "He will mix and if you mix this then the probability of clicking doesn't really depend on the starting state or anything else and well.",
            "In any case the variational distance between our best heuristics and empirical click fraction was rather small.",
            "0.2 or something like that."
        ],
        [
            "So the empirical click fraction and OK so unfortunately the colors are not good, but so then people click fraction an the results of our best touristy heuristics.",
            "Kind of confirmed that there exists on Golden triangle here.",
            "Most of the people will click just say in the picture that are on the top left.",
            "But you know if the colors were better you would see that here we also have silver triangle.",
            "So the probability that the user will actually click here is higher than the probability that the user will click here.",
            "So that's something that you know we didn't expect, and we found surprising so.",
            "You know, so, given these empirical quick fraction and stationary distribution of our Markov chain, we can."
        ],
        [
            "We can start thinking about the placement problem right, or at least heuristics for the placement problem.",
            "OK, we know where user kind of user are likely to click.",
            "Now.",
            "How should we place object in the Markov chain?"
        ],
        [
            "Um, well what we want to do in blazing, you know, in placing the objects is to guarantee that users are we likely to click on useful objects, objects that are, say, images, picture ads, or news that are useful to them or the search engine, right?"
        ],
        [
            "So for instance, we know that this spot here as I's probability of being clicked on.",
            "So maybe the best say picture should be placed."
        ],
        [
            "Yeah, maybe we should place the second here."
        ],
        [
            "Now, if we were to use row major order, what most people are doing right now, we would place the worst picture here.",
            "But you know, as you know again, if colors would be better, you would see that this is not the worst place to place the picture on."
        ],
        [
            "In fact, this is the worst place, and here you would put something like the 10th best picture or something like that.",
            "So it's not true that say, the bottom right corner is the worst one.",
            "Yeah, that's I mean you can find better pictures in the paper I guess.",
            "So that was so.",
            "This is something that we want to do while placing objects.",
            "We want to guarantee that users will be likely to click on good objects, but there's also a second thing that we want to do."
        ],
        [
            "So suppose and it's kind of regards user diversity or something like that.",
            "Suppose that user queries the search engine for Apple OK. Then maybe the user is thinking about Apple Incorporation.",
            "And So what?",
            "The user would like to see is the picture of the log of Apple Incorporation.",
            "That would be the best thing you could return.",
            "Or well, you could return an actual Apple in which case the user would maybe think that there was an honest mistake.",
            "You search for Apple and it got a picture of an Apple.",
            "But if you were to return, say, a picture of the Big Apple of New York City, then the user will, will, you know?",
            "Be unsatisfied is likely to be unsatisfied."
        ],
        [
            "Dehen if the user was actually thinking of the Big Apple and you know for some reason just search for the second word for Apple then well, you would want to return really the picture of the Big Apple as the first one.",
            "Again, the actual Apple is not a big problem, but say the log of Apple incorporation is not is not what you want to turn."
        ],
        [
            "Right and so so this kind of brings us to some model of user satisfaction.",
            "Different objects have different likelihoods of satisfying the user, and say the actual Apple will avoid losing the user already satisfaction in our example because, well, it's not likely that the user will stop looking at the page altogether just because it's so.",
            "It's an Apple, but a user would get more expected utility from the others.",
            "In the first case, you wanted an Apple Store, so if you actually click, if you return the.",
            "The Apple Incorporation logo, then you would have taken to say the Apple webpage that would have been good for him.",
            "Or maybe he was looking for a hotel in the Big Apple, right?",
            "So so we have two things that are playing together here.",
            "One is the likelihood of the user.",
            "Stopping that the user stops look looking at the page because this is something that it doesn't want to see.",
            "And then there's the utility that each object could bring to the user."
        ],
        [
            "So for instance, this is a good placement, at least in our example, right?",
            "We place the Apple here so the user starts here, looks at the Apple is, you know, if he was really searching."
        ],
        [
            "For the Apple and it would be OK, everything will be fine if you want."
        ],
        [
            "Searching for, say, the Apple Incorporation or the Big Apple, then now we'd say some probability you will actually transition to either the Big Apple or or Apple or Dell incorporation logo, in which case it would be happy.",
            "So placing objects this way would definitely be better than placing here Depot logo here or the OR, say, New York logo in the first position.",
            "So that's something that our problem that our definition of the problem has to take into consider."
        ],
        [
            "Ocean.",
            "So.",
            "Trying to be a bit more formal here, here is exactly what we want to do.",
            "Each object is defined by a pair stopping probability, an expected utility.",
            "The stopping probability is the probability that the user will stop looking at a page if he sees that object, that object and it doesn't like it, and the expected utility is, say, the gain of the user.",
            "If it looks at that object, OK, whatever the gain is, it can be.",
            "You know some time getting monetary gain or just user satisfaction.",
            "And whenever a user sees an object she will accrues is expected utility.",
            "And will stop looking at a page without stopping probability."
        ],
        [
            "So for instance, if the user starts here, she will accrue utility you of Apple.",
            "The utility of the Apple."
        ],
        [
            "Then she will flip a coin with probability P of Apple.",
            "She will just stop looking at the page, so our total utility will be the utility of the epsilon.",
            "But if she doesn't."
        ],
        [
            "Stop then she will transition somewhere else according to the Markov chain probabilities."
        ],
        [
            "And you know, maybe she'll go down as she walked through the utility of the, you know, the Apple logo picture.",
            "OK, so that's that's our."
        ],
        [
            "Model.",
            "Another placement problem is easy.",
            "How should we place objects automatically?",
            "Maximize the users extractor utility?",
            "So in another paper we analyzed this problem in his full generality on general graphs and we give some approximation algorithms and some hardness results, but in general it's hard for general graphs.",
            "For the graph we weren't able to find say I guess I polynomial approximation algorithm, But we do give efficient heuristics and also kernelization trick.",
            "That you could use to reduce their solution space.",
            "So suppose you want to look at the best.",
            "Yeah, the one best placement so you can do that.",
            "You need exponential time, but this conversation trick makes that I'm reasonably small."
        ],
        [
            "So if looking at quickly at our heuristics so the hit heuristics order Markov chains lots.",
            "Increasingly, by hitting time, the heating time of a slot in a Markov chain is the expected time you need to get to that to that single slot.",
            "The egg and utility orders lots according to the stationary probability, and then we have the column and row ordering the ones we see at the beginning.",
            "And now we just placed items over your utility in better slots.",
            "Slots that are better according to one of these four things.",
            "So what we can see here is that the hitting time heuristic bits, the row it's everyone else in.",
            "Basically each of the top K queries.",
            "We have yard average utility over the top K queries and hitting time heuristic is the best one by reasonably large amount.",
            "Right then we see also that the row ordering is actually the worst one, so that's something that you know it's good to keep in mind."
        ],
        [
            "So here's what they eat.",
            "Slots ordering would look like, so we would place the best picture here.",
            "The second best year, third 4th, 5th, 6th, 7th and so on and so forth.",
            "So we see that that's kind of as exact like pattern as opposed to a row major ordering."
        ],
        [
            "Thank you.",
            "So I'm immediately struck by the relationship between the two talks we've just seen because we wrote reason one and trees and the other one.",
            "Essentially, if you dangle it by the top corner, right?",
            "So that was a very interesting observation.",
            "And the other thing I was doing I was sitting here thinking about my own behavior with image search, and the reason I click on the bottom corner is because they're always weird.",
            "So, so you do your image search and you get.",
            "Yep, monkeys, monkeys, monkeys, monkeys, monkeys, monkeys and then down in the bottom there's something different because the lowest relevant or the least likely thing is being placed there and you go there out of curiosity more than anything else.",
            "It's not because you think it's relevant to go.",
            "Yes, that's an explanation I guess.",
            "I hope not every user is like that, but.",
            "Yeah, I mean, that's definitely an explanation, so we didn't actually do say some kind of bucket testing.",
            "So basically just I don't know.",
            "Take a query and just blaze pictures randomly and see where user clicked.",
            "We didn't do that, but we couldn't do that, but.",
            "It's unclear if that's really the reason.",
            "It might be that users are actually really just, you know, going through the Markov chain an you know so for some reason.",
            "That just depends on, uh, I mean, if you buy our Markov user model then what happens is that you know, once you get to the bottom right corner you remain there.",
            "You just don't go back where you are on the assumption that you only make a step of one that is right.",
            "That is right, that is right.",
            "The other comment is going to make was that you've kind of assumed that all of your layout is in a grid and it strikes me that you could have a lot of fun thinking about different sized images.",
            "So the ones that that the system is saying, hey, this is highly likely.",
            "Give a bigger thumbnail for it.",
            "Make it more attractive to be clicked on 'cause 'cause the HCI people will tell you that the effort that it takes to move a mouse and click on something depends on the size of the thing that you're trying to hit.",
            "Raised way I hate our HR system at the University 'cause the logout button is like 3 millimeters wide, so I agree with you on this thing.",
            "So again the issue we had is that we didn't do bucket testing.",
            "We couldn't do back at testing.",
            "It's hard to get that kind of information from the logs we had because where we didn't actually we had pictures of all the same size, so we couldn't actually say, OK, let's just place a larger picture here so that the user is more likely to click on that from.",
            "If you assume you know the Markov chain right and you just want to place objects on a more general Grafton just agreed, then we do have some algorithms that I guess just a theoretical interest since they are not.",
            "Usable in practice for some reasons.",
            "Complexity reasons, an approximation factor reasons.",
            "But I agree with you that this kind of marginal problem would be interesting to solve even from practical point of view.",
            "Don't worry, I mean very little users are like Alistair's question here.",
            "Maybe 1.",
            "Did you also look into time domain?",
            "So do you have an intuition how long a gay slingers at a certain spot so self transitions away, right?",
            "So actually we didn't look at that.",
            "We did look at self transitions.",
            "I didn't talk about that, but we didn't look at how much.",
            "So we didn't.",
            "I guess use this part of the log data.",
            "The timestamp data we don't use that.",
            "We just looked at the order of the clicks, not the time when they when they happen.",
            "And yeah again, I'm going to agree that this would be.",
            "This would be interesting to do.",
            "There in the back.",
            "Yeah, I was wondering how to train a hidden Markov model.",
            "How many users do you use to train the model right and have you have you tried to compare the behavior different user?",
            "OK, so we had.",
            "I guess 10s of millions of users.",
            "Or at least we had 10s of millions of traces.",
            "We didn't know which, you know.",
            "If say, a user you know 100,000 traces or not, we don't know that we just had traces and they were kind of 10s of millions and we didn't look at say different behaviors of different users.",
            "We are this kind of Markovian assumption that kind of made the problem more tractable.",
            "I guess that you know that's definitely interesting to look at that it's just that maybe it would be, you know, it would be more useful to try to solve this easier problem first to get a good solution for this problem 1st and then look at possible generalizations.",
            "Yeah, and I agreed that that would be quite important one.",
            "In the back.",
            "Do you?",
            "Do you have an intuition about whether the hot upper left corner is a result of reading order conventions?",
            "So, so the data we had was.",
            "For the US Yahoo.",
            "So people you know, most people would just look from left to right.",
            "I am not sure about that.",
            "I actually don't think it's because you know there were some people that you are used to look from to read from right to left because it happens also on the bottom.",
            "So we would have people that actually starts looking at.",
            "I guess bottom right corner and go up.",
            "So I don't think that's the reason.",
            "OK, let's thank you again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So height is, you know.",
                    "label": 0
                },
                {
                    "sent": "Giant worker Ravikumar barragan at Yahoo Research and you have lots so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me start with an example.",
                    "label": 0
                },
                {
                    "sent": "So here is what you would see on an image or product search, say on the Yahoo engine or or some other engine you look for anything.",
                    "label": 1
                },
                {
                    "sent": "Say you know some kind of furniture, an well the search engine will compute a score for each possible result and then say the best result will be placed here in the top left, the second best on its right, the third here, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "So basically your player search engines are placing results.",
                    "label": 0
                },
                {
                    "sent": "Left to right and top to bottom, this is called a row major order, so that's what I say.",
                    "label": 0
                },
                {
                    "sent": "As you know, people are doing right now.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But so there are plenty of evidence.",
                    "label": 1
                },
                {
                    "sent": "Evidence is the users do not serial measure, so we can get this evidence from eye tracking data where we see that user don't actually go this way, but you do something different.",
                    "label": 0
                },
                {
                    "sent": "We're not taking into account the fact that users can understand visual cues placed by search engines in different ways, and we're not taking into account diversity of users.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for instance, this is an eye gaze pattern from from Yao.",
                    "label": 0
                },
                {
                    "sent": "I guess some years ago, so we see that you know we have the usual so called Golden triangle here.",
                    "label": 0
                },
                {
                    "sent": "Many people will look on the say top left corner of the screen.",
                    "label": 0
                },
                {
                    "sent": "But I want say before looking here that will go down reasonably high probability.",
                    "label": 0
                },
                {
                    "sent": "So that's something that row measure hoarder doesn't capture when presenting results.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so we can't really try to guess our user.",
                    "label": 0
                },
                {
                    "sent": "Look at web pages using this.",
                    "label": 0
                },
                {
                    "sent": "I guess data because I guess getting I guess data is very very expensive.",
                    "label": 0
                },
                {
                    "sent": "So we propose a new approach which is which is penalize click logs where the user click on the page and in which order they will click on pictures on the page and infer users scan patterns according to this clicks, right?",
                    "label": 1
                },
                {
                    "sent": "So a user might look at a page.",
                    "label": 0
                },
                {
                    "sent": "This way or this other way, we don't know exactly where they will look, but we know where they click and say what time they click on each page on each picture in the page so we have hundreds of millions of users in our logs and now can we infer users Cam patterns?",
                    "label": 0
                },
                {
                    "sent": "Of course to do that.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You have kind of to postulate a user model.",
                    "label": 1
                },
                {
                    "sent": "How do users actually look at our page right?",
                    "label": 0
                },
                {
                    "sent": "So for instance, say that the user is looking at this picture.",
                    "label": 0
                },
                {
                    "sent": "OK, now we're saying that there exist some probability that the user would go left, so probably they will go down and some probability that we go right.",
                    "label": 0
                },
                {
                    "sent": "So basically, if the user is here, anyone stop looking at a page altogether, it will flip a coin and you know we probably point to go left or .5 down and .3, right?",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, of course, you might say that well, of course we don't have user side positions, but we don't even have transition probabilities.",
                    "label": 1
                },
                {
                    "sent": "So how can we guess transition probabilities given the data?",
                    "label": 1
                },
                {
                    "sent": "We have just a click logs.",
                    "label": 0
                },
                {
                    "sent": "Well, we have click position and click sequence.",
                    "label": 0
                },
                {
                    "sent": "Can we infer this probabilities from from these two from these two?",
                    "label": 0
                },
                {
                    "sent": "Beta, right?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this data.",
                    "label": 0
                },
                {
                    "sent": "So here's what we actually can see in our logs, so this is kind of the input of our first problem.",
                    "label": 0
                },
                {
                    "sent": "We have this grid, say, in this case 5 * 3 grid and say the first user do the following, click here, then here and then here.",
                    "label": 0
                },
                {
                    "sent": "We don't have any idea on what the probabilities where the transition probabilities where, but we know that the user clicked here and now, and now we're also assuming that user Markovian in the sense that.",
                    "label": 0
                },
                {
                    "sent": "What they do?",
                    "label": 0
                },
                {
                    "sent": "You know you know when looking at a slot only depends on that slot an on the picture that that's in the slot.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For instance, in this case, in this case, this three clicks here could have been.",
                    "label": 0
                },
                {
                    "sent": "Determined by at least by many different scan patterns, in fact, exponentially many so the user could have taken, say, the red path, or maybe the green one.",
                    "label": 1
                },
                {
                    "sent": "Right, and as we see here, if the user say took the red pad, then what's happening is it didn't click in the first pic on the first picture, it click on the second, the third not on the 4th and the 5th.",
                    "label": 0
                },
                {
                    "sent": "So here we have some kind of hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "OK, the user moves on this Markov chain and sometimes we get some output on the Markov chain with some probability.",
                    "label": 0
                },
                {
                    "sent": "We will get, you know the event that the user clicked on this picture.",
                    "label": 0
                },
                {
                    "sent": "In which case we will know that the user was looking at a picture, but of course there's some probability that he was looking at his picture and we want know about that.",
                    "label": 0
                },
                {
                    "sent": "We have to infer this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so this this kind of gives us the problems.",
                    "label": 0
                },
                {
                    "sent": "The one that we just talked about out to infer the Markov chain probabilities of this.",
                    "label": 0
                },
                {
                    "sent": "This kind of hidden Markov model type of problem and then the original problem.",
                    "label": 0
                },
                {
                    "sent": "How should we place objects in the Markov chain given the Markov chain probabilities that we infer?",
                    "label": 1
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's let's look 1st at this one problem here.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So can we infer the maximum likelihood probabilities so this problem is known to be hard for general graphs, so you can do anything and showing that it's hard for general graphs is kind of easy.",
                    "label": 1
                },
                {
                    "sent": "You can reduce from you know, usual problems like independent set or or click.",
                    "label": 1
                },
                {
                    "sent": "So we were able to show NP hardness for the grid.",
                    "label": 1
                },
                {
                    "sent": "Was non trivial because of the very little constraints involved.",
                    "label": 0
                },
                {
                    "sent": "We just have no this I guess list of clicks and we had to kind of construct an NPR instances just based on them so we can show NPR nessan.",
                    "label": 0
                },
                {
                    "sent": "We believe that one could also push the proof to showing strong inapproximability results, but we didn't do that.",
                    "label": 0
                },
                {
                    "sent": "So that's an open question.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, given given this NP hardness, we know we this was kind of disappointing, but we still wanted to solve the problem.",
                    "label": 0
                },
                {
                    "sent": "So we start looking for you Ristic San.",
                    "label": 0
                },
                {
                    "sent": "We find some that appears to be efficient an of equality in practice, and they're kind of Boo Boo struck bootstrap like methods one get into details, but you can find them in the paper.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so the probabilities that we infer by running our best heuristics on the data we had is RDS.",
                    "label": 0
                },
                {
                    "sent": "So for instance, you see that you know from the top left position there is reasonably high probability of going left, and I'm going down.",
                    "label": 0
                },
                {
                    "sent": "But the probability that you go from here back to 00 is very small, at least in a single step.",
                    "label": 0
                },
                {
                    "sent": "You might take a longer pets to go back there, but probably going from zero 1200 is, you know like 2 / 1000, so it's very small.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now what do we mean by the fact that the probability is this?",
                    "label": 0
                },
                {
                    "sent": "But this is this was our best heuristics.",
                    "label": 0
                },
                {
                    "sent": "Well, we did the following.",
                    "label": 0
                },
                {
                    "sent": "We computed the stationary distribution of this Markov chain and all of the Markov chain produced by our different heuristics.",
                    "label": 1
                },
                {
                    "sent": "And we computed the variational distance that's some form of probability distances between the stationary distribution of the Markov chains and empirical quick fraction.",
                    "label": 0
                },
                {
                    "sent": "We were kind of heuristically saying that if a user kind of has time to mixes, makes some steps on the Markov chain, then.",
                    "label": 0
                },
                {
                    "sent": "He will mix and if you mix this then the probability of clicking doesn't really depend on the starting state or anything else and well.",
                    "label": 1
                },
                {
                    "sent": "In any case the variational distance between our best heuristics and empirical click fraction was rather small.",
                    "label": 0
                },
                {
                    "sent": "0.2 or something like that.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the empirical click fraction and OK so unfortunately the colors are not good, but so then people click fraction an the results of our best touristy heuristics.",
                    "label": 1
                },
                {
                    "sent": "Kind of confirmed that there exists on Golden triangle here.",
                    "label": 0
                },
                {
                    "sent": "Most of the people will click just say in the picture that are on the top left.",
                    "label": 0
                },
                {
                    "sent": "But you know if the colors were better you would see that here we also have silver triangle.",
                    "label": 0
                },
                {
                    "sent": "So the probability that the user will actually click here is higher than the probability that the user will click here.",
                    "label": 0
                },
                {
                    "sent": "So that's something that you know we didn't expect, and we found surprising so.",
                    "label": 0
                },
                {
                    "sent": "You know, so, given these empirical quick fraction and stationary distribution of our Markov chain, we can.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can start thinking about the placement problem right, or at least heuristics for the placement problem.",
                    "label": 0
                },
                {
                    "sent": "OK, we know where user kind of user are likely to click.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "How should we place object in the Markov chain?",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um, well what we want to do in blazing, you know, in placing the objects is to guarantee that users are we likely to click on useful objects, objects that are, say, images, picture ads, or news that are useful to them or the search engine, right?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for instance, we know that this spot here as I's probability of being clicked on.",
                    "label": 0
                },
                {
                    "sent": "So maybe the best say picture should be placed.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, maybe we should place the second here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, if we were to use row major order, what most people are doing right now, we would place the worst picture here.",
                    "label": 0
                },
                {
                    "sent": "But you know, as you know again, if colors would be better, you would see that this is not the worst place to place the picture on.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In fact, this is the worst place, and here you would put something like the 10th best picture or something like that.",
                    "label": 0
                },
                {
                    "sent": "So it's not true that say, the bottom right corner is the worst one.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's I mean you can find better pictures in the paper I guess.",
                    "label": 0
                },
                {
                    "sent": "So that was so.",
                    "label": 0
                },
                {
                    "sent": "This is something that we want to do while placing objects.",
                    "label": 0
                },
                {
                    "sent": "We want to guarantee that users will be likely to click on good objects, but there's also a second thing that we want to do.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So suppose and it's kind of regards user diversity or something like that.",
                    "label": 0
                },
                {
                    "sent": "Suppose that user queries the search engine for Apple OK. Then maybe the user is thinking about Apple Incorporation.",
                    "label": 0
                },
                {
                    "sent": "And So what?",
                    "label": 0
                },
                {
                    "sent": "The user would like to see is the picture of the log of Apple Incorporation.",
                    "label": 0
                },
                {
                    "sent": "That would be the best thing you could return.",
                    "label": 0
                },
                {
                    "sent": "Or well, you could return an actual Apple in which case the user would maybe think that there was an honest mistake.",
                    "label": 1
                },
                {
                    "sent": "You search for Apple and it got a picture of an Apple.",
                    "label": 0
                },
                {
                    "sent": "But if you were to return, say, a picture of the Big Apple of New York City, then the user will, will, you know?",
                    "label": 0
                },
                {
                    "sent": "Be unsatisfied is likely to be unsatisfied.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dehen if the user was actually thinking of the Big Apple and you know for some reason just search for the second word for Apple then well, you would want to return really the picture of the Big Apple as the first one.",
                    "label": 0
                },
                {
                    "sent": "Again, the actual Apple is not a big problem, but say the log of Apple incorporation is not is not what you want to turn.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right and so so this kind of brings us to some model of user satisfaction.",
                    "label": 0
                },
                {
                    "sent": "Different objects have different likelihoods of satisfying the user, and say the actual Apple will avoid losing the user already satisfaction in our example because, well, it's not likely that the user will stop looking at the page altogether just because it's so.",
                    "label": 1
                },
                {
                    "sent": "It's an Apple, but a user would get more expected utility from the others.",
                    "label": 0
                },
                {
                    "sent": "In the first case, you wanted an Apple Store, so if you actually click, if you return the.",
                    "label": 1
                },
                {
                    "sent": "The Apple Incorporation logo, then you would have taken to say the Apple webpage that would have been good for him.",
                    "label": 0
                },
                {
                    "sent": "Or maybe he was looking for a hotel in the Big Apple, right?",
                    "label": 0
                },
                {
                    "sent": "So so we have two things that are playing together here.",
                    "label": 0
                },
                {
                    "sent": "One is the likelihood of the user.",
                    "label": 0
                },
                {
                    "sent": "Stopping that the user stops look looking at the page because this is something that it doesn't want to see.",
                    "label": 0
                },
                {
                    "sent": "And then there's the utility that each object could bring to the user.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for instance, this is a good placement, at least in our example, right?",
                    "label": 0
                },
                {
                    "sent": "We place the Apple here so the user starts here, looks at the Apple is, you know, if he was really searching.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the Apple and it would be OK, everything will be fine if you want.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Searching for, say, the Apple Incorporation or the Big Apple, then now we'd say some probability you will actually transition to either the Big Apple or or Apple or Dell incorporation logo, in which case it would be happy.",
                    "label": 0
                },
                {
                    "sent": "So placing objects this way would definitely be better than placing here Depot logo here or the OR, say, New York logo in the first position.",
                    "label": 0
                },
                {
                    "sent": "So that's something that our problem that our definition of the problem has to take into consider.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ocean.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Trying to be a bit more formal here, here is exactly what we want to do.",
                    "label": 0
                },
                {
                    "sent": "Each object is defined by a pair stopping probability, an expected utility.",
                    "label": 1
                },
                {
                    "sent": "The stopping probability is the probability that the user will stop looking at a page if he sees that object, that object and it doesn't like it, and the expected utility is, say, the gain of the user.",
                    "label": 0
                },
                {
                    "sent": "If it looks at that object, OK, whatever the gain is, it can be.",
                    "label": 0
                },
                {
                    "sent": "You know some time getting monetary gain or just user satisfaction.",
                    "label": 1
                },
                {
                    "sent": "And whenever a user sees an object she will accrues is expected utility.",
                    "label": 0
                },
                {
                    "sent": "And will stop looking at a page without stopping probability.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for instance, if the user starts here, she will accrue utility you of Apple.",
                    "label": 0
                },
                {
                    "sent": "The utility of the Apple.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then she will flip a coin with probability P of Apple.",
                    "label": 1
                },
                {
                    "sent": "She will just stop looking at the page, so our total utility will be the utility of the epsilon.",
                    "label": 0
                },
                {
                    "sent": "But if she doesn't.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stop then she will transition somewhere else according to the Markov chain probabilities.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you know, maybe she'll go down as she walked through the utility of the, you know, the Apple logo picture.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's our.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Model.",
                    "label": 0
                },
                {
                    "sent": "Another placement problem is easy.",
                    "label": 0
                },
                {
                    "sent": "How should we place objects automatically?",
                    "label": 0
                },
                {
                    "sent": "Maximize the users extractor utility?",
                    "label": 1
                },
                {
                    "sent": "So in another paper we analyzed this problem in his full generality on general graphs and we give some approximation algorithms and some hardness results, but in general it's hard for general graphs.",
                    "label": 1
                },
                {
                    "sent": "For the graph we weren't able to find say I guess I polynomial approximation algorithm, But we do give efficient heuristics and also kernelization trick.",
                    "label": 1
                },
                {
                    "sent": "That you could use to reduce their solution space.",
                    "label": 0
                },
                {
                    "sent": "So suppose you want to look at the best.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the one best placement so you can do that.",
                    "label": 0
                },
                {
                    "sent": "You need exponential time, but this conversation trick makes that I'm reasonably small.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if looking at quickly at our heuristics so the hit heuristics order Markov chains lots.",
                    "label": 1
                },
                {
                    "sent": "Increasingly, by hitting time, the heating time of a slot in a Markov chain is the expected time you need to get to that to that single slot.",
                    "label": 1
                },
                {
                    "sent": "The egg and utility orders lots according to the stationary probability, and then we have the column and row ordering the ones we see at the beginning.",
                    "label": 1
                },
                {
                    "sent": "And now we just placed items over your utility in better slots.",
                    "label": 1
                },
                {
                    "sent": "Slots that are better according to one of these four things.",
                    "label": 1
                },
                {
                    "sent": "So what we can see here is that the hitting time heuristic bits, the row it's everyone else in.",
                    "label": 0
                },
                {
                    "sent": "Basically each of the top K queries.",
                    "label": 1
                },
                {
                    "sent": "We have yard average utility over the top K queries and hitting time heuristic is the best one by reasonably large amount.",
                    "label": 1
                },
                {
                    "sent": "Right then we see also that the row ordering is actually the worst one, so that's something that you know it's good to keep in mind.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's what they eat.",
                    "label": 0
                },
                {
                    "sent": "Slots ordering would look like, so we would place the best picture here.",
                    "label": 1
                },
                {
                    "sent": "The second best year, third 4th, 5th, 6th, 7th and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "So we see that that's kind of as exact like pattern as opposed to a row major ordering.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So I'm immediately struck by the relationship between the two talks we've just seen because we wrote reason one and trees and the other one.",
                    "label": 0
                },
                {
                    "sent": "Essentially, if you dangle it by the top corner, right?",
                    "label": 0
                },
                {
                    "sent": "So that was a very interesting observation.",
                    "label": 0
                },
                {
                    "sent": "And the other thing I was doing I was sitting here thinking about my own behavior with image search, and the reason I click on the bottom corner is because they're always weird.",
                    "label": 0
                },
                {
                    "sent": "So, so you do your image search and you get.",
                    "label": 0
                },
                {
                    "sent": "Yep, monkeys, monkeys, monkeys, monkeys, monkeys, monkeys and then down in the bottom there's something different because the lowest relevant or the least likely thing is being placed there and you go there out of curiosity more than anything else.",
                    "label": 0
                },
                {
                    "sent": "It's not because you think it's relevant to go.",
                    "label": 0
                },
                {
                    "sent": "Yes, that's an explanation I guess.",
                    "label": 0
                },
                {
                    "sent": "I hope not every user is like that, but.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean, that's definitely an explanation, so we didn't actually do say some kind of bucket testing.",
                    "label": 0
                },
                {
                    "sent": "So basically just I don't know.",
                    "label": 0
                },
                {
                    "sent": "Take a query and just blaze pictures randomly and see where user clicked.",
                    "label": 0
                },
                {
                    "sent": "We didn't do that, but we couldn't do that, but.",
                    "label": 0
                },
                {
                    "sent": "It's unclear if that's really the reason.",
                    "label": 0
                },
                {
                    "sent": "It might be that users are actually really just, you know, going through the Markov chain an you know so for some reason.",
                    "label": 0
                },
                {
                    "sent": "That just depends on, uh, I mean, if you buy our Markov user model then what happens is that you know, once you get to the bottom right corner you remain there.",
                    "label": 0
                },
                {
                    "sent": "You just don't go back where you are on the assumption that you only make a step of one that is right.",
                    "label": 0
                },
                {
                    "sent": "That is right, that is right.",
                    "label": 0
                },
                {
                    "sent": "The other comment is going to make was that you've kind of assumed that all of your layout is in a grid and it strikes me that you could have a lot of fun thinking about different sized images.",
                    "label": 0
                },
                {
                    "sent": "So the ones that that the system is saying, hey, this is highly likely.",
                    "label": 0
                },
                {
                    "sent": "Give a bigger thumbnail for it.",
                    "label": 0
                },
                {
                    "sent": "Make it more attractive to be clicked on 'cause 'cause the HCI people will tell you that the effort that it takes to move a mouse and click on something depends on the size of the thing that you're trying to hit.",
                    "label": 0
                },
                {
                    "sent": "Raised way I hate our HR system at the University 'cause the logout button is like 3 millimeters wide, so I agree with you on this thing.",
                    "label": 0
                },
                {
                    "sent": "So again the issue we had is that we didn't do bucket testing.",
                    "label": 0
                },
                {
                    "sent": "We couldn't do back at testing.",
                    "label": 0
                },
                {
                    "sent": "It's hard to get that kind of information from the logs we had because where we didn't actually we had pictures of all the same size, so we couldn't actually say, OK, let's just place a larger picture here so that the user is more likely to click on that from.",
                    "label": 0
                },
                {
                    "sent": "If you assume you know the Markov chain right and you just want to place objects on a more general Grafton just agreed, then we do have some algorithms that I guess just a theoretical interest since they are not.",
                    "label": 0
                },
                {
                    "sent": "Usable in practice for some reasons.",
                    "label": 0
                },
                {
                    "sent": "Complexity reasons, an approximation factor reasons.",
                    "label": 0
                },
                {
                    "sent": "But I agree with you that this kind of marginal problem would be interesting to solve even from practical point of view.",
                    "label": 0
                },
                {
                    "sent": "Don't worry, I mean very little users are like Alistair's question here.",
                    "label": 0
                },
                {
                    "sent": "Maybe 1.",
                    "label": 0
                },
                {
                    "sent": "Did you also look into time domain?",
                    "label": 0
                },
                {
                    "sent": "So do you have an intuition how long a gay slingers at a certain spot so self transitions away, right?",
                    "label": 0
                },
                {
                    "sent": "So actually we didn't look at that.",
                    "label": 0
                },
                {
                    "sent": "We did look at self transitions.",
                    "label": 0
                },
                {
                    "sent": "I didn't talk about that, but we didn't look at how much.",
                    "label": 0
                },
                {
                    "sent": "So we didn't.",
                    "label": 0
                },
                {
                    "sent": "I guess use this part of the log data.",
                    "label": 0
                },
                {
                    "sent": "The timestamp data we don't use that.",
                    "label": 0
                },
                {
                    "sent": "We just looked at the order of the clicks, not the time when they when they happen.",
                    "label": 0
                },
                {
                    "sent": "And yeah again, I'm going to agree that this would be.",
                    "label": 0
                },
                {
                    "sent": "This would be interesting to do.",
                    "label": 0
                },
                {
                    "sent": "There in the back.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I was wondering how to train a hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "How many users do you use to train the model right and have you have you tried to compare the behavior different user?",
                    "label": 0
                },
                {
                    "sent": "OK, so we had.",
                    "label": 0
                },
                {
                    "sent": "I guess 10s of millions of users.",
                    "label": 0
                },
                {
                    "sent": "Or at least we had 10s of millions of traces.",
                    "label": 0
                },
                {
                    "sent": "We didn't know which, you know.",
                    "label": 0
                },
                {
                    "sent": "If say, a user you know 100,000 traces or not, we don't know that we just had traces and they were kind of 10s of millions and we didn't look at say different behaviors of different users.",
                    "label": 0
                },
                {
                    "sent": "We are this kind of Markovian assumption that kind of made the problem more tractable.",
                    "label": 0
                },
                {
                    "sent": "I guess that you know that's definitely interesting to look at that it's just that maybe it would be, you know, it would be more useful to try to solve this easier problem first to get a good solution for this problem 1st and then look at possible generalizations.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and I agreed that that would be quite important one.",
                    "label": 0
                },
                {
                    "sent": "In the back.",
                    "label": 0
                },
                {
                    "sent": "Do you?",
                    "label": 0
                },
                {
                    "sent": "Do you have an intuition about whether the hot upper left corner is a result of reading order conventions?",
                    "label": 0
                },
                {
                    "sent": "So, so the data we had was.",
                    "label": 0
                },
                {
                    "sent": "For the US Yahoo.",
                    "label": 0
                },
                {
                    "sent": "So people you know, most people would just look from left to right.",
                    "label": 0
                },
                {
                    "sent": "I am not sure about that.",
                    "label": 0
                },
                {
                    "sent": "I actually don't think it's because you know there were some people that you are used to look from to read from right to left because it happens also on the bottom.",
                    "label": 0
                },
                {
                    "sent": "So we would have people that actually starts looking at.",
                    "label": 0
                },
                {
                    "sent": "I guess bottom right corner and go up.",
                    "label": 0
                },
                {
                    "sent": "So I don't think that's the reason.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank you again.",
                    "label": 0
                }
            ]
        }
    }
}