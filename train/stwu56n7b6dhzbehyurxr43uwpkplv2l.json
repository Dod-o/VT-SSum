{
    "id": "stwu56n7b6dhzbehyurxr43uwpkplv2l",
    "title": "Networks of Linked Data Eddies: An Adaptive Web Query Processing Engine for RDF Data",
    "info": {
        "author": [
            "Maribel Acosta, Institute of Applied Informatics and Formal Description Methods (AIFB), Karlsruhe Institute of Technology (KIT)"
        ],
        "published": "Nov. 10, 2015",
        "recorded": "October 2015",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2015_acosta_linked_data/",
    "segmentation": [
        [
            "OK, good afternoon.",
            "My name is Maribel Acosta.",
            "I'm from the Culture Institute of Technology and this is joint work with Maria Sorbitol from NYC.",
            "At Simone Bolivar and that Alpha work is network of linked data eddies and adaptive web Q processing engine for RDF data."
        ],
        [
            "Now, with the publication of RDF datasets on the web."
        ],
        [
            "Several mechanisms or interfaces to access RDF data online have been proposed in the last years."
        ],
        [
            "So for."
        ],
        [
            "Sample we have the referencing which is just retrieving RDF documents from the web or."
        ],
        [
            "Even more expressive interfaces like sparkle in points."
        ],
        [
            "Recently a new type of interfaces have been proposed which are called the triple part of fragment servers, and this is what we're going to work on in this paper."
        ],
        [
            "Triple part of fragment servers are server capable of executing Sparkle, sparkle, triple patterns and they respond with a fragment."
        ],
        [
            "That contains the set of triple patterns that match the given.",
            "The set of triples that match the given triple pattern.",
            "In addition of these fragments also contain metadata.",
            "For example, the number of triples that can are contained within the fragment or also the page size which corresponds to the number of triples that can be retrieved from the server in a single request."
        ],
        [
            "In order to execute, queries are composed of more than one triple pattern.",
            "We need clients that are able to retrieve the fragments from the server and then combine the results locally.",
            "So an example of this type of client."
        ],
        [
            "The people part of Fragment client which is consider in this context the state of the art in order to execute the query that I'm showing right here.",
            "That triple butter fragment client builds."
        ],
        [
            "You're a plan that is called a level in your plan, and in order to execute this plan then."
        ],
        [
            "State of the art implements unnes."
        ],
        [
            "Said Luke join operator."
        ],
        [
            "We have executed this plan against the triple Butter fragment server for DB pedia."
        ],
        [
            "We obtained the following results, so the execution time for this plan was over 300 seconds.",
            "So more than five minutes and the total number of requests admitted to the server was over 1600.",
            "But this is just one way of executing this query and there are all the plans that can be more efficiently executed against these type of servers."
        ],
        [
            "So for example, Bushy tree plans.",
            "This type of plans have been shown in the literature that they are able to reduce the size of intermediate results and therefore they speed up the query execution time in."
        ],
        [
            "Into the shape of the plan, or so different operators like some metric has joined, can be used for executing this plan.",
            "So we have executed this bullshit through plan that I'm showing here against the same server."
        ],
        [
            "And we obtained the following results.",
            "So the execution time was reduced from 300 seconds to three seconds.",
            "The Bush Trip Plan was able to produce the whole answer, and it only submitted 67 requests to the server."
        ],
        [
            "The first goal of our approach is producing plants that are executed executed efficiently against this type of servers."
        ],
        [
            "Now, in some cases the performance of efficient plants can be negatively impacted when we are executing the query.",
            "For example with Frank."
        ],
        [
            "Are retrieved from the server.",
            "The execution conditions can suddenly change."
        ],
        [
            "Due to, for example, delays in the in the network or unexpected server workload, or even unexpected selectivity or data distribution in the triples that we are retrieving from the fragments.",
            "So for these cases we would like to adapt the plants to these unpredictable conditions.",
            "Now let me show."
        ],
        [
            "You an example, we have the Bush trip plan and now let us."
        ],
        [
            "Assume that the source for the triple pattern two becomes slow."
        ],
        [
            "So it would be desirable to change the order of the plan and then evaluate first the triple button for instead of waiting for two."
        ],
        [
            "So the plan can be changed to look something like this.",
            "Now if the condition changes again for it."
        ],
        [
            "Sample the source of 1 becomes slow, then the plan can be changed."
        ],
        [
            "Again, until we obtain a plan."
        ],
        [
            "And that is adapted to the current execution conditions.",
            "We have executed 2."
        ],
        [
            "Types of plan one is without activity or an adapted plan, and the other one is a fixed plan in a network with delays and we obtain the following results.",
            "For the data plan, it was able to retrieve the whole answers in 3.86 seconds, while the fixed plan took 5 seconds."
        ],
        [
            "So the second goal of our work is adapting the plans according to the execution conditions."
        ],
        [
            "So we propose our approach, which we call network of Lean Data 80s."
        ],
        [
            "And this is a client side query processing ending for executing sparkle queries against triple part of fragment servers.",
            "The first contribution of our work is a Sparkle query optimizer that is tailored for triple, but the fragment servers."
        ],
        [
            "In this part of our work, this optimizer will tackle the first goal, then our engine opportunistically execute the queries against the triple practice frag."
        ],
        [
            "Servers and this part of our world will tackle our second goal."
        ],
        [
            "The architecture of our approach looks like this, so the system receives a sparkle query and it will produce the results for the query and the first component that I'm going to talk about."
        ],
        [
            "Is the query optimizer."
        ],
        [
            "Our corrupting my sore generates bushy tree plants like they want to show you in the motivating example by following four simple steps.",
            "It first retrieves the triple pattern metadata and then bill star shape groups, which is a way of combining triple patterns able to reduce the size of intermediate results.",
            "This has been shown in a previous work.",
            "Then the third step is to place the appropriate physical operator.",
            "For example, either nested loop join or symmetric has joined and then finally the optimizer combines the star shape groups.",
            "In a Bush trip plan.",
            "Now."
        ],
        [
            "We show you with an example how our optimizer works.",
            "It fills first, retrieves the triple pattern META data and this is the running example."
        ],
        [
            "And this is the metadata for the query, so the count is the number of triples per triple pattern and then the page size."
        ],
        [
            "In the second step, the optimizer builds starshade groups and it will first start by selecting the most selective triple pattern in this case."
        ],
        [
            "Istripper Button 2 because it has the lowest number of count."
        ],
        [
            "And then even try to produce a Starship group by selecting another triple pattern that shares exactly 1 variable with this one.",
            "In this case, two and four are combined with the join operator."
        ],
        [
            "So the optimizer goes on and then it selects the next."
        ],
        [
            "What pattern in this case?"
        ],
        [
            "Would be triple butter one, which is combined with triple patterns.",
            "Free because they also form a starchy group."
        ],
        [
            "In the third step of, our optimizer replaces physical operators, which is either a nested loop join or a symmetric hash Join Now, for example, to combine the triple patterns to an for the optimizer exploits the metadata encoded in the fragments to determine determine how many requests it will require to retrieve each of the triple pattern."
        ],
        [
            "For example, triple pattern two requires 6 requests from the server, and triple butter four requires 25 requests."
        ],
        [
            "If the optimizer places and nested loop join then it this will result in 535 requests.",
            "6 requests to resolve triple pattern two and then 529 requests for each of the instances of triple pattern too.",
            "However, if it places a symmetric has joint, then this will produce only 31 request.",
            "It will produce 6 requests for triple pattern two and then 25 requests for triple pattern 4."
        ],
        [
            "Therefore, the optimizer chooses the more efficient operator which is in this case is the symmetric has joined."
        ],
        [
            "In a similar way, it exploits the metadata for two buttons, one and three, and the optimizer also places a symmetric as join here."
        ],
        [
            "Now that all that triple patterns belong to a one Star shape group, then the optimizer combines them in a bushy tree plan, and this is a very simple example it just."
        ],
        [
            "At another joint between the two groups and then place."
        ],
        [
            "Is a symmetric hash joins because this will allow the engine to evaluate several star shape groups at the same time.",
            "Anne."
        ],
        [
            "This is the final plan.",
            "It is an optimized physical plan that is tailored for triple butter fragments because it has been built by exploiting the metadata retrieved from the fragments."
        ],
        [
            "Now the second component of our architecture is."
        ],
        [
            "Adaptive engine."
        ],
        [
            "And this ending executes their plan that was divided by the optimizer.",
            "It performs two types of adaptivity interoperate reactivity.",
            "This is, the results are produced as soon as they are retrieved from the sources and routing operator activity that is able to change the order of the plan according to the current conditions at activity in our engineers perform on a tuple based basis.",
            "This is our ending performs a very fine grained granularity of activity.",
            "The components of the engine are adaptive operators and Eddie operators and in combination they form network.",
            "Offline data is.",
            "Now the."
        ],
        [
            "Adaptive operators correspond to the physical operators that were devised by the optimizer.",
            "So following our running example, this will be."
        ],
        [
            "The three symmetric hash joints.",
            "And."
        ],
        [
            "The other operator was previously proposed in the database community and this type of operator dynamically rocks.",
            "The top was through the operate."
        ],
        [
            "So it will receive tapas from operators and will send them back to the operators and so on and so forth."
        ],
        [
            "To produce sound results, an edit relies on top of annotations.",
            "In order to avoid, for example, sending the same tuple twice to an operator, because these would produce incorrect results so."
        ],
        [
            "One of these annotations is the ready vector which indicates the operator that should evaluate a given topic.",
            "Now let me show you an example for for a tuple that is coming from the triple pattern one, then the operators that should process this double according to the plans are zero and two therefore the ready vector for this top List 101 and one in position 0, Anna one in position 2."
        ],
        [
            "Another type of annotation is the dawn vector, which indicates the operators that have already processed a tuple.",
            "For example, if a tuple has already been processed by operator one, then the dawn vector of this table is zero, 10A one in the position one of the vector."
        ],
        [
            "In our approach."
        ],
        [
            "Much, there might be several edits are composing the network, therefore several eddies can distribute the workload among several processes."
        ],
        [
            "Each entry in our approach is autonomous disease.",
            "When an editor text data tuple is ready to be part of the output that it automatically produces directly to the output."
        ],
        [
            "In addition, our network offline data eddies maintains information about triple patterns that is recovered from the sparkle query.",
            "So for example, we maintain information about the joint or the variable positions of the joint, either if they are subject, subject or subject object or and so on and so forth, because this will allow us to estimate the selectivity of the joints that are performing the triple patterns."
        ],
        [
            "Now the last component of our approach is the routing policies which guide there any operators to choose their adaptive operators."
        ],
        [
            "When a Navy receives at top of the neatest or sit in a structure with that, we call routing buffer, which is acute."
        ],
        [
            "And for example, here in this routing buffer the first double processes tuple one and the edit process is the ready and the dawn vectors of the tuple.",
            "In this case, the Don Vector has all the entries equal to 1.",
            "Therefore this table is ready to be part of the output."
        ],
        [
            "The operation Ready minus done determines the operators that still need to be executed for a given topic.",
            "So for example, for the tuple two they ready minus down results in 100, which means that operator #2 still has to execute this double."
        ],
        [
            "And then if several operators are eligible, then the Eddie chooses the one with the highest priority in our approach will, prior to prioritize operators with the highest selectivity and we estimate the selectivity of operators by applying this formula that we proposed in our work and in combination with the sparkle heuristics using the information of the variable positions in the sparkle query."
        ],
        [
            "Now that's all for the approach.",
            "Now we have executed experiments to evaluate the effectiveness of our."
        ],
        [
            "Roche and we use this by executing queries against the triple butter fragmente server for DB pedia.",
            "We designed 45 sparkle queries, divided into benchmarks.",
            "Benchmark One contains 20 non selective queries and benchmark two contains 25 selective queries.",
            "We implemented our approach in Python And the timeout was set to 1800 seconds.",
            "These are the technical specifications of our of our machine that we used for experiments on each query was executed."
        ],
        [
            "10 Times Now for the first experiment, we measure the effectiveness of our optimization techniques and you're looking at the results for benchmark One.",
            "The light blue is our approach and dark blue is a state of the art, and as you can see, the plans generated by our approach are able to reduce execution time for almost all the queries."
        ],
        [
            "Now we look at the queries where we were not able to reduce execution time and we observed that we were able to produce even more answers for those queries."
        ],
        [
            "And in general, we observe this behavior for the whole benchmark.",
            "So our approach is able to produce the same amount or even more answer than state of the art before reaching a timeout."
        ],
        [
            "For the second experiments, we measure the effectiveness of again of our approach, but this time in benchmark two, and again we observe the send the plans generated by our approach are able to reduce execution time even for selective queries."
        ],
        [
            "And here both approaches produce the same amount of results, so we look into the number of requests that were submitted to the servers, and in the majority of the queries, our approach was able to reduce the number of Contacts or requests that were submitted to the triple part of Fragmente servers."
        ],
        [
            "Now for the last experiment we here, we measure the activity of our engine and we simulated a network with delays following this distribution.",
            "These models are fast network, medium, fast network, an on the blue bar you see our approach without activity and the red bar is our approach with activity and then you can see that our ending was able to adapt the plants according to the delays and we were able to reduce the execution time for almost all the queries."
        ],
        [
            "Now for the relay."
        ],
        [
            "At work we look into approaches that perform sparkle query processing over HTTP.",
            "We found for the referencing the link data traversal for the trip of butter Fragmente servers that current trip, but the fragment client and for sparkling points the Federated Indians.",
            "However, none of these approaches are able to cope with unexpected delays or unexpected data distributions and data like unlike our approach."
        ],
        [
            "So for the conclu."
        ],
        [
            "As we have presented an LDE or network offering data edits, which is a client side query engine against ripple pattern FRAGMENTE servers, our research contributions can be summarized as follows.",
            "We propose a novel optimization techniques tailored for triple butter fragments.",
            "We also propose autonomous eddies in our routing.",
            "Policies are tailored for sparkle queries.",
            "Our experimental results showed that our approach is able to overcome state of the art and our engine is also able to adapt execution to unexpected network delays."
        ],
        [
            "For the future work we play."
        ],
        [
            "To define cost models to estimate the selectivity of triple pattern fragments to enhance our query optimizer."
        ],
        [
            "We also would like to study different routing policies and finally."
        ],
        [
            "Play our adaptive techniques to federations of triple patterns.",
            "These are so."
        ],
        [
            "Of the references."
        ],
        [
            "We used and that's all from my side.",
            "Thank you very much.",
            "Three things.",
            "First of all, you made my day second, about language that you implemented versus source code.",
            "And finally, if the server sends extra metadata, which would be interesting for you.",
            "Very good questions.",
            "Thank you very much.",
            "So I'm very happy that I made your day.",
            "We implemented it in Python.",
            "We are right now.",
            "You know, working on the code to make it available and I will keep you up to date on that.",
            "And the third question, the metadata.",
            "I would like to have about information about the distribution of the triples that are contained within the fragment.",
            "This will be very very useful for our optimizer to decide what type of plan or what type of operator should be should be better.",
            "So I'm looking forward to.",
            "Get more metadata from the fragments.",
            "I just a question about your evaluation.",
            "You set a timeout, why exactly?",
            "Yes, some of the some of the questions or queries.",
            "In this case we're taking very long to execute.",
            "So actually for some queries with the triple butter fragment guy, we were not able to finish the whole the whole experiment.",
            "So that's why we just set up an timeout for experiments.",
            "Yeah.",
            "I have also question related to the experiments you showed results with respect to Q execution time and number of requests.",
            "Um, did you also look into the.",
            "Well.",
            "Data science that was shipped during the execution of this quiz.",
            "So some of these you showed one of these in the earlier in the first slide we showed something like requesting for whole triple patterns instead of requesting for the instantiated versions of them, which I would expect to ship more data than basically all you join.",
            "Yes, so we haven't measured the exact number of intermediate results that we shipped from the servers, but the number of requests that we are submitting.",
            "It's like an indication of the amount of data that we are retrieving.",
            "I mean, indeed we are retrieving the same amount of data, but we're just doing it in a more sorry we're not receiving the same amount of data we are just retrieving whatever we need because this is done by the by the physical optimizer, but the number of requests is actually an indication of the amount of data that we are shipping from the servers.",
            "We presented for Experiment 2 but also for experiment one.",
            "We did not report it on the paper, but we also were able to observe that the number of requests were much much lower than with the current client."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, good afternoon.",
                    "label": 0
                },
                {
                    "sent": "My name is Maribel Acosta.",
                    "label": 0
                },
                {
                    "sent": "I'm from the Culture Institute of Technology and this is joint work with Maria Sorbitol from NYC.",
                    "label": 0
                },
                {
                    "sent": "At Simone Bolivar and that Alpha work is network of linked data eddies and adaptive web Q processing engine for RDF data.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, with the publication of RDF datasets on the web.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Several mechanisms or interfaces to access RDF data online have been proposed in the last years.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sample we have the referencing which is just retrieving RDF documents from the web or.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Even more expressive interfaces like sparkle in points.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Recently a new type of interfaces have been proposed which are called the triple part of fragment servers, and this is what we're going to work on in this paper.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Triple part of fragment servers are server capable of executing Sparkle, sparkle, triple patterns and they respond with a fragment.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That contains the set of triple patterns that match the given.",
                    "label": 0
                },
                {
                    "sent": "The set of triples that match the given triple pattern.",
                    "label": 0
                },
                {
                    "sent": "In addition of these fragments also contain metadata.",
                    "label": 0
                },
                {
                    "sent": "For example, the number of triples that can are contained within the fragment or also the page size which corresponds to the number of triples that can be retrieved from the server in a single request.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In order to execute, queries are composed of more than one triple pattern.",
                    "label": 0
                },
                {
                    "sent": "We need clients that are able to retrieve the fragments from the server and then combine the results locally.",
                    "label": 0
                },
                {
                    "sent": "So an example of this type of client.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The people part of Fragment client which is consider in this context the state of the art in order to execute the query that I'm showing right here.",
                    "label": 0
                },
                {
                    "sent": "That triple butter fragment client builds.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You're a plan that is called a level in your plan, and in order to execute this plan then.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "State of the art implements unnes.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Said Luke join operator.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have executed this plan against the triple Butter fragment server for DB pedia.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We obtained the following results, so the execution time for this plan was over 300 seconds.",
                    "label": 0
                },
                {
                    "sent": "So more than five minutes and the total number of requests admitted to the server was over 1600.",
                    "label": 0
                },
                {
                    "sent": "But this is just one way of executing this query and there are all the plans that can be more efficiently executed against these type of servers.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example, Bushy tree plans.",
                    "label": 0
                },
                {
                    "sent": "This type of plans have been shown in the literature that they are able to reduce the size of intermediate results and therefore they speed up the query execution time in.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Into the shape of the plan, or so different operators like some metric has joined, can be used for executing this plan.",
                    "label": 0
                },
                {
                    "sent": "So we have executed this bullshit through plan that I'm showing here against the same server.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we obtained the following results.",
                    "label": 0
                },
                {
                    "sent": "So the execution time was reduced from 300 seconds to three seconds.",
                    "label": 0
                },
                {
                    "sent": "The Bush Trip Plan was able to produce the whole answer, and it only submitted 67 requests to the server.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first goal of our approach is producing plants that are executed executed efficiently against this type of servers.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, in some cases the performance of efficient plants can be negatively impacted when we are executing the query.",
                    "label": 0
                },
                {
                    "sent": "For example with Frank.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are retrieved from the server.",
                    "label": 0
                },
                {
                    "sent": "The execution conditions can suddenly change.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Due to, for example, delays in the in the network or unexpected server workload, or even unexpected selectivity or data distribution in the triples that we are retrieving from the fragments.",
                    "label": 1
                },
                {
                    "sent": "So for these cases we would like to adapt the plants to these unpredictable conditions.",
                    "label": 1
                },
                {
                    "sent": "Now let me show.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You an example, we have the Bush trip plan and now let us.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Assume that the source for the triple pattern two becomes slow.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it would be desirable to change the order of the plan and then evaluate first the triple button for instead of waiting for two.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the plan can be changed to look something like this.",
                    "label": 0
                },
                {
                    "sent": "Now if the condition changes again for it.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sample the source of 1 becomes slow, then the plan can be changed.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, until we obtain a plan.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that is adapted to the current execution conditions.",
                    "label": 0
                },
                {
                    "sent": "We have executed 2.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Types of plan one is without activity or an adapted plan, and the other one is a fixed plan in a network with delays and we obtain the following results.",
                    "label": 0
                },
                {
                    "sent": "For the data plan, it was able to retrieve the whole answers in 3.86 seconds, while the fixed plan took 5 seconds.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the second goal of our work is adapting the plans according to the execution conditions.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we propose our approach, which we call network of Lean Data 80s.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is a client side query processing ending for executing sparkle queries against triple part of fragment servers.",
                    "label": 0
                },
                {
                    "sent": "The first contribution of our work is a Sparkle query optimizer that is tailored for triple, but the fragment servers.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this part of our work, this optimizer will tackle the first goal, then our engine opportunistically execute the queries against the triple practice frag.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Servers and this part of our world will tackle our second goal.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The architecture of our approach looks like this, so the system receives a sparkle query and it will produce the results for the query and the first component that I'm going to talk about.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the query optimizer.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our corrupting my sore generates bushy tree plants like they want to show you in the motivating example by following four simple steps.",
                    "label": 1
                },
                {
                    "sent": "It first retrieves the triple pattern metadata and then bill star shape groups, which is a way of combining triple patterns able to reduce the size of intermediate results.",
                    "label": 0
                },
                {
                    "sent": "This has been shown in a previous work.",
                    "label": 0
                },
                {
                    "sent": "Then the third step is to place the appropriate physical operator.",
                    "label": 0
                },
                {
                    "sent": "For example, either nested loop join or symmetric has joined and then finally the optimizer combines the star shape groups.",
                    "label": 0
                },
                {
                    "sent": "In a Bush trip plan.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We show you with an example how our optimizer works.",
                    "label": 0
                },
                {
                    "sent": "It fills first, retrieves the triple pattern META data and this is the running example.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the metadata for the query, so the count is the number of triples per triple pattern and then the page size.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the second step, the optimizer builds starshade groups and it will first start by selecting the most selective triple pattern in this case.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Istripper Button 2 because it has the lowest number of count.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then even try to produce a Starship group by selecting another triple pattern that shares exactly 1 variable with this one.",
                    "label": 0
                },
                {
                    "sent": "In this case, two and four are combined with the join operator.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the optimizer goes on and then it selects the next.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What pattern in this case?",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Would be triple butter one, which is combined with triple patterns.",
                    "label": 0
                },
                {
                    "sent": "Free because they also form a starchy group.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the third step of, our optimizer replaces physical operators, which is either a nested loop join or a symmetric hash Join Now, for example, to combine the triple patterns to an for the optimizer exploits the metadata encoded in the fragments to determine determine how many requests it will require to retrieve each of the triple pattern.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, triple pattern two requires 6 requests from the server, and triple butter four requires 25 requests.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If the optimizer places and nested loop join then it this will result in 535 requests.",
                    "label": 1
                },
                {
                    "sent": "6 requests to resolve triple pattern two and then 529 requests for each of the instances of triple pattern too.",
                    "label": 0
                },
                {
                    "sent": "However, if it places a symmetric has joint, then this will produce only 31 request.",
                    "label": 0
                },
                {
                    "sent": "It will produce 6 requests for triple pattern two and then 25 requests for triple pattern 4.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Therefore, the optimizer chooses the more efficient operator which is in this case is the symmetric has joined.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a similar way, it exploits the metadata for two buttons, one and three, and the optimizer also places a symmetric as join here.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now that all that triple patterns belong to a one Star shape group, then the optimizer combines them in a bushy tree plan, and this is a very simple example it just.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At another joint between the two groups and then place.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a symmetric hash joins because this will allow the engine to evaluate several star shape groups at the same time.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the final plan.",
                    "label": 0
                },
                {
                    "sent": "It is an optimized physical plan that is tailored for triple butter fragments because it has been built by exploiting the metadata retrieved from the fragments.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the second component of our architecture is.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adaptive engine.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this ending executes their plan that was divided by the optimizer.",
                    "label": 0
                },
                {
                    "sent": "It performs two types of adaptivity interoperate reactivity.",
                    "label": 1
                },
                {
                    "sent": "This is, the results are produced as soon as they are retrieved from the sources and routing operator activity that is able to change the order of the plan according to the current conditions at activity in our engineers perform on a tuple based basis.",
                    "label": 1
                },
                {
                    "sent": "This is our ending performs a very fine grained granularity of activity.",
                    "label": 0
                },
                {
                    "sent": "The components of the engine are adaptive operators and Eddie operators and in combination they form network.",
                    "label": 0
                },
                {
                    "sent": "Offline data is.",
                    "label": 0
                },
                {
                    "sent": "Now the.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adaptive operators correspond to the physical operators that were devised by the optimizer.",
                    "label": 0
                },
                {
                    "sent": "So following our running example, this will be.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The three symmetric hash joints.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other operator was previously proposed in the database community and this type of operator dynamically rocks.",
                    "label": 0
                },
                {
                    "sent": "The top was through the operate.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it will receive tapas from operators and will send them back to the operators and so on and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To produce sound results, an edit relies on top of annotations.",
                    "label": 0
                },
                {
                    "sent": "In order to avoid, for example, sending the same tuple twice to an operator, because these would produce incorrect results so.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of these annotations is the ready vector which indicates the operator that should evaluate a given topic.",
                    "label": 0
                },
                {
                    "sent": "Now let me show you an example for for a tuple that is coming from the triple pattern one, then the operators that should process this double according to the plans are zero and two therefore the ready vector for this top List 101 and one in position 0, Anna one in position 2.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another type of annotation is the dawn vector, which indicates the operators that have already processed a tuple.",
                    "label": 0
                },
                {
                    "sent": "For example, if a tuple has already been processed by operator one, then the dawn vector of this table is zero, 10A one in the position one of the vector.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In our approach.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Much, there might be several edits are composing the network, therefore several eddies can distribute the workload among several processes.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each entry in our approach is autonomous disease.",
                    "label": 0
                },
                {
                    "sent": "When an editor text data tuple is ready to be part of the output that it automatically produces directly to the output.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In addition, our network offline data eddies maintains information about triple patterns that is recovered from the sparkle query.",
                    "label": 0
                },
                {
                    "sent": "So for example, we maintain information about the joint or the variable positions of the joint, either if they are subject, subject or subject object or and so on and so forth, because this will allow us to estimate the selectivity of the joints that are performing the triple patterns.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the last component of our approach is the routing policies which guide there any operators to choose their adaptive operators.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When a Navy receives at top of the neatest or sit in a structure with that, we call routing buffer, which is acute.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for example, here in this routing buffer the first double processes tuple one and the edit process is the ready and the dawn vectors of the tuple.",
                    "label": 0
                },
                {
                    "sent": "In this case, the Don Vector has all the entries equal to 1.",
                    "label": 0
                },
                {
                    "sent": "Therefore this table is ready to be part of the output.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The operation Ready minus done determines the operators that still need to be executed for a given topic.",
                    "label": 0
                },
                {
                    "sent": "So for example, for the tuple two they ready minus down results in 100, which means that operator #2 still has to execute this double.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then if several operators are eligible, then the Eddie chooses the one with the highest priority in our approach will, prior to prioritize operators with the highest selectivity and we estimate the selectivity of operators by applying this formula that we proposed in our work and in combination with the sparkle heuristics using the information of the variable positions in the sparkle query.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now that's all for the approach.",
                    "label": 0
                },
                {
                    "sent": "Now we have executed experiments to evaluate the effectiveness of our.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Roche and we use this by executing queries against the triple butter fragmente server for DB pedia.",
                    "label": 0
                },
                {
                    "sent": "We designed 45 sparkle queries, divided into benchmarks.",
                    "label": 0
                },
                {
                    "sent": "Benchmark One contains 20 non selective queries and benchmark two contains 25 selective queries.",
                    "label": 1
                },
                {
                    "sent": "We implemented our approach in Python And the timeout was set to 1800 seconds.",
                    "label": 1
                },
                {
                    "sent": "These are the technical specifications of our of our machine that we used for experiments on each query was executed.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "10 Times Now for the first experiment, we measure the effectiveness of our optimization techniques and you're looking at the results for benchmark One.",
                    "label": 0
                },
                {
                    "sent": "The light blue is our approach and dark blue is a state of the art, and as you can see, the plans generated by our approach are able to reduce execution time for almost all the queries.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we look at the queries where we were not able to reduce execution time and we observed that we were able to produce even more answers for those queries.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in general, we observe this behavior for the whole benchmark.",
                    "label": 0
                },
                {
                    "sent": "So our approach is able to produce the same amount or even more answer than state of the art before reaching a timeout.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the second experiments, we measure the effectiveness of again of our approach, but this time in benchmark two, and again we observe the send the plans generated by our approach are able to reduce execution time even for selective queries.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here both approaches produce the same amount of results, so we look into the number of requests that were submitted to the servers, and in the majority of the queries, our approach was able to reduce the number of Contacts or requests that were submitted to the triple part of Fragmente servers.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now for the last experiment we here, we measure the activity of our engine and we simulated a network with delays following this distribution.",
                    "label": 0
                },
                {
                    "sent": "These models are fast network, medium, fast network, an on the blue bar you see our approach without activity and the red bar is our approach with activity and then you can see that our ending was able to adapt the plants according to the delays and we were able to reduce the execution time for almost all the queries.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now for the relay.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At work we look into approaches that perform sparkle query processing over HTTP.",
                    "label": 1
                },
                {
                    "sent": "We found for the referencing the link data traversal for the trip of butter Fragmente servers that current trip, but the fragment client and for sparkling points the Federated Indians.",
                    "label": 1
                },
                {
                    "sent": "However, none of these approaches are able to cope with unexpected delays or unexpected data distributions and data like unlike our approach.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the conclu.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As we have presented an LDE or network offering data edits, which is a client side query engine against ripple pattern FRAGMENTE servers, our research contributions can be summarized as follows.",
                    "label": 1
                },
                {
                    "sent": "We propose a novel optimization techniques tailored for triple butter fragments.",
                    "label": 1
                },
                {
                    "sent": "We also propose autonomous eddies in our routing.",
                    "label": 0
                },
                {
                    "sent": "Policies are tailored for sparkle queries.",
                    "label": 0
                },
                {
                    "sent": "Our experimental results showed that our approach is able to overcome state of the art and our engine is also able to adapt execution to unexpected network delays.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the future work we play.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To define cost models to estimate the selectivity of triple pattern fragments to enhance our query optimizer.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also would like to study different routing policies and finally.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Play our adaptive techniques to federations of triple patterns.",
                    "label": 0
                },
                {
                    "sent": "These are so.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the references.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We used and that's all from my side.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Three things.",
                    "label": 0
                },
                {
                    "sent": "First of all, you made my day second, about language that you implemented versus source code.",
                    "label": 0
                },
                {
                    "sent": "And finally, if the server sends extra metadata, which would be interesting for you.",
                    "label": 0
                },
                {
                    "sent": "Very good questions.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "So I'm very happy that I made your day.",
                    "label": 0
                },
                {
                    "sent": "We implemented it in Python.",
                    "label": 0
                },
                {
                    "sent": "We are right now.",
                    "label": 0
                },
                {
                    "sent": "You know, working on the code to make it available and I will keep you up to date on that.",
                    "label": 0
                },
                {
                    "sent": "And the third question, the metadata.",
                    "label": 0
                },
                {
                    "sent": "I would like to have about information about the distribution of the triples that are contained within the fragment.",
                    "label": 0
                },
                {
                    "sent": "This will be very very useful for our optimizer to decide what type of plan or what type of operator should be should be better.",
                    "label": 0
                },
                {
                    "sent": "So I'm looking forward to.",
                    "label": 0
                },
                {
                    "sent": "Get more metadata from the fragments.",
                    "label": 0
                },
                {
                    "sent": "I just a question about your evaluation.",
                    "label": 0
                },
                {
                    "sent": "You set a timeout, why exactly?",
                    "label": 0
                },
                {
                    "sent": "Yes, some of the some of the questions or queries.",
                    "label": 0
                },
                {
                    "sent": "In this case we're taking very long to execute.",
                    "label": 0
                },
                {
                    "sent": "So actually for some queries with the triple butter fragment guy, we were not able to finish the whole the whole experiment.",
                    "label": 0
                },
                {
                    "sent": "So that's why we just set up an timeout for experiments.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I have also question related to the experiments you showed results with respect to Q execution time and number of requests.",
                    "label": 1
                },
                {
                    "sent": "Um, did you also look into the.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Data science that was shipped during the execution of this quiz.",
                    "label": 0
                },
                {
                    "sent": "So some of these you showed one of these in the earlier in the first slide we showed something like requesting for whole triple patterns instead of requesting for the instantiated versions of them, which I would expect to ship more data than basically all you join.",
                    "label": 0
                },
                {
                    "sent": "Yes, so we haven't measured the exact number of intermediate results that we shipped from the servers, but the number of requests that we are submitting.",
                    "label": 0
                },
                {
                    "sent": "It's like an indication of the amount of data that we are retrieving.",
                    "label": 0
                },
                {
                    "sent": "I mean, indeed we are retrieving the same amount of data, but we're just doing it in a more sorry we're not receiving the same amount of data we are just retrieving whatever we need because this is done by the by the physical optimizer, but the number of requests is actually an indication of the amount of data that we are shipping from the servers.",
                    "label": 0
                },
                {
                    "sent": "We presented for Experiment 2 but also for experiment one.",
                    "label": 0
                },
                {
                    "sent": "We did not report it on the paper, but we also were able to observe that the number of requests were much much lower than with the current client.",
                    "label": 0
                }
            ]
        }
    }
}