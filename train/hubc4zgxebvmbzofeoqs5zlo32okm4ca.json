{
    "id": "hubc4zgxebvmbzofeoqs5zlo32okm4ca",
    "title": "Tandem Connectionist Feature Extraction for Conversational Speech Recognition",
    "info": {
        "author": [
            "Barry Chen, American Electronics Association"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "June 2004",
        "category": [
            "Top->Computer Science->Speech Analysis",
            "Top->Computer Science->Machine Learning->Human Language Technology",
            "Top->Computer Science->Machine Learning->Markov Processes"
        ]
    },
    "url": "http://videolectures.net/mlmi04ch_chen_tcfec/",
    "segmentation": [
        [
            "And so my student chief and you spoke on Monday also was very involved in this and responsible for the paychecks.",
            "He Hermansky and Andreas Toki also were key contributors to Henik to all the background work on the temporal features, and Andreas views of the recognizer related topics.",
            "Oh this talk is really about a particular piece of berries work, which is to try to understand a couple things, couple specific things which are really interested me anyway, about using the kind of long-term temporal features that we've been interested in."
        ],
        [
            "The last number of years.",
            "So this slide shows a picture of the standard things that we all do.",
            "We in speech recognition we should say.",
            "Window the signal.",
            "We take the FFT.",
            "We do some kind of critical band integration.",
            "We typically do some kind of compression such as log compression, or to prove something and then this picture here being the picture of a spectrogram.",
            "Basically on the spectrogram and logical band energies.",
            "What we do is we take a slice at a particular point in time with this window open 8025 milliseconds or so, and we move this along every 10 milliseconds.",
            "That's what we all have done for a long time.",
            "Now."
        ],
        [
            "The interesting thing about hoenix traps and the EXE version of that is hats just slightly different thing is to look at more focus more on the temporal evolution in a relatively small part of the spectrum.",
            "The more general thing, though, is that what we want to do is look at big chunks."
        ],
        [
            "Time, so just background on traps.",
            "This was originated Oggi Sharma, Jane, Shiva, Dawson and Maski.",
            "Last two are currently Diddy at.",
            "The basic idea is look at a temporal pattern of speech energy in Monero chunk of frequency over say half to half a second to a second and in all the variants of traps.",
            "Pretty much well.",
            "Most of them use some kind of neural networks trained to get posteriors.",
            "This is very similar to what she thought she was talking about.",
            "Monday, where he was looking at different inputs rather than traps, but still getting neural networks trained to get posteriors and in as in his talk here were primarily using this posteriors as features after some some other processing and hidden activation traps are just another variant of this talk about briefly in a second."
        ],
        [
            "So the overall motivation is that we want to look at more time because we find from psychoacoustics that there is information that is spread over time, not just 25 milliseconds from speech sounds, and you can actually verify that in the signal, not just from what people here by doing various kinds of information theoretic measures and the overall motivation also is just to have greater robustness to degradations in the speech, both from varying speech patterns and from environmental customers.",
            "So you."
        ],
        [
            "Could think that you might not need to use traps because we have these very general very powerful classifiers these days we're looking at huge amounts of data and so you ought to be able to just take the entire big chunk of speech in this rectangle.",
            "Here is covering, I think, about 1/2 second of speech and just put it into your statistical learning system and it would be able to sort things out."
        ],
        [
            "Alternatively, you could say no.",
            "The temporal information is important.",
            "We want to focus it.",
            "We want to constrain the learning somehow, and in most of our systems, we're going to combine it with something that looks the other way anyway.",
            "That looks at more spectral information, so let's force it to do that.",
            "That's."
        ],
        [
            "It also shown here this this one stage approach just take all this log critical band spectrum, feed it into a big neural network and you get phoning posterior probabilities at each point at each frame of the speech and then you can use that in various ways.",
            "In the tandem approach that she found talked about Monday.",
            "Also belt Gyanendra Dixie while ago use these more features, but any event you get all the information this way."
        ],
        [
            "Also imagine a two stage approach where first you get do some sort of transformation on the individual critical bands and then you take the output from that emergent together in this slide.",
            "This transformation is linear.",
            "You can use PCA or LDA, say, and in this slide we have neural Nets."
        ],
        [
            "This is too small and prayed for you to get.",
            "There is a lot of detail here and it's we blew it up bigger in the papers.",
            "In the paper comes out to be actually be able to see what the slide is about, but let me just say that the main point of this slide is actually to differentiate between traps and hats and the distinction really is that in traps you have neural networks that are trained for each individual critical band in some instantiation's more than one critical band.",
            "And then their outputs go into a combining network and hats.",
            "You train up these Nets, but then you don't use the hidden to output connections, and there's some reasoning for this that bear goes into in this work.",
            "It turns out to work slightly better for some of the things that we looked at, so we tended to use those."
        ],
        [
            "But that's not really important here.",
            "The main thing is that I want to get to is the questions that really intrigued me about various work, which is, if you constrain the learning in this way so that you really look across the bands as we've been doing as it seemed to help number directions, is that after all better than just putting the whole thing and that you'd like to think that it was like, I think there was some advantage in being smart in this way, but maybe not, and so we wanted to test that.",
            "And the other thing is, it did seem like the neural Nets were good thing to do.",
            "We have them around.",
            "We know how to use them, but maybe just using something linear and simple would work just as well.",
            "So these were two questions we had."
        ],
        [
            "The system context at the same task that she found was talking bout Monday.",
            "This is the switchboard task, or conversational telephone speech task.",
            "It's called these days.",
            "This is a relatively small version of it, only only 68 hours of training.",
            "But this does amount to quite a few frames for the testing.",
            "Cases were testing on 2 million frames of speech, where frame is again every 10 milliseconds and 62,000 words, and I only mention this.",
            "Indicate the differences of a few tenths of a percent are actually statistically significant by most tests.",
            "Our back end recognizer is authorized to cipher system.",
            "There's a bunch of detail in the lines at the bottom, but the main point is that.",
            "This is a relatively simplified form of the of these large conversational telephone speech recognizers.",
            "They mostly have multiple passes with much more complex language models and acoustic models, but it's good enough to sort of get in the ballpark.",
            "Here's the 1st result."
        ],
        [
            "This is called frame classification.",
            "This means that for each 10 millisecond frame you find the highest value of.",
            "Of the posterior probabilities out of an app that you're training, so you're not doing word recognition yet, but you just see how accurate you can be in determining the label class of each frame, and so this one on the left is just throwing all of the log critical band data into a net, and the one on the right is the hats, and so in fact, at least at the frame level, it does seem to help to do the constraining and also intermediate is putting some sort of India linear transformation at the critical band level.",
            "So the non linearity also seems to help there."
        ],
        [
            "Now we want to actually do a a speech recognition system.",
            "So here we start off with a well calling a standalone feature system.",
            "That means that we're not combining these features with anything else, we're just using them on their on their own as the only features to do speech recognition with an as chief on was saying the other day, it's typical for us to do something to make the features look more Gaussian, such as taking the log just what we did here, and to do some sort of decorrelation, which we did in this case with PCA, which again is very similar to the tandem setup that.",
            "Was developed by her mask Ian and Dan Allison sent Sharma.",
            "And these are then used as front end features for the Sri recognizer.",
            "OK, so here's an ASA."
        ],
        [
            "So this is the opposite direction of what the previous graph for us, and that that was accuracy.",
            "And this is word error rate.",
            "So a big bar is bad, and so the bar on the left then shows that the again throwing all the data in did not work as well as other approaches and the bar in the firelight right indicates that doing the.",
            "Temporal constraint actually does seem to be the best, and the linear approaches are somewhere between with some variation.",
            "Now, the way we actually use these things, however."
        ],
        [
            "And in practice, on these large tasks and also in some smaller ones, is typically in combination with PLP and PLP.",
            "Related features like First River too.",
            "So what Sri actually uses their systems, LDA, and with some dimensional dimensionality reduction to go down to 39 dimensions.",
            "So we just concatenate these PCA transformed and truncated MLP based features to those features and see how.",
            "Sure.",
            "I'll shoot you more comparable here, so these are all combinations here when you add."
        ],
        [
            "Uof full 15 Browns by 51 frames.",
            "That's Alpha circum speech.",
            "Or doesn't help too much, and when you get over to these points to the right where?",
            "You're actually combining here with hats, and the one just to the right of it, the second from the far right is what she found was presenting the other day.",
            "You have a fair amount, more reaction, and the thing that works best is to put it over together.",
            "I should add for those who aren't familiar with these kinds of tasks, that a percent or two of word error rate reduction absolutely is actually pretty big deal.",
            "OK."
        ],
        [
            "So bye.",
            "I interpret them, which means that we haven't been wasting our time the last few years.",
            "Playing around with these things and we don't just have to put it all to the big gap and Secondly, also another way in which I think we weren't wasting our time.",
            "It turns out that that's appear to help over at least.",
            "Schudrich Patience, said she.",
            "Ludacris formation and we don't know well there would be much better, but at least the ones that don't let me know about that is good.",
            "And then the final thing, which is just sort of along the lines of.",
            "We tried the thing that we liked and it made everything better.",
            "In fact, combined synergistically with PLP features and with PLP MLP with sometimes called the tandem features too.",
            "Pretty pretty reasonable improvements on conversational telephone speech recognition, and that's the end."
        ],
        [
            "And one other thing.",
            "And of course, yeah, there are clear long term time constraints in speech has been shown, but is there direct evidence to such constraints acting in a trap, or how?",
            "Shame.",
            "Show show me.",
            "Parts please.",
            "Long term technical features and critical bands.",
            "Yes individually, yeah is there directs cycle acoustic support for that.",
            "Great scenic Good now I don't know if that's what I do know.",
            "Is that at the signal level we see it right?",
            "So if we look at the information theoretic measures that various kinds of like nonlinear versions of correlation essentially that you see this correlation, is there an that when you include these longer periods, even in within a critical band?",
            "That we get these improvements so would be getting better or we wouldn't be seeing these these correlations, but I don't know the cycle acoustics.",
            "Do you know if?",
            "Reason for working in the critical bands or isolated slices of the frequencies is very simple.",
            "You are using.",
            "Good morning brother.",
            "Machines for civil lawsuit.",
            "Ignore or deemphasized apart which maybe not giving you the reliable information and this second block which is there the tandem classifiers capable actually of of doing that, but at least the way I see it there is a week ago a little bit more into the reasons why we want to get go away entirely from these correlations across frequencies because those are the ones which had us the most in the case of like linear distortions and so on and so on basically.",
            "Recognizes do mine very much.",
            "Trump doesn't mind stuff down there, does exactly the same thing as hearing exactly very similar thing, but human urine does.",
            "Essentially it yesterday was talking about this layer.",
            "Swords for Big Boss in Florida.",
            "Seems as quickly as possible to posteriors and then you dearly posteriors.",
            "Could be isolated in frequencies and I think it is a big advantage of doing that, so sensible sort of psychoacoustic reason I guess is that is that it is that in terms of human performance on being resistant to different kinds of different kinds of errors.",
            "Also just the cycle the old psychoacoustics that determining the notion of critical band, right?",
            "I mean, is is implies some sort of independence there, right?",
            "And then we can so we are still isolated in frequencies, but we are looking at slightly more than single particle that actually is better, so there's nothing magic about physical and but there is some magical super difference and again I can go in through the windows.",
            "1st.",
            "Google."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so my student chief and you spoke on Monday also was very involved in this and responsible for the paychecks.",
                    "label": 0
                },
                {
                    "sent": "He Hermansky and Andreas Toki also were key contributors to Henik to all the background work on the temporal features, and Andreas views of the recognizer related topics.",
                    "label": 1
                },
                {
                    "sent": "Oh this talk is really about a particular piece of berries work, which is to try to understand a couple things, couple specific things which are really interested me anyway, about using the kind of long-term temporal features that we've been interested in.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The last number of years.",
                    "label": 0
                },
                {
                    "sent": "So this slide shows a picture of the standard things that we all do.",
                    "label": 0
                },
                {
                    "sent": "We in speech recognition we should say.",
                    "label": 0
                },
                {
                    "sent": "Window the signal.",
                    "label": 0
                },
                {
                    "sent": "We take the FFT.",
                    "label": 0
                },
                {
                    "sent": "We do some kind of critical band integration.",
                    "label": 0
                },
                {
                    "sent": "We typically do some kind of compression such as log compression, or to prove something and then this picture here being the picture of a spectrogram.",
                    "label": 0
                },
                {
                    "sent": "Basically on the spectrogram and logical band energies.",
                    "label": 1
                },
                {
                    "sent": "What we do is we take a slice at a particular point in time with this window open 8025 milliseconds or so, and we move this along every 10 milliseconds.",
                    "label": 0
                },
                {
                    "sent": "That's what we all have done for a long time.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The interesting thing about hoenix traps and the EXE version of that is hats just slightly different thing is to look at more focus more on the temporal evolution in a relatively small part of the spectrum.",
                    "label": 0
                },
                {
                    "sent": "The more general thing, though, is that what we want to do is look at big chunks.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Time, so just background on traps.",
                    "label": 0
                },
                {
                    "sent": "This was originated Oggi Sharma, Jane, Shiva, Dawson and Maski.",
                    "label": 0
                },
                {
                    "sent": "Last two are currently Diddy at.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is look at a temporal pattern of speech energy in Monero chunk of frequency over say half to half a second to a second and in all the variants of traps.",
                    "label": 0
                },
                {
                    "sent": "Pretty much well.",
                    "label": 0
                },
                {
                    "sent": "Most of them use some kind of neural networks trained to get posteriors.",
                    "label": 0
                },
                {
                    "sent": "This is very similar to what she thought she was talking about.",
                    "label": 0
                },
                {
                    "sent": "Monday, where he was looking at different inputs rather than traps, but still getting neural networks trained to get posteriors and in as in his talk here were primarily using this posteriors as features after some some other processing and hidden activation traps are just another variant of this talk about briefly in a second.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the overall motivation is that we want to look at more time because we find from psychoacoustics that there is information that is spread over time, not just 25 milliseconds from speech sounds, and you can actually verify that in the signal, not just from what people here by doing various kinds of information theoretic measures and the overall motivation also is just to have greater robustness to degradations in the speech, both from varying speech patterns and from environmental customers.",
                    "label": 0
                },
                {
                    "sent": "So you.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Could think that you might not need to use traps because we have these very general very powerful classifiers these days we're looking at huge amounts of data and so you ought to be able to just take the entire big chunk of speech in this rectangle.",
                    "label": 0
                },
                {
                    "sent": "Here is covering, I think, about 1/2 second of speech and just put it into your statistical learning system and it would be able to sort things out.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alternatively, you could say no.",
                    "label": 0
                },
                {
                    "sent": "The temporal information is important.",
                    "label": 0
                },
                {
                    "sent": "We want to focus it.",
                    "label": 0
                },
                {
                    "sent": "We want to constrain the learning somehow, and in most of our systems, we're going to combine it with something that looks the other way anyway.",
                    "label": 0
                },
                {
                    "sent": "That looks at more spectral information, so let's force it to do that.",
                    "label": 0
                },
                {
                    "sent": "That's.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It also shown here this this one stage approach just take all this log critical band spectrum, feed it into a big neural network and you get phoning posterior probabilities at each point at each frame of the speech and then you can use that in various ways.",
                    "label": 0
                },
                {
                    "sent": "In the tandem approach that she found talked about Monday.",
                    "label": 0
                },
                {
                    "sent": "Also belt Gyanendra Dixie while ago use these more features, but any event you get all the information this way.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also imagine a two stage approach where first you get do some sort of transformation on the individual critical bands and then you take the output from that emergent together in this slide.",
                    "label": 0
                },
                {
                    "sent": "This transformation is linear.",
                    "label": 0
                },
                {
                    "sent": "You can use PCA or LDA, say, and in this slide we have neural Nets.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is too small and prayed for you to get.",
                    "label": 0
                },
                {
                    "sent": "There is a lot of detail here and it's we blew it up bigger in the papers.",
                    "label": 0
                },
                {
                    "sent": "In the paper comes out to be actually be able to see what the slide is about, but let me just say that the main point of this slide is actually to differentiate between traps and hats and the distinction really is that in traps you have neural networks that are trained for each individual critical band in some instantiation's more than one critical band.",
                    "label": 0
                },
                {
                    "sent": "And then their outputs go into a combining network and hats.",
                    "label": 0
                },
                {
                    "sent": "You train up these Nets, but then you don't use the hidden to output connections, and there's some reasoning for this that bear goes into in this work.",
                    "label": 0
                },
                {
                    "sent": "It turns out to work slightly better for some of the things that we looked at, so we tended to use those.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But that's not really important here.",
                    "label": 0
                },
                {
                    "sent": "The main thing is that I want to get to is the questions that really intrigued me about various work, which is, if you constrain the learning in this way so that you really look across the bands as we've been doing as it seemed to help number directions, is that after all better than just putting the whole thing and that you'd like to think that it was like, I think there was some advantage in being smart in this way, but maybe not, and so we wanted to test that.",
                    "label": 0
                },
                {
                    "sent": "And the other thing is, it did seem like the neural Nets were good thing to do.",
                    "label": 0
                },
                {
                    "sent": "We have them around.",
                    "label": 0
                },
                {
                    "sent": "We know how to use them, but maybe just using something linear and simple would work just as well.",
                    "label": 0
                },
                {
                    "sent": "So these were two questions we had.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The system context at the same task that she found was talking bout Monday.",
                    "label": 0
                },
                {
                    "sent": "This is the switchboard task, or conversational telephone speech task.",
                    "label": 1
                },
                {
                    "sent": "It's called these days.",
                    "label": 1
                },
                {
                    "sent": "This is a relatively small version of it, only only 68 hours of training.",
                    "label": 0
                },
                {
                    "sent": "But this does amount to quite a few frames for the testing.",
                    "label": 0
                },
                {
                    "sent": "Cases were testing on 2 million frames of speech, where frame is again every 10 milliseconds and 62,000 words, and I only mention this.",
                    "label": 0
                },
                {
                    "sent": "Indicate the differences of a few tenths of a percent are actually statistically significant by most tests.",
                    "label": 0
                },
                {
                    "sent": "Our back end recognizer is authorized to cipher system.",
                    "label": 0
                },
                {
                    "sent": "There's a bunch of detail in the lines at the bottom, but the main point is that.",
                    "label": 0
                },
                {
                    "sent": "This is a relatively simplified form of the of these large conversational telephone speech recognizers.",
                    "label": 0
                },
                {
                    "sent": "They mostly have multiple passes with much more complex language models and acoustic models, but it's good enough to sort of get in the ballpark.",
                    "label": 0
                },
                {
                    "sent": "Here's the 1st result.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is called frame classification.",
                    "label": 1
                },
                {
                    "sent": "This means that for each 10 millisecond frame you find the highest value of.",
                    "label": 0
                },
                {
                    "sent": "Of the posterior probabilities out of an app that you're training, so you're not doing word recognition yet, but you just see how accurate you can be in determining the label class of each frame, and so this one on the left is just throwing all of the log critical band data into a net, and the one on the right is the hats, and so in fact, at least at the frame level, it does seem to help to do the constraining and also intermediate is putting some sort of India linear transformation at the critical band level.",
                    "label": 0
                },
                {
                    "sent": "So the non linearity also seems to help there.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we want to actually do a a speech recognition system.",
                    "label": 0
                },
                {
                    "sent": "So here we start off with a well calling a standalone feature system.",
                    "label": 0
                },
                {
                    "sent": "That means that we're not combining these features with anything else, we're just using them on their on their own as the only features to do speech recognition with an as chief on was saying the other day, it's typical for us to do something to make the features look more Gaussian, such as taking the log just what we did here, and to do some sort of decorrelation, which we did in this case with PCA, which again is very similar to the tandem setup that.",
                    "label": 0
                },
                {
                    "sent": "Was developed by her mask Ian and Dan Allison sent Sharma.",
                    "label": 0
                },
                {
                    "sent": "And these are then used as front end features for the Sri recognizer.",
                    "label": 1
                },
                {
                    "sent": "OK, so here's an ASA.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the opposite direction of what the previous graph for us, and that that was accuracy.",
                    "label": 0
                },
                {
                    "sent": "And this is word error rate.",
                    "label": 1
                },
                {
                    "sent": "So a big bar is bad, and so the bar on the left then shows that the again throwing all the data in did not work as well as other approaches and the bar in the firelight right indicates that doing the.",
                    "label": 0
                },
                {
                    "sent": "Temporal constraint actually does seem to be the best, and the linear approaches are somewhere between with some variation.",
                    "label": 0
                },
                {
                    "sent": "Now, the way we actually use these things, however.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in practice, on these large tasks and also in some smaller ones, is typically in combination with PLP and PLP.",
                    "label": 0
                },
                {
                    "sent": "Related features like First River too.",
                    "label": 0
                },
                {
                    "sent": "So what Sri actually uses their systems, LDA, and with some dimensional dimensionality reduction to go down to 39 dimensions.",
                    "label": 1
                },
                {
                    "sent": "So we just concatenate these PCA transformed and truncated MLP based features to those features and see how.",
                    "label": 1
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "I'll shoot you more comparable here, so these are all combinations here when you add.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Uof full 15 Browns by 51 frames.",
                    "label": 1
                },
                {
                    "sent": "That's Alpha circum speech.",
                    "label": 0
                },
                {
                    "sent": "Or doesn't help too much, and when you get over to these points to the right where?",
                    "label": 0
                },
                {
                    "sent": "You're actually combining here with hats, and the one just to the right of it, the second from the far right is what she found was presenting the other day.",
                    "label": 0
                },
                {
                    "sent": "You have a fair amount, more reaction, and the thing that works best is to put it over together.",
                    "label": 0
                },
                {
                    "sent": "I should add for those who aren't familiar with these kinds of tasks, that a percent or two of word error rate reduction absolutely is actually pretty big deal.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So bye.",
                    "label": 0
                },
                {
                    "sent": "I interpret them, which means that we haven't been wasting our time the last few years.",
                    "label": 0
                },
                {
                    "sent": "Playing around with these things and we don't just have to put it all to the big gap and Secondly, also another way in which I think we weren't wasting our time.",
                    "label": 0
                },
                {
                    "sent": "It turns out that that's appear to help over at least.",
                    "label": 0
                },
                {
                    "sent": "Schudrich Patience, said she.",
                    "label": 0
                },
                {
                    "sent": "Ludacris formation and we don't know well there would be much better, but at least the ones that don't let me know about that is good.",
                    "label": 0
                },
                {
                    "sent": "And then the final thing, which is just sort of along the lines of.",
                    "label": 0
                },
                {
                    "sent": "We tried the thing that we liked and it made everything better.",
                    "label": 0
                },
                {
                    "sent": "In fact, combined synergistically with PLP features and with PLP MLP with sometimes called the tandem features too.",
                    "label": 1
                },
                {
                    "sent": "Pretty pretty reasonable improvements on conversational telephone speech recognition, and that's the end.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And one other thing.",
                    "label": 0
                },
                {
                    "sent": "And of course, yeah, there are clear long term time constraints in speech has been shown, but is there direct evidence to such constraints acting in a trap, or how?",
                    "label": 0
                },
                {
                    "sent": "Shame.",
                    "label": 0
                },
                {
                    "sent": "Show show me.",
                    "label": 0
                },
                {
                    "sent": "Parts please.",
                    "label": 0
                },
                {
                    "sent": "Long term technical features and critical bands.",
                    "label": 0
                },
                {
                    "sent": "Yes individually, yeah is there directs cycle acoustic support for that.",
                    "label": 0
                },
                {
                    "sent": "Great scenic Good now I don't know if that's what I do know.",
                    "label": 0
                },
                {
                    "sent": "Is that at the signal level we see it right?",
                    "label": 0
                },
                {
                    "sent": "So if we look at the information theoretic measures that various kinds of like nonlinear versions of correlation essentially that you see this correlation, is there an that when you include these longer periods, even in within a critical band?",
                    "label": 0
                },
                {
                    "sent": "That we get these improvements so would be getting better or we wouldn't be seeing these these correlations, but I don't know the cycle acoustics.",
                    "label": 0
                },
                {
                    "sent": "Do you know if?",
                    "label": 0
                },
                {
                    "sent": "Reason for working in the critical bands or isolated slices of the frequencies is very simple.",
                    "label": 0
                },
                {
                    "sent": "You are using.",
                    "label": 0
                },
                {
                    "sent": "Good morning brother.",
                    "label": 0
                },
                {
                    "sent": "Machines for civil lawsuit.",
                    "label": 0
                },
                {
                    "sent": "Ignore or deemphasized apart which maybe not giving you the reliable information and this second block which is there the tandem classifiers capable actually of of doing that, but at least the way I see it there is a week ago a little bit more into the reasons why we want to get go away entirely from these correlations across frequencies because those are the ones which had us the most in the case of like linear distortions and so on and so on basically.",
                    "label": 0
                },
                {
                    "sent": "Recognizes do mine very much.",
                    "label": 0
                },
                {
                    "sent": "Trump doesn't mind stuff down there, does exactly the same thing as hearing exactly very similar thing, but human urine does.",
                    "label": 0
                },
                {
                    "sent": "Essentially it yesterday was talking about this layer.",
                    "label": 0
                },
                {
                    "sent": "Swords for Big Boss in Florida.",
                    "label": 0
                },
                {
                    "sent": "Seems as quickly as possible to posteriors and then you dearly posteriors.",
                    "label": 0
                },
                {
                    "sent": "Could be isolated in frequencies and I think it is a big advantage of doing that, so sensible sort of psychoacoustic reason I guess is that is that it is that in terms of human performance on being resistant to different kinds of different kinds of errors.",
                    "label": 0
                },
                {
                    "sent": "Also just the cycle the old psychoacoustics that determining the notion of critical band, right?",
                    "label": 0
                },
                {
                    "sent": "I mean, is is implies some sort of independence there, right?",
                    "label": 0
                },
                {
                    "sent": "And then we can so we are still isolated in frequencies, but we are looking at slightly more than single particle that actually is better, so there's nothing magic about physical and but there is some magical super difference and again I can go in through the windows.",
                    "label": 0
                },
                {
                    "sent": "1st.",
                    "label": 0
                },
                {
                    "sent": "Google.",
                    "label": 0
                }
            ]
        }
    }
}