{
    "id": "yu6ektpvwwih7sdo7mmyezdtcukiy5rv",
    "title": "Convolutional Object Finder, A Neural Architecture for Fast and Robust Object Detection",
    "info": {
        "author": [
            "Christophe Garc\u00eda, France Telecom Research"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "April 2005",
        "category": [
            "Top->Computer Science->Machine Learning->Neural Networks"
        ]
    },
    "url": "http://videolectures.net/pcw05_garcia_cofna/",
    "segmentation": [
        [
            "I will not talk about these VM's and there is sorry.",
            "So noisy and the second one is incomplete.",
            "Jet lag because I just arrived from the States, so I hope I will be understandable.",
            "And will go fast now because I think we took time with this technical problems.",
            "So we participate."
        ],
        [
            "Read it in.",
            "The competition for the detection and localization of two class objects only, which are motorbikes and cars.",
            "So the method is directly based on an architecture, but I developed time ago for faces for face detection which gave until now the best results in the literature.",
            "So it's exactly the same architecture but and it was interesting when we learn about this challenge we say OK, why not training with the same stuff on other objects are a bit more complicated because of the poses and other stuff.",
            "So it was interesting for us at least to start playing with something else and faces.",
            "Because after a while it gets a bit boring.",
            "Some challenges."
        ],
        [
            "Course we discuss about that quite complicated problem.",
            "OK, occlusions pose variation elimination, so there are some examples.",
            "So how does it work?"
        ],
        [
            "So we are in computing neural networks, so we try directly to build discriminative system.",
            "So we need.",
            "Kind of examples which are the positive and negative examples classically.",
            "So first we get our examples.",
            "So we use directly bonding boxes proposed and gravitation just the bonding boxes and actually we build them.",
            "We took any bigger than what was proposed for obvious reasons that the algorithm which works with convolutions and needs a bit of space on the borders.",
            "So for positive examples was easy.",
            "We had then.",
            "But for negative examples.",
            "What can we do?",
            "It's difficult, we know.",
            "What is a motor bike, which is not a motor bike is more complicated, so we follow a kind of classical schema, but we use for faces.",
            "Which relies on bootstrapping.",
            "So will explain a bit.",
            "After that.",
            "The scheme for detection is the following here.",
            "So as it was mentioned, is a technique which is like brute search in scaling positions.",
            "So of course, as we are looking for objects of different sizes and as I will say and present later on, we learn the object in a fixed size retina.",
            "We have, of course, then to process the image in a multi scale pyramid.",
            "Like that, so here we have an example.",
            "We have two motorbikes.",
            "They are fine at different scales.",
            "OK, so the idea is of course to use the classifier, but I will present after that at every scale.",
            "Find the results of vote at every scale, choose them.",
            "And then we'll see what we do.",
            "Some cleanup and other reasons.",
            "OK, so this is the schema it can look like heavy computation in reality is very fast because the kind of network we're using is there easily replicated and we talk about near real time when we process safety messages basically.",
            "So are you going with that?",
            "So."
        ],
        [
            "We use the convolution neural networks introduced by look in the 90s, so the interest of this kind of neural networks is that they follow.",
            "Costly bit of principles of memory and visual processing systems, which means that we use simple to complex cells.",
            "The first cells try to do simple processing and then there's a cascade of processing looking for more complex shapes.",
            "So it goes through local receptive fields, shell weights and subsampling.",
            "It was very good at the system is very good advantages, like he claims automatically feature extractors and classifiers at the same time.",
            "We don't process first extraction and classification that we were schema but learns what to extract.",
            "To classify that prove it, you are completely linked.",
            "So it has been proven to be very robust.",
            "A pattern by actions, specially occlusions.",
            "And the amount of noise.",
            "And of course, the implementation is very fast as well, which can be interesting in indexing applications.",
            "So does it."
        ],
        [
            "So it's a very very light system that we use here.",
            "Basically.",
            "For a positive example or negative example, but then turns the richina so we have six fixed size right now 52 by 30.",
            "In that case, what is important in Russia?",
            "And we tried to find among all the example Russia would could be compatible with most of the examples.",
            "That means most of the motorbikes have to fit in this retina, so according to bonding boxes we made very simple statistics to try to find a box, but can enclose I talk about that because we see that in four cars we have not very good results for one reason.",
            "But it was very complicated because of the different positive cars.",
            "To have this be sweet enough field nicely.",
            "So I will say that in that case we should need another network, for instance of two other networks and use them for different poses.",
            "Here we talk about only one network.",
            "So for one example.",
            "Classically, we target some results.",
            "So you know the easy way here we define two classes, motorbike non motorbikes.",
            "We want the system to answer close to one when it's motorbike minus one.",
            "When it's not motorbike.",
            "So we have a nice sigmoid function at the end basically.",
            "Very classical.",
            "Then how does it work?",
            "This part of the network.",
            "Here can be considered as a feature extraction system, so the idea is to do from the image directly in pixel.",
            "Be some representation.",
            "Of.",
            "Let's say Victor representation, but will automatically be extracted feature.",
            "And then.",
            "The second part is the classification layer, and you see here it's a very simple NLP, so very simple perceptron here.",
            "So just one layer.",
            "So it's quite light.",
            "No more independence.",
            "How does it work?",
            "We get what we call a convolutional layer.",
            "And the subsampling layer.",
            "So what is the commercial layer?",
            "Basically from the input in edge here?",
            "We have four convolutions possible or very small kernel 5 by 5, so that means everybody.",
            "Everything is random.",
            "At the beginning.",
            "We don't know the candles to apply, and through a system through the learning procedure will learn the parameters of the 5 / 4 years of five by five, so they will extract information from the image.",
            "So obviously being 5 by 5 that will extract like lines horizontal lines, the article lines.",
            "It's imperative.",
            "Then there is a subsampling layer layer.",
            "The idea here is of course to reduce information so that you have less to process after that, but a bit more, and that varies as well a coefficient.",
            "But it's supposed to adjust the answer with convolutions, which is linear at the beginning, and to be able to play with changing in elimination in lighting.",
            "So the systems are very good at adapting to lighting conditions.",
            "Full through barometer, which is here.",
            "So after subsampling, we can offer to make.",
            "The second layer.",
            "Of processing, so once again it's convolutional layer subsampling layer, but here it's a bit different what we do here is we have less information we can process more so it's the idea of simple to complex cells.",
            "Here what we do is that we have two type of convolutions.",
            "The first here.",
            "They are like.",
            "If I see well.",
            "Should be aids.",
            "I think mistake you see 7.",
            "So I told them this was included I think.",
            "So basically for all of them here you process two convolutions.",
            "So the idea is to say I will go into more complex features so you once again learn to convolution or very small size kernel three by three we can offer because we have stumbled.",
            "So the idea here is that we will we don't see nicely on the image of course here, but if here we are able to, for instance, they take lines here, will be may be able to detect corners or T. Or whatever.",
            "So here you get 2 convolutions separated for each of them and then here.",
            "We viewed as well convolutions.",
            "That means this image is obtained by the convolution coming from this image and a combination coming from this image.",
            "So here you are able to choose different channels of the beginning.",
            "OK, so it's once again aware finding higher, higher level features.",
            "Once again subsampling.",
            "Sorry it was here again subsampling.",
            "So what's the idea here?",
            "Once again, to adapt another another point which is very important is to get a reduced size vector, because this is our feature vector here, so this image is basically I don't remember exactly their size.",
            "Let's say it's 8 by 9 or 10 by 10.",
            "So and you get one year and receiving the information of this little image all the time here.",
            "So it's like a vector of information.",
            "OK, so they are separated so you get this layer.",
            "This layer will make the decision according to the features.",
            "So at the end you have one euro which receive all the information and votes negative positive.",
            "So actually.",
            "We get lots of connection if we see it as a neural network.",
            "If you don't consider the notion of convolution and you think about neural network, here you can consider that everybody is connected, but in reality we talk about convolution.",
            "That means the weight are shared is like you replicate part of the network.",
            "So in the system there are like 951 trainable coefficients.",
            "Which all the different values of the kernels biases as well, charge it always function.",
            "OK, so they are the parameters you we have to find to define the full system.",
            "OK.",
            "So this is learned by quite modified back propagation is not started back for vacation for lots of reasons with shared weights.",
            "And as well, because the different layers they don't have the same speed in converging.",
            "So there are some some trick here.",
            "Actually, going information computation you can quite solve any.",
            "But basically there are different learning rates at the different layers.",
            "Technical point of view.",
            "So then."
        ],
        [
            "You have to feed with example.",
            "When I first heard about the challenge, I thought our method will not do because they are very little number of other examples and it's much better to have a generative model then discriminative model I believe.",
            "But we said, OK, let's try it.",
            "So we took the 217 examples.",
            "So there are some of it here and we set something up anyway for us, so let's generate a couple of artificial ones.",
            "There easily by performing a bit of translation rotation noise.",
            "Smoothing it's not obvious here.",
            "We don't see very well, but yeah.",
            "Lots of.",
            "Little transformation, just to give the system more data to do it.",
            "So there are finally something like 3900 examples posted.",
            "Example she's quite.",
            "Small number in faces.",
            "For instance, we got more than 26,000 for system.",
            "Then the problem is how to define."
        ],
        [
            "The non motor example the negative examples.",
            "So we follow kind of bootstrapping procedure.",
            "That means we start to train the system.",
            "I will not go into details here, but the idea is that you train the system first to drop randomly some examples.",
            "Actually it's not that random, we find it is quite nice to crop examples which are quite close to the motorbikes, like your borders.",
            "To give to the system a notion of precision detection then.",
            "So we get this examples.",
            "And then we just train about the system and we run it in a very.",
            "Quite a certain number of scenery images.",
            "Basically textual images from coral etc which can give lots of.",
            "False positive basically.",
            "So we get the negative examples with the Aroseva network and we feed the system.",
            "Actually we have we have a simple way of not taking all of them we.",
            "Put the free cell then, then we reduce that mean.",
            "First we take.",
            "Directly, but negative examples, and then we consider taking the strong negative examples and then we reduce so that we stay close to the borders of the system.",
            "Here."
        ],
        [
            "This is just the process.",
            "Of grabbing this famous false alarms with negative examples, and we say that through the training, the positive this the average value for positive stay high.",
            "And through the training, what is grab that for Salam which reduces which is expectable we want when we send try learns he will answer.",
            "Lesson lesson on bad examples.",
            "So finally we grab quite a lot of false examples.",
            "Sylvan"
        ],
        [
            "Basically what I should be for so?",
            "And this seems to have more, more to say here we process, but the idea is that here basically.",
            "We don't have an example here, but every image when we process with the network, it's a sliding window.",
            "But because of the fact that we have convolutions, if you take the window and you move one pixel.",
            "Most of the computation is in common.",
            "Between these two position and with that kind of system we are able to take into to take advantage of it.",
            "Basically because we don't have to normalize in the window like deafening Easter embolization or whatever.",
            "So when we move as we have small convolution kernels.",
            "We just have to apply full convolution.",
            "On the image for first convolution, a second or third, etc.",
            "So it's a pipeline of processing, so you basically you do for convolution.",
            "For subsampling, cross convolutions, subsampling results.",
            "So this is done done in a pipeline.",
            "That's why it's like real time at the end.",
            "So I give an example here for typical size of images, 6 frames per second for that kind of images."
        ],
        [
            "So the results were somewhere like.",
            "I don't see what I think here.",
            "OK, that's been presented anyway, so we're quite surprised when we send.",
            "The reason we say OK will be very far away.",
            "And we are quite surprised to see that.",
            "It was for motorbikes at least it was.",
            "Not very far from from the best results.",
            "For the first 2.",
            "We are disappointed.",
            "We thought we could generalize a bit better, but what we think is that the the number of examples, the little number of examples we're using did not show enough poses, different poses, and I think when you go to test through, the generalization is more much more difficult.",
            "So it's what we think here.",
            "Forecast as I said."
        ],
        [
            "Disappointed.",
            "Because first we thought that car will be more more easily detectable than motorbikes because there are no no occlusion etc or less occlusions.",
            "But what we realized that because of the different poses of the car, we did not have lots of examples to follow.",
            "Anyone network.",
            "And because of this fixed size window.",
            "But we use we have to to have a rush or common ratio.",
            "It was difficult, so we really believe that we had to use at least two or three networks and choose them, which is not very costly, but we have to learn from different points of view in bad case.",
            "Because from side win from side view to review, for instance, the aspect ratio of the other window is very different and this method cannot cannot fit with us 'cause we need to fix window.",
            "So it is what we believe could be one of the reasons we have the.",
            "Quite average results here.",
            "So."
        ],
        [
            "Some results.",
            "Just to see a bit.",
            "Algorithm in terms of localization.",
            "So it's quite.",
            "Just to give an idea what to localize the system.",
            "So we have a nice voice around here.",
            "Difficult to explain.",
            "The trees is something they're interesting most of the time.",
            "So in four calls."
        ],
        [
            "So for example, is most of them are side use.",
            "So this is typical that kind of system is quite robust to occlusion, specially besides being pro shown in case of faces.",
            "And yes of course we see it very easily here.",
            "Yeah, I think it's by chance we get it in the shoulder.",
            "So as you can see, most of them aside, use.",
            "I think we did very bad on the other views and it's a pity we did not use this little weird information database.",
            "I think we did not use it, at least.",
            "To see.",
            "So just to."
        ],
        [
            "Rude.",
            "OK, but through it as well, the example is, well, not.",
            "For training that always are the best one.",
            "OK, what I said we fix racial problem.",
            "And OK, we have advantages outside before these.",
            "That's what I think.",
            "I hope I was clear enough and 'cause I don't get very clear.",
            "Same question.",
            "This is an occasion of convolutions of something they proved to be very resistant, isolating different faces.",
            "For instance, even if I was running from bases which are not specially even part of it like that.",
            "So what is the reason?",
            "The system tries to learn the first layers, some typical, very low level features, so of course systems to find enough low level features landscape, but it doesn't.",
            "I think it's great for this even if you lost quite a part of it.",
            "This is quite typical in what, when using that kind of system.",
            "And I wanted to add maybe something about this because we talked about that before the the idea of the influence of geometry, which was very interesting.",
            "In that kind of system, obviously there there is the notion of Georgia as we look at computation and it's localized convolution.",
            "So finally leaders have something.",
            "Somehow you aggregate that you use the national.",
            "I don't really understand it.",
            "And that meant a Joyce people needed, I believe, somehow this solution could be.",
            "Intermediate wasting that somehow you learn the geometry without to be very precise.",
            "You learn it from this subsampling operation.",
            "It's it's.",
            "It's a middle way between not and in geometry or dinner geometry, which is much detailing much too precise and will not be rubbish bin.",
            "So maybe.",
            "Something like that.",
            "In some of the datasets that were annotations like color, side and color ears on this Lee will be quoting myself helping.",
            "Yeah, yeah, yeah, it's it's a beauty, actually quite fast and looking at ice, which was possible.",
            "But then we did not really change.",
            "That could have been very interesting, but we think we discussed them.",
            "We'd like to go and change.",
            "And we are working right now in a kind of kaskada different system and not in the field of view about that boosts or by further join system for BAE Systems and.",
            "Trying to build systems one the first layer because Papa systems, for instance, we learn the typical examples and then another one will take care of the different poses.",
            "So the idea is to do kind of unsupervised clustering supervised.",
            "I'm not friends of that nature.",
            "Fantastic discussion."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will not talk about these VM's and there is sorry.",
                    "label": 0
                },
                {
                    "sent": "So noisy and the second one is incomplete.",
                    "label": 0
                },
                {
                    "sent": "Jet lag because I just arrived from the States, so I hope I will be understandable.",
                    "label": 0
                },
                {
                    "sent": "And will go fast now because I think we took time with this technical problems.",
                    "label": 0
                },
                {
                    "sent": "So we participate.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Read it in.",
                    "label": 0
                },
                {
                    "sent": "The competition for the detection and localization of two class objects only, which are motorbikes and cars.",
                    "label": 0
                },
                {
                    "sent": "So the method is directly based on an architecture, but I developed time ago for faces for face detection which gave until now the best results in the literature.",
                    "label": 0
                },
                {
                    "sent": "So it's exactly the same architecture but and it was interesting when we learn about this challenge we say OK, why not training with the same stuff on other objects are a bit more complicated because of the poses and other stuff.",
                    "label": 0
                },
                {
                    "sent": "So it was interesting for us at least to start playing with something else and faces.",
                    "label": 0
                },
                {
                    "sent": "Because after a while it gets a bit boring.",
                    "label": 0
                },
                {
                    "sent": "Some challenges.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Course we discuss about that quite complicated problem.",
                    "label": 0
                },
                {
                    "sent": "OK, occlusions pose variation elimination, so there are some examples.",
                    "label": 0
                },
                {
                    "sent": "So how does it work?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we are in computing neural networks, so we try directly to build discriminative system.",
                    "label": 0
                },
                {
                    "sent": "So we need.",
                    "label": 0
                },
                {
                    "sent": "Kind of examples which are the positive and negative examples classically.",
                    "label": 1
                },
                {
                    "sent": "So first we get our examples.",
                    "label": 0
                },
                {
                    "sent": "So we use directly bonding boxes proposed and gravitation just the bonding boxes and actually we build them.",
                    "label": 0
                },
                {
                    "sent": "We took any bigger than what was proposed for obvious reasons that the algorithm which works with convolutions and needs a bit of space on the borders.",
                    "label": 0
                },
                {
                    "sent": "So for positive examples was easy.",
                    "label": 0
                },
                {
                    "sent": "We had then.",
                    "label": 0
                },
                {
                    "sent": "But for negative examples.",
                    "label": 0
                },
                {
                    "sent": "What can we do?",
                    "label": 0
                },
                {
                    "sent": "It's difficult, we know.",
                    "label": 0
                },
                {
                    "sent": "What is a motor bike, which is not a motor bike is more complicated, so we follow a kind of classical schema, but we use for faces.",
                    "label": 0
                },
                {
                    "sent": "Which relies on bootstrapping.",
                    "label": 0
                },
                {
                    "sent": "So will explain a bit.",
                    "label": 0
                },
                {
                    "sent": "After that.",
                    "label": 0
                },
                {
                    "sent": "The scheme for detection is the following here.",
                    "label": 0
                },
                {
                    "sent": "So as it was mentioned, is a technique which is like brute search in scaling positions.",
                    "label": 0
                },
                {
                    "sent": "So of course, as we are looking for objects of different sizes and as I will say and present later on, we learn the object in a fixed size retina.",
                    "label": 0
                },
                {
                    "sent": "We have, of course, then to process the image in a multi scale pyramid.",
                    "label": 0
                },
                {
                    "sent": "Like that, so here we have an example.",
                    "label": 0
                },
                {
                    "sent": "We have two motorbikes.",
                    "label": 0
                },
                {
                    "sent": "They are fine at different scales.",
                    "label": 0
                },
                {
                    "sent": "OK, so the idea is of course to use the classifier, but I will present after that at every scale.",
                    "label": 0
                },
                {
                    "sent": "Find the results of vote at every scale, choose them.",
                    "label": 0
                },
                {
                    "sent": "And then we'll see what we do.",
                    "label": 0
                },
                {
                    "sent": "Some cleanup and other reasons.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the schema it can look like heavy computation in reality is very fast because the kind of network we're using is there easily replicated and we talk about near real time when we process safety messages basically.",
                    "label": 0
                },
                {
                    "sent": "So are you going with that?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We use the convolution neural networks introduced by look in the 90s, so the interest of this kind of neural networks is that they follow.",
                    "label": 1
                },
                {
                    "sent": "Costly bit of principles of memory and visual processing systems, which means that we use simple to complex cells.",
                    "label": 1
                },
                {
                    "sent": "The first cells try to do simple processing and then there's a cascade of processing looking for more complex shapes.",
                    "label": 0
                },
                {
                    "sent": "So it goes through local receptive fields, shell weights and subsampling.",
                    "label": 1
                },
                {
                    "sent": "It was very good at the system is very good advantages, like he claims automatically feature extractors and classifiers at the same time.",
                    "label": 1
                },
                {
                    "sent": "We don't process first extraction and classification that we were schema but learns what to extract.",
                    "label": 0
                },
                {
                    "sent": "To classify that prove it, you are completely linked.",
                    "label": 0
                },
                {
                    "sent": "So it has been proven to be very robust.",
                    "label": 0
                },
                {
                    "sent": "A pattern by actions, specially occlusions.",
                    "label": 0
                },
                {
                    "sent": "And the amount of noise.",
                    "label": 0
                },
                {
                    "sent": "And of course, the implementation is very fast as well, which can be interesting in indexing applications.",
                    "label": 0
                },
                {
                    "sent": "So does it.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's a very very light system that we use here.",
                    "label": 0
                },
                {
                    "sent": "Basically.",
                    "label": 0
                },
                {
                    "sent": "For a positive example or negative example, but then turns the richina so we have six fixed size right now 52 by 30.",
                    "label": 0
                },
                {
                    "sent": "In that case, what is important in Russia?",
                    "label": 0
                },
                {
                    "sent": "And we tried to find among all the example Russia would could be compatible with most of the examples.",
                    "label": 0
                },
                {
                    "sent": "That means most of the motorbikes have to fit in this retina, so according to bonding boxes we made very simple statistics to try to find a box, but can enclose I talk about that because we see that in four cars we have not very good results for one reason.",
                    "label": 0
                },
                {
                    "sent": "But it was very complicated because of the different positive cars.",
                    "label": 0
                },
                {
                    "sent": "To have this be sweet enough field nicely.",
                    "label": 0
                },
                {
                    "sent": "So I will say that in that case we should need another network, for instance of two other networks and use them for different poses.",
                    "label": 0
                },
                {
                    "sent": "Here we talk about only one network.",
                    "label": 0
                },
                {
                    "sent": "So for one example.",
                    "label": 0
                },
                {
                    "sent": "Classically, we target some results.",
                    "label": 0
                },
                {
                    "sent": "So you know the easy way here we define two classes, motorbike non motorbikes.",
                    "label": 0
                },
                {
                    "sent": "We want the system to answer close to one when it's motorbike minus one.",
                    "label": 0
                },
                {
                    "sent": "When it's not motorbike.",
                    "label": 0
                },
                {
                    "sent": "So we have a nice sigmoid function at the end basically.",
                    "label": 0
                },
                {
                    "sent": "Very classical.",
                    "label": 0
                },
                {
                    "sent": "Then how does it work?",
                    "label": 0
                },
                {
                    "sent": "This part of the network.",
                    "label": 0
                },
                {
                    "sent": "Here can be considered as a feature extraction system, so the idea is to do from the image directly in pixel.",
                    "label": 1
                },
                {
                    "sent": "Be some representation.",
                    "label": 0
                },
                {
                    "sent": "Of.",
                    "label": 0
                },
                {
                    "sent": "Let's say Victor representation, but will automatically be extracted feature.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "The second part is the classification layer, and you see here it's a very simple NLP, so very simple perceptron here.",
                    "label": 0
                },
                {
                    "sent": "So just one layer.",
                    "label": 0
                },
                {
                    "sent": "So it's quite light.",
                    "label": 0
                },
                {
                    "sent": "No more independence.",
                    "label": 0
                },
                {
                    "sent": "How does it work?",
                    "label": 0
                },
                {
                    "sent": "We get what we call a convolutional layer.",
                    "label": 0
                },
                {
                    "sent": "And the subsampling layer.",
                    "label": 0
                },
                {
                    "sent": "So what is the commercial layer?",
                    "label": 0
                },
                {
                    "sent": "Basically from the input in edge here?",
                    "label": 0
                },
                {
                    "sent": "We have four convolutions possible or very small kernel 5 by 5, so that means everybody.",
                    "label": 0
                },
                {
                    "sent": "Everything is random.",
                    "label": 0
                },
                {
                    "sent": "At the beginning.",
                    "label": 0
                },
                {
                    "sent": "We don't know the candles to apply, and through a system through the learning procedure will learn the parameters of the 5 / 4 years of five by five, so they will extract information from the image.",
                    "label": 0
                },
                {
                    "sent": "So obviously being 5 by 5 that will extract like lines horizontal lines, the article lines.",
                    "label": 0
                },
                {
                    "sent": "It's imperative.",
                    "label": 0
                },
                {
                    "sent": "Then there is a subsampling layer layer.",
                    "label": 0
                },
                {
                    "sent": "The idea here is of course to reduce information so that you have less to process after that, but a bit more, and that varies as well a coefficient.",
                    "label": 0
                },
                {
                    "sent": "But it's supposed to adjust the answer with convolutions, which is linear at the beginning, and to be able to play with changing in elimination in lighting.",
                    "label": 0
                },
                {
                    "sent": "So the systems are very good at adapting to lighting conditions.",
                    "label": 0
                },
                {
                    "sent": "Full through barometer, which is here.",
                    "label": 0
                },
                {
                    "sent": "So after subsampling, we can offer to make.",
                    "label": 0
                },
                {
                    "sent": "The second layer.",
                    "label": 0
                },
                {
                    "sent": "Of processing, so once again it's convolutional layer subsampling layer, but here it's a bit different what we do here is we have less information we can process more so it's the idea of simple to complex cells.",
                    "label": 1
                },
                {
                    "sent": "Here what we do is that we have two type of convolutions.",
                    "label": 0
                },
                {
                    "sent": "The first here.",
                    "label": 0
                },
                {
                    "sent": "They are like.",
                    "label": 0
                },
                {
                    "sent": "If I see well.",
                    "label": 0
                },
                {
                    "sent": "Should be aids.",
                    "label": 0
                },
                {
                    "sent": "I think mistake you see 7.",
                    "label": 0
                },
                {
                    "sent": "So I told them this was included I think.",
                    "label": 0
                },
                {
                    "sent": "So basically for all of them here you process two convolutions.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to say I will go into more complex features so you once again learn to convolution or very small size kernel three by three we can offer because we have stumbled.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is that we will we don't see nicely on the image of course here, but if here we are able to, for instance, they take lines here, will be may be able to detect corners or T. Or whatever.",
                    "label": 0
                },
                {
                    "sent": "So here you get 2 convolutions separated for each of them and then here.",
                    "label": 0
                },
                {
                    "sent": "We viewed as well convolutions.",
                    "label": 0
                },
                {
                    "sent": "That means this image is obtained by the convolution coming from this image and a combination coming from this image.",
                    "label": 0
                },
                {
                    "sent": "So here you are able to choose different channels of the beginning.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's once again aware finding higher, higher level features.",
                    "label": 0
                },
                {
                    "sent": "Once again subsampling.",
                    "label": 0
                },
                {
                    "sent": "Sorry it was here again subsampling.",
                    "label": 0
                },
                {
                    "sent": "So what's the idea here?",
                    "label": 0
                },
                {
                    "sent": "Once again, to adapt another another point which is very important is to get a reduced size vector, because this is our feature vector here, so this image is basically I don't remember exactly their size.",
                    "label": 0
                },
                {
                    "sent": "Let's say it's 8 by 9 or 10 by 10.",
                    "label": 0
                },
                {
                    "sent": "So and you get one year and receiving the information of this little image all the time here.",
                    "label": 0
                },
                {
                    "sent": "So it's like a vector of information.",
                    "label": 0
                },
                {
                    "sent": "OK, so they are separated so you get this layer.",
                    "label": 0
                },
                {
                    "sent": "This layer will make the decision according to the features.",
                    "label": 0
                },
                {
                    "sent": "So at the end you have one euro which receive all the information and votes negative positive.",
                    "label": 0
                },
                {
                    "sent": "So actually.",
                    "label": 0
                },
                {
                    "sent": "We get lots of connection if we see it as a neural network.",
                    "label": 0
                },
                {
                    "sent": "If you don't consider the notion of convolution and you think about neural network, here you can consider that everybody is connected, but in reality we talk about convolution.",
                    "label": 0
                },
                {
                    "sent": "That means the weight are shared is like you replicate part of the network.",
                    "label": 1
                },
                {
                    "sent": "So in the system there are like 951 trainable coefficients.",
                    "label": 0
                },
                {
                    "sent": "Which all the different values of the kernels biases as well, charge it always function.",
                    "label": 0
                },
                {
                    "sent": "OK, so they are the parameters you we have to find to define the full system.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is learned by quite modified back propagation is not started back for vacation for lots of reasons with shared weights.",
                    "label": 0
                },
                {
                    "sent": "And as well, because the different layers they don't have the same speed in converging.",
                    "label": 0
                },
                {
                    "sent": "So there are some some trick here.",
                    "label": 0
                },
                {
                    "sent": "Actually, going information computation you can quite solve any.",
                    "label": 0
                },
                {
                    "sent": "But basically there are different learning rates at the different layers.",
                    "label": 0
                },
                {
                    "sent": "Technical point of view.",
                    "label": 0
                },
                {
                    "sent": "So then.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have to feed with example.",
                    "label": 0
                },
                {
                    "sent": "When I first heard about the challenge, I thought our method will not do because they are very little number of other examples and it's much better to have a generative model then discriminative model I believe.",
                    "label": 0
                },
                {
                    "sent": "But we said, OK, let's try it.",
                    "label": 0
                },
                {
                    "sent": "So we took the 217 examples.",
                    "label": 0
                },
                {
                    "sent": "So there are some of it here and we set something up anyway for us, so let's generate a couple of artificial ones.",
                    "label": 0
                },
                {
                    "sent": "There easily by performing a bit of translation rotation noise.",
                    "label": 0
                },
                {
                    "sent": "Smoothing it's not obvious here.",
                    "label": 0
                },
                {
                    "sent": "We don't see very well, but yeah.",
                    "label": 0
                },
                {
                    "sent": "Lots of.",
                    "label": 0
                },
                {
                    "sent": "Little transformation, just to give the system more data to do it.",
                    "label": 0
                },
                {
                    "sent": "So there are finally something like 3900 examples posted.",
                    "label": 0
                },
                {
                    "sent": "Example she's quite.",
                    "label": 0
                },
                {
                    "sent": "Small number in faces.",
                    "label": 0
                },
                {
                    "sent": "For instance, we got more than 26,000 for system.",
                    "label": 0
                },
                {
                    "sent": "Then the problem is how to define.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The non motor example the negative examples.",
                    "label": 0
                },
                {
                    "sent": "So we follow kind of bootstrapping procedure.",
                    "label": 0
                },
                {
                    "sent": "That means we start to train the system.",
                    "label": 0
                },
                {
                    "sent": "I will not go into details here, but the idea is that you train the system first to drop randomly some examples.",
                    "label": 0
                },
                {
                    "sent": "Actually it's not that random, we find it is quite nice to crop examples which are quite close to the motorbikes, like your borders.",
                    "label": 0
                },
                {
                    "sent": "To give to the system a notion of precision detection then.",
                    "label": 0
                },
                {
                    "sent": "So we get this examples.",
                    "label": 0
                },
                {
                    "sent": "And then we just train about the system and we run it in a very.",
                    "label": 0
                },
                {
                    "sent": "Quite a certain number of scenery images.",
                    "label": 0
                },
                {
                    "sent": "Basically textual images from coral etc which can give lots of.",
                    "label": 0
                },
                {
                    "sent": "False positive basically.",
                    "label": 0
                },
                {
                    "sent": "So we get the negative examples with the Aroseva network and we feed the system.",
                    "label": 0
                },
                {
                    "sent": "Actually we have we have a simple way of not taking all of them we.",
                    "label": 0
                },
                {
                    "sent": "Put the free cell then, then we reduce that mean.",
                    "label": 0
                },
                {
                    "sent": "First we take.",
                    "label": 0
                },
                {
                    "sent": "Directly, but negative examples, and then we consider taking the strong negative examples and then we reduce so that we stay close to the borders of the system.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is just the process.",
                    "label": 0
                },
                {
                    "sent": "Of grabbing this famous false alarms with negative examples, and we say that through the training, the positive this the average value for positive stay high.",
                    "label": 1
                },
                {
                    "sent": "And through the training, what is grab that for Salam which reduces which is expectable we want when we send try learns he will answer.",
                    "label": 0
                },
                {
                    "sent": "Lesson lesson on bad examples.",
                    "label": 0
                },
                {
                    "sent": "So finally we grab quite a lot of false examples.",
                    "label": 0
                },
                {
                    "sent": "Sylvan",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically what I should be for so?",
                    "label": 0
                },
                {
                    "sent": "And this seems to have more, more to say here we process, but the idea is that here basically.",
                    "label": 0
                },
                {
                    "sent": "We don't have an example here, but every image when we process with the network, it's a sliding window.",
                    "label": 0
                },
                {
                    "sent": "But because of the fact that we have convolutions, if you take the window and you move one pixel.",
                    "label": 0
                },
                {
                    "sent": "Most of the computation is in common.",
                    "label": 0
                },
                {
                    "sent": "Between these two position and with that kind of system we are able to take into to take advantage of it.",
                    "label": 0
                },
                {
                    "sent": "Basically because we don't have to normalize in the window like deafening Easter embolization or whatever.",
                    "label": 0
                },
                {
                    "sent": "So when we move as we have small convolution kernels.",
                    "label": 0
                },
                {
                    "sent": "We just have to apply full convolution.",
                    "label": 0
                },
                {
                    "sent": "On the image for first convolution, a second or third, etc.",
                    "label": 0
                },
                {
                    "sent": "So it's a pipeline of processing, so you basically you do for convolution.",
                    "label": 0
                },
                {
                    "sent": "For subsampling, cross convolutions, subsampling results.",
                    "label": 0
                },
                {
                    "sent": "So this is done done in a pipeline.",
                    "label": 0
                },
                {
                    "sent": "That's why it's like real time at the end.",
                    "label": 0
                },
                {
                    "sent": "So I give an example here for typical size of images, 6 frames per second for that kind of images.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the results were somewhere like.",
                    "label": 0
                },
                {
                    "sent": "I don't see what I think here.",
                    "label": 0
                },
                {
                    "sent": "OK, that's been presented anyway, so we're quite surprised when we send.",
                    "label": 0
                },
                {
                    "sent": "The reason we say OK will be very far away.",
                    "label": 0
                },
                {
                    "sent": "And we are quite surprised to see that.",
                    "label": 0
                },
                {
                    "sent": "It was for motorbikes at least it was.",
                    "label": 0
                },
                {
                    "sent": "Not very far from from the best results.",
                    "label": 0
                },
                {
                    "sent": "For the first 2.",
                    "label": 0
                },
                {
                    "sent": "We are disappointed.",
                    "label": 0
                },
                {
                    "sent": "We thought we could generalize a bit better, but what we think is that the the number of examples, the little number of examples we're using did not show enough poses, different poses, and I think when you go to test through, the generalization is more much more difficult.",
                    "label": 0
                },
                {
                    "sent": "So it's what we think here.",
                    "label": 0
                },
                {
                    "sent": "Forecast as I said.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Disappointed.",
                    "label": 0
                },
                {
                    "sent": "Because first we thought that car will be more more easily detectable than motorbikes because there are no no occlusion etc or less occlusions.",
                    "label": 0
                },
                {
                    "sent": "But what we realized that because of the different poses of the car, we did not have lots of examples to follow.",
                    "label": 0
                },
                {
                    "sent": "Anyone network.",
                    "label": 0
                },
                {
                    "sent": "And because of this fixed size window.",
                    "label": 0
                },
                {
                    "sent": "But we use we have to to have a rush or common ratio.",
                    "label": 0
                },
                {
                    "sent": "It was difficult, so we really believe that we had to use at least two or three networks and choose them, which is not very costly, but we have to learn from different points of view in bad case.",
                    "label": 0
                },
                {
                    "sent": "Because from side win from side view to review, for instance, the aspect ratio of the other window is very different and this method cannot cannot fit with us 'cause we need to fix window.",
                    "label": 0
                },
                {
                    "sent": "So it is what we believe could be one of the reasons we have the.",
                    "label": 0
                },
                {
                    "sent": "Quite average results here.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some results.",
                    "label": 0
                },
                {
                    "sent": "Just to see a bit.",
                    "label": 0
                },
                {
                    "sent": "Algorithm in terms of localization.",
                    "label": 0
                },
                {
                    "sent": "So it's quite.",
                    "label": 0
                },
                {
                    "sent": "Just to give an idea what to localize the system.",
                    "label": 0
                },
                {
                    "sent": "So we have a nice voice around here.",
                    "label": 0
                },
                {
                    "sent": "Difficult to explain.",
                    "label": 0
                },
                {
                    "sent": "The trees is something they're interesting most of the time.",
                    "label": 0
                },
                {
                    "sent": "So in four calls.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example, is most of them are side use.",
                    "label": 0
                },
                {
                    "sent": "So this is typical that kind of system is quite robust to occlusion, specially besides being pro shown in case of faces.",
                    "label": 0
                },
                {
                    "sent": "And yes of course we see it very easily here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think it's by chance we get it in the shoulder.",
                    "label": 0
                },
                {
                    "sent": "So as you can see, most of them aside, use.",
                    "label": 0
                },
                {
                    "sent": "I think we did very bad on the other views and it's a pity we did not use this little weird information database.",
                    "label": 0
                },
                {
                    "sent": "I think we did not use it, at least.",
                    "label": 0
                },
                {
                    "sent": "To see.",
                    "label": 0
                },
                {
                    "sent": "So just to.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rude.",
                    "label": 0
                },
                {
                    "sent": "OK, but through it as well, the example is, well, not.",
                    "label": 0
                },
                {
                    "sent": "For training that always are the best one.",
                    "label": 0
                },
                {
                    "sent": "OK, what I said we fix racial problem.",
                    "label": 0
                },
                {
                    "sent": "And OK, we have advantages outside before these.",
                    "label": 0
                },
                {
                    "sent": "That's what I think.",
                    "label": 0
                },
                {
                    "sent": "I hope I was clear enough and 'cause I don't get very clear.",
                    "label": 0
                },
                {
                    "sent": "Same question.",
                    "label": 0
                },
                {
                    "sent": "This is an occasion of convolutions of something they proved to be very resistant, isolating different faces.",
                    "label": 0
                },
                {
                    "sent": "For instance, even if I was running from bases which are not specially even part of it like that.",
                    "label": 0
                },
                {
                    "sent": "So what is the reason?",
                    "label": 0
                },
                {
                    "sent": "The system tries to learn the first layers, some typical, very low level features, so of course systems to find enough low level features landscape, but it doesn't.",
                    "label": 0
                },
                {
                    "sent": "I think it's great for this even if you lost quite a part of it.",
                    "label": 0
                },
                {
                    "sent": "This is quite typical in what, when using that kind of system.",
                    "label": 0
                },
                {
                    "sent": "And I wanted to add maybe something about this because we talked about that before the the idea of the influence of geometry, which was very interesting.",
                    "label": 0
                },
                {
                    "sent": "In that kind of system, obviously there there is the notion of Georgia as we look at computation and it's localized convolution.",
                    "label": 0
                },
                {
                    "sent": "So finally leaders have something.",
                    "label": 0
                },
                {
                    "sent": "Somehow you aggregate that you use the national.",
                    "label": 0
                },
                {
                    "sent": "I don't really understand it.",
                    "label": 0
                },
                {
                    "sent": "And that meant a Joyce people needed, I believe, somehow this solution could be.",
                    "label": 0
                },
                {
                    "sent": "Intermediate wasting that somehow you learn the geometry without to be very precise.",
                    "label": 0
                },
                {
                    "sent": "You learn it from this subsampling operation.",
                    "label": 0
                },
                {
                    "sent": "It's it's.",
                    "label": 0
                },
                {
                    "sent": "It's a middle way between not and in geometry or dinner geometry, which is much detailing much too precise and will not be rubbish bin.",
                    "label": 0
                },
                {
                    "sent": "So maybe.",
                    "label": 0
                },
                {
                    "sent": "Something like that.",
                    "label": 0
                },
                {
                    "sent": "In some of the datasets that were annotations like color, side and color ears on this Lee will be quoting myself helping.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, yeah, it's it's a beauty, actually quite fast and looking at ice, which was possible.",
                    "label": 0
                },
                {
                    "sent": "But then we did not really change.",
                    "label": 0
                },
                {
                    "sent": "That could have been very interesting, but we think we discussed them.",
                    "label": 0
                },
                {
                    "sent": "We'd like to go and change.",
                    "label": 0
                },
                {
                    "sent": "And we are working right now in a kind of kaskada different system and not in the field of view about that boosts or by further join system for BAE Systems and.",
                    "label": 0
                },
                {
                    "sent": "Trying to build systems one the first layer because Papa systems, for instance, we learn the typical examples and then another one will take care of the different poses.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to do kind of unsupervised clustering supervised.",
                    "label": 0
                },
                {
                    "sent": "I'm not friends of that nature.",
                    "label": 0
                },
                {
                    "sent": "Fantastic discussion.",
                    "label": 0
                }
            ]
        }
    }
}