{
    "id": "2kra634bj6j3idz3i7imk6jbbxjeqm6o",
    "title": "Building apriori knowledge into conclusions drawn from simulations",
    "info": {
        "author": [
            "Persi Diaconis, Stanford University"
        ],
        "published": "Sept. 1, 2016",
        "recorded": "June 2016",
        "category": [
            "Top->Mathematics->Statistics"
        ]
    },
    "url": "http://videolectures.net/isba2016_diaconis_apriori_knowledge/",
    "segmentation": [
        [
            "Real honor to be able to speak in in this venue.",
            "To this to this audience.",
            "And on this occasion in particular, really honored that Fulvia began and and you got to hear her.",
            "Her thoughts.",
            "I remember when I just was starting in Graduate School and had no real idea of what statistics was about.",
            "Really.",
            "The first few weeks it was a graduate student at Harvard and Harvard, then had very strong group and exploratory data analysis, graphical methods, missing data, that sort of thing.",
            "And also there was.",
            "Art Dempster, who was very Bayesian and beyond upper and lower probabilities, and I didn't know anything, and I just really was trying to figure out what is statistics about what is what are we doing?",
            "What am I supposed to do?",
            "An didn't really know when I went to the Harvard bookstore and I was looking at the books the way we do and I saw this book, which I'm sorry that's the best we could get.",
            "But this is really a true story.",
            "It's definite ease.",
            "Probability induction and statistics.",
            "And I was just standing there and kind of opened it up and started to read and I couldn't put it down and I was poor as a churchmouse and it was, you know $80.00 or something and I bought it and I started to read it and I'm still reading it.",
            "And my my my it's I really recommend it.",
            "It's perhaps the most accessible introduction to his work and writing my first."
        ],
        [
            "Paper now I tried my first paper on my own was about definite ease, work, finite forms of different entities, theorem on exchange ability, and the last talk I gave, which was last Friday was."
        ],
        [
            "Work with Sergio Baca, Lotto Ann and Susan Homes.",
            "Different cities priors using Markov chain Monte Carlo computations.",
            "So from the beginning to the end.",
            "I have spent a career trying to understand in my own language what Divinity was talking about, and I'm not going to try to do that that today I I sent myself an impossible task today.",
            "The thing is that statistics has changed since different Eddie worked.",
            "It's not that the ideas aren't central and valuable, but but something's changed and what I want to try to do is at least for one second or for 15 minutes to try to think about what would definiti.",
            "What might he do if he were doing statistics today?",
            "OK, so.",
            "Want to look forward and of course the thing that's changed more than anything is is the computer just just normous datasets, but our ability to to actually do Bayesian analysis in in real time.",
            "In particular, Monte Carlo simulation is just just every place, and so I want to think about that and what might definitely think about.",
            "Think about that.",
            "And so first, here's a little paradox.",
            "Don't know if that'll work so thing."
        ],
        [
            "King about Monte Carlo data and the paradox of the problem is this.",
            "Why do we Bayesians and me too?",
            "Why do we Bayesians when we analyze the output of our Monte Carlo trials use frequentist methods?",
            "I never see anybody do anything other than X bar plus or minus 2 standard deviations.",
            "I mean you know people save different things, but if you look at what we actually do, what's been in every now it's not.",
            "It's not only the Bayesians problem, you know.",
            "Statisticians don't use modern statistical methods, they use Explorer plus or minus.",
            "Two SD if they do plus or minus two SD an So what can we think about now?",
            "Why is that now of course.",
            "The first answers are for many cases, maybe most cases.",
            "The extra thinking.",
            "First of all, it's difficult.",
            "You know you've got to slow down and think about every minor Carlo.",
            "Come on, it's costly, and then it's not worth it.",
            "The basic basic findings is that the data swamps the prior, and if you've got a lot of data the prior won't matter, and so why bother to specify a prior and that's all true and valid, and what I want to talk to you today about are some problems where it seems to be worthwhile where it's not so.",
            "It's not.",
            "The data doesn't swamped the prior and and maybe there's something more to be found by by incorporating what we know so."
        ],
        [
            "Here we go.",
            "So this is an example and please try to follow this because this theme runs throughout and it's a simple example to follow.",
            "When I first came to Stanford 1974, Don Kanute, the world's greatest computer scientist, I call 'em and wrote me a note saying hey, I have a statistical problem for you.",
            "OK, and he was trying to count how many pairs there are in a 10 by 10 grid.",
            "That's a 10 by 10 grid.",
            "This this one here, which start at 00 and wind up at 10:10 and don't intersect.",
            "OK, so here's an example of such a path.",
            "Here's a path which is in 100 by 100 grid, but take the 10 by 10 case.",
            "He wanted to know how many such pads are there.",
            "Well post question and the the the number of paths these saws self avoiding walks the growth rate of those are fundamental constants in physics and chemistry and.",
            "In biology and it's not a frivolous question and he had an algorithm which let me explain the algorithm."
        ],
        [
            "The idea is to grow one at random, and so let's suppose you start here at 00, so half the time you go up and half the time you go to the right.",
            "Say you go up OK and then here I could go up or to the right.",
            "I can't go back, so maybe I go here and now I could go up or to the right or down.",
            "Suppose I go down now I'm not stupid.",
            "I don't go back, you know I have no choice.",
            "I have to go here now.",
            "I could go here right here.",
            "Suppose I go here and now I have.",
            "I could go here or here.",
            "So you understand what I mean.",
            "You could grow one and you make the choices at random uniformly from the possible choices you can make.",
            "It's easy once you might get stuck, OK, you might get stuck.",
            "It turns out it's easy to check and not get stuck, but suppose you're not so smart.",
            "You just running the algorithm.",
            "If you're successful when you make a path that goes from 00 to, here's to 4.",
            "Four sorry, you could calculate very easily what's the chance of the of the path that you took.",
            "That is, I'm going to call the pans gamma and the chance of gamma.",
            "Well, it's 1/2 * 1/2 * 1/3 * 1 * 1/2, and so forth.",
            "You could just multiply the probabilities along the path.",
            "Yeah, that's OK with everybody, I hope.",
            "Thank you.",
            "Now let's make a statistic which is tiava trial is 0.",
            "If you get stuck and one over the probability of the path if you're OK.",
            "So that's a perfectly computable statistic.",
            "What's its mean value?",
            "Well, it's mean value.",
            "The expected value of this statistic.",
            "It's of course 0.",
            "If you get stuck, so it's only the sum over all possible paths, 'cause otherwise it's zero of the statistic times the probability.",
            "That you've chosen that path.",
            "Now the statistic is 1 / P of gamma and the P of gammas cancel, and you're left with the number of paths.",
            "So this is an example of classical idea of what's called sequential importance sampling.",
            "But if you haven't seen it before, don't remember it.",
            "It's sort of magical, it's an unbiased estimate of the number of paths and new.",
            "Ran it.",
            "You know, 10 billion times, 10 billion times, OK, really did run at 10 billion times.",
            "And he found he got estimates that his estimate for the number of paths was one point 6 plus or minus zero point 3 * 10 to the 24th.",
            "The average path length was about around 92.",
            "Now that's it's a 10 by 10 grid.",
            "So that means typical paths really almost cover everything.",
            "Surprising little bit.",
            "He found, you know 81% of them went through the middle vertex and.",
            "His problem was this.",
            "He said I ran this thing 10 billion times and you know, suppose I'm just calculating calculating the this statistic T and you, you know you run it.",
            "It's you know 10 to the 17th, 10 to the 19th, whatever it is.",
            "But then one value you know this these this is a product of a lot of little numbers.",
            "So one over it can be very big.",
            "One value overwhelms everything that came before.",
            "Typical problem that we have in important sampling and he he thought.",
            "You know, did these numbers mean anything?",
            "He understood that that was a problem, and it's a problem for us today when we use any version of important sampling.",
            "And that's a very common method.",
            "OK, so."
        ],
        [
            "There's the question do these numbers mean anything?",
            "This huge variability, as usual for important sampling?",
            "It seemed as if a million samples were determined by one or two numbers.",
            "Nowadays people do a funny thing.",
            "They calculate the.",
            "You know the.",
            "An estimate of the sample of the the effective sample size.",
            "Well, that's the standard deviation.",
            "If the mean doesn't mean anything, the stand deviation means much, much less and.",
            "OK is and then is the question.",
            "Is there more information that we have about the problem or that's in the data that we could use to help with this problem?",
            "And just to explain to you that there's something to understand here about 10 years after canoe he published this analysis.",
            "His work in science an about 10 years later, some physicists got annoyed and said 10 by 10 will blast it out and they just blasted it out and and these are the numbers.",
            "Can use estimate of the number of paths was 1.6 * 10 to the 24th.",
            "They know the exact number.",
            "That's not so helpful, but this is more helpful.",
            "It's you know, 1.5687 * 10 to the 24th.",
            "It seems to work pretty well, and his other numbers were spot on too, so there's something to understand.",
            "OK, it's not just crazy, it seems to work in an and do we have anything to say about it?"
        ],
        [
            "OK, so if you.",
            "Don't mind let me try to think out loud an I'm very eager to have feedback about this.",
            "What do we know?",
            "I mean, 'cause do we really know you know anything?",
            "So the first step is?",
            "To give it a name, so let's let Theta in be the number of self avoiding walks from 00 to NN and that can shock some people because it's a perfectly determined number.",
            "You know it's just some number that exists in nature, and if you haven't thought about that before you know.",
            "Think about the 37th digit of \u03c0.",
            "That is, for most of us you don't know what the 37th digit of pie is.",
            "For me, you know it's equally likely to be anything from zero to 9, and I'm perfectly happy to to make pet for small amounts on it.",
            "Now my math colleagues were always trying to figure out what the statisticians do, and so I said well, think about the 37th digit of pie and one of them said.",
            "The first guy who computed 796 digit of \u03c0.",
            "The first mistake he made was on the 37th digit.",
            "I said oh and the second guy said.",
            "Um?",
            "The 37th digit of \u03c0 past the decimal place is 0, so of course different people have different knowledge bases and you know different priors of course, and now you know what the 30 you have a reasonable mass at zero for what the 37th digit of \u03c0 is, but of course, as Bayesians were allowed to put priors on things that we don't know, and the number of paths in a in a 10 by 10 grid is really something that we don't.",
            "That we don't know.",
            "So we know something about it.",
            "For example, this walk each time that you take a step you can take at most three directions.",
            "So the number of the total number of pants can be at most 3 to the N squared.",
            "It can't be anymore than that.",
            "Now if you wanted to try to think about a lower bound, get busy, it's open.",
            "We don't know, there's nobody knows the aesthetics of these numbers, but.",
            "I buy very little thinking, could show that it was, you know.",
            "It grows like a constant to be N squared, so I know something about.",
            "It's about the log of this number roughly.",
            "And of course you know if I ran my simulations an it was outside those intervals.",
            "Somethings wrong with the computer code or something else, so I know a little bit.",
            "We also have some data.",
            "The data is the data from canuse trials, right?",
            "I can run this algorithm.",
            "It's an unbiased estimate of the my parameter, so it's data.",
            "Let's look at it as data for a second and try to think about it.",
            "So remember my statistic and now I'm going to use the fact that I know how to run this walk and not get stuck, so I never get stuck so well.",
            "This statistic T of gamma.",
            "It was the product over edges in the path of one over the probability of the edge.",
            "Yeah, and let me just put that up into the exponent the way we do and let me make it E. To the minus the sum over edges in the path.",
            "Of the log, which I'm calling in sub gamma of E and let me call that E to the minus H of gamma.",
            "OK, where in sub gamma of Y is 0 if if the probability is 1, log 2 or log three, it's so it's you know.",
            "So this H of gamma is the sum of a lot of little things, right?",
            "So maybe it's normal.",
            "You know, I mean, it's not such a stretch.",
            "You know that's the sum of their kind of random, right?",
            "You know, it's sort of going around.",
            "Maybe it's normal and the length of a typical path is around N squared, and so it's not such a crazy thing to say.",
            "Well, maybe this energy is roughly normal and it has, you know.",
            "Mean of order N squared and some standard deviation, and then I could put a prior as I will in the second on A&B and using the data I can compute the posterior and try to use this as an estimate of the number of paths.",
            "Now that may sound crazy to you, but let's will carry it forward.",
            "It's just what I'm doing is thinking out loud and you shouldn't do that.",
            "It can be embarrassing, but I'm going to continue for a little while.",
            "This route that I've just sketched suggests looking at more of the data than just this statistic.",
            "T of gamma, for example, if I want to say, are these things approximately normal?",
            "I could take my 10 billion sample pass, compute H of gamma and look at them, look at a histogram of them, you know, just see if they're normal.",
            "If I think that the central limit theorem is holding for this, I could look at each path and treated as a time series and kind of look to see.",
            "If this in a flex, you know enough randomness that the normality makes makes some sense.",
            "So these first thoughts are saying when you run a Monte Carlo trial is often an awful lot of information that we don't make use of.",
            "We can start to try to think about it, and I'm encouraging us to do that."
        ],
        [
            "Now here's.",
            "Some news, Alas.",
            "Minus log P of gamma is not roughly normal.",
            "This is a histogram from canoe stay to an you know whatever this Mrs.",
            "It's not normal.",
            "I mean you know we've all looked at a lot of histograms that that's not a that's not a normal that's not a histogram.",
            "However, looking at the data and thinking about it and some math that's coming later, it does seem to be that given the length of a path, if I condition on the length of the path, then this statistic minus log P of gamma is roughly normal, and it seems to be quite normal.",
            "Well, let me show you what the lengths of the pads are.",
            "This is from this is from the data.",
            "This is given the given the given the lengths of given the the length of a path can be anything from 20 to about 100 or so here.",
            "OK 120 maybe and.",
            "Can really it can really wind around.",
            "This is the expected value of on the left.",
            "The expected value of the energy minus log P given the length, and it's it's monotone is make some sense.",
            "And this is the standard deviation of the of the energy given the length of the path, and that is like that.",
            "OK, and now I could model these as splines and put.",
            "Parameters on the splines and then go to town, and I'm going to.",
            "I'm going to do something like that in a second, but the point again is there is information in the data and normally we're not led to use it in this kind of thinking about it in a Bayesian way has led to me to find interesting interesting structure."
        ],
        [
            "Let's go forward in this way.",
            "Here's here's a little tiny calculation.",
            "Here's what I'm going to do.",
            "We started by saying the number of paths is just this sum the sum of 1 over the number of fans, and that's the sum over the number of pans of P of gamma over P of gamma, and that's the expected value of 1 / P of gamma with respect to this measure on paths.",
            "Let's write that using double conditioning.",
            "I try to learn how to use this thing.",
            "That's the expected value of 1 / P of gamma given the length, and so I've just written that out.",
            "That's the expected value that's the sum over the different possible lengths 2200 of P of gamma times the expected value of 1 / P of gamma given the length.",
            "So here's my here's the trick.",
            "I'm going to use.",
            "These are just, you know, I have a. I have a billion data points and I have, you know the lengths, take values from zero to 100 so you can do anything you like, but just using the frequencies is all you're going to get.",
            "You know.",
            "So use estimate.",
            "You know this the the probability that a trial produces a path of length P from the data just directly or or be a Bayesian with that it won't won't help or hinder you.",
            "And then I'm going to estimate this conditional expected value of 1 / P of gamma.",
            "From from, from the lognormal assumption and using Bayes theorem and I'll, I'll carry that out and come back and do it, so that's a different way of using the data and my findings to get an estimate of the of the number of paths.",
            "Their scheme.",
            "Member where I started you know which is?",
            "You know, putting putting a prior over something strange and works pretty well and examples are coming.",
            "One point that I want to make now is I did have to think that as I had to Snoop around in the data and identify a parameter which in some sense was a sufficient statistic, namely the length of the path that is at the moment you know I'm running these trials.",
            "I've got all kinds of things I could look at.",
            "I in looking at them, I looked at the, you know, I found that the link conditioning on the length of a path seemed to seem to Get Me Out of trouble and so that that was something that took some some thinking or some insider.",
            "Something like doing science even right?",
            "Here's a second idea in this example, and many more that are coming.",
            "Only a few values of L mattered these these P lambdas, you know.",
            "Dropped off pretty rapidly and this expected value was only big for a few values of of L and so in instead of having to think I can.",
            "Try to take this tack and so this is a this is the theoretical contribution here, which is the following try.",
            "This idea, let's let's model this energy minus P of gamma as a mixture of lognormal distributions.",
            "OK, an you have to pick K, but that's a familiar problem and I'm going to take A to B6 and it works great and this."
        ],
        [
            "This picture is a plot of the as a function of the length of the estimate of the log of account and what you can see is it's very flat there in the middle and it drops off and this will only a few values of of of.",
            "Of the length mattered, and so I don't have to identify them the length let me just model my minus log P of gamma as as a mixture of normals.",
            "Now here's let me say a cautionary thing.",
            "The mathematician in me is striking up.",
            "It's a fact of nature.",
            "I have math fact of mathematics that any measure on the line, any problem, any probability density on the line can be very well approximated as a finite mixture of log normals.",
            "OK, so anything can be, so I'm modeling anything and that's because if you you know, let the mean and let the variance be, you know, Peaky you can.",
            "You can make a point mass as a.",
            "Normal and then and so the log of P is being is being the log of P is being modeled as a mixture of normals, but anything can be modeled as a mixture of normals and so you have to be worried about that anyway, let's not just go forward, so I now have say a mixture of K normals and I can put a prior on the mixing.",
            "Now you have to be careful and I was put a prior on the mixing weights data I.",
            "Put a prior on the means and the variance is coolest vector Ada and I should have said this.",
            "All of this work is joint work with Mark Corum, wonderfully innovative fellow at Stanford, Anne Anne we we we use K = 6 I took Theta the initial prior on the 100 and on the on the six waits to be uniform on the six simplex and I.",
            "Put you know, independent conjugate priors in the standard way on mu and Sigma squared, and as I said before, if I wanted to be more careful, I could model the means and the variances of splines and I could do that.",
            "I haven't.",
            "I haven't carried it out.",
            "OK, the point of this slide is 'cause there are many other sequential importance sampling problems coming.",
            "You don't have to be clever and identify.",
            "L of gamma you can try this for any sequential importance sampling, so let me show you what what happened."
        ],
        [
            "For canoes problem, so with all of this story going I now said let me start again.",
            "I took a fresh sample not of 10 to the 913.",
            "Whatever it was of 1000 paths.",
            "There they are.",
            "I I had these pants from my normality assumption.",
            "If I accept my normality assumption I can compute the posterior for this parameter ADA.",
            "Just by straightforward arguments, and now I can sample Ada from the posterior distribution.",
            "Easy to do and I can compute analytically my expected value of the account or any other statistic, given that it's that mixture of log normals.",
            "As sorry, I'm not doing so well at this, but I can try again as.",
            "You know G. Of Ada is the ADA, mixture of normals, and then I have to calculate this exponential integral and this is a histogram of.",
            "So sample data from the posterior calculate this estimate of account.",
            "You know do that some number of times.",
            "This is a histogram of those estimates of accounts, and from that you can get a 95% highest posterior interval for the count and that's.",
            "You know that that that came out to be, you know, between you know, 7 * 10 to the 23rd and 1 * 10 to the 27th.",
            "Ann Ann.",
            "Here the quote unquote right answer is, you know around 1.6 * 10 to the 24th.",
            "A point is that this Bayesian procedure that I just went through an I'm not telling you about a lot of trials that we did to to kind of see if it's actually true seems to be true.",
            "Got me down from needing, you know billions of samples of size billions to samples of size 1000.",
            "Well, that's good, right?",
            "That's that's an improvement.",
            "OK, so that's an example and let me.",
            "There are."
        ],
        [
            "Many many similar problems.",
            "Certainly basic important sampling.",
            "One of the mainstays of scientific computing you want to calculate an integral you can sample, perhaps independently, perhaps from a Markov chain from a different measure new, you estimate the integral by using the weighted values of the samples, sequential importance, sampling case.",
            "It's new to you is different in that I'm just building up this measure new.",
            "Sequentially and so my weights 1 / P or products, and so this lognormal stuff makes some sense.",
            "Here's an example, one of many that that I've been involved with.",
            "Counting tables, graphs, etc with given row sums.",
            "This is data that sometimes called Darwin's data.",
            "These are the finches on the Galapogos Island.",
            "These are the 18 islands that there were.",
            "There's a zero or one in in the IJ place if that Finch lives on that island, and a well ecologist calculate all kinds of statistics to see.",
            "Is this data different than data which was chosen at random with the rows in column sums fixed?",
            "It's a reasonable question how to calibrate their analysis.",
            "It's a first question.",
            "How many tables are there with the given row and column sums?",
            "With Ugo Chin and Susan Holmes Engine Lou we built a sequential importance sampling algorithm to do that and I just want to say a sentence about it because it's just very similar to what I just did.",
            "So suppose there are 1234 seemed to be 4 ones in the first column, so you might think OK, let me just build up a table sequentially at random, put 4 ones in the first column and then subtract 1 from each of those four row sums and then put however many ones have to go in the second column.",
            "And just keep going and.",
            "And that would get you a table or you would get stuck and now.",
            "There's two big steps.",
            "The first step is why not?",
            "If the row sums are big, why not make it more likely to put ones in the column in the rows where the row sums are big?",
            "It's easy to do that as long as you can compute what the probability is that you're putting rose in one at a time, and the second thing is, you can use math.",
            "The Gale riser theorem gives you a necessary and sufficient condition on a set of row sums in columns seems to be the row and column sums of a binary table.",
            "You can use math to say.",
            "One of the possible next moves you could make and never get stuck, and from that you can estimate the number of tables and where exactly in the same situation.",
            "It's a product of a lot of little numbers and an and seems as if lognormal.",
            "So good way to go."
        ],
        [
            "This is a huge set of examples.",
            "Anna is the motivation that canoe had for asking me his question.",
            "So in computer science there's a whole world of what are called backtracking algorithms and I'll give you a general reference for this.",
            "But if you just type it in on the Internet, you'll find it.",
            "So the issue is the problem is to find X one up to XN.",
            "Some parameters such that a certain condition PN of X1 up to XN holds.",
            "Where the excise are, you know, say, in integers, sets of integers.",
            "There in some sets, SI in backtracking algorithms, what you're giving is some partial constraints.",
            "That is your given PL of X1 up to Excel, so that if X1 up to XN holds then X one up to XL holds.",
            "The elf condition holds and so you can check along the way and if you can't fulfill.",
            "The If the L thing doesn't work then you don't have to try any of the extensions.",
            "OK, so this information is often collected into a backtracking tree.",
            "The most famous example is the end Queens problems.",
            "How many ways can you put in Queens down on an end by end board in such a way that they are non attacking their Excel?",
            "Is the column of the Queen.",
            "The Queens have to go all in different rows.",
            "An X one is what column is Queen one and X2 is what column in Queen Two is in there between one and in the condition PN of X1 up to XN is well.",
            "They shouldn't be.",
            "You know they shouldn't be in the same column and they should.",
            "You know they shouldn't be on the same diagonal and those same conditions hold for everything.",
            "This is the backtracking tree, and so you could put the first Queen in any of four places, 123 or 4.",
            "Columns this is in a four by four case.",
            "I should have said and then you can continue and you get stuck here and then you backtrack.",
            "I won't try to explain backtracking too carefully.",
            "There are two solutions here.",
            "Two ways of putting 4 Queens into a four by four board here."
        ],
        [
            "The here is the.",
            "Real chess board.",
            "The 8 by 8 there are 92 solutions and.",
            "Backtracking, you know you start to go and then you stop and you don't have to check anymore on that branch allows.",
            "I don't want to do that.",
            "Well, I can just go forward.",
            "Backtracking allows you to scan this whole backtracking tree using 1% of the eight to the cases.",
            "What canoe was interested in doing so backtracking algorithms when you run them?",
            "Some of them run lightning fast and some of them just take weeks and you don't know if it's gonna be months or years and how to estimate the running time of a backtracking algorithm was canus problem issue and.",
            "He had the following scheme, which is just sequential importance sampling.",
            "But let's say what it is.",
            "So you start to build your build a path at random, but don't backtrack.",
            "Just start to go down the tree and an each time making one of the available choices uniformly.",
            "If you.",
            "If you.",
            "If you are at level I.",
            "If you have DI places to go, that's that's die for that path.",
            "And then exactly the calculation that I did essentially shows that that this statistic T you never get stuck, you just stop when you get to a leaf which is D1 plus D 1 * D, Two plus, etc.",
            "This has under this random sampling distribution exactly the number of vertices, and if you wanted to know something else.",
            "You could use use these as as important sampling weights.",
            "Here's an example in the 8 Queens problem.",
            "The first Queen you know went there.",
            "The second Queen went here and you know the Queens.",
            "They got some.",
            "They got some place along and then it was stuck.",
            "There was no place to go.",
            "And when you multiply the number of choices as you went down the tree, the estimated number of of of of of vertices.",
            "The total number of vertices in this graph was 2129, the second a second trial was 2689.",
            "The third trial was 1489, so these are partial estimates along the way and even from doing it a few times.",
            "These four numbers give you some reasonable idea of how many vertices are in this tree.",
            "Here, it turns out the right answer is 20,057, and.",
            "In this example, you can blast it out the minimum, the minimum statistic it says down here is 489 the average.",
            "This is an unbiased estimate is 2020 two 1057.",
            "The Max is 7500 and the standard deviation is of the same order as the mean and so you could estimate accurately.",
            "How many vertices there are in this tree using using backtracking and an OK, let me let me go on."
        ],
        [
            "The points are any sequential importance sampling scheme, and there are thousands of them fits into this tree.",
            "This backtracking tree picture my chest, my my sorry self new self avoiding paths problem.",
            "You know you're starting to build a path, you just, you know, make a tree out of the possible choices that you have so they all fit into that.",
            "Pick a path in the tree at random and add the log degrees along the way will give a mixture of normals with length as the mixing variable, so that's a theorem.",
            "OK, now I have to make some assumptions about what kind of pans and trees, but under reasonable mild conditions.",
            "In particular, for the 8 Queens problem or in Queens problem for.",
            "For Galton Watson trees.",
            "This heuristic that I came upon with Mark is in fact the theorem that is that that things are mixtures of lognormal's.",
            "If you wanted to read more about backtracking, and in particular see this method of sequential importance sampling used in very interesting real problems can use the art.",
            "So he asked me this question when I started at Stanford in 1974 and he just now was coming to write volume 4B.",
            "And if you look on his website introduction to backtracking the art of computer programming volume.",
            "For pre fascicle 5B it's 100 page.",
            "Book on backtracking and sequential importance sampling, and I did quite a lot of math about sequential importance sampling that I'm not telling you about, but in in a paper with Sheriff Chatterjee.",
            "The sample size required an important sampling and it's on the archive or on my my web page which analyzes canus algorithm.",
            "More detail, let me might well be that this."
        ],
        [
            "This is my my last slide so back to the big picture.",
            "There's a question and I don't know the answer to it, but.",
            "Collectively, we know more than I do.",
            "So what kinds of information are available in our Monte Carlo simulations?",
            "We often use pitifully little because that's all we have time for that, so we think we care about when I look at what I do or what my compatriots do when they analyze their Montecarlo, this whatever statistics they are interested in, and then they might put some test statistics in because the standard way of calibrating is to take a bunch of test statistics and see if they seem to settle down.",
            "So we often have a handful of functions that we monitor along the path, and so that's some some use that we make of the information that people do.",
            "Things like computing effective sample size.",
            "Occasionally you'll see somebody reusing their samples by bootstrapping an.",
            "That's about all.",
            "I mean that that that that that I see now there should be a big literature on this, and I only know of 1 paper, and I'm sure I'll learn many more.",
            "So thank you in advance.",
            "I know of 1 paper which has a very similar theme, but then when in quite different directions, so laggy Kong Peter Mccullar, Sha Li, Ming an then Nikolai and I don't know Mr Tanz, first name wrote a paper called a theory of statistical models for Monte Carlo integration and was in Bayesian, but I'm sure that's 'cause Peter McCullough would never have his name associated with anything Bayesian.",
            "But the ideas are somewhat similar.",
            "That is trying to model.",
            "Things, but then the problem that they focused on was different.",
            "This article is a discussion article in the in the RSS and there were many interesting comments in many of those commentators, some of whom are here in the audience, wrote papers as follow-up papers.",
            "So if you type this in this paper in and then you look on Google Scholar who cited it, you'll find the literature that this is not very much, but that's a way of finding it.",
            "This it's a starting, it's I'm not the only crazy one.",
            "If you want to put it that way.",
            "This story I've just told you is a special case of what I call Bayesian numerical analysis that is.",
            "You have an integral or a some you want to do, even if you have a complicated formula for it, you don't know what it is.",
            "So put a prior on.",
            "Get some data, compute posteriors and use Bayes methods to get improved estimates.",
            "I wrote a paper about that in a long time ago, in which I traced the history of it back to Ponca, Ray.",
            "Nowadays it's slightly fashionable under the name of uncertainty quantification, and Jim Berger gave a talk and he said, well, the engineers did it and you know 1960.",
            "Welp, on Kare did it in 1890 so you know OK and many many other people.",
            "Well before the engineering literature.",
            "Stephen Lauer.",
            "It's and did wonderful work on it in estimating what the force of gravity is in the 1960s, I'm going to say so.",
            "This paper also, if you look who cites it.",
            "It was completely unsighted and then all of a sudden it's blossom, and in fact there's a marvelous website whichiscalledprobabilisticnumerics.org and and you can find what literature I know about.",
            "So the the theme of this talk was.",
            "You know it would have been natural to call it, you know Bayesian thinking about Monte Carlo, but I don't think you know.",
            "I think that just thinking is a Bayesian activity, and I think the finetti encouraged us to use what information we have and try to combine that with what data we have in innovative ways.",
            "This is another little pedal in the in the flower.",
            "The reason I decided to give this talk is I think many, many people in this audience have noticed.",
            "Why don't I ever use Bayesian methods when I analyze my Montecarlo data.",
            "I'll be happy to hear you know examples, references, thoughts, the collective power of this group is is much more than any one of us.",
            "And thank you very much.",
            "Thank you."
        ],
        [
            "Well, first I'm very honored to start a discussion for this first DEFINITY lecture.",
            "The second thing is, this is the first time when I write my discussion about six months.",
            "Before the talk, because actually.",
            "He happens to have this nips workshop last December in in Montreal.",
            "Which was about probabilistic numerics and was starting.",
            "Point was Percy's 1988 paper.",
            "And so.",
            "I was invited not as a specialist, but also a skeptic an so my talk was actually a discussion of the pros and cons of probabilistic numerics.",
            "And so I decided to to depth those those slides.",
            "Because it's all fits very well.",
            "Process talk OK."
        ],
        [
            "And so I go through four full names, Larry CC and Percy.",
            "Which all ends by E. The first one is is Larry's constant and this is a problem that has bothered me for for quite awhile.",
            "So I mean if you have not read Larry's book and and this question is.",
            "Is exactly this problem of of having a constant, not just 37th digit of pie, but a constant that is entirely defined from the fact that we are dealing with a density, but we don't know him, and so could we analyze this problem from a vision perspective and so they."
        ],
        [
            "So Larry put it as a as an example is in his book where.",
            "I mean, you can come up with a frequentist solution for proximity in C from say, nonparametric estimator of F. So F had over G is an estimator of C, and if you take more data or more simulations, you end up with the proper approximation to see and so if you turn."
        ],
        [
            "2.",
            "Two abbasian resolution.",
            "So if naive Bayesian approaches to say, well, I put a prayer and see because I'm basean.",
            "And so if you service with this native prayer and see you end up nowhere because your data say your simulation.",
            "Doesn't transfer into information about C per say.",
            "I mean it's a simulation from F and so you have to go around the corner to come up with an estimation or see.",
            "But if you write as as a naive version.",
            "Which Larry pretends to be in in this.",
            "In this text you end up nowhere, OK?"
        ],
        [
            "And so those outcomes I made six months ago that maybe I evolve a little bit about it, but.",
            "The first interpretation is that well.",
            "It's not a statistical problem because there is no likelihood per say if you write it that way OK, and so it is not.",
            "There is no data from your simulation about C, so if you get take it at face value, you are not analyzing something that is that is statistical and so you have to go somewhere farther to to come up with a statistical solution, which is a way of probabilities numeriques.",
            "Namely, that you have to model F. OG through prior rather than just the mere sees that by itself is isolated and cannot be.",
            "Informed through simulations."
        ],
        [
            "And so it it relates 2 two largest part of problem and in that connects with Percy stock that if you notice but the the new solution for the number of path is 1 harmonic nearest mirror in the sense that this is an average of one over probability or likelihood.",
            "And in that case in this is a finite universe there is no problem of infinite violence but still using a nominee communis tumor means that you.",
            "Have all subjected to this huge jumps by a few small values of P of gamma that that takes one of her peers gamma to be to be very large.",
            "So.",
            "I mean, that's maybe one reason why it's it's hard to come up with a solution that how many Queens are not the best Monte Carlo estimate.",
            "If you look at that at face value without the shrinking or regularization approach of of probabilities numerics OK and that relates to all the problems, I don't want to mention too much here, but somewhat.",
            "And that's another worry that that connects to to to process to get when we approach Monte Carlo, the first thing you want to to see is is unbias knus.",
            "In that kind of creates a huge tree that hides a Forester of problems that by trying to stick to unbiasedness as we shouldn't invasions.",
            "I just cut all self from from more efficient solutions.",
            "So I mean massive prediction of simulations to reach a proper estimators.",
            "Checking turn business is not necessary and efficient and efficiency."
        ],
        [
            "And then that that connects with something that has been part of the of the folklore, because never really published, which is Charlies regression.",
            "And so this is Charlie guy, huh?"
        ],
        [
            "We came up with an approach to.",
            "Constant estimation.",
            "So this is typical Monte Carlo integration problem as a true statistical problem through regression.",
            "So if you have a collection of of unknown normalizing constant associated with densities, and if you produce simulations from all of those densities, if you merge them together, you can create a likelihood that involves these unknown numbers in constant.",
            "That is, a logistic regression.",
            "That is, you merge all your samples and you try to reallocate each simulation to one of the density.",
            "So this is hiding some of the information you had as a beginning, but through this modeling you do end up with estimates of your constants, which is a bit of a of a miracle, but it it has a very interesting appeal that.",
            "It brings a constant into the statical model.",
            "And so this isn't a non vision solution, but if you you can derive vision versions of that by putting an extra prior."
        ],
        [
            "And you can start being up as testicle.",
            "More global cynical approach through service modeling and somebody needs a paper by Guy or was was never published.",
            "But it's it's all is still available and it it it's it's still known in the community."
        ],
        [
            "I will mention much can get hold now because I'm connecting.",
            "Connecting with that later, but this is actually a larger collection of of approaches through partition modeling and partition functions that does the same thing.",
            "That kind of hides part of the information is original model and then RE estimated as a statistical statistical approach."
        ],
        [
            "OK, I'll skip that.",
            "And then we arrived."
        ],
        [
            "To Shelley's Emily.",
            "So this is.",
            "A set of slides that that Shirley made for an arson workshop I attended, where I started to understand much better the 2003 paper.",
            "And of course, I mean you cannot look at the detail."
        ],
        [
            "Alphabet.",
            "This weather explanation of the Genesis be discussion paper where.",
            "Can't get at all.",
            "Explain how to set again a constant estimation problem.",
            "As a statistical model and ending up as an Emily Ware.",
            "It wasn't me parametric Emily, so I mean I will not read the detail, but there is this connection."
        ],
        [
            "With.",
            "With Charlie's solution."
        ],
        [
            "And yeah, the end point is that you can estimate density or constant as setting a maximum likelihood similar on a purely numerical problem.",
            "And those pictures were made my by my daughter when I discuss the paper at the."
        ],
        [
            "Society.",
            "And again, this is a something very surprising that you started as an Oracle problem and then you said it in a different way so that you end up with the statistical solution to the point of producing feature information for the precision and and some solutions of partitioning that are a form of row Blackwall isation.",
            "And then we can."
        ],
        [
            "To to to the last point, which is a purse is numeriques Ann.",
            "And this is a paper of 1988 that I remember discussing with George Casella in at about that time.",
            "Well, actually we're waiting for his car to be repaired and we were sitting in a cafe and we we started discussing that as something very exciting at the end of the of the cafe.",
            "We couldn't have better ideas, but we saw the idea very, very exciting."
        ],
        [
            "And then a few years went through and this was not followed by by something very very conclusive.",
            "Until this population numeric probability numerics.",
            "Come in and she came more from the engineering background and machine learning and you might make my colleague at Warwick module me starting promoting the use of basean and probabilistic modeling of functions as a way to improve considerably the resolution of integrals or partial differential equations or optimization problems.",
            "And so I mean, I want to go into the describing what it is, but usually there is a Gaussian process somewhere in the picture, so you can see the connection with machine learning where that's Gaussian process has to be used at some point.",
            "And then digital prior on an object of any complexity an any structure to function that you want to integrate.",
            "And this Goshen process prior is merged with simulations or data to return a posterior and real posterior in the sense we understand posteriors in a functional space that.",
            "Gives you both estimators for the functions into all.",
            "The differential equation an impressive imprecision.",
            "Evaluation as as we should have.",
            "OK, so there is availability assessment."
        ],
        [
            "OK. And.",
            "Of course, this is somewhat arbitrary.",
            "While Goshen process, I mean it, it is very concentrated in the space of all functions.",
            "But this is not something you have to believe.",
            "As something from nature is just a tool to model a huge unknown into producing better estimates."
        ],
        [
            "OK, so.",
            "And I want to take all the time, but.",
            "Let me move to my last slide.",
            "We had another one, sorry here.",
            "That I mean we can discuss some aspects of this as as being arguably arguable but.",
            "For instance, what sense do you do put on the probabilistic modeling on functions?",
            "And this notion that.",
            "Functional species are very large, but there are ways that.",
            "You can you can return something rather than nothing in a reasonable time, like when you move from a billion simulations to 1000 simulation.",
            "So if you can produce some more results around coherence, because again we are in spaces where I'm not sure Bayesian inference is always coherent, that that's a big plus that we should pursue, and the community is growing as demonstrated by this NIPS workshop last year."
        ],
        [
            "Now let me put a few personal worry about evolution and the shift about Monte Carlo.",
            "A certain meant and what how we could conduct Monte Carlo and arises.",
            "There is one thing that we always forget that when we try to approximate an integral, which is that no matter how complex the SpaceX is, where we conduct the interval interval as years into or is a is a real number.",
            "So we move from a very large space or re complex space onto the reline an often we just don't see that part.",
            "We rush into simulation, say from a certain density F and only later project onto the real line.",
            "It would be an improvement if we could.",
            "If we could conduct the alternative analysis that by getting around the curse of dimensionality, try to project 1st and then run the simulation and there is an illustration.",
            "Not completely clear to me, but with nested sampling, nested sampling.",
            "Is this technique introduced by John's killing to approximate the marginal likelihood invasion inference and one very nicest part of nested sampling.",
            "Is the concept that it is a 1 dimensional integral, and so he starts Johnston stores by reducing the problem to a 1D problem of the distribution of.",
            "This likelihood under the prior and the likelihood is a 1D object.",
            "After the simulation gets a bit hairy and an increase size and not necessarily very efficient, but the summation is under the constraints and the likelihood is as high values, which is a projection in in dimension one, and so in that direction.",
            "I think there are many ways to explore and to construct estimators that that would benefit considerably to the to the Monte Carlo issue.",
            "And so let me conclude by saying Percy for his talk and for his numerous contributions to our field that we would explore for years and years to come."
        ],
        [
            "Common that we think that we use in summarizing Markov chain Monte Carlo results and things of that sort of any kind of Carlo results that that are used to support Bayesian analysis.",
            "That's my primary interest.",
            "In many cases we have better options available, but it's remarkable how often they're not used in a particular case.",
            "In point is the idea of conditioning or what we've come to.",
            "Call Rao Blackwell Isation, which is pretty much always possible if you're using something based on full conditionals.",
            "But it's you know if you if you just look at papers in which people show plots of marginal densities that are a little bit bumpy, you know they plotted a kernel density estimate rather than something based on taking advantage of the available conditional distribution.",
            "But there's some good reasons.",
            "Number of good number of good, maybe some not so good reasons why people do this.",
            "Keeping it simple is useful.",
            "And in particular, sorry.",
            "Let's get this right."
        ],
        [
            "In terms of thinking about sort of priorities in, in, in, in when we're writing a paper if it's in a particular scientific context, that's by far the most important thing that that we want to spend our limited number of pages talking about, then the models and prior distributions that we're going to use need some time.",
            "What's inappropriate.",
            "Summary of the posterior distribution?",
            "You know?",
            "If it's a symmetric distribution, Amin is fine, but if it's heavily skewed, want to focus on the median.",
            "Then focusing on maybe the supporting methodology for doing the computation simulation, typically for us and only at the last stage do we want to have to discuss and defend the output summary method an at that point.",
            "Well, if expires good enough, let's just stick with.",
            "That is, I think, often the thing we do.",
            "Another factor is the software we work with.",
            "If you're using something like bugs or jancso your simulation.",
            "That's going to know about.",
            "Conditional distributions and things of that sort.",
            "But if you then pass on the results to something like Coda and BOA, that information is not transmitted about what the full conditionals are.",
            "You can write them down yourself, of course, and implement them, but.",
            "It's not only is it more work, it's also another thing you could get wrong.",
            "So again, if it's good enough, that's a good big reason why we do tend to stick with these simpler things.",
            "In"
        ],
        [
            "OK, the context where where it is common to use Bayesian methods.",
            "Situations where we have maybe very strong information for some simulation settings, but nothing in between.",
            "Classic examples are computer experiments where you you for certain parameter settings you run expensive simulations and get data in between.",
            "You have nothing but you may be willing to assume smoothness, so you use some sort of Gaussian.",
            "Surface priors to allow you to then compute some, simulate as some intermediate results together with uncertainties.",
            "This sort of numerical integration ideas that Percy mentioned that Chris talked a little about the numerical Bayesian analysis ideas are similar in that that you have good information that points and you fill things in in between."
        ],
        [
            "Looking a little bit at the self, avoiding random walk to help me understand what's going on here.",
            "I wrote a little.",
            "My own version of this, and I'm not sure I got it quite right in the sense that I have a different length distribution from the one that that Percy described as a bit lower, I am confident that my method is producing.",
            "A process that that could potentially hit an all of the self, avoiding paths between the two corners and any such process is going to give you the right estimate.",
            "I might not be using exactly the right one, I didn't have a chance to go back and look at the details of canoes approach, but I think qualitatively still little what I found will apply."
        ],
        [
            "So, at least with my simulation I get a distribution of those.",
            "Those negative log probabilities that is not normal, but could well be approximated as a mixture of normals.",
            "On the other hand, we do have this problem that the estimate is.",
            "Involved as some of the exponentials of these these guys, and so the.",
            "This the small values just don't contribute very much.",
            "In fact what I have here is is the.",
            "The red curve is a CDF of this.",
            "The black curve shows the percentage contribution to the sum that comes from the different values cumulatively.",
            "So basically nothing is accumulated until you get down to there and another way of saying it is is that.",
            "The 99.5% of the final estimate comes from the upper half percent of the distribution, so.",
            "In terms of modeling from my approach, at least if I use a model for this, it's not going to do very much for me because that's really what I have to get right way.",
            "Extreme upper tail, and that's very difficult to model properly, at least for me and I have to think about what can I do to convince myself that I've got a good model and then can I convince a referee that this is going to be a good thing to do?",
            "So definitely modeling is very good if we can get things into the middle of the distribution where we can use our models affectively, the tails, it could be a little trickier."
        ],
        [
            "It is easy in this case just to throw CPU cycles at things, so I ran 100 million observations in parallel.",
            "Took only a little over an hour and when I matched those up into 100 batches of a million each, and computed estimates from each, I get the.",
            "This distribution of the estimates take the logs of those estimates, and I get something that's still skewed.",
            "But at least now we're in.",
            "A situation where our final estimate, which is going to be around there, are mean our overall mean is in the middle of the distribution and I would feel comfortable trying to model this situation to try and extract more more information from it.",
            "So the one point I think I drew from from my experiments is applying modeling.",
            "Once you've done some batching, may be a useful thing to do in some situations.",
            "So."
        ],
        [
            "Just to finish up.",
            "It's very it's very useful to think about trying to take advantage of the theory that we have or just things that we can observe by looking at some of the structure of our data and using modeling to help allow us to perhaps get away with smaller sample sizes.",
            "And there's really nice ideas about that, and in the process to work.",
            "I'm a little less confident if if things really are dependent on tails and needing require tail modeling, which is just something I at least don't know how to do terribly well, matching maybe something that helps.",
            "But and of course, one thing to think about is can you change the simulation so it spends more time in the tail?",
            "The classic idea underlying important sampling.",
            "Thanks for a great talk."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Real honor to be able to speak in in this venue.",
                    "label": 0
                },
                {
                    "sent": "To this to this audience.",
                    "label": 0
                },
                {
                    "sent": "And on this occasion in particular, really honored that Fulvia began and and you got to hear her.",
                    "label": 0
                },
                {
                    "sent": "Her thoughts.",
                    "label": 0
                },
                {
                    "sent": "I remember when I just was starting in Graduate School and had no real idea of what statistics was about.",
                    "label": 0
                },
                {
                    "sent": "Really.",
                    "label": 0
                },
                {
                    "sent": "The first few weeks it was a graduate student at Harvard and Harvard, then had very strong group and exploratory data analysis, graphical methods, missing data, that sort of thing.",
                    "label": 0
                },
                {
                    "sent": "And also there was.",
                    "label": 0
                },
                {
                    "sent": "Art Dempster, who was very Bayesian and beyond upper and lower probabilities, and I didn't know anything, and I just really was trying to figure out what is statistics about what is what are we doing?",
                    "label": 0
                },
                {
                    "sent": "What am I supposed to do?",
                    "label": 0
                },
                {
                    "sent": "An didn't really know when I went to the Harvard bookstore and I was looking at the books the way we do and I saw this book, which I'm sorry that's the best we could get.",
                    "label": 0
                },
                {
                    "sent": "But this is really a true story.",
                    "label": 0
                },
                {
                    "sent": "It's definite ease.",
                    "label": 0
                },
                {
                    "sent": "Probability induction and statistics.",
                    "label": 0
                },
                {
                    "sent": "And I was just standing there and kind of opened it up and started to read and I couldn't put it down and I was poor as a churchmouse and it was, you know $80.00 or something and I bought it and I started to read it and I'm still reading it.",
                    "label": 0
                },
                {
                    "sent": "And my my my it's I really recommend it.",
                    "label": 0
                },
                {
                    "sent": "It's perhaps the most accessible introduction to his work and writing my first.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Paper now I tried my first paper on my own was about definite ease, work, finite forms of different entities, theorem on exchange ability, and the last talk I gave, which was last Friday was.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work with Sergio Baca, Lotto Ann and Susan Homes.",
                    "label": 0
                },
                {
                    "sent": "Different cities priors using Markov chain Monte Carlo computations.",
                    "label": 0
                },
                {
                    "sent": "So from the beginning to the end.",
                    "label": 0
                },
                {
                    "sent": "I have spent a career trying to understand in my own language what Divinity was talking about, and I'm not going to try to do that that today I I sent myself an impossible task today.",
                    "label": 0
                },
                {
                    "sent": "The thing is that statistics has changed since different Eddie worked.",
                    "label": 0
                },
                {
                    "sent": "It's not that the ideas aren't central and valuable, but but something's changed and what I want to try to do is at least for one second or for 15 minutes to try to think about what would definiti.",
                    "label": 0
                },
                {
                    "sent": "What might he do if he were doing statistics today?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Want to look forward and of course the thing that's changed more than anything is is the computer just just normous datasets, but our ability to to actually do Bayesian analysis in in real time.",
                    "label": 0
                },
                {
                    "sent": "In particular, Monte Carlo simulation is just just every place, and so I want to think about that and what might definitely think about.",
                    "label": 0
                },
                {
                    "sent": "Think about that.",
                    "label": 0
                },
                {
                    "sent": "And so first, here's a little paradox.",
                    "label": 0
                },
                {
                    "sent": "Don't know if that'll work so thing.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "King about Monte Carlo data and the paradox of the problem is this.",
                    "label": 0
                },
                {
                    "sent": "Why do we Bayesians and me too?",
                    "label": 0
                },
                {
                    "sent": "Why do we Bayesians when we analyze the output of our Monte Carlo trials use frequentist methods?",
                    "label": 0
                },
                {
                    "sent": "I never see anybody do anything other than X bar plus or minus 2 standard deviations.",
                    "label": 0
                },
                {
                    "sent": "I mean you know people save different things, but if you look at what we actually do, what's been in every now it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not only the Bayesians problem, you know.",
                    "label": 0
                },
                {
                    "sent": "Statisticians don't use modern statistical methods, they use Explorer plus or minus.",
                    "label": 0
                },
                {
                    "sent": "Two SD if they do plus or minus two SD an So what can we think about now?",
                    "label": 0
                },
                {
                    "sent": "Why is that now of course.",
                    "label": 0
                },
                {
                    "sent": "The first answers are for many cases, maybe most cases.",
                    "label": 0
                },
                {
                    "sent": "The extra thinking.",
                    "label": 0
                },
                {
                    "sent": "First of all, it's difficult.",
                    "label": 0
                },
                {
                    "sent": "You know you've got to slow down and think about every minor Carlo.",
                    "label": 0
                },
                {
                    "sent": "Come on, it's costly, and then it's not worth it.",
                    "label": 0
                },
                {
                    "sent": "The basic basic findings is that the data swamps the prior, and if you've got a lot of data the prior won't matter, and so why bother to specify a prior and that's all true and valid, and what I want to talk to you today about are some problems where it seems to be worthwhile where it's not so.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "The data doesn't swamped the prior and and maybe there's something more to be found by by incorporating what we know so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we go.",
                    "label": 0
                },
                {
                    "sent": "So this is an example and please try to follow this because this theme runs throughout and it's a simple example to follow.",
                    "label": 0
                },
                {
                    "sent": "When I first came to Stanford 1974, Don Kanute, the world's greatest computer scientist, I call 'em and wrote me a note saying hey, I have a statistical problem for you.",
                    "label": 0
                },
                {
                    "sent": "OK, and he was trying to count how many pairs there are in a 10 by 10 grid.",
                    "label": 0
                },
                {
                    "sent": "That's a 10 by 10 grid.",
                    "label": 0
                },
                {
                    "sent": "This this one here, which start at 00 and wind up at 10:10 and don't intersect.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's an example of such a path.",
                    "label": 0
                },
                {
                    "sent": "Here's a path which is in 100 by 100 grid, but take the 10 by 10 case.",
                    "label": 0
                },
                {
                    "sent": "He wanted to know how many such pads are there.",
                    "label": 0
                },
                {
                    "sent": "Well post question and the the the number of paths these saws self avoiding walks the growth rate of those are fundamental constants in physics and chemistry and.",
                    "label": 0
                },
                {
                    "sent": "In biology and it's not a frivolous question and he had an algorithm which let me explain the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The idea is to grow one at random, and so let's suppose you start here at 00, so half the time you go up and half the time you go to the right.",
                    "label": 0
                },
                {
                    "sent": "Say you go up OK and then here I could go up or to the right.",
                    "label": 0
                },
                {
                    "sent": "I can't go back, so maybe I go here and now I could go up or to the right or down.",
                    "label": 0
                },
                {
                    "sent": "Suppose I go down now I'm not stupid.",
                    "label": 0
                },
                {
                    "sent": "I don't go back, you know I have no choice.",
                    "label": 0
                },
                {
                    "sent": "I have to go here now.",
                    "label": 0
                },
                {
                    "sent": "I could go here right here.",
                    "label": 0
                },
                {
                    "sent": "Suppose I go here and now I have.",
                    "label": 0
                },
                {
                    "sent": "I could go here or here.",
                    "label": 0
                },
                {
                    "sent": "So you understand what I mean.",
                    "label": 0
                },
                {
                    "sent": "You could grow one and you make the choices at random uniformly from the possible choices you can make.",
                    "label": 0
                },
                {
                    "sent": "It's easy once you might get stuck, OK, you might get stuck.",
                    "label": 0
                },
                {
                    "sent": "It turns out it's easy to check and not get stuck, but suppose you're not so smart.",
                    "label": 0
                },
                {
                    "sent": "You just running the algorithm.",
                    "label": 0
                },
                {
                    "sent": "If you're successful when you make a path that goes from 00 to, here's to 4.",
                    "label": 0
                },
                {
                    "sent": "Four sorry, you could calculate very easily what's the chance of the of the path that you took.",
                    "label": 0
                },
                {
                    "sent": "That is, I'm going to call the pans gamma and the chance of gamma.",
                    "label": 0
                },
                {
                    "sent": "Well, it's 1/2 * 1/2 * 1/3 * 1 * 1/2, and so forth.",
                    "label": 0
                },
                {
                    "sent": "You could just multiply the probabilities along the path.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's OK with everybody, I hope.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Now let's make a statistic which is tiava trial is 0.",
                    "label": 0
                },
                {
                    "sent": "If you get stuck and one over the probability of the path if you're OK.",
                    "label": 0
                },
                {
                    "sent": "So that's a perfectly computable statistic.",
                    "label": 0
                },
                {
                    "sent": "What's its mean value?",
                    "label": 0
                },
                {
                    "sent": "Well, it's mean value.",
                    "label": 0
                },
                {
                    "sent": "The expected value of this statistic.",
                    "label": 0
                },
                {
                    "sent": "It's of course 0.",
                    "label": 0
                },
                {
                    "sent": "If you get stuck, so it's only the sum over all possible paths, 'cause otherwise it's zero of the statistic times the probability.",
                    "label": 0
                },
                {
                    "sent": "That you've chosen that path.",
                    "label": 0
                },
                {
                    "sent": "Now the statistic is 1 / P of gamma and the P of gammas cancel, and you're left with the number of paths.",
                    "label": 0
                },
                {
                    "sent": "So this is an example of classical idea of what's called sequential importance sampling.",
                    "label": 0
                },
                {
                    "sent": "But if you haven't seen it before, don't remember it.",
                    "label": 0
                },
                {
                    "sent": "It's sort of magical, it's an unbiased estimate of the number of paths and new.",
                    "label": 0
                },
                {
                    "sent": "Ran it.",
                    "label": 0
                },
                {
                    "sent": "You know, 10 billion times, 10 billion times, OK, really did run at 10 billion times.",
                    "label": 0
                },
                {
                    "sent": "And he found he got estimates that his estimate for the number of paths was one point 6 plus or minus zero point 3 * 10 to the 24th.",
                    "label": 0
                },
                {
                    "sent": "The average path length was about around 92.",
                    "label": 0
                },
                {
                    "sent": "Now that's it's a 10 by 10 grid.",
                    "label": 0
                },
                {
                    "sent": "So that means typical paths really almost cover everything.",
                    "label": 0
                },
                {
                    "sent": "Surprising little bit.",
                    "label": 0
                },
                {
                    "sent": "He found, you know 81% of them went through the middle vertex and.",
                    "label": 0
                },
                {
                    "sent": "His problem was this.",
                    "label": 0
                },
                {
                    "sent": "He said I ran this thing 10 billion times and you know, suppose I'm just calculating calculating the this statistic T and you, you know you run it.",
                    "label": 0
                },
                {
                    "sent": "It's you know 10 to the 17th, 10 to the 19th, whatever it is.",
                    "label": 0
                },
                {
                    "sent": "But then one value you know this these this is a product of a lot of little numbers.",
                    "label": 0
                },
                {
                    "sent": "So one over it can be very big.",
                    "label": 0
                },
                {
                    "sent": "One value overwhelms everything that came before.",
                    "label": 0
                },
                {
                    "sent": "Typical problem that we have in important sampling and he he thought.",
                    "label": 0
                },
                {
                    "sent": "You know, did these numbers mean anything?",
                    "label": 0
                },
                {
                    "sent": "He understood that that was a problem, and it's a problem for us today when we use any version of important sampling.",
                    "label": 0
                },
                {
                    "sent": "And that's a very common method.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's the question do these numbers mean anything?",
                    "label": 0
                },
                {
                    "sent": "This huge variability, as usual for important sampling?",
                    "label": 0
                },
                {
                    "sent": "It seemed as if a million samples were determined by one or two numbers.",
                    "label": 0
                },
                {
                    "sent": "Nowadays people do a funny thing.",
                    "label": 0
                },
                {
                    "sent": "They calculate the.",
                    "label": 0
                },
                {
                    "sent": "You know the.",
                    "label": 0
                },
                {
                    "sent": "An estimate of the sample of the the effective sample size.",
                    "label": 0
                },
                {
                    "sent": "Well, that's the standard deviation.",
                    "label": 0
                },
                {
                    "sent": "If the mean doesn't mean anything, the stand deviation means much, much less and.",
                    "label": 0
                },
                {
                    "sent": "OK is and then is the question.",
                    "label": 0
                },
                {
                    "sent": "Is there more information that we have about the problem or that's in the data that we could use to help with this problem?",
                    "label": 0
                },
                {
                    "sent": "And just to explain to you that there's something to understand here about 10 years after canoe he published this analysis.",
                    "label": 0
                },
                {
                    "sent": "His work in science an about 10 years later, some physicists got annoyed and said 10 by 10 will blast it out and they just blasted it out and and these are the numbers.",
                    "label": 0
                },
                {
                    "sent": "Can use estimate of the number of paths was 1.6 * 10 to the 24th.",
                    "label": 0
                },
                {
                    "sent": "They know the exact number.",
                    "label": 0
                },
                {
                    "sent": "That's not so helpful, but this is more helpful.",
                    "label": 0
                },
                {
                    "sent": "It's you know, 1.5687 * 10 to the 24th.",
                    "label": 0
                },
                {
                    "sent": "It seems to work pretty well, and his other numbers were spot on too, so there's something to understand.",
                    "label": 0
                },
                {
                    "sent": "OK, it's not just crazy, it seems to work in an and do we have anything to say about it?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so if you.",
                    "label": 0
                },
                {
                    "sent": "Don't mind let me try to think out loud an I'm very eager to have feedback about this.",
                    "label": 0
                },
                {
                    "sent": "What do we know?",
                    "label": 0
                },
                {
                    "sent": "I mean, 'cause do we really know you know anything?",
                    "label": 0
                },
                {
                    "sent": "So the first step is?",
                    "label": 0
                },
                {
                    "sent": "To give it a name, so let's let Theta in be the number of self avoiding walks from 00 to NN and that can shock some people because it's a perfectly determined number.",
                    "label": 0
                },
                {
                    "sent": "You know it's just some number that exists in nature, and if you haven't thought about that before you know.",
                    "label": 0
                },
                {
                    "sent": "Think about the 37th digit of \u03c0.",
                    "label": 0
                },
                {
                    "sent": "That is, for most of us you don't know what the 37th digit of pie is.",
                    "label": 0
                },
                {
                    "sent": "For me, you know it's equally likely to be anything from zero to 9, and I'm perfectly happy to to make pet for small amounts on it.",
                    "label": 0
                },
                {
                    "sent": "Now my math colleagues were always trying to figure out what the statisticians do, and so I said well, think about the 37th digit of pie and one of them said.",
                    "label": 0
                },
                {
                    "sent": "The first guy who computed 796 digit of \u03c0.",
                    "label": 0
                },
                {
                    "sent": "The first mistake he made was on the 37th digit.",
                    "label": 0
                },
                {
                    "sent": "I said oh and the second guy said.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The 37th digit of \u03c0 past the decimal place is 0, so of course different people have different knowledge bases and you know different priors of course, and now you know what the 30 you have a reasonable mass at zero for what the 37th digit of \u03c0 is, but of course, as Bayesians were allowed to put priors on things that we don't know, and the number of paths in a in a 10 by 10 grid is really something that we don't.",
                    "label": 0
                },
                {
                    "sent": "That we don't know.",
                    "label": 0
                },
                {
                    "sent": "So we know something about it.",
                    "label": 0
                },
                {
                    "sent": "For example, this walk each time that you take a step you can take at most three directions.",
                    "label": 0
                },
                {
                    "sent": "So the number of the total number of pants can be at most 3 to the N squared.",
                    "label": 0
                },
                {
                    "sent": "It can't be anymore than that.",
                    "label": 0
                },
                {
                    "sent": "Now if you wanted to try to think about a lower bound, get busy, it's open.",
                    "label": 0
                },
                {
                    "sent": "We don't know, there's nobody knows the aesthetics of these numbers, but.",
                    "label": 0
                },
                {
                    "sent": "I buy very little thinking, could show that it was, you know.",
                    "label": 0
                },
                {
                    "sent": "It grows like a constant to be N squared, so I know something about.",
                    "label": 0
                },
                {
                    "sent": "It's about the log of this number roughly.",
                    "label": 0
                },
                {
                    "sent": "And of course you know if I ran my simulations an it was outside those intervals.",
                    "label": 0
                },
                {
                    "sent": "Somethings wrong with the computer code or something else, so I know a little bit.",
                    "label": 0
                },
                {
                    "sent": "We also have some data.",
                    "label": 0
                },
                {
                    "sent": "The data is the data from canuse trials, right?",
                    "label": 0
                },
                {
                    "sent": "I can run this algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's an unbiased estimate of the my parameter, so it's data.",
                    "label": 0
                },
                {
                    "sent": "Let's look at it as data for a second and try to think about it.",
                    "label": 0
                },
                {
                    "sent": "So remember my statistic and now I'm going to use the fact that I know how to run this walk and not get stuck, so I never get stuck so well.",
                    "label": 0
                },
                {
                    "sent": "This statistic T of gamma.",
                    "label": 0
                },
                {
                    "sent": "It was the product over edges in the path of one over the probability of the edge.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and let me just put that up into the exponent the way we do and let me make it E. To the minus the sum over edges in the path.",
                    "label": 0
                },
                {
                    "sent": "Of the log, which I'm calling in sub gamma of E and let me call that E to the minus H of gamma.",
                    "label": 0
                },
                {
                    "sent": "OK, where in sub gamma of Y is 0 if if the probability is 1, log 2 or log three, it's so it's you know.",
                    "label": 0
                },
                {
                    "sent": "So this H of gamma is the sum of a lot of little things, right?",
                    "label": 0
                },
                {
                    "sent": "So maybe it's normal.",
                    "label": 0
                },
                {
                    "sent": "You know, I mean, it's not such a stretch.",
                    "label": 0
                },
                {
                    "sent": "You know that's the sum of their kind of random, right?",
                    "label": 0
                },
                {
                    "sent": "You know, it's sort of going around.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's normal and the length of a typical path is around N squared, and so it's not such a crazy thing to say.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe this energy is roughly normal and it has, you know.",
                    "label": 0
                },
                {
                    "sent": "Mean of order N squared and some standard deviation, and then I could put a prior as I will in the second on A&B and using the data I can compute the posterior and try to use this as an estimate of the number of paths.",
                    "label": 0
                },
                {
                    "sent": "Now that may sound crazy to you, but let's will carry it forward.",
                    "label": 0
                },
                {
                    "sent": "It's just what I'm doing is thinking out loud and you shouldn't do that.",
                    "label": 0
                },
                {
                    "sent": "It can be embarrassing, but I'm going to continue for a little while.",
                    "label": 0
                },
                {
                    "sent": "This route that I've just sketched suggests looking at more of the data than just this statistic.",
                    "label": 0
                },
                {
                    "sent": "T of gamma, for example, if I want to say, are these things approximately normal?",
                    "label": 0
                },
                {
                    "sent": "I could take my 10 billion sample pass, compute H of gamma and look at them, look at a histogram of them, you know, just see if they're normal.",
                    "label": 0
                },
                {
                    "sent": "If I think that the central limit theorem is holding for this, I could look at each path and treated as a time series and kind of look to see.",
                    "label": 0
                },
                {
                    "sent": "If this in a flex, you know enough randomness that the normality makes makes some sense.",
                    "label": 0
                },
                {
                    "sent": "So these first thoughts are saying when you run a Monte Carlo trial is often an awful lot of information that we don't make use of.",
                    "label": 0
                },
                {
                    "sent": "We can start to try to think about it, and I'm encouraging us to do that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now here's.",
                    "label": 0
                },
                {
                    "sent": "Some news, Alas.",
                    "label": 0
                },
                {
                    "sent": "Minus log P of gamma is not roughly normal.",
                    "label": 0
                },
                {
                    "sent": "This is a histogram from canoe stay to an you know whatever this Mrs.",
                    "label": 0
                },
                {
                    "sent": "It's not normal.",
                    "label": 0
                },
                {
                    "sent": "I mean you know we've all looked at a lot of histograms that that's not a that's not a normal that's not a histogram.",
                    "label": 0
                },
                {
                    "sent": "However, looking at the data and thinking about it and some math that's coming later, it does seem to be that given the length of a path, if I condition on the length of the path, then this statistic minus log P of gamma is roughly normal, and it seems to be quite normal.",
                    "label": 0
                },
                {
                    "sent": "Well, let me show you what the lengths of the pads are.",
                    "label": 0
                },
                {
                    "sent": "This is from this is from the data.",
                    "label": 0
                },
                {
                    "sent": "This is given the given the given the lengths of given the the length of a path can be anything from 20 to about 100 or so here.",
                    "label": 0
                },
                {
                    "sent": "OK 120 maybe and.",
                    "label": 0
                },
                {
                    "sent": "Can really it can really wind around.",
                    "label": 0
                },
                {
                    "sent": "This is the expected value of on the left.",
                    "label": 0
                },
                {
                    "sent": "The expected value of the energy minus log P given the length, and it's it's monotone is make some sense.",
                    "label": 0
                },
                {
                    "sent": "And this is the standard deviation of the of the energy given the length of the path, and that is like that.",
                    "label": 0
                },
                {
                    "sent": "OK, and now I could model these as splines and put.",
                    "label": 0
                },
                {
                    "sent": "Parameters on the splines and then go to town, and I'm going to.",
                    "label": 0
                },
                {
                    "sent": "I'm going to do something like that in a second, but the point again is there is information in the data and normally we're not led to use it in this kind of thinking about it in a Bayesian way has led to me to find interesting interesting structure.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's go forward in this way.",
                    "label": 0
                },
                {
                    "sent": "Here's here's a little tiny calculation.",
                    "label": 0
                },
                {
                    "sent": "Here's what I'm going to do.",
                    "label": 0
                },
                {
                    "sent": "We started by saying the number of paths is just this sum the sum of 1 over the number of fans, and that's the sum over the number of pans of P of gamma over P of gamma, and that's the expected value of 1 / P of gamma with respect to this measure on paths.",
                    "label": 0
                },
                {
                    "sent": "Let's write that using double conditioning.",
                    "label": 0
                },
                {
                    "sent": "I try to learn how to use this thing.",
                    "label": 0
                },
                {
                    "sent": "That's the expected value of 1 / P of gamma given the length, and so I've just written that out.",
                    "label": 0
                },
                {
                    "sent": "That's the expected value that's the sum over the different possible lengths 2200 of P of gamma times the expected value of 1 / P of gamma given the length.",
                    "label": 0
                },
                {
                    "sent": "So here's my here's the trick.",
                    "label": 0
                },
                {
                    "sent": "I'm going to use.",
                    "label": 0
                },
                {
                    "sent": "These are just, you know, I have a. I have a billion data points and I have, you know the lengths, take values from zero to 100 so you can do anything you like, but just using the frequencies is all you're going to get.",
                    "label": 0
                },
                {
                    "sent": "You know.",
                    "label": 0
                },
                {
                    "sent": "So use estimate.",
                    "label": 0
                },
                {
                    "sent": "You know this the the probability that a trial produces a path of length P from the data just directly or or be a Bayesian with that it won't won't help or hinder you.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to estimate this conditional expected value of 1 / P of gamma.",
                    "label": 0
                },
                {
                    "sent": "From from, from the lognormal assumption and using Bayes theorem and I'll, I'll carry that out and come back and do it, so that's a different way of using the data and my findings to get an estimate of the of the number of paths.",
                    "label": 0
                },
                {
                    "sent": "Their scheme.",
                    "label": 0
                },
                {
                    "sent": "Member where I started you know which is?",
                    "label": 0
                },
                {
                    "sent": "You know, putting putting a prior over something strange and works pretty well and examples are coming.",
                    "label": 0
                },
                {
                    "sent": "One point that I want to make now is I did have to think that as I had to Snoop around in the data and identify a parameter which in some sense was a sufficient statistic, namely the length of the path that is at the moment you know I'm running these trials.",
                    "label": 0
                },
                {
                    "sent": "I've got all kinds of things I could look at.",
                    "label": 0
                },
                {
                    "sent": "I in looking at them, I looked at the, you know, I found that the link conditioning on the length of a path seemed to seem to Get Me Out of trouble and so that that was something that took some some thinking or some insider.",
                    "label": 0
                },
                {
                    "sent": "Something like doing science even right?",
                    "label": 0
                },
                {
                    "sent": "Here's a second idea in this example, and many more that are coming.",
                    "label": 0
                },
                {
                    "sent": "Only a few values of L mattered these these P lambdas, you know.",
                    "label": 0
                },
                {
                    "sent": "Dropped off pretty rapidly and this expected value was only big for a few values of of L and so in instead of having to think I can.",
                    "label": 0
                },
                {
                    "sent": "Try to take this tack and so this is a this is the theoretical contribution here, which is the following try.",
                    "label": 0
                },
                {
                    "sent": "This idea, let's let's model this energy minus P of gamma as a mixture of lognormal distributions.",
                    "label": 0
                },
                {
                    "sent": "OK, an you have to pick K, but that's a familiar problem and I'm going to take A to B6 and it works great and this.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This picture is a plot of the as a function of the length of the estimate of the log of account and what you can see is it's very flat there in the middle and it drops off and this will only a few values of of of.",
                    "label": 0
                },
                {
                    "sent": "Of the length mattered, and so I don't have to identify them the length let me just model my minus log P of gamma as as a mixture of normals.",
                    "label": 0
                },
                {
                    "sent": "Now here's let me say a cautionary thing.",
                    "label": 0
                },
                {
                    "sent": "The mathematician in me is striking up.",
                    "label": 0
                },
                {
                    "sent": "It's a fact of nature.",
                    "label": 0
                },
                {
                    "sent": "I have math fact of mathematics that any measure on the line, any problem, any probability density on the line can be very well approximated as a finite mixture of log normals.",
                    "label": 0
                },
                {
                    "sent": "OK, so anything can be, so I'm modeling anything and that's because if you you know, let the mean and let the variance be, you know, Peaky you can.",
                    "label": 0
                },
                {
                    "sent": "You can make a point mass as a.",
                    "label": 0
                },
                {
                    "sent": "Normal and then and so the log of P is being is being the log of P is being modeled as a mixture of normals, but anything can be modeled as a mixture of normals and so you have to be worried about that anyway, let's not just go forward, so I now have say a mixture of K normals and I can put a prior on the mixing.",
                    "label": 0
                },
                {
                    "sent": "Now you have to be careful and I was put a prior on the mixing weights data I.",
                    "label": 0
                },
                {
                    "sent": "Put a prior on the means and the variance is coolest vector Ada and I should have said this.",
                    "label": 0
                },
                {
                    "sent": "All of this work is joint work with Mark Corum, wonderfully innovative fellow at Stanford, Anne Anne we we we use K = 6 I took Theta the initial prior on the 100 and on the on the six waits to be uniform on the six simplex and I.",
                    "label": 0
                },
                {
                    "sent": "Put you know, independent conjugate priors in the standard way on mu and Sigma squared, and as I said before, if I wanted to be more careful, I could model the means and the variances of splines and I could do that.",
                    "label": 0
                },
                {
                    "sent": "I haven't.",
                    "label": 0
                },
                {
                    "sent": "I haven't carried it out.",
                    "label": 0
                },
                {
                    "sent": "OK, the point of this slide is 'cause there are many other sequential importance sampling problems coming.",
                    "label": 0
                },
                {
                    "sent": "You don't have to be clever and identify.",
                    "label": 0
                },
                {
                    "sent": "L of gamma you can try this for any sequential importance sampling, so let me show you what what happened.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For canoes problem, so with all of this story going I now said let me start again.",
                    "label": 0
                },
                {
                    "sent": "I took a fresh sample not of 10 to the 913.",
                    "label": 0
                },
                {
                    "sent": "Whatever it was of 1000 paths.",
                    "label": 0
                },
                {
                    "sent": "There they are.",
                    "label": 0
                },
                {
                    "sent": "I I had these pants from my normality assumption.",
                    "label": 0
                },
                {
                    "sent": "If I accept my normality assumption I can compute the posterior for this parameter ADA.",
                    "label": 0
                },
                {
                    "sent": "Just by straightforward arguments, and now I can sample Ada from the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Easy to do and I can compute analytically my expected value of the account or any other statistic, given that it's that mixture of log normals.",
                    "label": 0
                },
                {
                    "sent": "As sorry, I'm not doing so well at this, but I can try again as.",
                    "label": 0
                },
                {
                    "sent": "You know G. Of Ada is the ADA, mixture of normals, and then I have to calculate this exponential integral and this is a histogram of.",
                    "label": 0
                },
                {
                    "sent": "So sample data from the posterior calculate this estimate of account.",
                    "label": 0
                },
                {
                    "sent": "You know do that some number of times.",
                    "label": 0
                },
                {
                    "sent": "This is a histogram of those estimates of accounts, and from that you can get a 95% highest posterior interval for the count and that's.",
                    "label": 0
                },
                {
                    "sent": "You know that that that came out to be, you know, between you know, 7 * 10 to the 23rd and 1 * 10 to the 27th.",
                    "label": 0
                },
                {
                    "sent": "Ann Ann.",
                    "label": 0
                },
                {
                    "sent": "Here the quote unquote right answer is, you know around 1.6 * 10 to the 24th.",
                    "label": 0
                },
                {
                    "sent": "A point is that this Bayesian procedure that I just went through an I'm not telling you about a lot of trials that we did to to kind of see if it's actually true seems to be true.",
                    "label": 0
                },
                {
                    "sent": "Got me down from needing, you know billions of samples of size billions to samples of size 1000.",
                    "label": 0
                },
                {
                    "sent": "Well, that's good, right?",
                    "label": 0
                },
                {
                    "sent": "That's that's an improvement.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's an example and let me.",
                    "label": 0
                },
                {
                    "sent": "There are.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many many similar problems.",
                    "label": 0
                },
                {
                    "sent": "Certainly basic important sampling.",
                    "label": 0
                },
                {
                    "sent": "One of the mainstays of scientific computing you want to calculate an integral you can sample, perhaps independently, perhaps from a Markov chain from a different measure new, you estimate the integral by using the weighted values of the samples, sequential importance, sampling case.",
                    "label": 0
                },
                {
                    "sent": "It's new to you is different in that I'm just building up this measure new.",
                    "label": 0
                },
                {
                    "sent": "Sequentially and so my weights 1 / P or products, and so this lognormal stuff makes some sense.",
                    "label": 0
                },
                {
                    "sent": "Here's an example, one of many that that I've been involved with.",
                    "label": 0
                },
                {
                    "sent": "Counting tables, graphs, etc with given row sums.",
                    "label": 0
                },
                {
                    "sent": "This is data that sometimes called Darwin's data.",
                    "label": 0
                },
                {
                    "sent": "These are the finches on the Galapogos Island.",
                    "label": 0
                },
                {
                    "sent": "These are the 18 islands that there were.",
                    "label": 0
                },
                {
                    "sent": "There's a zero or one in in the IJ place if that Finch lives on that island, and a well ecologist calculate all kinds of statistics to see.",
                    "label": 0
                },
                {
                    "sent": "Is this data different than data which was chosen at random with the rows in column sums fixed?",
                    "label": 0
                },
                {
                    "sent": "It's a reasonable question how to calibrate their analysis.",
                    "label": 0
                },
                {
                    "sent": "It's a first question.",
                    "label": 0
                },
                {
                    "sent": "How many tables are there with the given row and column sums?",
                    "label": 0
                },
                {
                    "sent": "With Ugo Chin and Susan Holmes Engine Lou we built a sequential importance sampling algorithm to do that and I just want to say a sentence about it because it's just very similar to what I just did.",
                    "label": 0
                },
                {
                    "sent": "So suppose there are 1234 seemed to be 4 ones in the first column, so you might think OK, let me just build up a table sequentially at random, put 4 ones in the first column and then subtract 1 from each of those four row sums and then put however many ones have to go in the second column.",
                    "label": 0
                },
                {
                    "sent": "And just keep going and.",
                    "label": 0
                },
                {
                    "sent": "And that would get you a table or you would get stuck and now.",
                    "label": 0
                },
                {
                    "sent": "There's two big steps.",
                    "label": 0
                },
                {
                    "sent": "The first step is why not?",
                    "label": 0
                },
                {
                    "sent": "If the row sums are big, why not make it more likely to put ones in the column in the rows where the row sums are big?",
                    "label": 0
                },
                {
                    "sent": "It's easy to do that as long as you can compute what the probability is that you're putting rose in one at a time, and the second thing is, you can use math.",
                    "label": 0
                },
                {
                    "sent": "The Gale riser theorem gives you a necessary and sufficient condition on a set of row sums in columns seems to be the row and column sums of a binary table.",
                    "label": 0
                },
                {
                    "sent": "You can use math to say.",
                    "label": 0
                },
                {
                    "sent": "One of the possible next moves you could make and never get stuck, and from that you can estimate the number of tables and where exactly in the same situation.",
                    "label": 0
                },
                {
                    "sent": "It's a product of a lot of little numbers and an and seems as if lognormal.",
                    "label": 0
                },
                {
                    "sent": "So good way to go.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a huge set of examples.",
                    "label": 0
                },
                {
                    "sent": "Anna is the motivation that canoe had for asking me his question.",
                    "label": 0
                },
                {
                    "sent": "So in computer science there's a whole world of what are called backtracking algorithms and I'll give you a general reference for this.",
                    "label": 0
                },
                {
                    "sent": "But if you just type it in on the Internet, you'll find it.",
                    "label": 0
                },
                {
                    "sent": "So the issue is the problem is to find X one up to XN.",
                    "label": 0
                },
                {
                    "sent": "Some parameters such that a certain condition PN of X1 up to XN holds.",
                    "label": 0
                },
                {
                    "sent": "Where the excise are, you know, say, in integers, sets of integers.",
                    "label": 0
                },
                {
                    "sent": "There in some sets, SI in backtracking algorithms, what you're giving is some partial constraints.",
                    "label": 0
                },
                {
                    "sent": "That is your given PL of X1 up to Excel, so that if X1 up to XN holds then X one up to XL holds.",
                    "label": 0
                },
                {
                    "sent": "The elf condition holds and so you can check along the way and if you can't fulfill.",
                    "label": 0
                },
                {
                    "sent": "The If the L thing doesn't work then you don't have to try any of the extensions.",
                    "label": 0
                },
                {
                    "sent": "OK, so this information is often collected into a backtracking tree.",
                    "label": 0
                },
                {
                    "sent": "The most famous example is the end Queens problems.",
                    "label": 0
                },
                {
                    "sent": "How many ways can you put in Queens down on an end by end board in such a way that they are non attacking their Excel?",
                    "label": 0
                },
                {
                    "sent": "Is the column of the Queen.",
                    "label": 0
                },
                {
                    "sent": "The Queens have to go all in different rows.",
                    "label": 0
                },
                {
                    "sent": "An X one is what column is Queen one and X2 is what column in Queen Two is in there between one and in the condition PN of X1 up to XN is well.",
                    "label": 0
                },
                {
                    "sent": "They shouldn't be.",
                    "label": 0
                },
                {
                    "sent": "You know they shouldn't be in the same column and they should.",
                    "label": 0
                },
                {
                    "sent": "You know they shouldn't be on the same diagonal and those same conditions hold for everything.",
                    "label": 0
                },
                {
                    "sent": "This is the backtracking tree, and so you could put the first Queen in any of four places, 123 or 4.",
                    "label": 0
                },
                {
                    "sent": "Columns this is in a four by four case.",
                    "label": 0
                },
                {
                    "sent": "I should have said and then you can continue and you get stuck here and then you backtrack.",
                    "label": 0
                },
                {
                    "sent": "I won't try to explain backtracking too carefully.",
                    "label": 0
                },
                {
                    "sent": "There are two solutions here.",
                    "label": 0
                },
                {
                    "sent": "Two ways of putting 4 Queens into a four by four board here.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The here is the.",
                    "label": 0
                },
                {
                    "sent": "Real chess board.",
                    "label": 0
                },
                {
                    "sent": "The 8 by 8 there are 92 solutions and.",
                    "label": 0
                },
                {
                    "sent": "Backtracking, you know you start to go and then you stop and you don't have to check anymore on that branch allows.",
                    "label": 0
                },
                {
                    "sent": "I don't want to do that.",
                    "label": 0
                },
                {
                    "sent": "Well, I can just go forward.",
                    "label": 0
                },
                {
                    "sent": "Backtracking allows you to scan this whole backtracking tree using 1% of the eight to the cases.",
                    "label": 0
                },
                {
                    "sent": "What canoe was interested in doing so backtracking algorithms when you run them?",
                    "label": 0
                },
                {
                    "sent": "Some of them run lightning fast and some of them just take weeks and you don't know if it's gonna be months or years and how to estimate the running time of a backtracking algorithm was canus problem issue and.",
                    "label": 0
                },
                {
                    "sent": "He had the following scheme, which is just sequential importance sampling.",
                    "label": 0
                },
                {
                    "sent": "But let's say what it is.",
                    "label": 0
                },
                {
                    "sent": "So you start to build your build a path at random, but don't backtrack.",
                    "label": 0
                },
                {
                    "sent": "Just start to go down the tree and an each time making one of the available choices uniformly.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "If you are at level I.",
                    "label": 0
                },
                {
                    "sent": "If you have DI places to go, that's that's die for that path.",
                    "label": 0
                },
                {
                    "sent": "And then exactly the calculation that I did essentially shows that that this statistic T you never get stuck, you just stop when you get to a leaf which is D1 plus D 1 * D, Two plus, etc.",
                    "label": 0
                },
                {
                    "sent": "This has under this random sampling distribution exactly the number of vertices, and if you wanted to know something else.",
                    "label": 0
                },
                {
                    "sent": "You could use use these as as important sampling weights.",
                    "label": 0
                },
                {
                    "sent": "Here's an example in the 8 Queens problem.",
                    "label": 0
                },
                {
                    "sent": "The first Queen you know went there.",
                    "label": 0
                },
                {
                    "sent": "The second Queen went here and you know the Queens.",
                    "label": 0
                },
                {
                    "sent": "They got some.",
                    "label": 0
                },
                {
                    "sent": "They got some place along and then it was stuck.",
                    "label": 0
                },
                {
                    "sent": "There was no place to go.",
                    "label": 0
                },
                {
                    "sent": "And when you multiply the number of choices as you went down the tree, the estimated number of of of of of vertices.",
                    "label": 0
                },
                {
                    "sent": "The total number of vertices in this graph was 2129, the second a second trial was 2689.",
                    "label": 0
                },
                {
                    "sent": "The third trial was 1489, so these are partial estimates along the way and even from doing it a few times.",
                    "label": 0
                },
                {
                    "sent": "These four numbers give you some reasonable idea of how many vertices are in this tree.",
                    "label": 0
                },
                {
                    "sent": "Here, it turns out the right answer is 20,057, and.",
                    "label": 0
                },
                {
                    "sent": "In this example, you can blast it out the minimum, the minimum statistic it says down here is 489 the average.",
                    "label": 0
                },
                {
                    "sent": "This is an unbiased estimate is 2020 two 1057.",
                    "label": 0
                },
                {
                    "sent": "The Max is 7500 and the standard deviation is of the same order as the mean and so you could estimate accurately.",
                    "label": 0
                },
                {
                    "sent": "How many vertices there are in this tree using using backtracking and an OK, let me let me go on.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The points are any sequential importance sampling scheme, and there are thousands of them fits into this tree.",
                    "label": 0
                },
                {
                    "sent": "This backtracking tree picture my chest, my my sorry self new self avoiding paths problem.",
                    "label": 0
                },
                {
                    "sent": "You know you're starting to build a path, you just, you know, make a tree out of the possible choices that you have so they all fit into that.",
                    "label": 0
                },
                {
                    "sent": "Pick a path in the tree at random and add the log degrees along the way will give a mixture of normals with length as the mixing variable, so that's a theorem.",
                    "label": 0
                },
                {
                    "sent": "OK, now I have to make some assumptions about what kind of pans and trees, but under reasonable mild conditions.",
                    "label": 0
                },
                {
                    "sent": "In particular, for the 8 Queens problem or in Queens problem for.",
                    "label": 0
                },
                {
                    "sent": "For Galton Watson trees.",
                    "label": 0
                },
                {
                    "sent": "This heuristic that I came upon with Mark is in fact the theorem that is that that things are mixtures of lognormal's.",
                    "label": 0
                },
                {
                    "sent": "If you wanted to read more about backtracking, and in particular see this method of sequential importance sampling used in very interesting real problems can use the art.",
                    "label": 0
                },
                {
                    "sent": "So he asked me this question when I started at Stanford in 1974 and he just now was coming to write volume 4B.",
                    "label": 0
                },
                {
                    "sent": "And if you look on his website introduction to backtracking the art of computer programming volume.",
                    "label": 0
                },
                {
                    "sent": "For pre fascicle 5B it's 100 page.",
                    "label": 0
                },
                {
                    "sent": "Book on backtracking and sequential importance sampling, and I did quite a lot of math about sequential importance sampling that I'm not telling you about, but in in a paper with Sheriff Chatterjee.",
                    "label": 0
                },
                {
                    "sent": "The sample size required an important sampling and it's on the archive or on my my web page which analyzes canus algorithm.",
                    "label": 0
                },
                {
                    "sent": "More detail, let me might well be that this.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is my my last slide so back to the big picture.",
                    "label": 0
                },
                {
                    "sent": "There's a question and I don't know the answer to it, but.",
                    "label": 0
                },
                {
                    "sent": "Collectively, we know more than I do.",
                    "label": 0
                },
                {
                    "sent": "So what kinds of information are available in our Monte Carlo simulations?",
                    "label": 0
                },
                {
                    "sent": "We often use pitifully little because that's all we have time for that, so we think we care about when I look at what I do or what my compatriots do when they analyze their Montecarlo, this whatever statistics they are interested in, and then they might put some test statistics in because the standard way of calibrating is to take a bunch of test statistics and see if they seem to settle down.",
                    "label": 0
                },
                {
                    "sent": "So we often have a handful of functions that we monitor along the path, and so that's some some use that we make of the information that people do.",
                    "label": 0
                },
                {
                    "sent": "Things like computing effective sample size.",
                    "label": 0
                },
                {
                    "sent": "Occasionally you'll see somebody reusing their samples by bootstrapping an.",
                    "label": 0
                },
                {
                    "sent": "That's about all.",
                    "label": 0
                },
                {
                    "sent": "I mean that that that that that I see now there should be a big literature on this, and I only know of 1 paper, and I'm sure I'll learn many more.",
                    "label": 0
                },
                {
                    "sent": "So thank you in advance.",
                    "label": 0
                },
                {
                    "sent": "I know of 1 paper which has a very similar theme, but then when in quite different directions, so laggy Kong Peter Mccullar, Sha Li, Ming an then Nikolai and I don't know Mr Tanz, first name wrote a paper called a theory of statistical models for Monte Carlo integration and was in Bayesian, but I'm sure that's 'cause Peter McCullough would never have his name associated with anything Bayesian.",
                    "label": 0
                },
                {
                    "sent": "But the ideas are somewhat similar.",
                    "label": 0
                },
                {
                    "sent": "That is trying to model.",
                    "label": 0
                },
                {
                    "sent": "Things, but then the problem that they focused on was different.",
                    "label": 0
                },
                {
                    "sent": "This article is a discussion article in the in the RSS and there were many interesting comments in many of those commentators, some of whom are here in the audience, wrote papers as follow-up papers.",
                    "label": 0
                },
                {
                    "sent": "So if you type this in this paper in and then you look on Google Scholar who cited it, you'll find the literature that this is not very much, but that's a way of finding it.",
                    "label": 0
                },
                {
                    "sent": "This it's a starting, it's I'm not the only crazy one.",
                    "label": 0
                },
                {
                    "sent": "If you want to put it that way.",
                    "label": 0
                },
                {
                    "sent": "This story I've just told you is a special case of what I call Bayesian numerical analysis that is.",
                    "label": 0
                },
                {
                    "sent": "You have an integral or a some you want to do, even if you have a complicated formula for it, you don't know what it is.",
                    "label": 0
                },
                {
                    "sent": "So put a prior on.",
                    "label": 0
                },
                {
                    "sent": "Get some data, compute posteriors and use Bayes methods to get improved estimates.",
                    "label": 0
                },
                {
                    "sent": "I wrote a paper about that in a long time ago, in which I traced the history of it back to Ponca, Ray.",
                    "label": 0
                },
                {
                    "sent": "Nowadays it's slightly fashionable under the name of uncertainty quantification, and Jim Berger gave a talk and he said, well, the engineers did it and you know 1960.",
                    "label": 0
                },
                {
                    "sent": "Welp, on Kare did it in 1890 so you know OK and many many other people.",
                    "label": 0
                },
                {
                    "sent": "Well before the engineering literature.",
                    "label": 0
                },
                {
                    "sent": "Stephen Lauer.",
                    "label": 0
                },
                {
                    "sent": "It's and did wonderful work on it in estimating what the force of gravity is in the 1960s, I'm going to say so.",
                    "label": 0
                },
                {
                    "sent": "This paper also, if you look who cites it.",
                    "label": 0
                },
                {
                    "sent": "It was completely unsighted and then all of a sudden it's blossom, and in fact there's a marvelous website whichiscalledprobabilisticnumerics.org and and you can find what literature I know about.",
                    "label": 0
                },
                {
                    "sent": "So the the theme of this talk was.",
                    "label": 0
                },
                {
                    "sent": "You know it would have been natural to call it, you know Bayesian thinking about Monte Carlo, but I don't think you know.",
                    "label": 0
                },
                {
                    "sent": "I think that just thinking is a Bayesian activity, and I think the finetti encouraged us to use what information we have and try to combine that with what data we have in innovative ways.",
                    "label": 0
                },
                {
                    "sent": "This is another little pedal in the in the flower.",
                    "label": 0
                },
                {
                    "sent": "The reason I decided to give this talk is I think many, many people in this audience have noticed.",
                    "label": 0
                },
                {
                    "sent": "Why don't I ever use Bayesian methods when I analyze my Montecarlo data.",
                    "label": 0
                },
                {
                    "sent": "I'll be happy to hear you know examples, references, thoughts, the collective power of this group is is much more than any one of us.",
                    "label": 0
                },
                {
                    "sent": "And thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, first I'm very honored to start a discussion for this first DEFINITY lecture.",
                    "label": 0
                },
                {
                    "sent": "The second thing is, this is the first time when I write my discussion about six months.",
                    "label": 0
                },
                {
                    "sent": "Before the talk, because actually.",
                    "label": 0
                },
                {
                    "sent": "He happens to have this nips workshop last December in in Montreal.",
                    "label": 0
                },
                {
                    "sent": "Which was about probabilistic numerics and was starting.",
                    "label": 0
                },
                {
                    "sent": "Point was Percy's 1988 paper.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "I was invited not as a specialist, but also a skeptic an so my talk was actually a discussion of the pros and cons of probabilistic numerics.",
                    "label": 0
                },
                {
                    "sent": "And so I decided to to depth those those slides.",
                    "label": 0
                },
                {
                    "sent": "Because it's all fits very well.",
                    "label": 0
                },
                {
                    "sent": "Process talk OK.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so I go through four full names, Larry CC and Percy.",
                    "label": 0
                },
                {
                    "sent": "Which all ends by E. The first one is is Larry's constant and this is a problem that has bothered me for for quite awhile.",
                    "label": 1
                },
                {
                    "sent": "So I mean if you have not read Larry's book and and this question is.",
                    "label": 0
                },
                {
                    "sent": "Is exactly this problem of of having a constant, not just 37th digit of pie, but a constant that is entirely defined from the fact that we are dealing with a density, but we don't know him, and so could we analyze this problem from a vision perspective and so they.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Larry put it as a as an example is in his book where.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can come up with a frequentist solution for proximity in C from say, nonparametric estimator of F. So F had over G is an estimator of C, and if you take more data or more simulations, you end up with the proper approximation to see and so if you turn.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "Two abbasian resolution.",
                    "label": 0
                },
                {
                    "sent": "So if naive Bayesian approaches to say, well, I put a prayer and see because I'm basean.",
                    "label": 0
                },
                {
                    "sent": "And so if you service with this native prayer and see you end up nowhere because your data say your simulation.",
                    "label": 0
                },
                {
                    "sent": "Doesn't transfer into information about C per say.",
                    "label": 0
                },
                {
                    "sent": "I mean it's a simulation from F and so you have to go around the corner to come up with an estimation or see.",
                    "label": 0
                },
                {
                    "sent": "But if you write as as a naive version.",
                    "label": 0
                },
                {
                    "sent": "Which Larry pretends to be in in this.",
                    "label": 0
                },
                {
                    "sent": "In this text you end up nowhere, OK?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so those outcomes I made six months ago that maybe I evolve a little bit about it, but.",
                    "label": 0
                },
                {
                    "sent": "The first interpretation is that well.",
                    "label": 0
                },
                {
                    "sent": "It's not a statistical problem because there is no likelihood per say if you write it that way OK, and so it is not.",
                    "label": 1
                },
                {
                    "sent": "There is no data from your simulation about C, so if you get take it at face value, you are not analyzing something that is that is statistical and so you have to go somewhere farther to to come up with a statistical solution, which is a way of probabilities numeriques.",
                    "label": 0
                },
                {
                    "sent": "Namely, that you have to model F. OG through prior rather than just the mere sees that by itself is isolated and cannot be.",
                    "label": 0
                },
                {
                    "sent": "Informed through simulations.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so it it relates 2 two largest part of problem and in that connects with Percy stock that if you notice but the the new solution for the number of path is 1 harmonic nearest mirror in the sense that this is an average of one over probability or likelihood.",
                    "label": 0
                },
                {
                    "sent": "And in that case in this is a finite universe there is no problem of infinite violence but still using a nominee communis tumor means that you.",
                    "label": 0
                },
                {
                    "sent": "Have all subjected to this huge jumps by a few small values of P of gamma that that takes one of her peers gamma to be to be very large.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's maybe one reason why it's it's hard to come up with a solution that how many Queens are not the best Monte Carlo estimate.",
                    "label": 0
                },
                {
                    "sent": "If you look at that at face value without the shrinking or regularization approach of of probabilities numerics OK and that relates to all the problems, I don't want to mention too much here, but somewhat.",
                    "label": 0
                },
                {
                    "sent": "And that's another worry that that connects to to to process to get when we approach Monte Carlo, the first thing you want to to see is is unbias knus.",
                    "label": 0
                },
                {
                    "sent": "In that kind of creates a huge tree that hides a Forester of problems that by trying to stick to unbiasedness as we shouldn't invasions.",
                    "label": 0
                },
                {
                    "sent": "I just cut all self from from more efficient solutions.",
                    "label": 0
                },
                {
                    "sent": "So I mean massive prediction of simulations to reach a proper estimators.",
                    "label": 0
                },
                {
                    "sent": "Checking turn business is not necessary and efficient and efficiency.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then that that connects with something that has been part of the of the folklore, because never really published, which is Charlies regression.",
                    "label": 0
                },
                {
                    "sent": "And so this is Charlie guy, huh?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We came up with an approach to.",
                    "label": 0
                },
                {
                    "sent": "Constant estimation.",
                    "label": 0
                },
                {
                    "sent": "So this is typical Monte Carlo integration problem as a true statistical problem through regression.",
                    "label": 0
                },
                {
                    "sent": "So if you have a collection of of unknown normalizing constant associated with densities, and if you produce simulations from all of those densities, if you merge them together, you can create a likelihood that involves these unknown numbers in constant.",
                    "label": 0
                },
                {
                    "sent": "That is, a logistic regression.",
                    "label": 0
                },
                {
                    "sent": "That is, you merge all your samples and you try to reallocate each simulation to one of the density.",
                    "label": 0
                },
                {
                    "sent": "So this is hiding some of the information you had as a beginning, but through this modeling you do end up with estimates of your constants, which is a bit of a of a miracle, but it it has a very interesting appeal that.",
                    "label": 0
                },
                {
                    "sent": "It brings a constant into the statical model.",
                    "label": 0
                },
                {
                    "sent": "And so this isn't a non vision solution, but if you you can derive vision versions of that by putting an extra prior.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can start being up as testicle.",
                    "label": 0
                },
                {
                    "sent": "More global cynical approach through service modeling and somebody needs a paper by Guy or was was never published.",
                    "label": 0
                },
                {
                    "sent": "But it's it's all is still available and it it it's it's still known in the community.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will mention much can get hold now because I'm connecting.",
                    "label": 0
                },
                {
                    "sent": "Connecting with that later, but this is actually a larger collection of of approaches through partition modeling and partition functions that does the same thing.",
                    "label": 0
                },
                {
                    "sent": "That kind of hides part of the information is original model and then RE estimated as a statistical statistical approach.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I'll skip that.",
                    "label": 0
                },
                {
                    "sent": "And then we arrived.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To Shelley's Emily.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "A set of slides that that Shirley made for an arson workshop I attended, where I started to understand much better the 2003 paper.",
                    "label": 0
                },
                {
                    "sent": "And of course, I mean you cannot look at the detail.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alphabet.",
                    "label": 0
                },
                {
                    "sent": "This weather explanation of the Genesis be discussion paper where.",
                    "label": 0
                },
                {
                    "sent": "Can't get at all.",
                    "label": 0
                },
                {
                    "sent": "Explain how to set again a constant estimation problem.",
                    "label": 0
                },
                {
                    "sent": "As a statistical model and ending up as an Emily Ware.",
                    "label": 1
                },
                {
                    "sent": "It wasn't me parametric Emily, so I mean I will not read the detail, but there is this connection.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "With Charlie's solution.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And yeah, the end point is that you can estimate density or constant as setting a maximum likelihood similar on a purely numerical problem.",
                    "label": 0
                },
                {
                    "sent": "And those pictures were made my by my daughter when I discuss the paper at the.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Society.",
                    "label": 0
                },
                {
                    "sent": "And again, this is a something very surprising that you started as an Oracle problem and then you said it in a different way so that you end up with the statistical solution to the point of producing feature information for the precision and and some solutions of partitioning that are a form of row Blackwall isation.",
                    "label": 0
                },
                {
                    "sent": "And then we can.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To to to the last point, which is a purse is numeriques Ann.",
                    "label": 0
                },
                {
                    "sent": "And this is a paper of 1988 that I remember discussing with George Casella in at about that time.",
                    "label": 0
                },
                {
                    "sent": "Well, actually we're waiting for his car to be repaired and we were sitting in a cafe and we we started discussing that as something very exciting at the end of the of the cafe.",
                    "label": 0
                },
                {
                    "sent": "We couldn't have better ideas, but we saw the idea very, very exciting.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then a few years went through and this was not followed by by something very very conclusive.",
                    "label": 0
                },
                {
                    "sent": "Until this population numeric probability numerics.",
                    "label": 0
                },
                {
                    "sent": "Come in and she came more from the engineering background and machine learning and you might make my colleague at Warwick module me starting promoting the use of basean and probabilistic modeling of functions as a way to improve considerably the resolution of integrals or partial differential equations or optimization problems.",
                    "label": 0
                },
                {
                    "sent": "And so I mean, I want to go into the describing what it is, but usually there is a Gaussian process somewhere in the picture, so you can see the connection with machine learning where that's Gaussian process has to be used at some point.",
                    "label": 0
                },
                {
                    "sent": "And then digital prior on an object of any complexity an any structure to function that you want to integrate.",
                    "label": 0
                },
                {
                    "sent": "And this Goshen process prior is merged with simulations or data to return a posterior and real posterior in the sense we understand posteriors in a functional space that.",
                    "label": 0
                },
                {
                    "sent": "Gives you both estimators for the functions into all.",
                    "label": 0
                },
                {
                    "sent": "The differential equation an impressive imprecision.",
                    "label": 0
                },
                {
                    "sent": "Evaluation as as we should have.",
                    "label": 0
                },
                {
                    "sent": "OK, so there is availability assessment.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. And.",
                    "label": 0
                },
                {
                    "sent": "Of course, this is somewhat arbitrary.",
                    "label": 0
                },
                {
                    "sent": "While Goshen process, I mean it, it is very concentrated in the space of all functions.",
                    "label": 0
                },
                {
                    "sent": "But this is not something you have to believe.",
                    "label": 0
                },
                {
                    "sent": "As something from nature is just a tool to model a huge unknown into producing better estimates.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "And I want to take all the time, but.",
                    "label": 0
                },
                {
                    "sent": "Let me move to my last slide.",
                    "label": 0
                },
                {
                    "sent": "We had another one, sorry here.",
                    "label": 0
                },
                {
                    "sent": "That I mean we can discuss some aspects of this as as being arguably arguable but.",
                    "label": 0
                },
                {
                    "sent": "For instance, what sense do you do put on the probabilistic modeling on functions?",
                    "label": 0
                },
                {
                    "sent": "And this notion that.",
                    "label": 0
                },
                {
                    "sent": "Functional species are very large, but there are ways that.",
                    "label": 0
                },
                {
                    "sent": "You can you can return something rather than nothing in a reasonable time, like when you move from a billion simulations to 1000 simulation.",
                    "label": 0
                },
                {
                    "sent": "So if you can produce some more results around coherence, because again we are in spaces where I'm not sure Bayesian inference is always coherent, that that's a big plus that we should pursue, and the community is growing as demonstrated by this NIPS workshop last year.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let me put a few personal worry about evolution and the shift about Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "A certain meant and what how we could conduct Monte Carlo and arises.",
                    "label": 1
                },
                {
                    "sent": "There is one thing that we always forget that when we try to approximate an integral, which is that no matter how complex the SpaceX is, where we conduct the interval interval as years into or is a is a real number.",
                    "label": 0
                },
                {
                    "sent": "So we move from a very large space or re complex space onto the reline an often we just don't see that part.",
                    "label": 0
                },
                {
                    "sent": "We rush into simulation, say from a certain density F and only later project onto the real line.",
                    "label": 0
                },
                {
                    "sent": "It would be an improvement if we could.",
                    "label": 0
                },
                {
                    "sent": "If we could conduct the alternative analysis that by getting around the curse of dimensionality, try to project 1st and then run the simulation and there is an illustration.",
                    "label": 1
                },
                {
                    "sent": "Not completely clear to me, but with nested sampling, nested sampling.",
                    "label": 1
                },
                {
                    "sent": "Is this technique introduced by John's killing to approximate the marginal likelihood invasion inference and one very nicest part of nested sampling.",
                    "label": 0
                },
                {
                    "sent": "Is the concept that it is a 1 dimensional integral, and so he starts Johnston stores by reducing the problem to a 1D problem of the distribution of.",
                    "label": 0
                },
                {
                    "sent": "This likelihood under the prior and the likelihood is a 1D object.",
                    "label": 0
                },
                {
                    "sent": "After the simulation gets a bit hairy and an increase size and not necessarily very efficient, but the summation is under the constraints and the likelihood is as high values, which is a projection in in dimension one, and so in that direction.",
                    "label": 0
                },
                {
                    "sent": "I think there are many ways to explore and to construct estimators that that would benefit considerably to the to the Monte Carlo issue.",
                    "label": 0
                },
                {
                    "sent": "And so let me conclude by saying Percy for his talk and for his numerous contributions to our field that we would explore for years and years to come.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Common that we think that we use in summarizing Markov chain Monte Carlo results and things of that sort of any kind of Carlo results that that are used to support Bayesian analysis.",
                    "label": 0
                },
                {
                    "sent": "That's my primary interest.",
                    "label": 0
                },
                {
                    "sent": "In many cases we have better options available, but it's remarkable how often they're not used in a particular case.",
                    "label": 0
                },
                {
                    "sent": "In point is the idea of conditioning or what we've come to.",
                    "label": 0
                },
                {
                    "sent": "Call Rao Blackwell Isation, which is pretty much always possible if you're using something based on full conditionals.",
                    "label": 0
                },
                {
                    "sent": "But it's you know if you if you just look at papers in which people show plots of marginal densities that are a little bit bumpy, you know they plotted a kernel density estimate rather than something based on taking advantage of the available conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "But there's some good reasons.",
                    "label": 0
                },
                {
                    "sent": "Number of good number of good, maybe some not so good reasons why people do this.",
                    "label": 0
                },
                {
                    "sent": "Keeping it simple is useful.",
                    "label": 0
                },
                {
                    "sent": "And in particular, sorry.",
                    "label": 0
                },
                {
                    "sent": "Let's get this right.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In terms of thinking about sort of priorities in, in, in, in when we're writing a paper if it's in a particular scientific context, that's by far the most important thing that that we want to spend our limited number of pages talking about, then the models and prior distributions that we're going to use need some time.",
                    "label": 1
                },
                {
                    "sent": "What's inappropriate.",
                    "label": 0
                },
                {
                    "sent": "Summary of the posterior distribution?",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "If it's a symmetric distribution, Amin is fine, but if it's heavily skewed, want to focus on the median.",
                    "label": 0
                },
                {
                    "sent": "Then focusing on maybe the supporting methodology for doing the computation simulation, typically for us and only at the last stage do we want to have to discuss and defend the output summary method an at that point.",
                    "label": 1
                },
                {
                    "sent": "Well, if expires good enough, let's just stick with.",
                    "label": 0
                },
                {
                    "sent": "That is, I think, often the thing we do.",
                    "label": 0
                },
                {
                    "sent": "Another factor is the software we work with.",
                    "label": 0
                },
                {
                    "sent": "If you're using something like bugs or jancso your simulation.",
                    "label": 0
                },
                {
                    "sent": "That's going to know about.",
                    "label": 0
                },
                {
                    "sent": "Conditional distributions and things of that sort.",
                    "label": 1
                },
                {
                    "sent": "But if you then pass on the results to something like Coda and BOA, that information is not transmitted about what the full conditionals are.",
                    "label": 0
                },
                {
                    "sent": "You can write them down yourself, of course, and implement them, but.",
                    "label": 0
                },
                {
                    "sent": "It's not only is it more work, it's also another thing you could get wrong.",
                    "label": 0
                },
                {
                    "sent": "So again, if it's good enough, that's a good big reason why we do tend to stick with these simpler things.",
                    "label": 0
                },
                {
                    "sent": "In",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, the context where where it is common to use Bayesian methods.",
                    "label": 0
                },
                {
                    "sent": "Situations where we have maybe very strong information for some simulation settings, but nothing in between.",
                    "label": 0
                },
                {
                    "sent": "Classic examples are computer experiments where you you for certain parameter settings you run expensive simulations and get data in between.",
                    "label": 0
                },
                {
                    "sent": "You have nothing but you may be willing to assume smoothness, so you use some sort of Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Surface priors to allow you to then compute some, simulate as some intermediate results together with uncertainties.",
                    "label": 0
                },
                {
                    "sent": "This sort of numerical integration ideas that Percy mentioned that Chris talked a little about the numerical Bayesian analysis ideas are similar in that that you have good information that points and you fill things in in between.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Looking a little bit at the self, avoiding random walk to help me understand what's going on here.",
                    "label": 0
                },
                {
                    "sent": "I wrote a little.",
                    "label": 0
                },
                {
                    "sent": "My own version of this, and I'm not sure I got it quite right in the sense that I have a different length distribution from the one that that Percy described as a bit lower, I am confident that my method is producing.",
                    "label": 0
                },
                {
                    "sent": "A process that that could potentially hit an all of the self, avoiding paths between the two corners and any such process is going to give you the right estimate.",
                    "label": 0
                },
                {
                    "sent": "I might not be using exactly the right one, I didn't have a chance to go back and look at the details of canoes approach, but I think qualitatively still little what I found will apply.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, at least with my simulation I get a distribution of those.",
                    "label": 0
                },
                {
                    "sent": "Those negative log probabilities that is not normal, but could well be approximated as a mixture of normals.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we do have this problem that the estimate is.",
                    "label": 1
                },
                {
                    "sent": "Involved as some of the exponentials of these these guys, and so the.",
                    "label": 0
                },
                {
                    "sent": "This the small values just don't contribute very much.",
                    "label": 0
                },
                {
                    "sent": "In fact what I have here is is the.",
                    "label": 0
                },
                {
                    "sent": "The red curve is a CDF of this.",
                    "label": 1
                },
                {
                    "sent": "The black curve shows the percentage contribution to the sum that comes from the different values cumulatively.",
                    "label": 0
                },
                {
                    "sent": "So basically nothing is accumulated until you get down to there and another way of saying it is is that.",
                    "label": 0
                },
                {
                    "sent": "The 99.5% of the final estimate comes from the upper half percent of the distribution, so.",
                    "label": 1
                },
                {
                    "sent": "In terms of modeling from my approach, at least if I use a model for this, it's not going to do very much for me because that's really what I have to get right way.",
                    "label": 0
                },
                {
                    "sent": "Extreme upper tail, and that's very difficult to model properly, at least for me and I have to think about what can I do to convince myself that I've got a good model and then can I convince a referee that this is going to be a good thing to do?",
                    "label": 0
                },
                {
                    "sent": "So definitely modeling is very good if we can get things into the middle of the distribution where we can use our models affectively, the tails, it could be a little trickier.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is easy in this case just to throw CPU cycles at things, so I ran 100 million observations in parallel.",
                    "label": 0
                },
                {
                    "sent": "Took only a little over an hour and when I matched those up into 100 batches of a million each, and computed estimates from each, I get the.",
                    "label": 1
                },
                {
                    "sent": "This distribution of the estimates take the logs of those estimates, and I get something that's still skewed.",
                    "label": 0
                },
                {
                    "sent": "But at least now we're in.",
                    "label": 0
                },
                {
                    "sent": "A situation where our final estimate, which is going to be around there, are mean our overall mean is in the middle of the distribution and I would feel comfortable trying to model this situation to try and extract more more information from it.",
                    "label": 0
                },
                {
                    "sent": "So the one point I think I drew from from my experiments is applying modeling.",
                    "label": 0
                },
                {
                    "sent": "Once you've done some batching, may be a useful thing to do in some situations.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just to finish up.",
                    "label": 0
                },
                {
                    "sent": "It's very it's very useful to think about trying to take advantage of the theory that we have or just things that we can observe by looking at some of the structure of our data and using modeling to help allow us to perhaps get away with smaller sample sizes.",
                    "label": 0
                },
                {
                    "sent": "And there's really nice ideas about that, and in the process to work.",
                    "label": 0
                },
                {
                    "sent": "I'm a little less confident if if things really are dependent on tails and needing require tail modeling, which is just something I at least don't know how to do terribly well, matching maybe something that helps.",
                    "label": 0
                },
                {
                    "sent": "But and of course, one thing to think about is can you change the simulation so it spends more time in the tail?",
                    "label": 1
                },
                {
                    "sent": "The classic idea underlying important sampling.",
                    "label": 1
                },
                {
                    "sent": "Thanks for a great talk.",
                    "label": 0
                }
            ]
        }
    }
}