{
    "id": "4ouu46fgyj66bj6i2gaffoi3slhwwdyf",
    "title": "Rapidly Integrating Services into the Linked Data Cloud",
    "info": {
        "author": [
            "Mohsen Taheriyan, University of Southern California"
        ],
        "published": "Dec. 3, 2012",
        "recorded": "November 2012",
        "category": [
            "Top->Computer Science->Semantic Web->Linked Data->Linked Data Cloud"
        ]
    },
    "url": "http://videolectures.net/iswc2012_taheriyan_data_cloud/",
    "segmentation": [
        [
            "My name is Nelson Tyrion an I'm a PhD student at University of Southern California.",
            "The title of my Talk is rapidly integrating services into the Link Data Cloud and this is actually a joint work at Information Science Institute of University of Southern California with my PhD advisor Craig Knoblock, and two other research faculties, Pedro Szekely and Jose Luis and Bit."
        ],
        [
            "So two day we have a huge amount of data available on the link data cloud, But the problem with this huge amount of data is large.",
            "Part of them are not current data.",
            "There are static data.",
            "For example, if we take a look to what we have about the downtown Los Angeles extracted from the DBPR, you can see that the population field is not up to date.",
            "Also we don't have the info."
        ],
        [
            "Mention about the life better."
        ],
        [
            "I don't have the information about the upcoming events, we don't know."
        ],
        [
            "About the Twitter feeds.",
            "So the main question is how we can get this information?",
            "Where can we get this information?",
            "So as you can guess."
        ],
        [
            "This information is coming from the web APIs and web services.",
            "There are lots of services and APIs on the web and they provide up-to-date data for us.",
            "And it is interesting to see that the number of these APIs is growing every day."
        ],
        [
            "If you take a look to this graph, you can see the number of APIs indexed by programmable website during the last year from 2011 to 2012 is 2 times of the total number of API's.",
            "Index it during the previous years and this statistics show that the.",
            "Most part of these APIs are rest services, and they mostly use the HTTP get methods.",
            "I'd like to get your attention to this figure.",
            "The right bottom corner of the slide, and this is the motivation of my attack.",
            "As you can see, the data format of the most of the APIs are XML and Jason, and as October 2012 we have only 65 API's that are using the audio."
        ],
        [
            "So for many people, applications and mashup that are dealing with the link data, it's not easy to liberate these API's to get the information they want.",
            "So the problem is that in one side we have a growing link data cloud and in other side we have lots of API's and services that don't consume link data and they also don't produce link data so they cannot contribute to the link data Club.",
            "So let's take a closer look to the problem."
        ],
        [
            "Suppose that we have some RDF data about the geographical point on the map.",
            "We know the latitude and longitude of the point and we will.",
            "We are interested to get information about the neighborhood area.",
            "We want to know the neighborhood named their nearby city.",
            "The country in which the point is located.",
            "So the first challenge we have is how to find this API is not a trivial task because for most of the API's we only have a textual description.",
            "And these textual descriptions only support the keyboard based search.",
            "Now suppose that we somehow know how to find the API.",
            "The second problem is that.",
            "Most of the API's don't."
        ],
        [
            "Consume link data and they don't produce link data.",
            "So if we want to invoke this API on RDF data, first we have to lower the data.",
            "The RDF data and come and build the invocation URL and then get the XML or Jason back and leave the XML data to create RDF data and link the RDF data to the input.",
            "So this is exactly so we have two problems here.",
            "First, finding the desired API and 2nd communicating the API with RDF data, and this is exactly where the semantic Web semantic service descriptions come into play.",
            "But as you know, writing this semantic descriptions for services is a painful task, because in addition to that, it takes much time.",
            "We have to know some knowledge about the semantic web.",
            "Technologies like RDF Sparkle, and the problem gets worse if you think about the lowering and lifting because we have to provide separate instructions to do the lowering and lifting.",
            "We introduce an approach in which the user interactively build the semantic descriptions for services, and then system automatically creates a linked API by linked API.",
            "We mean services that directly consume and produce link data.",
            "The main contribution of our work is that.",
            "Building semantic descriptions is really fast, and the user doesn't get involved in formalisms required to write these descriptions."
        ],
        [
            "This is the outline for the rest of the talk.",
            "First, I explain different steps of our approach to beat the link API's and then I go to the evaluation section and then compare our approach with other existing solutions.",
            "So the."
        ],
        [
            "First part of the approach, which is the central part, is building semantic model for API's.",
            "So what do we mean by building a semantic model?",
            "What is actually a semantic model of the API?"
        ],
        [
            "So let's go back to our example.",
            "We have a neighborhood example.",
            "We have a neighborhood API that takes the latitude and longitude and provides the city name, the neighborhood name Central Park, and the country name.",
            "And we want to express the functionality of this API using the using the domain ontology and in this case the domain Ontology is a Geo name ontology or WGS ontology.",
            "So the first step is to identify the data type of the service input and output attributes.",
            "For example, the first parameter of the API is latitude of a feature.",
            "The second parameter is longitude of the feature.",
            "The name of the neighborhood is the name of the future.",
            "So would it be enough to only assign types to the attributes?",
            "In many cases?",
            "No, we need to extract the relationship between the attributes.",
            "For example, here we want to know what is the relation between these two feature.",
            "In the correct model, this feature is the name the Central Park is a neighbor of the point.",
            "So the goal of semantic modeling.",
            "Is to create to create a model of the API that not only includes the data types of the input and output attributes, but also includes the relationship between the attributes.",
            "People in the day."
        ],
        [
            "Always community are more familiar with this kind of rules, Datalog rules and this rule exactly represented same semantics.",
            "So now I'm.",
            "No, I describe how we create such model in our approach."
        ],
        [
            "We already had a tool, a data integration tool called Karma and we use this tool to import source static sources from relational databases.",
            "Excel file CSV files.",
            "And to model them and publish RDF data, doing some different tasks to do the integration like data cleaning integration.",
            "So what we did here is to extend this tool to add the functionality to model the API's.",
            "So the input to the system.",
            "The system has two inputs.",
            "First examples of the API request URL's and you know these examples can be found in the documentation pages of the API's.",
            "And the second input is the domain ontology, and different users can import different ontology and create the model of APIs based on their own needs.",
            "The output is a semantic model that that I show you.",
            "I showed you in the previous slide."
        ],
        [
            "So first user provides some examples of the invocation URLs.",
            "Here we have 3 examples of the neighborhood API.",
            "So from this URL's system extracts the input parameters and their values.",
            "So we have latitude, longitude and username as the input parameters.",
            "Next, the system for each invocation actually invokes the API, takes the XML or Jason response, and extracts output parameters and the output values, and then concatenates the output values to the input values.",
            "So in this case we have only one output record for each invocation, but if we have multiple outputs, the system shows the data in nested structure."
        ],
        [
            "So once we constructed a table of the input and output values, we can treat this table as an aesthetic source.",
            "We can model it like other sources, so we use.",
            "We train a CRF veterana, conditional random fields model that learns from the assignment user has done in previous sessions to assign a semantic type to each attribute of the service and the semantic type can be an ontology class or a data property with its domain.",
            "So for example here the Latitude column would be elected to the feature.",
            "It is a it is a data property plots, the domain and we do the modeling for other attributes.",
            "So the last three columns are name of the features.",
            "As I said before, the next step of the semantic modeling is to extract the relationships."
        ],
        [
            "I'm not going to go through details of the algorithm, but the general idea is that from the assigned semantic types and the graph of the ontology, we construct another graph that defines all possible links between the semantic types.",
            "And in this graph we select the minimal tree that connects all the semantic types.",
            "And we consider this minimal tree as the initial model of the API."
        ],
        [
            "If the semantic types are wrong or the suggested links are not correct, the user can change can refine the model through a graphical user interface."
        ],
        [
            "And this is the final model of the API in our system.",
            "So we have a.",
            "We have a feature input feature which has a latitude and longitude.",
            "And it has a neighborhood name Central Park, and this neighborhood is nearby Manhattan City and the parent country is United States.",
            "So once we construct this semantic model."
        ],
        [
            "We have to be able to actually use this API.",
            "We have to formalize the model we have to generate the API, an API description."
        ],
        [
            "And in this step we introduce new RDF vocabulary, a simple ontology that reuses existing vocabulary, like address a stable URL.",
            "And this vocabulary captures both the syntax and the semantics of the API and we will see soon how Karma explores this vocabulary to automatically do the lowering and lifting.",
            "So let's see an example."
        ],
        [
            "This is a small part of our semantic model.",
            "So this is the input feature with latitude attribute and we have a neighborhood output here.",
            "First we create an ID for the service that we put the service address.",
            "The HTTP method is get and the name of the service neighborhood.",
            "It has one input.",
            "Latitude, so we create an input attribute is name.",
            "The attribute name is latitude and the grounding value is P1 and this grounding value shows the location of these Maps.",
            "This attribute to the parameter of the API.",
            "And this is the service out.",
            "So for each semantic type, we create a stable URL Atom for the Gray boxes.",
            "We create the class Atom.",
            "So for the input feature we create a class at home and this simply says.",
            "We have a variable V1 and it's typing and its type is a Geo name feature.",
            "For each data property we created property at home and the difference between property item and class Atom is a.",
            "Is that the property Atom has two arguments.",
            "So here we have a property Atom which represents the Latitude relationship.",
            "The first argument is V1 and the second argument is the latitude input.",
            "And we continue the modeling.",
            "The last link is the relationship between the input and output, so we have a neighborhood.",
            "We have a neighborhood relation between the input and output feature, so we have a property Atom.",
            "The relationship is never.",
            "The first argument is we won and the second argument is with.",
            "So.",
            "So far we created an RDF representation of the service.",
            "Description Once we publish this service descriptions, we can use the sparkle query to find the services we want and if you remember, this was the first challenge we had.",
            "For exam."
        ],
        [
            "So we want to get the services that take latitude and longitude and produce the neighborhood information.",
            "We can write a sparkle query to find this service so this query says we want to service that has a feature with latitude and longitude as input and it generates the neighborhood information."
        ],
        [
            "And the last part of the model is actually to deploy the link API.",
            "As I said before from the link API we mean the services that directly consume and produce link data."
        ],
        [
            "So we have a web server and this web server offers a rest interface and users can interact with this server to invoke the API's.",
            "If you invoke the link API with the get request.",
            "The server interacts with the repository to return the RDF description of the API.",
            "But to feed the RDF data to the API, the user has to issue a post request so the user generates the post, requires, puts his RDF data inside the body of the Post, request.",
            "The Karma server interacts with the repository to get the description and uses this users that description to automatically lower the data and then build the invocation.",
            "You are when we get the XML or Jason data back.",
            "We used again from the service descriptions to automatically leave the data and linked output input."
        ],
        [
            "So let's see the intuition behind automatically the automatic lowering and lifting.",
            "So this is the input audio.",
            "The input or did we have a feature with the latitude and longitude?",
            "And this is part of the service description.",
            "This is the semantic input model, so we use the graph of the input model and the graph of the audio to map the attributes and extract the URL of the attributes.",
            "So we know that.",
            "The input attribute in that has the value like 14th.",
            "Next we use the grounding property to map the input attributes of the service to the parameters of the API invocation and then use it.",
            "We use the service address to substitute the values into the parameters and building location URL."
        ],
        [
            "We have a similar task in lifting.",
            "We use the name of the attribute in XML output.",
            "To extract the UI of the output attributes and we use the semantic model of the output to build the RDF graph.",
            "As you can see here, this was our input and the RDF data is linked to the input, so we have this resource which has a neighbor Woodside and it's nearby the Queen City."
        ],
        [
            "Next eval."
        ],
        [
            "Nation we evaluated our approach by modeling 11 services from June named API.",
            "And as you can see, with only a few examples of service invocation URLs that user provides the system in a short amount of time, we create a link API.",
            "So the key observation here is that Karma enables users to rapidly build link API's, and we spent totally around 40 minutes to build such to model all the APIs."
        ],
        [
            "There are other approaches to create semantic service descriptions.",
            "Link services proposed in 2010, but Petrachi and Dominic.",
            "They propose a minimal service model, is simple ontology to annotate the input and outputs of the service, and publishes the service description into the link data cloud.",
            "But the, but because the vocabulary is limited, we cannot represent the relationship between the attributes.",
            "There are some approaches based on this partial graph patterns like link data services and link open services.",
            "They use a sparkle graph pattern to represent the input and output.",
            "Because they use the graph pattern, they can model the relationships, but the discovery of services is not as straightforward because there is no standard facility to query over this partial graph pattern.",
            "But another one is rest.",
            "This test uses the entry logic rules to to capture the functionality of the API."
        ],
        [
            "But what differentiates our approach, from all existing approaches is that in Karma users semi automatically built the semantic descriptions an user doesn't require to have expertise in semantic web technologies like RDF or Sparkle."
        ],
        [
            "Same conclusion be introduced an approach to build or rich semantic model for services and to publish semantic search descriptions into the link data cloud or descriptions provide strong support for discovery and composition, and we could use those descriptions to rapidly build linked APS."
        ],
        [
            "So in the future we are interested to apply your approach to rest like URLs.",
            "If you remember first part of the approach was extracting the input parameters from the invocation you are in.",
            "Invocation URLs like this, extracting the input parameters is not straightforward because there is not a standard pattern to do this, But if user provides more examples of the invocation URLs, we can find the static part of the URL and to see what is the actual input.",
            "So the next part is the next thing that we want to do is composing data and services.",
            "We already have a mediator system that rewrites the query as queries over other sources.",
            "So.",
            "Suppose that we have a service.",
            "It can be a Google Geocoding API that takes the address and provides the, decomposes the actress into city at state and zip code.",
            "We have another service that takes a city in this state and provides the live weather.",
            "We have another service too.",
            "To give the nearby hotels and restaurants.",
            "So if we load some data like upcoming events in Karma, we can do the composition to get the more information to provide more information for the user like the.",
            "Weather and hotels."
        ],
        [
            "For them or For more information like paper, software and demos, you can go to the website isi.edu integration slash integration slash Karma.",
            "We wanted to show a demo of the system in the demo session, but for me but we missed the deadline.",
            "But the good news is that we created a short YouTube video you can download that from the website that show and this video demonstrates how karma creates such linked APIs.",
            "Thanks for your attention and I would like to take your questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Nelson Tyrion an I'm a PhD student at University of Southern California.",
                    "label": 0
                },
                {
                    "sent": "The title of my Talk is rapidly integrating services into the Link Data Cloud and this is actually a joint work at Information Science Institute of University of Southern California with my PhD advisor Craig Knoblock, and two other research faculties, Pedro Szekely and Jose Luis and Bit.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So two day we have a huge amount of data available on the link data cloud, But the problem with this huge amount of data is large.",
                    "label": 0
                },
                {
                    "sent": "Part of them are not current data.",
                    "label": 0
                },
                {
                    "sent": "There are static data.",
                    "label": 0
                },
                {
                    "sent": "For example, if we take a look to what we have about the downtown Los Angeles extracted from the DBPR, you can see that the population field is not up to date.",
                    "label": 0
                },
                {
                    "sent": "Also we don't have the info.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mention about the life better.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I don't have the information about the upcoming events, we don't know.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About the Twitter feeds.",
                    "label": 0
                },
                {
                    "sent": "So the main question is how we can get this information?",
                    "label": 0
                },
                {
                    "sent": "Where can we get this information?",
                    "label": 0
                },
                {
                    "sent": "So as you can guess.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This information is coming from the web APIs and web services.",
                    "label": 1
                },
                {
                    "sent": "There are lots of services and APIs on the web and they provide up-to-date data for us.",
                    "label": 0
                },
                {
                    "sent": "And it is interesting to see that the number of these APIs is growing every day.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you take a look to this graph, you can see the number of APIs indexed by programmable website during the last year from 2011 to 2012 is 2 times of the total number of API's.",
                    "label": 0
                },
                {
                    "sent": "Index it during the previous years and this statistics show that the.",
                    "label": 0
                },
                {
                    "sent": "Most part of these APIs are rest services, and they mostly use the HTTP get methods.",
                    "label": 0
                },
                {
                    "sent": "I'd like to get your attention to this figure.",
                    "label": 0
                },
                {
                    "sent": "The right bottom corner of the slide, and this is the motivation of my attack.",
                    "label": 0
                },
                {
                    "sent": "As you can see, the data format of the most of the APIs are XML and Jason, and as October 2012 we have only 65 API's that are using the audio.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for many people, applications and mashup that are dealing with the link data, it's not easy to liberate these API's to get the information they want.",
                    "label": 0
                },
                {
                    "sent": "So the problem is that in one side we have a growing link data cloud and in other side we have lots of API's and services that don't consume link data and they also don't produce link data so they cannot contribute to the link data Club.",
                    "label": 0
                },
                {
                    "sent": "So let's take a closer look to the problem.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Suppose that we have some RDF data about the geographical point on the map.",
                    "label": 0
                },
                {
                    "sent": "We know the latitude and longitude of the point and we will.",
                    "label": 0
                },
                {
                    "sent": "We are interested to get information about the neighborhood area.",
                    "label": 0
                },
                {
                    "sent": "We want to know the neighborhood named their nearby city.",
                    "label": 0
                },
                {
                    "sent": "The country in which the point is located.",
                    "label": 0
                },
                {
                    "sent": "So the first challenge we have is how to find this API is not a trivial task because for most of the API's we only have a textual description.",
                    "label": 1
                },
                {
                    "sent": "And these textual descriptions only support the keyboard based search.",
                    "label": 0
                },
                {
                    "sent": "Now suppose that we somehow know how to find the API.",
                    "label": 0
                },
                {
                    "sent": "The second problem is that.",
                    "label": 0
                },
                {
                    "sent": "Most of the API's don't.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Consume link data and they don't produce link data.",
                    "label": 0
                },
                {
                    "sent": "So if we want to invoke this API on RDF data, first we have to lower the data.",
                    "label": 0
                },
                {
                    "sent": "The RDF data and come and build the invocation URL and then get the XML or Jason back and leave the XML data to create RDF data and link the RDF data to the input.",
                    "label": 0
                },
                {
                    "sent": "So this is exactly so we have two problems here.",
                    "label": 0
                },
                {
                    "sent": "First, finding the desired API and 2nd communicating the API with RDF data, and this is exactly where the semantic Web semantic service descriptions come into play.",
                    "label": 0
                },
                {
                    "sent": "But as you know, writing this semantic descriptions for services is a painful task, because in addition to that, it takes much time.",
                    "label": 0
                },
                {
                    "sent": "We have to know some knowledge about the semantic web.",
                    "label": 0
                },
                {
                    "sent": "Technologies like RDF Sparkle, and the problem gets worse if you think about the lowering and lifting because we have to provide separate instructions to do the lowering and lifting.",
                    "label": 0
                },
                {
                    "sent": "We introduce an approach in which the user interactively build the semantic descriptions for services, and then system automatically creates a linked API by linked API.",
                    "label": 0
                },
                {
                    "sent": "We mean services that directly consume and produce link data.",
                    "label": 0
                },
                {
                    "sent": "The main contribution of our work is that.",
                    "label": 0
                },
                {
                    "sent": "Building semantic descriptions is really fast, and the user doesn't get involved in formalisms required to write these descriptions.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the outline for the rest of the talk.",
                    "label": 0
                },
                {
                    "sent": "First, I explain different steps of our approach to beat the link API's and then I go to the evaluation section and then compare our approach with other existing solutions.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First part of the approach, which is the central part, is building semantic model for API's.",
                    "label": 0
                },
                {
                    "sent": "So what do we mean by building a semantic model?",
                    "label": 0
                },
                {
                    "sent": "What is actually a semantic model of the API?",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's go back to our example.",
                    "label": 0
                },
                {
                    "sent": "We have a neighborhood example.",
                    "label": 0
                },
                {
                    "sent": "We have a neighborhood API that takes the latitude and longitude and provides the city name, the neighborhood name Central Park, and the country name.",
                    "label": 0
                },
                {
                    "sent": "And we want to express the functionality of this API using the using the domain ontology and in this case the domain Ontology is a Geo name ontology or WGS ontology.",
                    "label": 0
                },
                {
                    "sent": "So the first step is to identify the data type of the service input and output attributes.",
                    "label": 0
                },
                {
                    "sent": "For example, the first parameter of the API is latitude of a feature.",
                    "label": 0
                },
                {
                    "sent": "The second parameter is longitude of the feature.",
                    "label": 0
                },
                {
                    "sent": "The name of the neighborhood is the name of the future.",
                    "label": 0
                },
                {
                    "sent": "So would it be enough to only assign types to the attributes?",
                    "label": 0
                },
                {
                    "sent": "In many cases?",
                    "label": 0
                },
                {
                    "sent": "No, we need to extract the relationship between the attributes.",
                    "label": 0
                },
                {
                    "sent": "For example, here we want to know what is the relation between these two feature.",
                    "label": 0
                },
                {
                    "sent": "In the correct model, this feature is the name the Central Park is a neighbor of the point.",
                    "label": 0
                },
                {
                    "sent": "So the goal of semantic modeling.",
                    "label": 0
                },
                {
                    "sent": "Is to create to create a model of the API that not only includes the data types of the input and output attributes, but also includes the relationship between the attributes.",
                    "label": 0
                },
                {
                    "sent": "People in the day.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Always community are more familiar with this kind of rules, Datalog rules and this rule exactly represented same semantics.",
                    "label": 0
                },
                {
                    "sent": "So now I'm.",
                    "label": 0
                },
                {
                    "sent": "No, I describe how we create such model in our approach.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We already had a tool, a data integration tool called Karma and we use this tool to import source static sources from relational databases.",
                    "label": 0
                },
                {
                    "sent": "Excel file CSV files.",
                    "label": 0
                },
                {
                    "sent": "And to model them and publish RDF data, doing some different tasks to do the integration like data cleaning integration.",
                    "label": 0
                },
                {
                    "sent": "So what we did here is to extend this tool to add the functionality to model the API's.",
                    "label": 0
                },
                {
                    "sent": "So the input to the system.",
                    "label": 0
                },
                {
                    "sent": "The system has two inputs.",
                    "label": 0
                },
                {
                    "sent": "First examples of the API request URL's and you know these examples can be found in the documentation pages of the API's.",
                    "label": 1
                },
                {
                    "sent": "And the second input is the domain ontology, and different users can import different ontology and create the model of APIs based on their own needs.",
                    "label": 0
                },
                {
                    "sent": "The output is a semantic model that that I show you.",
                    "label": 0
                },
                {
                    "sent": "I showed you in the previous slide.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first user provides some examples of the invocation URLs.",
                    "label": 1
                },
                {
                    "sent": "Here we have 3 examples of the neighborhood API.",
                    "label": 0
                },
                {
                    "sent": "So from this URL's system extracts the input parameters and their values.",
                    "label": 0
                },
                {
                    "sent": "So we have latitude, longitude and username as the input parameters.",
                    "label": 0
                },
                {
                    "sent": "Next, the system for each invocation actually invokes the API, takes the XML or Jason response, and extracts output parameters and the output values, and then concatenates the output values to the input values.",
                    "label": 1
                },
                {
                    "sent": "So in this case we have only one output record for each invocation, but if we have multiple outputs, the system shows the data in nested structure.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So once we constructed a table of the input and output values, we can treat this table as an aesthetic source.",
                    "label": 0
                },
                {
                    "sent": "We can model it like other sources, so we use.",
                    "label": 0
                },
                {
                    "sent": "We train a CRF veterana, conditional random fields model that learns from the assignment user has done in previous sessions to assign a semantic type to each attribute of the service and the semantic type can be an ontology class or a data property with its domain.",
                    "label": 1
                },
                {
                    "sent": "So for example here the Latitude column would be elected to the feature.",
                    "label": 0
                },
                {
                    "sent": "It is a it is a data property plots, the domain and we do the modeling for other attributes.",
                    "label": 0
                },
                {
                    "sent": "So the last three columns are name of the features.",
                    "label": 0
                },
                {
                    "sent": "As I said before, the next step of the semantic modeling is to extract the relationships.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm not going to go through details of the algorithm, but the general idea is that from the assigned semantic types and the graph of the ontology, we construct another graph that defines all possible links between the semantic types.",
                    "label": 0
                },
                {
                    "sent": "And in this graph we select the minimal tree that connects all the semantic types.",
                    "label": 1
                },
                {
                    "sent": "And we consider this minimal tree as the initial model of the API.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If the semantic types are wrong or the suggested links are not correct, the user can change can refine the model through a graphical user interface.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is the final model of the API in our system.",
                    "label": 0
                },
                {
                    "sent": "So we have a.",
                    "label": 0
                },
                {
                    "sent": "We have a feature input feature which has a latitude and longitude.",
                    "label": 0
                },
                {
                    "sent": "And it has a neighborhood name Central Park, and this neighborhood is nearby Manhattan City and the parent country is United States.",
                    "label": 0
                },
                {
                    "sent": "So once we construct this semantic model.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have to be able to actually use this API.",
                    "label": 0
                },
                {
                    "sent": "We have to formalize the model we have to generate the API, an API description.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this step we introduce new RDF vocabulary, a simple ontology that reuses existing vocabulary, like address a stable URL.",
                    "label": 0
                },
                {
                    "sent": "And this vocabulary captures both the syntax and the semantics of the API and we will see soon how Karma explores this vocabulary to automatically do the lowering and lifting.",
                    "label": 0
                },
                {
                    "sent": "So let's see an example.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a small part of our semantic model.",
                    "label": 0
                },
                {
                    "sent": "So this is the input feature with latitude attribute and we have a neighborhood output here.",
                    "label": 0
                },
                {
                    "sent": "First we create an ID for the service that we put the service address.",
                    "label": 0
                },
                {
                    "sent": "The HTTP method is get and the name of the service neighborhood.",
                    "label": 0
                },
                {
                    "sent": "It has one input.",
                    "label": 0
                },
                {
                    "sent": "Latitude, so we create an input attribute is name.",
                    "label": 0
                },
                {
                    "sent": "The attribute name is latitude and the grounding value is P1 and this grounding value shows the location of these Maps.",
                    "label": 0
                },
                {
                    "sent": "This attribute to the parameter of the API.",
                    "label": 0
                },
                {
                    "sent": "And this is the service out.",
                    "label": 0
                },
                {
                    "sent": "So for each semantic type, we create a stable URL Atom for the Gray boxes.",
                    "label": 0
                },
                {
                    "sent": "We create the class Atom.",
                    "label": 0
                },
                {
                    "sent": "So for the input feature we create a class at home and this simply says.",
                    "label": 0
                },
                {
                    "sent": "We have a variable V1 and it's typing and its type is a Geo name feature.",
                    "label": 0
                },
                {
                    "sent": "For each data property we created property at home and the difference between property item and class Atom is a.",
                    "label": 0
                },
                {
                    "sent": "Is that the property Atom has two arguments.",
                    "label": 0
                },
                {
                    "sent": "So here we have a property Atom which represents the Latitude relationship.",
                    "label": 0
                },
                {
                    "sent": "The first argument is V1 and the second argument is the latitude input.",
                    "label": 0
                },
                {
                    "sent": "And we continue the modeling.",
                    "label": 0
                },
                {
                    "sent": "The last link is the relationship between the input and output, so we have a neighborhood.",
                    "label": 0
                },
                {
                    "sent": "We have a neighborhood relation between the input and output feature, so we have a property Atom.",
                    "label": 0
                },
                {
                    "sent": "The relationship is never.",
                    "label": 0
                },
                {
                    "sent": "The first argument is we won and the second argument is with.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So far we created an RDF representation of the service.",
                    "label": 0
                },
                {
                    "sent": "Description Once we publish this service descriptions, we can use the sparkle query to find the services we want and if you remember, this was the first challenge we had.",
                    "label": 0
                },
                {
                    "sent": "For exam.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we want to get the services that take latitude and longitude and produce the neighborhood information.",
                    "label": 0
                },
                {
                    "sent": "We can write a sparkle query to find this service so this query says we want to service that has a feature with latitude and longitude as input and it generates the neighborhood information.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the last part of the model is actually to deploy the link API.",
                    "label": 0
                },
                {
                    "sent": "As I said before from the link API we mean the services that directly consume and produce link data.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have a web server and this web server offers a rest interface and users can interact with this server to invoke the API's.",
                    "label": 0
                },
                {
                    "sent": "If you invoke the link API with the get request.",
                    "label": 0
                },
                {
                    "sent": "The server interacts with the repository to return the RDF description of the API.",
                    "label": 0
                },
                {
                    "sent": "But to feed the RDF data to the API, the user has to issue a post request so the user generates the post, requires, puts his RDF data inside the body of the Post, request.",
                    "label": 0
                },
                {
                    "sent": "The Karma server interacts with the repository to get the description and uses this users that description to automatically lower the data and then build the invocation.",
                    "label": 0
                },
                {
                    "sent": "You are when we get the XML or Jason data back.",
                    "label": 0
                },
                {
                    "sent": "We used again from the service descriptions to automatically leave the data and linked output input.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see the intuition behind automatically the automatic lowering and lifting.",
                    "label": 0
                },
                {
                    "sent": "So this is the input audio.",
                    "label": 0
                },
                {
                    "sent": "The input or did we have a feature with the latitude and longitude?",
                    "label": 0
                },
                {
                    "sent": "And this is part of the service description.",
                    "label": 0
                },
                {
                    "sent": "This is the semantic input model, so we use the graph of the input model and the graph of the audio to map the attributes and extract the URL of the attributes.",
                    "label": 0
                },
                {
                    "sent": "So we know that.",
                    "label": 0
                },
                {
                    "sent": "The input attribute in that has the value like 14th.",
                    "label": 0
                },
                {
                    "sent": "Next we use the grounding property to map the input attributes of the service to the parameters of the API invocation and then use it.",
                    "label": 0
                },
                {
                    "sent": "We use the service address to substitute the values into the parameters and building location URL.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a similar task in lifting.",
                    "label": 0
                },
                {
                    "sent": "We use the name of the attribute in XML output.",
                    "label": 0
                },
                {
                    "sent": "To extract the UI of the output attributes and we use the semantic model of the output to build the RDF graph.",
                    "label": 0
                },
                {
                    "sent": "As you can see here, this was our input and the RDF data is linked to the input, so we have this resource which has a neighbor Woodside and it's nearby the Queen City.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next eval.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nation we evaluated our approach by modeling 11 services from June named API.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, with only a few examples of service invocation URLs that user provides the system in a short amount of time, we create a link API.",
                    "label": 0
                },
                {
                    "sent": "So the key observation here is that Karma enables users to rapidly build link API's, and we spent totally around 40 minutes to build such to model all the APIs.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are other approaches to create semantic service descriptions.",
                    "label": 1
                },
                {
                    "sent": "Link services proposed in 2010, but Petrachi and Dominic.",
                    "label": 0
                },
                {
                    "sent": "They propose a minimal service model, is simple ontology to annotate the input and outputs of the service, and publishes the service description into the link data cloud.",
                    "label": 1
                },
                {
                    "sent": "But the, but because the vocabulary is limited, we cannot represent the relationship between the attributes.",
                    "label": 1
                },
                {
                    "sent": "There are some approaches based on this partial graph patterns like link data services and link open services.",
                    "label": 0
                },
                {
                    "sent": "They use a sparkle graph pattern to represent the input and output.",
                    "label": 0
                },
                {
                    "sent": "Because they use the graph pattern, they can model the relationships, but the discovery of services is not as straightforward because there is no standard facility to query over this partial graph pattern.",
                    "label": 1
                },
                {
                    "sent": "But another one is rest.",
                    "label": 0
                },
                {
                    "sent": "This test uses the entry logic rules to to capture the functionality of the API.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But what differentiates our approach, from all existing approaches is that in Karma users semi automatically built the semantic descriptions an user doesn't require to have expertise in semantic web technologies like RDF or Sparkle.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same conclusion be introduced an approach to build or rich semantic model for services and to publish semantic search descriptions into the link data cloud or descriptions provide strong support for discovery and composition, and we could use those descriptions to rapidly build linked APS.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the future we are interested to apply your approach to rest like URLs.",
                    "label": 0
                },
                {
                    "sent": "If you remember first part of the approach was extracting the input parameters from the invocation you are in.",
                    "label": 0
                },
                {
                    "sent": "Invocation URLs like this, extracting the input parameters is not straightforward because there is not a standard pattern to do this, But if user provides more examples of the invocation URLs, we can find the static part of the URL and to see what is the actual input.",
                    "label": 0
                },
                {
                    "sent": "So the next part is the next thing that we want to do is composing data and services.",
                    "label": 1
                },
                {
                    "sent": "We already have a mediator system that rewrites the query as queries over other sources.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Suppose that we have a service.",
                    "label": 0
                },
                {
                    "sent": "It can be a Google Geocoding API that takes the address and provides the, decomposes the actress into city at state and zip code.",
                    "label": 0
                },
                {
                    "sent": "We have another service that takes a city in this state and provides the live weather.",
                    "label": 0
                },
                {
                    "sent": "We have another service too.",
                    "label": 0
                },
                {
                    "sent": "To give the nearby hotels and restaurants.",
                    "label": 0
                },
                {
                    "sent": "So if we load some data like upcoming events in Karma, we can do the composition to get the more information to provide more information for the user like the.",
                    "label": 0
                },
                {
                    "sent": "Weather and hotels.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For them or For more information like paper, software and demos, you can go to the website isi.edu integration slash integration slash Karma.",
                    "label": 0
                },
                {
                    "sent": "We wanted to show a demo of the system in the demo session, but for me but we missed the deadline.",
                    "label": 0
                },
                {
                    "sent": "But the good news is that we created a short YouTube video you can download that from the website that show and this video demonstrates how karma creates such linked APIs.",
                    "label": 0
                },
                {
                    "sent": "Thanks for your attention and I would like to take your questions.",
                    "label": 0
                }
            ]
        }
    }
}