{
    "id": "t3xrkbc3pfrsdscbux3s6dmntkfxzwba",
    "title": "Evaluating Superpixels in Video: Metrics Beyond Figure-Ground Segmentation",
    "info": {
        "author": [
            "Peer Neubert, Chemnitz University of Technology"
        ],
        "published": "April 3, 2014",
        "recorded": "September 2013",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/bmvc2013_neubert_superpixles/",
    "segmentation": [
        [
            "I'm talking about evaluating super pixels in video.",
            "And."
        ],
        [
            "This is what I will talk the next almost 20 minutes about.",
            "First, I will talk about super pixels.",
            "And I will introduce a new benchmark based on two criteria for evaluating superpixel algorithms based on ground truth optical flow.",
            "So we do not compute optical flow, we just use it OK, and I will present some results of various open source algorithms that produce that segmentations and we compare them."
        ],
        [
            "OK, what are super pixels?",
            "Here's an illustration of the superpixel segmentation, and on X is like size or meaning.",
            "You can put them somewhere between pixels and objects.",
            "I pradal demo application.",
            "So this is a superpixel segmentation of this room.",
            "And we can see that some object boundaries like of the door are recovered by super pixel boundaries, but there are really a lot of additional boundaries all over the image, and especially in homogeneous areas.",
            "So these are super pixels and we can play with some parameters and one important parameter is the number of super pixels.",
            "So these are about 1000.",
            "But maybe we kept just 100 or 10,000, so these are super pixels.",
            "OK, and they're really used in a lot of applications."
        ],
        [
            "For example, segmentation object recognition body model estimation.",
            "We have seen them in some presentations, for example elastics presentation and also on Monday on both tutorials they were mentioned as useful parts of machine learning pipelines.",
            "So.",
            "On"
        ],
        [
            "And since they are useful for such a many things, there are really a lot of algorithms to produce such segmentations.",
            "And here you can see an example image in the middle and some examples superpixel segmentation around and these segmentations are quite different.",
            "And Moreover."
        ],
        [
            "These algorithms have a lot of parameters, so the situation becomes worse and we have even more different segmentations.",
            "We have to choose between OK and so far."
        ],
        [
            "There are some measurements to compare such superpixel segmentation algorithms and.",
            "Mostly they are based on the question how well our figure crowned segmentations an object before.",
            "I'm background are recovered by these super pixels and there are measurements like boundary recall, another segmentation error and they can be used to choose an algorithm.",
            "Besides, you have the runtime and the question if there is an implementation of the algorithm of your choice available.",
            "So why am I standing here?",
            "The problem I see is I want to use super pixels in videos or live cameras like this.",
            "And there are some para meters that I can play with and they dramatically change the appearance of the segmentation, but cannot be well measured with such figure ground ground truth segmentation benchmarks, for example, this little slider I can move.",
            "And now the segmentation looks quite unstable.",
            "However, the object boundaries are still recovered well, so there will be not a huge difference in and figure ground segmentation benchmark between this segmentation.",
            "And let's say.",
            "This, but they are quite different.",
            "So OK, and that's what I'm talking about in this presentation."
        ],
        [
            "We define two criteria.",
            "That we want to evaluate.",
            "The first is the stability criteria.",
            "So here you can see the same behavior.",
            "We have two segmentations of a short video clip and one we consider unstable and another reasonably stable.",
            "Both recover object boundaries.",
            "But inhomogeneous image areas.",
            "They are quite different.",
            "So stability create criteria is that the segmentation algorithm find the same regions or object boundaries robust to changes in the image.",
            "This is the first question and the 2nd is."
        ],
        [
            "That this continuity criteria is formalized, as well as follows how well our motion discontinuity's in the image sequence represented by the algorithm segment boundaries.",
            "OK, the bottom image illustrates a shot of the sequence we've seen before, especially visualization of the optical flow by a color coding and the grade level image on the left side on my left side is the gradient of the motion.",
            "The magnitude of the gradient of the motion, and you can see there is this dragon in the background and around this dragon.",
            "There is a high gradient illustrated by dark values.",
            "And we can't expect that human label off object background would cover such a motion discontinuity at a moving foreground object, but at the wings of the Little dragon in the foreground, you can see that there are high motion discontinuity's inside of this nonrigid object.",
            "And if you want to make a 3D reconstruction of this nonrigid object, you want some superpixel borders near these motion discontinuity's.",
            "OK.",
            "The."
        ],
        [
            "Our idea is we cannot only use optical flow to visualize this problem, but we can also use it to measure how well some superpixel segmentation algorithm can solve these criterias.",
            "OK, Given 2 images from an image sequence connected by Crown truth optical flow field, visualize in the middle, we can compute two segmentations visualized by label images.",
            "So two pixels belonging to the same superpixel have the same label or same color.",
            "We can use the ground truth.",
            "Optical flow field to connect both segmentations and answer our two questions.",
            "How stable are the segmentations and how well our motion discontinuities represented?",
            "OK. Or if we want to use ground truth optical flow, we need some data providing ground truth optical flow and we use."
        ],
        [
            "Two datasets, the first is Kitty data set.",
            "We already heard off in the morning.",
            "These are St scenes connected by ground truth, optical flow and the ground truth.",
            "Optical flow is obtained from 3D laser scanner data, so you can see the optical flow field is some holes and we have some limited vertical field of view of the laser scanner and for example we have no idea of optical flow in this guy because this is not measured by the Velodyne scanner.",
            "OK, the second data set is much bad."
        ],
        [
            "Considering the amount of optical flow, it's the central data set.",
            "This is based on the animated short movie with the same name.",
            "It consists of some sequences, not only image pairs, but sequences, and there's almost perfect ground truth.",
            "We even have ground truth optical flow information for background pixels that are occluded by foreground objects.",
            "Because the ground truth is computed directly from the information used for rendering.",
            "So this is right quite a rich source of crowd of optical flow data."
        ],
        [
            "OK, so far we introduced these two new criteria, stability and represent representation of motion discontinuity's and propose to use ground truth optical flow.",
            "We introduce the datasets and now comes the more technical part.",
            "I'm going to talk about the metrics.",
            "So the equations we use for computing error metrics followed by some results on existing algorithms.",
            "OK."
        ],
        [
            "The first criteria is the segmentation stability, and here we can adopt straight forward the idea from the overview image, taking two images, image, one Image 2 and segmentations L1 and L2.",
            "We can apply the groundtruth optical flow on the 1st segmentation to bring it into the image space of the second segmentation and then compare both segmentations directly using a standard measure like under segmentation error.",
            "So this is the idea how we measure this segmentation stability.",
            "Apply optical flow on one segmentation and then compare both."
        ],
        [
            "So this is the equation for details, please have a look at the paper.",
            "For now.",
            "You can imagine this.",
            "We just measure how well is the segmentation L two were constructed by the transformed L1 based on a segment level.",
            "So we have a look at each segment of segmentation L2 and try to.",
            "Constructed with some segments of the first segmentation transformed through their optical flow OK pixels without valid flow information are ignored in this step and this is not a symmetric matrix, so we have to regard both cases.",
            "Comparing L1 to L2 and L2 to L1.",
            "OK."
        ],
        [
            "Some words on the results.",
            "We compared several algorithms and we just considered algorithms with an open source implementation and reasonable runtime on our image data that they are suitable for usage on video.",
            "So these are the algorithms faster put in locker.",
            "Hedgehog minded mean shift quickshift market controlled watershed and will be right superpixel segmentation two implementations of slick one from the original authors and run from the VL feat library and for baseline.",
            "We also applied the regular crit."
        ],
        [
            "So these are the curves.",
            "There are two plots, one for Simpson and one for Kitty.",
            "It is shown the motion on the segmentation error called Muse.",
            "Over the number of segments, and since it's an error metric, lower values are better.",
            "So let's have a look at some very rough interpretations.",
            "We can distinguish three groups of algorithms.",
            "First, there are Canadian tephinet algorithms without regulation of size of distribution.",
            "These algorithms put super pixel borders mainly at image gradients, and these image gradients move more less well defined with optical flow.",
            "So these algorithms can be considered stable.",
            "Under such motion.",
            "The second group algorithms with some additional boundaries, mainly introduced by compactness constraints.",
            "We limit the size of super pixels, so we need more borders, and these borders are sometimes not related to any image gradient, and these borders may be unstable.",
            "And here we have a large group of algorithms with additional stable boundaries.",
            "Normal crit segmentation is a perfect example for such additional boundaries that are stable and there is a third group of algorithms.",
            "They introduce additional boundaries and they are not stable.",
            "OK so far to the motion stability."
        ],
        [
            "The second part is measuring the accordance with motion discontinuity's.",
            "We said OK, these are images you have already seen just to remember motion disconnect discontinuity's result in high gradients and optical flow field and we want super pixels to separate differently moving objects object parts.",
            "So we define the motion discontinuity or Andy's."
        ],
        [
            "Follows this is the equation.",
            "And there is very intuitive interpretation of this equation.",
            "Important part of the equation is the second half, where we summarize overall image pixels and we summarize an hour.",
            "That is the product of the strength of motion discontinuity at this pixel.",
            "And the distance of this pixel to the next superpixel boundary.",
            "So if there are different moving parts.",
            "At this pixel and there is no super pixel boundary in this area, then this results in a high error.",
            "Finally, this is normalized with the total amount of motion."
        ],
        [
            "OK, let's have a look at the results.",
            "For teachers, please have a look at the paper so far.",
            "We can just say results are really inverted compared to the Muse error compactness constraints really help a lot too.",
            "Cover such motion motion discontinuity's because the newly introduced borders, which use the average distance to motion discontinuity's.",
            "And other algorithms exclusively relying upon image gradients really miss a lot of motion discontinuities."
        ],
        [
            "OK, some remarks in the Matrix and the favors.",
            "Segmentations with many boundary pixels.",
            "This is very similar to measures like boundary recall and it should be used together with complementing measurements.",
            "And and the and news are somehow complementary, and that algorithms that are good at one are not that good at the other.",
            "OK, and what we want to do is we want to look for well balanced algorithms or para meter sets.",
            "OK, so I want to point out that MDE and Muse do not replace figure Crown segmentations.",
            "So what we really should do is we should look for algorithms superpixel algorithms that are good at figure ground segmentation and then check if they are stable and also cover these motion discontinuity's."
        ],
        [
            "OK, that's it.",
            "That's conclude.",
            "We propose these two Noble criterias, segmentation, stability, and represent representation of motion discontinuity's we exploit crowd to optical flow to measure them.",
            "Define this as two matrix Muzin MD, and if you just want to use one of these super pixel algorithms, have a look at the paper if you want to measure your own algorithm, you can use the MATLAB toolbox we provide where these errors error metrics are implemented.",
            "And also their success to the datasets and some tools for visualization.",
            "And to answer the first question, I guess from our point of view, VR slick and quick shift algorithms show the best balance results, so I'm happy to answer further questions."
        ],
        [
            "For example, one of these thank you.",
            "I have a first question and I might have a second one depending on the answer.",
            "So the first question is, are any of these algorithms for superpixel computation exploiting temporal information?",
            "No OK, so I have a second question so so you're using.",
            "So you're evaluating image based superpixel algorithms.",
            "To evaluate our stability in video.",
            "Wouldn't need to also make sense to use if we know we're working on video using a regular temporal super pixels algorithms like there was a temporal superpixel paper in CPR 13, and I guess there are other type of algorithms like this.",
            "Yeah, I think that's what I mean with the second question, why not super voxels?",
            "So I think that's the term that is often used for that.",
            "And yes, of course, if you.",
            "Your video data allows to use super voxels.",
            "Use them, but if your frame rate is low compared to the amount of motion, super boxes will fail, then you should use some of these algorithms and maybe stability is also a criteria, not for video, but for something like object recognition.",
            "Maybe it helps to have some sort of stable super pixels.",
            "So you flip through the results graph quite quickly, but I seem to remember that for just a sort of a baseline benchmark you had just naively chop the image up into a regular grid boxes.",
            "It looked from the results graph that that algorithm it's do fairly competitively with quite a lot of others.",
            "Was not about right, if you could.",
            "At."
        ],
        [
            "So I don't get the question.",
            "Can you please repeat so simply chopping up the image into boxes?",
            "But that line sort of lies quite close to some of the other algorithms, yeah?",
            "And that's one of the reasons why we should not use these measures exclusively.",
            "We also should have a look if our segmentation also recovers figure ground segmentation so.",
            "Does this answer?",
            "Yes, pretty much actually thank you.",
            "So my question is a follow up to the first question.",
            "Given that none of your algorithms are exploiting temporal information, how does the MD error metric make sense?",
            "Aren't you placing a burden on sort of recovering motion boundaries with that metric, when in fact you're restricting all these algorithms to be unable to recover motion boundaries because they don't see any temporal information?",
            "Yeah, the problem is that.",
            "It's not the benchmark that is putting this.",
            "This requirement on superpixel algorithm, but the application because often we try to.",
            "For example, make it object detection of a nonrigid object.",
            "Or 3D reconstruction reconstruction from still images.",
            "And then it would be very helpful to have algorithms that are in principle able to handle these motion discontinuity.",
            "Even if they are not in these two images, right?",
            "Well, sure where you created these algorithms could magically predict the motion boundaries from a single frame, right?",
            "But MD is requiring them to predict to have access to temporal information, right?",
            "You're requiring like single frame algorithm to predict some motion.",
            "After only seeing a single frame.",
            "Kim, is that correct?",
            "We want the algorithms to produce results that can cover these motion discontinuity.",
            "Without knowing that there exists and without any clue or any indicator from the image, so that's right.",
            "That's really unfair, but I think we have a lot of applications where we exactly want these algorithms to do such things."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm talking about evaluating super pixels in video.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is what I will talk the next almost 20 minutes about.",
                    "label": 0
                },
                {
                    "sent": "First, I will talk about super pixels.",
                    "label": 0
                },
                {
                    "sent": "And I will introduce a new benchmark based on two criteria for evaluating superpixel algorithms based on ground truth optical flow.",
                    "label": 1
                },
                {
                    "sent": "So we do not compute optical flow, we just use it OK, and I will present some results of various open source algorithms that produce that segmentations and we compare them.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, what are super pixels?",
                    "label": 1
                },
                {
                    "sent": "Here's an illustration of the superpixel segmentation, and on X is like size or meaning.",
                    "label": 0
                },
                {
                    "sent": "You can put them somewhere between pixels and objects.",
                    "label": 0
                },
                {
                    "sent": "I pradal demo application.",
                    "label": 0
                },
                {
                    "sent": "So this is a superpixel segmentation of this room.",
                    "label": 0
                },
                {
                    "sent": "And we can see that some object boundaries like of the door are recovered by super pixel boundaries, but there are really a lot of additional boundaries all over the image, and especially in homogeneous areas.",
                    "label": 0
                },
                {
                    "sent": "So these are super pixels and we can play with some parameters and one important parameter is the number of super pixels.",
                    "label": 0
                },
                {
                    "sent": "So these are about 1000.",
                    "label": 0
                },
                {
                    "sent": "But maybe we kept just 100 or 10,000, so these are super pixels.",
                    "label": 0
                },
                {
                    "sent": "OK, and they're really used in a lot of applications.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For example, segmentation object recognition body model estimation.",
                    "label": 1
                },
                {
                    "sent": "We have seen them in some presentations, for example elastics presentation and also on Monday on both tutorials they were mentioned as useful parts of machine learning pipelines.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "On",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And since they are useful for such a many things, there are really a lot of algorithms to produce such segmentations.",
                    "label": 0
                },
                {
                    "sent": "And here you can see an example image in the middle and some examples superpixel segmentation around and these segmentations are quite different.",
                    "label": 0
                },
                {
                    "sent": "And Moreover.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These algorithms have a lot of parameters, so the situation becomes worse and we have even more different segmentations.",
                    "label": 0
                },
                {
                    "sent": "We have to choose between OK and so far.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are some measurements to compare such superpixel segmentation algorithms and.",
                    "label": 0
                },
                {
                    "sent": "Mostly they are based on the question how well our figure crowned segmentations an object before.",
                    "label": 0
                },
                {
                    "sent": "I'm background are recovered by these super pixels and there are measurements like boundary recall, another segmentation error and they can be used to choose an algorithm.",
                    "label": 0
                },
                {
                    "sent": "Besides, you have the runtime and the question if there is an implementation of the algorithm of your choice available.",
                    "label": 0
                },
                {
                    "sent": "So why am I standing here?",
                    "label": 1
                },
                {
                    "sent": "The problem I see is I want to use super pixels in videos or live cameras like this.",
                    "label": 0
                },
                {
                    "sent": "And there are some para meters that I can play with and they dramatically change the appearance of the segmentation, but cannot be well measured with such figure ground ground truth segmentation benchmarks, for example, this little slider I can move.",
                    "label": 0
                },
                {
                    "sent": "And now the segmentation looks quite unstable.",
                    "label": 0
                },
                {
                    "sent": "However, the object boundaries are still recovered well, so there will be not a huge difference in and figure ground segmentation benchmark between this segmentation.",
                    "label": 0
                },
                {
                    "sent": "And let's say.",
                    "label": 0
                },
                {
                    "sent": "This, but they are quite different.",
                    "label": 0
                },
                {
                    "sent": "So OK, and that's what I'm talking about in this presentation.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We define two criteria.",
                    "label": 0
                },
                {
                    "sent": "That we want to evaluate.",
                    "label": 0
                },
                {
                    "sent": "The first is the stability criteria.",
                    "label": 0
                },
                {
                    "sent": "So here you can see the same behavior.",
                    "label": 0
                },
                {
                    "sent": "We have two segmentations of a short video clip and one we consider unstable and another reasonably stable.",
                    "label": 0
                },
                {
                    "sent": "Both recover object boundaries.",
                    "label": 0
                },
                {
                    "sent": "But inhomogeneous image areas.",
                    "label": 0
                },
                {
                    "sent": "They are quite different.",
                    "label": 0
                },
                {
                    "sent": "So stability create criteria is that the segmentation algorithm find the same regions or object boundaries robust to changes in the image.",
                    "label": 1
                },
                {
                    "sent": "This is the first question and the 2nd is.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That this continuity criteria is formalized, as well as follows how well our motion discontinuity's in the image sequence represented by the algorithm segment boundaries.",
                    "label": 1
                },
                {
                    "sent": "OK, the bottom image illustrates a shot of the sequence we've seen before, especially visualization of the optical flow by a color coding and the grade level image on the left side on my left side is the gradient of the motion.",
                    "label": 0
                },
                {
                    "sent": "The magnitude of the gradient of the motion, and you can see there is this dragon in the background and around this dragon.",
                    "label": 0
                },
                {
                    "sent": "There is a high gradient illustrated by dark values.",
                    "label": 0
                },
                {
                    "sent": "And we can't expect that human label off object background would cover such a motion discontinuity at a moving foreground object, but at the wings of the Little dragon in the foreground, you can see that there are high motion discontinuity's inside of this nonrigid object.",
                    "label": 0
                },
                {
                    "sent": "And if you want to make a 3D reconstruction of this nonrigid object, you want some superpixel borders near these motion discontinuity's.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our idea is we cannot only use optical flow to visualize this problem, but we can also use it to measure how well some superpixel segmentation algorithm can solve these criterias.",
                    "label": 0
                },
                {
                    "sent": "OK, Given 2 images from an image sequence connected by Crown truth optical flow field, visualize in the middle, we can compute two segmentations visualized by label images.",
                    "label": 0
                },
                {
                    "sent": "So two pixels belonging to the same superpixel have the same label or same color.",
                    "label": 0
                },
                {
                    "sent": "We can use the ground truth.",
                    "label": 0
                },
                {
                    "sent": "Optical flow field to connect both segmentations and answer our two questions.",
                    "label": 0
                },
                {
                    "sent": "How stable are the segmentations and how well our motion discontinuities represented?",
                    "label": 0
                },
                {
                    "sent": "OK. Or if we want to use ground truth optical flow, we need some data providing ground truth optical flow and we use.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two datasets, the first is Kitty data set.",
                    "label": 0
                },
                {
                    "sent": "We already heard off in the morning.",
                    "label": 0
                },
                {
                    "sent": "These are St scenes connected by ground truth, optical flow and the ground truth.",
                    "label": 1
                },
                {
                    "sent": "Optical flow is obtained from 3D laser scanner data, so you can see the optical flow field is some holes and we have some limited vertical field of view of the laser scanner and for example we have no idea of optical flow in this guy because this is not measured by the Velodyne scanner.",
                    "label": 0
                },
                {
                    "sent": "OK, the second data set is much bad.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Considering the amount of optical flow, it's the central data set.",
                    "label": 0
                },
                {
                    "sent": "This is based on the animated short movie with the same name.",
                    "label": 1
                },
                {
                    "sent": "It consists of some sequences, not only image pairs, but sequences, and there's almost perfect ground truth.",
                    "label": 0
                },
                {
                    "sent": "We even have ground truth optical flow information for background pixels that are occluded by foreground objects.",
                    "label": 0
                },
                {
                    "sent": "Because the ground truth is computed directly from the information used for rendering.",
                    "label": 0
                },
                {
                    "sent": "So this is right quite a rich source of crowd of optical flow data.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so far we introduced these two new criteria, stability and represent representation of motion discontinuity's and propose to use ground truth optical flow.",
                    "label": 1
                },
                {
                    "sent": "We introduce the datasets and now comes the more technical part.",
                    "label": 1
                },
                {
                    "sent": "I'm going to talk about the metrics.",
                    "label": 0
                },
                {
                    "sent": "So the equations we use for computing error metrics followed by some results on existing algorithms.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first criteria is the segmentation stability, and here we can adopt straight forward the idea from the overview image, taking two images, image, one Image 2 and segmentations L1 and L2.",
                    "label": 1
                },
                {
                    "sent": "We can apply the groundtruth optical flow on the 1st segmentation to bring it into the image space of the second segmentation and then compare both segmentations directly using a standard measure like under segmentation error.",
                    "label": 0
                },
                {
                    "sent": "So this is the idea how we measure this segmentation stability.",
                    "label": 0
                },
                {
                    "sent": "Apply optical flow on one segmentation and then compare both.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the equation for details, please have a look at the paper.",
                    "label": 0
                },
                {
                    "sent": "For now.",
                    "label": 0
                },
                {
                    "sent": "You can imagine this.",
                    "label": 0
                },
                {
                    "sent": "We just measure how well is the segmentation L two were constructed by the transformed L1 based on a segment level.",
                    "label": 1
                },
                {
                    "sent": "So we have a look at each segment of segmentation L2 and try to.",
                    "label": 0
                },
                {
                    "sent": "Constructed with some segments of the first segmentation transformed through their optical flow OK pixels without valid flow information are ignored in this step and this is not a symmetric matrix, so we have to regard both cases.",
                    "label": 1
                },
                {
                    "sent": "Comparing L1 to L2 and L2 to L1.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some words on the results.",
                    "label": 0
                },
                {
                    "sent": "We compared several algorithms and we just considered algorithms with an open source implementation and reasonable runtime on our image data that they are suitable for usage on video.",
                    "label": 1
                },
                {
                    "sent": "So these are the algorithms faster put in locker.",
                    "label": 1
                },
                {
                    "sent": "Hedgehog minded mean shift quickshift market controlled watershed and will be right superpixel segmentation two implementations of slick one from the original authors and run from the VL feat library and for baseline.",
                    "label": 0
                },
                {
                    "sent": "We also applied the regular crit.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these are the curves.",
                    "label": 0
                },
                {
                    "sent": "There are two plots, one for Simpson and one for Kitty.",
                    "label": 0
                },
                {
                    "sent": "It is shown the motion on the segmentation error called Muse.",
                    "label": 0
                },
                {
                    "sent": "Over the number of segments, and since it's an error metric, lower values are better.",
                    "label": 0
                },
                {
                    "sent": "So let's have a look at some very rough interpretations.",
                    "label": 0
                },
                {
                    "sent": "We can distinguish three groups of algorithms.",
                    "label": 1
                },
                {
                    "sent": "First, there are Canadian tephinet algorithms without regulation of size of distribution.",
                    "label": 0
                },
                {
                    "sent": "These algorithms put super pixel borders mainly at image gradients, and these image gradients move more less well defined with optical flow.",
                    "label": 0
                },
                {
                    "sent": "So these algorithms can be considered stable.",
                    "label": 0
                },
                {
                    "sent": "Under such motion.",
                    "label": 0
                },
                {
                    "sent": "The second group algorithms with some additional boundaries, mainly introduced by compactness constraints.",
                    "label": 1
                },
                {
                    "sent": "We limit the size of super pixels, so we need more borders, and these borders are sometimes not related to any image gradient, and these borders may be unstable.",
                    "label": 0
                },
                {
                    "sent": "And here we have a large group of algorithms with additional stable boundaries.",
                    "label": 0
                },
                {
                    "sent": "Normal crit segmentation is a perfect example for such additional boundaries that are stable and there is a third group of algorithms.",
                    "label": 0
                },
                {
                    "sent": "They introduce additional boundaries and they are not stable.",
                    "label": 0
                },
                {
                    "sent": "OK so far to the motion stability.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second part is measuring the accordance with motion discontinuity's.",
                    "label": 1
                },
                {
                    "sent": "We said OK, these are images you have already seen just to remember motion disconnect discontinuity's result in high gradients and optical flow field and we want super pixels to separate differently moving objects object parts.",
                    "label": 0
                },
                {
                    "sent": "So we define the motion discontinuity or Andy's.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Follows this is the equation.",
                    "label": 0
                },
                {
                    "sent": "And there is very intuitive interpretation of this equation.",
                    "label": 0
                },
                {
                    "sent": "Important part of the equation is the second half, where we summarize overall image pixels and we summarize an hour.",
                    "label": 0
                },
                {
                    "sent": "That is the product of the strength of motion discontinuity at this pixel.",
                    "label": 1
                },
                {
                    "sent": "And the distance of this pixel to the next superpixel boundary.",
                    "label": 0
                },
                {
                    "sent": "So if there are different moving parts.",
                    "label": 0
                },
                {
                    "sent": "At this pixel and there is no super pixel boundary in this area, then this results in a high error.",
                    "label": 1
                },
                {
                    "sent": "Finally, this is normalized with the total amount of motion.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, let's have a look at the results.",
                    "label": 0
                },
                {
                    "sent": "For teachers, please have a look at the paper so far.",
                    "label": 0
                },
                {
                    "sent": "We can just say results are really inverted compared to the Muse error compactness constraints really help a lot too.",
                    "label": 1
                },
                {
                    "sent": "Cover such motion motion discontinuity's because the newly introduced borders, which use the average distance to motion discontinuity's.",
                    "label": 0
                },
                {
                    "sent": "And other algorithms exclusively relying upon image gradients really miss a lot of motion discontinuities.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, some remarks in the Matrix and the favors.",
                    "label": 0
                },
                {
                    "sent": "Segmentations with many boundary pixels.",
                    "label": 1
                },
                {
                    "sent": "This is very similar to measures like boundary recall and it should be used together with complementing measurements.",
                    "label": 1
                },
                {
                    "sent": "And and the and news are somehow complementary, and that algorithms that are good at one are not that good at the other.",
                    "label": 1
                },
                {
                    "sent": "OK, and what we want to do is we want to look for well balanced algorithms or para meter sets.",
                    "label": 0
                },
                {
                    "sent": "OK, so I want to point out that MDE and Muse do not replace figure Crown segmentations.",
                    "label": 0
                },
                {
                    "sent": "So what we really should do is we should look for algorithms superpixel algorithms that are good at figure ground segmentation and then check if they are stable and also cover these motion discontinuity's.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, that's it.",
                    "label": 0
                },
                {
                    "sent": "That's conclude.",
                    "label": 0
                },
                {
                    "sent": "We propose these two Noble criterias, segmentation, stability, and represent representation of motion discontinuity's we exploit crowd to optical flow to measure them.",
                    "label": 1
                },
                {
                    "sent": "Define this as two matrix Muzin MD, and if you just want to use one of these super pixel algorithms, have a look at the paper if you want to measure your own algorithm, you can use the MATLAB toolbox we provide where these errors error metrics are implemented.",
                    "label": 0
                },
                {
                    "sent": "And also their success to the datasets and some tools for visualization.",
                    "label": 0
                },
                {
                    "sent": "And to answer the first question, I guess from our point of view, VR slick and quick shift algorithms show the best balance results, so I'm happy to answer further questions.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, one of these thank you.",
                    "label": 0
                },
                {
                    "sent": "I have a first question and I might have a second one depending on the answer.",
                    "label": 0
                },
                {
                    "sent": "So the first question is, are any of these algorithms for superpixel computation exploiting temporal information?",
                    "label": 0
                },
                {
                    "sent": "No OK, so I have a second question so so you're using.",
                    "label": 0
                },
                {
                    "sent": "So you're evaluating image based superpixel algorithms.",
                    "label": 0
                },
                {
                    "sent": "To evaluate our stability in video.",
                    "label": 0
                },
                {
                    "sent": "Wouldn't need to also make sense to use if we know we're working on video using a regular temporal super pixels algorithms like there was a temporal superpixel paper in CPR 13, and I guess there are other type of algorithms like this.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think that's what I mean with the second question, why not super voxels?",
                    "label": 0
                },
                {
                    "sent": "So I think that's the term that is often used for that.",
                    "label": 0
                },
                {
                    "sent": "And yes, of course, if you.",
                    "label": 0
                },
                {
                    "sent": "Your video data allows to use super voxels.",
                    "label": 0
                },
                {
                    "sent": "Use them, but if your frame rate is low compared to the amount of motion, super boxes will fail, then you should use some of these algorithms and maybe stability is also a criteria, not for video, but for something like object recognition.",
                    "label": 0
                },
                {
                    "sent": "Maybe it helps to have some sort of stable super pixels.",
                    "label": 0
                },
                {
                    "sent": "So you flip through the results graph quite quickly, but I seem to remember that for just a sort of a baseline benchmark you had just naively chop the image up into a regular grid boxes.",
                    "label": 0
                },
                {
                    "sent": "It looked from the results graph that that algorithm it's do fairly competitively with quite a lot of others.",
                    "label": 0
                },
                {
                    "sent": "Was not about right, if you could.",
                    "label": 0
                },
                {
                    "sent": "At.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I don't get the question.",
                    "label": 0
                },
                {
                    "sent": "Can you please repeat so simply chopping up the image into boxes?",
                    "label": 0
                },
                {
                    "sent": "But that line sort of lies quite close to some of the other algorithms, yeah?",
                    "label": 0
                },
                {
                    "sent": "And that's one of the reasons why we should not use these measures exclusively.",
                    "label": 0
                },
                {
                    "sent": "We also should have a look if our segmentation also recovers figure ground segmentation so.",
                    "label": 0
                },
                {
                    "sent": "Does this answer?",
                    "label": 0
                },
                {
                    "sent": "Yes, pretty much actually thank you.",
                    "label": 0
                },
                {
                    "sent": "So my question is a follow up to the first question.",
                    "label": 0
                },
                {
                    "sent": "Given that none of your algorithms are exploiting temporal information, how does the MD error metric make sense?",
                    "label": 0
                },
                {
                    "sent": "Aren't you placing a burden on sort of recovering motion boundaries with that metric, when in fact you're restricting all these algorithms to be unable to recover motion boundaries because they don't see any temporal information?",
                    "label": 0
                },
                {
                    "sent": "Yeah, the problem is that.",
                    "label": 0
                },
                {
                    "sent": "It's not the benchmark that is putting this.",
                    "label": 0
                },
                {
                    "sent": "This requirement on superpixel algorithm, but the application because often we try to.",
                    "label": 0
                },
                {
                    "sent": "For example, make it object detection of a nonrigid object.",
                    "label": 0
                },
                {
                    "sent": "Or 3D reconstruction reconstruction from still images.",
                    "label": 0
                },
                {
                    "sent": "And then it would be very helpful to have algorithms that are in principle able to handle these motion discontinuity.",
                    "label": 0
                },
                {
                    "sent": "Even if they are not in these two images, right?",
                    "label": 0
                },
                {
                    "sent": "Well, sure where you created these algorithms could magically predict the motion boundaries from a single frame, right?",
                    "label": 0
                },
                {
                    "sent": "But MD is requiring them to predict to have access to temporal information, right?",
                    "label": 0
                },
                {
                    "sent": "You're requiring like single frame algorithm to predict some motion.",
                    "label": 0
                },
                {
                    "sent": "After only seeing a single frame.",
                    "label": 0
                },
                {
                    "sent": "Kim, is that correct?",
                    "label": 0
                },
                {
                    "sent": "We want the algorithms to produce results that can cover these motion discontinuity.",
                    "label": 0
                },
                {
                    "sent": "Without knowing that there exists and without any clue or any indicator from the image, so that's right.",
                    "label": 0
                },
                {
                    "sent": "That's really unfair, but I think we have a lot of applications where we exactly want these algorithms to do such things.",
                    "label": 0
                }
            ]
        }
    }
}