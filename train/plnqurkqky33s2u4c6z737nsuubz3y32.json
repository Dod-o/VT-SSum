{
    "id": "plnqurkqky33s2u4c6z737nsuubz3y32",
    "title": "Quality Indicator Maximization in Multiobjective Optimization Via Single-Objective Solvers",
    "info": {
        "author": [
            "Dimo Brockhoff, INRIA Saclay - \u00cele-de-France"
        ],
        "published": "May 6, 2019",
        "recorded": "April 2019",
        "category": [
            "Top->Science",
            "Top->Computer Science"
        ]
    },
    "url": "http://videolectures.net/solomon_brockhoff_quality_indicator_maximization/",
    "segmentation": [
        [
            "Good morning everybody.",
            "And hello to all the people in the Internet to millions of viewers.",
            "Yeah, I'm really happy to talk about today about our latest research and have to say latest because it's really literally latest and even change the title in between because the deadline was last week and we.",
            "One hour before the deadline, we change the title so I'm not going to talk about the unflattened hypervolume improvement today."
        ],
        [
            "But about the uncrowded, hypervolemic content is the same, but the title changed, so I hope you're not too disappointed.",
            "Yeah, so this is joint work with share Tori Nicholas Hanson and Energy.",
            "We are all in the Roundup team at INRIA and also at awkward Polytechnique and the new structure around this is the Epub Reader Institute.",
            "Polytechnic Department yeah so."
        ],
        [
            "I'm mainly talking about multi objective optimization today.",
            "But I want to start with general overview of which type of forms we're looking at.",
            "We are typically looking at challenging optimization problems.",
            "And by challenging I mean they are kind of nasty and not so nice, so they're typically not linear, non convex.",
            "There might be rocked etc.",
            "And they appear in many application areas.",
            "For example, in the design of new products like this train here or car, where for example you want to change the OR find the.",
            "Design the structure of these nodes of the train in order to reduce the drag, for example, or if you want to design A rocket you have para meters like the width of the rock at the height of the rocket, how much propellant do you put, etc.",
            "So all kinds of parameters that you can change, and once you want to maximizes the payload, you can get into it.",
            "Yeah, so we are talking about this challenging optimization problems and because they are so difficult we typically."
        ],
        [
            "Look at them as black box optimization problems where all the difficulties of the problem are inside this black box and the algorithm can only query this black box.",
            "So we assume for now that we are in numerical optimization.",
            "So where we have.",
            "Para meters that are continuous, so have any continuous parameters that I can put into my black box and then after some point in time I get back the function evaluation F of X and this can be a single value.",
            "Then the single objective case or if this is if you get more than two values that two or more than we are and the multi objective case.",
            "So this is also common in practice.",
            "So for example one to maximize performance but also minimize costs.",
            "And yeah, for this multi objective optimization problems, things are slightly different.",
            "Then in single objective problems, for now I don't talk about constraints."
        ],
        [
            "Usually you also have constraints.",
            "Here I will just not talk about this.",
            "To make things simpler."
        ],
        [
            "But the comparison to single objective optimization.",
            "In the single objective case, you always have a real value, so therefore you can always compare two solutions.",
            "So X&Y and you can always say X is better or why is better or the same in terms of the function value and therefore also the optimal function value is well defined mathematically.",
            "In the multi objective case.",
            "So if you have a larger than one then you can have the case that you have two incomparable solutions.",
            "So for one the first objective is better and for the other one the second one.",
            "For example one is more performant, the other one is cheaper.",
            "Therefore, you have tradeoffs between the objectives and then the optimal value concept translates into the optimum being a set, and this looks."
        ],
        [
            "Like that so now if you look at the two objectives here, the first objective and the second objective both to be minimized."
        ],
        [
            "Then we can throw in some solutions and we see the how they solutions the stars performed with respect these two objective functions.",
            "And then we can."
        ],
        [
            "See something like example.",
            "This one here is better than this yellow one because it is better smaller in both objective functions.",
            "So if one is smaller and F2 is smaller for the red one, then for the yellow one.",
            "And the."
        ],
        [
            "Comparability, I assume this is what I should say this.",
            "We also say typically then the red one dominates the yellow."
        ],
        [
            "And incompatibility you see here between these solutions.",
            "For example, where this solution is better with respect to F1 but works with this vector two and this one is better.",
            "Smaller with the specter of two but worse with respective one.",
            "So they're incomparable.",
            "And then if you look at all the solutions that are not dominated by any other in this case, these are the red ones here."
        ],
        [
            "These are the so-called preacher optimal objective vectors, and together they are called the printer front.",
            "So these are all solutions where there is no other solution to the lower left, so with smaller F1 and F2 then.",
            "And of course, everything generalizes to more than two objectives."
        ],
        [
            "And another difference, two single objective optimizations that we have actually two spaces.",
            "So this is the space that in single objective case you would never look at because it's trivial, just R. So here we are in R2, but what you would usually look at is the search space."
        ],
        [
            "And this we also have here.",
            "So the algorithms that actually optimize the solutions lift, typically in the search space.",
            "So where you have the parameters X12 X, let's say M let's say XN.",
            "And each of these solutions here is then mapped to the objective space and we evaluate the solutions in the objective space.",
            "But the actual optimizations going on here and the preimage of this pressure front is called the creator set.",
            "This is the set of red solutions here that we usually want to find.",
            "Want to find is a bit."
        ],
        [
            "Underspecified, so usually the question is what is the actual optimization goal of this type of problems?",
            "And one way to look at this is."
        ],
        [
            "You can look at a set based formalisation with respect and quality indicator.",
            "And what you are interested in is you have given a set of number of points P. And a quality indicator.",
            "I will explain in the immediate what it is, but just this is a function that takes a set of solutions and returns a quality.",
            "Can be anything.",
            "And then we are interested in what is the set of points that optimizes this quality so it maximizes this quality.",
            "And there are many quality indicators around.",
            "Probably the most common ones are these ones, the hypervolume, the excellent indicator to indicator, and the hypervolume.",
            "I will explain because our algorithm is based on this and it also has the nicest theoretical properties.",
            "So for example, the volume is the only quality indicator that we know that is strictly monotone in the sense that if I add a point to a set that is non dominated, it will increase strictly increase the value.",
            "And if you have such a formalization, so you specify how many.",
            "Points."
        ],
        [
            "Want to have and the indicator."
        ],
        [
            "Then this.",
            "Is nothing else than a single objective optimization problem, but now in a higher dimension.",
            "So now if you have points, each of them has variables in parameters, then this is just a P * N dimensional single objective problem.",
            "Or you want to maximize the indicator.",
            "OK, so now what is the hyper volume indicator?"
        ],
        [
            "That's also for two objectives, relatively simple to see.",
            "That's the area of the dominated space.",
            "So this is again the same problem before 2 objectives to be minimized."
        ],
        [
            "We put in a set here.",
            "There all non dominated solutions but they don't have to be and then you have to specify the so called."
        ],
        [
            "Reference point, which is a parameter of the indicator.",
            "Um?",
            "And then the quality of this red set is nothing."
        ],
        [
            "Then the area of the objective space that is dominated and at the same time bounded by the reference point.",
            "So everything so kind of is integral over all of the objective space.",
            "Overall points that are one if it is dominated by a red solution and not dominating, not dominated and dominating the reference point and 0 otherwise.",
            "So here is just the area."
        ],
        [
            "And the main question of my talk now is can we and if we can, how converge towards the optimal hypervolume linearly?",
            "So if we have given set a number of points P and the quality indicator the hypervolume, can we converge to this set of points that maximize the indicator?"
        ],
        [
            "OK, so how could we approach this and remember here that I said this is nothing is in a single objective optimization problem in dimension P times North.",
            "And I will give a example that will go throughout the talk to just compare different approaches.",
            "So now."
        ],
        [
            "Now we look at the search space.",
            "So here for two the simplest case for two variables X1 and X2 so."
        ],
        [
            "North in this.",
            "Problem definition is 2.",
            "And now I want to construct the problem or I will talk about the problem that is the simplest of all.",
            "Non trivial problems and I have marked here the.",
            "Single objective Optima.",
            "As this dots here.",
            "So the optimum for the first objective is in the zero vector and it's in 10000 in the higher dimensions.",
            "For the second objective.",
            "OK and I want to have a problem where the printer set."
        ],
        [
            "Is the straight line between them and then I just throw."
        ],
        [
            "In a number of points, let's say six points is at this point here, so one is on the printer set three, or here above one is below and one is exactly the optimal.",
            "Just for illustration purposes, and then I just try to see what is going on.",
            "How this problem actually looks like?",
            "And now."
        ],
        [
            "If this is the search space, I have to define what is the function in order to see something and here I."
        ],
        [
            "Choose really the simplest, simplest problems, so the so called double sphere problem.",
            "So in the first objective this is the sum.",
            "Of the XI squared.",
            "Because the first optimum here is in the all zero.",
            "And for the second one, it is the square of the sum of the square of the XI minus the optimal value.",
            "So it's X 1 -- 1 ^2 plus the sum of the XI square for all the rest.",
            "And then if you look at the level set so the lines of equal function value, these are just circles around the rounded to optimal.",
            "So for the first objective with the optimal here these are the level sets here, so these are circles with the center in this optimum and the other way round.",
            "These other level sets for the second objective.",
            "And that means also in this plot we can now to put these six points into the objective space."
        ],
        [
            "And it looks like this, so we have now F1 and F2 both to be minimized and each of these points now translates to a point here so."
        ],
        [
            "Example, this one here that has by definition the way I put it the same distance to the two Optima.",
            "So the same function value that Maps to this point here."
        ],
        [
            "Contrary, this one here has the same.",
            "Also the two distances are the same, but it's closer so that the sum of the squares smaller, and therefore it is moved here dominating the other point.",
            "So this point here is dominating this one.",
            "It's also closer to the operator set and so forth."
        ],
        [
            "For example, this one that is here exactly at the preset has very small distance, very small F value in F1, so it's close to 0 here and has a very large distance.",
            "Large sum of the squares with respect to the.",
            "Second objective.",
            "OK."
        ],
        [
            "So this is.",
            "The.",
            "The example.",
            "Um?"
        ],
        [
            "So now how does this problem look like?",
            "So we would now put the X values of these points into our North Times P dimensional vector.",
            "So the first 2 variables of the first point, then the second point with these two variables, etc up to the last point.",
            "With these two variables."
        ],
        [
            "And then we map this to the hypervolume.",
            "So in this case here we have a dominated point.",
            "Here it is the area this green area.",
            "So far.",
            "Nothing you."
        ],
        [
            "And now how can we approach this?",
            "So one way would be OK, you can say this is single objective problem.",
            "I might be able to compute the gradient and you can just do that because the hypervolume is nothing less than the sum of areas.",
            "Here some of rectangles in the two dimensional case.",
            "So you can compute the gradient and then you can just could run a gradient based algorithm on this.",
            "Quite a YouTube, JS, whatever who you think of.",
            "But that has some."
        ],
        [
            "Impracticalities one is that it's much higher than the original, much higher dimensional than the original problem.",
            "Now you have P * N dimensional.",
            "Usually you search for it's 100 points and if you do this in 100 dimensional space, the problem is already high dimension.",
            "Um?",
            "But you have also large scale variance of gradient based algorithms, so this is not a big problem in practice."
        ],
        [
            "But the bigger problem are these dominated points here.",
            "And this is also in the original paper.",
            "From this year, actually."
        ],
        [
            "If you look at this, if I move this point here, it has no effect on the hypervolume, so because it's a dominated point, the area that is dominated by the whole set is not changing.",
            "If I move this point around here.",
            "So if I compute the gradient, it has really zero entries for the two X values that belong to this point, and this is really the problem for the algorithm.",
            "So you cannot just run gradient based algorithm that.",
            "If you start with the with dominated points in your set here, then it will just not work and the work around they do in this paper is you run an evolutionary algorithm first to get a nice set of spread points.",
            "And once you have a set of nondominated points in the algorithm, then you switch over to the gradient based out.",
            "So it's kind of like you start evolutionary algorithm with key points we optimize and then once you say OK, I'm close to the front, then you would run a gradient based algorithm local solver to come closer to the to the front.",
            "OK, so now how do we approach these two things?",
            "The first part is relatively simple that."
        ],
        [
            "Also, I think already mentioned in this paper you can do subspace optimization.",
            "So what you do is you would not touch all the variables at the same time."
        ],
        [
            "But instead you keep all but one point fixed, so you fix all the points here and start to only move the first 2 variables or the first N variables that belong to the first point.",
            "So then you want."
        ],
        [
            "To optimize this point with respect to the over hypervolume.",
            "And then you have all this optimization problems in dimension North and then you just."
        ],
        [
            "Go to the next point to the next solution.",
            "The next N variables.",
            "So then you just go through this and you iterate.",
            "Becaused"
        ],
        [
            "This is a dynamic objective function, so whenever you are, you went through all the through all the solutions.",
            "So through all the points, then the neighbors have changed and therefore the hypervolume optimization problem for each solution has changed, right?",
            "So now if we go back.",
            "This was the first point, now after I have optimized this point I will touch this one and this one and they also move and therefore the hypervolume for this point will also move in the next iteration.",
            "So this is kind of a dynamic fitness.",
            "A dynamic objective function.",
            "Um?",
            "You can also see this as."
        ],
        [
            "Looking at the hypervolume improvement.",
            "So as I said, we fix all but one point and then you optimize with respect to this point.",
            "That's just the same as fixing all these P -- 1 points and trying to find the point that improves over the set of.",
            "In this case five points.",
            "Optimally.",
            "And this is how this hypervolume improvement objective function looks like.",
            "This is again the search space.",
            "This is the objective space.",
            "And what we see other level sets, so the lines of equal hypervolume improvement.",
            "Right, So what we see here?",
            "If we are in this dominated area we are in this normal hypervolume case where each point here is with respect to this hypervolume improvement.",
            "So the lines of equal.",
            "If your function value here equals hypervolume improvement hyperparameters.",
            "And this is smooth here, but not.",
            "It's continuous, but not.",
            "Awesome.",
            "This looks how is looking in the search space, so this is what the algorithm would actually look like or would look at and what you see is that inside this dominated area here it behaves quite nicely, so we are in the case where both objective functions are spheres.",
            "That also looks very much sphere like, so this looks like a simple optimization problem."
        ],
        [
            "But if you have a dominated point, then this objective function is flat.",
            "Write the same problem then before for the gradient.",
            "Yes, there's no way you can have any direction of search for the algorithm.",
            "OK, so."
        ],
        [
            "What are people doing instead, usually in order to kind of flatten this hypervolume improvement?",
            "So in order to get in the dominated area?",
            "Some.",
            "Direction of the search for the algorithm is.",
            "You can combine it with nondominated sorting, so this is what typical algorithms like this MSN.",
            "Why would do or the multi objective CMAS so you would.",
            "If you have a set and you want to remove some points.",
            "You would first do nondominated sorting, so it would assign to each point.",
            "Non dominated the best rank so this would if this is our set here of the six solutions.",
            "Those ones here that undominated they would get the best rank.",
            "Then you would temporarily remove them and do for the rest the same you would again compute the nondominated solutions and they would get rank that is by one worse etc until you have assigned a rank through all of them and then you would go from the lowest ranked solutions and would remove them with respect to the hypervolume.",
            "With respect to this set of the same rank, so in our case, that would mean if you would remove some points, you would start with this one and then afterwards if you want to remove another point you would remove them, remove it among these five points, and then you would use the hypervolume.",
            "So if we do this now for the hypervolume improvement, we can do the same.",
            "So we can say if the point is not dominated.",
            "Here we use the normal hypervolume improvement.",
            "If the point is dominated.",
            "So it is dominated by one of these points here.",
            "So if we are in this area we can say then we do the hypervolume improvement with respect to the current non domination front.",
            "So the same the points that have the same rank then the point you would introduce.",
            "So therefore if you look at this area here, it looks exactly the same then before just different colors because the overall color was changing and then in the other area here.",
            "It looks the same, also hyperbolic improvement.",
            "So you see the same lines of function values equal function values but with respect to this point here as the kind of front and over here, this is the same where you would assume you have no point, so it's just the hyper V with respect to this point here.",
            "So this is.",
            "Kind of how the fitness of common algorithms that do not dominate sorting plus hypervolume selection look like.",
            "An yeah 2."
        ],
        [
            "Observations.",
            "Three, the first one is now the hypervolume improvement is unflattened in the dominated region, so we have some direction.",
            "Towards better solutions.",
            "But above the reference point, so everything outside is still flat, so this is still a problem.",
            "So the choice of the reference point has an influence in practice.",
            "So if you have points that are outside, you still have no information of where to go."
        ],
        [
            "And the other observation.",
            "Is that if you look at the search direction here, search correction means if you follow the gradient of this level set so always perpendicular to the level sets right?",
            "Then you would always go.",
            "Optimization would move in this direction right?",
            "So if you're here you would try to optimize here and what you see is you will always optimize towards the point that you already have.",
            "That is by definition.",
            "So if you're here, we try to optimize.",
            "You always will end up.",
            "Or most likely will end up at the point where you already, so therefore that's probably not what you want.",
            "What you prefer would like to prefer us if you want to optimize for this point instead of this going towards this direction, it would be better to go here, because then you would have introduced a new new nondominated point.",
            "OK, so these are things that we tried to solve with our approach, and the idea is very simple.",
            "Surprised that nobody else had this idea before."
        ],
        [
            "And this is what we call now.",
            "The uncrowded hypervolume improvement, because it not only UN flattens it, but it's.",
            "Pushes solutions that are dominated towards uncrowded regions of the.",
            "Of the local preference and what we do is if the point is.",
            "Nondominated by the overall set, so the black ones here are the set that we have and the blue ones are some example points that we just add.",
            "So if this is dominated the nondominated here then we just use the normal hypervolume improvement.",
            "So this is this area that you get in addition to the normal hypervolume and if you are dominated by a point, so for example here you just choose the distance Euclidean distance to this black line.",
            "So this is the what we call the non dominated.",
            "The empirical nondominated front so it's just.",
            "The line that is given by the nondominated points and if you are here for example, you would choose again the new clean distance, which is the Euclidean distance to this corner point here.",
            "And if you do that."
        ],
        [
            "I have to say here, this is the empirical nondominated front and if you do that."
        ],
        [
            "Then everything looks like this.",
            "So again, the same thing, we just plot the lines of equal, uncrowded, hypervolume improvement now.",
            "In the dominant dominated area is the same than before.",
            "But in the dominated area is just now the distance to this line here that is given by the nondominated points OK. Now also some observations."
        ],
        [
            "The first"
        ],
        [
            "Observation is now the also outside of this region here, so above the reference point it is giving some directions for the search.",
            "So this is in this sense unflattened everywhere really, not just until the reference point like before and the search direction now points towards the.",
            "Uncrowded region, so towards the regions that where we don't have points.",
            "So if I start with this point and I want to improve it, kind of I would just go in this direction here if you follow the.",
            "Decrease distance in distance.",
            "I would just be here if I'm here, I would always be driven towards region where I was not where I don't have yet to point.",
            "OK.",
            "So that's the idea."
        ],
        [
            "And this we put into the so called suffer more framework which stands for single objective optimization for optimizing multi objective optimization problems.",
            "And that was a bit tricky to get to this acronym.",
            "The nice thing is the PhD student share who did this here in the second year of his PhD.",
            "So that fits the supermodel name.",
            "But this is the algorithm.",
            "The framework that does exactly what they said before.",
            "So we start with want to optimize P points and now we do for each.",
            "Of these points, we have a single objective optimizer.",
            "And we don't say here which one it is.",
            "It just say that each one of these optimizers says initial internal state.",
            "And that each of these optimizers will be able to recommend solution.",
            "So this is kind of.",
            "We assume that each algorithm has an idea of where the optimum is at each time.",
            "CMAS, for example, has this naturally, but also model based algorithms typically have this.",
            "They know where the optimum of the model is.",
            "Yes, and these are now.",
            "So this recommendations are now the points in the objective space that we have seen before.",
            "Like the points that I put in, there can be dominated on dominated.",
            "We don't care about this.",
            "Now.",
            "What we do is we just run a loop until some stopping criterion is met.",
            "And what we do in each?",
            "Iteration we choose one of the points.",
            "One of the optimizers.",
            "Which we also call kernels here.",
            "And a number of times.",
            "Tell I that we run this algorithm, so we run the algorithm I.",
            "4 to 8 times to iterations.",
            "This.",
            "Objective function that is this uncrowded hypervolume improvement with respect to all the other points, but the F1, so we keep this, is the definition.",
            "Here we keep all, but I fixed so kind of if you have these points, you kind of remove the point.",
            "The recommendation of the ice optimiser and then you try to improve the hypervolume improvement for iterations.",
            "Then at the end you also have to update this recommendation based on what the algorithm is giving and that's it.",
            "So not too complicated, but there are many design decisions that you can do.",
            "I didn't say which algorithm we use.",
            "I also didn't say how we choose this points etc etc.",
            "So what we did then is to instantiate."
        ],
        [
            "This former framework, with some specific solvers.",
            "And then the Como Cmas came out the.",
            "CMAS stands for covariance matrix adaptation evolution strategy, so it's a stochastic algorithm that has a.",
            "Internal probability distribution multivariate normal distribution.",
            "It samples Lambda points from this and then evaluates this Lambda points and depending on the ranking of this Lambda points with respect to F, it updates the internal probability distribution.",
            "So the mean the step size and the covariance matrix.",
            "This is CMA in a nutshell, and we know not from three we got from practice that this algorithm can learn the in.",
            "Yeah, the inverse of the Hessian of convex graphic problems.",
            "The theory is a bit more complicated, but we are convinced that we can prove it in.",
            "In 10 years, let's see.",
            "Um?",
            "Yeah, so this is the algorithm that we just put in as the solver and we use the sofa for sofa more framework with this uncrowded hypervolume improvement and the details details are that the recommendation that I was talking about we use the means of the probability distributions of each CMA as this incumbent or kernel.",
            "And then we always choose a kernel that we have not seen so far in the overall iteration before to see all kernels.",
            "So what we do is we and this is.",
            "But now we see this here, yes, so we sample.",
            "A permutation.",
            "On all accounts on all points, then we touch each of these kernels once.",
            "Before we touch it again.",
            "Right, so we really and then we draw again a random new random permutation.",
            "Then this towel I we chose as one right now, so we just do one iteration of the CMAS at each time, and then we go to the next kernel and move another point.",
            "And all this is done in Python, so it's really, really easy without asking tell interface of the PIE CMA module.",
            "So you just need to ask for the new points and afterwards tell the algorithm.",
            "What are the evaluations of these points?",
            "And in between we can hear compute really the fitness as a defined before the uncrowded type of volume improvement, where all the other points are fixed.",
            "OK, so that's it.",
            "Now I have a bit of time.",
            "I hope to talk about."
        ],
        [
            "Numerical results.",
            "And yeah, I have to start with."
        ],
        [
            "The original question right?",
            "Can we converge towards the optimal hypervolume?",
            "So given P, the number of points and the hypervolume indicator can be converted to this optimal hypervolume?",
            "And the first part I will show is exactly for the same problem that we have seen so far.",
            "So this double sphere problem, the sum of the XI squared for the first objective with the optimum zero.",
            "And this function here, which is the same but with the optimum in one 000.",
            "Now what they will plot is overtime, so here this is the.",
            "In our case the time or the number of.",
            "Function evaluations the number of times we call the black box.",
            "Divided by the number of kernels of the divided by P. And here we show in the log scale the difference of the hypervolume to the optimal hypervolume.",
            "I'm in this case we can.",
            "No, the optimal hyper volume four points and what we prefer now we wanted to have is kind of linear decrease in this log scale."
        ],
        [
            "And this is the result.",
            "So this is one run on this problem here with 10 variables and 31 points.",
            "So in the formalization that's set before, we now have a 310 dimensional problem.",
            "We see the hyper volume decreases or the hyperbolic distance to the optimal decreases linearly, so this is what we want and what we also see kind of.",
            "Here is the first phase where the single objective CMA's have to learn something and then you really see this decrease.",
            "And this you can also look at different.",
            "At other problems.",
            "I also have."
        ],
        [
            "Plot, which is not so interesting because it's mainly empty about the ratio of non dominated points among the P. So this really quickly goes up.",
            "So you start with dominated points but with respect to the distance that you optimize to the empirical front.",
            "This really goes up very quickly, so this is not so interesting plot, but we just verified that this is actually optimizing.",
            "Now we can."
        ],
        [
            "Cat also.",
            "Covariance matrix of the single objective CMAS.",
            "And here this is plotted for three randomly chosen kernels.",
            "So three out of the 31.",
            "And if you know about CMA, that looks a bit like you optimize really a sphere function, so the single objectives are spheres.",
            "Um?",
            "And as we have seen before, the level sets look like a bit like sphere functions, and we have the theory also in the paper.",
            "If you're interested, we know how the.",
            "Other problem looks like, so the Hessian.",
            "Close to the objective function is more or less the sphere function plus some.",
            "Rank one matrices that you that you add, so that's not surprising.",
            "Then that the algorithm, the single objective algorithms really see.",
            "Yes, yes and then."
        ],
        [
            "Holds for different problems.",
            "Convex cratic problems.",
            "So this was the fact that we have seen before.",
            "So where we have two sphere functions.",
            "That's the same if you look at elliptic functions.",
            "If they are separable so they are aligned to the axis also holds on other convex clarity functions where the spectrum is with different.",
            "So C gotta type function but also.",
            "If we have rotated, it's so it's so the two objective functions are rotated ellipsoid function, so the level sets are rotated ellipse and if they are not rotated in the same way, then the creator set is not a straight line anymore, but curve.",
            "And even in this case we see.",
            "This linear linear convergence is the hyperbolic difference."
        ],
        [
            "OK, so you can say nice, but all later have shown now was single runs so maybe that doesn't always happen.",
            "But we are also."
        ],
        [
            "There's no proof.",
            "We were convinced that it that it works.",
            "So here we see always four runs.",
            "And they always look more or less the same, and for four different algorithms.",
            "And the blue one is the Como CMA's that we have just seen.",
            "Now the green one is the previous multiobjective CMA variant from 2010.",
            "Must say so.",
            "The original paper was in 2007 and then there was a small a big improvement made in 2010.",
            "So this is the comparative algorithm.",
            "And then we have SMS or more.",
            "In purple here and in black we have the energy to.",
            "The Purple One is also supposed to optimize for the hypervolume.",
            "The Black one doesn't."
        ],
        [
            "And if we look now into this a bit more closely, so this is the first plot really on the same problem where both objective functions are functions.",
            "And now this looks a bit different here because in the plot we don't look at the optimum.",
            "We look at the best found by all the algorithms.",
            "So therefore this is a bit numerics here and you don't.",
            "Don't look at everything that is below anything that is below 10 to the minus 710 to the minus 14.",
            "OK, so here we see that the multi objective C MSD origonal one is faster.",
            "So this is for those who know it's a 1 + 1 strategy and this is a common strategy here.",
            "So this is supposed to be.",
            "On the on the sphere the same the convergence rate, but we didn't do any test.",
            "Any tuning of parameters, so we we are confident that we can drop this a bit.",
            "But we didn't do any tuning.",
            "This is surely the algorithm, and although this algorithm also tries to optimize the high performance this far slower.",
            "And this happens all kinds of.",
            "Problems.",
            "Um?"
        ],
        [
            "Yes, so this is the plot on the elliptic functions where both objective functions are ellipsoids.",
            "Instead of circles.",
            "And they are the common.",
            "CIS is better than all the other algorithms, and you'll see that the variances in the log scale not too large.",
            "So among four algorithms, so clearly this is statistically significantly better than this one and buy orders of magnitude."
        ],
        [
            "The interesting thing is we also looked at."
        ],
        [
            "So here we really look at the hypervolume difference between the optimum.",
            "The optimal performance that can reach with P points and the population of the algorithm in these two cases or the really number of kernels that we have in these two algorithms.",
            "Right, so we always look at sets of size P, But we can also do is we can look at the whole set of non dominated points that have been found by the algorithm.",
            "So with respect to the archive, the nondominated."
        ],
        [
            "Archive and then we see something like this.",
            "This is again two sphere problem.",
            "The biosphere problem we're here.",
            "Now we look at the difference between the hypervolume of all the points that have been found.",
            "Compared to the best you can get so kind of the hypervolume of the entire operator front, so therefore we don't go down too many too much precision, but also here we see that the Como Cmas is the best algorithm.",
            "Although none of this algorithm was supposed to be good in this setup."
        ],
        [
            "And this is for the ellipsoid function.",
            "So also here the cool mild rhythm is better than the others.",
            "And we also understood why it is better than the 1 + 1 CMA.",
            "So the more CMA is here because in order to converge with a common strategy, you can have a larger step size and this is beneficial in this setup where you converge two points.",
            "But if you have a larger step size to produce new points, you will always produce more points in the middle in between two points that will go into the archive and that will make the aircraft better.",
            "So This is why this also works here.",
            "We also looked at comparison with other algorithms over a larger set of functions which are not just convex quadratic."
        ],
        [
            "For example, with respect to the comparing continuous Optimizer platform where there is a by objective.",
            "Test suite with 55 functions.",
            "And.",
            "Yeah, so here we tested different number of kernels so Como is always the one that I just talked about.",
            "The comma multi objective CMA is the 1 + 1.",
            "Here is the merges the 2010 version that I just talked about before so the green.",
            "The green algorithm here.",
            "Then the Energycap 2 here is kind of the same the MATLAB implementation.",
            "This is like the black one here.",
            "And that's all what we see here.",
            "So the number here is the number of kernel kernels.",
            "So we have tried to approximate the preset with thousand points with 316 with 10.",
            "With three and, these are the empirical cumulative distribution functions of the runtime to reach certain target precisions.",
            "So here, this is the again, the time number of function evaluations in log scale.",
            "Divided by dimension and here is the number of problems that are solved at this time.",
            "So one algorithm is one line, and the higher the algorithm the better, and the more to the left the better.",
            "So the best algorithms are the ones that are here on top.",
            "And as a comparison, this line here the thick line is an artificial algorithm is the best performance that you can get from 16 algorithms that were submitted in 2016 to the workshop that we organized.",
            "So this is kind of the reference.",
            "And you see that single algorithms already reached this performance here in the overall.",
            "Aggregation, so overall 55 functions and."
        ],
        [
            "If you look closely to subsets of the functions, you see that on some in particular, the more complicated ones these algorithms can be better than the best."
        ],
        [
            "And that happens for several for several groups.",
            "So since we did not do any parameter tuning, we think that we can gain also there in the future.",
            "And one thing that we also didn't do, which looks very much.",
            "Needed here is to adapt the number of kernels, so adapt the number of points."
        ],
        [
            "You get if you look at the result here for example.",
            "This is the performance.",
            "The best performing algorithm is the one where we have only three points, then afterwards become better.",
            "Here if we have 10 points and then here we come better.",
            "If you have 32 points etc.",
            "So kind of what we should have is an algorithm that starts with a few number of points and then once you detect it you are the front.",
            "You just increase the number of points adaptively.",
            "So this is what we plan in the future."
        ],
        [
            "OK, so to conclude.",
            "We had a goal to converge linearly towards the optimal set of points with respect to the hypervolume indicator, which we managed to achieve with this new algorithm.",
            "Como CMA, yes, so we have some data that works well on convex traffic problems on the variety of them.",
            "For now it's only tested on two objective functions.",
            "But there's no reason that it should not work on in higher dimension.",
            "You just didn't try it.",
            "Um?",
            "Yes, we did it.",
            "With the following steps.",
            "So we introduce this new fitness or new objective function the unclouded hypervolume improvement, which is nothing else than the original hypervolume improvement.",
            "If you're nondominated now adding the Euclidean distance to the empirical front.",
            "If you have dominated point.",
            "And then we do this subspace optimization.",
            "So we only optimize one point at a time.",
            "It's relatively with CMA S, so single objective algorithm that optimizes this single objective hypervolume improvement and we only do one iteration of the algorithm before we touch.",
            "Before we touch all the other accounts.",
            "And we really just used the CMA as the default one.",
            "Didn't change anything and it worked.",
            "So this is one point we want to look at.",
            "What can we gain by parameter tuning?",
            "Yes, I also talked about this more general framework, so for more where.",
            "We can also plug in other algorithms, so this is clearly something we want to test.",
            "From the bbob data, so the Coco results.",
            "We know that SLP is the best performing algorithm, typically for low budgets, the best out of 200 algorithms.",
            "So this is something we would like to try.",
            "We definitely need to implement restart, so for now the algorithm just runs until forever.",
            "There's no stopping criterion, we just let it run.",
            "So that's also something that would improve the performance on multimodal functions for sure.",
            "So where you would need to say on I detect that I'm stuck and I would just restart the algorithm or put more points in, which is the probably the most crucial improvement that we can think of for improving the performance so.",
            "At number of points or increase the number of points adaptively.",
            "OK yeah, before I stop I want to make some."
        ],
        [
            "Advertisement So as you've seen, we work on this comparing continuous optimizes platform, so this is all available.",
            "If you are interested, just follow what we do.",
            "Try to benchmark your algorithms with the software so we always have a workshop at the Gecko Conference this year, again in July, where we try to collect data for comparing algorithms.",
            "OK."
        ],
        [
            "All so thank you very much and.",
            "Please ask questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good morning everybody.",
                    "label": 0
                },
                {
                    "sent": "And hello to all the people in the Internet to millions of viewers.",
                    "label": 1
                },
                {
                    "sent": "Yeah, I'm really happy to talk about today about our latest research and have to say latest because it's really literally latest and even change the title in between because the deadline was last week and we.",
                    "label": 0
                },
                {
                    "sent": "One hour before the deadline, we change the title so I'm not going to talk about the unflattened hypervolume improvement today.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But about the uncrowded, hypervolemic content is the same, but the title changed, so I hope you're not too disappointed.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is joint work with share Tori Nicholas Hanson and Energy.",
                    "label": 1
                },
                {
                    "sent": "We are all in the Roundup team at INRIA and also at awkward Polytechnique and the new structure around this is the Epub Reader Institute.",
                    "label": 0
                },
                {
                    "sent": "Polytechnic Department yeah so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm mainly talking about multi objective optimization today.",
                    "label": 0
                },
                {
                    "sent": "But I want to start with general overview of which type of forms we're looking at.",
                    "label": 0
                },
                {
                    "sent": "We are typically looking at challenging optimization problems.",
                    "label": 1
                },
                {
                    "sent": "And by challenging I mean they are kind of nasty and not so nice, so they're typically not linear, non convex.",
                    "label": 0
                },
                {
                    "sent": "There might be rocked etc.",
                    "label": 0
                },
                {
                    "sent": "And they appear in many application areas.",
                    "label": 1
                },
                {
                    "sent": "For example, in the design of new products like this train here or car, where for example you want to change the OR find the.",
                    "label": 0
                },
                {
                    "sent": "Design the structure of these nodes of the train in order to reduce the drag, for example, or if you want to design A rocket you have para meters like the width of the rock at the height of the rocket, how much propellant do you put, etc.",
                    "label": 0
                },
                {
                    "sent": "So all kinds of parameters that you can change, and once you want to maximizes the payload, you can get into it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we are talking about this challenging optimization problems and because they are so difficult we typically.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at them as black box optimization problems where all the difficulties of the problem are inside this black box and the algorithm can only query this black box.",
                    "label": 0
                },
                {
                    "sent": "So we assume for now that we are in numerical optimization.",
                    "label": 0
                },
                {
                    "sent": "So where we have.",
                    "label": 0
                },
                {
                    "sent": "Para meters that are continuous, so have any continuous parameters that I can put into my black box and then after some point in time I get back the function evaluation F of X and this can be a single value.",
                    "label": 0
                },
                {
                    "sent": "Then the single objective case or if this is if you get more than two values that two or more than we are and the multi objective case.",
                    "label": 0
                },
                {
                    "sent": "So this is also common in practice.",
                    "label": 0
                },
                {
                    "sent": "So for example one to maximize performance but also minimize costs.",
                    "label": 0
                },
                {
                    "sent": "And yeah, for this multi objective optimization problems, things are slightly different.",
                    "label": 0
                },
                {
                    "sent": "Then in single objective problems, for now I don't talk about constraints.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Usually you also have constraints.",
                    "label": 0
                },
                {
                    "sent": "Here I will just not talk about this.",
                    "label": 0
                },
                {
                    "sent": "To make things simpler.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But the comparison to single objective optimization.",
                    "label": 0
                },
                {
                    "sent": "In the single objective case, you always have a real value, so therefore you can always compare two solutions.",
                    "label": 0
                },
                {
                    "sent": "So X&Y and you can always say X is better or why is better or the same in terms of the function value and therefore also the optimal function value is well defined mathematically.",
                    "label": 0
                },
                {
                    "sent": "In the multi objective case.",
                    "label": 0
                },
                {
                    "sent": "So if you have a larger than one then you can have the case that you have two incomparable solutions.",
                    "label": 1
                },
                {
                    "sent": "So for one the first objective is better and for the other one the second one.",
                    "label": 0
                },
                {
                    "sent": "For example one is more performant, the other one is cheaper.",
                    "label": 1
                },
                {
                    "sent": "Therefore, you have tradeoffs between the objectives and then the optimal value concept translates into the optimum being a set, and this looks.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like that so now if you look at the two objectives here, the first objective and the second objective both to be minimized.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we can throw in some solutions and we see the how they solutions the stars performed with respect these two objective functions.",
                    "label": 0
                },
                {
                    "sent": "And then we can.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See something like example.",
                    "label": 0
                },
                {
                    "sent": "This one here is better than this yellow one because it is better smaller in both objective functions.",
                    "label": 0
                },
                {
                    "sent": "So if one is smaller and F2 is smaller for the red one, then for the yellow one.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Comparability, I assume this is what I should say this.",
                    "label": 0
                },
                {
                    "sent": "We also say typically then the red one dominates the yellow.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And incompatibility you see here between these solutions.",
                    "label": 0
                },
                {
                    "sent": "For example, where this solution is better with respect to F1 but works with this vector two and this one is better.",
                    "label": 0
                },
                {
                    "sent": "Smaller with the specter of two but worse with respective one.",
                    "label": 0
                },
                {
                    "sent": "So they're incomparable.",
                    "label": 0
                },
                {
                    "sent": "And then if you look at all the solutions that are not dominated by any other in this case, these are the red ones here.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are the so-called preacher optimal objective vectors, and together they are called the printer front.",
                    "label": 0
                },
                {
                    "sent": "So these are all solutions where there is no other solution to the lower left, so with smaller F1 and F2 then.",
                    "label": 0
                },
                {
                    "sent": "And of course, everything generalizes to more than two objectives.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And another difference, two single objective optimizations that we have actually two spaces.",
                    "label": 0
                },
                {
                    "sent": "So this is the space that in single objective case you would never look at because it's trivial, just R. So here we are in R2, but what you would usually look at is the search space.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this we also have here.",
                    "label": 1
                },
                {
                    "sent": "So the algorithms that actually optimize the solutions lift, typically in the search space.",
                    "label": 0
                },
                {
                    "sent": "So where you have the parameters X12 X, let's say M let's say XN.",
                    "label": 0
                },
                {
                    "sent": "And each of these solutions here is then mapped to the objective space and we evaluate the solutions in the objective space.",
                    "label": 0
                },
                {
                    "sent": "But the actual optimizations going on here and the preimage of this pressure front is called the creator set.",
                    "label": 1
                },
                {
                    "sent": "This is the set of red solutions here that we usually want to find.",
                    "label": 1
                },
                {
                    "sent": "Want to find is a bit.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Underspecified, so usually the question is what is the actual optimization goal of this type of problems?",
                    "label": 0
                },
                {
                    "sent": "And one way to look at this is.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can look at a set based formalisation with respect and quality indicator.",
                    "label": 0
                },
                {
                    "sent": "And what you are interested in is you have given a set of number of points P. And a quality indicator.",
                    "label": 1
                },
                {
                    "sent": "I will explain in the immediate what it is, but just this is a function that takes a set of solutions and returns a quality.",
                    "label": 0
                },
                {
                    "sent": "Can be anything.",
                    "label": 0
                },
                {
                    "sent": "And then we are interested in what is the set of points that optimizes this quality so it maximizes this quality.",
                    "label": 1
                },
                {
                    "sent": "And there are many quality indicators around.",
                    "label": 0
                },
                {
                    "sent": "Probably the most common ones are these ones, the hypervolume, the excellent indicator to indicator, and the hypervolume.",
                    "label": 0
                },
                {
                    "sent": "I will explain because our algorithm is based on this and it also has the nicest theoretical properties.",
                    "label": 0
                },
                {
                    "sent": "So for example, the volume is the only quality indicator that we know that is strictly monotone in the sense that if I add a point to a set that is non dominated, it will increase strictly increase the value.",
                    "label": 0
                },
                {
                    "sent": "And if you have such a formalization, so you specify how many.",
                    "label": 0
                },
                {
                    "sent": "Points.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Want to have and the indicator.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then this.",
                    "label": 0
                },
                {
                    "sent": "Is nothing else than a single objective optimization problem, but now in a higher dimension.",
                    "label": 0
                },
                {
                    "sent": "So now if you have points, each of them has variables in parameters, then this is just a P * N dimensional single objective problem.",
                    "label": 0
                },
                {
                    "sent": "Or you want to maximize the indicator.",
                    "label": 0
                },
                {
                    "sent": "OK, so now what is the hyper volume indicator?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's also for two objectives, relatively simple to see.",
                    "label": 0
                },
                {
                    "sent": "That's the area of the dominated space.",
                    "label": 0
                },
                {
                    "sent": "So this is again the same problem before 2 objectives to be minimized.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We put in a set here.",
                    "label": 0
                },
                {
                    "sent": "There all non dominated solutions but they don't have to be and then you have to specify the so called.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reference point, which is a parameter of the indicator.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And then the quality of this red set is nothing.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then the area of the objective space that is dominated and at the same time bounded by the reference point.",
                    "label": 1
                },
                {
                    "sent": "So everything so kind of is integral over all of the objective space.",
                    "label": 0
                },
                {
                    "sent": "Overall points that are one if it is dominated by a red solution and not dominating, not dominated and dominating the reference point and 0 otherwise.",
                    "label": 0
                },
                {
                    "sent": "So here is just the area.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the main question of my talk now is can we and if we can, how converge towards the optimal hypervolume linearly?",
                    "label": 0
                },
                {
                    "sent": "So if we have given set a number of points P and the quality indicator the hypervolume, can we converge to this set of points that maximize the indicator?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so how could we approach this and remember here that I said this is nothing is in a single objective optimization problem in dimension P times North.",
                    "label": 0
                },
                {
                    "sent": "And I will give a example that will go throughout the talk to just compare different approaches.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we look at the search space.",
                    "label": 0
                },
                {
                    "sent": "So here for two the simplest case for two variables X1 and X2 so.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "North in this.",
                    "label": 0
                },
                {
                    "sent": "Problem definition is 2.",
                    "label": 0
                },
                {
                    "sent": "And now I want to construct the problem or I will talk about the problem that is the simplest of all.",
                    "label": 0
                },
                {
                    "sent": "Non trivial problems and I have marked here the.",
                    "label": 0
                },
                {
                    "sent": "Single objective Optima.",
                    "label": 0
                },
                {
                    "sent": "As this dots here.",
                    "label": 0
                },
                {
                    "sent": "So the optimum for the first objective is in the zero vector and it's in 10000 in the higher dimensions.",
                    "label": 0
                },
                {
                    "sent": "For the second objective.",
                    "label": 0
                },
                {
                    "sent": "OK and I want to have a problem where the printer set.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the straight line between them and then I just throw.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a number of points, let's say six points is at this point here, so one is on the printer set three, or here above one is below and one is exactly the optimal.",
                    "label": 0
                },
                {
                    "sent": "Just for illustration purposes, and then I just try to see what is going on.",
                    "label": 0
                },
                {
                    "sent": "How this problem actually looks like?",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If this is the search space, I have to define what is the function in order to see something and here I.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Choose really the simplest, simplest problems, so the so called double sphere problem.",
                    "label": 0
                },
                {
                    "sent": "So in the first objective this is the sum.",
                    "label": 0
                },
                {
                    "sent": "Of the XI squared.",
                    "label": 0
                },
                {
                    "sent": "Because the first optimum here is in the all zero.",
                    "label": 0
                },
                {
                    "sent": "And for the second one, it is the square of the sum of the square of the XI minus the optimal value.",
                    "label": 0
                },
                {
                    "sent": "So it's X 1 -- 1 ^2 plus the sum of the XI square for all the rest.",
                    "label": 0
                },
                {
                    "sent": "And then if you look at the level set so the lines of equal function value, these are just circles around the rounded to optimal.",
                    "label": 0
                },
                {
                    "sent": "So for the first objective with the optimal here these are the level sets here, so these are circles with the center in this optimum and the other way round.",
                    "label": 0
                },
                {
                    "sent": "These other level sets for the second objective.",
                    "label": 0
                },
                {
                    "sent": "And that means also in this plot we can now to put these six points into the objective space.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it looks like this, so we have now F1 and F2 both to be minimized and each of these points now translates to a point here so.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example, this one here that has by definition the way I put it the same distance to the two Optima.",
                    "label": 0
                },
                {
                    "sent": "So the same function value that Maps to this point here.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Contrary, this one here has the same.",
                    "label": 0
                },
                {
                    "sent": "Also the two distances are the same, but it's closer so that the sum of the squares smaller, and therefore it is moved here dominating the other point.",
                    "label": 0
                },
                {
                    "sent": "So this point here is dominating this one.",
                    "label": 0
                },
                {
                    "sent": "It's also closer to the operator set and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, this one that is here exactly at the preset has very small distance, very small F value in F1, so it's close to 0 here and has a very large distance.",
                    "label": 0
                },
                {
                    "sent": "Large sum of the squares with respect to the.",
                    "label": 0
                },
                {
                    "sent": "Second objective.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The example.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now how does this problem look like?",
                    "label": 0
                },
                {
                    "sent": "So we would now put the X values of these points into our North Times P dimensional vector.",
                    "label": 0
                },
                {
                    "sent": "So the first 2 variables of the first point, then the second point with these two variables, etc up to the last point.",
                    "label": 0
                },
                {
                    "sent": "With these two variables.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we map this to the hypervolume.",
                    "label": 0
                },
                {
                    "sent": "So in this case here we have a dominated point.",
                    "label": 0
                },
                {
                    "sent": "Here it is the area this green area.",
                    "label": 0
                },
                {
                    "sent": "So far.",
                    "label": 0
                },
                {
                    "sent": "Nothing you.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now how can we approach this?",
                    "label": 0
                },
                {
                    "sent": "So one way would be OK, you can say this is single objective problem.",
                    "label": 0
                },
                {
                    "sent": "I might be able to compute the gradient and you can just do that because the hypervolume is nothing less than the sum of areas.",
                    "label": 0
                },
                {
                    "sent": "Here some of rectangles in the two dimensional case.",
                    "label": 0
                },
                {
                    "sent": "So you can compute the gradient and then you can just could run a gradient based algorithm on this.",
                    "label": 0
                },
                {
                    "sent": "Quite a YouTube, JS, whatever who you think of.",
                    "label": 0
                },
                {
                    "sent": "But that has some.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Impracticalities one is that it's much higher than the original, much higher dimensional than the original problem.",
                    "label": 0
                },
                {
                    "sent": "Now you have P * N dimensional.",
                    "label": 0
                },
                {
                    "sent": "Usually you search for it's 100 points and if you do this in 100 dimensional space, the problem is already high dimension.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But you have also large scale variance of gradient based algorithms, so this is not a big problem in practice.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the bigger problem are these dominated points here.",
                    "label": 0
                },
                {
                    "sent": "And this is also in the original paper.",
                    "label": 0
                },
                {
                    "sent": "From this year, actually.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you look at this, if I move this point here, it has no effect on the hypervolume, so because it's a dominated point, the area that is dominated by the whole set is not changing.",
                    "label": 0
                },
                {
                    "sent": "If I move this point around here.",
                    "label": 0
                },
                {
                    "sent": "So if I compute the gradient, it has really zero entries for the two X values that belong to this point, and this is really the problem for the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So you cannot just run gradient based algorithm that.",
                    "label": 0
                },
                {
                    "sent": "If you start with the with dominated points in your set here, then it will just not work and the work around they do in this paper is you run an evolutionary algorithm first to get a nice set of spread points.",
                    "label": 0
                },
                {
                    "sent": "And once you have a set of nondominated points in the algorithm, then you switch over to the gradient based out.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of like you start evolutionary algorithm with key points we optimize and then once you say OK, I'm close to the front, then you would run a gradient based algorithm local solver to come closer to the to the front.",
                    "label": 0
                },
                {
                    "sent": "OK, so now how do we approach these two things?",
                    "label": 0
                },
                {
                    "sent": "The first part is relatively simple that.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, I think already mentioned in this paper you can do subspace optimization.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you would not touch all the variables at the same time.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But instead you keep all but one point fixed, so you fix all the points here and start to only move the first 2 variables or the first N variables that belong to the first point.",
                    "label": 0
                },
                {
                    "sent": "So then you want.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To optimize this point with respect to the over hypervolume.",
                    "label": 0
                },
                {
                    "sent": "And then you have all this optimization problems in dimension North and then you just.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go to the next point to the next solution.",
                    "label": 0
                },
                {
                    "sent": "The next N variables.",
                    "label": 0
                },
                {
                    "sent": "So then you just go through this and you iterate.",
                    "label": 0
                },
                {
                    "sent": "Becaused",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a dynamic objective function, so whenever you are, you went through all the through all the solutions.",
                    "label": 0
                },
                {
                    "sent": "So through all the points, then the neighbors have changed and therefore the hypervolume optimization problem for each solution has changed, right?",
                    "label": 0
                },
                {
                    "sent": "So now if we go back.",
                    "label": 0
                },
                {
                    "sent": "This was the first point, now after I have optimized this point I will touch this one and this one and they also move and therefore the hypervolume for this point will also move in the next iteration.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of a dynamic fitness.",
                    "label": 0
                },
                {
                    "sent": "A dynamic objective function.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You can also see this as.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Looking at the hypervolume improvement.",
                    "label": 1
                },
                {
                    "sent": "So as I said, we fix all but one point and then you optimize with respect to this point.",
                    "label": 0
                },
                {
                    "sent": "That's just the same as fixing all these P -- 1 points and trying to find the point that improves over the set of.",
                    "label": 0
                },
                {
                    "sent": "In this case five points.",
                    "label": 0
                },
                {
                    "sent": "Optimally.",
                    "label": 0
                },
                {
                    "sent": "And this is how this hypervolume improvement objective function looks like.",
                    "label": 0
                },
                {
                    "sent": "This is again the search space.",
                    "label": 0
                },
                {
                    "sent": "This is the objective space.",
                    "label": 1
                },
                {
                    "sent": "And what we see other level sets, so the lines of equal hypervolume improvement.",
                    "label": 0
                },
                {
                    "sent": "Right, So what we see here?",
                    "label": 0
                },
                {
                    "sent": "If we are in this dominated area we are in this normal hypervolume case where each point here is with respect to this hypervolume improvement.",
                    "label": 0
                },
                {
                    "sent": "So the lines of equal.",
                    "label": 0
                },
                {
                    "sent": "If your function value here equals hypervolume improvement hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "And this is smooth here, but not.",
                    "label": 0
                },
                {
                    "sent": "It's continuous, but not.",
                    "label": 0
                },
                {
                    "sent": "Awesome.",
                    "label": 0
                },
                {
                    "sent": "This looks how is looking in the search space, so this is what the algorithm would actually look like or would look at and what you see is that inside this dominated area here it behaves quite nicely, so we are in the case where both objective functions are spheres.",
                    "label": 0
                },
                {
                    "sent": "That also looks very much sphere like, so this looks like a simple optimization problem.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if you have a dominated point, then this objective function is flat.",
                    "label": 0
                },
                {
                    "sent": "Write the same problem then before for the gradient.",
                    "label": 0
                },
                {
                    "sent": "Yes, there's no way you can have any direction of search for the algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What are people doing instead, usually in order to kind of flatten this hypervolume improvement?",
                    "label": 0
                },
                {
                    "sent": "So in order to get in the dominated area?",
                    "label": 0
                },
                {
                    "sent": "Some.",
                    "label": 0
                },
                {
                    "sent": "Direction of the search for the algorithm is.",
                    "label": 0
                },
                {
                    "sent": "You can combine it with nondominated sorting, so this is what typical algorithms like this MSN.",
                    "label": 0
                },
                {
                    "sent": "Why would do or the multi objective CMAS so you would.",
                    "label": 0
                },
                {
                    "sent": "If you have a set and you want to remove some points.",
                    "label": 0
                },
                {
                    "sent": "You would first do nondominated sorting, so it would assign to each point.",
                    "label": 1
                },
                {
                    "sent": "Non dominated the best rank so this would if this is our set here of the six solutions.",
                    "label": 0
                },
                {
                    "sent": "Those ones here that undominated they would get the best rank.",
                    "label": 0
                },
                {
                    "sent": "Then you would temporarily remove them and do for the rest the same you would again compute the nondominated solutions and they would get rank that is by one worse etc until you have assigned a rank through all of them and then you would go from the lowest ranked solutions and would remove them with respect to the hypervolume.",
                    "label": 0
                },
                {
                    "sent": "With respect to this set of the same rank, so in our case, that would mean if you would remove some points, you would start with this one and then afterwards if you want to remove another point you would remove them, remove it among these five points, and then you would use the hypervolume.",
                    "label": 0
                },
                {
                    "sent": "So if we do this now for the hypervolume improvement, we can do the same.",
                    "label": 1
                },
                {
                    "sent": "So we can say if the point is not dominated.",
                    "label": 1
                },
                {
                    "sent": "Here we use the normal hypervolume improvement.",
                    "label": 0
                },
                {
                    "sent": "If the point is dominated.",
                    "label": 0
                },
                {
                    "sent": "So it is dominated by one of these points here.",
                    "label": 0
                },
                {
                    "sent": "So if we are in this area we can say then we do the hypervolume improvement with respect to the current non domination front.",
                    "label": 0
                },
                {
                    "sent": "So the same the points that have the same rank then the point you would introduce.",
                    "label": 0
                },
                {
                    "sent": "So therefore if you look at this area here, it looks exactly the same then before just different colors because the overall color was changing and then in the other area here.",
                    "label": 0
                },
                {
                    "sent": "It looks the same, also hyperbolic improvement.",
                    "label": 0
                },
                {
                    "sent": "So you see the same lines of function values equal function values but with respect to this point here as the kind of front and over here, this is the same where you would assume you have no point, so it's just the hyper V with respect to this point here.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "Kind of how the fitness of common algorithms that do not dominate sorting plus hypervolume selection look like.",
                    "label": 0
                },
                {
                    "sent": "An yeah 2.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Observations.",
                    "label": 0
                },
                {
                    "sent": "Three, the first one is now the hypervolume improvement is unflattened in the dominated region, so we have some direction.",
                    "label": 1
                },
                {
                    "sent": "Towards better solutions.",
                    "label": 0
                },
                {
                    "sent": "But above the reference point, so everything outside is still flat, so this is still a problem.",
                    "label": 0
                },
                {
                    "sent": "So the choice of the reference point has an influence in practice.",
                    "label": 0
                },
                {
                    "sent": "So if you have points that are outside, you still have no information of where to go.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the other observation.",
                    "label": 0
                },
                {
                    "sent": "Is that if you look at the search direction here, search correction means if you follow the gradient of this level set so always perpendicular to the level sets right?",
                    "label": 1
                },
                {
                    "sent": "Then you would always go.",
                    "label": 0
                },
                {
                    "sent": "Optimization would move in this direction right?",
                    "label": 0
                },
                {
                    "sent": "So if you're here you would try to optimize here and what you see is you will always optimize towards the point that you already have.",
                    "label": 0
                },
                {
                    "sent": "That is by definition.",
                    "label": 0
                },
                {
                    "sent": "So if you're here, we try to optimize.",
                    "label": 1
                },
                {
                    "sent": "You always will end up.",
                    "label": 0
                },
                {
                    "sent": "Or most likely will end up at the point where you already, so therefore that's probably not what you want.",
                    "label": 0
                },
                {
                    "sent": "What you prefer would like to prefer us if you want to optimize for this point instead of this going towards this direction, it would be better to go here, because then you would have introduced a new new nondominated point.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are things that we tried to solve with our approach, and the idea is very simple.",
                    "label": 0
                },
                {
                    "sent": "Surprised that nobody else had this idea before.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is what we call now.",
                    "label": 0
                },
                {
                    "sent": "The uncrowded hypervolume improvement, because it not only UN flattens it, but it's.",
                    "label": 1
                },
                {
                    "sent": "Pushes solutions that are dominated towards uncrowded regions of the.",
                    "label": 0
                },
                {
                    "sent": "Of the local preference and what we do is if the point is.",
                    "label": 0
                },
                {
                    "sent": "Nondominated by the overall set, so the black ones here are the set that we have and the blue ones are some example points that we just add.",
                    "label": 0
                },
                {
                    "sent": "So if this is dominated the nondominated here then we just use the normal hypervolume improvement.",
                    "label": 0
                },
                {
                    "sent": "So this is this area that you get in addition to the normal hypervolume and if you are dominated by a point, so for example here you just choose the distance Euclidean distance to this black line.",
                    "label": 0
                },
                {
                    "sent": "So this is the what we call the non dominated.",
                    "label": 0
                },
                {
                    "sent": "The empirical nondominated front so it's just.",
                    "label": 0
                },
                {
                    "sent": "The line that is given by the nondominated points and if you are here for example, you would choose again the new clean distance, which is the Euclidean distance to this corner point here.",
                    "label": 0
                },
                {
                    "sent": "And if you do that.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have to say here, this is the empirical nondominated front and if you do that.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then everything looks like this.",
                    "label": 0
                },
                {
                    "sent": "So again, the same thing, we just plot the lines of equal, uncrowded, hypervolume improvement now.",
                    "label": 1
                },
                {
                    "sent": "In the dominant dominated area is the same than before.",
                    "label": 1
                },
                {
                    "sent": "But in the dominated area is just now the distance to this line here that is given by the nondominated points OK. Now also some observations.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Observation is now the also outside of this region here, so above the reference point it is giving some directions for the search.",
                    "label": 0
                },
                {
                    "sent": "So this is in this sense unflattened everywhere really, not just until the reference point like before and the search direction now points towards the.",
                    "label": 0
                },
                {
                    "sent": "Uncrowded region, so towards the regions that where we don't have points.",
                    "label": 0
                },
                {
                    "sent": "So if I start with this point and I want to improve it, kind of I would just go in this direction here if you follow the.",
                    "label": 0
                },
                {
                    "sent": "Decrease distance in distance.",
                    "label": 0
                },
                {
                    "sent": "I would just be here if I'm here, I would always be driven towards region where I was not where I don't have yet to point.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So that's the idea.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this we put into the so called suffer more framework which stands for single objective optimization for optimizing multi objective optimization problems.",
                    "label": 1
                },
                {
                    "sent": "And that was a bit tricky to get to this acronym.",
                    "label": 0
                },
                {
                    "sent": "The nice thing is the PhD student share who did this here in the second year of his PhD.",
                    "label": 0
                },
                {
                    "sent": "So that fits the supermodel name.",
                    "label": 0
                },
                {
                    "sent": "But this is the algorithm.",
                    "label": 0
                },
                {
                    "sent": "The framework that does exactly what they said before.",
                    "label": 0
                },
                {
                    "sent": "So we start with want to optimize P points and now we do for each.",
                    "label": 0
                },
                {
                    "sent": "Of these points, we have a single objective optimizer.",
                    "label": 0
                },
                {
                    "sent": "And we don't say here which one it is.",
                    "label": 0
                },
                {
                    "sent": "It just say that each one of these optimizers says initial internal state.",
                    "label": 0
                },
                {
                    "sent": "And that each of these optimizers will be able to recommend solution.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of.",
                    "label": 0
                },
                {
                    "sent": "We assume that each algorithm has an idea of where the optimum is at each time.",
                    "label": 0
                },
                {
                    "sent": "CMAS, for example, has this naturally, but also model based algorithms typically have this.",
                    "label": 0
                },
                {
                    "sent": "They know where the optimum of the model is.",
                    "label": 0
                },
                {
                    "sent": "Yes, and these are now.",
                    "label": 0
                },
                {
                    "sent": "So this recommendations are now the points in the objective space that we have seen before.",
                    "label": 0
                },
                {
                    "sent": "Like the points that I put in, there can be dominated on dominated.",
                    "label": 0
                },
                {
                    "sent": "We don't care about this.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "What we do is we just run a loop until some stopping criterion is met.",
                    "label": 0
                },
                {
                    "sent": "And what we do in each?",
                    "label": 0
                },
                {
                    "sent": "Iteration we choose one of the points.",
                    "label": 0
                },
                {
                    "sent": "One of the optimizers.",
                    "label": 0
                },
                {
                    "sent": "Which we also call kernels here.",
                    "label": 0
                },
                {
                    "sent": "And a number of times.",
                    "label": 0
                },
                {
                    "sent": "Tell I that we run this algorithm, so we run the algorithm I.",
                    "label": 0
                },
                {
                    "sent": "4 to 8 times to iterations.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Objective function that is this uncrowded hypervolume improvement with respect to all the other points, but the F1, so we keep this, is the definition.",
                    "label": 0
                },
                {
                    "sent": "Here we keep all, but I fixed so kind of if you have these points, you kind of remove the point.",
                    "label": 0
                },
                {
                    "sent": "The recommendation of the ice optimiser and then you try to improve the hypervolume improvement for iterations.",
                    "label": 0
                },
                {
                    "sent": "Then at the end you also have to update this recommendation based on what the algorithm is giving and that's it.",
                    "label": 0
                },
                {
                    "sent": "So not too complicated, but there are many design decisions that you can do.",
                    "label": 0
                },
                {
                    "sent": "I didn't say which algorithm we use.",
                    "label": 0
                },
                {
                    "sent": "I also didn't say how we choose this points etc etc.",
                    "label": 0
                },
                {
                    "sent": "So what we did then is to instantiate.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This former framework, with some specific solvers.",
                    "label": 0
                },
                {
                    "sent": "And then the Como Cmas came out the.",
                    "label": 0
                },
                {
                    "sent": "CMAS stands for covariance matrix adaptation evolution strategy, so it's a stochastic algorithm that has a.",
                    "label": 0
                },
                {
                    "sent": "Internal probability distribution multivariate normal distribution.",
                    "label": 0
                },
                {
                    "sent": "It samples Lambda points from this and then evaluates this Lambda points and depending on the ranking of this Lambda points with respect to F, it updates the internal probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So the mean the step size and the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "This is CMA in a nutshell, and we know not from three we got from practice that this algorithm can learn the in.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the inverse of the Hessian of convex graphic problems.",
                    "label": 0
                },
                {
                    "sent": "The theory is a bit more complicated, but we are convinced that we can prove it in.",
                    "label": 0
                },
                {
                    "sent": "In 10 years, let's see.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is the algorithm that we just put in as the solver and we use the sofa for sofa more framework with this uncrowded hypervolume improvement and the details details are that the recommendation that I was talking about we use the means of the probability distributions of each CMA as this incumbent or kernel.",
                    "label": 1
                },
                {
                    "sent": "And then we always choose a kernel that we have not seen so far in the overall iteration before to see all kernels.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we and this is.",
                    "label": 0
                },
                {
                    "sent": "But now we see this here, yes, so we sample.",
                    "label": 0
                },
                {
                    "sent": "A permutation.",
                    "label": 0
                },
                {
                    "sent": "On all accounts on all points, then we touch each of these kernels once.",
                    "label": 0
                },
                {
                    "sent": "Before we touch it again.",
                    "label": 1
                },
                {
                    "sent": "Right, so we really and then we draw again a random new random permutation.",
                    "label": 0
                },
                {
                    "sent": "Then this towel I we chose as one right now, so we just do one iteration of the CMAS at each time, and then we go to the next kernel and move another point.",
                    "label": 1
                },
                {
                    "sent": "And all this is done in Python, so it's really, really easy without asking tell interface of the PIE CMA module.",
                    "label": 0
                },
                {
                    "sent": "So you just need to ask for the new points and afterwards tell the algorithm.",
                    "label": 0
                },
                {
                    "sent": "What are the evaluations of these points?",
                    "label": 0
                },
                {
                    "sent": "And in between we can hear compute really the fitness as a defined before the uncrowded type of volume improvement, where all the other points are fixed.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's it.",
                    "label": 0
                },
                {
                    "sent": "Now I have a bit of time.",
                    "label": 0
                },
                {
                    "sent": "I hope to talk about.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Numerical results.",
                    "label": 0
                },
                {
                    "sent": "And yeah, I have to start with.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The original question right?",
                    "label": 0
                },
                {
                    "sent": "Can we converge towards the optimal hypervolume?",
                    "label": 1
                },
                {
                    "sent": "So given P, the number of points and the hypervolume indicator can be converted to this optimal hypervolume?",
                    "label": 0
                },
                {
                    "sent": "And the first part I will show is exactly for the same problem that we have seen so far.",
                    "label": 0
                },
                {
                    "sent": "So this double sphere problem, the sum of the XI squared for the first objective with the optimum zero.",
                    "label": 0
                },
                {
                    "sent": "And this function here, which is the same but with the optimum in one 000.",
                    "label": 0
                },
                {
                    "sent": "Now what they will plot is overtime, so here this is the.",
                    "label": 0
                },
                {
                    "sent": "In our case the time or the number of.",
                    "label": 0
                },
                {
                    "sent": "Function evaluations the number of times we call the black box.",
                    "label": 0
                },
                {
                    "sent": "Divided by the number of kernels of the divided by P. And here we show in the log scale the difference of the hypervolume to the optimal hypervolume.",
                    "label": 0
                },
                {
                    "sent": "I'm in this case we can.",
                    "label": 0
                },
                {
                    "sent": "No, the optimal hyper volume four points and what we prefer now we wanted to have is kind of linear decrease in this log scale.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the result.",
                    "label": 0
                },
                {
                    "sent": "So this is one run on this problem here with 10 variables and 31 points.",
                    "label": 0
                },
                {
                    "sent": "So in the formalization that's set before, we now have a 310 dimensional problem.",
                    "label": 0
                },
                {
                    "sent": "We see the hyper volume decreases or the hyperbolic distance to the optimal decreases linearly, so this is what we want and what we also see kind of.",
                    "label": 0
                },
                {
                    "sent": "Here is the first phase where the single objective CMA's have to learn something and then you really see this decrease.",
                    "label": 0
                },
                {
                    "sent": "And this you can also look at different.",
                    "label": 0
                },
                {
                    "sent": "At other problems.",
                    "label": 0
                },
                {
                    "sent": "I also have.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Plot, which is not so interesting because it's mainly empty about the ratio of non dominated points among the P. So this really quickly goes up.",
                    "label": 0
                },
                {
                    "sent": "So you start with dominated points but with respect to the distance that you optimize to the empirical front.",
                    "label": 0
                },
                {
                    "sent": "This really goes up very quickly, so this is not so interesting plot, but we just verified that this is actually optimizing.",
                    "label": 0
                },
                {
                    "sent": "Now we can.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cat also.",
                    "label": 0
                },
                {
                    "sent": "Covariance matrix of the single objective CMAS.",
                    "label": 0
                },
                {
                    "sent": "And here this is plotted for three randomly chosen kernels.",
                    "label": 0
                },
                {
                    "sent": "So three out of the 31.",
                    "label": 0
                },
                {
                    "sent": "And if you know about CMA, that looks a bit like you optimize really a sphere function, so the single objectives are spheres.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And as we have seen before, the level sets look like a bit like sphere functions, and we have the theory also in the paper.",
                    "label": 0
                },
                {
                    "sent": "If you're interested, we know how the.",
                    "label": 0
                },
                {
                    "sent": "Other problem looks like, so the Hessian.",
                    "label": 0
                },
                {
                    "sent": "Close to the objective function is more or less the sphere function plus some.",
                    "label": 0
                },
                {
                    "sent": "Rank one matrices that you that you add, so that's not surprising.",
                    "label": 0
                },
                {
                    "sent": "Then that the algorithm, the single objective algorithms really see.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes and then.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Holds for different problems.",
                    "label": 0
                },
                {
                    "sent": "Convex cratic problems.",
                    "label": 0
                },
                {
                    "sent": "So this was the fact that we have seen before.",
                    "label": 0
                },
                {
                    "sent": "So where we have two sphere functions.",
                    "label": 0
                },
                {
                    "sent": "That's the same if you look at elliptic functions.",
                    "label": 0
                },
                {
                    "sent": "If they are separable so they are aligned to the axis also holds on other convex clarity functions where the spectrum is with different.",
                    "label": 0
                },
                {
                    "sent": "So C gotta type function but also.",
                    "label": 0
                },
                {
                    "sent": "If we have rotated, it's so it's so the two objective functions are rotated ellipsoid function, so the level sets are rotated ellipse and if they are not rotated in the same way, then the creator set is not a straight line anymore, but curve.",
                    "label": 0
                },
                {
                    "sent": "And even in this case we see.",
                    "label": 0
                },
                {
                    "sent": "This linear linear convergence is the hyperbolic difference.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so you can say nice, but all later have shown now was single runs so maybe that doesn't always happen.",
                    "label": 0
                },
                {
                    "sent": "But we are also.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's no proof.",
                    "label": 0
                },
                {
                    "sent": "We were convinced that it that it works.",
                    "label": 0
                },
                {
                    "sent": "So here we see always four runs.",
                    "label": 0
                },
                {
                    "sent": "And they always look more or less the same, and for four different algorithms.",
                    "label": 0
                },
                {
                    "sent": "And the blue one is the Como CMA's that we have just seen.",
                    "label": 0
                },
                {
                    "sent": "Now the green one is the previous multiobjective CMA variant from 2010.",
                    "label": 0
                },
                {
                    "sent": "Must say so.",
                    "label": 0
                },
                {
                    "sent": "The original paper was in 2007 and then there was a small a big improvement made in 2010.",
                    "label": 0
                },
                {
                    "sent": "So this is the comparative algorithm.",
                    "label": 0
                },
                {
                    "sent": "And then we have SMS or more.",
                    "label": 0
                },
                {
                    "sent": "In purple here and in black we have the energy to.",
                    "label": 0
                },
                {
                    "sent": "The Purple One is also supposed to optimize for the hypervolume.",
                    "label": 0
                },
                {
                    "sent": "The Black one doesn't.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if we look now into this a bit more closely, so this is the first plot really on the same problem where both objective functions are functions.",
                    "label": 0
                },
                {
                    "sent": "And now this looks a bit different here because in the plot we don't look at the optimum.",
                    "label": 0
                },
                {
                    "sent": "We look at the best found by all the algorithms.",
                    "label": 0
                },
                {
                    "sent": "So therefore this is a bit numerics here and you don't.",
                    "label": 0
                },
                {
                    "sent": "Don't look at everything that is below anything that is below 10 to the minus 710 to the minus 14.",
                    "label": 0
                },
                {
                    "sent": "OK, so here we see that the multi objective C MSD origonal one is faster.",
                    "label": 0
                },
                {
                    "sent": "So this is for those who know it's a 1 + 1 strategy and this is a common strategy here.",
                    "label": 0
                },
                {
                    "sent": "So this is supposed to be.",
                    "label": 0
                },
                {
                    "sent": "On the on the sphere the same the convergence rate, but we didn't do any test.",
                    "label": 0
                },
                {
                    "sent": "Any tuning of parameters, so we we are confident that we can drop this a bit.",
                    "label": 0
                },
                {
                    "sent": "But we didn't do any tuning.",
                    "label": 0
                },
                {
                    "sent": "This is surely the algorithm, and although this algorithm also tries to optimize the high performance this far slower.",
                    "label": 0
                },
                {
                    "sent": "And this happens all kinds of.",
                    "label": 0
                },
                {
                    "sent": "Problems.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, so this is the plot on the elliptic functions where both objective functions are ellipsoids.",
                    "label": 0
                },
                {
                    "sent": "Instead of circles.",
                    "label": 0
                },
                {
                    "sent": "And they are the common.",
                    "label": 0
                },
                {
                    "sent": "CIS is better than all the other algorithms, and you'll see that the variances in the log scale not too large.",
                    "label": 0
                },
                {
                    "sent": "So among four algorithms, so clearly this is statistically significantly better than this one and buy orders of magnitude.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The interesting thing is we also looked at.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here we really look at the hypervolume difference between the optimum.",
                    "label": 0
                },
                {
                    "sent": "The optimal performance that can reach with P points and the population of the algorithm in these two cases or the really number of kernels that we have in these two algorithms.",
                    "label": 0
                },
                {
                    "sent": "Right, so we always look at sets of size P, But we can also do is we can look at the whole set of non dominated points that have been found by the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So with respect to the archive, the nondominated.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Archive and then we see something like this.",
                    "label": 0
                },
                {
                    "sent": "This is again two sphere problem.",
                    "label": 0
                },
                {
                    "sent": "The biosphere problem we're here.",
                    "label": 0
                },
                {
                    "sent": "Now we look at the difference between the hypervolume of all the points that have been found.",
                    "label": 0
                },
                {
                    "sent": "Compared to the best you can get so kind of the hypervolume of the entire operator front, so therefore we don't go down too many too much precision, but also here we see that the Como Cmas is the best algorithm.",
                    "label": 0
                },
                {
                    "sent": "Although none of this algorithm was supposed to be good in this setup.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is for the ellipsoid function.",
                    "label": 0
                },
                {
                    "sent": "So also here the cool mild rhythm is better than the others.",
                    "label": 0
                },
                {
                    "sent": "And we also understood why it is better than the 1 + 1 CMA.",
                    "label": 0
                },
                {
                    "sent": "So the more CMA is here because in order to converge with a common strategy, you can have a larger step size and this is beneficial in this setup where you converge two points.",
                    "label": 0
                },
                {
                    "sent": "But if you have a larger step size to produce new points, you will always produce more points in the middle in between two points that will go into the archive and that will make the aircraft better.",
                    "label": 0
                },
                {
                    "sent": "So This is why this also works here.",
                    "label": 0
                },
                {
                    "sent": "We also looked at comparison with other algorithms over a larger set of functions which are not just convex quadratic.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, with respect to the comparing continuous Optimizer platform where there is a by objective.",
                    "label": 0
                },
                {
                    "sent": "Test suite with 55 functions.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so here we tested different number of kernels so Como is always the one that I just talked about.",
                    "label": 0
                },
                {
                    "sent": "The comma multi objective CMA is the 1 + 1.",
                    "label": 0
                },
                {
                    "sent": "Here is the merges the 2010 version that I just talked about before so the green.",
                    "label": 0
                },
                {
                    "sent": "The green algorithm here.",
                    "label": 0
                },
                {
                    "sent": "Then the Energycap 2 here is kind of the same the MATLAB implementation.",
                    "label": 0
                },
                {
                    "sent": "This is like the black one here.",
                    "label": 0
                },
                {
                    "sent": "And that's all what we see here.",
                    "label": 0
                },
                {
                    "sent": "So the number here is the number of kernel kernels.",
                    "label": 0
                },
                {
                    "sent": "So we have tried to approximate the preset with thousand points with 316 with 10.",
                    "label": 0
                },
                {
                    "sent": "With three and, these are the empirical cumulative distribution functions of the runtime to reach certain target precisions.",
                    "label": 0
                },
                {
                    "sent": "So here, this is the again, the time number of function evaluations in log scale.",
                    "label": 0
                },
                {
                    "sent": "Divided by dimension and here is the number of problems that are solved at this time.",
                    "label": 0
                },
                {
                    "sent": "So one algorithm is one line, and the higher the algorithm the better, and the more to the left the better.",
                    "label": 0
                },
                {
                    "sent": "So the best algorithms are the ones that are here on top.",
                    "label": 0
                },
                {
                    "sent": "And as a comparison, this line here the thick line is an artificial algorithm is the best performance that you can get from 16 algorithms that were submitted in 2016 to the workshop that we organized.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of the reference.",
                    "label": 0
                },
                {
                    "sent": "And you see that single algorithms already reached this performance here in the overall.",
                    "label": 0
                },
                {
                    "sent": "Aggregation, so overall 55 functions and.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you look closely to subsets of the functions, you see that on some in particular, the more complicated ones these algorithms can be better than the best.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that happens for several for several groups.",
                    "label": 0
                },
                {
                    "sent": "So since we did not do any parameter tuning, we think that we can gain also there in the future.",
                    "label": 0
                },
                {
                    "sent": "And one thing that we also didn't do, which looks very much.",
                    "label": 0
                },
                {
                    "sent": "Needed here is to adapt the number of kernels, so adapt the number of points.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You get if you look at the result here for example.",
                    "label": 0
                },
                {
                    "sent": "This is the performance.",
                    "label": 0
                },
                {
                    "sent": "The best performing algorithm is the one where we have only three points, then afterwards become better.",
                    "label": 0
                },
                {
                    "sent": "Here if we have 10 points and then here we come better.",
                    "label": 0
                },
                {
                    "sent": "If you have 32 points etc.",
                    "label": 0
                },
                {
                    "sent": "So kind of what we should have is an algorithm that starts with a few number of points and then once you detect it you are the front.",
                    "label": 0
                },
                {
                    "sent": "You just increase the number of points adaptively.",
                    "label": 0
                },
                {
                    "sent": "So this is what we plan in the future.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so to conclude.",
                    "label": 0
                },
                {
                    "sent": "We had a goal to converge linearly towards the optimal set of points with respect to the hypervolume indicator, which we managed to achieve with this new algorithm.",
                    "label": 1
                },
                {
                    "sent": "Como CMA, yes, so we have some data that works well on convex traffic problems on the variety of them.",
                    "label": 0
                },
                {
                    "sent": "For now it's only tested on two objective functions.",
                    "label": 0
                },
                {
                    "sent": "But there's no reason that it should not work on in higher dimension.",
                    "label": 0
                },
                {
                    "sent": "You just didn't try it.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yes, we did it.",
                    "label": 0
                },
                {
                    "sent": "With the following steps.",
                    "label": 1
                },
                {
                    "sent": "So we introduce this new fitness or new objective function the unclouded hypervolume improvement, which is nothing else than the original hypervolume improvement.",
                    "label": 0
                },
                {
                    "sent": "If you're nondominated now adding the Euclidean distance to the empirical front.",
                    "label": 1
                },
                {
                    "sent": "If you have dominated point.",
                    "label": 0
                },
                {
                    "sent": "And then we do this subspace optimization.",
                    "label": 1
                },
                {
                    "sent": "So we only optimize one point at a time.",
                    "label": 0
                },
                {
                    "sent": "It's relatively with CMA S, so single objective algorithm that optimizes this single objective hypervolume improvement and we only do one iteration of the algorithm before we touch.",
                    "label": 0
                },
                {
                    "sent": "Before we touch all the other accounts.",
                    "label": 1
                },
                {
                    "sent": "And we really just used the CMA as the default one.",
                    "label": 0
                },
                {
                    "sent": "Didn't change anything and it worked.",
                    "label": 0
                },
                {
                    "sent": "So this is one point we want to look at.",
                    "label": 1
                },
                {
                    "sent": "What can we gain by parameter tuning?",
                    "label": 0
                },
                {
                    "sent": "Yes, I also talked about this more general framework, so for more where.",
                    "label": 0
                },
                {
                    "sent": "We can also plug in other algorithms, so this is clearly something we want to test.",
                    "label": 0
                },
                {
                    "sent": "From the bbob data, so the Coco results.",
                    "label": 1
                },
                {
                    "sent": "We know that SLP is the best performing algorithm, typically for low budgets, the best out of 200 algorithms.",
                    "label": 0
                },
                {
                    "sent": "So this is something we would like to try.",
                    "label": 0
                },
                {
                    "sent": "We definitely need to implement restart, so for now the algorithm just runs until forever.",
                    "label": 0
                },
                {
                    "sent": "There's no stopping criterion, we just let it run.",
                    "label": 0
                },
                {
                    "sent": "So that's also something that would improve the performance on multimodal functions for sure.",
                    "label": 0
                },
                {
                    "sent": "So where you would need to say on I detect that I'm stuck and I would just restart the algorithm or put more points in, which is the probably the most crucial improvement that we can think of for improving the performance so.",
                    "label": 0
                },
                {
                    "sent": "At number of points or increase the number of points adaptively.",
                    "label": 0
                },
                {
                    "sent": "OK yeah, before I stop I want to make some.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Advertisement So as you've seen, we work on this comparing continuous optimizes platform, so this is all available.",
                    "label": 0
                },
                {
                    "sent": "If you are interested, just follow what we do.",
                    "label": 0
                },
                {
                    "sent": "Try to benchmark your algorithms with the software so we always have a workshop at the Gecko Conference this year, again in July, where we try to collect data for comparing algorithms.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All so thank you very much and.",
                    "label": 0
                },
                {
                    "sent": "Please ask questions.",
                    "label": 0
                }
            ]
        }
    }
}