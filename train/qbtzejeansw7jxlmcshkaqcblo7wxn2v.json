{
    "id": "qbtzejeansw7jxlmcshkaqcblo7wxn2v",
    "title": "Learning Similarity Metrics for Event Identification in Social Media",
    "info": {
        "author": [
            "Hila Becker, Department of Computer Science, Columbia University"
        ],
        "published": "Oct. 12, 2010",
        "recorded": "February 2010",
        "category": [
            "Top->Computer Science->Social Media"
        ]
    },
    "url": "http://videolectures.net/wsdm2010_becker_lsmf/",
    "segmentation": [
        [
            "Alright, so good morning everybody.",
            "My name is Sheila Becker and I'm a PhD student at Columbia University and I'll be talking about learning similarity metrics for event.",
            "I did identification and social media, which is joint work with my advisor Luis Carvana at Columbia and more nominate rockers."
        ],
        [
            "Alright, so social media sites like Flickr, Twitter, YouTube and Facebook contain lots of user contributed information relating to a variety of real world events."
        ],
        [
            "The types of events we're interested in range from anything from popular and widely known events like the presidential inauguration or the Thanksgiving Day Parade.",
            "2 smaller events that don't necessarily receive much news coverage like a local bake sale or a workshop."
        ],
        [
            "OK.",
            "So our goal is to identify events and all of their associated social media documents, OK?"
        ],
        [
            "You can use that to facilitate applications like if I'm browsing or local event search where users would like to search for interesting events in their area."
        ],
        [
            "So here's a mockup that I created of what such an application might look like, and you can think of this as a similar to a news aggregation sites only for events where we can tailor the events that we display to a particular user and include a different descriptions of events in a bunch of associated media."
        ],
        [
            "OK, the general approach that we take in this paper is to group together a similar documents using clustering such that each cluster would ideally contain a single event, an all of its associated social media documents."
        ],
        [
            "All right, there are several challenges in this event identification."
        ],
        [
            "Task on the 1st as the quality of data that's available in social media.",
            "Very uneven.",
            "There's a missing shorts and an informative text.",
            "On the other hand, we do have some interesting structured context features like timestamp and tags and Geo coordinates.",
            "Of course we are dealing with web scale data, so our solutions have to be scalable and not only scalable.",
            "We have to adapt to a dynamic stream of data as users constantly upload information to social media sites.",
            "Finally, the number of events that we're trying to identify is unknown.",
            "This is difficult to estimate, and specifically because it is constantly changing.",
            "OK."
        ],
        [
            "So um, from now I'll talk about the different approaches."
        ],
        [
            "We take in.",
            "In particular, I'll mention how we can represent social media documents.",
            "Different ways of measuring social media document similarity.",
            "With our clustering framework, and specifically, the interesting part is how we can learn similarity metrics, and we propose two approaches.",
            "The first is an ensemble based approach and the 2nd is a classification based approach.",
            "And finally, I'll share some of our results."
        ],
        [
            "OK.",
            "So here is an example of just your average social media document here happens to be a photo from Flickr, and there is a set of context features that are more or less we more or less expect to find across the different sites the 1st."
        ],
        [
            "Is that title here?",
            "It's ADSC 01325.",
            "Not very informative.",
            "Goes back to the challenge."
        ],
        [
            "As we discussed."
        ],
        [
            "The second is."
        ],
        [
            "Short description."
        ],
        [
            "We have a bunch of keyword tags describing console."
        ],
        [
            "So the documents.",
            "The time and date here happens to be recorded."
        ],
        [
            "Camera."
        ],
        [
            "The location how it can be a string or."
        ],
        [
            "Geo coordinates."
        ],
        [
            "And finally, we can think of representing the documents using all of the textual information together."
        ],
        [
            "So how do we determine if two social media documents correspond to?"
        ],
        [
            "Same event, so to measure similarity, we can think of textual features using something like crossing similarity over TF IDF vectors.",
            "And of course we need to consider a different versions of TF IDF.",
            "We should do stemming, stopword elimination, etc."
        ],
        [
            "However, a more natural similarity approach that metric for something like a timestamp sum is the proximity of the documents time in minutes."
        ],
        [
            "And similarly for location.",
            "More.",
            "Appropriate metric would be the Geo coordinate proximity, OK. Also we can use each one of them in isolation, but we can think of how to learn a combination of these in a principled way."
        ],
        [
            "Alright, so to make our framework more concrete, which is where we're going to use these similarity metrics?"
        ],
        [
            "We have a set of social media document."
        ],
        [
            "We want to extract features and project them into the feature space and define appropriate similarity metrics such that documents that correspond to the same events."
        ],
        [
            "Cluster together."
        ],
        [
            "And you know each cluster will correspond to ideally a single."
        ],
        [
            "Shantan contain all the associated social media documents."
        ],
        [
            "OK. Oh"
        ],
        [
            "The clustering algorithm.",
            "There aren't many alternatives possible.",
            "This is not a new problem, but we have a bunch of challenges that we have to address and we decided to go with a single pass incremental clustering algorithm for this task.",
            "Scalable online solution and use effectively for event identification, textual news and also importantly does not require a priore knowledge of the number of clusters.",
            "The parameters that we have to.",
            "To give this algorithm is a similarity function and a threshold which we can train during supervised fights."
        ],
        [
            "OK, so with respect to similarity, we can think of using similarity between a document that every other documents in the cluster, but instead to speed things up we can represent the cluster using a centroid, which would be depending on the feature.",
            "Either the average TF IDF scores the textual features, the average time for the timestamp end the geographic midpoint for location based features.",
            "OK, so the way we tune the parameters of similarity metric and the threshold is during a supervised phase and we want to optimize to metrics.",
            "The first is normalized mutual information and the 2nd is VQ, which are clustering evaluation metric."
        ],
        [
            "OK so um.",
            "We did a lot of we looked a lot in two different ways of measuring the quality of the clustering and 1st we narrow down the characteristics that we want to have in our clusters."
        ],
        [
            "1st is homogeneity."
        ],
        [
            "Awesome for means that documents that belong to different events should go in different."
        ],
        [
            "Masters, right?",
            "The second is."
        ],
        [
            "Completeness meaning that documents that belong to the same event should go in a single cluster.",
            "Right?"
        ],
        [
            "And these are captured by both MINB cubed.",
            "They have different devices which we don't want to impose.",
            "So instead we optimize both of them using a single objective function, just the sum of MI plus with."
        ],
        [
            "OK, so some interesting stuff.",
            "This is our our offline of our approaches for learning similarity metric.",
            "We talk about the ensemble based similarity where we train a cluster ensemble and we have two different ways of computing similarity using the ensemble.",
            "And the second would be a classification based similarity where we have to consider a different training and modeling strategies."
        ],
        [
            "OK.",
            "So quick overview."
        ],
        [
            "So the clustering sample algorithm we have for each different similarity metric and an each feature that captures.",
            "We can have a what's called a cluster, which is just a clustering algorithm based on this features and similarities, and they have each one of them has its own view of the data and it's an idea of how to."
        ],
        [
            "Additional space.",
            "So for example.",
            "So what we want to do is for each one of these train awaited during a supervised phase and come up with a way to combine the weights and the votes of these different clusters using a some kind of consensus funk."
        ],
        [
            "Which would yield a single solution."
        ],
        [
            "OK, so the 1st way the 1st way to do this is."
        ],
        [
            "Looking at each cluster, so for each pair of documents they can both.",
            "If they should go to."
        ],
        [
            "Other or not, so you know the first one based on title says shouldn't go together, you know?"
        ],
        [
            "And so on, and then using our weights we can combine these votes."
        ],
        [
            "OK, so the 2nd way of doing it to speed things up so we don't have to compare all document pairs.",
            "We can for each for each of the clusters.",
            "What we learn is a similarity metric and the threshold OK and using that similarity metric and threshold we can for each documents then say according to say the time based similarity, if it's greater than the threshold that we tune then it should go into the receive this weight that we.",
            "So we trained for this particular feature."
        ],
        [
            "Bye.",
            "Right, so this is the ensemble based approach is now the classification."
        ],
        [
            "A similarity."
        ],
        [
            "What we do is we classify pairs of documents as similar or dissimilar.",
            "So the features in this classifier are the pairwise similarity scores.",
            "So for example, the pair document similarity according to time or according to location.",
            "OK, so we talked about the clustering algorithm where we can either judge similarity between document pairs or what we actually do in practice is we compare documents to centroid.",
            "So when we model this do we want to look at the similarities between document pairs or documents employed there?"
        ],
        [
            "One of the challenges here, of course, is that most of the document pairs in our data set do not correspond to the same event, so we get this food label distribution when we train a similarity metric using discrete label distribution, we end up getting is small and highly homogeneous clusters because the classifier accounts to think that events that pairs documents that do not belong to the same event and will only make positive decisions with high confidence.",
            "So we don't want that, so we need to come up with that.",
            "We came up with a few sampling strategies to alleviate this from the first is just random.",
            "Taking a document at random and pairing it with one positive example mini.",
            "They belong in the same events.",
            "One negative example.",
            "And the second one is a time based where will just take the first saw and documents and use and Diane and balance the distribution using resampling."
        ],
        [
            "OK, so um, what?",
            "So we have all these different."
        ],
        [
            "Coaches and we want to experiment to see which ones work best.",
            "Um, the approaches that we compare are at both of the ensemble based techniques.",
            "The classification based techniques that consider modeling document pairs, document sent repair as other different sampling strategies and also used it to different classifiers.",
            "Logistic regression, SVM.",
            "As baselines, we look at all the different similarities according to the different social media document features, and in particular, we also compared to all text where all the features including that time and location are encoded as text, and we use it.",
            "The text based on similarity."
        ],
        [
            "So for the experiments we have two datasets.",
            "The first is what we call the upcoming data set."
        ],
        [
            "And this is documents, so upcoming is a user contributed event database."
        ],
        [
            "And what we have is over 270,000 Flickr photos and those Flickr photos are labeled by users with what they call a machine tag, which is an upcoming: event and the event ID and that event ID refers back to the event from upcoming.",
            "So each photo is labeled with an event ID from upcoming.",
            "We use the Flickr API to crawl all such documents between now and 2006 and 2008.",
            "Uh, we split that into three parts.",
            "Training, validation, testing.",
            "OK, so the second data set."
        ],
        [
            "Is last FM.",
            "Corresponds to events from the last FM music catalog."
        ],
        [
            "Concerts.",
            "And over 594 thousand documents and the event labels of look like last FM.",
            "Call an event and the event ID.",
            "And we use that as a separate asset."
        ],
        [
            "Alright, so."
        ],
        [
            "Some results first, these were our best performing baselines.",
            "Not surprisingly, all text.",
            "But Interestingly tags just using tags alone with textual similarity performed almost as well as using all text.",
            "So it wasn't."
        ],
        [
            "You can see that the ensemble approaches are performing slightly better than the baselines ANF."
        ],
        [
            "Finally, our classification based approaches outperform both the baselines and are better than the ensemble based approaches.",
            "OK, so we asked ourselves."
        ],
        [
            "Is a significant, so we did this.",
            "Physical significance analysis where we took the test, sets the upcoming test set and partitioned it into 10 equal parts and we used a Friedman tests and we found that are so the Friedman test pretty much asks are the results of the different approaches significantly different when we find that found that yes, some of them are different with P less than .05, and then we had to do some post hoc analysis to try to determine which ones are different.",
            "Which ones are?",
            "Can we determine our difference?",
            "So this diagram pretty much take away messages that the classifiers.",
            "So the this diagram shows the average rank over the ten runs and the approaches are connected with a line cannot be determined statistically significantly different.",
            "So we can say that the classifiers are significantly different than the baselines.",
            "All the classification based marry metric learning approaches."
        ],
        [
            "Alright, so as I mentioned we used last September, they separate assets we wanted to see if say, for example we only have training data for like a certain.",
            "One data set and we don't.",
            "We are not able to get to train the models for the other data set, so we want to see from our models generalize and we have similar trends.",
            "We're still doing all the the similarity.",
            "Learning metric approaches perform better than the baseline, and here it's interesting to see that the ensemble of similarity based approach.",
            "Actually, our generalizes better, so it's possible that you know if you are not able to train a model on the on the data set itself that you want to do it on the unstable models generalize better."
        ],
        [
            "That"
        ],
        [
            "So just come up here.",
            "I have shown that the structured context features of social media provide nice complementary cues for documents similarity.",
            "Some analysis on our models show that tags in the time proximity are the highest weighted features.",
            "Are we show that the weighing the domain appropriate similarity metrics and principled ways yields high accuracy or high quality clustering results and we showed that they significantly outperformed the text only techniques.",
            "OK, and finally using the last 10 data we show that the similarity learning models generalize to unseen datasets."
        ],
        [
            "Right so future work, so we are now we only looked at so far.",
            "The length of the context, features of the documents.",
            "But we are also interested in using the explicit links that are available in social media like explicit social network connections or common links, which I presented in poster in the search and social Media Workshop.",
            "So we're looking how to into how to incorporate that into the.",
            "Already learning process.",
            "And of course, so we only experimented with Flickr, were interested in capturing event contents on a variety of social media sites like YouTube and obviously Twitter.",
            "And knowing that we have some events on our data, user contributed databases like upcoming, lots of them, you want to see if we can design strategies for event search.",
            "And."
        ],
        [
            "That sounds like any questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so good morning everybody.",
                    "label": 0
                },
                {
                    "sent": "My name is Sheila Becker and I'm a PhD student at Columbia University and I'll be talking about learning similarity metrics for event.",
                    "label": 1
                },
                {
                    "sent": "I did identification and social media, which is joint work with my advisor Luis Carvana at Columbia and more nominate rockers.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so social media sites like Flickr, Twitter, YouTube and Facebook contain lots of user contributed information relating to a variety of real world events.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The types of events we're interested in range from anything from popular and widely known events like the presidential inauguration or the Thanksgiving Day Parade.",
                    "label": 0
                },
                {
                    "sent": "2 smaller events that don't necessarily receive much news coverage like a local bake sale or a workshop.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So our goal is to identify events and all of their associated social media documents, OK?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can use that to facilitate applications like if I'm browsing or local event search where users would like to search for interesting events in their area.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's a mockup that I created of what such an application might look like, and you can think of this as a similar to a news aggregation sites only for events where we can tailor the events that we display to a particular user and include a different descriptions of events in a bunch of associated media.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, the general approach that we take in this paper is to group together a similar documents using clustering such that each cluster would ideally contain a single event, an all of its associated social media documents.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All right, there are several challenges in this event identification.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Task on the 1st as the quality of data that's available in social media.",
                    "label": 0
                },
                {
                    "sent": "Very uneven.",
                    "label": 0
                },
                {
                    "sent": "There's a missing shorts and an informative text.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we do have some interesting structured context features like timestamp and tags and Geo coordinates.",
                    "label": 0
                },
                {
                    "sent": "Of course we are dealing with web scale data, so our solutions have to be scalable and not only scalable.",
                    "label": 0
                },
                {
                    "sent": "We have to adapt to a dynamic stream of data as users constantly upload information to social media sites.",
                    "label": 0
                },
                {
                    "sent": "Finally, the number of events that we're trying to identify is unknown.",
                    "label": 1
                },
                {
                    "sent": "This is difficult to estimate, and specifically because it is constantly changing.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So um, from now I'll talk about the different approaches.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We take in.",
                    "label": 0
                },
                {
                    "sent": "In particular, I'll mention how we can represent social media documents.",
                    "label": 1
                },
                {
                    "sent": "Different ways of measuring social media document similarity.",
                    "label": 1
                },
                {
                    "sent": "With our clustering framework, and specifically, the interesting part is how we can learn similarity metrics, and we propose two approaches.",
                    "label": 0
                },
                {
                    "sent": "The first is an ensemble based approach and the 2nd is a classification based approach.",
                    "label": 0
                },
                {
                    "sent": "And finally, I'll share some of our results.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here is an example of just your average social media document here happens to be a photo from Flickr, and there is a set of context features that are more or less we more or less expect to find across the different sites the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that title here?",
                    "label": 0
                },
                {
                    "sent": "It's ADSC 01325.",
                    "label": 0
                },
                {
                    "sent": "Not very informative.",
                    "label": 0
                },
                {
                    "sent": "Goes back to the challenge.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As we discussed.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second is.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Short description.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a bunch of keyword tags describing console.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the documents.",
                    "label": 0
                },
                {
                    "sent": "The time and date here happens to be recorded.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Camera.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The location how it can be a string or.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Geo coordinates.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, we can think of representing the documents using all of the textual information together.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we determine if two social media documents correspond to?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same event, so to measure similarity, we can think of textual features using something like crossing similarity over TF IDF vectors.",
                    "label": 0
                },
                {
                    "sent": "And of course we need to consider a different versions of TF IDF.",
                    "label": 0
                },
                {
                    "sent": "We should do stemming, stopword elimination, etc.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, a more natural similarity approach that metric for something like a timestamp sum is the proximity of the documents time in minutes.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And similarly for location.",
                    "label": 0
                },
                {
                    "sent": "More.",
                    "label": 0
                },
                {
                    "sent": "Appropriate metric would be the Geo coordinate proximity, OK. Also we can use each one of them in isolation, but we can think of how to learn a combination of these in a principled way.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so to make our framework more concrete, which is where we're going to use these similarity metrics?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a set of social media document.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want to extract features and project them into the feature space and define appropriate similarity metrics such that documents that correspond to the same events.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cluster together.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you know each cluster will correspond to ideally a single.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Shantan contain all the associated social media documents.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Oh",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The clustering algorithm.",
                    "label": 0
                },
                {
                    "sent": "There aren't many alternatives possible.",
                    "label": 0
                },
                {
                    "sent": "This is not a new problem, but we have a bunch of challenges that we have to address and we decided to go with a single pass incremental clustering algorithm for this task.",
                    "label": 0
                },
                {
                    "sent": "Scalable online solution and use effectively for event identification, textual news and also importantly does not require a priore knowledge of the number of clusters.",
                    "label": 0
                },
                {
                    "sent": "The parameters that we have to.",
                    "label": 0
                },
                {
                    "sent": "To give this algorithm is a similarity function and a threshold which we can train during supervised fights.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so with respect to similarity, we can think of using similarity between a document that every other documents in the cluster, but instead to speed things up we can represent the cluster using a centroid, which would be depending on the feature.",
                    "label": 0
                },
                {
                    "sent": "Either the average TF IDF scores the textual features, the average time for the timestamp end the geographic midpoint for location based features.",
                    "label": 0
                },
                {
                    "sent": "OK, so the way we tune the parameters of similarity metric and the threshold is during a supervised phase and we want to optimize to metrics.",
                    "label": 0
                },
                {
                    "sent": "The first is normalized mutual information and the 2nd is VQ, which are clustering evaluation metric.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so um.",
                    "label": 0
                },
                {
                    "sent": "We did a lot of we looked a lot in two different ways of measuring the quality of the clustering and 1st we narrow down the characteristics that we want to have in our clusters.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1st is homogeneity.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Awesome for means that documents that belong to different events should go in different.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Masters, right?",
                    "label": 0
                },
                {
                    "sent": "The second is.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Completeness meaning that documents that belong to the same event should go in a single cluster.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And these are captured by both MINB cubed.",
                    "label": 0
                },
                {
                    "sent": "They have different devices which we don't want to impose.",
                    "label": 0
                },
                {
                    "sent": "So instead we optimize both of them using a single objective function, just the sum of MI plus with.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so some interesting stuff.",
                    "label": 0
                },
                {
                    "sent": "This is our our offline of our approaches for learning similarity metric.",
                    "label": 1
                },
                {
                    "sent": "We talk about the ensemble based similarity where we train a cluster ensemble and we have two different ways of computing similarity using the ensemble.",
                    "label": 0
                },
                {
                    "sent": "And the second would be a classification based similarity where we have to consider a different training and modeling strategies.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So quick overview.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the clustering sample algorithm we have for each different similarity metric and an each feature that captures.",
                    "label": 0
                },
                {
                    "sent": "We can have a what's called a cluster, which is just a clustering algorithm based on this features and similarities, and they have each one of them has its own view of the data and it's an idea of how to.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Additional space.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "So what we want to do is for each one of these train awaited during a supervised phase and come up with a way to combine the weights and the votes of these different clusters using a some kind of consensus funk.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which would yield a single solution.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the 1st way the 1st way to do this is.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Looking at each cluster, so for each pair of documents they can both.",
                    "label": 0
                },
                {
                    "sent": "If they should go to.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other or not, so you know the first one based on title says shouldn't go together, you know?",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so on, and then using our weights we can combine these votes.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the 2nd way of doing it to speed things up so we don't have to compare all document pairs.",
                    "label": 0
                },
                {
                    "sent": "We can for each for each of the clusters.",
                    "label": 0
                },
                {
                    "sent": "What we learn is a similarity metric and the threshold OK and using that similarity metric and threshold we can for each documents then say according to say the time based similarity, if it's greater than the threshold that we tune then it should go into the receive this weight that we.",
                    "label": 0
                },
                {
                    "sent": "So we trained for this particular feature.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bye.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is the ensemble based approach is now the classification.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A similarity.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we do is we classify pairs of documents as similar or dissimilar.",
                    "label": 0
                },
                {
                    "sent": "So the features in this classifier are the pairwise similarity scores.",
                    "label": 0
                },
                {
                    "sent": "So for example, the pair document similarity according to time or according to location.",
                    "label": 0
                },
                {
                    "sent": "OK, so we talked about the clustering algorithm where we can either judge similarity between document pairs or what we actually do in practice is we compare documents to centroid.",
                    "label": 0
                },
                {
                    "sent": "So when we model this do we want to look at the similarities between document pairs or documents employed there?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of the challenges here, of course, is that most of the document pairs in our data set do not correspond to the same event, so we get this food label distribution when we train a similarity metric using discrete label distribution, we end up getting is small and highly homogeneous clusters because the classifier accounts to think that events that pairs documents that do not belong to the same event and will only make positive decisions with high confidence.",
                    "label": 0
                },
                {
                    "sent": "So we don't want that, so we need to come up with that.",
                    "label": 0
                },
                {
                    "sent": "We came up with a few sampling strategies to alleviate this from the first is just random.",
                    "label": 0
                },
                {
                    "sent": "Taking a document at random and pairing it with one positive example mini.",
                    "label": 0
                },
                {
                    "sent": "They belong in the same events.",
                    "label": 0
                },
                {
                    "sent": "One negative example.",
                    "label": 0
                },
                {
                    "sent": "And the second one is a time based where will just take the first saw and documents and use and Diane and balance the distribution using resampling.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so um, what?",
                    "label": 0
                },
                {
                    "sent": "So we have all these different.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Coaches and we want to experiment to see which ones work best.",
                    "label": 0
                },
                {
                    "sent": "Um, the approaches that we compare are at both of the ensemble based techniques.",
                    "label": 0
                },
                {
                    "sent": "The classification based techniques that consider modeling document pairs, document sent repair as other different sampling strategies and also used it to different classifiers.",
                    "label": 0
                },
                {
                    "sent": "Logistic regression, SVM.",
                    "label": 0
                },
                {
                    "sent": "As baselines, we look at all the different similarities according to the different social media document features, and in particular, we also compared to all text where all the features including that time and location are encoded as text, and we use it.",
                    "label": 0
                },
                {
                    "sent": "The text based on similarity.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the experiments we have two datasets.",
                    "label": 0
                },
                {
                    "sent": "The first is what we call the upcoming data set.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is documents, so upcoming is a user contributed event database.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what we have is over 270,000 Flickr photos and those Flickr photos are labeled by users with what they call a machine tag, which is an upcoming: event and the event ID and that event ID refers back to the event from upcoming.",
                    "label": 1
                },
                {
                    "sent": "So each photo is labeled with an event ID from upcoming.",
                    "label": 0
                },
                {
                    "sent": "We use the Flickr API to crawl all such documents between now and 2006 and 2008.",
                    "label": 0
                },
                {
                    "sent": "Uh, we split that into three parts.",
                    "label": 0
                },
                {
                    "sent": "Training, validation, testing.",
                    "label": 0
                },
                {
                    "sent": "OK, so the second data set.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is last FM.",
                    "label": 0
                },
                {
                    "sent": "Corresponds to events from the last FM music catalog.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Concerts.",
                    "label": 0
                },
                {
                    "sent": "And over 594 thousand documents and the event labels of look like last FM.",
                    "label": 0
                },
                {
                    "sent": "Call an event and the event ID.",
                    "label": 0
                },
                {
                    "sent": "And we use that as a separate asset.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some results first, these were our best performing baselines.",
                    "label": 0
                },
                {
                    "sent": "Not surprisingly, all text.",
                    "label": 0
                },
                {
                    "sent": "But Interestingly tags just using tags alone with textual similarity performed almost as well as using all text.",
                    "label": 0
                },
                {
                    "sent": "So it wasn't.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can see that the ensemble approaches are performing slightly better than the baselines ANF.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, our classification based approaches outperform both the baselines and are better than the ensemble based approaches.",
                    "label": 0
                },
                {
                    "sent": "OK, so we asked ourselves.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a significant, so we did this.",
                    "label": 0
                },
                {
                    "sent": "Physical significance analysis where we took the test, sets the upcoming test set and partitioned it into 10 equal parts and we used a Friedman tests and we found that are so the Friedman test pretty much asks are the results of the different approaches significantly different when we find that found that yes, some of them are different with P less than .05, and then we had to do some post hoc analysis to try to determine which ones are different.",
                    "label": 0
                },
                {
                    "sent": "Which ones are?",
                    "label": 0
                },
                {
                    "sent": "Can we determine our difference?",
                    "label": 0
                },
                {
                    "sent": "So this diagram pretty much take away messages that the classifiers.",
                    "label": 0
                },
                {
                    "sent": "So the this diagram shows the average rank over the ten runs and the approaches are connected with a line cannot be determined statistically significantly different.",
                    "label": 0
                },
                {
                    "sent": "So we can say that the classifiers are significantly different than the baselines.",
                    "label": 0
                },
                {
                    "sent": "All the classification based marry metric learning approaches.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so as I mentioned we used last September, they separate assets we wanted to see if say, for example we only have training data for like a certain.",
                    "label": 0
                },
                {
                    "sent": "One data set and we don't.",
                    "label": 0
                },
                {
                    "sent": "We are not able to get to train the models for the other data set, so we want to see from our models generalize and we have similar trends.",
                    "label": 0
                },
                {
                    "sent": "We're still doing all the the similarity.",
                    "label": 0
                },
                {
                    "sent": "Learning metric approaches perform better than the baseline, and here it's interesting to see that the ensemble of similarity based approach.",
                    "label": 0
                },
                {
                    "sent": "Actually, our generalizes better, so it's possible that you know if you are not able to train a model on the on the data set itself that you want to do it on the unstable models generalize better.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just come up here.",
                    "label": 0
                },
                {
                    "sent": "I have shown that the structured context features of social media provide nice complementary cues for documents similarity.",
                    "label": 0
                },
                {
                    "sent": "Some analysis on our models show that tags in the time proximity are the highest weighted features.",
                    "label": 0
                },
                {
                    "sent": "Are we show that the weighing the domain appropriate similarity metrics and principled ways yields high accuracy or high quality clustering results and we showed that they significantly outperformed the text only techniques.",
                    "label": 0
                },
                {
                    "sent": "OK, and finally using the last 10 data we show that the similarity learning models generalize to unseen datasets.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right so future work, so we are now we only looked at so far.",
                    "label": 0
                },
                {
                    "sent": "The length of the context, features of the documents.",
                    "label": 1
                },
                {
                    "sent": "But we are also interested in using the explicit links that are available in social media like explicit social network connections or common links, which I presented in poster in the search and social Media Workshop.",
                    "label": 0
                },
                {
                    "sent": "So we're looking how to into how to incorporate that into the.",
                    "label": 0
                },
                {
                    "sent": "Already learning process.",
                    "label": 1
                },
                {
                    "sent": "And of course, so we only experimented with Flickr, were interested in capturing event contents on a variety of social media sites like YouTube and obviously Twitter.",
                    "label": 0
                },
                {
                    "sent": "And knowing that we have some events on our data, user contributed databases like upcoming, lots of them, you want to see if we can design strategies for event search.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That sounds like any questions.",
                    "label": 0
                }
            ]
        }
    }
}