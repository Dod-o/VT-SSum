{
    "id": "tc33gwjrabzstmh7tq7a2gzknxkkjo53",
    "title": "Oracle inequalities for computationally budgeted model selection",
    "info": {
        "author": [
            "Alekh Agarwal, Microsoft Research"
        ],
        "published": "Aug. 2, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Science->Complexity Science"
        ]
    },
    "url": "http://videolectures.net/colt2011_agarwal_model/",
    "segmentation": [
        [
            "So we're just."
        ],
        [
            "In this model selection problem where we have K function classes.",
            "We are interested in choosing for."
        ],
        [
            "And we have ended the samples at our disposal and the goal is."
        ],
        [
            "To estimate a good function from the union of these K classes.",
            "Laser pointer.",
            "So the goal is to pick a good function from the Union of these classes based on these N samples and what we mean by a good function is a function with a small expected risk.",
            "So we assume we have some loss function that has been provided to us and we will measure there is counter expected loss function.",
            "An F hat N is the estimator which is going to be picked from one of these model classes, which is why it's a model selection problem.",
            "And this is a very classically studied problem.",
            "There are lots of different approaches to go about it.",
            "The particular class that we're going to be concerned with is."
        ],
        [
            "Out of complexity, penalized model selection procedures.",
            "So here's the general idea is that I'm going to take each function classifier in isolation 1st and compute something like any armor approximately RM from the function class, and now I take the collection of these functions.",
            "F had eyes that I have computed.",
            "I measured their empirical risk but also add in a complexity term that depends only on the class I, so I will take some notion of complexity for the model classes and compute the function F had that minimizes the sum of both the empirical risk and the complexity term.",
            "And this is a fairly generic procedure, so different choices of the complexity term will hear different model selection criteria.",
            "For instance, you can get things like AIC, BICS, Mallows, CP.",
            "Nigeria and the one that's weird that we're going to be particularly concerned with is the framework of concentration based penalties that again a lot of people have looked at, and the key idea in this framework is that we're basically going to get these complexity penalties out of a concentration bound, and in particular it's going to be something that's an upper bound on the deviation between the empirical risk of this function F had I and the expected risk of the function F had I.",
            "And again there are different variants of this thing that go around, so some people would instead use a uniform deviation bound here over the entire function class, but it suffices to use this weaker notion for the things that we're going to be interested in this work OK, so based on this framework, there's been a lot of very nice results and."
        ],
        [
            "The the key approach.",
            "The key quantity is that people are interested in.",
            "Our Oracle inequality is guaranteeing a small risk of the function we eventually compute.",
            "So remember we go."
        ],
        [
            "This function F hat N by minimizing this penalized risk."
        ],
        [
            "Nigeria and the Oracle inequality.",
            "Typical African inequality states that the function have had end that we compute is going to have a risk that's competitive with the following Oracle that minimizes.",
            "Overall, the class is the sum of these three terms shown here.",
            "The first term is just the smallest class smallest risk over the function classify which can be thought of as the approximation error for the class.",
            "The second term is the complexity penalty of the class I.",
            "Which essentially is like the estimation error because it kind of bounced the gap between the risk of the function you compute and the risk of the best function in the class and the third term is a penalty that arises due to the fact that now you're not working with one function class, but you're working over a collection of model classes, and this typically will grow logarithmically in the number of classes and as one over root N and the bound tells us that we're going to be competitive with the best class that optimizes the sum of these three terms.",
            "OK, so so this."
        ],
        [
            "Is statistically a very nice guarantee because it tells us kind of there is only a log rhythmic penalty in the number of classes.",
            "So statistically we can.",
            "We can work with many many model classes and still not there very heavy price for having to choose between them.",
            "But at the same time if you think about this."
        ],
        [
            "Procedure computationally, then it's very challenging because now you need to compute this empirical risk minimizers are approximately arms for each function class, so computationally you essentially have a linear scaling with a number of model classes, and hence you're going to be still restricted to fairly small number of classes computationally.",
            "Anne."
        ],
        [
            "And the question we want to answer in this talk is can we have a procedure for model selection that has a good scaling both statistically and computationally, so that we can truly scale to a large number of model classes?",
            "OK, so."
        ],
        [
            "And now to do this, what we what we come up with our models is a budgeted model selection framework where the budget is on the amount of computation available to you, and so we assume that there is, in an abstract sense, there is a.",
            "There are T units of a computational budget available to you, and let me describe what you can do in one unit of this computational budget.",
            "So what we allow is that for a function class, if I if you take one unit of the budget then you can.",
            "Big an eye samples and compute this ERM or approximately RM quantity on the zenny samples over the function.",
            "Classify in one unit of time.",
            "Furthermore, to keep things."
        ],
        [
            "Simple, for now I'm going to assume a linear scaling of the budget, which is if I increase my budget to T units, then I can process tee times an eye samples over the function classifier.",
            "This assumption can be relaxed, but it leads to computational nightmare, so I'm not going to go over there."
        ],
        [
            "In the talk.",
            "So OK, so that once we have the framework, we now want to sort of get our goals defined.",
            "So let's first see what we can do it with Oracle access.",
            "So suppose article comes and gives us the best class I, then the natural thing to do in the framework is to devote your entire computational budget just to that class.",
            "Do not bother with the other classes and using the entire budget T you can.",
            "Now process tee times and I samples over that Oracle class.",
            "I an so the guarantee that we would like to get for our model selection procedure is to be essentially competitive with this Oracle.",
            "We would like a guarantee that tells us that we optimize the sum of a risk criterion a penalty criterion where the penalty now should be based on the entire budget, as if somebody came and told me the optimal class and then I devoted the entire budget only to it.",
            "And again, this third term I would want it to decay as if I had seen tee times and I samples on the class.",
            "So again, as if the class received entire budget, so that's going to be the yardstick that's going to be the desired goal.",
            "An while we don't, we won't get quite this, but we're going to get pretty close."
        ],
        [
            "Correct?",
            "OK, so.",
            "And then I take a very simple sort of hacker.",
            "The problem to begin with by saying that I'm going to just take my budget and split it uniformly across the model classes Givati over K budget to each class.",
            "Well, what can I do with it?",
            "I can train on T and I / K samples for the class.",
            "I write an.",
            "That means I will pick my approximate erm over T and I / K samples and I will compute this penalized risk criterion and find the function that optimizes at criterion.",
            "And I will get an Oracle inequality, but."
        ],
        [
            "Now the article inequality will only involve T an eye over K samples for the class.",
            "I so recall that we wanted to get TNI here, but what we're stuck with if we do this uniform splitting of the budget is only TNI OK?",
            "Which makes sense because that's the number of samples that the class I saw.",
            "So what this what this tells us is that for at least an eye procedure, we've kind of we're good in computational sense because we're only using 2 units of time now, but our statistical performance is terrible.",
            "So we just kind of shifted the burden from one aspect to the other, so we don't want to do this an to get some intuition about the problem will first start from from a similar setting with an additional assumption."
        ],
        [
            "So we assume that we have a nested hierarchy of model classes, which is to say that F1 is contained in F2 and so on up to FK an.",
            "These classes are ordered by inclusion an.",
            "This is not an unnatural assumption.",
            "Actually we do have a lot of model selection problems where we actually select over nested hierarchies, so you can for instance define the fight to be the class of linear predictors with the non bounded by RI and as long as the sequence RI is increasing this is going to be a nested hierarchy.",
            "Similarly you can.",
            "Have an extra directly based on the number of dimensions that you're working in.",
            "Or you can have it based on the number.",
            "The first few coefficients in a in a wavelet basis and things like that so, so it's a pretty pretty natural sort of assumption to make in a model."
        ],
        [
            "Selection problem Now what this assumption buys us is that it imposes actually a very nice structure on the risks and the penalty functions.",
            "So let's define our.",
            "I start to be the smallest risk over the function, classify, then the first thing to observe is that our istar decays monotonically as a function of the class index I under the nesting assumption.",
            "Why is that?",
            "Well, if I go from eye to eye plus one, I have included more functions, so this minimum here.",
            "The yield me a smaller quantity.",
            "Second of all, for any reasonable penalty function, I should have a monotone increase of the penalty with the class index because I'm measuring the complexity of the class and when I go from eye to eye plus one, I go to a bigger class, so any natural complexity measure should increase.",
            "But this is not a slowly goes to 0 right?",
            "The right collection yes yes.",
            "So in general, there's going to be a Bayes risk.",
            "I and of course when you add the two quantities up then you get a function that decays initially and increases later on and we are of course interested in getting in identifying the point at which this minimum occurs.",
            "And we want to exploit these two structures to get to this point using a computationally efficient procedure."
        ],
        [
            "So the key idea that we use in order to do this is instead of training all the model classes, we're just going to pick a handful of model classes and restrict our computation only to them.",
            "And then we're going to use basically these monotonicity structures to interpolate to the other classes.",
            "OK, now you can think of doing this in various ways this partitioning, so you could just say that I'm going to pick every times model class, and then only work with with with that subset.",
            "Well, that's not going to work, but it turns out a very simple trick works, and that is based on partitioning the class based on the penalty function gamma N. OK, so here what I've shown is.",
            "Again, the penalty function plotted as the function of the model class I. Multi function is kind of on a multiplicative scale here, so.",
            "So Lambda can be any constant and I just ask which is the function class with the complexity one which is the function class with the complexity one plus Lambda one plus Lambda squared and so on.",
            "And I take these model classes that correspond to these complexity values and I only pick that subset of model classes.",
            "That's what I call a coarse grid set course, because I expect that hopefully it's going to only have a small number of classes and so now based on the thing to see is that this is going to be a very nonuniform partitioning because.",
            "Early on, when the penalty function is rising steeply, you're going to be discreet.",
            "You're going to be picking function classes fairly close to each other, whereas later on as the penalty function kind of flattens out, you're going to pick only a handful of function classes from the from the later part, so that's kind of the subset of function classes that we want to work with."
        ],
        [
            "And.",
            "Then basically now just defining the set is not sufficient.",
            "What we this is only going to be useful if its cardinality is fairly small, because once we have identified these function classes, we're going to do this ERM style computation over them.",
            "So ideally we would want to say that the size of this set is roughly logarithmic in the total number of classes, and it turns out that's not such a crazy thing to ask for.",
            "Actually a lot of natural hierarchies do satisfy that condition.",
            "So for instance, if you take.",
            "Take a collection of nested VC classes where the VC dimension does not grow very sharply from 11 function class to the next.",
            "Then this cardinality is actually going to be logarithmic in the number of classes.",
            "Similar phenomenon happens for base over several F spaces of smooth functions or for weight and spline hierarchies.",
            "Basically, as long as your complexity does not grow too much from one step to the next.",
            "You're going to be fine, and there's a more general condition in the paper telling when when this log rhythmic bound holds on the cardinality OK."
        ],
        [
            "So now this gives us a simple algorithm to analyze as well, because what I do is I take this course grid set that we got in the previous step and let let's call its cardinality little less.",
            "I split the budget uniformly between all the classes of this course grid set.",
            "I compute the approximate garden for each class, compute the function that optimizes the complexity penalized criterion."
        ],
        [
            "Ann again establish an article inequality on the resulting function that I get and the Oracle inequality now depends on the minimum risk.",
            "For class I the penalty function for class I with T and I / S. Samples now because that's the number of samples klassics and with the with the additional term that again grows as something that's Logitech making something that depends on the cardinality of the coarse grid set and the key thing to note here is that even though I worked with a with a smaller subset of the number of classes, this Oracle inequality holds overall classes.",
            "So that's where these monotonicity properties come in, and that's where this adaptive partitioning helps me that after I.",
            "Get an Oracle inequality just over this course grid set.",
            "I can use the I pick my function classes to interpolate to the rest.",
            "Rest of the collection as well and get get an Oracle inequality bound that is competitive with the entire hierarchy."
        ],
        [
            "And the particularly interesting case.",
            "Again, as I said, is the case when this cardinality is only logarithmic in case so that now I have terms that do not grow faster than logarithm log rhythmic in the number of classes anywhere."
        ],
        [
            "An so we kind of get to the goal that we were shooting for that we have a procedure that scales logarithmically both in terms of statistics and computational performance."
        ],
        [
            "So, so that's that's nice.",
            "But still this, there's this business that we had to make the nesting assumption, which ideally we would like to get rid of.",
            "Because in general you could wanted, you might want to do model selection over a fairly heterogeneous set of model classes.",
            "You could have different classes having corresponding to different kernel functions, decision trees we have let's and so on so forth.",
            "And you still want ideally a function satisfying a similar Oracle bound as we wanted before, so competitive with the same Oracle.",
            "But this this this turns out to be a significant bit harder than the nested case that the general case, and actually we're going to use a completely different style."
        ],
        [
            "Procedure to analyze this so the key idea here is going to be sort of to take an online approach.",
            "Instead, we're going to we're going to solve this problem by allocating these computational quantas online, so at every every step we're going to take a class, give, give an additional unit of computation to it, and then do something with the unit of computation, and then try to prove something about the procedure we obtain."
        ],
        [
            "And in particular, we're going to model this as I came by this problem.",
            "OK, so where does where does the bandit problem come in?",
            "Well, recall that the quantity that we are interested in minimizing is a penalized risk criteria which involves this are I start the minimum risk that I have no idea what it's going to be, because if it were observable, of course this would be a solved problem, but it's not observed.",
            "What I do know is how to construct estimates of it using the minimum empirical risk over the function class.",
            "In particular, I can also get high probability lower confidence bounds on on the minimum risk by Additionally subtracting the penalty term corresponding to class I.",
            "And now this starts sounding very reminiscent we have.",
            "We have a set up where we are allowed to take only one out of K actions, which is to pick a function class at every round.",
            "We have a procedure to construct these lower confidence bounds on the on the quality of each each.",
            "Action, and in this setting the very nice paper of our adult from 2002 tells us exactly what to do we so we pick the class that has the smallest lower bound, let's call it ID.",
            "We play, we play that class in the sense of we give it an additional unit of computational budget.",
            "Now that means that that that class it can take and sobriety knew samples of training data and compute an empirical risk minimizer.",
            "On whatever it had before, and these new samples and update its estimate of the minimum risk by by using the empirical risk over the larger set of examples now and then.",
            "This procedure is repeated."
        ],
        [
            "OK, and it turns out that the regret analysis of UCB algorithm can actually be suitably modified to get an Oracle inequality for this procedure.",
            "So let I star be the optimal class, which is the class that minimizes this penalized risk criterion.",
            "Now, just like is common to most UCB style analysis, we're going to assume a separation condition that we assume these gaps, Delta eyes, which our difference between.",
            "There, the penalized risk of class I end up penalized risk of class I stab.",
            "And for simplicity of presentation I'm also going to assume for now that the penalty function is the form constant divided by square root N where the constant depends on class I of course.",
            "So then what we can establish is that for any suboptimal class I the fraction of the budget, the fraction of the computational budget that's allocated to it is going to be small.",
            "In particular with high probability, this budget is going to just grow logarithmically in T, so it's only a log arhythmic fraction of the budget.",
            "As long as these gaps Delta I squares are not too not too small.",
            "OK, So what that tells us for model selection is that if I just take the class that my algorithm queried the most number of times to call, that's going to be the optimal class.",
            "I star as long as these deltas are not not too degenerate, and Secondly, that class I star received almost the entire budget, all but vanish in fraction of the budget.",
            "So actually the function I estimated on that class is going to be good because it has it has indeed seen a lot of samples because it got most of the budget.",
            "OK."
        ],
        [
            "So.",
            "So that's great, but still this budget condition.",
            "This separation condition is kind of unsatisfactory, because encams bandits it's kind of a natural thing to ask for, but here it's it's pretty hard to get intuition about what it means to have classes being separated under this penalized risk criterion.",
            "It's it's not a very natural condition to ask for, so so ideally we would like to get rid of it and prove prove result without this condition.",
            "Turn out to be fairly fairly hard and we can't quite get as good as a result as we would like, but nevertheless we do have something so we make the additional assumption that we can define an addition operator for functions that belong to two different classes.",
            "So if you take F from the classifier, Angie from the class of JIT, then you can meaningfully Adam and that's usually true as long as you have functions going from the same input to output domain, then it's going to be true if they are non compatible than not but.",
            "Assuming you can define them now, let F be the function the algorithm plays at time T. So what is this function?",
            "Recall that at every round I pick I choose a class, I give give it some computational budget.",
            "That means it rains on some samples and updates its empirical risk minimizer, or approximately RM and.",
            "FT is going to be back function that was computed at time T. Now I will define my final estimator to be just the average of all the functions I played.",
            "And I can prove a bound on the risk of this function that holds with high probability that is competitive with the risk with the, with the risk of the article, the penalize risk of the article, but with an additional term, which, unfortunately in this case is going to have a square root K factor, so that's why this bound is not quite what we would want it to be.",
            "In this most general case, but the nice thing is well, if at least in this term that we care about, we were able to keep the scalings right.",
            "But in the in the in the additional term we do not have the log rhythmic scaling anyway."
        ],
        [
            "OK, so to wrap up what we've seen on this work is knew computationally budgeted framework for model selection and is in this framework we were able to provide Oracle inequality's for nested hierarchies of model classes using the using a natural course grid search algorithm.",
            "We also saw Article Inequality's for a UCB style algorithm in the general case without dismissing assumption and.",
            "At least in some of the cases we were able to obtain scalings that are favorable both statistically and computationally, meaning we can truly scale up to a large number of model classes if one of those settings holds true.",
            "For future work, it would be really interesting to understand what are the other structures, what are the other conditions on model classes in which we can have a similar statement that we can have good scaling both statistically and computationally.",
            "So that's all I have to say."
        ],
        [
            "Answer your attention.",
            "So normally when you have a computational small budget.",
            "You a sample less functions and that way that there is an advantage to the disadvantage because there's less overfitting like an EM when you do early stopping.",
            "For example, you don't go to maximum works better, so I didn't see that coming back in your talk is there?",
            "I mean there should also be some kind of.",
            "Because you you only look at a few.",
            "Well, I guess you look at all the advice, but most of them you hardly look at.",
            "So so the bad help somehow.",
            "OK so the so the way that's going to come in is basically we know that for for the very complex model classes we can anyway as train on very few samples.",
            "So the budget that's going to go to them.",
            "So there's going to be.",
            "Do things that happen."
        ],
        [
            "First becausw.",
            "If you're in this sort of a Redeemer, your penalty function flattens out.",
            "For more complex classes, then you're going to sample that very sparsely.",
            "Now that the reason the reason you do need to sample from that is that if you do, if you kind of completely give up on that region, then as your budget increases, you're going to end up producing something sub optimal.",
            "So to have to have a rate that's good both in the small budget and large budget regime, you need to query at least a few classes from the flattening regions still.",
            "But there's there's going to be only a very few of them an plus they're going to be trained on a fairly small number of examples because.",
            "You did not just give them unrestricted training time, you gave them a fairly small training time so that I think those are the two ways in which the early stopping phenomenon will come in.",
            "OK.",
            "Yes, very.",
            "So when you take actually this course grade, I can't understand why you just take this grid according to the complexity to the complexity term, I don't understand how you don't need to put any assumption on your risk so that how.",
            "How is it that you control that you risk doesn't completely jump from one point of the grid to the other one?",
            "Do you have any smoothness assumption on the owner?",
            "We we do not need that because the nice thing is that so OK, so the risk you know is going to decrease as you increase the model complexity, right?",
            "As you go to bigger classes, the risk always decreases and the penalty function is.",
            "Is the one that's increasing so OK, what this kind of say?",
            "So the way you.",
            "Construct this grid set kind of is you start from the from the largest class.",
            "Then you pick the next one such that the penalty has fallen sufficiently, and then you kind of keep doing this repeatedly.",
            "Now, if the penalty between two has not changed by much, then it's always kind of better to just slide off to as right as you can go, so you are because the penalty does not hurt you much and risk has only decreased.",
            "That kind of gets handled.",
            "Automatically in the analysis penalties sometimes.",
            "If you deriving it for the 1st place then it could be you know very conservative, right?",
            "And then people would come up with empirical ways of measuring complexity.",
            "So any ideas about how you could you know extend the analyst to that case.",
            "So, so that's very tricky.",
            "For for this sort of an approach because one of the things that we so that was actually one of the disappointments that this does not address any data driven penalty at all.",
            "And the reason is that here we are kind of.",
            "Relying on this very nice fact that because we know the penalty function apriori, we can do this computation of which functions should be used for the grid sort of offline before we even start the procedure.",
            "And because we know the function in closed form, we can do this computation rather easily.",
            "That which guys correspond to enter the grid set.",
            "Now, if I have a data driven penalty, then that like that will also have to come from my budget and that becomes a much, much trickier issue.",
            "So I thought about it a little, and I.",
            "At least I did not see any easy way to proceed in that direction.",
            "But you're right, that's a very interesting question of data driven penalties.",
            "Yeah, OK, so we will postpone any further questions through the break and let's think again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're just.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this model selection problem where we have K function classes.",
                    "label": 0
                },
                {
                    "sent": "We are interested in choosing for.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have ended the samples at our disposal and the goal is.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To estimate a good function from the union of these K classes.",
                    "label": 0
                },
                {
                    "sent": "Laser pointer.",
                    "label": 0
                },
                {
                    "sent": "So the goal is to pick a good function from the Union of these classes based on these N samples and what we mean by a good function is a function with a small expected risk.",
                    "label": 0
                },
                {
                    "sent": "So we assume we have some loss function that has been provided to us and we will measure there is counter expected loss function.",
                    "label": 0
                },
                {
                    "sent": "An F hat N is the estimator which is going to be picked from one of these model classes, which is why it's a model selection problem.",
                    "label": 0
                },
                {
                    "sent": "And this is a very classically studied problem.",
                    "label": 0
                },
                {
                    "sent": "There are lots of different approaches to go about it.",
                    "label": 0
                },
                {
                    "sent": "The particular class that we're going to be concerned with is.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Out of complexity, penalized model selection procedures.",
                    "label": 1
                },
                {
                    "sent": "So here's the general idea is that I'm going to take each function classifier in isolation 1st and compute something like any armor approximately RM from the function class, and now I take the collection of these functions.",
                    "label": 0
                },
                {
                    "sent": "F had eyes that I have computed.",
                    "label": 0
                },
                {
                    "sent": "I measured their empirical risk but also add in a complexity term that depends only on the class I, so I will take some notion of complexity for the model classes and compute the function F had that minimizes the sum of both the empirical risk and the complexity term.",
                    "label": 0
                },
                {
                    "sent": "And this is a fairly generic procedure, so different choices of the complexity term will hear different model selection criteria.",
                    "label": 1
                },
                {
                    "sent": "For instance, you can get things like AIC, BICS, Mallows, CP.",
                    "label": 0
                },
                {
                    "sent": "Nigeria and the one that's weird that we're going to be particularly concerned with is the framework of concentration based penalties that again a lot of people have looked at, and the key idea in this framework is that we're basically going to get these complexity penalties out of a concentration bound, and in particular it's going to be something that's an upper bound on the deviation between the empirical risk of this function F had I and the expected risk of the function F had I.",
                    "label": 0
                },
                {
                    "sent": "And again there are different variants of this thing that go around, so some people would instead use a uniform deviation bound here over the entire function class, but it suffices to use this weaker notion for the things that we're going to be interested in this work OK, so based on this framework, there's been a lot of very nice results and.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The the key approach.",
                    "label": 0
                },
                {
                    "sent": "The key quantity is that people are interested in.",
                    "label": 0
                },
                {
                    "sent": "Our Oracle inequality is guaranteeing a small risk of the function we eventually compute.",
                    "label": 1
                },
                {
                    "sent": "So remember we go.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This function F hat N by minimizing this penalized risk.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nigeria and the Oracle inequality.",
                    "label": 0
                },
                {
                    "sent": "Typical African inequality states that the function have had end that we compute is going to have a risk that's competitive with the following Oracle that minimizes.",
                    "label": 0
                },
                {
                    "sent": "Overall, the class is the sum of these three terms shown here.",
                    "label": 0
                },
                {
                    "sent": "The first term is just the smallest class smallest risk over the function classify which can be thought of as the approximation error for the class.",
                    "label": 0
                },
                {
                    "sent": "The second term is the complexity penalty of the class I.",
                    "label": 0
                },
                {
                    "sent": "Which essentially is like the estimation error because it kind of bounced the gap between the risk of the function you compute and the risk of the best function in the class and the third term is a penalty that arises due to the fact that now you're not working with one function class, but you're working over a collection of model classes, and this typically will grow logarithmically in the number of classes and as one over root N and the bound tells us that we're going to be competitive with the best class that optimizes the sum of these three terms.",
                    "label": 0
                },
                {
                    "sent": "OK, so so this.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is statistically a very nice guarantee because it tells us kind of there is only a log rhythmic penalty in the number of classes.",
                    "label": 1
                },
                {
                    "sent": "So statistically we can.",
                    "label": 0
                },
                {
                    "sent": "We can work with many many model classes and still not there very heavy price for having to choose between them.",
                    "label": 0
                },
                {
                    "sent": "But at the same time if you think about this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Procedure computationally, then it's very challenging because now you need to compute this empirical risk minimizers are approximately arms for each function class, so computationally you essentially have a linear scaling with a number of model classes, and hence you're going to be still restricted to fairly small number of classes computationally.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the question we want to answer in this talk is can we have a procedure for model selection that has a good scaling both statistically and computationally, so that we can truly scale to a large number of model classes?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now to do this, what we what we come up with our models is a budgeted model selection framework where the budget is on the amount of computation available to you, and so we assume that there is, in an abstract sense, there is a.",
                    "label": 1
                },
                {
                    "sent": "There are T units of a computational budget available to you, and let me describe what you can do in one unit of this computational budget.",
                    "label": 0
                },
                {
                    "sent": "So what we allow is that for a function class, if I if you take one unit of the budget then you can.",
                    "label": 0
                },
                {
                    "sent": "Big an eye samples and compute this ERM or approximately RM quantity on the zenny samples over the function.",
                    "label": 0
                },
                {
                    "sent": "Classify in one unit of time.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, to keep things.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simple, for now I'm going to assume a linear scaling of the budget, which is if I increase my budget to T units, then I can process tee times an eye samples over the function classifier.",
                    "label": 0
                },
                {
                    "sent": "This assumption can be relaxed, but it leads to computational nightmare, so I'm not going to go over there.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the talk.",
                    "label": 0
                },
                {
                    "sent": "So OK, so that once we have the framework, we now want to sort of get our goals defined.",
                    "label": 0
                },
                {
                    "sent": "So let's first see what we can do it with Oracle access.",
                    "label": 0
                },
                {
                    "sent": "So suppose article comes and gives us the best class I, then the natural thing to do in the framework is to devote your entire computational budget just to that class.",
                    "label": 0
                },
                {
                    "sent": "Do not bother with the other classes and using the entire budget T you can.",
                    "label": 1
                },
                {
                    "sent": "Now process tee times and I samples over that Oracle class.",
                    "label": 0
                },
                {
                    "sent": "I an so the guarantee that we would like to get for our model selection procedure is to be essentially competitive with this Oracle.",
                    "label": 0
                },
                {
                    "sent": "We would like a guarantee that tells us that we optimize the sum of a risk criterion a penalty criterion where the penalty now should be based on the entire budget, as if somebody came and told me the optimal class and then I devoted the entire budget only to it.",
                    "label": 0
                },
                {
                    "sent": "And again, this third term I would want it to decay as if I had seen tee times and I samples on the class.",
                    "label": 0
                },
                {
                    "sent": "So again, as if the class received entire budget, so that's going to be the yardstick that's going to be the desired goal.",
                    "label": 0
                },
                {
                    "sent": "An while we don't, we won't get quite this, but we're going to get pretty close.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Correct?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "And then I take a very simple sort of hacker.",
                    "label": 0
                },
                {
                    "sent": "The problem to begin with by saying that I'm going to just take my budget and split it uniformly across the model classes Givati over K budget to each class.",
                    "label": 1
                },
                {
                    "sent": "Well, what can I do with it?",
                    "label": 0
                },
                {
                    "sent": "I can train on T and I / K samples for the class.",
                    "label": 0
                },
                {
                    "sent": "I write an.",
                    "label": 0
                },
                {
                    "sent": "That means I will pick my approximate erm over T and I / K samples and I will compute this penalized risk criterion and find the function that optimizes at criterion.",
                    "label": 0
                },
                {
                    "sent": "And I will get an Oracle inequality, but.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the article inequality will only involve T an eye over K samples for the class.",
                    "label": 0
                },
                {
                    "sent": "I so recall that we wanted to get TNI here, but what we're stuck with if we do this uniform splitting of the budget is only TNI OK?",
                    "label": 0
                },
                {
                    "sent": "Which makes sense because that's the number of samples that the class I saw.",
                    "label": 0
                },
                {
                    "sent": "So what this what this tells us is that for at least an eye procedure, we've kind of we're good in computational sense because we're only using 2 units of time now, but our statistical performance is terrible.",
                    "label": 0
                },
                {
                    "sent": "So we just kind of shifted the burden from one aspect to the other, so we don't want to do this an to get some intuition about the problem will first start from from a similar setting with an additional assumption.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we assume that we have a nested hierarchy of model classes, which is to say that F1 is contained in F2 and so on up to FK an.",
                    "label": 0
                },
                {
                    "sent": "These classes are ordered by inclusion an.",
                    "label": 0
                },
                {
                    "sent": "This is not an unnatural assumption.",
                    "label": 0
                },
                {
                    "sent": "Actually we do have a lot of model selection problems where we actually select over nested hierarchies, so you can for instance define the fight to be the class of linear predictors with the non bounded by RI and as long as the sequence RI is increasing this is going to be a nested hierarchy.",
                    "label": 0
                },
                {
                    "sent": "Similarly you can.",
                    "label": 0
                },
                {
                    "sent": "Have an extra directly based on the number of dimensions that you're working in.",
                    "label": 0
                },
                {
                    "sent": "Or you can have it based on the number.",
                    "label": 0
                },
                {
                    "sent": "The first few coefficients in a in a wavelet basis and things like that so, so it's a pretty pretty natural sort of assumption to make in a model.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Selection problem Now what this assumption buys us is that it imposes actually a very nice structure on the risks and the penalty functions.",
                    "label": 0
                },
                {
                    "sent": "So let's define our.",
                    "label": 0
                },
                {
                    "sent": "I start to be the smallest risk over the function, classify, then the first thing to observe is that our istar decays monotonically as a function of the class index I under the nesting assumption.",
                    "label": 0
                },
                {
                    "sent": "Why is that?",
                    "label": 0
                },
                {
                    "sent": "Well, if I go from eye to eye plus one, I have included more functions, so this minimum here.",
                    "label": 0
                },
                {
                    "sent": "The yield me a smaller quantity.",
                    "label": 0
                },
                {
                    "sent": "Second of all, for any reasonable penalty function, I should have a monotone increase of the penalty with the class index because I'm measuring the complexity of the class and when I go from eye to eye plus one, I go to a bigger class, so any natural complexity measure should increase.",
                    "label": 0
                },
                {
                    "sent": "But this is not a slowly goes to 0 right?",
                    "label": 0
                },
                {
                    "sent": "The right collection yes yes.",
                    "label": 0
                },
                {
                    "sent": "So in general, there's going to be a Bayes risk.",
                    "label": 0
                },
                {
                    "sent": "I and of course when you add the two quantities up then you get a function that decays initially and increases later on and we are of course interested in getting in identifying the point at which this minimum occurs.",
                    "label": 0
                },
                {
                    "sent": "And we want to exploit these two structures to get to this point using a computationally efficient procedure.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the key idea that we use in order to do this is instead of training all the model classes, we're just going to pick a handful of model classes and restrict our computation only to them.",
                    "label": 0
                },
                {
                    "sent": "And then we're going to use basically these monotonicity structures to interpolate to the other classes.",
                    "label": 1
                },
                {
                    "sent": "OK, now you can think of doing this in various ways this partitioning, so you could just say that I'm going to pick every times model class, and then only work with with with that subset.",
                    "label": 0
                },
                {
                    "sent": "Well, that's not going to work, but it turns out a very simple trick works, and that is based on partitioning the class based on the penalty function gamma N. OK, so here what I've shown is.",
                    "label": 0
                },
                {
                    "sent": "Again, the penalty function plotted as the function of the model class I. Multi function is kind of on a multiplicative scale here, so.",
                    "label": 0
                },
                {
                    "sent": "So Lambda can be any constant and I just ask which is the function class with the complexity one which is the function class with the complexity one plus Lambda one plus Lambda squared and so on.",
                    "label": 1
                },
                {
                    "sent": "And I take these model classes that correspond to these complexity values and I only pick that subset of model classes.",
                    "label": 0
                },
                {
                    "sent": "That's what I call a coarse grid set course, because I expect that hopefully it's going to only have a small number of classes and so now based on the thing to see is that this is going to be a very nonuniform partitioning because.",
                    "label": 1
                },
                {
                    "sent": "Early on, when the penalty function is rising steeply, you're going to be discreet.",
                    "label": 0
                },
                {
                    "sent": "You're going to be picking function classes fairly close to each other, whereas later on as the penalty function kind of flattens out, you're going to pick only a handful of function classes from the from the later part, so that's kind of the subset of function classes that we want to work with.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Then basically now just defining the set is not sufficient.",
                    "label": 0
                },
                {
                    "sent": "What we this is only going to be useful if its cardinality is fairly small, because once we have identified these function classes, we're going to do this ERM style computation over them.",
                    "label": 0
                },
                {
                    "sent": "So ideally we would want to say that the size of this set is roughly logarithmic in the total number of classes, and it turns out that's not such a crazy thing to ask for.",
                    "label": 0
                },
                {
                    "sent": "Actually a lot of natural hierarchies do satisfy that condition.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if you take.",
                    "label": 0
                },
                {
                    "sent": "Take a collection of nested VC classes where the VC dimension does not grow very sharply from 11 function class to the next.",
                    "label": 0
                },
                {
                    "sent": "Then this cardinality is actually going to be logarithmic in the number of classes.",
                    "label": 0
                },
                {
                    "sent": "Similar phenomenon happens for base over several F spaces of smooth functions or for weight and spline hierarchies.",
                    "label": 1
                },
                {
                    "sent": "Basically, as long as your complexity does not grow too much from one step to the next.",
                    "label": 0
                },
                {
                    "sent": "You're going to be fine, and there's a more general condition in the paper telling when when this log rhythmic bound holds on the cardinality OK.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now this gives us a simple algorithm to analyze as well, because what I do is I take this course grid set that we got in the previous step and let let's call its cardinality little less.",
                    "label": 0
                },
                {
                    "sent": "I split the budget uniformly between all the classes of this course grid set.",
                    "label": 1
                },
                {
                    "sent": "I compute the approximate garden for each class, compute the function that optimizes the complexity penalized criterion.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ann again establish an article inequality on the resulting function that I get and the Oracle inequality now depends on the minimum risk.",
                    "label": 0
                },
                {
                    "sent": "For class I the penalty function for class I with T and I / S. Samples now because that's the number of samples klassics and with the with the additional term that again grows as something that's Logitech making something that depends on the cardinality of the coarse grid set and the key thing to note here is that even though I worked with a with a smaller subset of the number of classes, this Oracle inequality holds overall classes.",
                    "label": 0
                },
                {
                    "sent": "So that's where these monotonicity properties come in, and that's where this adaptive partitioning helps me that after I.",
                    "label": 0
                },
                {
                    "sent": "Get an Oracle inequality just over this course grid set.",
                    "label": 1
                },
                {
                    "sent": "I can use the I pick my function classes to interpolate to the rest.",
                    "label": 0
                },
                {
                    "sent": "Rest of the collection as well and get get an Oracle inequality bound that is competitive with the entire hierarchy.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the particularly interesting case.",
                    "label": 0
                },
                {
                    "sent": "Again, as I said, is the case when this cardinality is only logarithmic in case so that now I have terms that do not grow faster than logarithm log rhythmic in the number of classes anywhere.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An so we kind of get to the goal that we were shooting for that we have a procedure that scales logarithmically both in terms of statistics and computational performance.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so that's that's nice.",
                    "label": 0
                },
                {
                    "sent": "But still this, there's this business that we had to make the nesting assumption, which ideally we would like to get rid of.",
                    "label": 1
                },
                {
                    "sent": "Because in general you could wanted, you might want to do model selection over a fairly heterogeneous set of model classes.",
                    "label": 0
                },
                {
                    "sent": "You could have different classes having corresponding to different kernel functions, decision trees we have let's and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "And you still want ideally a function satisfying a similar Oracle bound as we wanted before, so competitive with the same Oracle.",
                    "label": 1
                },
                {
                    "sent": "But this this this turns out to be a significant bit harder than the nested case that the general case, and actually we're going to use a completely different style.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Procedure to analyze this so the key idea here is going to be sort of to take an online approach.",
                    "label": 0
                },
                {
                    "sent": "Instead, we're going to we're going to solve this problem by allocating these computational quantas online, so at every every step we're going to take a class, give, give an additional unit of computation to it, and then do something with the unit of computation, and then try to prove something about the procedure we obtain.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in particular, we're going to model this as I came by this problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so where does where does the bandit problem come in?",
                    "label": 0
                },
                {
                    "sent": "Well, recall that the quantity that we are interested in minimizing is a penalized risk criteria which involves this are I start the minimum risk that I have no idea what it's going to be, because if it were observable, of course this would be a solved problem, but it's not observed.",
                    "label": 0
                },
                {
                    "sent": "What I do know is how to construct estimates of it using the minimum empirical risk over the function class.",
                    "label": 0
                },
                {
                    "sent": "In particular, I can also get high probability lower confidence bounds on on the minimum risk by Additionally subtracting the penalty term corresponding to class I.",
                    "label": 0
                },
                {
                    "sent": "And now this starts sounding very reminiscent we have.",
                    "label": 0
                },
                {
                    "sent": "We have a set up where we are allowed to take only one out of K actions, which is to pick a function class at every round.",
                    "label": 0
                },
                {
                    "sent": "We have a procedure to construct these lower confidence bounds on the on the quality of each each.",
                    "label": 0
                },
                {
                    "sent": "Action, and in this setting the very nice paper of our adult from 2002 tells us exactly what to do we so we pick the class that has the smallest lower bound, let's call it ID.",
                    "label": 0
                },
                {
                    "sent": "We play, we play that class in the sense of we give it an additional unit of computational budget.",
                    "label": 0
                },
                {
                    "sent": "Now that means that that that class it can take and sobriety knew samples of training data and compute an empirical risk minimizer.",
                    "label": 0
                },
                {
                    "sent": "On whatever it had before, and these new samples and update its estimate of the minimum risk by by using the empirical risk over the larger set of examples now and then.",
                    "label": 0
                },
                {
                    "sent": "This procedure is repeated.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and it turns out that the regret analysis of UCB algorithm can actually be suitably modified to get an Oracle inequality for this procedure.",
                    "label": 0
                },
                {
                    "sent": "So let I star be the optimal class, which is the class that minimizes this penalized risk criterion.",
                    "label": 0
                },
                {
                    "sent": "Now, just like is common to most UCB style analysis, we're going to assume a separation condition that we assume these gaps, Delta eyes, which our difference between.",
                    "label": 0
                },
                {
                    "sent": "There, the penalized risk of class I end up penalized risk of class I stab.",
                    "label": 1
                },
                {
                    "sent": "And for simplicity of presentation I'm also going to assume for now that the penalty function is the form constant divided by square root N where the constant depends on class I of course.",
                    "label": 0
                },
                {
                    "sent": "So then what we can establish is that for any suboptimal class I the fraction of the budget, the fraction of the computational budget that's allocated to it is going to be small.",
                    "label": 1
                },
                {
                    "sent": "In particular with high probability, this budget is going to just grow logarithmically in T, so it's only a log arhythmic fraction of the budget.",
                    "label": 0
                },
                {
                    "sent": "As long as these gaps Delta I squares are not too not too small.",
                    "label": 1
                },
                {
                    "sent": "OK, So what that tells us for model selection is that if I just take the class that my algorithm queried the most number of times to call, that's going to be the optimal class.",
                    "label": 0
                },
                {
                    "sent": "I star as long as these deltas are not not too degenerate, and Secondly, that class I star received almost the entire budget, all but vanish in fraction of the budget.",
                    "label": 0
                },
                {
                    "sent": "So actually the function I estimated on that class is going to be good because it has it has indeed seen a lot of samples because it got most of the budget.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So that's great, but still this budget condition.",
                    "label": 0
                },
                {
                    "sent": "This separation condition is kind of unsatisfactory, because encams bandits it's kind of a natural thing to ask for, but here it's it's pretty hard to get intuition about what it means to have classes being separated under this penalized risk criterion.",
                    "label": 0
                },
                {
                    "sent": "It's it's not a very natural condition to ask for, so so ideally we would like to get rid of it and prove prove result without this condition.",
                    "label": 0
                },
                {
                    "sent": "Turn out to be fairly fairly hard and we can't quite get as good as a result as we would like, but nevertheless we do have something so we make the additional assumption that we can define an addition operator for functions that belong to two different classes.",
                    "label": 0
                },
                {
                    "sent": "So if you take F from the classifier, Angie from the class of JIT, then you can meaningfully Adam and that's usually true as long as you have functions going from the same input to output domain, then it's going to be true if they are non compatible than not but.",
                    "label": 0
                },
                {
                    "sent": "Assuming you can define them now, let F be the function the algorithm plays at time T. So what is this function?",
                    "label": 0
                },
                {
                    "sent": "Recall that at every round I pick I choose a class, I give give it some computational budget.",
                    "label": 0
                },
                {
                    "sent": "That means it rains on some samples and updates its empirical risk minimizer, or approximately RM and.",
                    "label": 0
                },
                {
                    "sent": "FT is going to be back function that was computed at time T. Now I will define my final estimator to be just the average of all the functions I played.",
                    "label": 0
                },
                {
                    "sent": "And I can prove a bound on the risk of this function that holds with high probability that is competitive with the risk with the, with the risk of the article, the penalize risk of the article, but with an additional term, which, unfortunately in this case is going to have a square root K factor, so that's why this bound is not quite what we would want it to be.",
                    "label": 0
                },
                {
                    "sent": "In this most general case, but the nice thing is well, if at least in this term that we care about, we were able to keep the scalings right.",
                    "label": 0
                },
                {
                    "sent": "But in the in the in the additional term we do not have the log rhythmic scaling anyway.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so to wrap up what we've seen on this work is knew computationally budgeted framework for model selection and is in this framework we were able to provide Oracle inequality's for nested hierarchies of model classes using the using a natural course grid search algorithm.",
                    "label": 1
                },
                {
                    "sent": "We also saw Article Inequality's for a UCB style algorithm in the general case without dismissing assumption and.",
                    "label": 0
                },
                {
                    "sent": "At least in some of the cases we were able to obtain scalings that are favorable both statistically and computationally, meaning we can truly scale up to a large number of model classes if one of those settings holds true.",
                    "label": 1
                },
                {
                    "sent": "For future work, it would be really interesting to understand what are the other structures, what are the other conditions on model classes in which we can have a similar statement that we can have good scaling both statistically and computationally.",
                    "label": 0
                },
                {
                    "sent": "So that's all I have to say.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Answer your attention.",
                    "label": 0
                },
                {
                    "sent": "So normally when you have a computational small budget.",
                    "label": 0
                },
                {
                    "sent": "You a sample less functions and that way that there is an advantage to the disadvantage because there's less overfitting like an EM when you do early stopping.",
                    "label": 0
                },
                {
                    "sent": "For example, you don't go to maximum works better, so I didn't see that coming back in your talk is there?",
                    "label": 0
                },
                {
                    "sent": "I mean there should also be some kind of.",
                    "label": 0
                },
                {
                    "sent": "Because you you only look at a few.",
                    "label": 0
                },
                {
                    "sent": "Well, I guess you look at all the advice, but most of them you hardly look at.",
                    "label": 0
                },
                {
                    "sent": "So so the bad help somehow.",
                    "label": 0
                },
                {
                    "sent": "OK so the so the way that's going to come in is basically we know that for for the very complex model classes we can anyway as train on very few samples.",
                    "label": 0
                },
                {
                    "sent": "So the budget that's going to go to them.",
                    "label": 0
                },
                {
                    "sent": "So there's going to be.",
                    "label": 0
                },
                {
                    "sent": "Do things that happen.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First becausw.",
                    "label": 0
                },
                {
                    "sent": "If you're in this sort of a Redeemer, your penalty function flattens out.",
                    "label": 0
                },
                {
                    "sent": "For more complex classes, then you're going to sample that very sparsely.",
                    "label": 0
                },
                {
                    "sent": "Now that the reason the reason you do need to sample from that is that if you do, if you kind of completely give up on that region, then as your budget increases, you're going to end up producing something sub optimal.",
                    "label": 0
                },
                {
                    "sent": "So to have to have a rate that's good both in the small budget and large budget regime, you need to query at least a few classes from the flattening regions still.",
                    "label": 0
                },
                {
                    "sent": "But there's there's going to be only a very few of them an plus they're going to be trained on a fairly small number of examples because.",
                    "label": 0
                },
                {
                    "sent": "You did not just give them unrestricted training time, you gave them a fairly small training time so that I think those are the two ways in which the early stopping phenomenon will come in.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Yes, very.",
                    "label": 0
                },
                {
                    "sent": "So when you take actually this course grade, I can't understand why you just take this grid according to the complexity to the complexity term, I don't understand how you don't need to put any assumption on your risk so that how.",
                    "label": 0
                },
                {
                    "sent": "How is it that you control that you risk doesn't completely jump from one point of the grid to the other one?",
                    "label": 0
                },
                {
                    "sent": "Do you have any smoothness assumption on the owner?",
                    "label": 0
                },
                {
                    "sent": "We we do not need that because the nice thing is that so OK, so the risk you know is going to decrease as you increase the model complexity, right?",
                    "label": 0
                },
                {
                    "sent": "As you go to bigger classes, the risk always decreases and the penalty function is.",
                    "label": 0
                },
                {
                    "sent": "Is the one that's increasing so OK, what this kind of say?",
                    "label": 0
                },
                {
                    "sent": "So the way you.",
                    "label": 0
                },
                {
                    "sent": "Construct this grid set kind of is you start from the from the largest class.",
                    "label": 0
                },
                {
                    "sent": "Then you pick the next one such that the penalty has fallen sufficiently, and then you kind of keep doing this repeatedly.",
                    "label": 0
                },
                {
                    "sent": "Now, if the penalty between two has not changed by much, then it's always kind of better to just slide off to as right as you can go, so you are because the penalty does not hurt you much and risk has only decreased.",
                    "label": 0
                },
                {
                    "sent": "That kind of gets handled.",
                    "label": 0
                },
                {
                    "sent": "Automatically in the analysis penalties sometimes.",
                    "label": 0
                },
                {
                    "sent": "If you deriving it for the 1st place then it could be you know very conservative, right?",
                    "label": 0
                },
                {
                    "sent": "And then people would come up with empirical ways of measuring complexity.",
                    "label": 0
                },
                {
                    "sent": "So any ideas about how you could you know extend the analyst to that case.",
                    "label": 0
                },
                {
                    "sent": "So, so that's very tricky.",
                    "label": 0
                },
                {
                    "sent": "For for this sort of an approach because one of the things that we so that was actually one of the disappointments that this does not address any data driven penalty at all.",
                    "label": 0
                },
                {
                    "sent": "And the reason is that here we are kind of.",
                    "label": 0
                },
                {
                    "sent": "Relying on this very nice fact that because we know the penalty function apriori, we can do this computation of which functions should be used for the grid sort of offline before we even start the procedure.",
                    "label": 0
                },
                {
                    "sent": "And because we know the function in closed form, we can do this computation rather easily.",
                    "label": 0
                },
                {
                    "sent": "That which guys correspond to enter the grid set.",
                    "label": 0
                },
                {
                    "sent": "Now, if I have a data driven penalty, then that like that will also have to come from my budget and that becomes a much, much trickier issue.",
                    "label": 0
                },
                {
                    "sent": "So I thought about it a little, and I.",
                    "label": 0
                },
                {
                    "sent": "At least I did not see any easy way to proceed in that direction.",
                    "label": 0
                },
                {
                    "sent": "But you're right, that's a very interesting question of data driven penalties.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so we will postpone any further questions through the break and let's think again.",
                    "label": 0
                }
            ]
        }
    }
}