{
    "id": "dqdjhid3yedvnrd54blk6kgb365mytmq",
    "title": "Exact inference and learning for cumulative",
    "info": {
        "author": [
            "Jim C. Huang, Amazon"
        ],
        "published": "March 25, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Mathematics->Graph Theory"
        ]
    },
    "url": "http://videolectures.net/nips2010_huang_eil/",
    "segmentation": [
        [
            "So the problem we look at in our paper is 1 in its most general form of computing, the mixed derivative of some function call it big F that factorizes over some subsets of variables in the model.",
            "So usually this factorization can be represented conveniently in the form of a graph is shown on the right.",
            "Interestingly, this problem occurs in a wide variety of settings.",
            "It turns out a lot of hard counting problems in common, that orexin statistical physics and computational chemistry can be viewed as computing a quantity precisely that form.",
            "Today I'm going to talk about a particular setting of this problem, one where you want to compute this quantity for a CDF.",
            "So we're going big.",
            "F corresponds to a cumulative distribution function.",
            "They probability over any quality events or interval events.",
            "And so the idea is that there are two fundamental problems that you want to solve when you're looking at models for CDF's.",
            "The first one is how do you go from the CDF Big F back to a probability density function, big P?",
            "And so that's just the mixed derivative.",
            "And then if you want to do maximum likelihood estimation, how that corresponds to computing the gradient of big pee.",
            "So previously we showed how to do this efficiently using message passing for tree structured CDF's.",
            "However, if your graph has cycles in it, then of course something more is required."
        ],
        [
            "And so the approach we take is one of divide and conquer.",
            "So this will appeal to those of you who enjoyed inception.",
            "The idea is you're going to take this global differentiation problem, and you're going to break it down into smaller sub pieces.",
            "And the idea is that the solution to each of these sub pieces itself should ought to be manageable.",
            "And really the algorithm tells you how to piece together these subproblems such that the overall solution is exact, and so this recursive decomposition approaches very naturally described by a junction tree.",
            "And so the global differentiation can be viewed simply as passing messages within this junction tree where messages correspond to derivatives of the subparts of your CDF with respect to sub parts of the graph.",
            "And so we call the resulting algorithm jaded for junction tree differentiation.",
            "Not surprisingly, because it's based on the junction tree.",
            "Decomposition complexity is exponential in the tree with the graph."
        ],
        [
            "And so the kinds of data that we'd like to look at once we have a scheme for inference and learning of joint CDF.",
            "SAR datasets that are multivariate exhibit certain dependencies structures.",
            "An exhibit heavy tailed statistics.",
            "So examples of these that we look at in the paper include modeling rainfall measurements at discrete numbers of spatial measurement locations or modeling H1N1 mortality.",
            "So why show on the right?",
            "Here is an overlay of.",
            "Data for the rainfall data set so clearly non Gaussian very heavy tailed.",
            "An overlaid on top of that are the PDF contours obtained from the model that we learned using the algorithm just described."
        ],
        [
            "And so when we compare model CDN model into distribution network model to a panel of methods for modeling heavy tailed data such as tree structured CDN's or copula based methods, we got significantly more predictive probability distributions as measured by test likelihood on left out data and it's certainly worth mentioning that where you do attempt computing derivatives using the standard symbolic differentiation.",
            "Seems that you very quickly run into trouble so.",
            "That being said, if you'd like to hear a bit more about some of the things I touched on last four minutes, please come see our poster tonight.",
            "Number 87."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the problem we look at in our paper is 1 in its most general form of computing, the mixed derivative of some function call it big F that factorizes over some subsets of variables in the model.",
                    "label": 0
                },
                {
                    "sent": "So usually this factorization can be represented conveniently in the form of a graph is shown on the right.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, this problem occurs in a wide variety of settings.",
                    "label": 0
                },
                {
                    "sent": "It turns out a lot of hard counting problems in common, that orexin statistical physics and computational chemistry can be viewed as computing a quantity precisely that form.",
                    "label": 1
                },
                {
                    "sent": "Today I'm going to talk about a particular setting of this problem, one where you want to compute this quantity for a CDF.",
                    "label": 0
                },
                {
                    "sent": "So we're going big.",
                    "label": 1
                },
                {
                    "sent": "F corresponds to a cumulative distribution function.",
                    "label": 1
                },
                {
                    "sent": "They probability over any quality events or interval events.",
                    "label": 1
                },
                {
                    "sent": "And so the idea is that there are two fundamental problems that you want to solve when you're looking at models for CDF's.",
                    "label": 0
                },
                {
                    "sent": "The first one is how do you go from the CDF Big F back to a probability density function, big P?",
                    "label": 0
                },
                {
                    "sent": "And so that's just the mixed derivative.",
                    "label": 0
                },
                {
                    "sent": "And then if you want to do maximum likelihood estimation, how that corresponds to computing the gradient of big pee.",
                    "label": 0
                },
                {
                    "sent": "So previously we showed how to do this efficiently using message passing for tree structured CDF's.",
                    "label": 0
                },
                {
                    "sent": "However, if your graph has cycles in it, then of course something more is required.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so the approach we take is one of divide and conquer.",
                    "label": 1
                },
                {
                    "sent": "So this will appeal to those of you who enjoyed inception.",
                    "label": 1
                },
                {
                    "sent": "The idea is you're going to take this global differentiation problem, and you're going to break it down into smaller sub pieces.",
                    "label": 0
                },
                {
                    "sent": "And the idea is that the solution to each of these sub pieces itself should ought to be manageable.",
                    "label": 0
                },
                {
                    "sent": "And really the algorithm tells you how to piece together these subproblems such that the overall solution is exact, and so this recursive decomposition approaches very naturally described by a junction tree.",
                    "label": 1
                },
                {
                    "sent": "And so the global differentiation can be viewed simply as passing messages within this junction tree where messages correspond to derivatives of the subparts of your CDF with respect to sub parts of the graph.",
                    "label": 1
                },
                {
                    "sent": "And so we call the resulting algorithm jaded for junction tree differentiation.",
                    "label": 0
                },
                {
                    "sent": "Not surprisingly, because it's based on the junction tree.",
                    "label": 0
                },
                {
                    "sent": "Decomposition complexity is exponential in the tree with the graph.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so the kinds of data that we'd like to look at once we have a scheme for inference and learning of joint CDF.",
                    "label": 0
                },
                {
                    "sent": "SAR datasets that are multivariate exhibit certain dependencies structures.",
                    "label": 0
                },
                {
                    "sent": "An exhibit heavy tailed statistics.",
                    "label": 0
                },
                {
                    "sent": "So examples of these that we look at in the paper include modeling rainfall measurements at discrete numbers of spatial measurement locations or modeling H1N1 mortality.",
                    "label": 1
                },
                {
                    "sent": "So why show on the right?",
                    "label": 0
                },
                {
                    "sent": "Here is an overlay of.",
                    "label": 0
                },
                {
                    "sent": "Data for the rainfall data set so clearly non Gaussian very heavy tailed.",
                    "label": 0
                },
                {
                    "sent": "An overlaid on top of that are the PDF contours obtained from the model that we learned using the algorithm just described.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so when we compare model CDN model into distribution network model to a panel of methods for modeling heavy tailed data such as tree structured CDN's or copula based methods, we got significantly more predictive probability distributions as measured by test likelihood on left out data and it's certainly worth mentioning that where you do attempt computing derivatives using the standard symbolic differentiation.",
                    "label": 0
                },
                {
                    "sent": "Seems that you very quickly run into trouble so.",
                    "label": 0
                },
                {
                    "sent": "That being said, if you'd like to hear a bit more about some of the things I touched on last four minutes, please come see our poster tonight.",
                    "label": 1
                },
                {
                    "sent": "Number 87.",
                    "label": 0
                }
            ]
        }
    }
}