{
    "id": "6toldmepuexx6325k2crfvie5bgs7x7t",
    "title": "Non-Parametric Scan Statistics for Event Detection and Forecasting in Heterogeneous Social Media Graphs",
    "info": {
        "author": [
            "Feng Chen, College of Computing and Information (CCI), University at Albany, State University of New York"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_chen_social_media/",
    "segmentation": [
        [
            "Good afternoon everyone.",
            "My name is function.",
            "I'm going to present non parametric scan statistics for event detection and forecasting in heterogeneous social media graphs.",
            "So this is joint collaboration with Doctor Daniel Neal."
        ],
        [
            "So before I introduce our work, you may ask the question WHI can we detect and forecast events from social media?",
            "So here we define an event as a larger population behavior.",
            "Social media can be considered as a real time sensor of large population behavior.",
            "Therefore, it is possible for us to monitor social media to track large population human behavior.",
            "To detect an forecast.",
            "Events if we sense public discussions about ongoing events.",
            "Then we can possibly detect events if we can sense public discussions about trigger events, then we can potentially forecast events."
        ],
        [
            "So let us go.",
            "Let us consider very concrete example of a real disease hantavirus outbreak detection in Treaty last year.",
            "So these are.",
            "True Raw tweet Twitter texts.",
            "About hantavirus the first tweet is about people dying from heart virus in the city, also known by the local government.",
            "Do not report.",
            "And as a Utah Twitter user back for help.",
            "The second one is the retweet of a confirmed infection of Honduras.",
            "From channel which we do not know.",
            "The third one is a confirmed infection.",
            "Actually is the death of our one young man by hand virus.",
            "That the user read from public blog as shown here.",
            "So last one is a retweet by influential user named as radio polynomial about a confirmed case of 100 various."
        ],
        [
            "So the challenge is for detection of events.",
            "In Twitter data and social media, data can be interpreted as the old story of big elephants and the blind man.",
            "Social media data can be considered as a big elephant.",
            "And we, the human can be considered as a blind man.",
            "So if there is."
        ],
        [
            "100 various disease outbreak what we observed are many small pieces potentially relevant information that are connected."
        ],
        [
            "Through heterogeneous relations.",
            "Now the training tree is how we can identify the sub graph of a.",
            "Potentially relevant signals and make use of the sub graph to detect and forecast hantavirus outbreak.",
            "You may think about how do we consider multi variant classification and regression.",
            "But here what we considered is a graph of nodes that can be different types and each node type may have different attributes, so it's not a very straightforward way that you can fit in traditional machine learning techniques."
        ],
        [
            "So our solution, including includes three steps.",
            "The first step we consider had had a genius network to model social media data.",
            "So this is 1 example is a diagram of a.",
            "Network for Twitter.",
            "So in this heterogeneous network, each node can be.",
            "Different types such as term tweet, location, user, hashtag and link, and the relations between nodes can be different types such as tone, tone, coconas is important as you know, topic modeling is so so powerful.",
            "Actually Co occurrence is one of the major factors of topic modeling and location location we consider.",
            "Geographic neighbors"
        ],
        [
            "And similarly for other nodes you can have different race relations.",
            "So this is 1 example.",
            "So we can see.",
            "Different node types such as text.",
            "And this one is a location.",
            "This is a keyword.",
            "This is #link."
        ],
        [
            "And in saying for each node we consider a set of features which we predefined because we believe they are potentially useful and we assume it is possible some features may be noise.",
            "So I'm going to discuss numbers later on.",
            "OK."
        ],
        [
            "And then the question we're going to answer 2 research questions.",
            "So given our higher genius network that is composed of nodes, attributes, relations that could be different types, then we are trying to answer the first question.",
            "How we can define an appropriate scan statistic function for a given connected sub graph will always call window and then second question how we can design efficient algorithms to maximize the scan statistic function.",
            "Over all windows.",
            "All potentially connected subgraphs."
        ],
        [
            "For the first question.",
            "First, we propose a two stage empirical calibration process to calibrate an empirical P value single for each node.",
            "2nd, we present a number of metrics.",
            "Can static function forgiven connected sub graph based on only node level single empirical P value obtained by the first step?",
            "And then for the second research question, then we propose a Fusion algorithm.",
            "For the sub graph search."
        ],
        [
            "So now you ask how we can calculate a single empirical P value for us for each node.",
            "So so here we have two stages, so the first stage for each attribute in each node we compare the current value with historical records, which we believe they are not related to event.",
            "So, for example, suppose the current day.",
            "Here the number of tweets posted by user relevant tool handle various.",
            "We compare with the number of tweets in historical days by the user.",
            "When there's no event occurring and the percentage of historical days who's number of tweets posted an equal to or greater than the current value is considered as a empirical P value.",
            "So the low P value which means.",
            "So less likely.",
            "The distribution when there's no event can generate the number of tweets as extreme as the current value.",
            "OK."
        ],
        [
            "And after that, now each node has multiple attributes and each attribute has multiple P value as one key value.",
            "So each node we can get multiple key values.",
            "Now we need to combine multiple key values into a single P value and we cannot just take minimum take average, take medium 'cause we need to consider the problem of multiple hypothesis testing.",
            "So which means even there's no any interesting if the number of attributes is very big, we have a high chance to get just happened to get a small value.",
            "So here we have two steps.",
            "The first step we calculate the minimum P value for each node.",
            "And then we compare the minimum P value of the current of this node with the historical minimum P values of this node, which means each historic day we can calculate minimum P value.",
            "And then we check how many, how much percent of historical minimum P values are equal to or greater than the current value.",
            "And then we can calculate the single P value.",
            "So after this process they re calibrate different node types and different attributes for each node."
        ],
        [
            "So which means OK, so here is some theorem so we can prove that this calibration process can handle correlations between multiple P values.",
            "So in each node.",
            "Under the assumption multiple current observations, my multivariant observations for a single node are exchangeable within the reference that, given the null hypothesis that no events of interest occurring."
        ],
        [
            "And now each node has a empirical P value.",
            "Now we need to define the function F for a given sub graph.",
            "So this is called a non parametric scan statistics.",
            "So it looks like looks like complicated by actually the idea is very simple.",
            "So here here is the sub graph.",
            "And Alpha represents the number of nodes whose P values are greater than your confidence interval, such as .05, and they unearth is the total number of nodes in each sub graph, and here this is a.",
            "This fee is the KL divergences function which is convex.",
            "So which means if the rate here the number of the percentage of nodes with small Alpha with P values, let's say Alpha, if this percentage is same as R4 then this becomes 0.",
            "If this person is very high, which means we observe more abnormal than expected, then this distance becomes very large.",
            "So which means this core function will give large value to sub graph with more anomalous anomalous nodes.",
            "And then here after Max is redevelop range for confidence interval cause this makes it possible, we can give a high score to a sub graph if the nodes in this acquired subgraphs very small.",
            "Not just lower the Alpha."
        ],
        [
            "So after that, so here is some empirical interpretation, so this not parametric sketch the district function.",
            "This example is bugged statistic function, so we can use hypothesis testing to.",
            "Describe and end the.",
            "And then after you use hypothesis testing to describe and then the log likelihood ratio function will become this for this formula.",
            "So for example.",
            "And this is not new.",
            "This was presented 79, which was the I was born and and we compared this function with other nonparametric stats, statistical functions.",
            "So here you ask what is number metrics?",
            "So any function defined based on P values.",
            "Can be considered as non parametric sketch that scale studies functions."
        ],
        [
            "So after that, now the problem becomes we need to maximize the amount parametric scan static static function over all connected subgraphs and this is on be hard.",
            "So."
        ],
        [
            "So we proposed so basic idea is if you consider here so we have one Max which is often confidence less than Alpha Max.",
            "We exchange Max.",
            "Here to here, consider only distinct values that they are for Max and then."
        ],
        [
            "Focus on this sub graph search.",
            "And it's a base."
        ],
        [
            "Idea is as follows.",
            "We consider many signals as a potential subgraphs Center for each city node, we concede."
        ],
        [
            "We try to find the subset of neighbors in combination with courage set such that the function F can be maximized is a greedy algorithm and we have a property we call linear time property, which means for this subproblem, which means if we only consider sub graph of subset of neighbors then we can solve the problem in linear time."
        ],
        [
            "And we showed that."
        ],
        [
            "So the basis based idea we expand to find some neighbors to update the sub graph and then we expand to add more neighbors until the function converge.",
            "So this is a greedy algorithm."
        ],
        [
            "But"
        ],
        [
            "So we can show."
        ],
        [
            "So for us The thing is, it is guaranteed to find the globally optimal solution if the data contained no break time entities.",
            "So what is break time?",
            "Which means the true sub graph cannot be disconnected.",
            "By nodes who's are who's P values are greater than Alpha.",
            "So this is called a break time knows.",
            "If this is if this satisfies, then we guaranteed to find the global optimal solution, and this is equivalent to percolation based graph scale statistics and certain simplifying assumptions.",
            "So why we need to make the connection becauses are beautiful theoretical properties of population based scan statistics.",
            "So I mean, for our solution we cannot prove theoretical properties very solid, so we just make make connection to traditional.",
            "Sorry this case this function, so we say we share features.",
            "Yes."
        ],
        [
            "OK, so this is basic idea, so we define with two stage empirical calibration to define AP value for each node and then we define function F based on sub graph or P values and then we maximize the function based on overall connected subgraphs."
        ],
        [
            "And we consider Twitter data.",
            "So we consider 2 examples.",
            "So first is called 100 virus outbreak.",
            "We observe the actually.",
            "The second one is called civil unrest events.",
            "So we define performance matrix as follows.",
            "So have a notch in the same stage one to seven days before event is called forecasting after the event date is called up detection."
        ],
        [
            "OK, and we use Twitter data so each event number tells what is the title about the outbreak location and then what is description.",
            "We offer some King outbreaks."
        ],
        [
            "And then this is a two data set for civil unrest.",
            "So we have a 918 we collected from public news websites.",
            "About which means if a news article reports there's a protest in some city in which dates and we can see as label the earliest report."
        ],
        [
            "And then we compare on.",
            "But you can read our paper.",
            "The basic idea is we compare with the spatial temporal burst detection graph partition earthquake.",
            "Real World event detection topic modeling and we show we have a pretty good improvement is 10 percent 20%."
        ],
        [
            "OK, and so here we also compare.",
            "How about we compare Hydrogenics graph with homogeneous graph.",
            "So we compare with only user stage tweet keyword based homogeneous graph and we show in this example the signal is better if we consider genius."
        ],
        [
            "OK, so this is our conclusion so we present non parametric scans.",
            "That is the approach to event detection forecasting in heterogeneous social media graph.",
            "So we do not assume any distribution and we believe that nonparametric methods are better suited to social media then parametric methods and we have good experiments to demonstrate the effectiveness of an efficiency of our approach.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is function.",
                    "label": 0
                },
                {
                    "sent": "I'm going to present non parametric scan statistics for event detection and forecasting in heterogeneous social media graphs.",
                    "label": 1
                },
                {
                    "sent": "So this is joint collaboration with Doctor Daniel Neal.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before I introduce our work, you may ask the question WHI can we detect and forecast events from social media?",
                    "label": 1
                },
                {
                    "sent": "So here we define an event as a larger population behavior.",
                    "label": 1
                },
                {
                    "sent": "Social media can be considered as a real time sensor of large population behavior.",
                    "label": 0
                },
                {
                    "sent": "Therefore, it is possible for us to monitor social media to track large population human behavior.",
                    "label": 1
                },
                {
                    "sent": "To detect an forecast.",
                    "label": 0
                },
                {
                    "sent": "Events if we sense public discussions about ongoing events.",
                    "label": 0
                },
                {
                    "sent": "Then we can possibly detect events if we can sense public discussions about trigger events, then we can potentially forecast events.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let us go.",
                    "label": 0
                },
                {
                    "sent": "Let us consider very concrete example of a real disease hantavirus outbreak detection in Treaty last year.",
                    "label": 0
                },
                {
                    "sent": "So these are.",
                    "label": 0
                },
                {
                    "sent": "True Raw tweet Twitter texts.",
                    "label": 0
                },
                {
                    "sent": "About hantavirus the first tweet is about people dying from heart virus in the city, also known by the local government.",
                    "label": 1
                },
                {
                    "sent": "Do not report.",
                    "label": 0
                },
                {
                    "sent": "And as a Utah Twitter user back for help.",
                    "label": 0
                },
                {
                    "sent": "The second one is the retweet of a confirmed infection of Honduras.",
                    "label": 1
                },
                {
                    "sent": "From channel which we do not know.",
                    "label": 1
                },
                {
                    "sent": "The third one is a confirmed infection.",
                    "label": 0
                },
                {
                    "sent": "Actually is the death of our one young man by hand virus.",
                    "label": 0
                },
                {
                    "sent": "That the user read from public blog as shown here.",
                    "label": 0
                },
                {
                    "sent": "So last one is a retweet by influential user named as radio polynomial about a confirmed case of 100 various.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the challenge is for detection of events.",
                    "label": 0
                },
                {
                    "sent": "In Twitter data and social media, data can be interpreted as the old story of big elephants and the blind man.",
                    "label": 1
                },
                {
                    "sent": "Social media data can be considered as a big elephant.",
                    "label": 0
                },
                {
                    "sent": "And we, the human can be considered as a blind man.",
                    "label": 0
                },
                {
                    "sent": "So if there is.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "100 various disease outbreak what we observed are many small pieces potentially relevant information that are connected.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Through heterogeneous relations.",
                    "label": 0
                },
                {
                    "sent": "Now the training tree is how we can identify the sub graph of a.",
                    "label": 0
                },
                {
                    "sent": "Potentially relevant signals and make use of the sub graph to detect and forecast hantavirus outbreak.",
                    "label": 0
                },
                {
                    "sent": "You may think about how do we consider multi variant classification and regression.",
                    "label": 0
                },
                {
                    "sent": "But here what we considered is a graph of nodes that can be different types and each node type may have different attributes, so it's not a very straightforward way that you can fit in traditional machine learning techniques.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our solution, including includes three steps.",
                    "label": 0
                },
                {
                    "sent": "The first step we consider had had a genius network to model social media data.",
                    "label": 0
                },
                {
                    "sent": "So this is 1 example is a diagram of a.",
                    "label": 0
                },
                {
                    "sent": "Network for Twitter.",
                    "label": 0
                },
                {
                    "sent": "So in this heterogeneous network, each node can be.",
                    "label": 0
                },
                {
                    "sent": "Different types such as term tweet, location, user, hashtag and link, and the relations between nodes can be different types such as tone, tone, coconas is important as you know, topic modeling is so so powerful.",
                    "label": 0
                },
                {
                    "sent": "Actually Co occurrence is one of the major factors of topic modeling and location location we consider.",
                    "label": 0
                },
                {
                    "sent": "Geographic neighbors",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And similarly for other nodes you can have different race relations.",
                    "label": 0
                },
                {
                    "sent": "So this is 1 example.",
                    "label": 0
                },
                {
                    "sent": "So we can see.",
                    "label": 0
                },
                {
                    "sent": "Different node types such as text.",
                    "label": 0
                },
                {
                    "sent": "And this one is a location.",
                    "label": 0
                },
                {
                    "sent": "This is a keyword.",
                    "label": 0
                },
                {
                    "sent": "This is #link.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in saying for each node we consider a set of features which we predefined because we believe they are potentially useful and we assume it is possible some features may be noise.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to discuss numbers later on.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then the question we're going to answer 2 research questions.",
                    "label": 0
                },
                {
                    "sent": "So given our higher genius network that is composed of nodes, attributes, relations that could be different types, then we are trying to answer the first question.",
                    "label": 1
                },
                {
                    "sent": "How we can define an appropriate scan statistic function for a given connected sub graph will always call window and then second question how we can design efficient algorithms to maximize the scan statistic function.",
                    "label": 0
                },
                {
                    "sent": "Over all windows.",
                    "label": 0
                },
                {
                    "sent": "All potentially connected subgraphs.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the first question.",
                    "label": 0
                },
                {
                    "sent": "First, we propose a two stage empirical calibration process to calibrate an empirical P value single for each node.",
                    "label": 1
                },
                {
                    "sent": "2nd, we present a number of metrics.",
                    "label": 0
                },
                {
                    "sent": "Can static function forgiven connected sub graph based on only node level single empirical P value obtained by the first step?",
                    "label": 0
                },
                {
                    "sent": "And then for the second research question, then we propose a Fusion algorithm.",
                    "label": 0
                },
                {
                    "sent": "For the sub graph search.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now you ask how we can calculate a single empirical P value for us for each node.",
                    "label": 0
                },
                {
                    "sent": "So so here we have two stages, so the first stage for each attribute in each node we compare the current value with historical records, which we believe they are not related to event.",
                    "label": 0
                },
                {
                    "sent": "So, for example, suppose the current day.",
                    "label": 0
                },
                {
                    "sent": "Here the number of tweets posted by user relevant tool handle various.",
                    "label": 0
                },
                {
                    "sent": "We compare with the number of tweets in historical days by the user.",
                    "label": 0
                },
                {
                    "sent": "When there's no event occurring and the percentage of historical days who's number of tweets posted an equal to or greater than the current value is considered as a empirical P value.",
                    "label": 0
                },
                {
                    "sent": "So the low P value which means.",
                    "label": 0
                },
                {
                    "sent": "So less likely.",
                    "label": 0
                },
                {
                    "sent": "The distribution when there's no event can generate the number of tweets as extreme as the current value.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And after that, now each node has multiple attributes and each attribute has multiple P value as one key value.",
                    "label": 1
                },
                {
                    "sent": "So each node we can get multiple key values.",
                    "label": 1
                },
                {
                    "sent": "Now we need to combine multiple key values into a single P value and we cannot just take minimum take average, take medium 'cause we need to consider the problem of multiple hypothesis testing.",
                    "label": 0
                },
                {
                    "sent": "So which means even there's no any interesting if the number of attributes is very big, we have a high chance to get just happened to get a small value.",
                    "label": 0
                },
                {
                    "sent": "So here we have two steps.",
                    "label": 0
                },
                {
                    "sent": "The first step we calculate the minimum P value for each node.",
                    "label": 0
                },
                {
                    "sent": "And then we compare the minimum P value of the current of this node with the historical minimum P values of this node, which means each historic day we can calculate minimum P value.",
                    "label": 0
                },
                {
                    "sent": "And then we check how many, how much percent of historical minimum P values are equal to or greater than the current value.",
                    "label": 1
                },
                {
                    "sent": "And then we can calculate the single P value.",
                    "label": 0
                },
                {
                    "sent": "So after this process they re calibrate different node types and different attributes for each node.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So which means OK, so here is some theorem so we can prove that this calibration process can handle correlations between multiple P values.",
                    "label": 0
                },
                {
                    "sent": "So in each node.",
                    "label": 0
                },
                {
                    "sent": "Under the assumption multiple current observations, my multivariant observations for a single node are exchangeable within the reference that, given the null hypothesis that no events of interest occurring.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now each node has a empirical P value.",
                    "label": 0
                },
                {
                    "sent": "Now we need to define the function F for a given sub graph.",
                    "label": 0
                },
                {
                    "sent": "So this is called a non parametric scan statistics.",
                    "label": 0
                },
                {
                    "sent": "So it looks like looks like complicated by actually the idea is very simple.",
                    "label": 0
                },
                {
                    "sent": "So here here is the sub graph.",
                    "label": 0
                },
                {
                    "sent": "And Alpha represents the number of nodes whose P values are greater than your confidence interval, such as .05, and they unearth is the total number of nodes in each sub graph, and here this is a.",
                    "label": 1
                },
                {
                    "sent": "This fee is the KL divergences function which is convex.",
                    "label": 0
                },
                {
                    "sent": "So which means if the rate here the number of the percentage of nodes with small Alpha with P values, let's say Alpha, if this percentage is same as R4 then this becomes 0.",
                    "label": 0
                },
                {
                    "sent": "If this person is very high, which means we observe more abnormal than expected, then this distance becomes very large.",
                    "label": 0
                },
                {
                    "sent": "So which means this core function will give large value to sub graph with more anomalous anomalous nodes.",
                    "label": 0
                },
                {
                    "sent": "And then here after Max is redevelop range for confidence interval cause this makes it possible, we can give a high score to a sub graph if the nodes in this acquired subgraphs very small.",
                    "label": 0
                },
                {
                    "sent": "Not just lower the Alpha.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So after that, so here is some empirical interpretation, so this not parametric sketch the district function.",
                    "label": 0
                },
                {
                    "sent": "This example is bugged statistic function, so we can use hypothesis testing to.",
                    "label": 0
                },
                {
                    "sent": "Describe and end the.",
                    "label": 0
                },
                {
                    "sent": "And then after you use hypothesis testing to describe and then the log likelihood ratio function will become this for this formula.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "And this is not new.",
                    "label": 0
                },
                {
                    "sent": "This was presented 79, which was the I was born and and we compared this function with other nonparametric stats, statistical functions.",
                    "label": 0
                },
                {
                    "sent": "So here you ask what is number metrics?",
                    "label": 0
                },
                {
                    "sent": "So any function defined based on P values.",
                    "label": 0
                },
                {
                    "sent": "Can be considered as non parametric sketch that scale studies functions.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So after that, now the problem becomes we need to maximize the amount parametric scan static static function over all connected subgraphs and this is on be hard.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we proposed so basic idea is if you consider here so we have one Max which is often confidence less than Alpha Max.",
                    "label": 0
                },
                {
                    "sent": "We exchange Max.",
                    "label": 0
                },
                {
                    "sent": "Here to here, consider only distinct values that they are for Max and then.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Focus on this sub graph search.",
                    "label": 0
                },
                {
                    "sent": "And it's a base.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Idea is as follows.",
                    "label": 0
                },
                {
                    "sent": "We consider many signals as a potential subgraphs Center for each city node, we concede.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We try to find the subset of neighbors in combination with courage set such that the function F can be maximized is a greedy algorithm and we have a property we call linear time property, which means for this subproblem, which means if we only consider sub graph of subset of neighbors then we can solve the problem in linear time.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we showed that.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the basis based idea we expand to find some neighbors to update the sub graph and then we expand to add more neighbors until the function converge.",
                    "label": 0
                },
                {
                    "sent": "So this is a greedy algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can show.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for us The thing is, it is guaranteed to find the globally optimal solution if the data contained no break time entities.",
                    "label": 1
                },
                {
                    "sent": "So what is break time?",
                    "label": 0
                },
                {
                    "sent": "Which means the true sub graph cannot be disconnected.",
                    "label": 0
                },
                {
                    "sent": "By nodes who's are who's P values are greater than Alpha.",
                    "label": 0
                },
                {
                    "sent": "So this is called a break time knows.",
                    "label": 1
                },
                {
                    "sent": "If this is if this satisfies, then we guaranteed to find the global optimal solution, and this is equivalent to percolation based graph scale statistics and certain simplifying assumptions.",
                    "label": 0
                },
                {
                    "sent": "So why we need to make the connection becauses are beautiful theoretical properties of population based scan statistics.",
                    "label": 0
                },
                {
                    "sent": "So I mean, for our solution we cannot prove theoretical properties very solid, so we just make make connection to traditional.",
                    "label": 0
                },
                {
                    "sent": "Sorry this case this function, so we say we share features.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is basic idea, so we define with two stage empirical calibration to define AP value for each node and then we define function F based on sub graph or P values and then we maximize the function based on overall connected subgraphs.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we consider Twitter data.",
                    "label": 1
                },
                {
                    "sent": "So we consider 2 examples.",
                    "label": 0
                },
                {
                    "sent": "So first is called 100 virus outbreak.",
                    "label": 0
                },
                {
                    "sent": "We observe the actually.",
                    "label": 0
                },
                {
                    "sent": "The second one is called civil unrest events.",
                    "label": 1
                },
                {
                    "sent": "So we define performance matrix as follows.",
                    "label": 0
                },
                {
                    "sent": "So have a notch in the same stage one to seven days before event is called forecasting after the event date is called up detection.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and we use Twitter data so each event number tells what is the title about the outbreak location and then what is description.",
                    "label": 0
                },
                {
                    "sent": "We offer some King outbreaks.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then this is a two data set for civil unrest.",
                    "label": 1
                },
                {
                    "sent": "So we have a 918 we collected from public news websites.",
                    "label": 0
                },
                {
                    "sent": "About which means if a news article reports there's a protest in some city in which dates and we can see as label the earliest report.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we compare on.",
                    "label": 0
                },
                {
                    "sent": "But you can read our paper.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is we compare with the spatial temporal burst detection graph partition earthquake.",
                    "label": 0
                },
                {
                    "sent": "Real World event detection topic modeling and we show we have a pretty good improvement is 10 percent 20%.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and so here we also compare.",
                    "label": 0
                },
                {
                    "sent": "How about we compare Hydrogenics graph with homogeneous graph.",
                    "label": 0
                },
                {
                    "sent": "So we compare with only user stage tweet keyword based homogeneous graph and we show in this example the signal is better if we consider genius.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is our conclusion so we present non parametric scans.",
                    "label": 0
                },
                {
                    "sent": "That is the approach to event detection forecasting in heterogeneous social media graph.",
                    "label": 1
                },
                {
                    "sent": "So we do not assume any distribution and we believe that nonparametric methods are better suited to social media then parametric methods and we have good experiments to demonstrate the effectiveness of an efficiency of our approach.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}