{
    "id": "qn2oadfyexntmneducrg5e7njfkunfke",
    "title": "Over-complete representations on recurrent neural networks can support persistent percepts",
    "info": {
        "author": [
            "Shaul Druckmann, Howard Hughes Medical Institute"
        ],
        "published": "Jan. 12, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Neural Networks"
        ]
    },
    "url": "http://videolectures.net/nips2010_druckmann_ocr/",
    "segmentation": [
        [
            "Good morning everyone.",
            "The slightly abbreviated title of My Talk is Neural Networks supporting persistent percepts.",
            "My name is Joel Druckman.",
            "I'm a postdoc of meteors.",
            "Close keys in the generic form research campus, and the."
        ],
        [
            "The phenomenon I want to talk to you about is working memory and the classical example is a delayed match to sample task.",
            "So we have an animal."
        ],
        [
            "Say that a screen it's fixating at the center.",
            "We're going to show it a brief image.",
            "It's going to come up any moment, and then there's a delay.",
            "Between several seconds in several 10s of seconds, and we're going to show the second image and the animal needs to say whether it's the same or different.",
            "So the first image was an image of filet II images here of Vancouver.",
            "So if the animal is smart, it will know that these are two different images and will give a negative response if the animal is really smart, he'll know that both of them are in the West coast of North America, which would make it a smarter than me.",
            "And be less surprised of how long a flight it was to get here.",
            "So."
        ],
        [
            "There are traditional explanation of how this actually happens in the brain.",
            "Is that this constant percept maintained during the delay.",
            "Is maintained by constant activity."
        ],
        [
            "So if I look at neuronal activity, the X axis is time, the Y axis is firing rate."
        ],
        [
            "And I look at these at this time between the first image presentation and the second image presentation.",
            "Then if we look at."
        ],
        [
            "Iran that's tuned for the stimulus it's firing rate is going to go up once it sees the first image is going to stay elevated and constant until it sees the second image.",
            "And that's how this persistent first ever concert percept is maintain."
        ],
        [
            "And indeed, in the early experiments, people were very excited that you can actually find these types of neurons whose firing rate remains elevated for many, many 10s of seconds.",
            "But the story is a little bit."
        ],
        [
            "More complicated, more recently when people didn't work careful experiments and looked at."
        ],
        [
            "Many neurons during this delay.",
            "Then they found that actually this sort of time invariant this constant activity is very rare, so some neurons this again lots of firing rate like in the bottom right start up high and then fall down some other neurons like in the bottom left startup low and then go up and you have many many different kinds of combinations."
        ],
        [
            "This simple model, in which there is a neuron that's tuned for the stimulus, who's firing rate remains constant, and that's how this constant persip is maintained.",
            "Doesn't seem to be applicable."
        ],
        [
            "And the question we wanted to ask is, can time variant neuronal activity as we now know there is support time invariant percepts as there must be for working memory and the traditional answer at first at face value is no and why is that the case?"
        ],
        [
            "So let's think of a similar simple linear encoding scheme in an orthogonal basis."
        ],
        [
            "So I'm going to look at one small Patch of the image I showed you.",
            "I'm going to call it the stimulus."
        ],
        [
            "South by the usual method of looking at pixel by pixel grayscale value and then for each one of the neurons in the network, I'm going to turn the receptive field or feature vector into again a column vector in the same way.",
            "Concatenate all these vectors into the matrix D and then multiply the representation D by the neural activity A and get the simple linear encoding scheme South equals D. The feature vector matrix times A and now what I?"
        ],
        [
            "Want to have as I want the DS over DT the derivative of the stimulus was presented with time will be 0 in order for the Percepta be constant and what the."
        ],
        [
            "Supplies again in linear according an orthogonal basis.",
            "Is that the?"
        ],
        [
            "Derivative of activity with respect to time must be 0 and we know this isn't the case, so we before we abandon linear."
        ],
        [
            "Coding and trying to think of something more complicated."
        ],
        [
            "Let's think about the issue of orthogonal basis, so why?"
        ],
        [
            "Why would we not think of orthogonal basis?",
            "And this is a simple effect from anatomy.",
            "So Cortex essentially a lot of what it represents is what is already in the thalamus, but the number of neurons in the cortex is far greater than the number of neurons in thalamus that can range from 10 times as many to 1550 times as many in certain primates and human, so it's very likely that a cortex uses an orthogonal and more to be more exact overcomplete representation.",
            "So how would?"
        ],
        [
            "This change if I had an overcomplete representation, so first of all there."
        ],
        [
            "Now a lot more neurons, so more neurons here and D. The matrix of feature vectors or receptive fields is now not square, but fat and wide, and will this change this issue of persistent percepts with time invariant activity?",
            "So in order to?"
        ],
        [
            "Explain why that will change.",
            "I want to switch to a slightly simpler exam."
        ],
        [
            "So, so consider only representing points on a plane, stimulus dimension being equal to two, and that's it presented with this frame of three neurons, each neuron A1 representing the up direction A2 and A3 down into the right and down into the left.",
            "This is sometimes called the Merced this Benz frame, so it might be more politically called the peace sign frame.",
            "I don't know why this was chosen and what I'm sure many of you knows."
        ],
        [
            "And overcomplete representations.",
            "If I want to represent this point here, which is directly up on the Y axis I have."
        ],
        [
            "New ways to do this?",
            "I can take one times neuron one.",
            "This will represent it just fine.",
            "Or I could take half times neuron, 1 minus half time neuron two and minus half times neuron 3, and add these up as vectors should be added and I'm going to represent exactly the same point.",
            "So in overcomplete representations"
        ],
        [
            "To make the picture more complete, if you look at the left, then certain changes in your own activity are going to change the point that's being represented on the plane.",
            "That's this little blue dot moving around, but other changes in neuronal activity, like the ones on the right are going to cancel each other out and there's going to be no change at all in the stimulus represented by the network."
        ],
        [
            "So how does this help us?",
            "Well, this freedom, this degree of freedom here represented in activity space as the red line, can be exploited by the network.",
            "So anywhere the network inactivity space goes on the red line representation is going to be exactly the same.",
            "And if we now look experimentally."
        ],
        [
            "It's one year on like we did before.",
            "As the network goes up."
        ],
        [
            "Down this degree of freedom, then the firing rate is going to go down and then go up but all the time, the network itself as a whole is maintaining exactly the same repres."
        ],
        [
            "Station, and this is just one example of what you can find.",
            "And of course we can construct the other ones just as well."
        ],
        [
            "So in an overcomplete representation time variant, neuronal activity can represent a time invariant percept."
        ],
        [
            "Just to go over the formalism."
        ],
        [
            "So we have linear encoding S, the stimulus vector D concatenated matrix of feature vectors are receptive field and anger on elective."
        ],
        [
            "T. And we assume standard rate dynamics.",
            "So a derivative of a with respect to time equals minus a decay term plus L. The lateral connectivity matrix times a activity of the neurons, and if we."
        ],
        [
            "We now want to have the derivative with respect to time, which is just D times to a dot to be 0.",
            "To get persistent percepts, we plug this in from the right dynamic."
        ],
        [
            "Simplify and we get DA equals DLA and if this is to hold for every pattern of neuronal activity a as it should be.",
            "Since there are no reason to have preferred pattern."
        ],
        [
            "Then we simplify to D = D. L&D equals DL in an overcomplete representation.",
            "Isn't just one solution, it's an entire family of solutions, one of the."
        ],
        [
            "Is the trivial solution.",
            "Eliquis I, which is not interesting to us because it's not a network model, it's just a network that has no lateral connections but only self synapses or autopc is, which is what we know, not realistic for cortex that has many net natural collections and few autopsies."
        ],
        [
            "So out of this family of solutions, we want to pick."
        ],
        [
            "Tific solutions."
        ],
        [
            "And the solutions we think makes sense are sparse solutions."
        ],
        [
            "So the entries in L remember represent actual physical synaptic connections."
        ],
        [
            "Which have an actual physical cost, both in terms of volume they take up in our head and in terms of metabolic costs.",
            "So we want to minimize these costs and."
        ],
        [
            "We can do this in a standard format where we want to minimize.",
            "At one hand the reconstruction error.",
            "How accurately is D equals to DL, and on the other hand a sparsity term, and we trade off these two things with the parameter Lambda and this can be solved with many standard L2L1 packages like spam, zorki, SVD."
        ],
        [
            "So again, just to give a little bit more intuition, but what D = D L means.",
            "So if we calculate the network that we get L in the simple example of them are set."
        ],
        [
            "Ben's frame we get this little network where all neurons are connected to each other with negative synapses of weight.",
            "One and."
        ],
        [
            "What you may notice and I'll show you that, is that the sum of the outgoing synapses times the postsynaptic receptor fields is equal to the neurons own receptive field.",
            "And what do I mean by that so?"
        ],
        [
            "We look at neuron one.",
            "This is its receptive field or its feature vector.",
            "The up direction in the Y axis.",
            "If we go through it, sign up says it has minus 1 * 8 Two that's this."
        ],
        [
            "Action in space and its other signups is minus 1 * A three.",
            "That's that direction in space.",
            "And if I now add them as vectors should be added, I get back A1 automatically.",
            "So every time that the activity in a one and you're on one changes their presentation, its contribution to the network changes, but this is automatically canceled out by it driving neurons two and three in a way that compensates for its own change in representation.",
            "So this is a very nice intuition.",
            "Ford equals DL."
        ],
        [
            "Which we call receptive field recombination to have a nice acronym, REFIRE and it is what guarantees persistent percepts?",
            "It is what guarantees that the network remains on the degree of freedom that it has to remain to get persistent persons."
        ],
        [
            "So let's look at a slightly more interesting example with not the Mercedes-Benz."
        ],
        [
            "We want to look at V1 receptive fields.",
            "We learn receptive fields from natural images, just as all sales and field does that."
        ],
        [
            "So we get the matrix D and now we want to learn the lateral connectivity, the matrix L."
        ],
        [
            "And So what we do, again, we want the sum of the synapse.",
            "We want the receptive field to be equal to the sum of postsynaptic receptor fields."
        ],
        [
            "Times the natural connections.",
            "So this is the receptive field in bottom left and you want it to be equal to."
        ],
        [
            "Some of some sparse combination of the postsynaptic receptor fields times the lateral connections, and again we solve this with standard sparse solving software, and that's how we get the."
        ],
        [
            "Network model, so we have for each one of the neurons it's receptive field.",
            "We have all of the connections we can try looking for structures inside this thing, But this is a little bit too."
        ],
        [
            "Top high of you, so let's look into."
        ],
        [
            "Some more detailed aspects.",
            "So first numerical validation.",
            "We want to see that percepts are indeed persistent, so we simulate the right dynamics.",
            "X axis is time or accesses activity.",
            "And I plot here the activity for subset of neurons.",
            "As you can see activity is going crazy all over the place just like it did in the example of real data.",
            "And I have the Patch is represented by the network above.",
            "So the Patch with a black frame around it is the one at time zero and the other patches or.",
            "With time as time goes by and you can see that they are perfectly identical.",
            "So the numerical validation does show that percepts are persistent.",
            "A slightly."
        ],
        [
            "Different way to look at it is that if I plot for each neuron above and read its activity as a trace, and if I plot under that where the white squares are now, I plot the its contribution to the Patch represented by the network I'm going to do this for all six networks and then at the very bottom I'm going to plot the representation.",
            "The Patch represented by the network as a whole, and I run the right dynamics.",
            "So each one of the activities of each one of the neurons is going to change, some go up, some go down.",
            "And accordingly, what is represented by each one of these neurons changes, so each neuron individually isn't keeping a persistent percept.",
            "But due to this D equals DL, this receptive field recombination rule, then lateral connectivity enforces that the network as a whole has a persistent percept, and you can see that in the bottom that both the little patches at the very bottom and then and also the color map that remains perfectly stable with time.",
            "So, aside from maintaining the."
        ],
        [
            "Persistent percepts we have a specific specific form for the network.",
            "We can actually compute, and we want to see whether this network seems realistic so we can check various statistical."
        ],
        [
            "Properties, for instance, we can look at the distribution of weights amongst different neurons.",
            "If you do this experimentally with paired recordings, you get sort of this heavy tail distrib."
        ],
        [
            "And if we do this in our model, we get a very similar type of distribution.",
            "We can look at more."
        ],
        [
            "Detailed aspects."
        ],
        [
            "Network motifs, so if you look at two neuron motif store."
        ],
        [
            "3 two known motifs you run a is connected to neuron B. Neuron B is connected to neuron A and the reciprocal connection between A&B."
        ],
        [
            "And what we find both in real cortical networks and our networks is that reciprocal connections are far more common than random.",
            "About four to five times more common."
        ],
        [
            "We can also do this for three neuron motifs.",
            "There are 16 of these and just to give you the broad sense."
        ],
        [
            "There are missing connections like the one on the bottom, which you have only one connection between the neurons and there are full motives that there are connections between all neurons."
        ],
        [
            "And again, both in cortex and then refire networks.",
            "We find a large overexpression of reciprocal motifs.",
            "So to sum this up, if you're on a is connected to neuron B and you're on B is connected to an see, it's far more likely that you're on a will also be connected to neurons.",
            "See then you would expect by an average randomly Corentin average controlled network.",
            "So just to sum up."
        ],
        [
            "The question we sought out to ask is can time variant neuronal activity, which is what we know exists in the brain represent time invariant percepts, which is what we know the brain has to do in order to have working memory."
        ],
        [
            "The answer is yes, but not in orthogonal basis.",
            "But again, it's very reasonable to think in a basis that's not orthogonal in an overcomplete frame because of the Thelma cortical divergance."
        ],
        [
            "We propose a very specific form of a network that actually supports time invariant percepts, with the rule of refire network that the lateral connectivity ensures that the persistence of the percepts we call these refire networks, and we can calculate them from data, and we find that once we do calculate them the network."
        ],
        [
            "Qualitatively match known statistical properties of cortical networks, both of the two I've showed you and also a number of properties, more they didn't have time to go over."
        ],
        [
            "So with that, I'd like to conclude to."
        ],
        [
            "Comedians Club ski my post documents."
        ],
        [
            "Other members of the club Ski Lab and Frank for helping us with drawing up the figure of the network structure and of course, thank you for your attention and for having to give this talk.",
            "Yeah, so my question is why does the brain use such a complicated way to represent persistent percepts?",
            "So can you speculate a bit about the computational function of this?",
            "Yeah, so actually I can speculate a lot about its computational function.",
            "I don't like to hand wave and I didn't have time to show you to show you many of the things that one can do with this, But if you allow me to speak a little bit more freely than what this allows you is to disentangle the fact that you need to represent something.",
            "With how you need to represent it.",
            "So if you have an orthogonal basis, there's only one fixed way in which the network can represent this given stimulus.",
            "In these networks you can completely change the profile of activity and still represent the same thing.",
            "So for instance, you can have the activity sparse or non sparse to trade off robustness against non robustness and there are a number of other computations that we can show that can be done by this, but I didn't want.",
            "I didn't have time to really get into them in detail, but I have my poster if you want to.",
            "I'll be glad to try and answer so your model is a linear one and how old your conclusions change if you include the nonlinearities that we know neurons have.",
            "OK, so I sort of expected that question to be asked, and so we've we've extended this now for.",
            "No.",
            "We've extended, sorry, we've extended this now to spiking neural networks and just to give you the one minute answer.",
            "So if I show you.",
            "If I show you a very similar plot to what we showed before with the activity of the neurons again being red traces, and the representation being in the white spaces, then we again the representation of each neuron changes a lot as it spikes, but the representation of the network as a whole remain constant, and in fact there's a paradox that I think is sort of has been a little bit overlooked in neuroscience that in order for a neuron to communicate, it needs to spike, but if it needs to spike, it resets and it loses its information and this is fine and good if there's a constant stimulus, that's it.",
            "Integrating, but if there is no constant stimulus, that's a problem.",
            "But this refire rule allows sort of as a high dimensional integrator to keep integrating even though the stimulus has died out.",
            "So this works for spiking nonlinearities, and there are some very interesting properties that we're still working through, but it does work, and we can have very different some computations."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "The slightly abbreviated title of My Talk is Neural Networks supporting persistent percepts.",
                    "label": 1
                },
                {
                    "sent": "My name is Joel Druckman.",
                    "label": 0
                },
                {
                    "sent": "I'm a postdoc of meteors.",
                    "label": 0
                },
                {
                    "sent": "Close keys in the generic form research campus, and the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The phenomenon I want to talk to you about is working memory and the classical example is a delayed match to sample task.",
                    "label": 0
                },
                {
                    "sent": "So we have an animal.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Say that a screen it's fixating at the center.",
                    "label": 0
                },
                {
                    "sent": "We're going to show it a brief image.",
                    "label": 0
                },
                {
                    "sent": "It's going to come up any moment, and then there's a delay.",
                    "label": 0
                },
                {
                    "sent": "Between several seconds in several 10s of seconds, and we're going to show the second image and the animal needs to say whether it's the same or different.",
                    "label": 0
                },
                {
                    "sent": "So the first image was an image of filet II images here of Vancouver.",
                    "label": 0
                },
                {
                    "sent": "So if the animal is smart, it will know that these are two different images and will give a negative response if the animal is really smart, he'll know that both of them are in the West coast of North America, which would make it a smarter than me.",
                    "label": 0
                },
                {
                    "sent": "And be less surprised of how long a flight it was to get here.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are traditional explanation of how this actually happens in the brain.",
                    "label": 0
                },
                {
                    "sent": "Is that this constant percept maintained during the delay.",
                    "label": 0
                },
                {
                    "sent": "Is maintained by constant activity.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if I look at neuronal activity, the X axis is time, the Y axis is firing rate.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I look at these at this time between the first image presentation and the second image presentation.",
                    "label": 0
                },
                {
                    "sent": "Then if we look at.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Iran that's tuned for the stimulus it's firing rate is going to go up once it sees the first image is going to stay elevated and constant until it sees the second image.",
                    "label": 0
                },
                {
                    "sent": "And that's how this persistent first ever concert percept is maintain.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And indeed, in the early experiments, people were very excited that you can actually find these types of neurons whose firing rate remains elevated for many, many 10s of seconds.",
                    "label": 0
                },
                {
                    "sent": "But the story is a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More complicated, more recently when people didn't work careful experiments and looked at.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many neurons during this delay.",
                    "label": 0
                },
                {
                    "sent": "Then they found that actually this sort of time invariant this constant activity is very rare, so some neurons this again lots of firing rate like in the bottom right start up high and then fall down some other neurons like in the bottom left startup low and then go up and you have many many different kinds of combinations.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This simple model, in which there is a neuron that's tuned for the stimulus, who's firing rate remains constant, and that's how this constant persip is maintained.",
                    "label": 0
                },
                {
                    "sent": "Doesn't seem to be applicable.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the question we wanted to ask is, can time variant neuronal activity as we now know there is support time invariant percepts as there must be for working memory and the traditional answer at first at face value is no and why is that the case?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's think of a similar simple linear encoding scheme in an orthogonal basis.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to look at one small Patch of the image I showed you.",
                    "label": 0
                },
                {
                    "sent": "I'm going to call it the stimulus.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "South by the usual method of looking at pixel by pixel grayscale value and then for each one of the neurons in the network, I'm going to turn the receptive field or feature vector into again a column vector in the same way.",
                    "label": 0
                },
                {
                    "sent": "Concatenate all these vectors into the matrix D and then multiply the representation D by the neural activity A and get the simple linear encoding scheme South equals D. The feature vector matrix times A and now what I?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Want to have as I want the DS over DT the derivative of the stimulus was presented with time will be 0 in order for the Percepta be constant and what the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Supplies again in linear according an orthogonal basis.",
                    "label": 0
                },
                {
                    "sent": "Is that the?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Derivative of activity with respect to time must be 0 and we know this isn't the case, so we before we abandon linear.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Coding and trying to think of something more complicated.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's think about the issue of orthogonal basis, so why?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why would we not think of orthogonal basis?",
                    "label": 0
                },
                {
                    "sent": "And this is a simple effect from anatomy.",
                    "label": 0
                },
                {
                    "sent": "So Cortex essentially a lot of what it represents is what is already in the thalamus, but the number of neurons in the cortex is far greater than the number of neurons in thalamus that can range from 10 times as many to 1550 times as many in certain primates and human, so it's very likely that a cortex uses an orthogonal and more to be more exact overcomplete representation.",
                    "label": 1
                },
                {
                    "sent": "So how would?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This change if I had an overcomplete representation, so first of all there.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now a lot more neurons, so more neurons here and D. The matrix of feature vectors or receptive fields is now not square, but fat and wide, and will this change this issue of persistent percepts with time invariant activity?",
                    "label": 0
                },
                {
                    "sent": "So in order to?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Explain why that will change.",
                    "label": 0
                },
                {
                    "sent": "I want to switch to a slightly simpler exam.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so consider only representing points on a plane, stimulus dimension being equal to two, and that's it presented with this frame of three neurons, each neuron A1 representing the up direction A2 and A3 down into the right and down into the left.",
                    "label": 0
                },
                {
                    "sent": "This is sometimes called the Merced this Benz frame, so it might be more politically called the peace sign frame.",
                    "label": 0
                },
                {
                    "sent": "I don't know why this was chosen and what I'm sure many of you knows.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And overcomplete representations.",
                    "label": 0
                },
                {
                    "sent": "If I want to represent this point here, which is directly up on the Y axis I have.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "New ways to do this?",
                    "label": 0
                },
                {
                    "sent": "I can take one times neuron one.",
                    "label": 0
                },
                {
                    "sent": "This will represent it just fine.",
                    "label": 0
                },
                {
                    "sent": "Or I could take half times neuron, 1 minus half time neuron two and minus half times neuron 3, and add these up as vectors should be added and I'm going to represent exactly the same point.",
                    "label": 0
                },
                {
                    "sent": "So in overcomplete representations",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To make the picture more complete, if you look at the left, then certain changes in your own activity are going to change the point that's being represented on the plane.",
                    "label": 0
                },
                {
                    "sent": "That's this little blue dot moving around, but other changes in neuronal activity, like the ones on the right are going to cancel each other out and there's going to be no change at all in the stimulus represented by the network.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how does this help us?",
                    "label": 0
                },
                {
                    "sent": "Well, this freedom, this degree of freedom here represented in activity space as the red line, can be exploited by the network.",
                    "label": 0
                },
                {
                    "sent": "So anywhere the network inactivity space goes on the red line representation is going to be exactly the same.",
                    "label": 0
                },
                {
                    "sent": "And if we now look experimentally.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's one year on like we did before.",
                    "label": 0
                },
                {
                    "sent": "As the network goes up.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Down this degree of freedom, then the firing rate is going to go down and then go up but all the time, the network itself as a whole is maintaining exactly the same repres.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Station, and this is just one example of what you can find.",
                    "label": 0
                },
                {
                    "sent": "And of course we can construct the other ones just as well.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in an overcomplete representation time variant, neuronal activity can represent a time invariant percept.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to go over the formalism.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have linear encoding S, the stimulus vector D concatenated matrix of feature vectors are receptive field and anger on elective.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "T. And we assume standard rate dynamics.",
                    "label": 0
                },
                {
                    "sent": "So a derivative of a with respect to time equals minus a decay term plus L. The lateral connectivity matrix times a activity of the neurons, and if we.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We now want to have the derivative with respect to time, which is just D times to a dot to be 0.",
                    "label": 0
                },
                {
                    "sent": "To get persistent percepts, we plug this in from the right dynamic.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simplify and we get DA equals DLA and if this is to hold for every pattern of neuronal activity a as it should be.",
                    "label": 0
                },
                {
                    "sent": "Since there are no reason to have preferred pattern.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we simplify to D = D. L&D equals DL in an overcomplete representation.",
                    "label": 0
                },
                {
                    "sent": "Isn't just one solution, it's an entire family of solutions, one of the.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the trivial solution.",
                    "label": 0
                },
                {
                    "sent": "Eliquis I, which is not interesting to us because it's not a network model, it's just a network that has no lateral connections but only self synapses or autopc is, which is what we know, not realistic for cortex that has many net natural collections and few autopsies.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So out of this family of solutions, we want to pick.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tific solutions.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the solutions we think makes sense are sparse solutions.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the entries in L remember represent actual physical synaptic connections.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which have an actual physical cost, both in terms of volume they take up in our head and in terms of metabolic costs.",
                    "label": 0
                },
                {
                    "sent": "So we want to minimize these costs and.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can do this in a standard format where we want to minimize.",
                    "label": 0
                },
                {
                    "sent": "At one hand the reconstruction error.",
                    "label": 0
                },
                {
                    "sent": "How accurately is D equals to DL, and on the other hand a sparsity term, and we trade off these two things with the parameter Lambda and this can be solved with many standard L2L1 packages like spam, zorki, SVD.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, just to give a little bit more intuition, but what D = D L means.",
                    "label": 0
                },
                {
                    "sent": "So if we calculate the network that we get L in the simple example of them are set.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ben's frame we get this little network where all neurons are connected to each other with negative synapses of weight.",
                    "label": 0
                },
                {
                    "sent": "One and.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What you may notice and I'll show you that, is that the sum of the outgoing synapses times the postsynaptic receptor fields is equal to the neurons own receptive field.",
                    "label": 0
                },
                {
                    "sent": "And what do I mean by that so?",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We look at neuron one.",
                    "label": 0
                },
                {
                    "sent": "This is its receptive field or its feature vector.",
                    "label": 1
                },
                {
                    "sent": "The up direction in the Y axis.",
                    "label": 0
                },
                {
                    "sent": "If we go through it, sign up says it has minus 1 * 8 Two that's this.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Action in space and its other signups is minus 1 * A three.",
                    "label": 0
                },
                {
                    "sent": "That's that direction in space.",
                    "label": 0
                },
                {
                    "sent": "And if I now add them as vectors should be added, I get back A1 automatically.",
                    "label": 0
                },
                {
                    "sent": "So every time that the activity in a one and you're on one changes their presentation, its contribution to the network changes, but this is automatically canceled out by it driving neurons two and three in a way that compensates for its own change in representation.",
                    "label": 0
                },
                {
                    "sent": "So this is a very nice intuition.",
                    "label": 0
                },
                {
                    "sent": "Ford equals DL.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which we call receptive field recombination to have a nice acronym, REFIRE and it is what guarantees persistent percepts?",
                    "label": 0
                },
                {
                    "sent": "It is what guarantees that the network remains on the degree of freedom that it has to remain to get persistent persons.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at a slightly more interesting example with not the Mercedes-Benz.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want to look at V1 receptive fields.",
                    "label": 0
                },
                {
                    "sent": "We learn receptive fields from natural images, just as all sales and field does that.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we get the matrix D and now we want to learn the lateral connectivity, the matrix L.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And So what we do, again, we want the sum of the synapse.",
                    "label": 0
                },
                {
                    "sent": "We want the receptive field to be equal to the sum of postsynaptic receptor fields.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Times the natural connections.",
                    "label": 0
                },
                {
                    "sent": "So this is the receptive field in bottom left and you want it to be equal to.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some of some sparse combination of the postsynaptic receptor fields times the lateral connections, and again we solve this with standard sparse solving software, and that's how we get the.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Network model, so we have for each one of the neurons it's receptive field.",
                    "label": 0
                },
                {
                    "sent": "We have all of the connections we can try looking for structures inside this thing, But this is a little bit too.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Top high of you, so let's look into.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some more detailed aspects.",
                    "label": 0
                },
                {
                    "sent": "So first numerical validation.",
                    "label": 0
                },
                {
                    "sent": "We want to see that percepts are indeed persistent, so we simulate the right dynamics.",
                    "label": 0
                },
                {
                    "sent": "X axis is time or accesses activity.",
                    "label": 0
                },
                {
                    "sent": "And I plot here the activity for subset of neurons.",
                    "label": 0
                },
                {
                    "sent": "As you can see activity is going crazy all over the place just like it did in the example of real data.",
                    "label": 0
                },
                {
                    "sent": "And I have the Patch is represented by the network above.",
                    "label": 0
                },
                {
                    "sent": "So the Patch with a black frame around it is the one at time zero and the other patches or.",
                    "label": 0
                },
                {
                    "sent": "With time as time goes by and you can see that they are perfectly identical.",
                    "label": 0
                },
                {
                    "sent": "So the numerical validation does show that percepts are persistent.",
                    "label": 1
                },
                {
                    "sent": "A slightly.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different way to look at it is that if I plot for each neuron above and read its activity as a trace, and if I plot under that where the white squares are now, I plot the its contribution to the Patch represented by the network I'm going to do this for all six networks and then at the very bottom I'm going to plot the representation.",
                    "label": 0
                },
                {
                    "sent": "The Patch represented by the network as a whole, and I run the right dynamics.",
                    "label": 0
                },
                {
                    "sent": "So each one of the activities of each one of the neurons is going to change, some go up, some go down.",
                    "label": 0
                },
                {
                    "sent": "And accordingly, what is represented by each one of these neurons changes, so each neuron individually isn't keeping a persistent percept.",
                    "label": 0
                },
                {
                    "sent": "But due to this D equals DL, this receptive field recombination rule, then lateral connectivity enforces that the network as a whole has a persistent percept, and you can see that in the bottom that both the little patches at the very bottom and then and also the color map that remains perfectly stable with time.",
                    "label": 0
                },
                {
                    "sent": "So, aside from maintaining the.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Persistent percepts we have a specific specific form for the network.",
                    "label": 0
                },
                {
                    "sent": "We can actually compute, and we want to see whether this network seems realistic so we can check various statistical.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Properties, for instance, we can look at the distribution of weights amongst different neurons.",
                    "label": 0
                },
                {
                    "sent": "If you do this experimentally with paired recordings, you get sort of this heavy tail distrib.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if we do this in our model, we get a very similar type of distribution.",
                    "label": 0
                },
                {
                    "sent": "We can look at more.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Detailed aspects.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Network motifs, so if you look at two neuron motif store.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "3 two known motifs you run a is connected to neuron B. Neuron B is connected to neuron A and the reciprocal connection between A&B.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what we find both in real cortical networks and our networks is that reciprocal connections are far more common than random.",
                    "label": 0
                },
                {
                    "sent": "About four to five times more common.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can also do this for three neuron motifs.",
                    "label": 0
                },
                {
                    "sent": "There are 16 of these and just to give you the broad sense.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are missing connections like the one on the bottom, which you have only one connection between the neurons and there are full motives that there are connections between all neurons.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And again, both in cortex and then refire networks.",
                    "label": 1
                },
                {
                    "sent": "We find a large overexpression of reciprocal motifs.",
                    "label": 1
                },
                {
                    "sent": "So to sum this up, if you're on a is connected to neuron B and you're on B is connected to an see, it's far more likely that you're on a will also be connected to neurons.",
                    "label": 0
                },
                {
                    "sent": "See then you would expect by an average randomly Corentin average controlled network.",
                    "label": 0
                },
                {
                    "sent": "So just to sum up.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The question we sought out to ask is can time variant neuronal activity, which is what we know exists in the brain represent time invariant percepts, which is what we know the brain has to do in order to have working memory.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The answer is yes, but not in orthogonal basis.",
                    "label": 0
                },
                {
                    "sent": "But again, it's very reasonable to think in a basis that's not orthogonal in an overcomplete frame because of the Thelma cortical divergance.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We propose a very specific form of a network that actually supports time invariant percepts, with the rule of refire network that the lateral connectivity ensures that the persistence of the percepts we call these refire networks, and we can calculate them from data, and we find that once we do calculate them the network.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Qualitatively match known statistical properties of cortical networks, both of the two I've showed you and also a number of properties, more they didn't have time to go over.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with that, I'd like to conclude to.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Comedians Club ski my post documents.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other members of the club Ski Lab and Frank for helping us with drawing up the figure of the network structure and of course, thank you for your attention and for having to give this talk.",
                    "label": 1
                },
                {
                    "sent": "Yeah, so my question is why does the brain use such a complicated way to represent persistent percepts?",
                    "label": 0
                },
                {
                    "sent": "So can you speculate a bit about the computational function of this?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so actually I can speculate a lot about its computational function.",
                    "label": 0
                },
                {
                    "sent": "I don't like to hand wave and I didn't have time to show you to show you many of the things that one can do with this, But if you allow me to speak a little bit more freely than what this allows you is to disentangle the fact that you need to represent something.",
                    "label": 0
                },
                {
                    "sent": "With how you need to represent it.",
                    "label": 0
                },
                {
                    "sent": "So if you have an orthogonal basis, there's only one fixed way in which the network can represent this given stimulus.",
                    "label": 0
                },
                {
                    "sent": "In these networks you can completely change the profile of activity and still represent the same thing.",
                    "label": 0
                },
                {
                    "sent": "So for instance, you can have the activity sparse or non sparse to trade off robustness against non robustness and there are a number of other computations that we can show that can be done by this, but I didn't want.",
                    "label": 0
                },
                {
                    "sent": "I didn't have time to really get into them in detail, but I have my poster if you want to.",
                    "label": 0
                },
                {
                    "sent": "I'll be glad to try and answer so your model is a linear one and how old your conclusions change if you include the nonlinearities that we know neurons have.",
                    "label": 0
                },
                {
                    "sent": "OK, so I sort of expected that question to be asked, and so we've we've extended this now for.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "We've extended, sorry, we've extended this now to spiking neural networks and just to give you the one minute answer.",
                    "label": 0
                },
                {
                    "sent": "So if I show you.",
                    "label": 0
                },
                {
                    "sent": "If I show you a very similar plot to what we showed before with the activity of the neurons again being red traces, and the representation being in the white spaces, then we again the representation of each neuron changes a lot as it spikes, but the representation of the network as a whole remain constant, and in fact there's a paradox that I think is sort of has been a little bit overlooked in neuroscience that in order for a neuron to communicate, it needs to spike, but if it needs to spike, it resets and it loses its information and this is fine and good if there's a constant stimulus, that's it.",
                    "label": 0
                },
                {
                    "sent": "Integrating, but if there is no constant stimulus, that's a problem.",
                    "label": 0
                },
                {
                    "sent": "But this refire rule allows sort of as a high dimensional integrator to keep integrating even though the stimulus has died out.",
                    "label": 0
                },
                {
                    "sent": "So this works for spiking nonlinearities, and there are some very interesting properties that we're still working through, but it does work, and we can have very different some computations.",
                    "label": 0
                }
            ]
        }
    }
}