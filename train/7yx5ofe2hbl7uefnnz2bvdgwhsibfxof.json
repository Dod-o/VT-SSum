{
    "id": "7yx5ofe2hbl7uefnnz2bvdgwhsibfxof",
    "title": "LOD-a-lot: A Queryable Dump of the LOD cloud",
    "info": {
        "author": [
            "Javier David Fern\u00e1ndez Garc\u00eda, Vienna University of Economics and Business"
        ],
        "published": "Nov. 28, 2017",
        "recorded": "October 2017",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2017_fernandez_LOD_cloud/",
    "segmentation": [
        [
            "So my name is Javier Fernandez from Vienna, although I'm originally from Spain.",
            "As you can see by my accent.",
            "I will present this work is a research paper alot alot coauthored by me and about traffic from the University Amsterdam.",
            "Also Miguel Martinez from Barry to Spain and Marius from his own company.",
            "Modular software UK.",
            "So let me just start."
        ],
        [
            "Without saying that link open data is great.",
            "OK, so we basically started with some nice idea, but another track layer.",
            "OK, we have this abstract representation.",
            "We didn't know how to build this part, so at the end we came up with a very practical approach which is linked open data cloud OK and we have several estimations about the size of linkoping data, but we can say roughly that we have more than 150 billion triples more than our around six 6000 datasets.",
            "OK, and more than 500 sparkling points, so saying that that is great.",
            "I will challenge you to ask this question."
        ],
        [
            "OK, so give me all the entities with the label acceptors.",
            "So if you have one solution to get this question, I know in 10 seconds I will stop my talk.",
            "But I hope you don't have it."
        ],
        [
            "OK, so let's look, let's look at the linked data ecosystem and see what which store."
        ],
        [
            "And we have there.",
            "OK, so the first approach to try to solve this query, could we do Federated queries?",
            "OK, so essentially we get a list of this sparkling points, for instance for some apps like that happened over here, so we have a list of inspection points and then we just query this this this this sentence, this query two of them multiple starting points and we aggregate the results.",
            "OK, so the promise you aren't that essentially there's parking points in general, we know that they have low availability.",
            "OK, so for instance we have this service called Sparkles OK. Posted here also in Vail and this service basically monitors the sparkling points and it says that the hardware of the sparkling points are always done.",
            "OK, all wisdom and others have serious disruptions plus."
        ],
        [
            "Also, given that we are academics, we don't have great resources and usually we just public speaking points in very bad services.",
            "So essentially we tried to put some limits.",
            "OK, so we limit the number of results and we limit the time out.",
            "OK, so usually when you have a complex query you get the partial results and also with delays and just."
        ],
        [
            "OK, so the other idea to query to query this just follow your nose approach.",
            "OK so we are in the link link data approach so we can do is just to get all our eyes and to get the RDF and then filter the results so that works is is is essentially the philosophy of link of linked data.",
            "OK, but you have to start with since it OK to get all these high rise.",
            "Maybe DPS are good candidates because it's in the center of the link.",
            "Open data cloud so we can start with the pedia.",
            "With slow because we have to face many documents and then plus for our query in particular and give me everything about.",
            "Acceptance is a literal.",
            "We don't have work to start.",
            "OK, we don't have an idea right to get their sources.",
            "So this is not also feasible and."
        ],
        [
            "Last solution could be two years ago to the idea of dams.",
            "OK, so again we get a list of dams we we called the web to get a look at these times.",
            "We downloaded datasets.",
            "So for this you better have a space in your machine to get all the datasets.",
            "Then we index then locali.",
            "OK so for this again you have to patience and deals with and deal with this parsing errors.",
            "OK because we know that data is quite messy and find out you have to query all the datasets OK and again I hear you were alive by them, OK?",
            "So again, the program sees huge resources to consume information, plus the messages of the data.",
            "But don't panic gect because."
        ],
        [
            "We have the link data Hacker toolkit.",
            "OK, so the link data Hacker took two tickets for us is based on three tools, so the first one is laundromat by both here and on others.",
            "Especially what we did is just to do some work for us.",
            "They crawl link open data.",
            "OK so they clean it so they try to fix this person arrows and then they index it.",
            "OK so at the end what they have is for each of these of these dumps.",
            "Here they have one data set.",
            "OK so they have a DN 650,000 datasets.",
            "OK available so for this of these 650 data set they have the plain version clean a compressed version that I will mention Now HD and the link data from an endpoint of each of these datasets.",
            "OK, so again if you would need to resolve this kind of query across all of them, what you have to do?",
            "I mean these are very nice result but you have to query all these datasets one by one and then aggregate the results.",
            "And of course, just to mention this is just a partial crew.",
            "OK, because we base also in some seats, so they'll be saying some seats, but it still is like with approximation of the link, update McLeod."
        ],
        [
            "OK, this is the second tool that we have in our toolkit.",
            "Is HTT, authored by me and Miguel Mario an essentially what we did is just to provide a compact format for RDF.",
            "OK, so we have RDF and we put in a binary and compact format and the good news is that you can also query.",
            "It encompasses space.",
            "OK.",
            "So yes, using a small portion like 3% of the size mapping memory you can query information and get through patterns out of the data.",
            "We are for Deal button as fast as some solutions like this.",
            "So I'm for full sparkle.",
            "We also supported by grabbing it into general.",
            "OK, so we use Jenna as the top layer and then the back end is just this compress and queryable format HT just to give you some some example.",
            "So this is the PDF, attacking is not the last version but the previous one is the English portion and it had like 400 million triples.",
            "OK and in plain it took 63 gigabytes with I mean if you want to just to sleep it is 5 gigabytes is not bad for us is 66 gigabytes.",
            "So as you can see it's a bit more.",
            "But the good thing is that you can query it.",
            "The talent with HD essentially is that you have to pay the price to convert it.",
            "OK, it's not for free.",
            "You have to create this format.",
            "You have to index so you have to pay the price off of query of creating it.",
            "But once you have it the the consumer can consume it."
        ],
        [
            "Recently OK because it's just brand X so you can query it uncompresses space.",
            "And the third approach, of course, is linked to the fragment is well known.",
            "So essentially we tried to elevate the burden of of the of the sparkling points, and we move some computation to the client.",
            "OK, so in particular with the performance we move the table patterns right?",
            "So you can query patterns to the server and then the claim has to aggregate the results and provide full spark.",
            "So it's also a very well known to live very efficient, but for complex for these queries we have problem.",
            "OK, so I so here also some papers because there is a huge community working with optimizations for Federated queries."
        ],
        [
            "So let me just compare these three tools, so I presented this in our stop this genocide you see.",
            "And it was actually so let's see this time.",
            "So I tried to compare our DHT and link from Laundromat by comparing Rome it OK which is the plane area and the process meat that is HT the hamburger.",
            "OK so if you see RDF in plain sight is Rome it.",
            "If you search this hamburger right?",
            "So if you want to consume this Rome it you can just."
        ],
        [
            "Download the file.",
            "OK, an index so you have to get your hands dirty, OK and if you want to aspire to process this particular point about this room it then you have to queue for the cooker just to to prepare your meal.",
            "And at the end you don't even even know if you like the information here behind this marketing point.",
            "OK, so you see the face of this guy here so it's like, oh man, I'm very hungry and I don't even know if I like whatever you are cooking.",
            "OK, we figured if we have the information process already so you can just get your HT and just process the bite.",
            "OK, so you just give a bite and you know what this is already."
        ],
        [
            "So what this link data from installing different way to compute the information?",
            "This big information intense.",
            "OK, just a fermentation of the meat.",
            "And finally what is link a lot laundromat?",
            "Some restaurant.",
            "OK, so it's a restaurant.",
            "We have the menu of all the missile, all the hamburgers that you can get.",
            "OK."
        ],
        [
            "So having said that, we need web scale queries.",
            "OK, so at the end we have this guy who is very hungry and he wants to consume a big portion of the of the of the data.",
            "OK, big hamburger.",
            "So that's what we did here in Laundromat."
        ],
        [
            "The loud sorry solo dolo.",
            "Essentially we took the basic role of a laundromat OK and this 650,000 datasets and we just integrate into one.",
            "OK so we integrated all these datasets into just one HD file.",
            "OK, an essentially the interface to query bieling data fragments.",
            "OK so we have a huge file.",
            "OK with 28 billion triples that is substantially all the different reports that we found in this goal of the link of Native Cloud.",
            "OK, so just to give you some NUM."
        ],
        [
            "Again, the number of triples is 28 billion.",
            "OK, so we have around 3 billion subjects, 1 million predicates.",
            "3 billion objects are the world from this subject.",
            "We have more than one billion literals.",
            "OK, so we're wondering about the data size.",
            "I have it here so I can give it to you after the talk if you are interested.",
            "Here are modest HD SSD driver and essentially the HD file takes about 300 gigabytes, so it's quite affordable for.",
            "For any almost any researcher here and then over this, we need some additional indexes to have all the all the queries, and this takes another 100 gigabytes, more.",
            "So since then in less than half a TB you can get your your lot dump and query the dump over this size.",
            "OK, so to query it as I said, you need more or less than 3% of the size map memory.",
            "So for this size models you have like 16 gigabytes of RAM.",
            "OK, so you have a laptop with 32 gigabytes of RAM.",
            "You have more than enough to to query the file OK then if you're wondering about the loading time.",
            "So how much time you need to to allow the time?",
            "Then essentially we just need a couple of minutes to load this information into gram.",
            "OK, so I can give you this disk."
        ],
        [
            "Plug into your laptop and then in two minutes you can query information.",
            "OK, this is just to mention that the latter that we'll just put one potential laptop service.",
            "For instance, you have 8 cores, 32 gigabytes of RAM, an essentially basic installation.",
            "You can query it, and then we call it low cost because at the time of writing the paper we take off the prices of this thing and it's impossible as 300 euros.",
            "OK, so we did it with 300 euros you can download.",
            "One query, a good portion of the loudcloud and about dealing with affirmative page resolution is insulating the level of milliseconds.",
            "OK, so we are quite efficient as well.",
            "Finally, just to mention about decoration time, it took us like 64 hours to create HTTP.",
            "So this file here plus the index.",
            "It was another.",
            "I think it was eight hours more.",
            "OK, so it's quite feasible to do it incrementally at any state of time."
        ],
        [
            "OK, so this is the link to our issues.",
            "Lot a lot.",
            "OK, and we're also list now in that hub so you can access the information for free."
        ],
        [
            "Finally, some use case, so the first one is the one that I gave you during the talk.",
            "This query social web scale.",
            "OK, so now you can use link data from into query our file and also if you're interested in full sparkle you can grab it into Jenna and query this winter jam.",
            "And the use cases evaluation and miss marking.",
            "OK, so usually you have disk using your papers that it doesn't scale.",
            "I didn't have the resources.",
            "Now you don't have accused.",
            "I'm sorry for you so you can download this file and queried in your modest infrastructure.",
            "Finally to create some metrics and analytics.",
            "This is also very, very handy.",
            "So for instance, I was interested in computing the degree of the nodes.",
            "OK, I need to me exactly one hour to get these graphics.",
            "OK, so I just load my file.",
            "I didn't compute the degrees of the subject predicate and obvious just to verify is if, as we supposed, it was a Power Distribution and it took me one hour.",
            "You can imagine another metric and just you get your file and just your queries."
        ],
        [
            "OK, so this was the.",
            "This is where the data that they use cases that we imagine when we created the paper.",
            "Then we have been working on that and we have more use cases in a paper in semantics this year.",
            "So for instance more use cases where to compute into the closure.",
            "So you have questions you can ask about are so we create the closer he created the closure of SMS and compute some cluster about it.",
            "And also we have been working on graph navigation.",
            "So for instance to compute random works over the file and also shortest path.",
            "OK, I'm finally the use cases that have been saying OK per axle with all the entities.",
            "So now we can just go to this link.",
            "Here in less than 1020 seconds, I promise we have all the entities related to accept polar ISM.",
            "So I think that's all from my side.",
            "The next step is just to compute these grow like.",
            "More frequent OK so we have this version.",
            "It was from the beginning of the year.",
            "We will try to create a more up-to-date version, OK, and also we like to keep the graph."
        ],
        [
            "They could."
        ],
        [
            "In the data.",
            "OK, so now given that we have integrated everything."
        ],
        [
            "It's just one single data set.",
            "We lost the provenance information.",
            "OK, so we don't know for each of the particular tools in which graph is on which day today was hosted, but we can do it be a lot laundromat.",
            "OK so we have one trip we can go always to Laundromat and get there in a graph but this information is not hosted now in our filing entity so this is a future work and finally we want to implement all these use cases because at the end we think like that low-cost actors to to load is high.",
            "Influence high impact research.",
            "OK, some nourishment for all the partners with stealing the famine and laundromat, and that's all from my side."
        ],
        [
            "Submit you've done this kind of integration a number of times.",
            "Do you have a sense of how the rate of growth of the integrated data set?",
            "So we're going to have a idea of the rate of growth.",
            "Yeah, there is some papers about this growth and it says that basically you have 30% of new information every year.",
            "But I mean just some estimation.",
            "There is not like a great study with this.",
            "You told him in the slides that an index works relatively well for simple queries, so wondering what are the queries which are performed which perform relativly worse.",
            "And this is quite large datasets, some aggregations order by or do you have some insights?",
            "Yeah, so as I said, we believe on Gina.",
            "OK, as the query planner, equity optimiser and this is not so optimal.",
            "So we basically believe from Gina.",
            "So some complex query with many joints optional, some counts and so on that we done performed as well As for instance with tools or other tools.",
            "But our future work is just to change a bit.",
            "This interview with Gina and try to leverage more the features of entity.",
            "Thanks for representation.",
            "My question is related to the.",
            "Well, first the change on the data.",
            "So what happened is actually the new data in or can you actually use the difference like addition and deletions to really update this?",
            "Or you have to process it all over again to create a new one?",
            "Question so essentially yes, you should have to process everything like in the naive words in the night version, but we have a way to do it efficiently.",
            "So indeed, if you have seen the numbers here.",
            "So we integrated this 650 datasets.",
            "OK, I need to cast 64 hours OK so we didn't have to create everything from scratch because otherwise he has some weeks so we try to merge different files into one efficiently.",
            "Great thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So my name is Javier Fernandez from Vienna, although I'm originally from Spain.",
                    "label": 0
                },
                {
                    "sent": "As you can see by my accent.",
                    "label": 0
                },
                {
                    "sent": "I will present this work is a research paper alot alot coauthored by me and about traffic from the University Amsterdam.",
                    "label": 0
                },
                {
                    "sent": "Also Miguel Martinez from Barry to Spain and Marius from his own company.",
                    "label": 0
                },
                {
                    "sent": "Modular software UK.",
                    "label": 0
                },
                {
                    "sent": "So let me just start.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Without saying that link open data is great.",
                    "label": 1
                },
                {
                    "sent": "OK, so we basically started with some nice idea, but another track layer.",
                    "label": 0
                },
                {
                    "sent": "OK, we have this abstract representation.",
                    "label": 0
                },
                {
                    "sent": "We didn't know how to build this part, so at the end we came up with a very practical approach which is linked open data cloud OK and we have several estimations about the size of linkoping data, but we can say roughly that we have more than 150 billion triples more than our around six 6000 datasets.",
                    "label": 0
                },
                {
                    "sent": "OK, and more than 500 sparkling points, so saying that that is great.",
                    "label": 0
                },
                {
                    "sent": "I will challenge you to ask this question.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so give me all the entities with the label acceptors.",
                    "label": 1
                },
                {
                    "sent": "So if you have one solution to get this question, I know in 10 seconds I will stop my talk.",
                    "label": 0
                },
                {
                    "sent": "But I hope you don't have it.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's look, let's look at the linked data ecosystem and see what which store.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we have there.",
                    "label": 0
                },
                {
                    "sent": "OK, so the first approach to try to solve this query, could we do Federated queries?",
                    "label": 1
                },
                {
                    "sent": "OK, so essentially we get a list of this sparkling points, for instance for some apps like that happened over here, so we have a list of inspection points and then we just query this this this this sentence, this query two of them multiple starting points and we aggregate the results.",
                    "label": 1
                },
                {
                    "sent": "OK, so the promise you aren't that essentially there's parking points in general, we know that they have low availability.",
                    "label": 1
                },
                {
                    "sent": "OK, so for instance we have this service called Sparkles OK. Posted here also in Vail and this service basically monitors the sparkling points and it says that the hardware of the sparkling points are always done.",
                    "label": 0
                },
                {
                    "sent": "OK, all wisdom and others have serious disruptions plus.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, given that we are academics, we don't have great resources and usually we just public speaking points in very bad services.",
                    "label": 0
                },
                {
                    "sent": "So essentially we tried to put some limits.",
                    "label": 0
                },
                {
                    "sent": "OK, so we limit the number of results and we limit the time out.",
                    "label": 0
                },
                {
                    "sent": "OK, so usually when you have a complex query you get the partial results and also with delays and just.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the other idea to query to query this just follow your nose approach.",
                    "label": 0
                },
                {
                    "sent": "OK so we are in the link link data approach so we can do is just to get all our eyes and to get the RDF and then filter the results so that works is is is essentially the philosophy of link of linked data.",
                    "label": 1
                },
                {
                    "sent": "OK, but you have to start with since it OK to get all these high rise.",
                    "label": 0
                },
                {
                    "sent": "Maybe DPS are good candidates because it's in the center of the link.",
                    "label": 0
                },
                {
                    "sent": "Open data cloud so we can start with the pedia.",
                    "label": 1
                },
                {
                    "sent": "With slow because we have to face many documents and then plus for our query in particular and give me everything about.",
                    "label": 0
                },
                {
                    "sent": "Acceptance is a literal.",
                    "label": 0
                },
                {
                    "sent": "We don't have work to start.",
                    "label": 0
                },
                {
                    "sent": "OK, we don't have an idea right to get their sources.",
                    "label": 0
                },
                {
                    "sent": "So this is not also feasible and.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Last solution could be two years ago to the idea of dams.",
                    "label": 0
                },
                {
                    "sent": "OK, so again we get a list of dams we we called the web to get a look at these times.",
                    "label": 0
                },
                {
                    "sent": "We downloaded datasets.",
                    "label": 0
                },
                {
                    "sent": "So for this you better have a space in your machine to get all the datasets.",
                    "label": 1
                },
                {
                    "sent": "Then we index then locali.",
                    "label": 1
                },
                {
                    "sent": "OK so for this again you have to patience and deals with and deal with this parsing errors.",
                    "label": 0
                },
                {
                    "sent": "OK because we know that data is quite messy and find out you have to query all the datasets OK and again I hear you were alive by them, OK?",
                    "label": 1
                },
                {
                    "sent": "So again, the program sees huge resources to consume information, plus the messages of the data.",
                    "label": 0
                },
                {
                    "sent": "But don't panic gect because.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have the link data Hacker toolkit.",
                    "label": 1
                },
                {
                    "sent": "OK, so the link data Hacker took two tickets for us is based on three tools, so the first one is laundromat by both here and on others.",
                    "label": 0
                },
                {
                    "sent": "Especially what we did is just to do some work for us.",
                    "label": 0
                },
                {
                    "sent": "They crawl link open data.",
                    "label": 0
                },
                {
                    "sent": "OK so they clean it so they try to fix this person arrows and then they index it.",
                    "label": 0
                },
                {
                    "sent": "OK so at the end what they have is for each of these of these dumps.",
                    "label": 0
                },
                {
                    "sent": "Here they have one data set.",
                    "label": 0
                },
                {
                    "sent": "OK so they have a DN 650,000 datasets.",
                    "label": 0
                },
                {
                    "sent": "OK available so for this of these 650 data set they have the plain version clean a compressed version that I will mention Now HD and the link data from an endpoint of each of these datasets.",
                    "label": 0
                },
                {
                    "sent": "OK, so again if you would need to resolve this kind of query across all of them, what you have to do?",
                    "label": 0
                },
                {
                    "sent": "I mean these are very nice result but you have to query all these datasets one by one and then aggregate the results.",
                    "label": 0
                },
                {
                    "sent": "And of course, just to mention this is just a partial crew.",
                    "label": 0
                },
                {
                    "sent": "OK, because we base also in some seats, so they'll be saying some seats, but it still is like with approximation of the link, update McLeod.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, this is the second tool that we have in our toolkit.",
                    "label": 0
                },
                {
                    "sent": "Is HTT, authored by me and Miguel Mario an essentially what we did is just to provide a compact format for RDF.",
                    "label": 1
                },
                {
                    "sent": "OK, so we have RDF and we put in a binary and compact format and the good news is that you can also query.",
                    "label": 0
                },
                {
                    "sent": "It encompasses space.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So yes, using a small portion like 3% of the size mapping memory you can query information and get through patterns out of the data.",
                    "label": 0
                },
                {
                    "sent": "We are for Deal button as fast as some solutions like this.",
                    "label": 0
                },
                {
                    "sent": "So I'm for full sparkle.",
                    "label": 0
                },
                {
                    "sent": "We also supported by grabbing it into general.",
                    "label": 0
                },
                {
                    "sent": "OK, so we use Jenna as the top layer and then the back end is just this compress and queryable format HT just to give you some some example.",
                    "label": 0
                },
                {
                    "sent": "So this is the PDF, attacking is not the last version but the previous one is the English portion and it had like 400 million triples.",
                    "label": 0
                },
                {
                    "sent": "OK and in plain it took 63 gigabytes with I mean if you want to just to sleep it is 5 gigabytes is not bad for us is 66 gigabytes.",
                    "label": 0
                },
                {
                    "sent": "So as you can see it's a bit more.",
                    "label": 1
                },
                {
                    "sent": "But the good thing is that you can query it.",
                    "label": 0
                },
                {
                    "sent": "The talent with HD essentially is that you have to pay the price to convert it.",
                    "label": 0
                },
                {
                    "sent": "OK, it's not for free.",
                    "label": 0
                },
                {
                    "sent": "You have to create this format.",
                    "label": 0
                },
                {
                    "sent": "You have to index so you have to pay the price off of query of creating it.",
                    "label": 0
                },
                {
                    "sent": "But once you have it the the consumer can consume it.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Recently OK because it's just brand X so you can query it uncompresses space.",
                    "label": 0
                },
                {
                    "sent": "And the third approach, of course, is linked to the fragment is well known.",
                    "label": 0
                },
                {
                    "sent": "So essentially we tried to elevate the burden of of the of the sparkling points, and we move some computation to the client.",
                    "label": 0
                },
                {
                    "sent": "OK, so in particular with the performance we move the table patterns right?",
                    "label": 0
                },
                {
                    "sent": "So you can query patterns to the server and then the claim has to aggregate the results and provide full spark.",
                    "label": 0
                },
                {
                    "sent": "So it's also a very well known to live very efficient, but for complex for these queries we have problem.",
                    "label": 1
                },
                {
                    "sent": "OK, so I so here also some papers because there is a huge community working with optimizations for Federated queries.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me just compare these three tools, so I presented this in our stop this genocide you see.",
                    "label": 0
                },
                {
                    "sent": "And it was actually so let's see this time.",
                    "label": 0
                },
                {
                    "sent": "So I tried to compare our DHT and link from Laundromat by comparing Rome it OK which is the plane area and the process meat that is HT the hamburger.",
                    "label": 0
                },
                {
                    "sent": "OK so if you see RDF in plain sight is Rome it.",
                    "label": 0
                },
                {
                    "sent": "If you search this hamburger right?",
                    "label": 0
                },
                {
                    "sent": "So if you want to consume this Rome it you can just.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Download the file.",
                    "label": 0
                },
                {
                    "sent": "OK, an index so you have to get your hands dirty, OK and if you want to aspire to process this particular point about this room it then you have to queue for the cooker just to to prepare your meal.",
                    "label": 0
                },
                {
                    "sent": "And at the end you don't even even know if you like the information here behind this marketing point.",
                    "label": 0
                },
                {
                    "sent": "OK, so you see the face of this guy here so it's like, oh man, I'm very hungry and I don't even know if I like whatever you are cooking.",
                    "label": 1
                },
                {
                    "sent": "OK, we figured if we have the information process already so you can just get your HT and just process the bite.",
                    "label": 0
                },
                {
                    "sent": "OK, so you just give a bite and you know what this is already.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what this link data from installing different way to compute the information?",
                    "label": 0
                },
                {
                    "sent": "This big information intense.",
                    "label": 0
                },
                {
                    "sent": "OK, just a fermentation of the meat.",
                    "label": 0
                },
                {
                    "sent": "And finally what is link a lot laundromat?",
                    "label": 0
                },
                {
                    "sent": "Some restaurant.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a restaurant.",
                    "label": 0
                },
                {
                    "sent": "We have the menu of all the missile, all the hamburgers that you can get.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So having said that, we need web scale queries.",
                    "label": 0
                },
                {
                    "sent": "OK, so at the end we have this guy who is very hungry and he wants to consume a big portion of the of the of the data.",
                    "label": 0
                },
                {
                    "sent": "OK, big hamburger.",
                    "label": 0
                },
                {
                    "sent": "So that's what we did here in Laundromat.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The loud sorry solo dolo.",
                    "label": 0
                },
                {
                    "sent": "Essentially we took the basic role of a laundromat OK and this 650,000 datasets and we just integrate into one.",
                    "label": 0
                },
                {
                    "sent": "OK so we integrated all these datasets into just one HD file.",
                    "label": 0
                },
                {
                    "sent": "OK, an essentially the interface to query bieling data fragments.",
                    "label": 0
                },
                {
                    "sent": "OK so we have a huge file.",
                    "label": 0
                },
                {
                    "sent": "OK with 28 billion triples that is substantially all the different reports that we found in this goal of the link of Native Cloud.",
                    "label": 0
                },
                {
                    "sent": "OK, so just to give you some NUM.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again, the number of triples is 28 billion.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have around 3 billion subjects, 1 million predicates.",
                    "label": 0
                },
                {
                    "sent": "3 billion objects are the world from this subject.",
                    "label": 0
                },
                {
                    "sent": "We have more than one billion literals.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're wondering about the data size.",
                    "label": 0
                },
                {
                    "sent": "I have it here so I can give it to you after the talk if you are interested.",
                    "label": 0
                },
                {
                    "sent": "Here are modest HD SSD driver and essentially the HD file takes about 300 gigabytes, so it's quite affordable for.",
                    "label": 0
                },
                {
                    "sent": "For any almost any researcher here and then over this, we need some additional indexes to have all the all the queries, and this takes another 100 gigabytes, more.",
                    "label": 0
                },
                {
                    "sent": "So since then in less than half a TB you can get your your lot dump and query the dump over this size.",
                    "label": 0
                },
                {
                    "sent": "OK, so to query it as I said, you need more or less than 3% of the size map memory.",
                    "label": 1
                },
                {
                    "sent": "So for this size models you have like 16 gigabytes of RAM.",
                    "label": 1
                },
                {
                    "sent": "OK, so you have a laptop with 32 gigabytes of RAM.",
                    "label": 0
                },
                {
                    "sent": "You have more than enough to to query the file OK then if you're wondering about the loading time.",
                    "label": 0
                },
                {
                    "sent": "So how much time you need to to allow the time?",
                    "label": 0
                },
                {
                    "sent": "Then essentially we just need a couple of minutes to load this information into gram.",
                    "label": 0
                },
                {
                    "sent": "OK, so I can give you this disk.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Plug into your laptop and then in two minutes you can query information.",
                    "label": 0
                },
                {
                    "sent": "OK, this is just to mention that the latter that we'll just put one potential laptop service.",
                    "label": 0
                },
                {
                    "sent": "For instance, you have 8 cores, 32 gigabytes of RAM, an essentially basic installation.",
                    "label": 0
                },
                {
                    "sent": "You can query it, and then we call it low cost because at the time of writing the paper we take off the prices of this thing and it's impossible as 300 euros.",
                    "label": 0
                },
                {
                    "sent": "OK, so we did it with 300 euros you can download.",
                    "label": 0
                },
                {
                    "sent": "One query, a good portion of the loudcloud and about dealing with affirmative page resolution is insulating the level of milliseconds.",
                    "label": 0
                },
                {
                    "sent": "OK, so we are quite efficient as well.",
                    "label": 0
                },
                {
                    "sent": "Finally, just to mention about decoration time, it took us like 64 hours to create HTTP.",
                    "label": 0
                },
                {
                    "sent": "So this file here plus the index.",
                    "label": 0
                },
                {
                    "sent": "It was another.",
                    "label": 0
                },
                {
                    "sent": "I think it was eight hours more.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's quite feasible to do it incrementally at any state of time.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is the link to our issues.",
                    "label": 0
                },
                {
                    "sent": "Lot a lot.",
                    "label": 0
                },
                {
                    "sent": "OK, and we're also list now in that hub so you can access the information for free.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, some use case, so the first one is the one that I gave you during the talk.",
                    "label": 0
                },
                {
                    "sent": "This query social web scale.",
                    "label": 1
                },
                {
                    "sent": "OK, so now you can use link data from into query our file and also if you're interested in full sparkle you can grab it into Jenna and query this winter jam.",
                    "label": 0
                },
                {
                    "sent": "And the use cases evaluation and miss marking.",
                    "label": 1
                },
                {
                    "sent": "OK, so usually you have disk using your papers that it doesn't scale.",
                    "label": 0
                },
                {
                    "sent": "I didn't have the resources.",
                    "label": 0
                },
                {
                    "sent": "Now you don't have accused.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry for you so you can download this file and queried in your modest infrastructure.",
                    "label": 0
                },
                {
                    "sent": "Finally to create some metrics and analytics.",
                    "label": 1
                },
                {
                    "sent": "This is also very, very handy.",
                    "label": 0
                },
                {
                    "sent": "So for instance, I was interested in computing the degree of the nodes.",
                    "label": 0
                },
                {
                    "sent": "OK, I need to me exactly one hour to get these graphics.",
                    "label": 0
                },
                {
                    "sent": "OK, so I just load my file.",
                    "label": 0
                },
                {
                    "sent": "I didn't compute the degrees of the subject predicate and obvious just to verify is if, as we supposed, it was a Power Distribution and it took me one hour.",
                    "label": 0
                },
                {
                    "sent": "You can imagine another metric and just you get your file and just your queries.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this was the.",
                    "label": 0
                },
                {
                    "sent": "This is where the data that they use cases that we imagine when we created the paper.",
                    "label": 1
                },
                {
                    "sent": "Then we have been working on that and we have more use cases in a paper in semantics this year.",
                    "label": 0
                },
                {
                    "sent": "So for instance more use cases where to compute into the closure.",
                    "label": 1
                },
                {
                    "sent": "So you have questions you can ask about are so we create the closer he created the closure of SMS and compute some cluster about it.",
                    "label": 0
                },
                {
                    "sent": "And also we have been working on graph navigation.",
                    "label": 1
                },
                {
                    "sent": "So for instance to compute random works over the file and also shortest path.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm finally the use cases that have been saying OK per axle with all the entities.",
                    "label": 0
                },
                {
                    "sent": "So now we can just go to this link.",
                    "label": 0
                },
                {
                    "sent": "Here in less than 1020 seconds, I promise we have all the entities related to accept polar ISM.",
                    "label": 0
                },
                {
                    "sent": "So I think that's all from my side.",
                    "label": 0
                },
                {
                    "sent": "The next step is just to compute these grow like.",
                    "label": 0
                },
                {
                    "sent": "More frequent OK so we have this version.",
                    "label": 0
                },
                {
                    "sent": "It was from the beginning of the year.",
                    "label": 0
                },
                {
                    "sent": "We will try to create a more up-to-date version, OK, and also we like to keep the graph.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They could.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the data.",
                    "label": 0
                },
                {
                    "sent": "OK, so now given that we have integrated everything.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's just one single data set.",
                    "label": 0
                },
                {
                    "sent": "We lost the provenance information.",
                    "label": 0
                },
                {
                    "sent": "OK, so we don't know for each of the particular tools in which graph is on which day today was hosted, but we can do it be a lot laundromat.",
                    "label": 0
                },
                {
                    "sent": "OK so we have one trip we can go always to Laundromat and get there in a graph but this information is not hosted now in our filing entity so this is a future work and finally we want to implement all these use cases because at the end we think like that low-cost actors to to load is high.",
                    "label": 0
                },
                {
                    "sent": "Influence high impact research.",
                    "label": 0
                },
                {
                    "sent": "OK, some nourishment for all the partners with stealing the famine and laundromat, and that's all from my side.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Submit you've done this kind of integration a number of times.",
                    "label": 0
                },
                {
                    "sent": "Do you have a sense of how the rate of growth of the integrated data set?",
                    "label": 0
                },
                {
                    "sent": "So we're going to have a idea of the rate of growth.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there is some papers about this growth and it says that basically you have 30% of new information every year.",
                    "label": 0
                },
                {
                    "sent": "But I mean just some estimation.",
                    "label": 0
                },
                {
                    "sent": "There is not like a great study with this.",
                    "label": 0
                },
                {
                    "sent": "You told him in the slides that an index works relatively well for simple queries, so wondering what are the queries which are performed which perform relativly worse.",
                    "label": 0
                },
                {
                    "sent": "And this is quite large datasets, some aggregations order by or do you have some insights?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so as I said, we believe on Gina.",
                    "label": 0
                },
                {
                    "sent": "OK, as the query planner, equity optimiser and this is not so optimal.",
                    "label": 0
                },
                {
                    "sent": "So we basically believe from Gina.",
                    "label": 0
                },
                {
                    "sent": "So some complex query with many joints optional, some counts and so on that we done performed as well As for instance with tools or other tools.",
                    "label": 0
                },
                {
                    "sent": "But our future work is just to change a bit.",
                    "label": 0
                },
                {
                    "sent": "This interview with Gina and try to leverage more the features of entity.",
                    "label": 0
                },
                {
                    "sent": "Thanks for representation.",
                    "label": 0
                },
                {
                    "sent": "My question is related to the.",
                    "label": 0
                },
                {
                    "sent": "Well, first the change on the data.",
                    "label": 0
                },
                {
                    "sent": "So what happened is actually the new data in or can you actually use the difference like addition and deletions to really update this?",
                    "label": 0
                },
                {
                    "sent": "Or you have to process it all over again to create a new one?",
                    "label": 0
                },
                {
                    "sent": "Question so essentially yes, you should have to process everything like in the naive words in the night version, but we have a way to do it efficiently.",
                    "label": 0
                },
                {
                    "sent": "So indeed, if you have seen the numbers here.",
                    "label": 0
                },
                {
                    "sent": "So we integrated this 650 datasets.",
                    "label": 0
                },
                {
                    "sent": "OK, I need to cast 64 hours OK so we didn't have to create everything from scratch because otherwise he has some weeks so we try to merge different files into one efficiently.",
                    "label": 0
                },
                {
                    "sent": "Great thanks.",
                    "label": 0
                }
            ]
        }
    }
}