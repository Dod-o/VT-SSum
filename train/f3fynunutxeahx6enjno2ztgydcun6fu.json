{
    "id": "f3fynunutxeahx6enjno2ztgydcun6fu",
    "title": "Natural Language Processing",
    "info": {
        "author": [
            "Phil Blunsom, Department of Computer Science, University of Oxford"
        ],
        "published": "July 27, 2017",
        "recorded": "July 2017",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2017_blunsom_language_processing/",
    "segmentation": [
        [
            "So these questions are not nothing terribly modern about these questions are things are discussed in this lecture, are very old questions in linguistics, possibly from a modern perspective.",
            "So much of this.",
            "Work, maybe 2/3 is works at currently or recently being done at DeepMind, particularly from these people.",
            "So Chris Dyer, Daniel Gatama, Felix healing, and did all this, all this work, and I borrowed many slides from their presentations."
        ],
        [
            "So in the first lecture I introduced this idea of language modeling, talked about how we can do that with various neural networks, how we can apply that to problems like translation.",
            "But there are some key sort of obvious language problems that we're still a long way from solving so well.",
            "We can do very well modeling language with recurrent networks.",
            "They're still not capturing what we understand to be the structure of language.",
            "So in this lecture I'm going to have more deeply into these two key questions, so one is syntax that is the structure of language, the way, language way languages structure their presentation of meaning, and the second topic is semantics.",
            "That is the meaning itself and where it comes from, and particularly this lecture we talking about grounding.",
            "That is, how do we connect symbols that we see in language in our utterances with meaning in the world?",
            "Which an agent is situated?",
            "So these are things that have been discussed in the core of of linguistics, computational linguistics, NLP since their inception, but they're still very hard problems.",
            "It's very hard.",
            "There's lots of theories of syntax.",
            "There's lots of theories of semantics, some more successful than others, but are still plenty of unknowns about what the right way of thinking about these problems.",
            "In most state of the art models, neither of these things are really dealt with explicitly.",
            "They often implicitly in their recurrent networks capture something of syntax, but they're not in there explicitly, and the same with semantics, we would say a machine translation system and neural empty system is definitely capturing aspect of meaning by being under translate from French into English, but it's not doing it in an explicit way, or a terribly nuanced way."
        ],
        [
            "So this afternoon I'm going to talk through roughly 3 topics.",
            "First one is modeling hierarchical structure with recurrent network.",
            "So how do we go from straight, flat, sequential networks to something that looks a bit more adequate for the structure that we know language has?",
            "In the second section, all talk about how do we then take these ideas and tune them to some sort of downstream task?",
            "And we think about this a little bit like grounding the structure of language with some downstream reward like classification sentiment analysis.",
            "These sorts of things.",
            "And in the third part I'll talk about how do we take this idea of grounding?",
            "Further, less of the structure and how do we ground simple linguistic expressions in a world?",
            "So in this case I'll look at training artificial agents in a 3 dimensional environment, having them do tasks and what we can, what we can learn and understand from that sort of problem."
        ],
        [
            "OK, so let's start with hierarchy."
        ],
        [
            "Structure, so we've seen a lot of recurrent neural networks and we see that they are the state of the art for most problems and their exceptionally good at modeling sequences, but there's many things that they don't capture, and particularly they have this.",
            "Bias for sequential dependencies and recency so they're good at capturing things that happened recently.",
            "They could capturing sequential things, or, as I mentioned, the last lecture triggers.",
            "So a particular thing happened to pass, so that can increase probability in the future, but they're not really capturing high level hierarchical structures.",
            "So we can we can enhance them with things like attention.",
            "Obviously gating architectures improve some of these problems, but they don't remove them and LSD EM is still essentially modeling sequential recency.",
            "So if we look to the field of linguistics and what it says about language, one of the key things of the generative School of linguistics, that is the one inspired by Chomsky, it's a key argument that language structures information hierarchically not sequentially, and this is really one of the key underpinnings of that that model of language."
        ],
        [
            "So these things are not terribly controversial.",
            "I mean, language has syntax.",
            "It has semantics.",
            "These are two different things.",
            "Sometimes it's easier to think of these things in terms of artificial languages like programming languages, something like Python.",
            "It's easy to separate the meaning of a Python program from the valid ways you can write Python programs.",
            "There's a valid way you can write a for loop in Python And there's lots of ways that are invalid or ungrammatical in that language, and then that for loop has some semantics away, it's executed.",
            "So we can see in those languages are very clear.",
            "Semantic syntax distinction.",
            "The same exists in natural language.",
            "It's not necessarily clear all the time where it is, but it's definitely there to language has this structure.",
            "We can see this big cause we get these effects where we can think up grammatical utterances, and this is a classic one thought up by Chomsky color screen, orange asleep, furiously, that are perfectly grammatically well formed, but uh, semantically incoherent.",
            "So there's no semantic meaning there.",
            "Equally, we can jumble around words and create something that is neither grammatical nor semantically well formed, or we can come up with things that we can interpret semantically, button not grammatical.",
            "So if I say something like John like Apple or something like that, so that's not grammatically well formed, but you'll have no trouble extracting meaning from that.",
            "So we have this difference between syntax and semantics.",
            "One way of thinking of syntax is it's this interface.",
            "From what you hear in your sensory motor interface, or that you try and say by speaking.",
            "And your conceptual intentional interface.",
            "That is your your meaning in your head.",
            "So just as an aside on this topic, one of the one of the places where field like linguistics, an machine learning, often don't sort of come together nicely, is that the way the different fields approach language.",
            "So the dominant sort of generative school in linguistics really approaches language from a tool for thought.",
            "So language is a way we can structure our thought as a tool for helping us think, generally in sort of machine learning world we approach language from an empirical communication point of view.",
            "It's a tool for communicating between people.",
            "And these are quite different views of language.",
            "And lead to quite different.",
            "Hypothesis, but it's good to keep these in mind because often different fields will get crossed wires on how they're describing problems, and important to think that often a linguist is thinking of language in terms of the way we structure our thoughts, not necessarily the way we communicate.",
            "It's one of the great questions about.",
            "What is the actual reality of language?",
            "Which one came first, the way we think in a hierarchical structured fashion or the way we communicate?"
        ],
        [
            "So why do I say that language is hierarchy?",
            "What is the evidence for this?",
            "So a classic example is the way we create questions from statements.",
            "So if we have a statement like the students are enjoying the lecture and we want to turn this into a yes, no question, we would take the are the auxiliary and we will move it to the front of the sentence.",
            "So we could say other students enjoying the lecture.",
            "And so if you wanted to derive an empirical rule for this process, you might say that the way we convert a statement to a question is to take the first auxiliary, the R, and move it to the front.",
            "This process is called often called auxiliary fronting."
        ],
        [
            "But this is a bad rule because imagine we have an extra clause in there, so we have other students who are sleeping, enjoying the lecture.",
            "Now, of course, if we take the first auxiliary and move it to the front, we get a badly formed ungrammatical sentence.",
            "So we get other students who sleeping are enjoying the lecture.",
            "And that's clearly nonsense.",
            "We have to take the second one.",
            "So our rule is no good.",
            "Now, this may seem simple, but why is it that we take that second one?",
            "It's because it's in a structural relationship.",
            "The verb are the auxiliary is in a structural relationship with the students who are sleeping.",
            "The students who are sleeping is the subject of that verb."
        ],
        [
            "And it's this this idea of structure relationships that lead to a hierarchical understanding of language.",
            "So if we look at the way we might think of these sentences hierarchically, just ignoring any sort of linguistic labels or anything like that, we can see that there is some constituent students which is the subject being.",
            "Interacting with this other constituent which is headed by the auxiliary and in the first example we see that we take the ring to the front.",
            "In the second example we see that because you are sleeping as part of this, the subject then again we take the auxiliary that's after that and bring it to the front.",
            "So now we can understand these processes in terms of the hierarchical structure of language and.",
            "Many phenomena or phenomenon we look at the language exhibit this same property that there's these hierarchical structures and many of the transformations are relationships between different ways of saying things the way we make active sentence is passive, and all these sorts of things.",
            "Done so in terms of this hierarchical structure, so the structure is there."
        ],
        [
            "But our models, the current state of the art models don't capture it, so there's a great paper that I've just stolen some figures and tables from that was published last year in tackle that looked at recurrent neural networks and how much of this sort of hierarchical structure they can capture.",
            "And so here's a here's a sentence.",
            "The keys to the camera on the table.",
            "And here we see that the auxiliary verb are has to agree with the subject.",
            "So if we have the keys, then we need R. If we had the key to the cabinet, then we would have is on the table.",
            "So if the subject was singular, we would need is if when it's plural we use our so there's this agreement going on.",
            "And again, this is mediated by the structure of the sentence.",
            "So if we had the keys are on the table, it's easy to see that the.",
            "Verb must agree with the previous noun phrase, but then we've inserted to the cabinet in there as well, and the cabinet is singular, so that creates a distracter that we might be confused.",
            "And so if we just look at the most recent verb, it's singular, but if not the most recent one that matters, it's the subject of the verb that matters.",
            "So again, we see this structural property, and in this paper.",
            "Authored by telling them they looked at a number of different tasks with recurrent networks and try to tease apart whether they can capture these sorts of dependencies.",
            "So you can think with your recurrent neural network language model as you're predicting this sentence, the keys to the cabinet.",
            "It should give higher probability to R than is.",
            "So they look at four different tasks depending on whether they use supervision, so they can just roll out the keys to the cabinet and then predict a label, plural or singular.",
            "They looked at the first one number prediction.",
            "They looked at the second one where they actually say what the verb is.",
            "Sorry, that's confusing, but they give the.",
            "The singular form of the verb, and so the model knows what the verbs, and then it has to choose where it's the singular plural.",
            "That's the verb inflection.",
            "Grammaticality is just where it gets the whole sentence, and has to say whether it's grammatical or not.",
            "And the language model, the last one, is really the one we should be interested in.",
            "And that's if you train a big language model and just ask it what verb should come next.",
            "After this, the start of this sentence is prefix, and so he doesn't give higher probability to the right.",
            "That agrees with the subject or not.",
            "So this is a nice setup because what we can do is we can look at different numbers of distractors.",
            "So to the cabinet there we can say is a distracter and we can lovely hierarchical structure of language means we can just keep putting things in there and taking the subject further and further away from the verb.",
            "So the keys to the cabinet that are on the.",
            "The case of the Cabinet which are blue, are on the table or something like that.",
            "We can keep putting more information in there that doesn't change the agreement.",
            "And test how well models."
        ],
        [
            "Cope with that.",
            "So on the left.",
            "So these are taken from their paper.",
            "Is the error rate on these problems.",
            "I think this is just the number prediction problem with no intervening nouns.",
            "And the bottom the X axis areas distance.",
            "So number of words between the noun and the subject.",
            "But there's no distracting nouns, and you'll see that the model is pretty much perfect.",
            "There's a slight degradation with length, but you're going pretty much no error, so this is a recurrent neural network trained to do this, so it's.",
            "So it's very good at just remembering what the last nouns count, whether a thorough or singular and just carrying that forward until it sees the verb and getting the right inflection.",
            "Getting the agreement now on the right hand side is when we have attractors or these other nouns in there that could confuse the model, like in the previous example, and we can put more and more of these in SO11 tractor or two, or three or four.",
            "And now we see that the performance degrades rapidly, so the different colors there are these different cases.",
            "Bottom, So the one that's most interesting to us.",
            "Really.",
            "The language modeling ones.",
            "So you look at the red line, their language modeling, you see.",
            "It starts out with very low error when there's no attractors, but as soon as we start putting nouns in between the verb and the subject, the error rapidly degrades.",
            "And this is true of all of the ones that the model does slightly better when it's trained specifically just on this classification task.",
            "But you can see the pattern is clear, basically recurrent networks.",
            "They're perfectly good at catching things and then getting the right agreement sequentially in the future, but they're not good at discovering hierarchical structure and the language models in these cases have not discovered the hierarchical structure of language did not discovered that those attractors are not relevant to the prediction, and all they have to do is remember the subject when they come to productive.",
            "So This is why I like this paper, 'cause it's really getting at this problem that well, these models are the state of the language modeling, and they're great models.",
            "There's still a lot that they're not capturing, so there's still a lot of room for improvement there, and they're really not getting at the structure of language.",
            "OK."
        ],
        [
            "So how do we get the structure of language so?",
            "In this next section I'm going to introduce class of models called Recurrent neural network grammars, which are a way of taking a recurrent neural network and setting it up so it will generate trees.",
            "In computational linguistics, we always like to have our trees upside down so we always go from the root downwards for some reason.",
            "There's no reason they could be the other way around, but for some reason we have them upside down.",
            "So I say that I mean given enough data, recurrent neural networks will learn this stuff.",
            "There are universal approximators, you give them huge amounts of data, they'll learn the distribution if they've got enough hidden units, etc.",
            "But what we should really be interested in in a lot of the problems facing, but particularly language, we should be less obsessed about sort of accuracy or blue scores, are all these sorts of things and more obsessed about sample complexity.",
            "'cause that's what really we have to care about.",
            "If at some point we want to get to sort of really interesting AI, we need to be able to learn faster because our models take far too much data to learn at the moment.",
            "So the fact that RNS will learn this stuff given huge amounts of data.",
            "Tells us that we should search for models which are going to learn the more quickly.",
            "And this is very true of sort of classic sequence to sequence models versus attention.",
            "By adding that extra bias of attention, we get a model that learns much more faster, much more quickly, and that's the sort of thing we should be searching for.",
            "So in language we should be looking for these sort of hierarchical biases that give us this sort of fast learning, good sample complexity."
        ],
        [
            "So recurrent neural network grammars or our NGS or model, introduced by Chris Dyer last year.",
            "There are a top down left to right generative process for trees.",
            "So think of the tree and the string at the bottom.",
            "We're going to start at the top and generate down the left side.",
            "In left to right generative process.",
            "And so this is So what we do is we structure the problem of generating a string an it's tree, like a sequential generation problem for recurrent neural network.",
            "And what we do is add in extra especially latent symbols which give the tree structure and I'll come to these.",
            "And what's going to happen is that sub sequences like these constituents, hopefully belonging to these sort of phrases.",
            "There are attractors appeared in in that in that paper get compressed so that in our sequential RNM sequence we can compress constituents down to a single representation.",
            "Anne.",
            "So yes, the base of this model.",
            "Basically it's an RNN, but now we've introduced extra symbols which have a particular interpretation semantics which give us the process of generating the tree, and they tell us when do we compress a constituent.",
            "When do we generate word?"
        ],
        [
            "So I'm going to run through an example generation in an RNG for this simple sentence, which turned out to be true earlier, so the happy students applaud.",
            "So we're going to generate this little tree.",
            "In a left out top down, left to right fashion."
        ],
        [
            "And we're going to do this using.",
            "What's called a shift reduce stack type parser, so we're going to start out.",
            "With.",
            "An action to generate the top of our tree S is the start symbol you think of or sentence so empty there says the action is introducing S, so this is the output.",
            "The first output from our current new network.",
            "So we start we introduce an S and we have a distribution on the right there.",
            "So top is just like our starter like in our in language model you have started sentence.",
            "We have taught that's the start of our sequence.",
            "So we always are going to generate more generally an S at the top of our sentence.",
            "So that's our first action, and then what we're going to do is put that action onto our stack on the left.",
            "We're going to build up things on that STACK which are going to allow us to represent the tree.",
            "So then we've got an S on the stack, and we're going to produce a next action so condition so that probability there says conditioned on the top of the stack being an S, what's the probability going to probability over actions and this time I'm going to choose to introduce a nonterminal called an NP, and NP is just sort of linguistic term for noun phrase.",
            "That means something like the cat or the dog, or in this case the students.",
            "And we're going to keep doing this.",
            "So now we've got SNP on the top there, and we're going to have another operation called generate for Jenn here.",
            "And that means generator, a leaf of the tree, a terminal.",
            "So, given that we've got an SMP on the stack, we're going to distribution over what to do next, and we're going to sample that.",
            "We should generate the lexical item, though.",
            "OK, now we've got this stack.",
            "We got three items on the stack there, three different items, SMP and the.",
            "We're going to generate again, and we're going to get happy, hopefully matching our right derivation.",
            "So now we've got four things we're going to keep doing this.",
            "I'm going to generate students.",
            "So now it should get a little bit more interesting.",
            "Now we've got that happy students on our stack, and if you can remember our derivation from earlier, those those words form a constituent.",
            "So we have another operation that's reduced.",
            "So now.",
            "There just memory conditioning on everything on the stack.",
            "Still nothing's changed.",
            "I just ran out of room so now we sample reduce action and what that means is take those three things on the stack there, happy students, and we're going to reduce them down to a single item on the stack.",
            "So in terms of our current network, those three are going to be represented by three vectors after the reduce operation, they're going to be compressed down to one vector that represents them in the sequence.",
            "So I show that by showing them as one green long constituent.",
            "So now we've only got two things on the stack.",
            "We've got an S start symbol and we've got a noun phrase, the happy students.",
            "So we're going to keep going through this process.",
            "Next, we're going to do nonterminal verb phrase.",
            "Put that on the stack.",
            "We're going to generate the lexical item, applaud and then so on and so on.",
            "So again, we put applaud on we reduce the verb phrase becomes an item on the stack.",
            "We generate our.",
            "Because it's nice to have a full stop on the universe sentence.",
            "We reduce again and we get one item on the stack, which is the whole derivation.",
            "So this is a generative process for derivations of trees.",
            "But it's also just a sequence, so we're just making a sequence of decisions that we can model with the recurrent network.",
            "And that means each time we might choose one of these actions, we're conditioning on all the actions we chose in the past.",
            "So we are compressing that history."
        ],
        [
            "Now it's important that for every series of these actions that they only lead to one tree string pair.",
            "When you have multiple ways of deriving the same tree, we call that spurious ambiguity.",
            "In some syntactic theories permit this, but for our convenience we really want just a unique sequence of these actions to give us one tree string pair.",
            "Then that means that we can very easily calculate the probability just like we do for any language model simply by taking the product of the operations that we chose.",
            "So just like our language model, we take the product of all our probabilities to get their probability of a string.",
            "In this case, for our trees, we just take the probability of all their actions and we get the probability value our tree.",
            "So now we have a nice recurrent model of generating trees and their strings.",
            "That's just structured like a recurrent network and gives us valid probabilities."
        ],
        [
            "So if we look at what's going on when we're doing these conditional probabilities, so I said at this point we're choosing some action A and we're conditioning on what's on the stack.",
            "This was the state where we had four items on the stack.",
            "S the NP the happy Students of EP that was introduced yet and applaud, and we choose some action.",
            "In this case, it would have been reduced to VP applaud there, but you can see above that is the corresponding recurrent network abstracted away the lower parts and you can see that our current network encoding of this context is just going to look at this as one unit.",
            "The Happy students all becomes one step in that recurrent network and VPN applaud.",
            "And if you think about it, you can start hopefully to see how this can help us solve some of those problems about models becoming to understand how a subject would agree with its verb, because the subject gets nicely compressed down to one unit of representation."
        ],
        [
            "So the question is, how do we actually do this?",
            "So the way once we've generated these reduced phrases like this NP for the happy students, we then embed it just like any sort of sequence embedding model.",
            "In this case, Chris used bidirectional recurrent network, so we took that phrase once it was reduced, ran recurrent networks in both directions.",
            "Across it he appends some control symbols that either side the MPs, so that gives a recurrent network, some extra information about what it's embedding.",
            "So you run this, you take the two endpoints of recurrent network, concatenate them together.",
            "And that's the representation for this phrase.",
            "So each time the models reducing a phrase and then build the representation for it and pushes that into the recurrent network in place of the whole phrase.",
            "We can do this recursively, so if it was a happy if it was, the phrase was the happy students in the lecture Theatre.",
            "So if we add that prepositional phrase, then that itself would be another level in the hierarchy that would have been embedded with bidirectional recurrent network and that would be inserted into this MP's just a single symbol and its single representation in the embedding process.",
            "So we're getting this hierarchical compression of the the sequence as we're generating it.",
            "So this is."
        ],
        [
            "In one sense, is exactly what we.",
            "We want for modeling language because we get this structure.",
            "There is of course a catch and there's always a downside, and so we don't actually observe this structure when we get sentence is on the web or anywhere else.",
            "So it's a question relevant.",
            "Sorry, can you say that?",
            "So because each of the decisions the."
        ],
        [
            "When we choose an action, it's probabilistic, so we're getting a distribution over actions, so any ambiguity in the structure will be encoded in that probability distribution.",
            "So if you have like an attachment ambiguity, like.",
            "I demand so the dog with the telescope and you have a question, is the dog holding the telescope or is the man holding the telescope?",
            "That will give you different series of actions and so they will give you a different series of samples from the conditional distribution and hence different probabilities.",
            "So all of the syntactic attachment ambiguity is in the distribution, hopefully."
        ],
        [
            "So yes, the key problem is that we don't observe these trees in the wild.",
            "In fact, it's not exactly clear what the right ones would be if you got the group of linguist together and ask them for a syntactic theory as old jokes go.",
            "If you got together probably 11 different theories.",
            "So well, syntax is definitely a thing.",
            "There's a lot we can agree on.",
            "There's still a lot people don't agree on, but.",
            "So in general, we've now we've got a nice model, but it's not necessarily trivial how we train that.",
            "If we're lucky, we might have a tree bank full of sentence is nicely annotated with the trees that go along with them according to something syntactic theory.",
            "So these exist.",
            "The Penn Treebank is a classic one that you would often hear about, so we can train these models in a supervised fashion.",
            "That is, we take a tree bank like the Penn Treebank or this treebanks for other languages as well.",
            "And we just treat those latent for any tree.",
            "We can map it onto a series of actions, and so we can treat those actions of the.",
            "We don't have to do any sort of inference over them, so that's the supervised case in the unsupervised case.",
            "We would have to marginalized them out.",
            "We then have a second decision is that we want to build a generative model or a discriminative model.",
            "So what I described as a generative model, that is, we have a model that generates the lexical items.",
            "The actual words, the happy students and it gives us a joint distribution over trees and strings that if we marginalized will sum to one.",
            "The discriminative cases where we treat the string is observed and we just got a conditional distribution over the trees.",
            "So rather than getting the probability of tree and string, we get the probability of tree given string.",
            "So that's a discriminative case.",
            "Most work in supervised parsing builds discriminative models 'cause they just care about the trees.",
            "It's not exactly clear well not to me.",
            "There's some argument this what the use of.",
            "Actually just pausing to get trees is because they're not that useful in order themselves, but it is clear what the use of generative models is, because that's what we use in all our language modeling, machine translation, etc.",
            "So really, from my point of view, it really should be the generative models that we care about.",
            "We are interested in not producing trees, were interested, interested in models that understand language, and happen to have trees as part of that link process.",
            "So the difference in this criminal cases is essentially rather than that generate generate action.",
            "We just have an action which shifts the words on because they're observed they don't need to be generated."
        ],
        [
            "So as I said, this is Christine's work, and he these are the results you came up with, which I may be wrong, but I probably still a state of the art for passing on this data set, and so there's a whole lot of results dating back to start petrols work in his thesis, all sorts of different models, or else model there, which is a sequence to sequence learning model, and right at the bottom we have the generative version of this RNG, and you can see it works.",
            "It does very well.",
            "And for this task, which had stagnated for a long time, a few percent lower than that, it's actually a pretty good achievement to get that sort of accuracy on passing, but the really cool thing is that the generative model works better than the discriminative model, and this is.",
            "This is unusual, yes, but it's cool because it now means that we have a generative model that we know gives good trees 'cause we're seeing it here in terms of the performance.",
            "But we can actually generate strings from it.",
            "We can actually use it for generating problems, which is what we really care about, not producing trees."
        ],
        [
            "So if we care about using it as a language model that we might want to say, well, how does it do as a language model now?",
            "As I said, there's a few problems here.",
            "1 to get the probability of a string P of X, we have to marginalized out the trees.",
            "Now that means some overall possible trees.",
            "There's an exponential number of them for a given string with a lot of parser carefully structured with Markov assumptions so that you can do that marginalization.",
            "This is not one of them, because we have that recurrent network in there.",
            "There's no way that we can do a dynamic program overall trees.",
            "So the only way we could marginalized would be to enumerate the exponential number and some of their probabilities.",
            "Obviously we can't do that, so Chris used Monte Carlo approximation together.",
            "That is, sampling small set so these are results when he trained on a supervised.",
            "This was on the Penn Treebank, but it's a different Penn Treebank language modeling set up to the one that's popular, mostly because the one that's popular isn't properly grammatical because of the filtering that's being done.",
            "So this is on the original with.",
            "All of the sort of unfiltered bits there.",
            "And it works at least in.",
            "This is a relatively small evaluation, but having the syntactic structure in there and trying to marginalise it out does give you better perplexities.",
            "Just like the other recurrent network results, you would want to sort of stress test this in larger situations.",
            "Give model to get an approximate posterior and do this more efficient.",
            "So you could then set it up like a variational autoencoder or something like that.",
            "I don't think anyone tried something like that.",
            "I think I'm trying to remember.",
            "I think Chris was using important sampling.",
            "To do the approximation but.",
            "We or discriminatively trained model for doing Q of why given it to the proposal Now, I think what was the proposal?",
            "He may have just been sequentially sampling and doing it like a particle filter, but not not a.",
            "Probably the best way to do it would be a proper particle filter with with important resampling and everything.",
            "I think he may have just been doing greedy sampling and then importantly, waiting.",
            "But that's really the big caveat with.",
            "These models are beautiful model captures.",
            "Lots about language, but we have this latent variable that is difficult to deal with and this is always a sort of conundrum.",
            "In this sort of modeling, do we introduce these discrete latent variables, which are very informative and capture the structure?",
            "Or do we go with something more continuous that we can back propagate through but might not be so nicely structured?",
            "Question.",
            "Yeah.",
            "Flights that you had to internal.",
            "How you get the conditional if you would just want the so why being the tree if you just want probably the tree given X then that was."
        ],
        [
            "Where so in the bottom there?",
            "If we just replace that generate action with the shift action.",
            "Basically it just means before when we worked out the probability of generating the next word.",
            "If it's observed, we just remove that probability.",
            "So it's just conditioned directly on.",
            "We can do some other tricks, so if you're conditioning on the string you can look at the future so you can also, when you're doing these actions, you can incorporate an extra vector which might be a recurrent embedding of the future.",
            "You can't do that with the generative model because you haven't generated the future.",
            "But that's often why discriminative models do better, because you can include extra conditioning.",
            "OK."
        ],
        [
            "So.",
            "To summarize the RNG, so I think we got this lovely model.",
            "It really captures the bias that we think is there, but we have this problem that we'd still we don't observe this syntax, at least most of the time.",
            "There's this another great follow up paper by Adi Concur that was at ESL this year, which they were bit deeper into what these models are learning, and it turns out things like even the labels on the constituents you don't actually.",
            "Need to observe those the embeddings you end up learning for the constituents.",
            "Nicely predict NP or VP and all these sorts of things.",
            "The other thing to realize is that.",
            "This is presented as a model of language, but what we really producing here is a hierarchical model of any sort of sequential input.",
            "So lots of work in other areas, like program induction.",
            "These different problems, that number are you talking about program induction?",
            "OK, well things done, those interested in you can also attack them from similar sorts of models, so you can think of here we think of phrases and constituents in a hierarchy.",
            "You can also think of programs and procedures and.",
            "Calling other programs in a similar sort of hierarchy.",
            "So that."
        ],
        [
            "Models and I think more people should use them.",
            "OK, so now we're going to take that that basic model simplify it a little bit and then apply it in a slightly different way.",
            "Which is to say, well, maybe we don't observe the trees, but maybe we're doing some sort of task like classifying strings into into categories or their sentiment, or something like that.",
            "And maybe we can use that classification task to ground the structure of the trees.",
            "That is, can we use the signal from that classification task to choose what is a good tree for that problem?",
            "So miss."
        ],
        [
            "Some work that Danny Yoga Tama did it I clear and the idea is to use reinforcement learning to try and choose a good tree for a given task.",
            "So I've been saying most of the time in report we don't observe the trees.",
            "We can get these treebanks, but they're small there and they often don't project across domains nicely.",
            "So in this.",
            "In this setting here, we're going to assume that we have strings.",
            "We have some sort of hierarchical model for embedding them down to a representation.",
            "Then, given that representation, we're going to do some downstream task and take the signal from that task to try and choose what a good tree is.",
            "To do that embedding.",
            "OK, so there's been lots of work on unsupervised grammar induction, something I did lots of in the past, and normally what you do is you have a generative model like the RNG there that assigns a likelihood to a string, and then you maximize likelihood of the data.",
            "So you try and choose trees and maximize the likelihood of the data you observe.",
            "So this is slightly different setting where we're trying to learn the trees, not by maximizing the likelihood of the strings, but by maximizing the downstream task."
        ],
        [
            "OK, so this falls under the category of embedding models 'cause we're trying to take a string and embed it down to a vector for our task.",
            "There's been lots of work on this, roughly sort of in the deep learning world categorized along.",
            "We can use convolutional neural networks to do this.",
            "We can use recurrent networks to do this, and also recursive networks which are sort of recurrent networks, but in a hierarchical hierarchical fashion.",
            "So all of these are being applied to learning these embeddings, and this work essentially fits.",
            "And the recursive network similar very similar to what Sam Bowman did, except where he observed the trees where using the reinforcement learning to try and discover them from the task."
        ],
        [
            "OK, so quick review of different ways we can do.",
            "Encoding, so a classic way is to use a recurrent network.",
            "So here we just run the recurrent network across the input and produce the output.",
            "And the red the red box.",
            "There is supposed to be our final embedding that we're going to feed to our classifier.",
            "But as I."
        ],
        [
            "Pain sort of saying repeatedly through today.",
            "Recurrent networks are not actually great.",
            "Getting the hierarchical structure of this, so we might not necessarily expect them to be good at embedding it."
        ],
        [
            "So recursive neural networks proposed by Richard circa.",
            "Instead, do a bottom up embedding of the input.",
            "They assume some sort of tree, or there was also a variant that would sort of choose a tree greedily, but in those arrows as a binary composition, each time to yellow box.",
            "So that's some function that takes the embeddings of the children and combines them to an embedding for the constituent.",
            "And does that recursively up the tree.",
            "Every yellow box has the same embedding function.",
            "That's why we call it a recursive network, and again we end up with a final embedding for the sentence at the output.",
            "So normally you would assume that you have a syntactic parse of the tree and that you do your composition.",
            "Following that, an enrich its work.",
            "He showed that by assuming these trees, you could get slightly better results."
        ],
        [
            "The convolutional version of this is similar except now rather than assuming a particular tree, we sort of look at all.",
            "It's more like.",
            "Directed acyclic graph that we get where we get lots of crossing arrows feeding into higher and higher levels of representation, again finishing with our embedding at the top and hear each layer would have different.",
            "Different weights to different convolutions."
        ],
        [
            "So Danny's model essentially builds on the recursive network idea.",
            "And combine some of those ideas from the RNG earlier into a shift.",
            "Reduce parser that builds a structure bottom up, but does it.",
            "Not fixed to a particular tree, so this is not a generative model, so we don't have to generate the the string like we did for the RNG.",
            "So we have shift and reduce option action.",
            "So here shift is in replace of the generate option we had previously and we have the same sort of reduce option.",
            "So we have a buffer, and that's the string we're going to process, and the first thing we do is we shift the first symbol onto the stack, and then we have a on the stack.",
            "We shift again and we get boy.",
            "And then we're going to reduce and what we do when we reduce with this model is we take a binary model, so we're always reducing pairs.",
            "So we take the pairs.",
            "The two terminals that we're going to be doing, and we feed them into a tree LM.",
            "So that means as we go up the hierarchy, we're going to have it going for material SDM and all that real STM does.",
            "It's like the recursive network, except we have some of the properties of an LTM where we have a additive memory that propagates nicely in depth, so that's out.",
            "Composition function that realist LM is a composition function and we just keep doing this so we can shift again.",
            "And we take drags on there.",
            "And just like the RNG we're building these things up on the stack and then reducing them.",
            "So in this case we have to go past the verb.",
            "We get to the noun phrase here sled and will reduce that first.",
            "So now we end up with three things on the stack.",
            "We reduce again and will reduce the previous two things of the verb phrase.",
            "Now we end up with the noun phrase and verb phrase, and one more reduce and we end up with one whole analysis.",
            "So again, we're using the same sort of shift reduce architecture.",
            "Here, we're not generating the string, we just conditioning on it, and we're using the tree STM as a way of composing these representations up, and the final trailer steam output of this whole composition is going to be the representation we feed to our task."
        ],
        [
            "So just like the RNG, we can show that any sequence of these shift reduce actions give us a different tree and therefore a different representation at the end, and what we want to do is learn a model that learns good sequence of actions that lead to good representations, and the intuition is that composing things are any constituent together like the boy is a better idea than composing things earlier which are not together."
        ],
        [
            "So the idea here is to use reinforcement learning.",
            "In this case the reinforce algorithm to choose the optimal sequence.",
            "So the question is how do we choose an optimal sequence?",
            "So one way as I said previously, is to maximize the likelihood of the string we observe.",
            "But a different ways to say, well, we're using this representation to do something.",
            "So let's maximize the utility of whatever it is we're doing."
        ],
        [
            "So there's no supervisor on the trees.",
            "The only way we get supervision is in the downstream task.",
            "So, so the classic RL setup is that you're in a particular state.",
            "And you have a set of actions and an agent and Agent has a policy over what actions to take in a particular state and choose an action and the state of the world is updated and the agent goes on and choose more actions.",
            "And in this case the actions are going to be those shift and reduce actions.",
            "So in this setup the agent is deposer and it's choosing at each time step whether to shift or reduce.",
            "And the reward that we're going to use in reinforce is going to be the log likelihood of the downstream tasks.",
            "So the main task here is sentiment analysis, so it's going to be the log likelihood of predicting the correct sentiment label.",
            "And as I said, we're going to reinforce algorithm.",
            "So just to train a policy directly, so I'm not going to go into this.",
            "I think there's a whole another workshop on summer school memory."
        ],
        [
            "Forcement learning we get to learn more about that, but I'll reinforce a very simple algorithm.",
            "Sometimes works often doesn't work, but in this case it seems to work quite well.",
            "You have to have a small number of actions.",
            "It's not magic.",
            "OK, so these are results I grabbed from Danny's paper and.",
            "The story plays out nicely, so at the top there's various other ways of embedding these.",
            "These models embedding data.",
            "Either.",
            "Yeah, very simple and we've got various baselines, so an obvious approach is obviously a left to right LS TM is also an obvious question about do we need to go left or right?",
            "Why not right to left so we should ask what does the right right to left or left him do?",
            "Turns out is slightly worse, but.",
            "It seems logical that we process language left to right.",
            "Obviously you can do a bidirectional steam as well, and that's slightly better.",
            "Well, actually, it's about the same as left to right and then we look at the models using the shift reduce setup so we can do this with supervised syntax.",
            "That is, if we assume that we observe the trees from a tree bank and this is essentially what Sam Bowman did in his work previously, and that gives a good result compared to the previous ones.",
            "But the interesting thing is sorry, the question of.",
            "QikLink um, that's a good question.",
            "I don't know so.",
            "I normally say that the average length of a sentence well in news takes about 30 words.",
            "These will be shorter than not really news text, but there's probably somewhere 15 to 20 I would guess.",
            "There's not going to be the way the data was collected.",
            "There's not going to be very long strings that you get.",
            "Sometimes you're not going to get the 200 word sentences that occasionally short.",
            "So yes, continuing the nice result is that letting the structure be latent rather than supervised actually leads to better results in the downstream task.",
            "So that's interesting, but also not hugely different.",
            "But it does show that using reinforced to choose the structure rather than taking it as given.",
            "Gives us a slight improvement, is also just as an aside, there's some.",
            "For the last one, so the middle on the semi supervised is pre trained with the supervised syntax and then let go and then the last one is just no supervised syntax at all.",
            "So and we see basically gradient there that not bothering with supervised syntax helps now.",
            "There's been an assumption in everything that I've been saying, which is very common in the NLP world, but it is wrong that syntax sort of equals semantics.",
            "And as I said at the start, these two things are different so.",
            "You see a lot of work in NLP that says, OK, we should respect the hierarchical structure of language.",
            "So let's use a path tree.",
            "Let's compose our representation with the past tree.",
            "But the point of syntax is not to say that's the way, meaning composers.",
            "We know that semantics can diverge from the syntactic structure of a sentence, so they're not the same thing.",
            "The problem is that we have ways of parsing, but no one has really gotten very far with actual semantics, and there's even less agreement on semantic theories and syntactic ones, so we tend to trick treat.",
            "Proper semantics is just too hard and use syntax is outstanding, but in this case there's no real reason.",
            "Some weak reasons, but in general it's not necessarily assumed that we should compose the meaning of the sentence following the syntax.",
            "So the idea that on some sort of semantic task like sentiment prediction that a different composition works better is not in any way contradictory to that sort of syntactic theory.",
            "But it's an interesting thing, LLP that people just often say I'm going to do sort of something linguistically inspired.",
            "So I'm going to use a path tree and then predict something semantic off that, that's that, is in some sense sort of abusing the sense of syntax.",
            "OK."
        ],
        [
            "So an obvious question is what sort of trees does it learn and do they look logical anyway so?",
            "So I stole this slide from Danny and it's a bit convoluted, but if you can sort of read this.",
            "There you can see some rough sense.",
            "Yes there are.",
            "Boy is a noun phrase and that's being pulled into one constituent, his sled as a noun phrase.",
            "The snow is a noun phrase and somehow the full stops getting tacked on the end there.",
            "But there the noun phrase is sort of getting joined together.",
            "The verb drags is being composed with the subject, normally in a syntactic theory you would have the verb composed with the object.",
            "He slid through the.",
            "You said in this case, but that's not sort of too crazy, so that looks like a reasonable sort of structure."
        ],
        [
            "And here's another one that doesn't look so reasonable in this case.",
            "A home so this is family members standing outside a home.",
            "The noun phrase a home has been split up, which doesn't really make any sense.",
            "They should really be together, either in syntax or semantics, and that's been combined with outside a.",
            "So looking at these trees, they're not hugely consistent in saying that they're learning something really deep about language, but they it is interesting that we get this variance in result.",
            "There's obvious follow on work to this.",
            "As I said, traditionally unsupervised.",
            "Grammar induction models maximize likelihood of the strings.",
            "There's no reason why we can't combine those objective functions.",
            "It makes sense that we should maximize what we see in the string and the tasks.",
            "There's also a good psycholinguistic reasons that that might be more similar to what children do."
        ],
        [
            "OK, how am I doing?",
            "OK, so moving on to the last part of this lecture.",
            "So we first 2/3 of this lecture is really focused on this question of structure in language, in particular syntactic structure.",
            "And can we get this into the models and I presented some models which aimed to capture this.",
            "But there are some promising things, but there's still a great deal to be done.",
            "We still really don't know what the best way I've really capturing structure in our in our neural networks is.",
            "These models have taken the sort of hard latent variable version of this where we have discrete latent variables for the structure is also promising to ask other soft ways of doing this.",
            "The capture the structure.",
            "Now in the last section I'll talk less about hierarchical structure and more about how do we connect.",
            "Linguistic utterances with meaning.",
            "So if we have.",
            "We observe utterances like the dog or something like that.",
            "How do we connect those symbols with the actual meaning of a dog?",
            "The dog that we have in our head.",
            "We do it because we experience the world.",
            "But how can we get our models to do that?",
            "And this is this is a hard problem.",
            "An most of NLP is tackling this sort of problem in direct."
        ],
        [
            "Hey.",
            "OK.",
            "So now I'm going to talk a bit more about this problem of situating our agents in a world.",
            "In this case, is going to be simulated world and trying to get them to learn to connect language symbols there, observing where things in that world and then perform tasks.",
            "So this is sort of inspired by the question of if we want to get to an artificial intelligence that can understand language.",
            "What sort of training environment that we need to create for this agent, which is going to allow to do this.",
            "Most of the ways we're training our natural language systems at the moment and not plausable ways of getting to any real sort of language understanding.",
            "You're not going to build bigger and bigger, more complicated models of sentiment analysis and suddenly have an agent that understands all of language.",
            "None of the tasks that we really doing at the moment are going to get us there as I sort of claimed earlier.",
            "Language modeling hides a lot of.",
            "Flexity of language within that task, but it's hard to see how a model will ever actually solve that language modeling problem without access to a world to understand what the symbols it's manipulating actually mean.",
            "So it's interesting question to ask is what is the sort of minimally adequate sort of environment that would allow us to get to the point of real language understanding?",
            "So in NLP as I said, we tend to our sense of grounding in appears often in terms of labels like sentiment labels for the input symbols or document labels like categories, politics etc.",
            "So that sort of grounding or in some cases we ground in terms of the other linguistic symbols.",
            "So if you think about word embedding work where we learn lexical semantic representations of words there grounded in terms of the words they Co occur with.",
            "So we learn the meaning of dog which is a.",
            "A symbol in our input from its distribution over other symbols in our input.",
            "So this is a sort of circular semantics, and that means it's very hard to learn certain properties.",
            "We can learn distributional properties, but it's very hard to learn other properties.",
            "So for instance, it's very hard to learn spatial things, so if you have the words behind and in front from a distribution model, you're never going to learn what behind and in front actually mean.",
            "So if I say is behind be, then you know that bees in front of a for those two things hold in front of behind their opposites.",
            "But you're never going to learn that from analyzing the distribution of the word in text, we know that because we're situated in the world and we've learned to ground these terms, so there's a lot of language that you cannot get simply from that distribution.",
            "There's a lot you can.",
            "There's a lot you can't as well.",
            "So the question is, how do we get this sort of thing into our models?",
            "Yeah.",
            "Observing a dialogue and somebody says, oh, it's behind that it's behind the bottle.",
            "Oh, move the bottle and then you'll see it like that.",
            "I feel like you can't say definitively that you can't get it from language.",
            "I agree it's hard.",
            "The question is whether you really understand the meaning of infant behind, or whether you can use them in appropriate ways.",
            "I think it would be hard to see how you would.",
            "I mean, obviously if your measure of understanding is can you match the distribution, then in the limit of seeing all of the data, you should be able to match the distribution.",
            "But in the sense of.",
            "Coming into an understanding of language quickly from limited data, it seems hard to see how you could ever capture those sorts of things.",
            "I mean, even things like behind themselves are very complicated.",
            "So if I'm looking at something and there's a tree, and I say that John is behind the tree, how far does John have to move away from that tree before?",
            "I wouldn't say he's behind it so we can go a bit and I still says behind it a bit further and behind it.",
            "At some point I'm going to say, well, he's not really behind it anymore, so even things like that are a distribution you can't.",
            "Write down a rule for when a is behind be and when it's not and different people will give you different judgments on those things, and also depends on scale.",
            "If John is behind a mountain is a very different judgment from John is behind a tree.",
            "OK. Well, I had another example of empty empty we we can think of.",
            "We ground the semantics of one language.",
            "In the other we learned the meaning of dog by its translation in another language.",
            "And again, there's a sense of grounding the meaning there, but it's slightly."
        ],
        [
            "Regular sense.",
            "And that we don't ever have to understand what a dog is to produce the right translation.",
            "So an obvious place to go to for inspiration is humans, so there are example of language learners.",
            "The question is what sort of environment do humans learn language, the language acquisition, acquisition is one of the great problems of linguistics and psycholinguistics and.",
            "A number of areas and is still a great mystery.",
            "There's so much that we don't really understand about how children learn language, but there's a lot of data we have about how they do, and it does contradict a lot of people's intuitions in the machine learning community.",
            "You'll often hear people speaking about how we need agents that can interact with the world, can feel things, and talk to teachers and all this sort of thing to learn language.",
            "But we have a lot of evidence that children learn language without any of these things well, without most of these things.",
            "Children learn with minimal direct teaching.",
            "Parents often think that they teach me.",
            "Parents often think that they teach children their children language.",
            "They say that's a dog and that's a cat.",
            "But children learn language themselves from their environment, and parents have actually relatively little influence on that.",
            "So this model of teaching language by direct.",
            "Direct explanation is not necessarily.",
            "It does not necessarily match the data.",
            "We have.",
            "Children learn language simply from their environment.",
            "You put a child in an environment where people are speaking the language to each other and they will learn language.",
            "We know this because children learn language and amazingly diverse and adverse environment.",
            "So children are horribly abused in families, will still learn language even if no one talks to them just from being around people speaking language but also children learn language from all sorts of different input.",
            "Blind children, learn language just fine.",
            "Often they learn it in a different way, too excited child.",
            "Instance there's various observations that blind children learn the sense of a preposition preposition like on in terms of, put something on.",
            "So put on your shoes before they learn the bottle is on the table where is assigned.",
            "A child might learn the reverse and you can see why this is the case because the blind child will not often see or will not see bottles on tables that will have to be described to them, but I'll often put on their socks or their shoes themselves.",
            "There's an interesting differences, but the most interesting thing is no.",
            "Children often take different paths and have different input.",
            "They all all, unless in sort of dire circumstances, end up at the same point, and that's very good comprehension of language.",
            "And it really takes pretty serious problems to stop that.",
            "So deaf children learn language just fine, depending on what other issues they have.",
            "But if this is the only one they learn language just fine.",
            "The interesting thing is, as I understand it, I'm not an expert in this.",
            "As I understand it, there's no evidence of children learning language from reading.",
            "So if a child is just taught language from visual symbols, they can't learn it.",
            "Inability.",
            "So you have children that can't move, so have disabilities such they can't move.",
            "Learn language fine children that can't interact with their environment at all.",
            "Depending on going often, children have other disabilities that do tend to.",
            "If you're if you're blind, can't move, tends to get very hard at death.",
            "But if you just can't move but can see and speak, you'll still learn language fine, you don't.",
            "Speaking or something.",
            "Well, speaking is a way to interact with others, but you don't necessarily need to feel objects or understand things in that way.",
            "Obviously this is a very large part of children's development.",
            "Exploring the world and feeling things.",
            "But the question I'm asking here is what is the minimal?",
            "And it turns out that it seems like the minimal is actually very minimal.",
            "So in terms of input, we know that there's various studies of sort of tribes in South America that show that children can learn language with.",
            "I think the result is something like 60 hours of actual direct conversation, everything else indirect.",
            "So there's a tribe that carries children on their back and never actually speaks to them, but they still learn language just fine from.",
            "There are deaf and repair, and they are born in an adversarial environment where people don't point to think, do any sort of science to them.",
            "There's obviously limits and I couldn't tell you what they are, but the interesting thing is that the general robustness of this process, so yes.",
            "Always a limit that some point children will not learn language.",
            "There's lots of other sorts of things, so there's various brain injuries a child can have which affect parts of the brain that to do with language.",
            "Yet still they learn to speak language for other sorts of process is so they might learn the different way.",
            "And all these sorts of things.",
            "But the interesting thing is just how robust language acquisition is in children and the other thing is that for getting all these disabilities, just ordinary children.",
            "Always learn language.",
            "It's not like they fail.",
            "It's not like our agents where we might launch 100 agents and just one of them actually learn something and all of the other sort of learn nothing.",
            "Children always learn we don't get this case where we say are sort of little Johnny or Johnny didn't learn language.",
            "He was here.",
            "He had a bad initializer and.",
            "And didn't learn language.",
            "Language learning in children is just incredibly robust.",
            "Anyway, I'm going on a bit of a sidetrack here, so I'm not going to solve all of these problems, but it's a good problem for us to think about is what would be environments that would satisfy this.",
            "As you can see, there is no one answer, so it seems like the connection of audio input and vision is a good starting point.",
            "But of course blind children learn language, so there's other routes to this.",
            "So here's what I'm going to discuss.",
            "Is a very sort of simple starting point for this, obviously not claiming to solve all of these problems, but is a simple 3D World we built with some language input.",
            "To get agents to do tasks, and here I'm sort of conflicting with a few of these things.",
            "'cause this is a very teacher driven setup."
        ],
        [
            "OK, so this environment that we're using is based on DeepMind lab.",
            "So Deep Mind released this.",
            "3D game environment.",
            "I think it was around Christmas last year.",
            "That you can this open source.",
            "There's a GitHub repository there you can build agents based on this, so it's a great environment for training agents.",
            "It's based on the Quake 3 engine open Arena I think, so you get it's not the most modern game engine, but it's not the worst either."
        ],
        [
            "So the basic setup is you have these agents out sort of orb there, and in the basic DeepMind lab you have input from pixel, so the agent gets to observe the pixels on the screen from its current viewpoint, and you can also input a reward if it does something right, and so here little Apple means maybe if it picks up the Apple it will get a reward.",
            "So you can define these rewards and set up different tasks to test out agents, and you can do all sorts of things like navigation and all sorts of different problems and transom agents, and there's been quite a lot of papers from deep mind using this environment and then we have a set of actions.",
            "The classic sort of ones you would assume from this sort of game environment so we can move.",
            "We can strafe jumping and things like this.",
            "Most of these aren't relevant for various tasks.",
            "Mostly you just want to be able to move around and look around."
        ],
        [
            "Now OK, so I have a little just little bit.",
            "This is just a classic DeepMind lab setup of an agent.",
            "This is a human playing this.",
            "Sorry, just exploring the environment.",
            "So this is what it looks like and you can have objects here.",
            "These are apples and the idea is that the apples or some sort of rewarding.",
            "Rewarding symbol.",
            "OK, probably don't need all that."
        ],
        [
            "So that was our starting point, and so we wanted to add language to this environment.",
            "So we essentially just add an extra channel of input to our agents and they can receive text based utterances and so here's some screenshots of what it looks like.",
            "The utterances across the top.",
            "This is actually fed directly to the agent.",
            "It doesn't have to get it from the pixels or anything like that.",
            "It's getting the the string.",
            "Input and what we want to do is build little task.",
            "So this says red object next to the green object and that's telling the agent that has to explore its environment and find the red object that is next to a green object and grab that object.",
            "And so the idea is that we added this language channel.",
            "Then we came up with various sort of language tasks for the agent to do and write up from.",
            "Starting from simple things like get the Apple two more relative things like this.",
            "So to understand when something is next to something else is a more challenging problem.",
            "We can describe objects in terms of well, colors of their neighbors, also in terms of rooms, so they see that the rooms have funny colored floors, so we can refer to that so we can talk about the blue room.",
            "So get the Apple in the blue room as opposed to the pink room or something like that.",
            "We also have.",
            "Yeah, so this is the language side is very simple.",
            "Just generated from basic basic scripts, so there's nothing terribly complicated going on the language.",
            "There's no sort of hierarchical composition.",
            "There's some minimal composition in that we can compose adjectives and nouns.",
            "And simple prepositional phrases like in the blue room.",
            "These sorts of things so very simple language, and we're really just at the starting point of in this environment where we have very low level input in terms of pixels.",
            "And we have very delayed reward in terms of the agent has to take many actions that might be hundreds of actions to get the right object.",
            "Can we teach the agent to ground the language?",
            "Can we?",
            "Can it discover that the the symbol green in there refers to this color?",
            "Can it discover that hat or something like that refers to a hat shape?",
            "And so we know that in sort of image net like situations we can do this in static 2D images.",
            "This is getting more challenging one because the reward is delayed to these objects look different from.",
            "Different viewpoints, so you have to understand what they look like from different views.",
            "We also have scales so we can have big hats, small hats and we ask questions about relative size.",
            "So get the biggest object and things like this.",
            "The other aspect, of course, is the agent is intentional.",
            "It can move about the environment so it performs actions and it can change what it's looking at.",
            "And we want to learn."
        ],
        [
            "All of these things together into in, so we specify the general layouts of the tasks of problems of language and then these are generated.",
            "From a script so that we can get billions of different combinations to train our agents on."
        ],
        [
            "OK, so the basic lexecon that we use is this.",
            "So we have 40 different shapes, 13 colors pattern shades and we can combine all of these so you can see that the if you take the set of product of this we have a very large space of objects so we can take.",
            "The objects are very strange for some reason in this decline lab, we have an interesting choice of objects, so like giant giant floating toothbrushes and things like this.",
            "So these agents learn some strange.",
            "Objects, but we have.",
            "This is the infantry have the one we're working with and then so for each shape you can choose different colors.",
            "They can have patterns, so they're going to be checkered with two different colors, stripe.",
            "These sorts of things we're going to have shades so light, dark and neutral, and we can have sizes small, medium, large.",
            "That way we can ask questions about that.",
            "Pick the darker hat or the largest toothbrush or something like this.",
            "So we have this space of objects and colors and patterns and such and the product space is quite large."
        ],
        [
            "OK, so this.",
            "Looks that way cause this.",
            "So this is a sort of sort of medley video of a trained agent that's trained to do multiple different language tasks going about in the DeepMind lab world.",
            "Doing these tasks and I'll just play this to give you an idea of what it looks like.",
            "So this is an agent ranges from nothing but the pixels and the language input.",
            "So it learns to get objects which are next to other objects, and now it's looking for the blue object next to the green object.",
            "That doesn't look very good, so see the TV's only have their color on one side, so the agent learns to wait for them to turn around, which is sort of cool.",
            "So we have problems like where it has to just get all of 1 color of object.",
            "Is it still reinforce?",
            "So I'll say a bit more about the agent, but the basic agent is a 3C and then we also augmented it with some auxiliary's.",
            "So this is 1 where it's got to look for the green room, so it doesn't want that magenta object, but it wants not that guitar.",
            "As I said, the objects are a bit strange, floating guitars etc.",
            "There's the comb.",
            "At the bottom are the numbers.",
            "Sorry, these numbers on the bottom don't really mean anything, they're just artifact of the.",
            "Of the game environment.",
            "And as I said, the instruction is coming through a separate channel, so it doesn't actually have to read those pixels or anything.",
            "So that one's quite cool that Caesar read object.",
            "And when you when you look at these things from above, so the agent doesn't get to see this.",
            "But this is what the agent looks like when it's doing this an it does start to look really intentional.",
            "Look, it's going for the red object, sees what's next to it and go straight for it.",
            "So it waits for the TV to turn around.",
            "It's the wrong one.",
            "It doesn't have diagonal stripes, so it goes to look somewhere else.",
            "It's waiting for that one now, but it seems that one in the distance and it looks good, doesn't have very good memory.",
            "That still sort of weights to be sure.",
            "Yes, a tape.",
            "OK, so that's."
        ],
        [
            "That's what the trained agent ended up doing.",
            "So as I said, the language is very simple, but just in that simple language we can explore quite a lot of interesting sorts of problems.",
            "Can the agent learn to interpret combinations of attitude, and now that's never seen before?",
            "Do these tasks where it has to understand something relative objects relative to other objects.",
            "So what was the actual agent look like?",
            "So their starting point is a 3C.",
            "That we sort of ad diagram here.",
            "At the bottom we have going in the pixels for the image.",
            "It goes into a convolution network.",
            "We have a ladder as the sole linguistic symbol.",
            "Here are some minimal utterance if the task was just get the ladder that goes into an STM.",
            "Obviously a bit of overkill for one symbol, but if you have a whole phrase that's more useful that feeds up into into a composition analysis team for the agent and then from that we have the policy and the value function so.",
            "That's a class."
        ],
        [
            "A 3C"
        ],
        [
            "So as I was showing the results, that doesn't actually work in this situation, so we need to augment it.",
            "So we augment this with various auxiliary's.",
            "This is similar to the Unreal Agent that was published from Deep Mind.",
            "I clear where we've got things that are P, there is reward prediction.",
            "So that's where the agents predicting from frames whether it's going to reward or not.",
            "Soon value replay is where it replays episodes and optimize the value function with Q learning.",
            "LP is language prediction and think I've got these so that more."
        ],
        [
            "Interesting ones for our case.",
            "Pacific to this language setup is language prediction, so that's given and given a visual frame, try and predict the tasks that would go along with this.",
            "So if you see in a minimal sort of example, if you see a ladder and a can like that then you get the agent should be predicting that the instruction is either lateral can or maybe it's pink or red or something like that.",
            "So that's an auxiliary task we can learn and the second one is the auto encoder which tries to predict given the current frame.",
            "And an action.",
            "What will the next frame look like?",
            "So a classic sort of auto encoding, although it's not quite auto encoding 'cause we also condition on the action.",
            "Now these are reasonably obvious auxillaries, but they're also interesting because they overlap quite a lot with what we think children do in their learning environment.",
            "So as I said, children learn a lot of language, not directly from their parents, but just from the environment, and they seem to be doing this using basic language modeling type problems.",
            "There constantly hearing language, and they're in their head predicting what's going to come next, and they're learning, essentially learning a language model to go from their environment and what they're going to do next.",
            "Do this visually as well.",
            "There's lots of intuitive physics experiments where you can sort of roller ball down the slope behind.",
            "Some obstruction and the child will expect the ball to roll out the other side if it has a model of physics in its head, and if it doesn't, then it will be surprised we can do the same thing for language, we can show that children are predicting what comes next in a language, because if we mess with that, they are surprised in some way when it doesn't happen.",
            "So, so we're interested in taking sort of inspiration from this an encoding.",
            "These sorts of auxiliary's as well."
        ],
        [
            "Now so it doesn't work, so this is what it looks like.",
            "So the Gray line along the bottom here.",
            "These are training episodes.",
            "On the bottom there's a very large numbers.",
            "I'll come back to that in a moment and reward on the Y axis.",
            "That Gray line along the bottom is basically a 3C.",
            "In these setups, it really doesn't learn.",
            "If you get very simple setups where you're very close to the object's, a 3C might work, but we really need to add these auxiliary to get it to work, and you see that each time we add improve things and we end up with an agent at the end there that's using all of these different auxilaries and it's working quite well.",
            "So when we start to add these unsupervised signals, so the agents actually at every step it's doing something and getting some sort of signal.",
            "Then we start to see learning."
        ],
        [
            "OK, so just like in the video, this is just another diagram of an agent doing a task, so this was green object next to the blue object and the black path is the path it took.",
            "So it looked at the chair there and what is that?",
            "I think that was a cake.",
            "I should be better at recognizing these objects and then it goes back into the other room and look for the right one."
        ],
        [
            "OK.",
            "Allowed.",
            "You always say like the blue guitar next to the red table, even if there's only one movie star.",
            "So it varies, so normally they will be distracted, so there might be 2 blue guitars and it has to choose.",
            "So yeah normally there are distractors so.",
            "Information.",
            "Yes, it depends on the task.",
            "So we got a mixture of tasks.",
            "Sometimes the tasks are just one sort of task, like they always get the something next to something and we just see whether we can train agent just to do that and other times like the agent I showed earlier, it will be trained on a whole variety of different tasks and there yes it could be just something like get the get the green object or something like that.",
            "If it was unambiguous.",
            "Integrated music player.",
            "Maybe I mean if we connect this to sort of our world, we sort of do the opposite.",
            "Humans are very good at using pragmatics to sort of under specify the description, so there's classic examples where like this class example, you have three faces, an one has glasses on another glasses and a hat, and the third one has neither.",
            "And if someone wants to pick out the person with glasses but not a hat, they'll say the person with glasses.",
            "And although the person with glasses and a hat also has glasses out of pragmatic interpretation is if if I meant the one with the hat, I would have said that so humans are sort of the opposite.",
            "In weekend we didn't find interesting ways to under specify we're not getting any of that here, but that would be a very interesting thing.",
            "In pragmatics is really interesting because coming back to sort of how good children are learning language.",
            "The other thing about when children learn language is we almost never give them the literal expression that they need to interpret.",
            "We're almost always as humans using some sort of pragmatic expression like.",
            "When I say when I want you to pass assault, I don't say pass assault.",
            "I said can you please pass the salt and you know that I don't.",
            "I'm not asking you a question, I'm saying pass itself, but if you think about many of the things you will say to each other into children, you're almost always using some sort of pragmatic interpretation.",
            "It's not literal, so if you think about the poor child, it's trying to learn languages they actually often don't get the literal interpretation they have to do some sort of pragmatic inference.",
            "OK, I'm getting distracted.",
            "OK, OK this was this is a short video showing.",
            "This language prediction auxiliary so at the top is just the maximum from the distribution of what the agent is predicting from its visual scene.",
            "So here it's looking at a key and it's predicting the symbol key and you'll see that changes.",
            "It sometimes predicts the color, and that's just the distribution changing, but that's what this auxiliary looks like.",
            "It's just slow down here, so it's a bit easier to see, so it's approaching.",
            "It's constantly learning and that basically helps it learn to segment the world.",
            "So it's got the segment the world of pixels into objects, so it can ground them in the symbols.",
            "Now sort of the key task for this agent.",
            "Learning that this set of pixels are stripy set corresponds to the sort of stripey hat and you see it's language prediction is sort of oscillating between different things, so see this chair and it thinks it's large.",
            "That looks like a large share it share large.",
            "Etc."
        ],
        [
            "OK, this is the next frame prediction.",
            "It's actually reasonably hard to interpret this, but this is what it looks like when it's on the top left is what season in the other all the other frames are sort of what it's predicting in its encoder for different actions so that each one is a different action, like go backwards, look right and what it predicts.",
            "There's not a huge amount of variance."
        ],
        [
            "There.",
            "OK, so curriculum is important for these.",
            "Get the agents to learn the complex tasks.",
            "So the language prediction the it's just getting the supervision comes from the task itself, so it as it's learning these tasks it has this very basically parallel data of tasks, utterances and the visual world and what it's doing is learning to predict one from the other.",
            "So it's basically just learning that I observed this language in this context and trying to learn to predict that.",
            "Yeah, OK, so curriculum is important for the complex tasks, so these sort of where we got multiple rooms in the agent has to explore.",
            "If you just start out with that, it doesn't learn very much, so we have various correct."
        ],
        [
            "So starting out with sort of 1 big room with different layouts and then getting increasingly complex here, the red line on the right there is what you get if you just try and train directly on that level.",
            "Whereas if you've trained on on level one, when you train on Level 2, the agent quickly maximizes the reward there.",
            "So 10 up there just means the agents doing it perfectly and again we see this as we get to more and more complex tasks.",
            "So here the difference is between two and three of the number of objects, different objects the agent may observe, and then the full set at the end.",
            "So for these agents at least, they need to start out with simple worlds and learning from that and simple spaces or objects before they get to more complicated ones.",
            "In order for good learning to occur."
        ],
        [
            "So we can probe sort of various generalizations beyond just whether they can do the task, and they generalize.",
            "So here we get sort of compositional generalization.",
            "So at training time we have different objects, different adjectives, and then at Test time we have combinations of adjectives and nouns that the agents never seen in training.",
            "And.",
            "As you can see in the left at the blue line is training.",
            "Red Line is testing, so the agents learn to generalize.",
            "They learn to combine sort of yellow mug, never having seen a yellow mug before."
        ],
        [
            "This also works in.",
            "In a situation where it's not given the individual items, if it's only ever season composed, it learns to decompose them, learn some decomposed green mug into green and mug, so then it can learn to interpret green prints pencil in terms of those."
        ],
        [
            "So this is pretty minimal composition, but it's the very starting point of if you think about sort of the most minimal composition you could do these.",
            "Relative, so as I said, we can change the sizes so we can compare two objects and ask for if the agent is 2 objects in the room.",
            "We can tell the agent to get the larger one.",
            "And it can have.",
            "It might have seen balls and know the larger ball, but never seen a pencil before, but can still learn to interpret which one is larger than the other."
        ],
        [
            "OK, coming back to that issue of sample complexity in all these plots.",
            "If you look at the X axis it looks a bit dire 'cause that's a lot of training episodes and as I said, the cool thing about children as they learn so quickly these agents don't learn quickly.",
            "They take a lot of training so our best agent there that's got all of the auxiliary's are still taking about quarter of a million episodes before it takes off with learning.",
            "So this is really the very sort of starting point for this sort of.",
            "Training an agent.",
            "Somehow we need to learn how to do this from a great deal less experience."
        ],
        [
            "OK, other cool things about the agent is so.",
            "Whether this is intuitive, not it's sort of interesting, but the more words and agent knows, the faster it learns other ones.",
            "So the red line there is just starting from scratch with an empty vocabulary.",
            "The green and blue lines.",
            "If the agent already knows a few words.",
            "And then these rewards are, on other words, as it tries to learn them.",
            "So if an agent already knows 2 words, which is the green line, then it very quickly starts to learn other words much more quicker, much more quickly than the red one.",
            "If it knows 20 words and it's very quick.",
            "This is."
        ],
        [
            "Interesting.",
            "So it's already been trained and get some perfect reward on those two words.",
            "And then that those results are on extra words as we add more words in.",
            "So an agent that knows the words it's already started to understand something about doing tasks that started to segment its world, and then it becomes much easier for it to integrate more words.",
            "So this may be a bit of a Longbow, but there's a great deal of interest in language acquisition at this idea of vocabulary spurt, which about 18 months old children go from learning very few words, maybe one a day or less to suddenly learning words very quickly, multiple words per day.",
            "And this is known as vocabulary spurt and it happened very rapidly and it changes a bit when it happens, but it's roughly around 18 months.",
            "These graphs on the right from actual children they suddenly take off in the number of words they know so that the left access areas a number of words.",
            "There's lots of theories about why this happens, and a good one is.",
            "It has to do with sort of the lexical network.",
            "As a child knows, knows more words than they can understand new words in the context of what they know.",
            "And it seems very similar to our agent, so once it knows a few words then it really takes off and can learn more very quickly."
        ],
        [
            "OK, so that's it for this lecture, so I've gone right through sort of hierarchical composition in language syntactic structure and then onto semantics and grounding.",
            "At the end, all of these things we're still a long way from human level processing.",
            "In both they are sort of models, understanding of syntactic structure in language and also in terms of these environments.",
            "Obviously they're incredibly simplistic in terms of what humans face and in terms of the.",
            "The problems but.",
            "There's lots of reasons we should be hopeful that we can tackle some of these problems, But some of the interesting ones are really not so much the models that we focus on all the time, but coming up with environments that really allow us to learn these things.",
            "So how can we extend these sorts of environments?",
            "They showed such that we can have agents really learn hierarchical compositional structure for language.",
            "How can we have them really learn large vocabularies which allow them to interpret the real world and all these sorts of things?",
            "But yes, that's it for me.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these questions are not nothing terribly modern about these questions are things are discussed in this lecture, are very old questions in linguistics, possibly from a modern perspective.",
                    "label": 0
                },
                {
                    "sent": "So much of this.",
                    "label": 0
                },
                {
                    "sent": "Work, maybe 2/3 is works at currently or recently being done at DeepMind, particularly from these people.",
                    "label": 0
                },
                {
                    "sent": "So Chris Dyer, Daniel Gatama, Felix healing, and did all this, all this work, and I borrowed many slides from their presentations.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the first lecture I introduced this idea of language modeling, talked about how we can do that with various neural networks, how we can apply that to problems like translation.",
                    "label": 0
                },
                {
                    "sent": "But there are some key sort of obvious language problems that we're still a long way from solving so well.",
                    "label": 0
                },
                {
                    "sent": "We can do very well modeling language with recurrent networks.",
                    "label": 0
                },
                {
                    "sent": "They're still not capturing what we understand to be the structure of language.",
                    "label": 1
                },
                {
                    "sent": "So in this lecture I'm going to have more deeply into these two key questions, so one is syntax that is the structure of language, the way, language way languages structure their presentation of meaning, and the second topic is semantics.",
                    "label": 0
                },
                {
                    "sent": "That is the meaning itself and where it comes from, and particularly this lecture we talking about grounding.",
                    "label": 0
                },
                {
                    "sent": "That is, how do we connect symbols that we see in language in our utterances with meaning in the world?",
                    "label": 0
                },
                {
                    "sent": "Which an agent is situated?",
                    "label": 0
                },
                {
                    "sent": "So these are things that have been discussed in the core of of linguistics, computational linguistics, NLP since their inception, but they're still very hard problems.",
                    "label": 0
                },
                {
                    "sent": "It's very hard.",
                    "label": 0
                },
                {
                    "sent": "There's lots of theories of syntax.",
                    "label": 0
                },
                {
                    "sent": "There's lots of theories of semantics, some more successful than others, but are still plenty of unknowns about what the right way of thinking about these problems.",
                    "label": 0
                },
                {
                    "sent": "In most state of the art models, neither of these things are really dealt with explicitly.",
                    "label": 0
                },
                {
                    "sent": "They often implicitly in their recurrent networks capture something of syntax, but they're not in there explicitly, and the same with semantics, we would say a machine translation system and neural empty system is definitely capturing aspect of meaning by being under translate from French into English, but it's not doing it in an explicit way, or a terribly nuanced way.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this afternoon I'm going to talk through roughly 3 topics.",
                    "label": 0
                },
                {
                    "sent": "First one is modeling hierarchical structure with recurrent network.",
                    "label": 1
                },
                {
                    "sent": "So how do we go from straight, flat, sequential networks to something that looks a bit more adequate for the structure that we know language has?",
                    "label": 0
                },
                {
                    "sent": "In the second section, all talk about how do we then take these ideas and tune them to some sort of downstream task?",
                    "label": 0
                },
                {
                    "sent": "And we think about this a little bit like grounding the structure of language with some downstream reward like classification sentiment analysis.",
                    "label": 0
                },
                {
                    "sent": "These sorts of things.",
                    "label": 0
                },
                {
                    "sent": "And in the third part I'll talk about how do we take this idea of grounding?",
                    "label": 0
                },
                {
                    "sent": "Further, less of the structure and how do we ground simple linguistic expressions in a world?",
                    "label": 0
                },
                {
                    "sent": "So in this case I'll look at training artificial agents in a 3 dimensional environment, having them do tasks and what we can, what we can learn and understand from that sort of problem.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's start with hierarchy.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Structure, so we've seen a lot of recurrent neural networks and we see that they are the state of the art for most problems and their exceptionally good at modeling sequences, but there's many things that they don't capture, and particularly they have this.",
                    "label": 1
                },
                {
                    "sent": "Bias for sequential dependencies and recency so they're good at capturing things that happened recently.",
                    "label": 0
                },
                {
                    "sent": "They could capturing sequential things, or, as I mentioned, the last lecture triggers.",
                    "label": 0
                },
                {
                    "sent": "So a particular thing happened to pass, so that can increase probability in the future, but they're not really capturing high level hierarchical structures.",
                    "label": 1
                },
                {
                    "sent": "So we can we can enhance them with things like attention.",
                    "label": 0
                },
                {
                    "sent": "Obviously gating architectures improve some of these problems, but they don't remove them and LSD EM is still essentially modeling sequential recency.",
                    "label": 0
                },
                {
                    "sent": "So if we look to the field of linguistics and what it says about language, one of the key things of the generative School of linguistics, that is the one inspired by Chomsky, it's a key argument that language structures information hierarchically not sequentially, and this is really one of the key underpinnings of that that model of language.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these things are not terribly controversial.",
                    "label": 0
                },
                {
                    "sent": "I mean, language has syntax.",
                    "label": 1
                },
                {
                    "sent": "It has semantics.",
                    "label": 0
                },
                {
                    "sent": "These are two different things.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's easier to think of these things in terms of artificial languages like programming languages, something like Python.",
                    "label": 0
                },
                {
                    "sent": "It's easy to separate the meaning of a Python program from the valid ways you can write Python programs.",
                    "label": 0
                },
                {
                    "sent": "There's a valid way you can write a for loop in Python And there's lots of ways that are invalid or ungrammatical in that language, and then that for loop has some semantics away, it's executed.",
                    "label": 0
                },
                {
                    "sent": "So we can see in those languages are very clear.",
                    "label": 0
                },
                {
                    "sent": "Semantic syntax distinction.",
                    "label": 0
                },
                {
                    "sent": "The same exists in natural language.",
                    "label": 0
                },
                {
                    "sent": "It's not necessarily clear all the time where it is, but it's definitely there to language has this structure.",
                    "label": 1
                },
                {
                    "sent": "We can see this big cause we get these effects where we can think up grammatical utterances, and this is a classic one thought up by Chomsky color screen, orange asleep, furiously, that are perfectly grammatically well formed, but uh, semantically incoherent.",
                    "label": 0
                },
                {
                    "sent": "So there's no semantic meaning there.",
                    "label": 0
                },
                {
                    "sent": "Equally, we can jumble around words and create something that is neither grammatical nor semantically well formed, or we can come up with things that we can interpret semantically, button not grammatical.",
                    "label": 0
                },
                {
                    "sent": "So if I say something like John like Apple or something like that, so that's not grammatically well formed, but you'll have no trouble extracting meaning from that.",
                    "label": 0
                },
                {
                    "sent": "So we have this difference between syntax and semantics.",
                    "label": 0
                },
                {
                    "sent": "One way of thinking of syntax is it's this interface.",
                    "label": 0
                },
                {
                    "sent": "From what you hear in your sensory motor interface, or that you try and say by speaking.",
                    "label": 0
                },
                {
                    "sent": "And your conceptual intentional interface.",
                    "label": 0
                },
                {
                    "sent": "That is your your meaning in your head.",
                    "label": 0
                },
                {
                    "sent": "So just as an aside on this topic, one of the one of the places where field like linguistics, an machine learning, often don't sort of come together nicely, is that the way the different fields approach language.",
                    "label": 0
                },
                {
                    "sent": "So the dominant sort of generative school in linguistics really approaches language from a tool for thought.",
                    "label": 0
                },
                {
                    "sent": "So language is a way we can structure our thought as a tool for helping us think, generally in sort of machine learning world we approach language from an empirical communication point of view.",
                    "label": 0
                },
                {
                    "sent": "It's a tool for communicating between people.",
                    "label": 0
                },
                {
                    "sent": "And these are quite different views of language.",
                    "label": 0
                },
                {
                    "sent": "And lead to quite different.",
                    "label": 0
                },
                {
                    "sent": "Hypothesis, but it's good to keep these in mind because often different fields will get crossed wires on how they're describing problems, and important to think that often a linguist is thinking of language in terms of the way we structure our thoughts, not necessarily the way we communicate.",
                    "label": 0
                },
                {
                    "sent": "It's one of the great questions about.",
                    "label": 0
                },
                {
                    "sent": "What is the actual reality of language?",
                    "label": 0
                },
                {
                    "sent": "Which one came first, the way we think in a hierarchical structured fashion or the way we communicate?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why do I say that language is hierarchy?",
                    "label": 1
                },
                {
                    "sent": "What is the evidence for this?",
                    "label": 0
                },
                {
                    "sent": "So a classic example is the way we create questions from statements.",
                    "label": 0
                },
                {
                    "sent": "So if we have a statement like the students are enjoying the lecture and we want to turn this into a yes, no question, we would take the are the auxiliary and we will move it to the front of the sentence.",
                    "label": 0
                },
                {
                    "sent": "So we could say other students enjoying the lecture.",
                    "label": 1
                },
                {
                    "sent": "And so if you wanted to derive an empirical rule for this process, you might say that the way we convert a statement to a question is to take the first auxiliary, the R, and move it to the front.",
                    "label": 1
                },
                {
                    "sent": "This process is called often called auxiliary fronting.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But this is a bad rule because imagine we have an extra clause in there, so we have other students who are sleeping, enjoying the lecture.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, if we take the first auxiliary and move it to the front, we get a badly formed ungrammatical sentence.",
                    "label": 1
                },
                {
                    "sent": "So we get other students who sleeping are enjoying the lecture.",
                    "label": 0
                },
                {
                    "sent": "And that's clearly nonsense.",
                    "label": 0
                },
                {
                    "sent": "We have to take the second one.",
                    "label": 0
                },
                {
                    "sent": "So our rule is no good.",
                    "label": 0
                },
                {
                    "sent": "Now, this may seem simple, but why is it that we take that second one?",
                    "label": 0
                },
                {
                    "sent": "It's because it's in a structural relationship.",
                    "label": 0
                },
                {
                    "sent": "The verb are the auxiliary is in a structural relationship with the students who are sleeping.",
                    "label": 0
                },
                {
                    "sent": "The students who are sleeping is the subject of that verb.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it's this this idea of structure relationships that lead to a hierarchical understanding of language.",
                    "label": 0
                },
                {
                    "sent": "So if we look at the way we might think of these sentences hierarchically, just ignoring any sort of linguistic labels or anything like that, we can see that there is some constituent students which is the subject being.",
                    "label": 0
                },
                {
                    "sent": "Interacting with this other constituent which is headed by the auxiliary and in the first example we see that we take the ring to the front.",
                    "label": 0
                },
                {
                    "sent": "In the second example we see that because you are sleeping as part of this, the subject then again we take the auxiliary that's after that and bring it to the front.",
                    "label": 1
                },
                {
                    "sent": "So now we can understand these processes in terms of the hierarchical structure of language and.",
                    "label": 0
                },
                {
                    "sent": "Many phenomena or phenomenon we look at the language exhibit this same property that there's these hierarchical structures and many of the transformations are relationships between different ways of saying things the way we make active sentence is passive, and all these sorts of things.",
                    "label": 0
                },
                {
                    "sent": "Done so in terms of this hierarchical structure, so the structure is there.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But our models, the current state of the art models don't capture it, so there's a great paper that I've just stolen some figures and tables from that was published last year in tackle that looked at recurrent neural networks and how much of this sort of hierarchical structure they can capture.",
                    "label": 0
                },
                {
                    "sent": "And so here's a here's a sentence.",
                    "label": 0
                },
                {
                    "sent": "The keys to the camera on the table.",
                    "label": 0
                },
                {
                    "sent": "And here we see that the auxiliary verb are has to agree with the subject.",
                    "label": 0
                },
                {
                    "sent": "So if we have the keys, then we need R. If we had the key to the cabinet, then we would have is on the table.",
                    "label": 0
                },
                {
                    "sent": "So if the subject was singular, we would need is if when it's plural we use our so there's this agreement going on.",
                    "label": 0
                },
                {
                    "sent": "And again, this is mediated by the structure of the sentence.",
                    "label": 0
                },
                {
                    "sent": "So if we had the keys are on the table, it's easy to see that the.",
                    "label": 0
                },
                {
                    "sent": "Verb must agree with the previous noun phrase, but then we've inserted to the cabinet in there as well, and the cabinet is singular, so that creates a distracter that we might be confused.",
                    "label": 0
                },
                {
                    "sent": "And so if we just look at the most recent verb, it's singular, but if not the most recent one that matters, it's the subject of the verb that matters.",
                    "label": 0
                },
                {
                    "sent": "So again, we see this structural property, and in this paper.",
                    "label": 0
                },
                {
                    "sent": "Authored by telling them they looked at a number of different tasks with recurrent networks and try to tease apart whether they can capture these sorts of dependencies.",
                    "label": 0
                },
                {
                    "sent": "So you can think with your recurrent neural network language model as you're predicting this sentence, the keys to the cabinet.",
                    "label": 0
                },
                {
                    "sent": "It should give higher probability to R than is.",
                    "label": 0
                },
                {
                    "sent": "So they look at four different tasks depending on whether they use supervision, so they can just roll out the keys to the cabinet and then predict a label, plural or singular.",
                    "label": 0
                },
                {
                    "sent": "They looked at the first one number prediction.",
                    "label": 0
                },
                {
                    "sent": "They looked at the second one where they actually say what the verb is.",
                    "label": 0
                },
                {
                    "sent": "Sorry, that's confusing, but they give the.",
                    "label": 0
                },
                {
                    "sent": "The singular form of the verb, and so the model knows what the verbs, and then it has to choose where it's the singular plural.",
                    "label": 0
                },
                {
                    "sent": "That's the verb inflection.",
                    "label": 0
                },
                {
                    "sent": "Grammaticality is just where it gets the whole sentence, and has to say whether it's grammatical or not.",
                    "label": 0
                },
                {
                    "sent": "And the language model, the last one, is really the one we should be interested in.",
                    "label": 0
                },
                {
                    "sent": "And that's if you train a big language model and just ask it what verb should come next.",
                    "label": 0
                },
                {
                    "sent": "After this, the start of this sentence is prefix, and so he doesn't give higher probability to the right.",
                    "label": 0
                },
                {
                    "sent": "That agrees with the subject or not.",
                    "label": 0
                },
                {
                    "sent": "So this is a nice setup because what we can do is we can look at different numbers of distractors.",
                    "label": 0
                },
                {
                    "sent": "So to the cabinet there we can say is a distracter and we can lovely hierarchical structure of language means we can just keep putting things in there and taking the subject further and further away from the verb.",
                    "label": 0
                },
                {
                    "sent": "So the keys to the cabinet that are on the.",
                    "label": 0
                },
                {
                    "sent": "The case of the Cabinet which are blue, are on the table or something like that.",
                    "label": 0
                },
                {
                    "sent": "We can keep putting more information in there that doesn't change the agreement.",
                    "label": 0
                },
                {
                    "sent": "And test how well models.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cope with that.",
                    "label": 0
                },
                {
                    "sent": "So on the left.",
                    "label": 0
                },
                {
                    "sent": "So these are taken from their paper.",
                    "label": 0
                },
                {
                    "sent": "Is the error rate on these problems.",
                    "label": 0
                },
                {
                    "sent": "I think this is just the number prediction problem with no intervening nouns.",
                    "label": 0
                },
                {
                    "sent": "And the bottom the X axis areas distance.",
                    "label": 0
                },
                {
                    "sent": "So number of words between the noun and the subject.",
                    "label": 0
                },
                {
                    "sent": "But there's no distracting nouns, and you'll see that the model is pretty much perfect.",
                    "label": 0
                },
                {
                    "sent": "There's a slight degradation with length, but you're going pretty much no error, so this is a recurrent neural network trained to do this, so it's.",
                    "label": 0
                },
                {
                    "sent": "So it's very good at just remembering what the last nouns count, whether a thorough or singular and just carrying that forward until it sees the verb and getting the right inflection.",
                    "label": 0
                },
                {
                    "sent": "Getting the agreement now on the right hand side is when we have attractors or these other nouns in there that could confuse the model, like in the previous example, and we can put more and more of these in SO11 tractor or two, or three or four.",
                    "label": 0
                },
                {
                    "sent": "And now we see that the performance degrades rapidly, so the different colors there are these different cases.",
                    "label": 0
                },
                {
                    "sent": "Bottom, So the one that's most interesting to us.",
                    "label": 0
                },
                {
                    "sent": "Really.",
                    "label": 0
                },
                {
                    "sent": "The language modeling ones.",
                    "label": 0
                },
                {
                    "sent": "So you look at the red line, their language modeling, you see.",
                    "label": 0
                },
                {
                    "sent": "It starts out with very low error when there's no attractors, but as soon as we start putting nouns in between the verb and the subject, the error rapidly degrades.",
                    "label": 0
                },
                {
                    "sent": "And this is true of all of the ones that the model does slightly better when it's trained specifically just on this classification task.",
                    "label": 0
                },
                {
                    "sent": "But you can see the pattern is clear, basically recurrent networks.",
                    "label": 0
                },
                {
                    "sent": "They're perfectly good at catching things and then getting the right agreement sequentially in the future, but they're not good at discovering hierarchical structure and the language models in these cases have not discovered the hierarchical structure of language did not discovered that those attractors are not relevant to the prediction, and all they have to do is remember the subject when they come to productive.",
                    "label": 0
                },
                {
                    "sent": "So This is why I like this paper, 'cause it's really getting at this problem that well, these models are the state of the language modeling, and they're great models.",
                    "label": 0
                },
                {
                    "sent": "There's still a lot that they're not capturing, so there's still a lot of room for improvement there, and they're really not getting at the structure of language.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we get the structure of language so?",
                    "label": 1
                },
                {
                    "sent": "In this next section I'm going to introduce class of models called Recurrent neural network grammars, which are a way of taking a recurrent neural network and setting it up so it will generate trees.",
                    "label": 0
                },
                {
                    "sent": "In computational linguistics, we always like to have our trees upside down so we always go from the root downwards for some reason.",
                    "label": 0
                },
                {
                    "sent": "There's no reason they could be the other way around, but for some reason we have them upside down.",
                    "label": 0
                },
                {
                    "sent": "So I say that I mean given enough data, recurrent neural networks will learn this stuff.",
                    "label": 1
                },
                {
                    "sent": "There are universal approximators, you give them huge amounts of data, they'll learn the distribution if they've got enough hidden units, etc.",
                    "label": 0
                },
                {
                    "sent": "But what we should really be interested in in a lot of the problems facing, but particularly language, we should be less obsessed about sort of accuracy or blue scores, are all these sorts of things and more obsessed about sample complexity.",
                    "label": 0
                },
                {
                    "sent": "'cause that's what really we have to care about.",
                    "label": 0
                },
                {
                    "sent": "If at some point we want to get to sort of really interesting AI, we need to be able to learn faster because our models take far too much data to learn at the moment.",
                    "label": 0
                },
                {
                    "sent": "So the fact that RNS will learn this stuff given huge amounts of data.",
                    "label": 1
                },
                {
                    "sent": "Tells us that we should search for models which are going to learn the more quickly.",
                    "label": 0
                },
                {
                    "sent": "And this is very true of sort of classic sequence to sequence models versus attention.",
                    "label": 0
                },
                {
                    "sent": "By adding that extra bias of attention, we get a model that learns much more faster, much more quickly, and that's the sort of thing we should be searching for.",
                    "label": 0
                },
                {
                    "sent": "So in language we should be looking for these sort of hierarchical biases that give us this sort of fast learning, good sample complexity.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So recurrent neural network grammars or our NGS or model, introduced by Chris Dyer last year.",
                    "label": 1
                },
                {
                    "sent": "There are a top down left to right generative process for trees.",
                    "label": 1
                },
                {
                    "sent": "So think of the tree and the string at the bottom.",
                    "label": 0
                },
                {
                    "sent": "We're going to start at the top and generate down the left side.",
                    "label": 1
                },
                {
                    "sent": "In left to right generative process.",
                    "label": 0
                },
                {
                    "sent": "And so this is So what we do is we structure the problem of generating a string an it's tree, like a sequential generation problem for recurrent neural network.",
                    "label": 0
                },
                {
                    "sent": "And what we do is add in extra especially latent symbols which give the tree structure and I'll come to these.",
                    "label": 0
                },
                {
                    "sent": "And what's going to happen is that sub sequences like these constituents, hopefully belonging to these sort of phrases.",
                    "label": 0
                },
                {
                    "sent": "There are attractors appeared in in that in that paper get compressed so that in our sequential RNM sequence we can compress constituents down to a single representation.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So yes, the base of this model.",
                    "label": 0
                },
                {
                    "sent": "Basically it's an RNN, but now we've introduced extra symbols which have a particular interpretation semantics which give us the process of generating the tree, and they tell us when do we compress a constituent.",
                    "label": 0
                },
                {
                    "sent": "When do we generate word?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to run through an example generation in an RNG for this simple sentence, which turned out to be true earlier, so the happy students applaud.",
                    "label": 0
                },
                {
                    "sent": "So we're going to generate this little tree.",
                    "label": 0
                },
                {
                    "sent": "In a left out top down, left to right fashion.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we're going to do this using.",
                    "label": 0
                },
                {
                    "sent": "What's called a shift reduce stack type parser, so we're going to start out.",
                    "label": 0
                },
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "An action to generate the top of our tree S is the start symbol you think of or sentence so empty there says the action is introducing S, so this is the output.",
                    "label": 0
                },
                {
                    "sent": "The first output from our current new network.",
                    "label": 0
                },
                {
                    "sent": "So we start we introduce an S and we have a distribution on the right there.",
                    "label": 0
                },
                {
                    "sent": "So top is just like our starter like in our in language model you have started sentence.",
                    "label": 0
                },
                {
                    "sent": "We have taught that's the start of our sequence.",
                    "label": 0
                },
                {
                    "sent": "So we always are going to generate more generally an S at the top of our sentence.",
                    "label": 0
                },
                {
                    "sent": "So that's our first action, and then what we're going to do is put that action onto our stack on the left.",
                    "label": 0
                },
                {
                    "sent": "We're going to build up things on that STACK which are going to allow us to represent the tree.",
                    "label": 0
                },
                {
                    "sent": "So then we've got an S on the stack, and we're going to produce a next action so condition so that probability there says conditioned on the top of the stack being an S, what's the probability going to probability over actions and this time I'm going to choose to introduce a nonterminal called an NP, and NP is just sort of linguistic term for noun phrase.",
                    "label": 0
                },
                {
                    "sent": "That means something like the cat or the dog, or in this case the students.",
                    "label": 0
                },
                {
                    "sent": "And we're going to keep doing this.",
                    "label": 0
                },
                {
                    "sent": "So now we've got SNP on the top there, and we're going to have another operation called generate for Jenn here.",
                    "label": 0
                },
                {
                    "sent": "And that means generator, a leaf of the tree, a terminal.",
                    "label": 0
                },
                {
                    "sent": "So, given that we've got an SMP on the stack, we're going to distribution over what to do next, and we're going to sample that.",
                    "label": 0
                },
                {
                    "sent": "We should generate the lexical item, though.",
                    "label": 0
                },
                {
                    "sent": "OK, now we've got this stack.",
                    "label": 0
                },
                {
                    "sent": "We got three items on the stack there, three different items, SMP and the.",
                    "label": 0
                },
                {
                    "sent": "We're going to generate again, and we're going to get happy, hopefully matching our right derivation.",
                    "label": 0
                },
                {
                    "sent": "So now we've got four things we're going to keep doing this.",
                    "label": 0
                },
                {
                    "sent": "I'm going to generate students.",
                    "label": 0
                },
                {
                    "sent": "So now it should get a little bit more interesting.",
                    "label": 0
                },
                {
                    "sent": "Now we've got that happy students on our stack, and if you can remember our derivation from earlier, those those words form a constituent.",
                    "label": 0
                },
                {
                    "sent": "So we have another operation that's reduced.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "There just memory conditioning on everything on the stack.",
                    "label": 0
                },
                {
                    "sent": "Still nothing's changed.",
                    "label": 0
                },
                {
                    "sent": "I just ran out of room so now we sample reduce action and what that means is take those three things on the stack there, happy students, and we're going to reduce them down to a single item on the stack.",
                    "label": 0
                },
                {
                    "sent": "So in terms of our current network, those three are going to be represented by three vectors after the reduce operation, they're going to be compressed down to one vector that represents them in the sequence.",
                    "label": 0
                },
                {
                    "sent": "So I show that by showing them as one green long constituent.",
                    "label": 0
                },
                {
                    "sent": "So now we've only got two things on the stack.",
                    "label": 0
                },
                {
                    "sent": "We've got an S start symbol and we've got a noun phrase, the happy students.",
                    "label": 0
                },
                {
                    "sent": "So we're going to keep going through this process.",
                    "label": 0
                },
                {
                    "sent": "Next, we're going to do nonterminal verb phrase.",
                    "label": 0
                },
                {
                    "sent": "Put that on the stack.",
                    "label": 0
                },
                {
                    "sent": "We're going to generate the lexical item, applaud and then so on and so on.",
                    "label": 0
                },
                {
                    "sent": "So again, we put applaud on we reduce the verb phrase becomes an item on the stack.",
                    "label": 0
                },
                {
                    "sent": "We generate our.",
                    "label": 0
                },
                {
                    "sent": "Because it's nice to have a full stop on the universe sentence.",
                    "label": 0
                },
                {
                    "sent": "We reduce again and we get one item on the stack, which is the whole derivation.",
                    "label": 0
                },
                {
                    "sent": "So this is a generative process for derivations of trees.",
                    "label": 0
                },
                {
                    "sent": "But it's also just a sequence, so we're just making a sequence of decisions that we can model with the recurrent network.",
                    "label": 0
                },
                {
                    "sent": "And that means each time we might choose one of these actions, we're conditioning on all the actions we chose in the past.",
                    "label": 0
                },
                {
                    "sent": "So we are compressing that history.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now it's important that for every series of these actions that they only lead to one tree string pair.",
                    "label": 1
                },
                {
                    "sent": "When you have multiple ways of deriving the same tree, we call that spurious ambiguity.",
                    "label": 0
                },
                {
                    "sent": "In some syntactic theories permit this, but for our convenience we really want just a unique sequence of these actions to give us one tree string pair.",
                    "label": 1
                },
                {
                    "sent": "Then that means that we can very easily calculate the probability just like we do for any language model simply by taking the product of the operations that we chose.",
                    "label": 1
                },
                {
                    "sent": "So just like our language model, we take the product of all our probabilities to get their probability of a string.",
                    "label": 0
                },
                {
                    "sent": "In this case, for our trees, we just take the probability of all their actions and we get the probability value our tree.",
                    "label": 0
                },
                {
                    "sent": "So now we have a nice recurrent model of generating trees and their strings.",
                    "label": 0
                },
                {
                    "sent": "That's just structured like a recurrent network and gives us valid probabilities.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we look at what's going on when we're doing these conditional probabilities, so I said at this point we're choosing some action A and we're conditioning on what's on the stack.",
                    "label": 1
                },
                {
                    "sent": "This was the state where we had four items on the stack.",
                    "label": 0
                },
                {
                    "sent": "S the NP the happy Students of EP that was introduced yet and applaud, and we choose some action.",
                    "label": 0
                },
                {
                    "sent": "In this case, it would have been reduced to VP applaud there, but you can see above that is the corresponding recurrent network abstracted away the lower parts and you can see that our current network encoding of this context is just going to look at this as one unit.",
                    "label": 0
                },
                {
                    "sent": "The Happy students all becomes one step in that recurrent network and VPN applaud.",
                    "label": 0
                },
                {
                    "sent": "And if you think about it, you can start hopefully to see how this can help us solve some of those problems about models becoming to understand how a subject would agree with its verb, because the subject gets nicely compressed down to one unit of representation.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the question is, how do we actually do this?",
                    "label": 0
                },
                {
                    "sent": "So the way once we've generated these reduced phrases like this NP for the happy students, we then embed it just like any sort of sequence embedding model.",
                    "label": 0
                },
                {
                    "sent": "In this case, Chris used bidirectional recurrent network, so we took that phrase once it was reduced, ran recurrent networks in both directions.",
                    "label": 0
                },
                {
                    "sent": "Across it he appends some control symbols that either side the MPs, so that gives a recurrent network, some extra information about what it's embedding.",
                    "label": 0
                },
                {
                    "sent": "So you run this, you take the two endpoints of recurrent network, concatenate them together.",
                    "label": 0
                },
                {
                    "sent": "And that's the representation for this phrase.",
                    "label": 0
                },
                {
                    "sent": "So each time the models reducing a phrase and then build the representation for it and pushes that into the recurrent network in place of the whole phrase.",
                    "label": 0
                },
                {
                    "sent": "We can do this recursively, so if it was a happy if it was, the phrase was the happy students in the lecture Theatre.",
                    "label": 0
                },
                {
                    "sent": "So if we add that prepositional phrase, then that itself would be another level in the hierarchy that would have been embedded with bidirectional recurrent network and that would be inserted into this MP's just a single symbol and its single representation in the embedding process.",
                    "label": 0
                },
                {
                    "sent": "So we're getting this hierarchical compression of the the sequence as we're generating it.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In one sense, is exactly what we.",
                    "label": 0
                },
                {
                    "sent": "We want for modeling language because we get this structure.",
                    "label": 0
                },
                {
                    "sent": "There is of course a catch and there's always a downside, and so we don't actually observe this structure when we get sentence is on the web or anywhere else.",
                    "label": 0
                },
                {
                    "sent": "So it's a question relevant.",
                    "label": 0
                },
                {
                    "sent": "Sorry, can you say that?",
                    "label": 0
                },
                {
                    "sent": "So because each of the decisions the.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we choose an action, it's probabilistic, so we're getting a distribution over actions, so any ambiguity in the structure will be encoded in that probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So if you have like an attachment ambiguity, like.",
                    "label": 0
                },
                {
                    "sent": "I demand so the dog with the telescope and you have a question, is the dog holding the telescope or is the man holding the telescope?",
                    "label": 0
                },
                {
                    "sent": "That will give you different series of actions and so they will give you a different series of samples from the conditional distribution and hence different probabilities.",
                    "label": 0
                },
                {
                    "sent": "So all of the syntactic attachment ambiguity is in the distribution, hopefully.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So yes, the key problem is that we don't observe these trees in the wild.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's not exactly clear what the right ones would be if you got the group of linguist together and ask them for a syntactic theory as old jokes go.",
                    "label": 0
                },
                {
                    "sent": "If you got together probably 11 different theories.",
                    "label": 0
                },
                {
                    "sent": "So well, syntax is definitely a thing.",
                    "label": 0
                },
                {
                    "sent": "There's a lot we can agree on.",
                    "label": 0
                },
                {
                    "sent": "There's still a lot people don't agree on, but.",
                    "label": 0
                },
                {
                    "sent": "So in general, we've now we've got a nice model, but it's not necessarily trivial how we train that.",
                    "label": 0
                },
                {
                    "sent": "If we're lucky, we might have a tree bank full of sentence is nicely annotated with the trees that go along with them according to something syntactic theory.",
                    "label": 0
                },
                {
                    "sent": "So these exist.",
                    "label": 0
                },
                {
                    "sent": "The Penn Treebank is a classic one that you would often hear about, so we can train these models in a supervised fashion.",
                    "label": 0
                },
                {
                    "sent": "That is, we take a tree bank like the Penn Treebank or this treebanks for other languages as well.",
                    "label": 1
                },
                {
                    "sent": "And we just treat those latent for any tree.",
                    "label": 1
                },
                {
                    "sent": "We can map it onto a series of actions, and so we can treat those actions of the.",
                    "label": 0
                },
                {
                    "sent": "We don't have to do any sort of inference over them, so that's the supervised case in the unsupervised case.",
                    "label": 1
                },
                {
                    "sent": "We would have to marginalized them out.",
                    "label": 1
                },
                {
                    "sent": "We then have a second decision is that we want to build a generative model or a discriminative model.",
                    "label": 1
                },
                {
                    "sent": "So what I described as a generative model, that is, we have a model that generates the lexical items.",
                    "label": 0
                },
                {
                    "sent": "The actual words, the happy students and it gives us a joint distribution over trees and strings that if we marginalized will sum to one.",
                    "label": 0
                },
                {
                    "sent": "The discriminative cases where we treat the string is observed and we just got a conditional distribution over the trees.",
                    "label": 0
                },
                {
                    "sent": "So rather than getting the probability of tree and string, we get the probability of tree given string.",
                    "label": 0
                },
                {
                    "sent": "So that's a discriminative case.",
                    "label": 0
                },
                {
                    "sent": "Most work in supervised parsing builds discriminative models 'cause they just care about the trees.",
                    "label": 0
                },
                {
                    "sent": "It's not exactly clear well not to me.",
                    "label": 0
                },
                {
                    "sent": "There's some argument this what the use of.",
                    "label": 0
                },
                {
                    "sent": "Actually just pausing to get trees is because they're not that useful in order themselves, but it is clear what the use of generative models is, because that's what we use in all our language modeling, machine translation, etc.",
                    "label": 0
                },
                {
                    "sent": "So really, from my point of view, it really should be the generative models that we care about.",
                    "label": 0
                },
                {
                    "sent": "We are interested in not producing trees, were interested, interested in models that understand language, and happen to have trees as part of that link process.",
                    "label": 0
                },
                {
                    "sent": "So the difference in this criminal cases is essentially rather than that generate generate action.",
                    "label": 0
                },
                {
                    "sent": "We just have an action which shifts the words on because they're observed they don't need to be generated.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as I said, this is Christine's work, and he these are the results you came up with, which I may be wrong, but I probably still a state of the art for passing on this data set, and so there's a whole lot of results dating back to start petrols work in his thesis, all sorts of different models, or else model there, which is a sequence to sequence learning model, and right at the bottom we have the generative version of this RNG, and you can see it works.",
                    "label": 0
                },
                {
                    "sent": "It does very well.",
                    "label": 0
                },
                {
                    "sent": "And for this task, which had stagnated for a long time, a few percent lower than that, it's actually a pretty good achievement to get that sort of accuracy on passing, but the really cool thing is that the generative model works better than the discriminative model, and this is.",
                    "label": 0
                },
                {
                    "sent": "This is unusual, yes, but it's cool because it now means that we have a generative model that we know gives good trees 'cause we're seeing it here in terms of the performance.",
                    "label": 0
                },
                {
                    "sent": "But we can actually generate strings from it.",
                    "label": 0
                },
                {
                    "sent": "We can actually use it for generating problems, which is what we really care about, not producing trees.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we care about using it as a language model that we might want to say, well, how does it do as a language model now?",
                    "label": 0
                },
                {
                    "sent": "As I said, there's a few problems here.",
                    "label": 0
                },
                {
                    "sent": "1 to get the probability of a string P of X, we have to marginalized out the trees.",
                    "label": 0
                },
                {
                    "sent": "Now that means some overall possible trees.",
                    "label": 0
                },
                {
                    "sent": "There's an exponential number of them for a given string with a lot of parser carefully structured with Markov assumptions so that you can do that marginalization.",
                    "label": 0
                },
                {
                    "sent": "This is not one of them, because we have that recurrent network in there.",
                    "label": 0
                },
                {
                    "sent": "There's no way that we can do a dynamic program overall trees.",
                    "label": 0
                },
                {
                    "sent": "So the only way we could marginalized would be to enumerate the exponential number and some of their probabilities.",
                    "label": 0
                },
                {
                    "sent": "Obviously we can't do that, so Chris used Monte Carlo approximation together.",
                    "label": 0
                },
                {
                    "sent": "That is, sampling small set so these are results when he trained on a supervised.",
                    "label": 0
                },
                {
                    "sent": "This was on the Penn Treebank, but it's a different Penn Treebank language modeling set up to the one that's popular, mostly because the one that's popular isn't properly grammatical because of the filtering that's being done.",
                    "label": 0
                },
                {
                    "sent": "So this is on the original with.",
                    "label": 0
                },
                {
                    "sent": "All of the sort of unfiltered bits there.",
                    "label": 0
                },
                {
                    "sent": "And it works at least in.",
                    "label": 0
                },
                {
                    "sent": "This is a relatively small evaluation, but having the syntactic structure in there and trying to marginalise it out does give you better perplexities.",
                    "label": 0
                },
                {
                    "sent": "Just like the other recurrent network results, you would want to sort of stress test this in larger situations.",
                    "label": 0
                },
                {
                    "sent": "Give model to get an approximate posterior and do this more efficient.",
                    "label": 0
                },
                {
                    "sent": "So you could then set it up like a variational autoencoder or something like that.",
                    "label": 0
                },
                {
                    "sent": "I don't think anyone tried something like that.",
                    "label": 0
                },
                {
                    "sent": "I think I'm trying to remember.",
                    "label": 0
                },
                {
                    "sent": "I think Chris was using important sampling.",
                    "label": 0
                },
                {
                    "sent": "To do the approximation but.",
                    "label": 0
                },
                {
                    "sent": "We or discriminatively trained model for doing Q of why given it to the proposal Now, I think what was the proposal?",
                    "label": 0
                },
                {
                    "sent": "He may have just been sequentially sampling and doing it like a particle filter, but not not a.",
                    "label": 0
                },
                {
                    "sent": "Probably the best way to do it would be a proper particle filter with with important resampling and everything.",
                    "label": 0
                },
                {
                    "sent": "I think he may have just been doing greedy sampling and then importantly, waiting.",
                    "label": 0
                },
                {
                    "sent": "But that's really the big caveat with.",
                    "label": 0
                },
                {
                    "sent": "These models are beautiful model captures.",
                    "label": 0
                },
                {
                    "sent": "Lots about language, but we have this latent variable that is difficult to deal with and this is always a sort of conundrum.",
                    "label": 0
                },
                {
                    "sent": "In this sort of modeling, do we introduce these discrete latent variables, which are very informative and capture the structure?",
                    "label": 0
                },
                {
                    "sent": "Or do we go with something more continuous that we can back propagate through but might not be so nicely structured?",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Flights that you had to internal.",
                    "label": 0
                },
                {
                    "sent": "How you get the conditional if you would just want the so why being the tree if you just want probably the tree given X then that was.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where so in the bottom there?",
                    "label": 0
                },
                {
                    "sent": "If we just replace that generate action with the shift action.",
                    "label": 0
                },
                {
                    "sent": "Basically it just means before when we worked out the probability of generating the next word.",
                    "label": 0
                },
                {
                    "sent": "If it's observed, we just remove that probability.",
                    "label": 0
                },
                {
                    "sent": "So it's just conditioned directly on.",
                    "label": 0
                },
                {
                    "sent": "We can do some other tricks, so if you're conditioning on the string you can look at the future so you can also, when you're doing these actions, you can incorporate an extra vector which might be a recurrent embedding of the future.",
                    "label": 0
                },
                {
                    "sent": "You can't do that with the generative model because you haven't generated the future.",
                    "label": 0
                },
                {
                    "sent": "But that's often why discriminative models do better, because you can include extra conditioning.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "To summarize the RNG, so I think we got this lovely model.",
                    "label": 0
                },
                {
                    "sent": "It really captures the bias that we think is there, but we have this problem that we'd still we don't observe this syntax, at least most of the time.",
                    "label": 0
                },
                {
                    "sent": "There's this another great follow up paper by Adi Concur that was at ESL this year, which they were bit deeper into what these models are learning, and it turns out things like even the labels on the constituents you don't actually.",
                    "label": 0
                },
                {
                    "sent": "Need to observe those the embeddings you end up learning for the constituents.",
                    "label": 0
                },
                {
                    "sent": "Nicely predict NP or VP and all these sorts of things.",
                    "label": 0
                },
                {
                    "sent": "The other thing to realize is that.",
                    "label": 0
                },
                {
                    "sent": "This is presented as a model of language, but what we really producing here is a hierarchical model of any sort of sequential input.",
                    "label": 0
                },
                {
                    "sent": "So lots of work in other areas, like program induction.",
                    "label": 0
                },
                {
                    "sent": "These different problems, that number are you talking about program induction?",
                    "label": 0
                },
                {
                    "sent": "OK, well things done, those interested in you can also attack them from similar sorts of models, so you can think of here we think of phrases and constituents in a hierarchy.",
                    "label": 0
                },
                {
                    "sent": "You can also think of programs and procedures and.",
                    "label": 0
                },
                {
                    "sent": "Calling other programs in a similar sort of hierarchy.",
                    "label": 0
                },
                {
                    "sent": "So that.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Models and I think more people should use them.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we're going to take that that basic model simplify it a little bit and then apply it in a slightly different way.",
                    "label": 0
                },
                {
                    "sent": "Which is to say, well, maybe we don't observe the trees, but maybe we're doing some sort of task like classifying strings into into categories or their sentiment, or something like that.",
                    "label": 0
                },
                {
                    "sent": "And maybe we can use that classification task to ground the structure of the trees.",
                    "label": 0
                },
                {
                    "sent": "That is, can we use the signal from that classification task to choose what is a good tree for that problem?",
                    "label": 0
                },
                {
                    "sent": "So miss.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some work that Danny Yoga Tama did it I clear and the idea is to use reinforcement learning to try and choose a good tree for a given task.",
                    "label": 0
                },
                {
                    "sent": "So I've been saying most of the time in report we don't observe the trees.",
                    "label": 0
                },
                {
                    "sent": "We can get these treebanks, but they're small there and they often don't project across domains nicely.",
                    "label": 0
                },
                {
                    "sent": "So in this.",
                    "label": 0
                },
                {
                    "sent": "In this setting here, we're going to assume that we have strings.",
                    "label": 0
                },
                {
                    "sent": "We have some sort of hierarchical model for embedding them down to a representation.",
                    "label": 0
                },
                {
                    "sent": "Then, given that representation, we're going to do some downstream task and take the signal from that task to try and choose what a good tree is.",
                    "label": 0
                },
                {
                    "sent": "To do that embedding.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's been lots of work on unsupervised grammar induction, something I did lots of in the past, and normally what you do is you have a generative model like the RNG there that assigns a likelihood to a string, and then you maximize likelihood of the data.",
                    "label": 0
                },
                {
                    "sent": "So you try and choose trees and maximize the likelihood of the data you observe.",
                    "label": 0
                },
                {
                    "sent": "So this is slightly different setting where we're trying to learn the trees, not by maximizing the likelihood of the strings, but by maximizing the downstream task.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this falls under the category of embedding models 'cause we're trying to take a string and embed it down to a vector for our task.",
                    "label": 0
                },
                {
                    "sent": "There's been lots of work on this, roughly sort of in the deep learning world categorized along.",
                    "label": 0
                },
                {
                    "sent": "We can use convolutional neural networks to do this.",
                    "label": 0
                },
                {
                    "sent": "We can use recurrent networks to do this, and also recursive networks which are sort of recurrent networks, but in a hierarchical hierarchical fashion.",
                    "label": 0
                },
                {
                    "sent": "So all of these are being applied to learning these embeddings, and this work essentially fits.",
                    "label": 0
                },
                {
                    "sent": "And the recursive network similar very similar to what Sam Bowman did, except where he observed the trees where using the reinforcement learning to try and discover them from the task.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so quick review of different ways we can do.",
                    "label": 0
                },
                {
                    "sent": "Encoding, so a classic way is to use a recurrent network.",
                    "label": 0
                },
                {
                    "sent": "So here we just run the recurrent network across the input and produce the output.",
                    "label": 0
                },
                {
                    "sent": "And the red the red box.",
                    "label": 0
                },
                {
                    "sent": "There is supposed to be our final embedding that we're going to feed to our classifier.",
                    "label": 0
                },
                {
                    "sent": "But as I.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pain sort of saying repeatedly through today.",
                    "label": 0
                },
                {
                    "sent": "Recurrent networks are not actually great.",
                    "label": 0
                },
                {
                    "sent": "Getting the hierarchical structure of this, so we might not necessarily expect them to be good at embedding it.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So recursive neural networks proposed by Richard circa.",
                    "label": 0
                },
                {
                    "sent": "Instead, do a bottom up embedding of the input.",
                    "label": 0
                },
                {
                    "sent": "They assume some sort of tree, or there was also a variant that would sort of choose a tree greedily, but in those arrows as a binary composition, each time to yellow box.",
                    "label": 0
                },
                {
                    "sent": "So that's some function that takes the embeddings of the children and combines them to an embedding for the constituent.",
                    "label": 0
                },
                {
                    "sent": "And does that recursively up the tree.",
                    "label": 0
                },
                {
                    "sent": "Every yellow box has the same embedding function.",
                    "label": 0
                },
                {
                    "sent": "That's why we call it a recursive network, and again we end up with a final embedding for the sentence at the output.",
                    "label": 0
                },
                {
                    "sent": "So normally you would assume that you have a syntactic parse of the tree and that you do your composition.",
                    "label": 0
                },
                {
                    "sent": "Following that, an enrich its work.",
                    "label": 0
                },
                {
                    "sent": "He showed that by assuming these trees, you could get slightly better results.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The convolutional version of this is similar except now rather than assuming a particular tree, we sort of look at all.",
                    "label": 0
                },
                {
                    "sent": "It's more like.",
                    "label": 0
                },
                {
                    "sent": "Directed acyclic graph that we get where we get lots of crossing arrows feeding into higher and higher levels of representation, again finishing with our embedding at the top and hear each layer would have different.",
                    "label": 0
                },
                {
                    "sent": "Different weights to different convolutions.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Danny's model essentially builds on the recursive network idea.",
                    "label": 0
                },
                {
                    "sent": "And combine some of those ideas from the RNG earlier into a shift.",
                    "label": 0
                },
                {
                    "sent": "Reduce parser that builds a structure bottom up, but does it.",
                    "label": 0
                },
                {
                    "sent": "Not fixed to a particular tree, so this is not a generative model, so we don't have to generate the the string like we did for the RNG.",
                    "label": 0
                },
                {
                    "sent": "So we have shift and reduce option action.",
                    "label": 0
                },
                {
                    "sent": "So here shift is in replace of the generate option we had previously and we have the same sort of reduce option.",
                    "label": 0
                },
                {
                    "sent": "So we have a buffer, and that's the string we're going to process, and the first thing we do is we shift the first symbol onto the stack, and then we have a on the stack.",
                    "label": 0
                },
                {
                    "sent": "We shift again and we get boy.",
                    "label": 0
                },
                {
                    "sent": "And then we're going to reduce and what we do when we reduce with this model is we take a binary model, so we're always reducing pairs.",
                    "label": 0
                },
                {
                    "sent": "So we take the pairs.",
                    "label": 0
                },
                {
                    "sent": "The two terminals that we're going to be doing, and we feed them into a tree LM.",
                    "label": 0
                },
                {
                    "sent": "So that means as we go up the hierarchy, we're going to have it going for material SDM and all that real STM does.",
                    "label": 0
                },
                {
                    "sent": "It's like the recursive network, except we have some of the properties of an LTM where we have a additive memory that propagates nicely in depth, so that's out.",
                    "label": 0
                },
                {
                    "sent": "Composition function that realist LM is a composition function and we just keep doing this so we can shift again.",
                    "label": 0
                },
                {
                    "sent": "And we take drags on there.",
                    "label": 0
                },
                {
                    "sent": "And just like the RNG we're building these things up on the stack and then reducing them.",
                    "label": 0
                },
                {
                    "sent": "So in this case we have to go past the verb.",
                    "label": 0
                },
                {
                    "sent": "We get to the noun phrase here sled and will reduce that first.",
                    "label": 0
                },
                {
                    "sent": "So now we end up with three things on the stack.",
                    "label": 0
                },
                {
                    "sent": "We reduce again and will reduce the previous two things of the verb phrase.",
                    "label": 0
                },
                {
                    "sent": "Now we end up with the noun phrase and verb phrase, and one more reduce and we end up with one whole analysis.",
                    "label": 0
                },
                {
                    "sent": "So again, we're using the same sort of shift reduce architecture.",
                    "label": 0
                },
                {
                    "sent": "Here, we're not generating the string, we just conditioning on it, and we're using the tree STM as a way of composing these representations up, and the final trailer steam output of this whole composition is going to be the representation we feed to our task.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just like the RNG, we can show that any sequence of these shift reduce actions give us a different tree and therefore a different representation at the end, and what we want to do is learn a model that learns good sequence of actions that lead to good representations, and the intuition is that composing things are any constituent together like the boy is a better idea than composing things earlier which are not together.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the idea here is to use reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "In this case the reinforce algorithm to choose the optimal sequence.",
                    "label": 0
                },
                {
                    "sent": "So the question is how do we choose an optimal sequence?",
                    "label": 0
                },
                {
                    "sent": "So one way as I said previously, is to maximize the likelihood of the string we observe.",
                    "label": 0
                },
                {
                    "sent": "But a different ways to say, well, we're using this representation to do something.",
                    "label": 0
                },
                {
                    "sent": "So let's maximize the utility of whatever it is we're doing.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's no supervisor on the trees.",
                    "label": 1
                },
                {
                    "sent": "The only way we get supervision is in the downstream task.",
                    "label": 1
                },
                {
                    "sent": "So, so the classic RL setup is that you're in a particular state.",
                    "label": 0
                },
                {
                    "sent": "And you have a set of actions and an agent and Agent has a policy over what actions to take in a particular state and choose an action and the state of the world is updated and the agent goes on and choose more actions.",
                    "label": 1
                },
                {
                    "sent": "And in this case the actions are going to be those shift and reduce actions.",
                    "label": 0
                },
                {
                    "sent": "So in this setup the agent is deposer and it's choosing at each time step whether to shift or reduce.",
                    "label": 0
                },
                {
                    "sent": "And the reward that we're going to use in reinforce is going to be the log likelihood of the downstream tasks.",
                    "label": 0
                },
                {
                    "sent": "So the main task here is sentiment analysis, so it's going to be the log likelihood of predicting the correct sentiment label.",
                    "label": 0
                },
                {
                    "sent": "And as I said, we're going to reinforce algorithm.",
                    "label": 0
                },
                {
                    "sent": "So just to train a policy directly, so I'm not going to go into this.",
                    "label": 0
                },
                {
                    "sent": "I think there's a whole another workshop on summer school memory.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Forcement learning we get to learn more about that, but I'll reinforce a very simple algorithm.",
                    "label": 0
                },
                {
                    "sent": "Sometimes works often doesn't work, but in this case it seems to work quite well.",
                    "label": 0
                },
                {
                    "sent": "You have to have a small number of actions.",
                    "label": 0
                },
                {
                    "sent": "It's not magic.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are results I grabbed from Danny's paper and.",
                    "label": 0
                },
                {
                    "sent": "The story plays out nicely, so at the top there's various other ways of embedding these.",
                    "label": 0
                },
                {
                    "sent": "These models embedding data.",
                    "label": 0
                },
                {
                    "sent": "Either.",
                    "label": 0
                },
                {
                    "sent": "Yeah, very simple and we've got various baselines, so an obvious approach is obviously a left to right LS TM is also an obvious question about do we need to go left or right?",
                    "label": 0
                },
                {
                    "sent": "Why not right to left so we should ask what does the right right to left or left him do?",
                    "label": 0
                },
                {
                    "sent": "Turns out is slightly worse, but.",
                    "label": 0
                },
                {
                    "sent": "It seems logical that we process language left to right.",
                    "label": 0
                },
                {
                    "sent": "Obviously you can do a bidirectional steam as well, and that's slightly better.",
                    "label": 0
                },
                {
                    "sent": "Well, actually, it's about the same as left to right and then we look at the models using the shift reduce setup so we can do this with supervised syntax.",
                    "label": 0
                },
                {
                    "sent": "That is, if we assume that we observe the trees from a tree bank and this is essentially what Sam Bowman did in his work previously, and that gives a good result compared to the previous ones.",
                    "label": 0
                },
                {
                    "sent": "But the interesting thing is sorry, the question of.",
                    "label": 0
                },
                {
                    "sent": "QikLink um, that's a good question.",
                    "label": 0
                },
                {
                    "sent": "I don't know so.",
                    "label": 0
                },
                {
                    "sent": "I normally say that the average length of a sentence well in news takes about 30 words.",
                    "label": 0
                },
                {
                    "sent": "These will be shorter than not really news text, but there's probably somewhere 15 to 20 I would guess.",
                    "label": 0
                },
                {
                    "sent": "There's not going to be the way the data was collected.",
                    "label": 0
                },
                {
                    "sent": "There's not going to be very long strings that you get.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you're not going to get the 200 word sentences that occasionally short.",
                    "label": 0
                },
                {
                    "sent": "So yes, continuing the nice result is that letting the structure be latent rather than supervised actually leads to better results in the downstream task.",
                    "label": 0
                },
                {
                    "sent": "So that's interesting, but also not hugely different.",
                    "label": 0
                },
                {
                    "sent": "But it does show that using reinforced to choose the structure rather than taking it as given.",
                    "label": 0
                },
                {
                    "sent": "Gives us a slight improvement, is also just as an aside, there's some.",
                    "label": 0
                },
                {
                    "sent": "For the last one, so the middle on the semi supervised is pre trained with the supervised syntax and then let go and then the last one is just no supervised syntax at all.",
                    "label": 0
                },
                {
                    "sent": "So and we see basically gradient there that not bothering with supervised syntax helps now.",
                    "label": 0
                },
                {
                    "sent": "There's been an assumption in everything that I've been saying, which is very common in the NLP world, but it is wrong that syntax sort of equals semantics.",
                    "label": 0
                },
                {
                    "sent": "And as I said at the start, these two things are different so.",
                    "label": 0
                },
                {
                    "sent": "You see a lot of work in NLP that says, OK, we should respect the hierarchical structure of language.",
                    "label": 0
                },
                {
                    "sent": "So let's use a path tree.",
                    "label": 0
                },
                {
                    "sent": "Let's compose our representation with the past tree.",
                    "label": 0
                },
                {
                    "sent": "But the point of syntax is not to say that's the way, meaning composers.",
                    "label": 0
                },
                {
                    "sent": "We know that semantics can diverge from the syntactic structure of a sentence, so they're not the same thing.",
                    "label": 0
                },
                {
                    "sent": "The problem is that we have ways of parsing, but no one has really gotten very far with actual semantics, and there's even less agreement on semantic theories and syntactic ones, so we tend to trick treat.",
                    "label": 0
                },
                {
                    "sent": "Proper semantics is just too hard and use syntax is outstanding, but in this case there's no real reason.",
                    "label": 0
                },
                {
                    "sent": "Some weak reasons, but in general it's not necessarily assumed that we should compose the meaning of the sentence following the syntax.",
                    "label": 0
                },
                {
                    "sent": "So the idea that on some sort of semantic task like sentiment prediction that a different composition works better is not in any way contradictory to that sort of syntactic theory.",
                    "label": 0
                },
                {
                    "sent": "But it's an interesting thing, LLP that people just often say I'm going to do sort of something linguistically inspired.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to use a path tree and then predict something semantic off that, that's that, is in some sense sort of abusing the sense of syntax.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So an obvious question is what sort of trees does it learn and do they look logical anyway so?",
                    "label": 0
                },
                {
                    "sent": "So I stole this slide from Danny and it's a bit convoluted, but if you can sort of read this.",
                    "label": 0
                },
                {
                    "sent": "There you can see some rough sense.",
                    "label": 0
                },
                {
                    "sent": "Yes there are.",
                    "label": 0
                },
                {
                    "sent": "Boy is a noun phrase and that's being pulled into one constituent, his sled as a noun phrase.",
                    "label": 0
                },
                {
                    "sent": "The snow is a noun phrase and somehow the full stops getting tacked on the end there.",
                    "label": 0
                },
                {
                    "sent": "But there the noun phrase is sort of getting joined together.",
                    "label": 0
                },
                {
                    "sent": "The verb drags is being composed with the subject, normally in a syntactic theory you would have the verb composed with the object.",
                    "label": 0
                },
                {
                    "sent": "He slid through the.",
                    "label": 0
                },
                {
                    "sent": "You said in this case, but that's not sort of too crazy, so that looks like a reasonable sort of structure.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's another one that doesn't look so reasonable in this case.",
                    "label": 0
                },
                {
                    "sent": "A home so this is family members standing outside a home.",
                    "label": 0
                },
                {
                    "sent": "The noun phrase a home has been split up, which doesn't really make any sense.",
                    "label": 0
                },
                {
                    "sent": "They should really be together, either in syntax or semantics, and that's been combined with outside a.",
                    "label": 0
                },
                {
                    "sent": "So looking at these trees, they're not hugely consistent in saying that they're learning something really deep about language, but they it is interesting that we get this variance in result.",
                    "label": 0
                },
                {
                    "sent": "There's obvious follow on work to this.",
                    "label": 0
                },
                {
                    "sent": "As I said, traditionally unsupervised.",
                    "label": 0
                },
                {
                    "sent": "Grammar induction models maximize likelihood of the strings.",
                    "label": 0
                },
                {
                    "sent": "There's no reason why we can't combine those objective functions.",
                    "label": 0
                },
                {
                    "sent": "It makes sense that we should maximize what we see in the string and the tasks.",
                    "label": 0
                },
                {
                    "sent": "There's also a good psycholinguistic reasons that that might be more similar to what children do.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, how am I doing?",
                    "label": 0
                },
                {
                    "sent": "OK, so moving on to the last part of this lecture.",
                    "label": 0
                },
                {
                    "sent": "So we first 2/3 of this lecture is really focused on this question of structure in language, in particular syntactic structure.",
                    "label": 0
                },
                {
                    "sent": "And can we get this into the models and I presented some models which aimed to capture this.",
                    "label": 0
                },
                {
                    "sent": "But there are some promising things, but there's still a great deal to be done.",
                    "label": 0
                },
                {
                    "sent": "We still really don't know what the best way I've really capturing structure in our in our neural networks is.",
                    "label": 0
                },
                {
                    "sent": "These models have taken the sort of hard latent variable version of this where we have discrete latent variables for the structure is also promising to ask other soft ways of doing this.",
                    "label": 0
                },
                {
                    "sent": "The capture the structure.",
                    "label": 0
                },
                {
                    "sent": "Now in the last section I'll talk less about hierarchical structure and more about how do we connect.",
                    "label": 0
                },
                {
                    "sent": "Linguistic utterances with meaning.",
                    "label": 0
                },
                {
                    "sent": "So if we have.",
                    "label": 0
                },
                {
                    "sent": "We observe utterances like the dog or something like that.",
                    "label": 0
                },
                {
                    "sent": "How do we connect those symbols with the actual meaning of a dog?",
                    "label": 0
                },
                {
                    "sent": "The dog that we have in our head.",
                    "label": 0
                },
                {
                    "sent": "We do it because we experience the world.",
                    "label": 0
                },
                {
                    "sent": "But how can we get our models to do that?",
                    "label": 0
                },
                {
                    "sent": "And this is this is a hard problem.",
                    "label": 0
                },
                {
                    "sent": "An most of NLP is tackling this sort of problem in direct.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hey.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now I'm going to talk a bit more about this problem of situating our agents in a world.",
                    "label": 0
                },
                {
                    "sent": "In this case, is going to be simulated world and trying to get them to learn to connect language symbols there, observing where things in that world and then perform tasks.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of inspired by the question of if we want to get to an artificial intelligence that can understand language.",
                    "label": 0
                },
                {
                    "sent": "What sort of training environment that we need to create for this agent, which is going to allow to do this.",
                    "label": 0
                },
                {
                    "sent": "Most of the ways we're training our natural language systems at the moment and not plausable ways of getting to any real sort of language understanding.",
                    "label": 0
                },
                {
                    "sent": "You're not going to build bigger and bigger, more complicated models of sentiment analysis and suddenly have an agent that understands all of language.",
                    "label": 0
                },
                {
                    "sent": "None of the tasks that we really doing at the moment are going to get us there as I sort of claimed earlier.",
                    "label": 0
                },
                {
                    "sent": "Language modeling hides a lot of.",
                    "label": 0
                },
                {
                    "sent": "Flexity of language within that task, but it's hard to see how a model will ever actually solve that language modeling problem without access to a world to understand what the symbols it's manipulating actually mean.",
                    "label": 0
                },
                {
                    "sent": "So it's interesting question to ask is what is the sort of minimally adequate sort of environment that would allow us to get to the point of real language understanding?",
                    "label": 0
                },
                {
                    "sent": "So in NLP as I said, we tend to our sense of grounding in appears often in terms of labels like sentiment labels for the input symbols or document labels like categories, politics etc.",
                    "label": 0
                },
                {
                    "sent": "So that sort of grounding or in some cases we ground in terms of the other linguistic symbols.",
                    "label": 0
                },
                {
                    "sent": "So if you think about word embedding work where we learn lexical semantic representations of words there grounded in terms of the words they Co occur with.",
                    "label": 0
                },
                {
                    "sent": "So we learn the meaning of dog which is a.",
                    "label": 0
                },
                {
                    "sent": "A symbol in our input from its distribution over other symbols in our input.",
                    "label": 0
                },
                {
                    "sent": "So this is a sort of circular semantics, and that means it's very hard to learn certain properties.",
                    "label": 0
                },
                {
                    "sent": "We can learn distributional properties, but it's very hard to learn other properties.",
                    "label": 0
                },
                {
                    "sent": "So for instance, it's very hard to learn spatial things, so if you have the words behind and in front from a distribution model, you're never going to learn what behind and in front actually mean.",
                    "label": 0
                },
                {
                    "sent": "So if I say is behind be, then you know that bees in front of a for those two things hold in front of behind their opposites.",
                    "label": 0
                },
                {
                    "sent": "But you're never going to learn that from analyzing the distribution of the word in text, we know that because we're situated in the world and we've learned to ground these terms, so there's a lot of language that you cannot get simply from that distribution.",
                    "label": 0
                },
                {
                    "sent": "There's a lot you can.",
                    "label": 0
                },
                {
                    "sent": "There's a lot you can't as well.",
                    "label": 0
                },
                {
                    "sent": "So the question is, how do we get this sort of thing into our models?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Observing a dialogue and somebody says, oh, it's behind that it's behind the bottle.",
                    "label": 0
                },
                {
                    "sent": "Oh, move the bottle and then you'll see it like that.",
                    "label": 0
                },
                {
                    "sent": "I feel like you can't say definitively that you can't get it from language.",
                    "label": 0
                },
                {
                    "sent": "I agree it's hard.",
                    "label": 0
                },
                {
                    "sent": "The question is whether you really understand the meaning of infant behind, or whether you can use them in appropriate ways.",
                    "label": 0
                },
                {
                    "sent": "I think it would be hard to see how you would.",
                    "label": 0
                },
                {
                    "sent": "I mean, obviously if your measure of understanding is can you match the distribution, then in the limit of seeing all of the data, you should be able to match the distribution.",
                    "label": 0
                },
                {
                    "sent": "But in the sense of.",
                    "label": 0
                },
                {
                    "sent": "Coming into an understanding of language quickly from limited data, it seems hard to see how you could ever capture those sorts of things.",
                    "label": 0
                },
                {
                    "sent": "I mean, even things like behind themselves are very complicated.",
                    "label": 0
                },
                {
                    "sent": "So if I'm looking at something and there's a tree, and I say that John is behind the tree, how far does John have to move away from that tree before?",
                    "label": 0
                },
                {
                    "sent": "I wouldn't say he's behind it so we can go a bit and I still says behind it a bit further and behind it.",
                    "label": 0
                },
                {
                    "sent": "At some point I'm going to say, well, he's not really behind it anymore, so even things like that are a distribution you can't.",
                    "label": 0
                },
                {
                    "sent": "Write down a rule for when a is behind be and when it's not and different people will give you different judgments on those things, and also depends on scale.",
                    "label": 0
                },
                {
                    "sent": "If John is behind a mountain is a very different judgment from John is behind a tree.",
                    "label": 0
                },
                {
                    "sent": "OK. Well, I had another example of empty empty we we can think of.",
                    "label": 0
                },
                {
                    "sent": "We ground the semantics of one language.",
                    "label": 0
                },
                {
                    "sent": "In the other we learned the meaning of dog by its translation in another language.",
                    "label": 0
                },
                {
                    "sent": "And again, there's a sense of grounding the meaning there, but it's slightly.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Regular sense.",
                    "label": 0
                },
                {
                    "sent": "And that we don't ever have to understand what a dog is to produce the right translation.",
                    "label": 0
                },
                {
                    "sent": "So an obvious place to go to for inspiration is humans, so there are example of language learners.",
                    "label": 0
                },
                {
                    "sent": "The question is what sort of environment do humans learn language, the language acquisition, acquisition is one of the great problems of linguistics and psycholinguistics and.",
                    "label": 0
                },
                {
                    "sent": "A number of areas and is still a great mystery.",
                    "label": 0
                },
                {
                    "sent": "There's so much that we don't really understand about how children learn language, but there's a lot of data we have about how they do, and it does contradict a lot of people's intuitions in the machine learning community.",
                    "label": 0
                },
                {
                    "sent": "You'll often hear people speaking about how we need agents that can interact with the world, can feel things, and talk to teachers and all this sort of thing to learn language.",
                    "label": 0
                },
                {
                    "sent": "But we have a lot of evidence that children learn language without any of these things well, without most of these things.",
                    "label": 0
                },
                {
                    "sent": "Children learn with minimal direct teaching.",
                    "label": 0
                },
                {
                    "sent": "Parents often think that they teach me.",
                    "label": 0
                },
                {
                    "sent": "Parents often think that they teach children their children language.",
                    "label": 0
                },
                {
                    "sent": "They say that's a dog and that's a cat.",
                    "label": 0
                },
                {
                    "sent": "But children learn language themselves from their environment, and parents have actually relatively little influence on that.",
                    "label": 0
                },
                {
                    "sent": "So this model of teaching language by direct.",
                    "label": 0
                },
                {
                    "sent": "Direct explanation is not necessarily.",
                    "label": 0
                },
                {
                    "sent": "It does not necessarily match the data.",
                    "label": 0
                },
                {
                    "sent": "We have.",
                    "label": 0
                },
                {
                    "sent": "Children learn language simply from their environment.",
                    "label": 0
                },
                {
                    "sent": "You put a child in an environment where people are speaking the language to each other and they will learn language.",
                    "label": 1
                },
                {
                    "sent": "We know this because children learn language and amazingly diverse and adverse environment.",
                    "label": 0
                },
                {
                    "sent": "So children are horribly abused in families, will still learn language even if no one talks to them just from being around people speaking language but also children learn language from all sorts of different input.",
                    "label": 0
                },
                {
                    "sent": "Blind children, learn language just fine.",
                    "label": 0
                },
                {
                    "sent": "Often they learn it in a different way, too excited child.",
                    "label": 1
                },
                {
                    "sent": "Instance there's various observations that blind children learn the sense of a preposition preposition like on in terms of, put something on.",
                    "label": 0
                },
                {
                    "sent": "So put on your shoes before they learn the bottle is on the table where is assigned.",
                    "label": 0
                },
                {
                    "sent": "A child might learn the reverse and you can see why this is the case because the blind child will not often see or will not see bottles on tables that will have to be described to them, but I'll often put on their socks or their shoes themselves.",
                    "label": 0
                },
                {
                    "sent": "There's an interesting differences, but the most interesting thing is no.",
                    "label": 0
                },
                {
                    "sent": "Children often take different paths and have different input.",
                    "label": 0
                },
                {
                    "sent": "They all all, unless in sort of dire circumstances, end up at the same point, and that's very good comprehension of language.",
                    "label": 0
                },
                {
                    "sent": "And it really takes pretty serious problems to stop that.",
                    "label": 0
                },
                {
                    "sent": "So deaf children learn language just fine, depending on what other issues they have.",
                    "label": 0
                },
                {
                    "sent": "But if this is the only one they learn language just fine.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing is, as I understand it, I'm not an expert in this.",
                    "label": 0
                },
                {
                    "sent": "As I understand it, there's no evidence of children learning language from reading.",
                    "label": 0
                },
                {
                    "sent": "So if a child is just taught language from visual symbols, they can't learn it.",
                    "label": 0
                },
                {
                    "sent": "Inability.",
                    "label": 0
                },
                {
                    "sent": "So you have children that can't move, so have disabilities such they can't move.",
                    "label": 0
                },
                {
                    "sent": "Learn language fine children that can't interact with their environment at all.",
                    "label": 0
                },
                {
                    "sent": "Depending on going often, children have other disabilities that do tend to.",
                    "label": 0
                },
                {
                    "sent": "If you're if you're blind, can't move, tends to get very hard at death.",
                    "label": 0
                },
                {
                    "sent": "But if you just can't move but can see and speak, you'll still learn language fine, you don't.",
                    "label": 0
                },
                {
                    "sent": "Speaking or something.",
                    "label": 0
                },
                {
                    "sent": "Well, speaking is a way to interact with others, but you don't necessarily need to feel objects or understand things in that way.",
                    "label": 0
                },
                {
                    "sent": "Obviously this is a very large part of children's development.",
                    "label": 1
                },
                {
                    "sent": "Exploring the world and feeling things.",
                    "label": 0
                },
                {
                    "sent": "But the question I'm asking here is what is the minimal?",
                    "label": 0
                },
                {
                    "sent": "And it turns out that it seems like the minimal is actually very minimal.",
                    "label": 0
                },
                {
                    "sent": "So in terms of input, we know that there's various studies of sort of tribes in South America that show that children can learn language with.",
                    "label": 0
                },
                {
                    "sent": "I think the result is something like 60 hours of actual direct conversation, everything else indirect.",
                    "label": 0
                },
                {
                    "sent": "So there's a tribe that carries children on their back and never actually speaks to them, but they still learn language just fine from.",
                    "label": 0
                },
                {
                    "sent": "There are deaf and repair, and they are born in an adversarial environment where people don't point to think, do any sort of science to them.",
                    "label": 0
                },
                {
                    "sent": "There's obviously limits and I couldn't tell you what they are, but the interesting thing is that the general robustness of this process, so yes.",
                    "label": 1
                },
                {
                    "sent": "Always a limit that some point children will not learn language.",
                    "label": 0
                },
                {
                    "sent": "There's lots of other sorts of things, so there's various brain injuries a child can have which affect parts of the brain that to do with language.",
                    "label": 0
                },
                {
                    "sent": "Yet still they learn to speak language for other sorts of process is so they might learn the different way.",
                    "label": 0
                },
                {
                    "sent": "And all these sorts of things.",
                    "label": 0
                },
                {
                    "sent": "But the interesting thing is just how robust language acquisition is in children and the other thing is that for getting all these disabilities, just ordinary children.",
                    "label": 0
                },
                {
                    "sent": "Always learn language.",
                    "label": 0
                },
                {
                    "sent": "It's not like they fail.",
                    "label": 0
                },
                {
                    "sent": "It's not like our agents where we might launch 100 agents and just one of them actually learn something and all of the other sort of learn nothing.",
                    "label": 0
                },
                {
                    "sent": "Children always learn we don't get this case where we say are sort of little Johnny or Johnny didn't learn language.",
                    "label": 0
                },
                {
                    "sent": "He was here.",
                    "label": 0
                },
                {
                    "sent": "He had a bad initializer and.",
                    "label": 0
                },
                {
                    "sent": "And didn't learn language.",
                    "label": 0
                },
                {
                    "sent": "Language learning in children is just incredibly robust.",
                    "label": 0
                },
                {
                    "sent": "Anyway, I'm going on a bit of a sidetrack here, so I'm not going to solve all of these problems, but it's a good problem for us to think about is what would be environments that would satisfy this.",
                    "label": 0
                },
                {
                    "sent": "As you can see, there is no one answer, so it seems like the connection of audio input and vision is a good starting point.",
                    "label": 0
                },
                {
                    "sent": "But of course blind children learn language, so there's other routes to this.",
                    "label": 0
                },
                {
                    "sent": "So here's what I'm going to discuss.",
                    "label": 0
                },
                {
                    "sent": "Is a very sort of simple starting point for this, obviously not claiming to solve all of these problems, but is a simple 3D World we built with some language input.",
                    "label": 1
                },
                {
                    "sent": "To get agents to do tasks, and here I'm sort of conflicting with a few of these things.",
                    "label": 0
                },
                {
                    "sent": "'cause this is a very teacher driven setup.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this environment that we're using is based on DeepMind lab.",
                    "label": 0
                },
                {
                    "sent": "So Deep Mind released this.",
                    "label": 0
                },
                {
                    "sent": "3D game environment.",
                    "label": 0
                },
                {
                    "sent": "I think it was around Christmas last year.",
                    "label": 0
                },
                {
                    "sent": "That you can this open source.",
                    "label": 0
                },
                {
                    "sent": "There's a GitHub repository there you can build agents based on this, so it's a great environment for training agents.",
                    "label": 0
                },
                {
                    "sent": "It's based on the Quake 3 engine open Arena I think, so you get it's not the most modern game engine, but it's not the worst either.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the basic setup is you have these agents out sort of orb there, and in the basic DeepMind lab you have input from pixel, so the agent gets to observe the pixels on the screen from its current viewpoint, and you can also input a reward if it does something right, and so here little Apple means maybe if it picks up the Apple it will get a reward.",
                    "label": 0
                },
                {
                    "sent": "So you can define these rewards and set up different tasks to test out agents, and you can do all sorts of things like navigation and all sorts of different problems and transom agents, and there's been quite a lot of papers from deep mind using this environment and then we have a set of actions.",
                    "label": 0
                },
                {
                    "sent": "The classic sort of ones you would assume from this sort of game environment so we can move.",
                    "label": 0
                },
                {
                    "sent": "We can strafe jumping and things like this.",
                    "label": 0
                },
                {
                    "sent": "Most of these aren't relevant for various tasks.",
                    "label": 0
                },
                {
                    "sent": "Mostly you just want to be able to move around and look around.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now OK, so I have a little just little bit.",
                    "label": 0
                },
                {
                    "sent": "This is just a classic DeepMind lab setup of an agent.",
                    "label": 1
                },
                {
                    "sent": "This is a human playing this.",
                    "label": 0
                },
                {
                    "sent": "Sorry, just exploring the environment.",
                    "label": 0
                },
                {
                    "sent": "So this is what it looks like and you can have objects here.",
                    "label": 0
                },
                {
                    "sent": "These are apples and the idea is that the apples or some sort of rewarding.",
                    "label": 0
                },
                {
                    "sent": "Rewarding symbol.",
                    "label": 0
                },
                {
                    "sent": "OK, probably don't need all that.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that was our starting point, and so we wanted to add language to this environment.",
                    "label": 0
                },
                {
                    "sent": "So we essentially just add an extra channel of input to our agents and they can receive text based utterances and so here's some screenshots of what it looks like.",
                    "label": 0
                },
                {
                    "sent": "The utterances across the top.",
                    "label": 0
                },
                {
                    "sent": "This is actually fed directly to the agent.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have to get it from the pixels or anything like that.",
                    "label": 0
                },
                {
                    "sent": "It's getting the the string.",
                    "label": 0
                },
                {
                    "sent": "Input and what we want to do is build little task.",
                    "label": 0
                },
                {
                    "sent": "So this says red object next to the green object and that's telling the agent that has to explore its environment and find the red object that is next to a green object and grab that object.",
                    "label": 0
                },
                {
                    "sent": "And so the idea is that we added this language channel.",
                    "label": 0
                },
                {
                    "sent": "Then we came up with various sort of language tasks for the agent to do and write up from.",
                    "label": 0
                },
                {
                    "sent": "Starting from simple things like get the Apple two more relative things like this.",
                    "label": 0
                },
                {
                    "sent": "So to understand when something is next to something else is a more challenging problem.",
                    "label": 0
                },
                {
                    "sent": "We can describe objects in terms of well, colors of their neighbors, also in terms of rooms, so they see that the rooms have funny colored floors, so we can refer to that so we can talk about the blue room.",
                    "label": 0
                },
                {
                    "sent": "So get the Apple in the blue room as opposed to the pink room or something like that.",
                    "label": 0
                },
                {
                    "sent": "We also have.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is the language side is very simple.",
                    "label": 0
                },
                {
                    "sent": "Just generated from basic basic scripts, so there's nothing terribly complicated going on the language.",
                    "label": 0
                },
                {
                    "sent": "There's no sort of hierarchical composition.",
                    "label": 0
                },
                {
                    "sent": "There's some minimal composition in that we can compose adjectives and nouns.",
                    "label": 0
                },
                {
                    "sent": "And simple prepositional phrases like in the blue room.",
                    "label": 0
                },
                {
                    "sent": "These sorts of things so very simple language, and we're really just at the starting point of in this environment where we have very low level input in terms of pixels.",
                    "label": 0
                },
                {
                    "sent": "And we have very delayed reward in terms of the agent has to take many actions that might be hundreds of actions to get the right object.",
                    "label": 0
                },
                {
                    "sent": "Can we teach the agent to ground the language?",
                    "label": 0
                },
                {
                    "sent": "Can we?",
                    "label": 0
                },
                {
                    "sent": "Can it discover that the the symbol green in there refers to this color?",
                    "label": 0
                },
                {
                    "sent": "Can it discover that hat or something like that refers to a hat shape?",
                    "label": 0
                },
                {
                    "sent": "And so we know that in sort of image net like situations we can do this in static 2D images.",
                    "label": 0
                },
                {
                    "sent": "This is getting more challenging one because the reward is delayed to these objects look different from.",
                    "label": 0
                },
                {
                    "sent": "Different viewpoints, so you have to understand what they look like from different views.",
                    "label": 0
                },
                {
                    "sent": "We also have scales so we can have big hats, small hats and we ask questions about relative size.",
                    "label": 0
                },
                {
                    "sent": "So get the biggest object and things like this.",
                    "label": 0
                },
                {
                    "sent": "The other aspect, of course, is the agent is intentional.",
                    "label": 0
                },
                {
                    "sent": "It can move about the environment so it performs actions and it can change what it's looking at.",
                    "label": 0
                },
                {
                    "sent": "And we want to learn.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All of these things together into in, so we specify the general layouts of the tasks of problems of language and then these are generated.",
                    "label": 0
                },
                {
                    "sent": "From a script so that we can get billions of different combinations to train our agents on.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the basic lexecon that we use is this.",
                    "label": 0
                },
                {
                    "sent": "So we have 40 different shapes, 13 colors pattern shades and we can combine all of these so you can see that the if you take the set of product of this we have a very large space of objects so we can take.",
                    "label": 0
                },
                {
                    "sent": "The objects are very strange for some reason in this decline lab, we have an interesting choice of objects, so like giant giant floating toothbrushes and things like this.",
                    "label": 1
                },
                {
                    "sent": "So these agents learn some strange.",
                    "label": 0
                },
                {
                    "sent": "Objects, but we have.",
                    "label": 0
                },
                {
                    "sent": "This is the infantry have the one we're working with and then so for each shape you can choose different colors.",
                    "label": 0
                },
                {
                    "sent": "They can have patterns, so they're going to be checkered with two different colors, stripe.",
                    "label": 0
                },
                {
                    "sent": "These sorts of things we're going to have shades so light, dark and neutral, and we can have sizes small, medium, large.",
                    "label": 0
                },
                {
                    "sent": "That way we can ask questions about that.",
                    "label": 0
                },
                {
                    "sent": "Pick the darker hat or the largest toothbrush or something like this.",
                    "label": 0
                },
                {
                    "sent": "So we have this space of objects and colors and patterns and such and the product space is quite large.",
                    "label": 1
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this.",
                    "label": 0
                },
                {
                    "sent": "Looks that way cause this.",
                    "label": 0
                },
                {
                    "sent": "So this is a sort of sort of medley video of a trained agent that's trained to do multiple different language tasks going about in the DeepMind lab world.",
                    "label": 0
                },
                {
                    "sent": "Doing these tasks and I'll just play this to give you an idea of what it looks like.",
                    "label": 0
                },
                {
                    "sent": "So this is an agent ranges from nothing but the pixels and the language input.",
                    "label": 0
                },
                {
                    "sent": "So it learns to get objects which are next to other objects, and now it's looking for the blue object next to the green object.",
                    "label": 0
                },
                {
                    "sent": "That doesn't look very good, so see the TV's only have their color on one side, so the agent learns to wait for them to turn around, which is sort of cool.",
                    "label": 0
                },
                {
                    "sent": "So we have problems like where it has to just get all of 1 color of object.",
                    "label": 0
                },
                {
                    "sent": "Is it still reinforce?",
                    "label": 0
                },
                {
                    "sent": "So I'll say a bit more about the agent, but the basic agent is a 3C and then we also augmented it with some auxiliary's.",
                    "label": 0
                },
                {
                    "sent": "So this is 1 where it's got to look for the green room, so it doesn't want that magenta object, but it wants not that guitar.",
                    "label": 0
                },
                {
                    "sent": "As I said, the objects are a bit strange, floating guitars etc.",
                    "label": 0
                },
                {
                    "sent": "There's the comb.",
                    "label": 0
                },
                {
                    "sent": "At the bottom are the numbers.",
                    "label": 0
                },
                {
                    "sent": "Sorry, these numbers on the bottom don't really mean anything, they're just artifact of the.",
                    "label": 0
                },
                {
                    "sent": "Of the game environment.",
                    "label": 0
                },
                {
                    "sent": "And as I said, the instruction is coming through a separate channel, so it doesn't actually have to read those pixels or anything.",
                    "label": 0
                },
                {
                    "sent": "So that one's quite cool that Caesar read object.",
                    "label": 0
                },
                {
                    "sent": "And when you when you look at these things from above, so the agent doesn't get to see this.",
                    "label": 0
                },
                {
                    "sent": "But this is what the agent looks like when it's doing this an it does start to look really intentional.",
                    "label": 0
                },
                {
                    "sent": "Look, it's going for the red object, sees what's next to it and go straight for it.",
                    "label": 0
                },
                {
                    "sent": "So it waits for the TV to turn around.",
                    "label": 0
                },
                {
                    "sent": "It's the wrong one.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have diagonal stripes, so it goes to look somewhere else.",
                    "label": 0
                },
                {
                    "sent": "It's waiting for that one now, but it seems that one in the distance and it looks good, doesn't have very good memory.",
                    "label": 0
                },
                {
                    "sent": "That still sort of weights to be sure.",
                    "label": 0
                },
                {
                    "sent": "Yes, a tape.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's what the trained agent ended up doing.",
                    "label": 1
                },
                {
                    "sent": "So as I said, the language is very simple, but just in that simple language we can explore quite a lot of interesting sorts of problems.",
                    "label": 0
                },
                {
                    "sent": "Can the agent learn to interpret combinations of attitude, and now that's never seen before?",
                    "label": 0
                },
                {
                    "sent": "Do these tasks where it has to understand something relative objects relative to other objects.",
                    "label": 0
                },
                {
                    "sent": "So what was the actual agent look like?",
                    "label": 0
                },
                {
                    "sent": "So their starting point is a 3C.",
                    "label": 0
                },
                {
                    "sent": "That we sort of ad diagram here.",
                    "label": 0
                },
                {
                    "sent": "At the bottom we have going in the pixels for the image.",
                    "label": 0
                },
                {
                    "sent": "It goes into a convolution network.",
                    "label": 0
                },
                {
                    "sent": "We have a ladder as the sole linguistic symbol.",
                    "label": 0
                },
                {
                    "sent": "Here are some minimal utterance if the task was just get the ladder that goes into an STM.",
                    "label": 0
                },
                {
                    "sent": "Obviously a bit of overkill for one symbol, but if you have a whole phrase that's more useful that feeds up into into a composition analysis team for the agent and then from that we have the policy and the value function so.",
                    "label": 0
                },
                {
                    "sent": "That's a class.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A 3C",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as I was showing the results, that doesn't actually work in this situation, so we need to augment it.",
                    "label": 0
                },
                {
                    "sent": "So we augment this with various auxiliary's.",
                    "label": 0
                },
                {
                    "sent": "This is similar to the Unreal Agent that was published from Deep Mind.",
                    "label": 0
                },
                {
                    "sent": "I clear where we've got things that are P, there is reward prediction.",
                    "label": 0
                },
                {
                    "sent": "So that's where the agents predicting from frames whether it's going to reward or not.",
                    "label": 0
                },
                {
                    "sent": "Soon value replay is where it replays episodes and optimize the value function with Q learning.",
                    "label": 0
                },
                {
                    "sent": "LP is language prediction and think I've got these so that more.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interesting ones for our case.",
                    "label": 0
                },
                {
                    "sent": "Pacific to this language setup is language prediction, so that's given and given a visual frame, try and predict the tasks that would go along with this.",
                    "label": 0
                },
                {
                    "sent": "So if you see in a minimal sort of example, if you see a ladder and a can like that then you get the agent should be predicting that the instruction is either lateral can or maybe it's pink or red or something like that.",
                    "label": 0
                },
                {
                    "sent": "So that's an auxiliary task we can learn and the second one is the auto encoder which tries to predict given the current frame.",
                    "label": 0
                },
                {
                    "sent": "And an action.",
                    "label": 0
                },
                {
                    "sent": "What will the next frame look like?",
                    "label": 0
                },
                {
                    "sent": "So a classic sort of auto encoding, although it's not quite auto encoding 'cause we also condition on the action.",
                    "label": 0
                },
                {
                    "sent": "Now these are reasonably obvious auxillaries, but they're also interesting because they overlap quite a lot with what we think children do in their learning environment.",
                    "label": 0
                },
                {
                    "sent": "So as I said, children learn a lot of language, not directly from their parents, but just from the environment, and they seem to be doing this using basic language modeling type problems.",
                    "label": 0
                },
                {
                    "sent": "There constantly hearing language, and they're in their head predicting what's going to come next, and they're learning, essentially learning a language model to go from their environment and what they're going to do next.",
                    "label": 0
                },
                {
                    "sent": "Do this visually as well.",
                    "label": 0
                },
                {
                    "sent": "There's lots of intuitive physics experiments where you can sort of roller ball down the slope behind.",
                    "label": 0
                },
                {
                    "sent": "Some obstruction and the child will expect the ball to roll out the other side if it has a model of physics in its head, and if it doesn't, then it will be surprised we can do the same thing for language, we can show that children are predicting what comes next in a language, because if we mess with that, they are surprised in some way when it doesn't happen.",
                    "label": 0
                },
                {
                    "sent": "So, so we're interested in taking sort of inspiration from this an encoding.",
                    "label": 0
                },
                {
                    "sent": "These sorts of auxiliary's as well.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now so it doesn't work, so this is what it looks like.",
                    "label": 0
                },
                {
                    "sent": "So the Gray line along the bottom here.",
                    "label": 0
                },
                {
                    "sent": "These are training episodes.",
                    "label": 0
                },
                {
                    "sent": "On the bottom there's a very large numbers.",
                    "label": 0
                },
                {
                    "sent": "I'll come back to that in a moment and reward on the Y axis.",
                    "label": 0
                },
                {
                    "sent": "That Gray line along the bottom is basically a 3C.",
                    "label": 0
                },
                {
                    "sent": "In these setups, it really doesn't learn.",
                    "label": 0
                },
                {
                    "sent": "If you get very simple setups where you're very close to the object's, a 3C might work, but we really need to add these auxiliary to get it to work, and you see that each time we add improve things and we end up with an agent at the end there that's using all of these different auxilaries and it's working quite well.",
                    "label": 0
                },
                {
                    "sent": "So when we start to add these unsupervised signals, so the agents actually at every step it's doing something and getting some sort of signal.",
                    "label": 0
                },
                {
                    "sent": "Then we start to see learning.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so just like in the video, this is just another diagram of an agent doing a task, so this was green object next to the blue object and the black path is the path it took.",
                    "label": 0
                },
                {
                    "sent": "So it looked at the chair there and what is that?",
                    "label": 0
                },
                {
                    "sent": "I think that was a cake.",
                    "label": 0
                },
                {
                    "sent": "I should be better at recognizing these objects and then it goes back into the other room and look for the right one.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Allowed.",
                    "label": 0
                },
                {
                    "sent": "You always say like the blue guitar next to the red table, even if there's only one movie star.",
                    "label": 0
                },
                {
                    "sent": "So it varies, so normally they will be distracted, so there might be 2 blue guitars and it has to choose.",
                    "label": 0
                },
                {
                    "sent": "So yeah normally there are distractors so.",
                    "label": 0
                },
                {
                    "sent": "Information.",
                    "label": 0
                },
                {
                    "sent": "Yes, it depends on the task.",
                    "label": 0
                },
                {
                    "sent": "So we got a mixture of tasks.",
                    "label": 0
                },
                {
                    "sent": "Sometimes the tasks are just one sort of task, like they always get the something next to something and we just see whether we can train agent just to do that and other times like the agent I showed earlier, it will be trained on a whole variety of different tasks and there yes it could be just something like get the get the green object or something like that.",
                    "label": 0
                },
                {
                    "sent": "If it was unambiguous.",
                    "label": 0
                },
                {
                    "sent": "Integrated music player.",
                    "label": 0
                },
                {
                    "sent": "Maybe I mean if we connect this to sort of our world, we sort of do the opposite.",
                    "label": 0
                },
                {
                    "sent": "Humans are very good at using pragmatics to sort of under specify the description, so there's classic examples where like this class example, you have three faces, an one has glasses on another glasses and a hat, and the third one has neither.",
                    "label": 0
                },
                {
                    "sent": "And if someone wants to pick out the person with glasses but not a hat, they'll say the person with glasses.",
                    "label": 0
                },
                {
                    "sent": "And although the person with glasses and a hat also has glasses out of pragmatic interpretation is if if I meant the one with the hat, I would have said that so humans are sort of the opposite.",
                    "label": 0
                },
                {
                    "sent": "In weekend we didn't find interesting ways to under specify we're not getting any of that here, but that would be a very interesting thing.",
                    "label": 0
                },
                {
                    "sent": "In pragmatics is really interesting because coming back to sort of how good children are learning language.",
                    "label": 0
                },
                {
                    "sent": "The other thing about when children learn language is we almost never give them the literal expression that they need to interpret.",
                    "label": 0
                },
                {
                    "sent": "We're almost always as humans using some sort of pragmatic expression like.",
                    "label": 0
                },
                {
                    "sent": "When I say when I want you to pass assault, I don't say pass assault.",
                    "label": 0
                },
                {
                    "sent": "I said can you please pass the salt and you know that I don't.",
                    "label": 0
                },
                {
                    "sent": "I'm not asking you a question, I'm saying pass itself, but if you think about many of the things you will say to each other into children, you're almost always using some sort of pragmatic interpretation.",
                    "label": 0
                },
                {
                    "sent": "It's not literal, so if you think about the poor child, it's trying to learn languages they actually often don't get the literal interpretation they have to do some sort of pragmatic inference.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm getting distracted.",
                    "label": 0
                },
                {
                    "sent": "OK, OK this was this is a short video showing.",
                    "label": 0
                },
                {
                    "sent": "This language prediction auxiliary so at the top is just the maximum from the distribution of what the agent is predicting from its visual scene.",
                    "label": 0
                },
                {
                    "sent": "So here it's looking at a key and it's predicting the symbol key and you'll see that changes.",
                    "label": 0
                },
                {
                    "sent": "It sometimes predicts the color, and that's just the distribution changing, but that's what this auxiliary looks like.",
                    "label": 0
                },
                {
                    "sent": "It's just slow down here, so it's a bit easier to see, so it's approaching.",
                    "label": 0
                },
                {
                    "sent": "It's constantly learning and that basically helps it learn to segment the world.",
                    "label": 0
                },
                {
                    "sent": "So it's got the segment the world of pixels into objects, so it can ground them in the symbols.",
                    "label": 0
                },
                {
                    "sent": "Now sort of the key task for this agent.",
                    "label": 0
                },
                {
                    "sent": "Learning that this set of pixels are stripy set corresponds to the sort of stripey hat and you see it's language prediction is sort of oscillating between different things, so see this chair and it thinks it's large.",
                    "label": 0
                },
                {
                    "sent": "That looks like a large share it share large.",
                    "label": 0
                },
                {
                    "sent": "Etc.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, this is the next frame prediction.",
                    "label": 0
                },
                {
                    "sent": "It's actually reasonably hard to interpret this, but this is what it looks like when it's on the top left is what season in the other all the other frames are sort of what it's predicting in its encoder for different actions so that each one is a different action, like go backwards, look right and what it predicts.",
                    "label": 0
                },
                {
                    "sent": "There's not a huge amount of variance.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There.",
                    "label": 0
                },
                {
                    "sent": "OK, so curriculum is important for these.",
                    "label": 0
                },
                {
                    "sent": "Get the agents to learn the complex tasks.",
                    "label": 0
                },
                {
                    "sent": "So the language prediction the it's just getting the supervision comes from the task itself, so it as it's learning these tasks it has this very basically parallel data of tasks, utterances and the visual world and what it's doing is learning to predict one from the other.",
                    "label": 0
                },
                {
                    "sent": "So it's basically just learning that I observed this language in this context and trying to learn to predict that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so curriculum is important for the complex tasks, so these sort of where we got multiple rooms in the agent has to explore.",
                    "label": 0
                },
                {
                    "sent": "If you just start out with that, it doesn't learn very much, so we have various correct.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So starting out with sort of 1 big room with different layouts and then getting increasingly complex here, the red line on the right there is what you get if you just try and train directly on that level.",
                    "label": 0
                },
                {
                    "sent": "Whereas if you've trained on on level one, when you train on Level 2, the agent quickly maximizes the reward there.",
                    "label": 0
                },
                {
                    "sent": "So 10 up there just means the agents doing it perfectly and again we see this as we get to more and more complex tasks.",
                    "label": 0
                },
                {
                    "sent": "So here the difference is between two and three of the number of objects, different objects the agent may observe, and then the full set at the end.",
                    "label": 0
                },
                {
                    "sent": "So for these agents at least, they need to start out with simple worlds and learning from that and simple spaces or objects before they get to more complicated ones.",
                    "label": 0
                },
                {
                    "sent": "In order for good learning to occur.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can probe sort of various generalizations beyond just whether they can do the task, and they generalize.",
                    "label": 0
                },
                {
                    "sent": "So here we get sort of compositional generalization.",
                    "label": 0
                },
                {
                    "sent": "So at training time we have different objects, different adjectives, and then at Test time we have combinations of adjectives and nouns that the agents never seen in training.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "As you can see in the left at the blue line is training.",
                    "label": 0
                },
                {
                    "sent": "Red Line is testing, so the agents learn to generalize.",
                    "label": 0
                },
                {
                    "sent": "They learn to combine sort of yellow mug, never having seen a yellow mug before.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This also works in.",
                    "label": 0
                },
                {
                    "sent": "In a situation where it's not given the individual items, if it's only ever season composed, it learns to decompose them, learn some decomposed green mug into green and mug, so then it can learn to interpret green prints pencil in terms of those.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is pretty minimal composition, but it's the very starting point of if you think about sort of the most minimal composition you could do these.",
                    "label": 0
                },
                {
                    "sent": "Relative, so as I said, we can change the sizes so we can compare two objects and ask for if the agent is 2 objects in the room.",
                    "label": 0
                },
                {
                    "sent": "We can tell the agent to get the larger one.",
                    "label": 0
                },
                {
                    "sent": "And it can have.",
                    "label": 0
                },
                {
                    "sent": "It might have seen balls and know the larger ball, but never seen a pencil before, but can still learn to interpret which one is larger than the other.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, coming back to that issue of sample complexity in all these plots.",
                    "label": 0
                },
                {
                    "sent": "If you look at the X axis it looks a bit dire 'cause that's a lot of training episodes and as I said, the cool thing about children as they learn so quickly these agents don't learn quickly.",
                    "label": 0
                },
                {
                    "sent": "They take a lot of training so our best agent there that's got all of the auxiliary's are still taking about quarter of a million episodes before it takes off with learning.",
                    "label": 0
                },
                {
                    "sent": "So this is really the very sort of starting point for this sort of.",
                    "label": 0
                },
                {
                    "sent": "Training an agent.",
                    "label": 0
                },
                {
                    "sent": "Somehow we need to learn how to do this from a great deal less experience.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, other cool things about the agent is so.",
                    "label": 0
                },
                {
                    "sent": "Whether this is intuitive, not it's sort of interesting, but the more words and agent knows, the faster it learns other ones.",
                    "label": 0
                },
                {
                    "sent": "So the red line there is just starting from scratch with an empty vocabulary.",
                    "label": 0
                },
                {
                    "sent": "The green and blue lines.",
                    "label": 0
                },
                {
                    "sent": "If the agent already knows a few words.",
                    "label": 0
                },
                {
                    "sent": "And then these rewards are, on other words, as it tries to learn them.",
                    "label": 0
                },
                {
                    "sent": "So if an agent already knows 2 words, which is the green line, then it very quickly starts to learn other words much more quicker, much more quickly than the red one.",
                    "label": 0
                },
                {
                    "sent": "If it knows 20 words and it's very quick.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interesting.",
                    "label": 0
                },
                {
                    "sent": "So it's already been trained and get some perfect reward on those two words.",
                    "label": 0
                },
                {
                    "sent": "And then that those results are on extra words as we add more words in.",
                    "label": 0
                },
                {
                    "sent": "So an agent that knows the words it's already started to understand something about doing tasks that started to segment its world, and then it becomes much easier for it to integrate more words.",
                    "label": 0
                },
                {
                    "sent": "So this may be a bit of a Longbow, but there's a great deal of interest in language acquisition at this idea of vocabulary spurt, which about 18 months old children go from learning very few words, maybe one a day or less to suddenly learning words very quickly, multiple words per day.",
                    "label": 0
                },
                {
                    "sent": "And this is known as vocabulary spurt and it happened very rapidly and it changes a bit when it happens, but it's roughly around 18 months.",
                    "label": 0
                },
                {
                    "sent": "These graphs on the right from actual children they suddenly take off in the number of words they know so that the left access areas a number of words.",
                    "label": 0
                },
                {
                    "sent": "There's lots of theories about why this happens, and a good one is.",
                    "label": 0
                },
                {
                    "sent": "It has to do with sort of the lexical network.",
                    "label": 0
                },
                {
                    "sent": "As a child knows, knows more words than they can understand new words in the context of what they know.",
                    "label": 0
                },
                {
                    "sent": "And it seems very similar to our agent, so once it knows a few words then it really takes off and can learn more very quickly.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's it for this lecture, so I've gone right through sort of hierarchical composition in language syntactic structure and then onto semantics and grounding.",
                    "label": 0
                },
                {
                    "sent": "At the end, all of these things we're still a long way from human level processing.",
                    "label": 0
                },
                {
                    "sent": "In both they are sort of models, understanding of syntactic structure in language and also in terms of these environments.",
                    "label": 0
                },
                {
                    "sent": "Obviously they're incredibly simplistic in terms of what humans face and in terms of the.",
                    "label": 0
                },
                {
                    "sent": "The problems but.",
                    "label": 0
                },
                {
                    "sent": "There's lots of reasons we should be hopeful that we can tackle some of these problems, But some of the interesting ones are really not so much the models that we focus on all the time, but coming up with environments that really allow us to learn these things.",
                    "label": 0
                },
                {
                    "sent": "So how can we extend these sorts of environments?",
                    "label": 0
                },
                {
                    "sent": "They showed such that we can have agents really learn hierarchical compositional structure for language.",
                    "label": 0
                },
                {
                    "sent": "How can we have them really learn large vocabularies which allow them to interpret the real world and all these sorts of things?",
                    "label": 0
                },
                {
                    "sent": "But yes, that's it for me.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}