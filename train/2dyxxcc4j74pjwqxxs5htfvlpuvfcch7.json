{
    "id": "2dyxxcc4j74pjwqxxs5htfvlpuvfcch7",
    "title": "Learning Deformable Models",
    "info": {
        "author": [
            "Yali Amit, Department of Statistics, University of Chicago"
        ],
        "published": "July 30, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/mlss09us_amit_ldm/",
    "segmentation": [
        [
            "I'd like to 1st thank the organizers for organizing such a nice conference mission.",
            "Partha and Steve's very.",
            "Interesting collection of subjects and talks and as a local.",
            "I'd also like to tell you that usually this Hall is used for very intense political meetings, so for me it's very strange to sit here and or stand and give a scientific talk.",
            "It's not the usual use of this auditorium, so you should imagine some fire brand talking from the stage as opposed to a cool mathematician or computer scientist."
        ],
        [
            "So I'm going to try to.",
            "Describe an approach that is maybe you could call it more traditionally statistical in the analysis of image data.",
            "In which we actually describe generative models for the data as opposed to thinking of the data as points in some space.",
            "Still have the board up there.",
            "Um?",
            "And let me try to argue why this is very useful.",
            "Generative models allow us to move from learned objects to making online decisions on object configurations.",
            "In an image.",
            "One thing that you have to keep in mind when you're thinking about the grand problem of computer vision is that ultimately you want to take in images that have many objects you don't know where they are.",
            "They might be including one another, and so on, and you want to be able to use the information that you learned when you saw individual objects to be able to online make decisions.",
            "About configurations of objects and when you have models for data.",
            "For data given object configurations that are composed from models from individual object, that's something you can do online, so that's a very important aspect, and you'll see a little bit of it as I go along.",
            "Although the main focus here will be on how we learn the models.",
            "Also, generative models for object allow us to learn the object models one at a time.",
            "We don't have to learn decision boundaries.",
            "We basically learn how to represent a certain class of an object using the data we have and if additional data comes from that object, we can enrich the model.",
            "If a new object comes along new data, we create a new model and basically we go along like that and then decisions again are basically made on.",
            "Comparing likelihoods of data decisions in terms of classification of individual objects or deciding which configuration of objects is in the scene or in the image, that's based on likelihood comparisons.",
            "Now the third thing is that proper modeling involves taking into account invariances and variability that are inherent in object classes in images.",
            "You're actually forced to think how to model these variabilities and.",
            "Although you have to spend some time modeling, you can't just immediately throw in a cost function and start computing.",
            "But the gain is that you can learn these models with much smaller samples than are typically used in classical discriminative methods.",
            "And one other thing is, it's kind of hang up of mine.",
            "I don't like learning with large large numbers of background images, which is something that's typically done in many applications, at least in my experience.",
            "You can get away without that."
        ],
        [
            "So object classes are recognized in data modulo strong variations, both geometric variations and photometric variation.",
            "Something we have to remember that if you looked at an image and you changed and you went into GIMP or Photoshop and change the intensity scale of your image, even did it separately in different parts of the image, you would still recognize everything you see in the image.",
            "Our visual system is very invariant to that.",
            "If you think about any of the linear operators that you've seen in the past few days.",
            "Apply to an image where you've done some nonlinear transformation or even a linear transformation.",
            "The Gray levels that response of these linear matrices that are these.",
            "These dictionaries for example that you would apply it would be very sensitive to these transformations.",
            "Something to remember.",
            "So there's both strong variations that are geometric and photometric, and so just as a wink to the highly mathematical level of this conference, which is way above me.",
            "I wanna say that these variations are modeled as some group acting on the data or on the model.",
            "I'll explain this more later on.",
            "And so ultimately, what we want to do is model object appearance through the group action on a template or a model which then undergo some degradation to become observed data.",
            "So think of you have a model for a seven, there is some deformation that Maps it into the image.",
            "There could be other junk in the image.",
            "It's not necessarily just the seven, and this deformation comes from some distribution on deformation that describes the variability of.",
            "The seven and on top of that, there's some degradation.",
            "There might be some noise.",
            "There might be some other things that happen.",
            "But that's the basic idea, and just as.",
            "A hint into what I was saying earlier, although I'm not going to talk about it very much.",
            "You have to think that what the ultimate goal is is to be able to take object models and then analyze an image that has several objects in it and decide which sequence of labels is the most likely sequence.",
            "That will explain the data in this image."
        ],
        [
            "So.",
            "I think if you take go away from this talk with this picture, that's probably all it's important.",
            "Look at these three instances of an arc in an image.",
            "They're identical arcs.",
            "They have a different location, a slight, somewhat different rotation, and maybe a different intensity.",
            "Level, and maybe there's some noise, and basically these are three instances of the same object.",
            "If you took these images as elements in R, whatever 256.",
            "They would be extremely far apart under any metric you would impose on that space.",
            "In fact, they could be as far from each other as from objects that look entirely different.",
            "OK.",
            "However, if you know that there is an underlying trend, there are underlying transformations that are taking place here.",
            "You can basically recover the fact that these are all the same thing.",
            "Modulo certain translations, rotations and contrast changes, and so this, uh, modelling modulo deformations, it could be simple deformations, like here which involve just rotation, translation and contrast, change or nonlinear deformations, which I will describe later on.",
            "That provides a very rich structure.",
            "To analyze images which I believe is fundamental because I don't think our visual system would have been able to function without these, this very rich structure which allows us in some sense to.",
            "Ahead of time.",
            "Understand a lot about what people like to think of which is the manifold structure of the data.",
            "Because we know how these deformations act on the data.",
            "So just remember this picture and you can go.",
            "So as I said, this structure here would never be the commonality of the.",
            "If this was your sample.",
            "You would never discover through dictionary searches or through various more sophisticated searches for manifold structure, you would never discover this structure.",
            "If you knew that things are perturbed modulo certain families of transformations, you could recover, and that's why.",
            "Also, you can learn these things with once you model these deformations you can learn these structures with much less.",
            "That data"
        ],
        [
            "So let's try to formulate this mathematically.",
            "So this is the picture we had before.",
            "We have some model, it's deformed into the data and so you have the data on a pixel.",
            "Lattice access is distributed according to some distribution at at the Point X in the distribution is determined by the deformed template feti.",
            "At X of S and I will give different examples of what I mean by fee of T. It's some deformation acting on the template model.",
            "And there's some parameter that you might there still parameters that you might have to estimate in addition to the template itself.",
            "The template is not given has to be estimated.",
            "Now, one thing that really is unavoidable if you want to do computationally efficient algorithms is you have to assume that conditional on the deformation on this on this instantiation variable, once you know that the data in the image, whether it's the pixel data or you have some features that you are computing.",
            "The data is assumed independent and so the data models become just products of these types of terms, and you might also have you actually have to have models for what happens on the parts of the image that are not on the support of the object.",
            "That's what this S of T is.",
            "It's saying the seven occupies a certain part of the image on that part of modeling the data according to the DEFORM template, but I need to have also modeled for what's happening.",
            "Outside the the the the the form template because you have to explain or model all the data, especially if you're going to compare different hypothesis about what's happening, you have to compare the likelihood under different hypothesis of the same data set and so that's very important.",
            "But I'm not going to talk much about background modeling and such because again the emphasis is on estimation.",
            "So this is again I is the observed data on a lattice.",
            "T is the template that can be defined in the continuum and then sampled after it's deformed.",
            "On the lattice fearsome group element acting on the template and as an example, the most common example would be that fee T of X is T composed with fee inverse.",
            "That's the classical deformable template formulation.",
            "And maybe I should say here that this formal template formulation is probably should be attributed to old grin and are who's been talking about it for probably half a decade in various books that are very hard to read, but the concepts are very deep in all the theories that he has been developing and.",
            "And finally, as I said, F is a distribution observation.",
            "So think of an example where you take the template, you deform it and then the pixel values are normally distributed around the template.",
            "The form template value with some variants that you have to maybe estimate.",
            "Or maybe you know.",
            "But the main goal is to estimate the template from samples of the objects.",
            "And you want to also estimate a distribution on the set of possible deformations.",
            "So just as a contrast in terms of thinking in terms of what Steve was talking about earlier as points in space where you have some metric information but you don't have any.",
            "Action Group action that that preserves the semantic properties of the object, namely that the object class is invariant under these actions.",
            "You have much less structure.",
            "Here we're exploiting a much richer structure.",
            "Now, as I said, we introduced the notion of group.",
            "In the end, you don't really think that the whole group is acting on the template.",
            "It's some subset of the group around the identity.",
            "You're not going to perturb A7 and stretch it all over the place, and so on.",
            "So I mean there.",
            "It's a limited deformation."
        ],
        [
            "How can we estimate these templates?",
            "Well, that's a pretty painful problem because we don't observe when we have data.",
            "When you have examples of.",
            "Sevens or twos or whatever.",
            "We don't get to see the underlying deformation that produced that.",
            "In fact, it's a figment of our imagination, but it's a very productive, useful figment of our imagination.",
            "So basically, you are in the situation of estimating things when part of the data is unobserved, so it's kind of expectation maximization context that you can use and just to go through some details here.",
            "We can parameterize the temple.",
            "Remember, the template is a function in the continuum, so we can expand it in some basis.",
            "The basis could be some kernels could be some orthonormal basis.",
            "That's an, it's just parameterized by the coefficient, and then we have.",
            "Images.",
            "Samples of the object and we want to maximize the likelihood of the observations.",
            "Now, if we knew the deformations, if we knew them, then we can write the full likelihood and maximize in the parameters gamma an it's not that bad because if Phi is for example acting like I showed before which you compose it with the inverse of fee.",
            "It's a linear functional on functions.",
            "It's not linear, but it's a linear functional and functions and then basically the FI acting Auntie acts on each of the basis elements or each of the functions that you are using to expand the template and you can.",
            "Since you know fee, you can just compute this as a data matrix.",
            "So for every pixel you go and observe the deformed basis element at that pixel Ann, you have that for each of the J each of the our basis element and then ascentia Lee given.",
            "Given the deformations given the fees, the gammas are just estimated through regression.",
            "OK, so although it's a highly nonlinear situation, if you know the fezan, you know the basis.",
            "You can deform the basis you have to do it separately for each example.",
            "It's not one deformation of the basis.",
            "Each example has its own basis deformation, and you know for those of you who are used to working in the L2 settings and so on, you know this is not a typical thing where you start warping your basis to please every data point.",
            "But if you have the observed data you can do that and then you can estimate the parameters of.",
            "The coefficients that go into the template using simple regression.",
            "If your model is Gaussian like the one I said before, if your observation model if F is a normal distribution.",
            "If F is something else, it might be some other type of nonlinear regression.",
            "But these are context that we can work with pretty easily.",
            "Once we have this X matrix.",
            "And of course, if you have the samples, you can parametrize the distribution.",
            "If you have the deformations, you can parameterise the distribution there.",
            "An estimate that."
        ],
        [
            "When you have an observed deformations, which is the current situation, which is the real situation, then you try to iterate and at each step you try to develop a distribution on the deformations given the current parameters and the image.",
            "And that's a pretty complicated distribution.",
            "The product there it had to remind you is because we're assuming the pixels are independent.",
            "Given the deformations, you have a product over the pixels in the image of the likelihood of the data.",
            "Given the deformed template at that pixel.",
            "So if Y is finite and we're going to look at an example where the set of deformations is discrete and finite manageable, then you can compute this explicitly.",
            "You just do Bayes rule and you did.",
            "You normalize this by summing over all possible values of the deformation?",
            "If not, one alternative is to use complicated Markov chain variations on EM or the simple alternative is just to basically an alternative to EM is just you do Max Max so.",
            "At every step you find the deformation that maximizes the current joint distribution, and you use that as if it's the observed.",
            "Deformation and basically what it says is given the current parameters of the template you're trying to find the deform and and the distribution on deformation trying to find the deformation that best matches each image and that becomes your that goes into the next step of the loop.",
            "And so do."
        ],
        [
            "Doing these kinds of things here is just a sample from a toy example from the US Postal set.",
            "And just to illustrate the idea, this algorithm was run here on.",
            "I believe there's 40 examples per class.",
            "The top 10 images are just simple averages that you would get if you average these images.",
            "Now these images, although there affectively binary, they were treated as if the template that you had.",
            "Added Gaussian noise to the template, so it's it's it's the Gaussian model we will move away from that in a minute.",
            "Down below you see the templates that are estimated using this procedure and what you see is that because you have factored in the deformations, you get very very sharp descriptions of the different classes.",
            "I'm not going to dwell too much on this because there's some inherent problems in this model, one of which that we don't model changes in contrast, so this model would fall apart if suddenly you made all the images half as bright.",
            "Now of course you could say, oh, if they're half as bright, you can normalize.",
            "But let's say you don't know that you can normalize then this model falls apart and dealing with contrast is a very important element.",
            "So in general you think about the variability that exists.",
            "In the appearances of objects, I said is geometric and photometric, and there's always an interplay between the part of the variability that you model explicitly and the part that you try to.",
            "I say modded out OK, Sir, you can compute certain features on the data that are invariant, or at least very robust to certain parts of the variability, and then you don't have to model that Anna.",
            "Typical thing that's done in computer vision is to transform.",
            "The Gray level data to oriented binary edge date binary oriented edge data which a lot, which in some sense not perfectly but are strong, are invariant.",
            "Let's say to the changes in intensity that are so difficult to deal with and so from now on we will look at that time."
        ],
        [
            "Above so here's just an example.",
            "Here's an image of a face, and here you see, there's very crude edges.",
            "Basically, looking at local Maxima of the gradient in different directions, and you see horizontal and vertical edges on this face.",
            "So now the image data is transformed and we have in some sense modded out the variability to contrast.",
            "Now, one thing to keep in mind is now our data is binary.",
            "You can't think of this anymore as a linear space where you can model things as sums of dictionaries.",
            "It really doesn't make any sense anymore, yeah?"
        ],
        [
            "In the case of the digits, what was the group fee that you use it?",
            "It was exactly it was OK. Basically you had another set of basis elements, and you, the group was basically you describe the deformation as the identity plus a small term that was expanded in some basis elements.",
            "So you I cannot guarantee by the way that it was a group that it was an actual diffeomorphism, it was.",
            "A map of the domain into itself that was close to the identity and therefore mostly one to one.",
            "This element, however, in this case they were kernels with knots at some regular space rates, but you could do the same thing if you wanted with some other basis with wavelets or so.",
            "You basically expand the displacement of each pixel in the two components of the displacements of vector field in the basis.",
            "No, no, no that is.",
            "No, no.",
            "They were kernels.",
            "They were very smooth.",
            "Actually they were kernels.",
            "Yeah yeah yeah.",
            "5.",
            "No, no fi is not at all a linear function in this context.",
            "Sorry if you go back.",
            "Oh, this doesn't go back that way, I'm sorry."
        ],
        [
            "Here 5 is not a linear function, Phi is.",
            "You can think of it as I said, it's the identity map plus a vector field which is expanded in a finite basis with some coefficients.",
            "OK, so it's a map that is not guaranteed to be one to one, but it's very close 'cause it's not so far from the identity.",
            "Now there are more sophisticated methods that can develop, can make defies real diffeomorphism so that.",
            "When you talk about a group, you're really talking about a group, but that's that's not something I'm going to.",
            "That's also computationally very."
        ],
        [
            "Expensive so.",
            "Let me skip.",
            "Well, let me just say that sometimes it's easier to transform the data into the template rather than transforming the template.",
            "This is kind of a shortcut.",
            "So if you know the deformation, you can say that if I compose I with the deformation and do some feature extraction on the deformed image, I get a set of features and you can try to learn the template that way, namely that the the.",
            "Data that you get after deforming the image, say rotating the image or scaling the image and then extracting features is distributed according to something that is determined by your template.",
            "So instead of deforming the template into the image, you deform the image into the reference grid of the template.",
            "This is not really a generative model for images, but once you estimate this, you can actually produce at least if the fees are discrete set.",
            "You can produce models for.",
            "Each possible deformation of the template I don't want to.",
            "I don't have time to go into the details here, but actually we use this quite a lot because it saves some time."
        ],
        [
            "And I want to."
        ],
        [
            "This and now I want to go into the idea that we know intuitively that even simple classes like handwritten digits which are really simple classes and it's a good framework to think about things, not all versions of a handwritten two are going to be able.",
            "You're going to be able to create from one deformable template.",
            "There are certain there different types of two that are topologically different and cannot be obtained one from the other safe.",
            "There's a loop at the bottom or not.",
            "And so you want to model object classes as mixtures of deformable templates.",
            "So in addition to the UN observed information you have now a none observed component membership variable that you have to deal with in the EM and I will get back to this problem.",
            "But first, kind of as a response."
        ],
        [
            "Wants to stuff that I heard yesterday.",
            "I want to talk about the issue of very, very simple deformable templates to model the microworld.",
            "So this this business of dictionaries.",
            "So up here you have samples from some random images, just Gray level images of the world down here you have a sample of 6 by 6 sub images from the population of handwritten digits.",
            "So these are different populations.",
            "OK, now you can decide.",
            "To just estimate a mixture model for this data now remember because we don't want to deal with the problem of contrast, we want 22 patches that are the same except for a contrast change to be effectively the same thing.",
            "And that's why we transform this data again into binary oriented edges.",
            "So we have binary data now arranged on the grid, as opposed to Gray Le."
        ],
        [
            "All data and we model.",
            "This population is a very simple thing.",
            "So when I write XX plus WR with square bracket around I, it means that I extract.",
            "The binary edges in a window of size W around little X from image I.",
            "And now I'm saying that this population is a mixture of some number of models.",
            "And each of the models.",
            "Under each of the models, if you come from that component.",
            "The edges are all independent.",
            "OK, it's a very strong assumption.",
            "The edges are all independent and basically the model is summarized very simply by the probability at each pixel.",
            "To get an edge.",
            "So here I don't enumerate the edge types.",
            "There shouldn't be an E down there because I just want to simplify notations.",
            "Images just one binary feature.",
            "So at each location you have the probability for that component for that feature to be there, and 1 -- P is the probability for that feature not to be there.",
            "So I called these Bernoulli models.",
            "They're independent Bernoulli variables.",
            "For each component so of course.",
            "The marginal distribution when you after you mix things.",
            "The data is not at all independent, so our model of the world is not assuming that pixels are independent, but there are independent conditional on the component you come from.",
            "Now you can train a model like this in a few minutes.",
            "From any of those datas, here are 100 or 99 mixture components that were obtained from from the handwritten data.",
            "Using this EM, and it's a very, very stable EM can be unstable, but when M is working on binary variables, it's dynamite.",
            "It goes fast and it's stable and nothing crazy ever happens and you can initialize it randomly and it's fine.",
            "So what you're seeing here is the mean Gray level image for eat.",
            "For the image that fell in each of the components.",
            "So I 'cause he's hard to look at edge data.",
            "These are the mean images and what you see is what you see when anybody makes some kind of dictionary for local data, you see bars and corners and some maybe maybe it's not big enough to see intersections, but if you made the image is a little bigger, you start seeing intersection.",
            "No surprise there.",
            "Now let's put in the idea of a deformable template, we know.",
            "Is that we can look at the world standing on our head or standing up and the statistics shouldn't change very much.",
            "So we know that there is a rotational symmetry in these in this microworld.",
            "So let's estimate a mixture of deformable templates for this microworld, where the only deformation is just rotation.",
            "You could also add for example rotation an shifts because after all you're not always observing something perfectly central, but forget the shifted small enough.",
            "You could do.",
            "You could estimate modular rotations and inversions because sometimes you're looking at a black on a white or sometimes white on black and that should also be in some sense the same thing, so you can."
        ],
        [
            "Define.",
            "The notion of applying a rotation to the edge data by saying you wrote to instead of applying the rotation to the AAD data, especially if the rotations are.",
            "Finer in resolution than the edge angles you.",
            "It's easier to think of it as rotating the image and then extracting the edges.",
            "That has to do with this idea of transforming the data into the reference grid as opposed to transforming the template.",
            "And then, if you know for each one of these micro image samples which component it came from and which angle it came from, then this is simply the estimates of the model.",
            "So the estimate of the model would be if X comes from angle a produce, rotate the image by angle A, get the edges and count how many times you got an edge at pixel Z.",
            "That's the probability that a model.",
            "At C, and from that you can then generate each one of the rotated models.",
            "And again, if you don't have F and a, they're not observed, you can do EM.",
            "In this case you can do EM explicitly, because the group here is discrete.",
            "You can do 16 angles, 24 angles doesn't matter.",
            "It's a small group.",
            "And the nice thing is that once you introduce angles, you only need a very small number of components in the mixture model, because you're already all of this stuff that you had here.",
            "All these rotated versions of the same thing.",
            "Are not now going to fall under the same mixture component and so.",
            "OK, this is just an."
        ],
        [
            "Rotation for the M and so here's what you get.",
            "So for example, if you take the data from the handwritten digits, you say I want seven components and I want 16 angles.",
            "These are the mean images.",
            "The first column are the mean images you get in the actual 7 components, and then each one you're shown the rotated template 16 times the mean images of the rotated template.",
            "But the computation is all taking place on the edge Maps, not on the Gray level.",
            "So these are this is a mixture model of the microworld which is invariant to Gray.",
            "Level transformations are almost in fact this is obtained from some sample of micro images.",
            "I think taken from cats, just to show you it's not that different.",
            "You know the microworld is not that.",
            "Different even between handwritten digits and cats.",
            "A little different, but.",
            "So.",
            "You get."
        ],
        [
            "These and why is this interesting?",
            "So this is just a simple illustration of the idea of estimating a deformable template where the deformations in this case linear just rotations simple.",
            "You get this you can do this in a few minutes for any sample that you take.",
            "Tufts of microworld images and you get a library.",
            "Avara Dictionary is some people like it, but it's got structure now, so it's not only that you basically reduce the complexity because you introduce the fact that there's rotation.",
            "So you basically only had to estimate 7 components.",
            "You want 10 components.",
            "You can play around with that, but that's about the order of magnitude.",
            "You have structure in your dictionary now and you know what?",
            "Part of the dictionary's rotation is a rotated version of another part.",
            "But another reason this is interesting is that.",
            "These parts are really local descriptions of objects because one thing I didn't tell you is when you estimate this mixture, you throw away samples that do not reject a null hypothesis that it's kind of a flat.",
            "Part that there's nothing going on, so there's a good chance that all these things you've got are parts of objects, and so the idea comes, which is to say why don't we re code the image now in terms of this dictionary, where at each point?",
            "We can say which element of the dictionary is most likely, but then we can describe this at a much lower resolution.",
            "Because once you know which element of the dictionary was present in a neighborhood, it basically describes the entire neighborhood.",
            "You don't need the full resolution.",
            "Maybe you can't reconstruct the image, but it preserves a lot of.",
            "Information, so that's that."
        ],
        [
            "Next step is to use.",
            "I call it Part Basic Color dictionary based representation.",
            "You now make a new transfer.",
            "You went from Gray level to oriented edges and now you transform the images one more time.",
            "At each point you can ask which.",
            "Dictionary most gives the likelihood of the data is maximized under which of the models you assigned that label to that that point.",
            "So there's the component and the angle, and then you can course in the data and what that is the same as introducing the edges in order to MoD out Gray level variability when you course in the data on a coarse lattice using this maximization operation, you're basically modding out.",
            "A large degree of variable geometric variability, both shifting and rotation, because you're maximizing over angles in the neighborhood of the angle that you're coding for, and so basically you're saying on the coarse lattice the pixel corresponds to some area in the original image where there existed this part model.",
            "I don't know exactly where it was, and it might have been at.",
            "You know, one index of rotation.",
            "Away from the current index, and this introduces a huge amount of invariants.",
            "In fact, you can introduce too much invariants, namely, if the coarse lattice is its size is the same as the dimension of the image you you're basically recording everything at one pixel.",
            "That's what people call bag of features.",
            "So bag of features is just one point on a continuum of the introduction of invariants.",
            "Now one deep problem, which I don't know.",
            "The solution I don't even know exactly how to formulate it mathematically.",
            "Is what is the trade off and how do you find the correct tradeoff between invariants and specificity?",
            "Because what happens when you introduce too much invariants of the representation?",
            "You might not be able then to discriminate between things, so that's a hard problem.",
            "And now once we have this new.",
            "Representation of the data in terms of binary features on a coarser grid, we again model.",
            "Now say we want to model objects OK, we started modeling the microworld now in terms of these model objects, again is a mixture of Bernoulli models, so conditional on the mixture component, the probability of finding any one of these features in the mixture component will be.",
            "The probabilities will be independent.",
            "Variables will be independent and so in contrast to what Galmore was telling you yesterday.",
            "Um?",
            "You get very very powerful classifiers on amnesty, for example using this very, very simple architecture that takes maybe 10 minutes from the sampling of the microimages all the way to the classifier to train on a computer.",
            "It's trivial.",
            "This is all 40 years old statistical techniques.",
            "There's nothing fancy and you can see, for example, if you take 30 example for class, so you're estimating only using 30 digits from each class.",
            "And you do 2 mixture components per model.",
            "My rule of thumb is you want about 20 examples per mixture component to get a reasonable estimate of the probabilities, you get 4% error.",
            "This is 30 examples.",
            "There's 6000 examples from each class in the Emnace data set.",
            "By the time you're up to 1000 examples per class, you are at 1.5 and the point is you did not train the the components of your dictionary.",
            "Based on the task of classifying, you just tried to model the microworld modulo certain invariances."
        ],
        [
            "So now I just want to talk about another framework where you can estimate using nonlinear deformations, estimate object models, objects that are represented in terms of the edge data.",
            "So you're again estimating probability Maps.",
            "These models will be invariant to contrast, 'cause they're based on the edges, and in this case the idea of the deformation is very simple.",
            "You have a number of points Z1 through Z on the reference grid.",
            "And each point is shifted, and that's how we represent the deformation.",
            "I now have to tell you how that deformation acts on the template.",
            "OK, 'cause that's just meaningless at this point.",
            "So here's a picture.",
            "Imagine that what you see here is the probability map in black.",
            "It's high probability for a certain feature an as it gets lighter, it's low probability, and each of the Reds dots is one of those Z points.",
            "You take a window around it, and the Tau tells you how to shift it.",
            "So each of these Windows gets shifted according.",
            "To the displacement assigned to the center.",
            "So you have N shifts an end center points.",
            "Now when you shift these probability Maps, they become inconsistent.",
            "If you don't shift them and you look at a pic so it's got two probability Maps above it, there are signing the same probability, but when you shift that, they're inconsistent and so we do what's called a patchwork of parts.",
            "Once you shift them, every pixels finds all the windows above it and averages the probabilities there.",
            "That's the action of the deformation on the probability map, so in this case it this is the formal definition.",
            "Every pixel in the image, so think of that too, or that too is an image.",
            "You have a bunch of shifts, towel.",
            "Assigned to each of the red dots and every pixel finds out how many of these windows shifted windows is above it, and the probability assigned to that pixel now.",
            "Orphee P of X now is the average of all the probabilities that that Pixel sees from the different windows, which aren't necessarily the same.",
            "So if Tau is 0 for each of these reference points, then the probabilities are the same, and so this average is equal to each one of the terms and four pixels that are not covered by any of these patches.",
            "Then there's some background probability, and as I said, I don't have time today to talk about background, but it's a whole story in itself.",
            "So this is what we call patchwork of parts models and we also have."
        ],
        [
            "The formulation for Gray levels, which introduces an explicit modeling of contrast and intensity.",
            "Because we're trying to actually think of how the image is generated with different lighting conditions and so on.",
            "But this is work in Prague."
        ],
        [
            "Horse to train apart model.",
            "Is not so difficult as long as you decide to train each one of those patches separately, and it turns out it's not such a big.",
            "There's not much loss in training each of the parts separately, as long as the training data is is not too noisy, so each of the parts basically is trained where the only deformation parameter is a shift.",
            "In the same spirit as we were training the microworld model model rotation here it's modulo shift and it's a very simple EM algorithm that finds the probability map locali around a certain area of the image and then you can Patch together these probability Maps and you get.",
            "Sorry."
        ],
        [
            "You get something like this, which in fact is a patching together of probability Maps that were estimated separately from samples of two.",
            "And again you see how this probability map once you try to now.",
            "You give it 2 new samples and you're trying to find what are the optimal shifts to explain the data you're able to take this template, and using these shifts, modify it to match these different instances of the object."
        ],
        [
            "So this is an example where you have a nonlinear type of deformation acting on binary features.",
            "Well, the deformation is acting on the template, but the observations are binary.",
            "And it allows us to even further, so I won't go into the details of how it strains the same idea.",
            "It allows us to go.",
            "Sorry, I'm not very good at.",
            "Almost done."
        ],
        [
            "And so, just to wrap everything together.",
            "The part based representation.",
            "Think of it as modding out a lot of the variability and so you basically don't have to deal with this UN observed deformation variable and therefore it's very easy to estimate the mixtures in the population corresponding to a particular class.",
            "Then for each of these mixture component that you estimate based on the course part models, you can estimate using the images in each one of the mixture component.",
            "You can estimate your pop model.",
            "So what you're looking at here is the following.",
            "Mixture models were estimated on each one of the classes separately.",
            "Every estimations separately in each class there's 100 examples per class.",
            "So you get the five mixture components, each mixture component.",
            "The pop models were estimated based on the oriented edge data.",
            "Each component of the pop model, each window that's estimated.",
            "It's based on the edges, but after you estimate the shifts, you can compute the mean image just for visualization purposes, and then you can Patch together the mean images using the same average income operation, and this is what you get.",
            "So what you have here is something very indirectly obtained.",
            "From the original image data, it's just showing you a visual representation of the class.",
            "Is the actual models are models on edge probabilities on edge data, not probabilities on grade level.",
            "But this is a visual representation that gives you a feel of what is estimated in the different classes.",
            "So using say 400 images in the Olivetti data set, estimating a mixture component, estimating pop models, you get these four.",
            "These five quasi individuals, but they're not really an individual, these are.",
            "Patches Patch works of averages modulo deformations that were obtained during the estimation procedure.",
            "Same for you could do for horses or for other objects."
        ],
        [
            "And so using this methodology which allows you, as I said to also deal with object configurations in a in a principled manner, you can get, for example, if you look at that again at the in this data set.",
            "I don't have it together with the course part models, but for example with 100 with 1000 examples for image with the course part model, the error rate was 1.5 and then if you add this extra layer of.",
            "The pop models you can reduce the error rate to .8 and this is very stable.",
            "You can take any subset of 10,000 images of the training set and get similar results.",
            "It's not a particular fine tuned result on this particular training set and.",
            "I think the more interesting results are for example, what happens if you're training with 30 elements per class.",
            "You know you can get your error rate down to 3%.",
            "We just seen 30 examples of each one of the classes OK, but beyond that, whenever you're thinking about classifying digits, you want to think what's the next step.",
            "If I know how to classify digits, what will I do when I want to read zip codes?",
            "OK, and this allows you.",
            "This framework allows you to actually formulate that problem as a likelihood maximization problem and deal with it similarly.",
            "Reading license plate.",
            "Similarly you can use the same types of models to try to detect faces in an image.",
            "And you know you can train your model based on a small set of faces, say 400 faces.",
            "You never have to see a background image in your life beforehand, and using an adaptive background model that gets modified as you move along in the image, you can get basically state of the art detection results on these standard face datasets and so."
        ],
        [
            "Let me just go to the conclusion.",
            "So the importance of modeling variability is a hidden random variable.",
            "The estimation of templates and mixtures through OEM types of algorithms in the local world that provides parts or dictionaries with symmetries and for at the object level.",
            "Of course you have to introduce nonlinear deformations.",
            "There's the idea that instead of modeling variability you somehow Max over simple subsets of the deformations to obtain object parts.",
            "Um?",
            "This is something that needs formalization intuitively.",
            "We know what we're doing, but it would.",
            "It's something that's really.",
            "I think there's something deep going on there in terms of how we approximate.",
            "The complicated deformation of the full blown objects.",
            "In some sense, this is a computational tool.",
            "It's something that allows us to do things quickly.",
            "Once we MoD out the variability, formalizing and trying to think what are the optimal ways of doing this, I think is a very deep questions which I don't know the answer to.",
            "So really for object recognition, there's a very rich structure in the subject matter beyond linear operations and function spaces.",
            "Distances should not be measured directly in observation space.",
            "The quote unquote manifold is defined through the group action.",
            "It's we already, in some sense know what it is.",
            "If you give an example, if you have the template, you somehow because you know what deformations are possible, you know what the manifold is, and I think there's a wide range of interesting questions to be studied on this, and it would be good if some of the bright minds and machine learning devoted them to themselves too.",
            "To this type of problem, let me just say one more thing that in some sense I think the same set of ideas holds also in speech recognition.",
            "This is not something that's just true for image analysis in speech recognition.",
            "In the prevailing paradigm of hidden Markov models, the hidden Markov model is a deformation model.",
            "You might not like it.",
            "You might think it should be something else, but it is an inherent model to think about.",
            "The fact that objects deform.",
            "In complex ways, so I'll stop here and answer questions.",
            "Yeah.",
            "I didn't hear you.",
            "In the object model, yes.",
            "So when do you estimate the actual tablets you get at the same time estimate a joint distribution on how these different points move.",
            "Honestly, in the context of just classifying the isolated digits, that information is not that important, but they got is so compelling in terms of how the October part the patches should be form that the extra cost of the deformation doesn't play much of a role.",
            "It plays more of a role in two settings.",
            "One is when you're actually reading zip codes and you have to sometimes refine.",
            "A detection of a particular object you actually have to refine a support of the option, decide what part of the image the object is under.",
            "10 is responsible for an when you're doing detection object detection, like using the face models.",
            "Because there's junk around the face you want to penalize deformations that try to take part of the object model and explain something in the background using it.",
            "So this distribution on deformation helps you constrain how these things move.",
            "But the whole issue of modeling the distribution on deformations is has some deep open questions in it as well.",
            "It's not an entirely resolved issue.",
            "Hard.",
            "I don't ship.",
            "So is this size?",
            "No, this is robust to a certain range of sizes, but saying if you want to detect faces in multiple scales, say you take, you wanted to take all faces within a range of two to one that you would have to under.",
            "In this context, you would have to have models for the larger faces trained separately.",
            "It's not a very good idea.",
            "You can scale the probability map.",
            "But it's not that good because when you scale, the probability that you spread the probabilities and that's not what people know.",
            "Boundaries don't spread when you sail in object, the boundary stays about you, so you don't really want.",
            "There might be a smarter way to actually scale the models without relearning them, but what I do when I'm detecting faces is I'll take the sample faces bigger and re estimate a deformable model for that.",
            "That's a very good question.",
            "In fact, for the digits, because in zip codes, by the way, you know in M NIS the digits are about the same size.",
            "If you take zip codes, the ratio of size even in one zip code can be 2 to one between two objects, so also in the ZIP codes you need with the same training set to produce models for a number of different size.",
            "So small changes in size.",
            "The pop model can accommodate easily, but a large change it can't.",
            "OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'd like to 1st thank the organizers for organizing such a nice conference mission.",
                    "label": 0
                },
                {
                    "sent": "Partha and Steve's very.",
                    "label": 0
                },
                {
                    "sent": "Interesting collection of subjects and talks and as a local.",
                    "label": 0
                },
                {
                    "sent": "I'd also like to tell you that usually this Hall is used for very intense political meetings, so for me it's very strange to sit here and or stand and give a scientific talk.",
                    "label": 0
                },
                {
                    "sent": "It's not the usual use of this auditorium, so you should imagine some fire brand talking from the stage as opposed to a cool mathematician or computer scientist.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to try to.",
                    "label": 0
                },
                {
                    "sent": "Describe an approach that is maybe you could call it more traditionally statistical in the analysis of image data.",
                    "label": 0
                },
                {
                    "sent": "In which we actually describe generative models for the data as opposed to thinking of the data as points in some space.",
                    "label": 0
                },
                {
                    "sent": "Still have the board up there.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And let me try to argue why this is very useful.",
                    "label": 0
                },
                {
                    "sent": "Generative models allow us to move from learned objects to making online decisions on object configurations.",
                    "label": 1
                },
                {
                    "sent": "In an image.",
                    "label": 0
                },
                {
                    "sent": "One thing that you have to keep in mind when you're thinking about the grand problem of computer vision is that ultimately you want to take in images that have many objects you don't know where they are.",
                    "label": 0
                },
                {
                    "sent": "They might be including one another, and so on, and you want to be able to use the information that you learned when you saw individual objects to be able to online make decisions.",
                    "label": 0
                },
                {
                    "sent": "About configurations of objects and when you have models for data.",
                    "label": 0
                },
                {
                    "sent": "For data given object configurations that are composed from models from individual object, that's something you can do online, so that's a very important aspect, and you'll see a little bit of it as I go along.",
                    "label": 0
                },
                {
                    "sent": "Although the main focus here will be on how we learn the models.",
                    "label": 1
                },
                {
                    "sent": "Also, generative models for object allow us to learn the object models one at a time.",
                    "label": 0
                },
                {
                    "sent": "We don't have to learn decision boundaries.",
                    "label": 0
                },
                {
                    "sent": "We basically learn how to represent a certain class of an object using the data we have and if additional data comes from that object, we can enrich the model.",
                    "label": 0
                },
                {
                    "sent": "If a new object comes along new data, we create a new model and basically we go along like that and then decisions again are basically made on.",
                    "label": 0
                },
                {
                    "sent": "Comparing likelihoods of data decisions in terms of classification of individual objects or deciding which configuration of objects is in the scene or in the image, that's based on likelihood comparisons.",
                    "label": 0
                },
                {
                    "sent": "Now the third thing is that proper modeling involves taking into account invariances and variability that are inherent in object classes in images.",
                    "label": 0
                },
                {
                    "sent": "You're actually forced to think how to model these variabilities and.",
                    "label": 0
                },
                {
                    "sent": "Although you have to spend some time modeling, you can't just immediately throw in a cost function and start computing.",
                    "label": 0
                },
                {
                    "sent": "But the gain is that you can learn these models with much smaller samples than are typically used in classical discriminative methods.",
                    "label": 0
                },
                {
                    "sent": "And one other thing is, it's kind of hang up of mine.",
                    "label": 0
                },
                {
                    "sent": "I don't like learning with large large numbers of background images, which is something that's typically done in many applications, at least in my experience.",
                    "label": 0
                },
                {
                    "sent": "You can get away without that.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So object classes are recognized in data modulo strong variations, both geometric variations and photometric variation.",
                    "label": 1
                },
                {
                    "sent": "Something we have to remember that if you looked at an image and you changed and you went into GIMP or Photoshop and change the intensity scale of your image, even did it separately in different parts of the image, you would still recognize everything you see in the image.",
                    "label": 0
                },
                {
                    "sent": "Our visual system is very invariant to that.",
                    "label": 0
                },
                {
                    "sent": "If you think about any of the linear operators that you've seen in the past few days.",
                    "label": 0
                },
                {
                    "sent": "Apply to an image where you've done some nonlinear transformation or even a linear transformation.",
                    "label": 0
                },
                {
                    "sent": "The Gray levels that response of these linear matrices that are these.",
                    "label": 0
                },
                {
                    "sent": "These dictionaries for example that you would apply it would be very sensitive to these transformations.",
                    "label": 0
                },
                {
                    "sent": "Something to remember.",
                    "label": 0
                },
                {
                    "sent": "So there's both strong variations that are geometric and photometric, and so just as a wink to the highly mathematical level of this conference, which is way above me.",
                    "label": 0
                },
                {
                    "sent": "I wanna say that these variations are modeled as some group acting on the data or on the model.",
                    "label": 0
                },
                {
                    "sent": "I'll explain this more later on.",
                    "label": 0
                },
                {
                    "sent": "And so ultimately, what we want to do is model object appearance through the group action on a template or a model which then undergo some degradation to become observed data.",
                    "label": 1
                },
                {
                    "sent": "So think of you have a model for a seven, there is some deformation that Maps it into the image.",
                    "label": 0
                },
                {
                    "sent": "There could be other junk in the image.",
                    "label": 0
                },
                {
                    "sent": "It's not necessarily just the seven, and this deformation comes from some distribution on deformation that describes the variability of.",
                    "label": 0
                },
                {
                    "sent": "The seven and on top of that, there's some degradation.",
                    "label": 0
                },
                {
                    "sent": "There might be some noise.",
                    "label": 0
                },
                {
                    "sent": "There might be some other things that happen.",
                    "label": 0
                },
                {
                    "sent": "But that's the basic idea, and just as.",
                    "label": 0
                },
                {
                    "sent": "A hint into what I was saying earlier, although I'm not going to talk about it very much.",
                    "label": 0
                },
                {
                    "sent": "You have to think that what the ultimate goal is is to be able to take object models and then analyze an image that has several objects in it and decide which sequence of labels is the most likely sequence.",
                    "label": 0
                },
                {
                    "sent": "That will explain the data in this image.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I think if you take go away from this talk with this picture, that's probably all it's important.",
                    "label": 0
                },
                {
                    "sent": "Look at these three instances of an arc in an image.",
                    "label": 0
                },
                {
                    "sent": "They're identical arcs.",
                    "label": 0
                },
                {
                    "sent": "They have a different location, a slight, somewhat different rotation, and maybe a different intensity.",
                    "label": 1
                },
                {
                    "sent": "Level, and maybe there's some noise, and basically these are three instances of the same object.",
                    "label": 0
                },
                {
                    "sent": "If you took these images as elements in R, whatever 256.",
                    "label": 1
                },
                {
                    "sent": "They would be extremely far apart under any metric you would impose on that space.",
                    "label": 0
                },
                {
                    "sent": "In fact, they could be as far from each other as from objects that look entirely different.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "However, if you know that there is an underlying trend, there are underlying transformations that are taking place here.",
                    "label": 0
                },
                {
                    "sent": "You can basically recover the fact that these are all the same thing.",
                    "label": 1
                },
                {
                    "sent": "Modulo certain translations, rotations and contrast changes, and so this, uh, modelling modulo deformations, it could be simple deformations, like here which involve just rotation, translation and contrast, change or nonlinear deformations, which I will describe later on.",
                    "label": 0
                },
                {
                    "sent": "That provides a very rich structure.",
                    "label": 0
                },
                {
                    "sent": "To analyze images which I believe is fundamental because I don't think our visual system would have been able to function without these, this very rich structure which allows us in some sense to.",
                    "label": 0
                },
                {
                    "sent": "Ahead of time.",
                    "label": 0
                },
                {
                    "sent": "Understand a lot about what people like to think of which is the manifold structure of the data.",
                    "label": 0
                },
                {
                    "sent": "Because we know how these deformations act on the data.",
                    "label": 1
                },
                {
                    "sent": "So just remember this picture and you can go.",
                    "label": 0
                },
                {
                    "sent": "So as I said, this structure here would never be the commonality of the.",
                    "label": 0
                },
                {
                    "sent": "If this was your sample.",
                    "label": 0
                },
                {
                    "sent": "You would never discover through dictionary searches or through various more sophisticated searches for manifold structure, you would never discover this structure.",
                    "label": 0
                },
                {
                    "sent": "If you knew that things are perturbed modulo certain families of transformations, you could recover, and that's why.",
                    "label": 0
                },
                {
                    "sent": "Also, you can learn these things with once you model these deformations you can learn these structures with much less.",
                    "label": 0
                },
                {
                    "sent": "That data",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's try to formulate this mathematically.",
                    "label": 0
                },
                {
                    "sent": "So this is the picture we had before.",
                    "label": 0
                },
                {
                    "sent": "We have some model, it's deformed into the data and so you have the data on a pixel.",
                    "label": 0
                },
                {
                    "sent": "Lattice access is distributed according to some distribution at at the Point X in the distribution is determined by the deformed template feti.",
                    "label": 0
                },
                {
                    "sent": "At X of S and I will give different examples of what I mean by fee of T. It's some deformation acting on the template model.",
                    "label": 0
                },
                {
                    "sent": "And there's some parameter that you might there still parameters that you might have to estimate in addition to the template itself.",
                    "label": 0
                },
                {
                    "sent": "The template is not given has to be estimated.",
                    "label": 0
                },
                {
                    "sent": "Now, one thing that really is unavoidable if you want to do computationally efficient algorithms is you have to assume that conditional on the deformation on this on this instantiation variable, once you know that the data in the image, whether it's the pixel data or you have some features that you are computing.",
                    "label": 0
                },
                {
                    "sent": "The data is assumed independent and so the data models become just products of these types of terms, and you might also have you actually have to have models for what happens on the parts of the image that are not on the support of the object.",
                    "label": 0
                },
                {
                    "sent": "That's what this S of T is.",
                    "label": 0
                },
                {
                    "sent": "It's saying the seven occupies a certain part of the image on that part of modeling the data according to the DEFORM template, but I need to have also modeled for what's happening.",
                    "label": 0
                },
                {
                    "sent": "Outside the the the the the form template because you have to explain or model all the data, especially if you're going to compare different hypothesis about what's happening, you have to compare the likelihood under different hypothesis of the same data set and so that's very important.",
                    "label": 0
                },
                {
                    "sent": "But I'm not going to talk much about background modeling and such because again the emphasis is on estimation.",
                    "label": 0
                },
                {
                    "sent": "So this is again I is the observed data on a lattice.",
                    "label": 0
                },
                {
                    "sent": "T is the template that can be defined in the continuum and then sampled after it's deformed.",
                    "label": 0
                },
                {
                    "sent": "On the lattice fearsome group element acting on the template and as an example, the most common example would be that fee T of X is T composed with fee inverse.",
                    "label": 0
                },
                {
                    "sent": "That's the classical deformable template formulation.",
                    "label": 0
                },
                {
                    "sent": "And maybe I should say here that this formal template formulation is probably should be attributed to old grin and are who's been talking about it for probably half a decade in various books that are very hard to read, but the concepts are very deep in all the theories that he has been developing and.",
                    "label": 0
                },
                {
                    "sent": "And finally, as I said, F is a distribution observation.",
                    "label": 0
                },
                {
                    "sent": "So think of an example where you take the template, you deform it and then the pixel values are normally distributed around the template.",
                    "label": 0
                },
                {
                    "sent": "The form template value with some variants that you have to maybe estimate.",
                    "label": 0
                },
                {
                    "sent": "Or maybe you know.",
                    "label": 0
                },
                {
                    "sent": "But the main goal is to estimate the template from samples of the objects.",
                    "label": 0
                },
                {
                    "sent": "And you want to also estimate a distribution on the set of possible deformations.",
                    "label": 0
                },
                {
                    "sent": "So just as a contrast in terms of thinking in terms of what Steve was talking about earlier as points in space where you have some metric information but you don't have any.",
                    "label": 0
                },
                {
                    "sent": "Action Group action that that preserves the semantic properties of the object, namely that the object class is invariant under these actions.",
                    "label": 0
                },
                {
                    "sent": "You have much less structure.",
                    "label": 0
                },
                {
                    "sent": "Here we're exploiting a much richer structure.",
                    "label": 0
                },
                {
                    "sent": "Now, as I said, we introduced the notion of group.",
                    "label": 0
                },
                {
                    "sent": "In the end, you don't really think that the whole group is acting on the template.",
                    "label": 0
                },
                {
                    "sent": "It's some subset of the group around the identity.",
                    "label": 0
                },
                {
                    "sent": "You're not going to perturb A7 and stretch it all over the place, and so on.",
                    "label": 0
                },
                {
                    "sent": "So I mean there.",
                    "label": 0
                },
                {
                    "sent": "It's a limited deformation.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How can we estimate these templates?",
                    "label": 0
                },
                {
                    "sent": "Well, that's a pretty painful problem because we don't observe when we have data.",
                    "label": 0
                },
                {
                    "sent": "When you have examples of.",
                    "label": 0
                },
                {
                    "sent": "Sevens or twos or whatever.",
                    "label": 0
                },
                {
                    "sent": "We don't get to see the underlying deformation that produced that.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's a figment of our imagination, but it's a very productive, useful figment of our imagination.",
                    "label": 0
                },
                {
                    "sent": "So basically, you are in the situation of estimating things when part of the data is unobserved, so it's kind of expectation maximization context that you can use and just to go through some details here.",
                    "label": 0
                },
                {
                    "sent": "We can parameterize the temple.",
                    "label": 0
                },
                {
                    "sent": "Remember, the template is a function in the continuum, so we can expand it in some basis.",
                    "label": 0
                },
                {
                    "sent": "The basis could be some kernels could be some orthonormal basis.",
                    "label": 0
                },
                {
                    "sent": "That's an, it's just parameterized by the coefficient, and then we have.",
                    "label": 0
                },
                {
                    "sent": "Images.",
                    "label": 0
                },
                {
                    "sent": "Samples of the object and we want to maximize the likelihood of the observations.",
                    "label": 0
                },
                {
                    "sent": "Now, if we knew the deformations, if we knew them, then we can write the full likelihood and maximize in the parameters gamma an it's not that bad because if Phi is for example acting like I showed before which you compose it with the inverse of fee.",
                    "label": 0
                },
                {
                    "sent": "It's a linear functional on functions.",
                    "label": 0
                },
                {
                    "sent": "It's not linear, but it's a linear functional and functions and then basically the FI acting Auntie acts on each of the basis elements or each of the functions that you are using to expand the template and you can.",
                    "label": 0
                },
                {
                    "sent": "Since you know fee, you can just compute this as a data matrix.",
                    "label": 0
                },
                {
                    "sent": "So for every pixel you go and observe the deformed basis element at that pixel Ann, you have that for each of the J each of the our basis element and then ascentia Lee given.",
                    "label": 0
                },
                {
                    "sent": "Given the deformations given the fees, the gammas are just estimated through regression.",
                    "label": 0
                },
                {
                    "sent": "OK, so although it's a highly nonlinear situation, if you know the fezan, you know the basis.",
                    "label": 0
                },
                {
                    "sent": "You can deform the basis you have to do it separately for each example.",
                    "label": 0
                },
                {
                    "sent": "It's not one deformation of the basis.",
                    "label": 0
                },
                {
                    "sent": "Each example has its own basis deformation, and you know for those of you who are used to working in the L2 settings and so on, you know this is not a typical thing where you start warping your basis to please every data point.",
                    "label": 0
                },
                {
                    "sent": "But if you have the observed data you can do that and then you can estimate the parameters of.",
                    "label": 0
                },
                {
                    "sent": "The coefficients that go into the template using simple regression.",
                    "label": 0
                },
                {
                    "sent": "If your model is Gaussian like the one I said before, if your observation model if F is a normal distribution.",
                    "label": 0
                },
                {
                    "sent": "If F is something else, it might be some other type of nonlinear regression.",
                    "label": 0
                },
                {
                    "sent": "But these are context that we can work with pretty easily.",
                    "label": 0
                },
                {
                    "sent": "Once we have this X matrix.",
                    "label": 0
                },
                {
                    "sent": "And of course, if you have the samples, you can parametrize the distribution.",
                    "label": 0
                },
                {
                    "sent": "If you have the deformations, you can parameterise the distribution there.",
                    "label": 0
                },
                {
                    "sent": "An estimate that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When you have an observed deformations, which is the current situation, which is the real situation, then you try to iterate and at each step you try to develop a distribution on the deformations given the current parameters and the image.",
                    "label": 0
                },
                {
                    "sent": "And that's a pretty complicated distribution.",
                    "label": 0
                },
                {
                    "sent": "The product there it had to remind you is because we're assuming the pixels are independent.",
                    "label": 0
                },
                {
                    "sent": "Given the deformations, you have a product over the pixels in the image of the likelihood of the data.",
                    "label": 0
                },
                {
                    "sent": "Given the deformed template at that pixel.",
                    "label": 0
                },
                {
                    "sent": "So if Y is finite and we're going to look at an example where the set of deformations is discrete and finite manageable, then you can compute this explicitly.",
                    "label": 0
                },
                {
                    "sent": "You just do Bayes rule and you did.",
                    "label": 0
                },
                {
                    "sent": "You normalize this by summing over all possible values of the deformation?",
                    "label": 0
                },
                {
                    "sent": "If not, one alternative is to use complicated Markov chain variations on EM or the simple alternative is just to basically an alternative to EM is just you do Max Max so.",
                    "label": 0
                },
                {
                    "sent": "At every step you find the deformation that maximizes the current joint distribution, and you use that as if it's the observed.",
                    "label": 0
                },
                {
                    "sent": "Deformation and basically what it says is given the current parameters of the template you're trying to find the deform and and the distribution on deformation trying to find the deformation that best matches each image and that becomes your that goes into the next step of the loop.",
                    "label": 0
                },
                {
                    "sent": "And so do.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Doing these kinds of things here is just a sample from a toy example from the US Postal set.",
                    "label": 0
                },
                {
                    "sent": "And just to illustrate the idea, this algorithm was run here on.",
                    "label": 0
                },
                {
                    "sent": "I believe there's 40 examples per class.",
                    "label": 0
                },
                {
                    "sent": "The top 10 images are just simple averages that you would get if you average these images.",
                    "label": 0
                },
                {
                    "sent": "Now these images, although there affectively binary, they were treated as if the template that you had.",
                    "label": 0
                },
                {
                    "sent": "Added Gaussian noise to the template, so it's it's it's the Gaussian model we will move away from that in a minute.",
                    "label": 0
                },
                {
                    "sent": "Down below you see the templates that are estimated using this procedure and what you see is that because you have factored in the deformations, you get very very sharp descriptions of the different classes.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to dwell too much on this because there's some inherent problems in this model, one of which that we don't model changes in contrast, so this model would fall apart if suddenly you made all the images half as bright.",
                    "label": 0
                },
                {
                    "sent": "Now of course you could say, oh, if they're half as bright, you can normalize.",
                    "label": 0
                },
                {
                    "sent": "But let's say you don't know that you can normalize then this model falls apart and dealing with contrast is a very important element.",
                    "label": 0
                },
                {
                    "sent": "So in general you think about the variability that exists.",
                    "label": 0
                },
                {
                    "sent": "In the appearances of objects, I said is geometric and photometric, and there's always an interplay between the part of the variability that you model explicitly and the part that you try to.",
                    "label": 0
                },
                {
                    "sent": "I say modded out OK, Sir, you can compute certain features on the data that are invariant, or at least very robust to certain parts of the variability, and then you don't have to model that Anna.",
                    "label": 0
                },
                {
                    "sent": "Typical thing that's done in computer vision is to transform.",
                    "label": 1
                },
                {
                    "sent": "The Gray level data to oriented binary edge date binary oriented edge data which a lot, which in some sense not perfectly but are strong, are invariant.",
                    "label": 0
                },
                {
                    "sent": "Let's say to the changes in intensity that are so difficult to deal with and so from now on we will look at that time.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Above so here's just an example.",
                    "label": 0
                },
                {
                    "sent": "Here's an image of a face, and here you see, there's very crude edges.",
                    "label": 0
                },
                {
                    "sent": "Basically, looking at local Maxima of the gradient in different directions, and you see horizontal and vertical edges on this face.",
                    "label": 0
                },
                {
                    "sent": "So now the image data is transformed and we have in some sense modded out the variability to contrast.",
                    "label": 0
                },
                {
                    "sent": "Now, one thing to keep in mind is now our data is binary.",
                    "label": 0
                },
                {
                    "sent": "You can't think of this anymore as a linear space where you can model things as sums of dictionaries.",
                    "label": 0
                },
                {
                    "sent": "It really doesn't make any sense anymore, yeah?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the case of the digits, what was the group fee that you use it?",
                    "label": 0
                },
                {
                    "sent": "It was exactly it was OK. Basically you had another set of basis elements, and you, the group was basically you describe the deformation as the identity plus a small term that was expanded in some basis elements.",
                    "label": 0
                },
                {
                    "sent": "So you I cannot guarantee by the way that it was a group that it was an actual diffeomorphism, it was.",
                    "label": 0
                },
                {
                    "sent": "A map of the domain into itself that was close to the identity and therefore mostly one to one.",
                    "label": 0
                },
                {
                    "sent": "This element, however, in this case they were kernels with knots at some regular space rates, but you could do the same thing if you wanted with some other basis with wavelets or so.",
                    "label": 0
                },
                {
                    "sent": "You basically expand the displacement of each pixel in the two components of the displacements of vector field in the basis.",
                    "label": 0
                },
                {
                    "sent": "No, no, no that is.",
                    "label": 0
                },
                {
                    "sent": "No, no.",
                    "label": 0
                },
                {
                    "sent": "They were kernels.",
                    "label": 0
                },
                {
                    "sent": "They were very smooth.",
                    "label": 0
                },
                {
                    "sent": "Actually they were kernels.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "5.",
                    "label": 0
                },
                {
                    "sent": "No, no fi is not at all a linear function in this context.",
                    "label": 0
                },
                {
                    "sent": "Sorry if you go back.",
                    "label": 0
                },
                {
                    "sent": "Oh, this doesn't go back that way, I'm sorry.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here 5 is not a linear function, Phi is.",
                    "label": 0
                },
                {
                    "sent": "You can think of it as I said, it's the identity map plus a vector field which is expanded in a finite basis with some coefficients.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a map that is not guaranteed to be one to one, but it's very close 'cause it's not so far from the identity.",
                    "label": 0
                },
                {
                    "sent": "Now there are more sophisticated methods that can develop, can make defies real diffeomorphism so that.",
                    "label": 0
                },
                {
                    "sent": "When you talk about a group, you're really talking about a group, but that's that's not something I'm going to.",
                    "label": 0
                },
                {
                    "sent": "That's also computationally very.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Expensive so.",
                    "label": 0
                },
                {
                    "sent": "Let me skip.",
                    "label": 0
                },
                {
                    "sent": "Well, let me just say that sometimes it's easier to transform the data into the template rather than transforming the template.",
                    "label": 1
                },
                {
                    "sent": "This is kind of a shortcut.",
                    "label": 0
                },
                {
                    "sent": "So if you know the deformation, you can say that if I compose I with the deformation and do some feature extraction on the deformed image, I get a set of features and you can try to learn the template that way, namely that the the.",
                    "label": 0
                },
                {
                    "sent": "Data that you get after deforming the image, say rotating the image or scaling the image and then extracting features is distributed according to something that is determined by your template.",
                    "label": 0
                },
                {
                    "sent": "So instead of deforming the template into the image, you deform the image into the reference grid of the template.",
                    "label": 1
                },
                {
                    "sent": "This is not really a generative model for images, but once you estimate this, you can actually produce at least if the fees are discrete set.",
                    "label": 0
                },
                {
                    "sent": "You can produce models for.",
                    "label": 0
                },
                {
                    "sent": "Each possible deformation of the template I don't want to.",
                    "label": 0
                },
                {
                    "sent": "I don't have time to go into the details here, but actually we use this quite a lot because it saves some time.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I want to.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This and now I want to go into the idea that we know intuitively that even simple classes like handwritten digits which are really simple classes and it's a good framework to think about things, not all versions of a handwritten two are going to be able.",
                    "label": 0
                },
                {
                    "sent": "You're going to be able to create from one deformable template.",
                    "label": 0
                },
                {
                    "sent": "There are certain there different types of two that are topologically different and cannot be obtained one from the other safe.",
                    "label": 0
                },
                {
                    "sent": "There's a loop at the bottom or not.",
                    "label": 0
                },
                {
                    "sent": "And so you want to model object classes as mixtures of deformable templates.",
                    "label": 0
                },
                {
                    "sent": "So in addition to the UN observed information you have now a none observed component membership variable that you have to deal with in the EM and I will get back to this problem.",
                    "label": 0
                },
                {
                    "sent": "But first, kind of as a response.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Wants to stuff that I heard yesterday.",
                    "label": 0
                },
                {
                    "sent": "I want to talk about the issue of very, very simple deformable templates to model the microworld.",
                    "label": 1
                },
                {
                    "sent": "So this this business of dictionaries.",
                    "label": 0
                },
                {
                    "sent": "So up here you have samples from some random images, just Gray level images of the world down here you have a sample of 6 by 6 sub images from the population of handwritten digits.",
                    "label": 0
                },
                {
                    "sent": "So these are different populations.",
                    "label": 0
                },
                {
                    "sent": "OK, now you can decide.",
                    "label": 0
                },
                {
                    "sent": "To just estimate a mixture model for this data now remember because we don't want to deal with the problem of contrast, we want 22 patches that are the same except for a contrast change to be effectively the same thing.",
                    "label": 0
                },
                {
                    "sent": "And that's why we transform this data again into binary oriented edges.",
                    "label": 0
                },
                {
                    "sent": "So we have binary data now arranged on the grid, as opposed to Gray Le.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All data and we model.",
                    "label": 0
                },
                {
                    "sent": "This population is a very simple thing.",
                    "label": 0
                },
                {
                    "sent": "So when I write XX plus WR with square bracket around I, it means that I extract.",
                    "label": 0
                },
                {
                    "sent": "The binary edges in a window of size W around little X from image I.",
                    "label": 0
                },
                {
                    "sent": "And now I'm saying that this population is a mixture of some number of models.",
                    "label": 0
                },
                {
                    "sent": "And each of the models.",
                    "label": 0
                },
                {
                    "sent": "Under each of the models, if you come from that component.",
                    "label": 0
                },
                {
                    "sent": "The edges are all independent.",
                    "label": 0
                },
                {
                    "sent": "OK, it's a very strong assumption.",
                    "label": 0
                },
                {
                    "sent": "The edges are all independent and basically the model is summarized very simply by the probability at each pixel.",
                    "label": 0
                },
                {
                    "sent": "To get an edge.",
                    "label": 0
                },
                {
                    "sent": "So here I don't enumerate the edge types.",
                    "label": 0
                },
                {
                    "sent": "There shouldn't be an E down there because I just want to simplify notations.",
                    "label": 0
                },
                {
                    "sent": "Images just one binary feature.",
                    "label": 0
                },
                {
                    "sent": "So at each location you have the probability for that component for that feature to be there, and 1 -- P is the probability for that feature not to be there.",
                    "label": 0
                },
                {
                    "sent": "So I called these Bernoulli models.",
                    "label": 0
                },
                {
                    "sent": "They're independent Bernoulli variables.",
                    "label": 0
                },
                {
                    "sent": "For each component so of course.",
                    "label": 0
                },
                {
                    "sent": "The marginal distribution when you after you mix things.",
                    "label": 0
                },
                {
                    "sent": "The data is not at all independent, so our model of the world is not assuming that pixels are independent, but there are independent conditional on the component you come from.",
                    "label": 0
                },
                {
                    "sent": "Now you can train a model like this in a few minutes.",
                    "label": 0
                },
                {
                    "sent": "From any of those datas, here are 100 or 99 mixture components that were obtained from from the handwritten data.",
                    "label": 0
                },
                {
                    "sent": "Using this EM, and it's a very, very stable EM can be unstable, but when M is working on binary variables, it's dynamite.",
                    "label": 0
                },
                {
                    "sent": "It goes fast and it's stable and nothing crazy ever happens and you can initialize it randomly and it's fine.",
                    "label": 0
                },
                {
                    "sent": "So what you're seeing here is the mean Gray level image for eat.",
                    "label": 0
                },
                {
                    "sent": "For the image that fell in each of the components.",
                    "label": 1
                },
                {
                    "sent": "So I 'cause he's hard to look at edge data.",
                    "label": 0
                },
                {
                    "sent": "These are the mean images and what you see is what you see when anybody makes some kind of dictionary for local data, you see bars and corners and some maybe maybe it's not big enough to see intersections, but if you made the image is a little bigger, you start seeing intersection.",
                    "label": 0
                },
                {
                    "sent": "No surprise there.",
                    "label": 0
                },
                {
                    "sent": "Now let's put in the idea of a deformable template, we know.",
                    "label": 0
                },
                {
                    "sent": "Is that we can look at the world standing on our head or standing up and the statistics shouldn't change very much.",
                    "label": 0
                },
                {
                    "sent": "So we know that there is a rotational symmetry in these in this microworld.",
                    "label": 0
                },
                {
                    "sent": "So let's estimate a mixture of deformable templates for this microworld, where the only deformation is just rotation.",
                    "label": 0
                },
                {
                    "sent": "You could also add for example rotation an shifts because after all you're not always observing something perfectly central, but forget the shifted small enough.",
                    "label": 0
                },
                {
                    "sent": "You could do.",
                    "label": 0
                },
                {
                    "sent": "You could estimate modular rotations and inversions because sometimes you're looking at a black on a white or sometimes white on black and that should also be in some sense the same thing, so you can.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Define.",
                    "label": 0
                },
                {
                    "sent": "The notion of applying a rotation to the edge data by saying you wrote to instead of applying the rotation to the AAD data, especially if the rotations are.",
                    "label": 0
                },
                {
                    "sent": "Finer in resolution than the edge angles you.",
                    "label": 0
                },
                {
                    "sent": "It's easier to think of it as rotating the image and then extracting the edges.",
                    "label": 0
                },
                {
                    "sent": "That has to do with this idea of transforming the data into the reference grid as opposed to transforming the template.",
                    "label": 0
                },
                {
                    "sent": "And then, if you know for each one of these micro image samples which component it came from and which angle it came from, then this is simply the estimates of the model.",
                    "label": 0
                },
                {
                    "sent": "So the estimate of the model would be if X comes from angle a produce, rotate the image by angle A, get the edges and count how many times you got an edge at pixel Z.",
                    "label": 0
                },
                {
                    "sent": "That's the probability that a model.",
                    "label": 0
                },
                {
                    "sent": "At C, and from that you can then generate each one of the rotated models.",
                    "label": 0
                },
                {
                    "sent": "And again, if you don't have F and a, they're not observed, you can do EM.",
                    "label": 0
                },
                {
                    "sent": "In this case you can do EM explicitly, because the group here is discrete.",
                    "label": 0
                },
                {
                    "sent": "You can do 16 angles, 24 angles doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "It's a small group.",
                    "label": 0
                },
                {
                    "sent": "And the nice thing is that once you introduce angles, you only need a very small number of components in the mixture model, because you're already all of this stuff that you had here.",
                    "label": 0
                },
                {
                    "sent": "All these rotated versions of the same thing.",
                    "label": 0
                },
                {
                    "sent": "Are not now going to fall under the same mixture component and so.",
                    "label": 0
                },
                {
                    "sent": "OK, this is just an.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rotation for the M and so here's what you get.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you take the data from the handwritten digits, you say I want seven components and I want 16 angles.",
                    "label": 0
                },
                {
                    "sent": "These are the mean images.",
                    "label": 0
                },
                {
                    "sent": "The first column are the mean images you get in the actual 7 components, and then each one you're shown the rotated template 16 times the mean images of the rotated template.",
                    "label": 0
                },
                {
                    "sent": "But the computation is all taking place on the edge Maps, not on the Gray level.",
                    "label": 0
                },
                {
                    "sent": "So these are this is a mixture model of the microworld which is invariant to Gray.",
                    "label": 0
                },
                {
                    "sent": "Level transformations are almost in fact this is obtained from some sample of micro images.",
                    "label": 0
                },
                {
                    "sent": "I think taken from cats, just to show you it's not that different.",
                    "label": 0
                },
                {
                    "sent": "You know the microworld is not that.",
                    "label": 0
                },
                {
                    "sent": "Different even between handwritten digits and cats.",
                    "label": 0
                },
                {
                    "sent": "A little different, but.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You get.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These and why is this interesting?",
                    "label": 0
                },
                {
                    "sent": "So this is just a simple illustration of the idea of estimating a deformable template where the deformations in this case linear just rotations simple.",
                    "label": 0
                },
                {
                    "sent": "You get this you can do this in a few minutes for any sample that you take.",
                    "label": 0
                },
                {
                    "sent": "Tufts of microworld images and you get a library.",
                    "label": 0
                },
                {
                    "sent": "Avara Dictionary is some people like it, but it's got structure now, so it's not only that you basically reduce the complexity because you introduce the fact that there's rotation.",
                    "label": 0
                },
                {
                    "sent": "So you basically only had to estimate 7 components.",
                    "label": 0
                },
                {
                    "sent": "You want 10 components.",
                    "label": 0
                },
                {
                    "sent": "You can play around with that, but that's about the order of magnitude.",
                    "label": 0
                },
                {
                    "sent": "You have structure in your dictionary now and you know what?",
                    "label": 0
                },
                {
                    "sent": "Part of the dictionary's rotation is a rotated version of another part.",
                    "label": 0
                },
                {
                    "sent": "But another reason this is interesting is that.",
                    "label": 0
                },
                {
                    "sent": "These parts are really local descriptions of objects because one thing I didn't tell you is when you estimate this mixture, you throw away samples that do not reject a null hypothesis that it's kind of a flat.",
                    "label": 0
                },
                {
                    "sent": "Part that there's nothing going on, so there's a good chance that all these things you've got are parts of objects, and so the idea comes, which is to say why don't we re code the image now in terms of this dictionary, where at each point?",
                    "label": 0
                },
                {
                    "sent": "We can say which element of the dictionary is most likely, but then we can describe this at a much lower resolution.",
                    "label": 0
                },
                {
                    "sent": "Because once you know which element of the dictionary was present in a neighborhood, it basically describes the entire neighborhood.",
                    "label": 0
                },
                {
                    "sent": "You don't need the full resolution.",
                    "label": 0
                },
                {
                    "sent": "Maybe you can't reconstruct the image, but it preserves a lot of.",
                    "label": 0
                },
                {
                    "sent": "Information, so that's that.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next step is to use.",
                    "label": 0
                },
                {
                    "sent": "I call it Part Basic Color dictionary based representation.",
                    "label": 1
                },
                {
                    "sent": "You now make a new transfer.",
                    "label": 0
                },
                {
                    "sent": "You went from Gray level to oriented edges and now you transform the images one more time.",
                    "label": 0
                },
                {
                    "sent": "At each point you can ask which.",
                    "label": 0
                },
                {
                    "sent": "Dictionary most gives the likelihood of the data is maximized under which of the models you assigned that label to that that point.",
                    "label": 0
                },
                {
                    "sent": "So there's the component and the angle, and then you can course in the data and what that is the same as introducing the edges in order to MoD out Gray level variability when you course in the data on a coarse lattice using this maximization operation, you're basically modding out.",
                    "label": 0
                },
                {
                    "sent": "A large degree of variable geometric variability, both shifting and rotation, because you're maximizing over angles in the neighborhood of the angle that you're coding for, and so basically you're saying on the coarse lattice the pixel corresponds to some area in the original image where there existed this part model.",
                    "label": 0
                },
                {
                    "sent": "I don't know exactly where it was, and it might have been at.",
                    "label": 0
                },
                {
                    "sent": "You know, one index of rotation.",
                    "label": 0
                },
                {
                    "sent": "Away from the current index, and this introduces a huge amount of invariants.",
                    "label": 0
                },
                {
                    "sent": "In fact, you can introduce too much invariants, namely, if the coarse lattice is its size is the same as the dimension of the image you you're basically recording everything at one pixel.",
                    "label": 0
                },
                {
                    "sent": "That's what people call bag of features.",
                    "label": 0
                },
                {
                    "sent": "So bag of features is just one point on a continuum of the introduction of invariants.",
                    "label": 0
                },
                {
                    "sent": "Now one deep problem, which I don't know.",
                    "label": 0
                },
                {
                    "sent": "The solution I don't even know exactly how to formulate it mathematically.",
                    "label": 0
                },
                {
                    "sent": "Is what is the trade off and how do you find the correct tradeoff between invariants and specificity?",
                    "label": 1
                },
                {
                    "sent": "Because what happens when you introduce too much invariants of the representation?",
                    "label": 0
                },
                {
                    "sent": "You might not be able then to discriminate between things, so that's a hard problem.",
                    "label": 0
                },
                {
                    "sent": "And now once we have this new.",
                    "label": 0
                },
                {
                    "sent": "Representation of the data in terms of binary features on a coarser grid, we again model.",
                    "label": 0
                },
                {
                    "sent": "Now say we want to model objects OK, we started modeling the microworld now in terms of these model objects, again is a mixture of Bernoulli models, so conditional on the mixture component, the probability of finding any one of these features in the mixture component will be.",
                    "label": 0
                },
                {
                    "sent": "The probabilities will be independent.",
                    "label": 0
                },
                {
                    "sent": "Variables will be independent and so in contrast to what Galmore was telling you yesterday.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You get very very powerful classifiers on amnesty, for example using this very, very simple architecture that takes maybe 10 minutes from the sampling of the microimages all the way to the classifier to train on a computer.",
                    "label": 0
                },
                {
                    "sent": "It's trivial.",
                    "label": 0
                },
                {
                    "sent": "This is all 40 years old statistical techniques.",
                    "label": 0
                },
                {
                    "sent": "There's nothing fancy and you can see, for example, if you take 30 example for class, so you're estimating only using 30 digits from each class.",
                    "label": 0
                },
                {
                    "sent": "And you do 2 mixture components per model.",
                    "label": 0
                },
                {
                    "sent": "My rule of thumb is you want about 20 examples per mixture component to get a reasonable estimate of the probabilities, you get 4% error.",
                    "label": 0
                },
                {
                    "sent": "This is 30 examples.",
                    "label": 0
                },
                {
                    "sent": "There's 6000 examples from each class in the Emnace data set.",
                    "label": 0
                },
                {
                    "sent": "By the time you're up to 1000 examples per class, you are at 1.5 and the point is you did not train the the components of your dictionary.",
                    "label": 0
                },
                {
                    "sent": "Based on the task of classifying, you just tried to model the microworld modulo certain invariances.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now I just want to talk about another framework where you can estimate using nonlinear deformations, estimate object models, objects that are represented in terms of the edge data.",
                    "label": 1
                },
                {
                    "sent": "So you're again estimating probability Maps.",
                    "label": 0
                },
                {
                    "sent": "These models will be invariant to contrast, 'cause they're based on the edges, and in this case the idea of the deformation is very simple.",
                    "label": 0
                },
                {
                    "sent": "You have a number of points Z1 through Z on the reference grid.",
                    "label": 0
                },
                {
                    "sent": "And each point is shifted, and that's how we represent the deformation.",
                    "label": 0
                },
                {
                    "sent": "I now have to tell you how that deformation acts on the template.",
                    "label": 0
                },
                {
                    "sent": "OK, 'cause that's just meaningless at this point.",
                    "label": 0
                },
                {
                    "sent": "So here's a picture.",
                    "label": 0
                },
                {
                    "sent": "Imagine that what you see here is the probability map in black.",
                    "label": 0
                },
                {
                    "sent": "It's high probability for a certain feature an as it gets lighter, it's low probability, and each of the Reds dots is one of those Z points.",
                    "label": 0
                },
                {
                    "sent": "You take a window around it, and the Tau tells you how to shift it.",
                    "label": 0
                },
                {
                    "sent": "So each of these Windows gets shifted according.",
                    "label": 0
                },
                {
                    "sent": "To the displacement assigned to the center.",
                    "label": 0
                },
                {
                    "sent": "So you have N shifts an end center points.",
                    "label": 0
                },
                {
                    "sent": "Now when you shift these probability Maps, they become inconsistent.",
                    "label": 0
                },
                {
                    "sent": "If you don't shift them and you look at a pic so it's got two probability Maps above it, there are signing the same probability, but when you shift that, they're inconsistent and so we do what's called a patchwork of parts.",
                    "label": 0
                },
                {
                    "sent": "Once you shift them, every pixels finds all the windows above it and averages the probabilities there.",
                    "label": 0
                },
                {
                    "sent": "That's the action of the deformation on the probability map, so in this case it this is the formal definition.",
                    "label": 0
                },
                {
                    "sent": "Every pixel in the image, so think of that too, or that too is an image.",
                    "label": 0
                },
                {
                    "sent": "You have a bunch of shifts, towel.",
                    "label": 0
                },
                {
                    "sent": "Assigned to each of the red dots and every pixel finds out how many of these windows shifted windows is above it, and the probability assigned to that pixel now.",
                    "label": 0
                },
                {
                    "sent": "Orphee P of X now is the average of all the probabilities that that Pixel sees from the different windows, which aren't necessarily the same.",
                    "label": 0
                },
                {
                    "sent": "So if Tau is 0 for each of these reference points, then the probabilities are the same, and so this average is equal to each one of the terms and four pixels that are not covered by any of these patches.",
                    "label": 0
                },
                {
                    "sent": "Then there's some background probability, and as I said, I don't have time today to talk about background, but it's a whole story in itself.",
                    "label": 0
                },
                {
                    "sent": "So this is what we call patchwork of parts models and we also have.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The formulation for Gray levels, which introduces an explicit modeling of contrast and intensity.",
                    "label": 1
                },
                {
                    "sent": "Because we're trying to actually think of how the image is generated with different lighting conditions and so on.",
                    "label": 0
                },
                {
                    "sent": "But this is work in Prague.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Horse to train apart model.",
                    "label": 0
                },
                {
                    "sent": "Is not so difficult as long as you decide to train each one of those patches separately, and it turns out it's not such a big.",
                    "label": 0
                },
                {
                    "sent": "There's not much loss in training each of the parts separately, as long as the training data is is not too noisy, so each of the parts basically is trained where the only deformation parameter is a shift.",
                    "label": 0
                },
                {
                    "sent": "In the same spirit as we were training the microworld model model rotation here it's modulo shift and it's a very simple EM algorithm that finds the probability map locali around a certain area of the image and then you can Patch together these probability Maps and you get.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You get something like this, which in fact is a patching together of probability Maps that were estimated separately from samples of two.",
                    "label": 0
                },
                {
                    "sent": "And again you see how this probability map once you try to now.",
                    "label": 0
                },
                {
                    "sent": "You give it 2 new samples and you're trying to find what are the optimal shifts to explain the data you're able to take this template, and using these shifts, modify it to match these different instances of the object.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is an example where you have a nonlinear type of deformation acting on binary features.",
                    "label": 0
                },
                {
                    "sent": "Well, the deformation is acting on the template, but the observations are binary.",
                    "label": 0
                },
                {
                    "sent": "And it allows us to even further, so I won't go into the details of how it strains the same idea.",
                    "label": 0
                },
                {
                    "sent": "It allows us to go.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I'm not very good at.",
                    "label": 0
                },
                {
                    "sent": "Almost done.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so, just to wrap everything together.",
                    "label": 0
                },
                {
                    "sent": "The part based representation.",
                    "label": 0
                },
                {
                    "sent": "Think of it as modding out a lot of the variability and so you basically don't have to deal with this UN observed deformation variable and therefore it's very easy to estimate the mixtures in the population corresponding to a particular class.",
                    "label": 0
                },
                {
                    "sent": "Then for each of these mixture component that you estimate based on the course part models, you can estimate using the images in each one of the mixture component.",
                    "label": 0
                },
                {
                    "sent": "You can estimate your pop model.",
                    "label": 0
                },
                {
                    "sent": "So what you're looking at here is the following.",
                    "label": 0
                },
                {
                    "sent": "Mixture models were estimated on each one of the classes separately.",
                    "label": 0
                },
                {
                    "sent": "Every estimations separately in each class there's 100 examples per class.",
                    "label": 0
                },
                {
                    "sent": "So you get the five mixture components, each mixture component.",
                    "label": 0
                },
                {
                    "sent": "The pop models were estimated based on the oriented edge data.",
                    "label": 1
                },
                {
                    "sent": "Each component of the pop model, each window that's estimated.",
                    "label": 0
                },
                {
                    "sent": "It's based on the edges, but after you estimate the shifts, you can compute the mean image just for visualization purposes, and then you can Patch together the mean images using the same average income operation, and this is what you get.",
                    "label": 0
                },
                {
                    "sent": "So what you have here is something very indirectly obtained.",
                    "label": 0
                },
                {
                    "sent": "From the original image data, it's just showing you a visual representation of the class.",
                    "label": 0
                },
                {
                    "sent": "Is the actual models are models on edge probabilities on edge data, not probabilities on grade level.",
                    "label": 0
                },
                {
                    "sent": "But this is a visual representation that gives you a feel of what is estimated in the different classes.",
                    "label": 0
                },
                {
                    "sent": "So using say 400 images in the Olivetti data set, estimating a mixture component, estimating pop models, you get these four.",
                    "label": 0
                },
                {
                    "sent": "These five quasi individuals, but they're not really an individual, these are.",
                    "label": 0
                },
                {
                    "sent": "Patches Patch works of averages modulo deformations that were obtained during the estimation procedure.",
                    "label": 0
                },
                {
                    "sent": "Same for you could do for horses or for other objects.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so using this methodology which allows you, as I said to also deal with object configurations in a in a principled manner, you can get, for example, if you look at that again at the in this data set.",
                    "label": 0
                },
                {
                    "sent": "I don't have it together with the course part models, but for example with 100 with 1000 examples for image with the course part model, the error rate was 1.5 and then if you add this extra layer of.",
                    "label": 0
                },
                {
                    "sent": "The pop models you can reduce the error rate to .8 and this is very stable.",
                    "label": 0
                },
                {
                    "sent": "You can take any subset of 10,000 images of the training set and get similar results.",
                    "label": 0
                },
                {
                    "sent": "It's not a particular fine tuned result on this particular training set and.",
                    "label": 0
                },
                {
                    "sent": "I think the more interesting results are for example, what happens if you're training with 30 elements per class.",
                    "label": 0
                },
                {
                    "sent": "You know you can get your error rate down to 3%.",
                    "label": 0
                },
                {
                    "sent": "We just seen 30 examples of each one of the classes OK, but beyond that, whenever you're thinking about classifying digits, you want to think what's the next step.",
                    "label": 0
                },
                {
                    "sent": "If I know how to classify digits, what will I do when I want to read zip codes?",
                    "label": 0
                },
                {
                    "sent": "OK, and this allows you.",
                    "label": 0
                },
                {
                    "sent": "This framework allows you to actually formulate that problem as a likelihood maximization problem and deal with it similarly.",
                    "label": 0
                },
                {
                    "sent": "Reading license plate.",
                    "label": 0
                },
                {
                    "sent": "Similarly you can use the same types of models to try to detect faces in an image.",
                    "label": 0
                },
                {
                    "sent": "And you know you can train your model based on a small set of faces, say 400 faces.",
                    "label": 0
                },
                {
                    "sent": "You never have to see a background image in your life beforehand, and using an adaptive background model that gets modified as you move along in the image, you can get basically state of the art detection results on these standard face datasets and so.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me just go to the conclusion.",
                    "label": 0
                },
                {
                    "sent": "So the importance of modeling variability is a hidden random variable.",
                    "label": 1
                },
                {
                    "sent": "The estimation of templates and mixtures through OEM types of algorithms in the local world that provides parts or dictionaries with symmetries and for at the object level.",
                    "label": 0
                },
                {
                    "sent": "Of course you have to introduce nonlinear deformations.",
                    "label": 0
                },
                {
                    "sent": "There's the idea that instead of modeling variability you somehow Max over simple subsets of the deformations to obtain object parts.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "This is something that needs formalization intuitively.",
                    "label": 0
                },
                {
                    "sent": "We know what we're doing, but it would.",
                    "label": 0
                },
                {
                    "sent": "It's something that's really.",
                    "label": 0
                },
                {
                    "sent": "I think there's something deep going on there in terms of how we approximate.",
                    "label": 0
                },
                {
                    "sent": "The complicated deformation of the full blown objects.",
                    "label": 0
                },
                {
                    "sent": "In some sense, this is a computational tool.",
                    "label": 0
                },
                {
                    "sent": "It's something that allows us to do things quickly.",
                    "label": 0
                },
                {
                    "sent": "Once we MoD out the variability, formalizing and trying to think what are the optimal ways of doing this, I think is a very deep questions which I don't know the answer to.",
                    "label": 0
                },
                {
                    "sent": "So really for object recognition, there's a very rich structure in the subject matter beyond linear operations and function spaces.",
                    "label": 1
                },
                {
                    "sent": "Distances should not be measured directly in observation space.",
                    "label": 0
                },
                {
                    "sent": "The quote unquote manifold is defined through the group action.",
                    "label": 0
                },
                {
                    "sent": "It's we already, in some sense know what it is.",
                    "label": 0
                },
                {
                    "sent": "If you give an example, if you have the template, you somehow because you know what deformations are possible, you know what the manifold is, and I think there's a wide range of interesting questions to be studied on this, and it would be good if some of the bright minds and machine learning devoted them to themselves too.",
                    "label": 0
                },
                {
                    "sent": "To this type of problem, let me just say one more thing that in some sense I think the same set of ideas holds also in speech recognition.",
                    "label": 0
                },
                {
                    "sent": "This is not something that's just true for image analysis in speech recognition.",
                    "label": 0
                },
                {
                    "sent": "In the prevailing paradigm of hidden Markov models, the hidden Markov model is a deformation model.",
                    "label": 0
                },
                {
                    "sent": "You might not like it.",
                    "label": 0
                },
                {
                    "sent": "You might think it should be something else, but it is an inherent model to think about.",
                    "label": 0
                },
                {
                    "sent": "The fact that objects deform.",
                    "label": 0
                },
                {
                    "sent": "In complex ways, so I'll stop here and answer questions.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I didn't hear you.",
                    "label": 0
                },
                {
                    "sent": "In the object model, yes.",
                    "label": 0
                },
                {
                    "sent": "So when do you estimate the actual tablets you get at the same time estimate a joint distribution on how these different points move.",
                    "label": 0
                },
                {
                    "sent": "Honestly, in the context of just classifying the isolated digits, that information is not that important, but they got is so compelling in terms of how the October part the patches should be form that the extra cost of the deformation doesn't play much of a role.",
                    "label": 0
                },
                {
                    "sent": "It plays more of a role in two settings.",
                    "label": 0
                },
                {
                    "sent": "One is when you're actually reading zip codes and you have to sometimes refine.",
                    "label": 0
                },
                {
                    "sent": "A detection of a particular object you actually have to refine a support of the option, decide what part of the image the object is under.",
                    "label": 0
                },
                {
                    "sent": "10 is responsible for an when you're doing detection object detection, like using the face models.",
                    "label": 0
                },
                {
                    "sent": "Because there's junk around the face you want to penalize deformations that try to take part of the object model and explain something in the background using it.",
                    "label": 0
                },
                {
                    "sent": "So this distribution on deformation helps you constrain how these things move.",
                    "label": 0
                },
                {
                    "sent": "But the whole issue of modeling the distribution on deformations is has some deep open questions in it as well.",
                    "label": 0
                },
                {
                    "sent": "It's not an entirely resolved issue.",
                    "label": 0
                },
                {
                    "sent": "Hard.",
                    "label": 0
                },
                {
                    "sent": "I don't ship.",
                    "label": 0
                },
                {
                    "sent": "So is this size?",
                    "label": 0
                },
                {
                    "sent": "No, this is robust to a certain range of sizes, but saying if you want to detect faces in multiple scales, say you take, you wanted to take all faces within a range of two to one that you would have to under.",
                    "label": 0
                },
                {
                    "sent": "In this context, you would have to have models for the larger faces trained separately.",
                    "label": 0
                },
                {
                    "sent": "It's not a very good idea.",
                    "label": 0
                },
                {
                    "sent": "You can scale the probability map.",
                    "label": 0
                },
                {
                    "sent": "But it's not that good because when you scale, the probability that you spread the probabilities and that's not what people know.",
                    "label": 0
                },
                {
                    "sent": "Boundaries don't spread when you sail in object, the boundary stays about you, so you don't really want.",
                    "label": 0
                },
                {
                    "sent": "There might be a smarter way to actually scale the models without relearning them, but what I do when I'm detecting faces is I'll take the sample faces bigger and re estimate a deformable model for that.",
                    "label": 0
                },
                {
                    "sent": "That's a very good question.",
                    "label": 0
                },
                {
                    "sent": "In fact, for the digits, because in zip codes, by the way, you know in M NIS the digits are about the same size.",
                    "label": 0
                },
                {
                    "sent": "If you take zip codes, the ratio of size even in one zip code can be 2 to one between two objects, so also in the ZIP codes you need with the same training set to produce models for a number of different size.",
                    "label": 0
                },
                {
                    "sent": "So small changes in size.",
                    "label": 0
                },
                {
                    "sent": "The pop model can accommodate easily, but a large change it can't.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        }
    }
}