{
    "id": "b4uk4wilklwvnw5qyzxf7mhsugk7otgl",
    "title": "Poster Spotlights",
    "info": {
        "author": [
            "Brenna D. Argall, Carnegie Mellon University",
            "Bertrand Douillard, University of Sydney",
            "Amrish S. Kapoor, University of Utah",
            "Jes\u00fas Mart\u00ednez-G\u00f3mez, University of Castilla-La Mancha",
            "Arman Melkumyan, University of Sydney"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Robotics"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_various_ps/",
    "segmentation": [
        [
            "We're really talking about different formulations for data source and where your data source might be coming from.",
            "So in particular we already sorry work with my colleagues.",
            "We already had this algorithm called Town tactile policy correction.",
            "We basically have a humanoid that we're driving in motion control policy for demonstration, and then when the robot executes with its policy, we're providing corrections through tactile interface with the robot can respond to our touched and what we've done is sort of re look at this approach based on.",
            "The call for papers in this workshop and and we really think that there's a couple of different factors in influencing our data that could characterize source as being separate sources.",
            "So one is the teacher.",
            "We have multiple human teachers involved in the loop.",
            "One is the technique where we have we have the.",
            "We have a demonstration.",
            "We also have tactile correction, and then we also use this to try to develop a variety of tasks.",
            "So within the poster I'll present this algorithm and then also.",
            "Talk about this source characterization and then just sort of discuss are the open design decisions because we would like to start reasoning about this explicitly within our algorithm, but we haven't yet, so I do reported.",
            "Yeah, the work isn't very nice.",
            "Sunday plays originally.",
            "So I'm going to stop.",
            "So the idea is to deliver 3 classifier classifieds."
        ],
        [
            "Drivers license, test subjects and so we based on laser vision data.",
            "So we use the data provided by the company so you can see.",
            "And so the.",
            "The system is is multi stage system which produce a number of intermediate representations which are a.",
            "So those are typical in there.",
            "This is coral imagery.",
            "This is 3 later which was in fact provided by your answer.",
            "And so to get to full 3D semantic examination of the world, we go through different stages, which I strated.",
            "First.",
            "We segment out the ground from the rest of the scene.",
            "And using a standard deviation not gonna fewer tricks.",
            "Then we classify the ground using an amazing presentation of CRF, where each ground sound is represented as a note in the CRF.",
            "He and resistance for class Russ an this color here stands for the class dashboard.",
            "So just if I could use those two classes and then once ground identified we segment of whatever is above the ground is in the box edition of the space and also as we use this authorization in 3D we define in image original Pinterest for each corresponding object.",
            "So by the end of this segmentation processes we have a.",
            "Three segmentation on the objects, plus original features.",
            "Defining image as a result of that, we can combine laser envisioned perform classification and he is a set of examples of things that labels.",
            "So I'm sorry it's not very reliable.",
            "But this year we could see if you were closer you could see that the system is able to correctly pick up the cars on the side of the road and also 12 lower classes.",
            "So if you want to know more about this three classifier, please going to discuss.",
            "Great.",
            "No fucking factor regression finding interesting sources of information.",
            "I'm rich."
        ],
        [
            "Hi, I'm on this computer and our people is about factory testing.",
            "Combining everything is sources of information so our problem domain is essentially genomic data.",
            "As we all know, there's a vast abundance of such data available as a result of a lot of experiments on the various settings.",
            "So there is a real need for having computational techniques to effectively being relevant information.",
            "But what happened so far is that all these techniques either concentrate on doing factor regression models using microarray data directly or by using NLP style text, data mining techniques, or rationale is that if we combine these two techniques into a single model, we should be able to outperform any one of those models individually.",
            "So the approach that we've taken is to use an infinite hierarchical factor regression model and combine a lot of the text data that we can get into that.",
            "And we also show that this is.",
            "Actually, an approximation of the parasite style graphical model and the reconstruction error curves that we show here showing effective improvement over using any of the single models alone.",
            "So if you're interested in this sort of stuff, please spend some time in a poster here today.",
            "Thank you.",
            "Using odometry, an enquiry sufficient for basic localization by."
        ],
        [
            "Also.",
            "Ali Ali, Andrew, immensely Castle is my legacy of Arabia or say, guns.",
            "Looking everybody name.",
            "Pizza, but when they got a base.",
            "Yes to their low passive aggressive metal using a particle filter base using Monte Carlo and using invariant feature for the disrespect.",
            "And Additionally, my practice in the sunlight using hot chocolate with lessons present axiom.",
            "Another spinners will require using their Idol database, so they running information is used is a sequence of training in Muscatine under different lighting conditions.",
            "Three different system where frame using the three depending on this chance another system were infested with three different sequence of this unit.",
            "Do you want to see work or happened?",
            "Question please.",
            "He lost.",
            "Processes by."
        ],
        [
            "Fabulous.",
            "So our task is to develop Gaussian process that will be able to fuse information from different sources.",
            "So it is being done by multitask ocean processes, but in the previous approaches that were out there the multi task is constructed using the same formula, same class of covariance function for each class and very just the parameters.",
            "And here we propose a general general method for fusing every any type of stationary covariance functions.",
            "And in our approach we can have different kernels for each of the tasks, and this one point Multicare approach and we also validated without showing through datasets from Georgie.",
            "So if you have comments."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're really talking about different formulations for data source and where your data source might be coming from.",
                    "label": 0
                },
                {
                    "sent": "So in particular we already sorry work with my colleagues.",
                    "label": 0
                },
                {
                    "sent": "We already had this algorithm called Town tactile policy correction.",
                    "label": 1
                },
                {
                    "sent": "We basically have a humanoid that we're driving in motion control policy for demonstration, and then when the robot executes with its policy, we're providing corrections through tactile interface with the robot can respond to our touched and what we've done is sort of re look at this approach based on.",
                    "label": 0
                },
                {
                    "sent": "The call for papers in this workshop and and we really think that there's a couple of different factors in influencing our data that could characterize source as being separate sources.",
                    "label": 0
                },
                {
                    "sent": "So one is the teacher.",
                    "label": 0
                },
                {
                    "sent": "We have multiple human teachers involved in the loop.",
                    "label": 0
                },
                {
                    "sent": "One is the technique where we have we have the.",
                    "label": 0
                },
                {
                    "sent": "We have a demonstration.",
                    "label": 1
                },
                {
                    "sent": "We also have tactile correction, and then we also use this to try to develop a variety of tasks.",
                    "label": 1
                },
                {
                    "sent": "So within the poster I'll present this algorithm and then also.",
                    "label": 0
                },
                {
                    "sent": "Talk about this source characterization and then just sort of discuss are the open design decisions because we would like to start reasoning about this explicitly within our algorithm, but we haven't yet, so I do reported.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the work isn't very nice.",
                    "label": 0
                },
                {
                    "sent": "Sunday plays originally.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to stop.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to deliver 3 classifier classifieds.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Drivers license, test subjects and so we based on laser vision data.",
                    "label": 0
                },
                {
                    "sent": "So we use the data provided by the company so you can see.",
                    "label": 0
                },
                {
                    "sent": "And so the.",
                    "label": 0
                },
                {
                    "sent": "The system is is multi stage system which produce a number of intermediate representations which are a.",
                    "label": 0
                },
                {
                    "sent": "So those are typical in there.",
                    "label": 0
                },
                {
                    "sent": "This is coral imagery.",
                    "label": 0
                },
                {
                    "sent": "This is 3 later which was in fact provided by your answer.",
                    "label": 0
                },
                {
                    "sent": "And so to get to full 3D semantic examination of the world, we go through different stages, which I strated.",
                    "label": 0
                },
                {
                    "sent": "First.",
                    "label": 0
                },
                {
                    "sent": "We segment out the ground from the rest of the scene.",
                    "label": 0
                },
                {
                    "sent": "And using a standard deviation not gonna fewer tricks.",
                    "label": 0
                },
                {
                    "sent": "Then we classify the ground using an amazing presentation of CRF, where each ground sound is represented as a note in the CRF.",
                    "label": 0
                },
                {
                    "sent": "He and resistance for class Russ an this color here stands for the class dashboard.",
                    "label": 0
                },
                {
                    "sent": "So just if I could use those two classes and then once ground identified we segment of whatever is above the ground is in the box edition of the space and also as we use this authorization in 3D we define in image original Pinterest for each corresponding object.",
                    "label": 0
                },
                {
                    "sent": "So by the end of this segmentation processes we have a.",
                    "label": 0
                },
                {
                    "sent": "Three segmentation on the objects, plus original features.",
                    "label": 0
                },
                {
                    "sent": "Defining image as a result of that, we can combine laser envisioned perform classification and he is a set of examples of things that labels.",
                    "label": 0
                },
                {
                    "sent": "So I'm sorry it's not very reliable.",
                    "label": 0
                },
                {
                    "sent": "But this year we could see if you were closer you could see that the system is able to correctly pick up the cars on the side of the road and also 12 lower classes.",
                    "label": 0
                },
                {
                    "sent": "So if you want to know more about this three classifier, please going to discuss.",
                    "label": 0
                },
                {
                    "sent": "Great.",
                    "label": 0
                },
                {
                    "sent": "No fucking factor regression finding interesting sources of information.",
                    "label": 0
                },
                {
                    "sent": "I'm rich.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hi, I'm on this computer and our people is about factory testing.",
                    "label": 0
                },
                {
                    "sent": "Combining everything is sources of information so our problem domain is essentially genomic data.",
                    "label": 1
                },
                {
                    "sent": "As we all know, there's a vast abundance of such data available as a result of a lot of experiments on the various settings.",
                    "label": 0
                },
                {
                    "sent": "So there is a real need for having computational techniques to effectively being relevant information.",
                    "label": 0
                },
                {
                    "sent": "But what happened so far is that all these techniques either concentrate on doing factor regression models using microarray data directly or by using NLP style text, data mining techniques, or rationale is that if we combine these two techniques into a single model, we should be able to outperform any one of those models individually.",
                    "label": 1
                },
                {
                    "sent": "So the approach that we've taken is to use an infinite hierarchical factor regression model and combine a lot of the text data that we can get into that.",
                    "label": 0
                },
                {
                    "sent": "And we also show that this is.",
                    "label": 0
                },
                {
                    "sent": "Actually, an approximation of the parasite style graphical model and the reconstruction error curves that we show here showing effective improvement over using any of the single models alone.",
                    "label": 1
                },
                {
                    "sent": "So if you're interested in this sort of stuff, please spend some time in a poster here today.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Using odometry, an enquiry sufficient for basic localization by.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also.",
                    "label": 0
                },
                {
                    "sent": "Ali Ali, Andrew, immensely Castle is my legacy of Arabia or say, guns.",
                    "label": 0
                },
                {
                    "sent": "Looking everybody name.",
                    "label": 0
                },
                {
                    "sent": "Pizza, but when they got a base.",
                    "label": 0
                },
                {
                    "sent": "Yes to their low passive aggressive metal using a particle filter base using Monte Carlo and using invariant feature for the disrespect.",
                    "label": 0
                },
                {
                    "sent": "And Additionally, my practice in the sunlight using hot chocolate with lessons present axiom.",
                    "label": 0
                },
                {
                    "sent": "Another spinners will require using their Idol database, so they running information is used is a sequence of training in Muscatine under different lighting conditions.",
                    "label": 0
                },
                {
                    "sent": "Three different system where frame using the three depending on this chance another system were infested with three different sequence of this unit.",
                    "label": 0
                },
                {
                    "sent": "Do you want to see work or happened?",
                    "label": 0
                },
                {
                    "sent": "Question please.",
                    "label": 0
                },
                {
                    "sent": "He lost.",
                    "label": 0
                },
                {
                    "sent": "Processes by.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fabulous.",
                    "label": 0
                },
                {
                    "sent": "So our task is to develop Gaussian process that will be able to fuse information from different sources.",
                    "label": 0
                },
                {
                    "sent": "So it is being done by multitask ocean processes, but in the previous approaches that were out there the multi task is constructed using the same formula, same class of covariance function for each class and very just the parameters.",
                    "label": 0
                },
                {
                    "sent": "And here we propose a general general method for fusing every any type of stationary covariance functions.",
                    "label": 0
                },
                {
                    "sent": "And in our approach we can have different kernels for each of the tasks, and this one point Multicare approach and we also validated without showing through datasets from Georgie.",
                    "label": 0
                },
                {
                    "sent": "So if you have comments.",
                    "label": 0
                }
            ]
        }
    }
}