{
    "id": "wb4wymmqwyfug4n5baog2uxnze7yui2z",
    "title": "SIMCOMP: A Hybrid Soft Clustering of Metagenome Reads",
    "info": {
        "author": [
            "Shruthi Prabhakara, Department of Computer Science and Engineering, Pennsylvania State University"
        ],
        "published": "Oct. 14, 2010",
        "recorded": "September 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/prib2010_prabhakara_simc/",
    "segmentation": [
        [
            "The first part is hybrid soft cusping of Mecca, genome risk.",
            "Bite through the crack head.",
            "Roger Italia, yeah.",
            "OK, very good afternoon to you all.",
            "Today I will be presenting my talk on hybrid soft clustering algorithms for Metagenome reads.",
            "So the good news that I have for you is Doctor Daniel Houston covered half my slides so my talk will be a lot shorter.",
            "No."
        ],
        [
            "OK, so we all know what metagenomics us right now and we all know the two kinds of questions that metagenomics seeks to answer.",
            "The first one being who is there and the second being what are they doing?",
            "And we know the examples of the metagenome analysis, so the question that is who is there and how much of each Organism is there is answered by the sequence driven analysis and the questions regarding what these organisms are doing.",
            "What are the functions of these organisms is answered by the function driven analysis.",
            "So my talk will be concentrated on the sequence."
        ],
        [
            "She went analysis.",
            "So what is the objective of my algorithm?",
            "So the algorithm that we had?",
            "So we basically want to taxonomically characterize the metagenome data set that is, given a metagenome sample containing greets from different organisms, we want to cluster them into separate bins.",
            "Ideally each bench it contained reads from particular species at the same time we want to be quantifying the abundance of each of these species.",
            "So the objective is to determine who's there.",
            "And how much of each Organism is present?"
        ],
        [
            "Some additional mixes are relatively new field that's been in existence for about a decade or so.",
            "A number of tools have been developed for characterizing the metagenomics samples, so these approaches can be classified into 2 main categories.",
            "Once the similarity based on the comparative approaches, the second one being the composition based approaches.",
            "So the similarity based approaches align the reads to the existing databases using, say, blast, and hence they depend.",
            "On the availability of closely related genomes in the existing databases, so Megan presented by Doctor Houston is the most represented example of this kind.",
            "Now an obvious limitation of these problems is what do we do when we have read from novel species which do not give a hit to the existing databases, so these methods fail to find home logs for the new species, so they don't count the second kind of method, which is the composition based approach.",
            "So composition based approach use the intrinsic features of the sequences, such as the oligo, more frequency, the codon usage preferences, or the GC content to distinguish reads belonging to different.",
            "Different species, so a lot of the limitations of this kind of method is that reads that are shorter than a kilo base pair carry insufficient signal to separate reeds belonging to different species.",
            "So as you can see, the two methods are kind of complementary, and in our algorithm we try to combine."
        ],
        [
            "The two approaches.",
            "So our algorithm was inspired by the works of two papers for the 1st, first one being the works of the Libya troll.",
            "So here the authors propose a method for clustering the reads based on protein hits.",
            "These protein hits are called as proxy jeans and they are obtained by blasting the reads against a reference protein database.",
            "So the underlying basis of this method is that high sequence similarity between the read and the proxy gene implies that the organisms from which the region read in the proxy in originate are closely related and therefore the taxonomic annotation of the proxy gene can be used to assess that of the."
        ],
        [
            "Beats.",
            "Now the authors of this paper I'm pleased to know that the authors of this paper also present amongst us in the audience they extended the previous method to cluster the reads based on weighted proteins.",
            "So the used method for assigning proteins weight based on the significance, the more significant the protein is, the lower is its weight, and they used a method and elegant method based on weighted set clustering to cluster the reads based on this.",
            "So these two methods perform well when we have a significant fraction of our data set that gives us good match when used with BLAST.",
            "But what happens when we have leads from new species?"
        ],
        [
            "So as I said before, we are proposing a soft clustering approach.",
            "Now white soft clustering.",
            "So the metagenomics data is characterized by the presence of increased amounts of polymorphism.",
            "Horizontal gene transfer over representation of certain concealed parts of the of the genomes leading to conflicts in assembly and clustering.",
            "So.",
            "Closely related species are most likely to have Houma Logus sequences shared between them.",
            "So where do we place such sequences with species to replace such sequences into?",
            "Secondly, metagenomics data is characterized by incomplete and fragmentary nature of the data set, lowering the quality of annotation.",
            "So in so in order to address these characteristics of the metagenomics data set we propose, we propose overlapping clusters.",
            "We propose an algorithm to develop.",
            "To implement overlapping clusters, so we hope to capture the Houma logus sequences and the low quality annotated reads into the soft boundaries of the clusters."
        ],
        [
            "So our basic algorithm is a fuzzy adaptation of incremental leader clustering algorithm.",
            "Algorithm groups turrids into clusters.",
            "Each cluster has a core of fringe and a leader.",
            "So the core of the clusters contained reads that definitely belong to the cluster.",
            "The fringes of one or more clusters may contain reads that overlap and each cluster has leader.",
            "Leader is basically a Reed which is most representative of the cluster."
        ],
        [
            "Oh so our algorithm proceeds in two passes.",
            "The first pass is the similarity based parser, the comparative pass in the second pass is the composition based fast.",
            "So in the similarity based past we use blast to extract reference sequences from within the data set and cluster the reads based on their taxonomy similarity.",
            "Basically, in the second pass we take the remaining reads that did not give a significant blast hits and we cluster them based on their composition."
        ],
        [
            "So getting into the details of the first pass, which is the similarity based passed.",
            "So we take the read from a genome data set and we blasted against a reference protein database.",
            "So fraction of the rates will give us significant protein hits, so we extract the taxonomy of the protein hits from the NCBI database and we cluster the wreaths associated with the proteins based on the taxonomy of the proteins.",
            "So the end of this step we basically have similarity based a taxonomy based clusters.",
            "Now as a last step, we find a reader for each cluster.",
            "Really there is one who serves, which is most representative of the cluster whose sum of sequence similarity from the remaining reads in the cluster is maximum."
        ],
        [
            "In the second step, we take the remaining great streets that did not give us a significant blast hit against the database, and we cluster them based on our incremental leader clustering algorithm.",
            "So we determine the read similarity of each of the remaining creates with the existing read read leaders.",
            "So if the read similarity is created in the code threshold we added to the core of the cluster, if it's created in the French threshold, the Reed gets added to fringes of one or more clusters.",
            "Otherwise they read itself forms new cluster with itself as the reader.",
            "So here the parameters code threshold and the French thresholds are determined based on our experiments on simulated datasets."
        ],
        [
            "So we perform their experiments on 12th simulated datasets containing 45454 reads of 100 base pairs in length of about 100 piece parent length and I will be presenting the results on one particular data set that contains 9 organisms at a coverage of .1 X."
        ],
        [
            "So are you going to was able to successfully enriched the data set into a small number of clusters?",
            "Now we wanted to quantify how representative our leaders are of each of the clusters.",
            "So in order to do so, all the reads in the cluster were assigned the same tax as that of the leader.",
            "And then we measured the taxonomic distribution represented by our leaders as opposed to the true distribution."
        ],
        [
            "So we see from the figure the true distribution is represented by the green line and the distribution determined by our leaders is represented by the yellow lines that the distribution determined by our algorithm is quite close to the true distribution at all ranks.",
            "Therefore, leaders can be used as an accurate estimation of the of the taxonomic distribution of our data set."
        ],
        [
            "So the 2nd we wanted to measure how homogeneous or how pure are the clusters that we that we found.",
            "So how much unity of the cluster is defined as the fraction of reads within the cluster which belong to the same taxonomy.",
            "So here we define two kinds of cluster purity.",
            "Once the total cost, cluster purity and other cool cluster purity.",
            "So total cluster purity is the maximum fraction of the reeds belonging to the same taxonomy in the cluster and core cluster.",
            "Purity is the maximum fraction of the reach within the.",
            "Call of the cluster.",
            "They belong to the same taxonomy and as we can see the core cluster purity is greater than the total cluster purity at all ranks, so this.",
            "This asserts our algorithms ability to filter out the low quality reads into the fringes of the cluster."
        ],
        [
            "So finally we wanted to measure how the cluster purity varies with the length of the oligomers and that and with the re threshold.",
            "So we performed experiments for Loma length, very waiting from 3 primers to excimers and we found that excimers all have the best discriminatory power.",
            "This is in agreement with the related work and as far as the re thresholds go we saw that with the increase in the re threshold the cluster purity increases.",
            "Now possible justification for this could be that with the increase.",
            "In the read thresholds, we have most stringent, more stricter criteria and the size of the clusters were smaller and hence are more likely to be pure, more likely to be pure."
        ],
        [
            "So in conclusion, we proposed a semi supervised algorithm that is a hybrid of comparative and composition based approaches.",
            "It's a soft clustering algorithm.",
            "We have captured the ambiguity associated with Houma Logus sequences and low quality reads within the soft boundaries.",
            "So the most time consuming part of our algorithm was that of the blast plastic of the reeds, and as future work we hope to investigate the scope.",
            "So I presented this algorithm as opposed to yesterday, and I got quite some.",
            "Constructive feedback from authors of related work and based on their feedback I hope to.",
            "I want to investigate the scope of the soft boundaries of the clusters ahead and.",
            "One of the ways of testing the robustness of the algorithm is to actually mask the best data.",
            "Best blast hit return by best hit return by the blast, and see how our algorithm performs then just by using the composition based metric.",
            "Secondly, so we've come a long way since we published this paper and in the present implementation of our algorithm we don't have as many parameters as is there in this particular algorithm, and we hope to use also use a better similarity.",
            "Based metric in the future versions.",
            "That's why."
        ],
        [
            "I'll be happy to take any questions.",
            "Frog.",
            "Is this an effective procedure?",
            "No no no.",
            "Because you are doing being tried to Gloucester into the.",
            "Organism originally present at the first step, you do blast X if you got hit, you have a group of reeds.",
            "Would you look back?",
            "Do a plus N because within this group probably if you look at plus 10 and summaries shouldn't be said.",
            "You you, let's say you you being a group of reason according to Class X, right right?",
            "And so in my algorithm I haven't know.",
            "I'm assuming that if all the reads had the same species, same proteins belonging to the same species.",
            "Sequences right, but if they, if they match the match of protein, which is the more conserved part?",
            "I have more reason to believe that they belong to the same species.",
            "I see your point.",
            "Or higher level, but nothing suspicious, nothing.",
            "I probably have to look into it further, yes.",
            "Anymore questions.",
            "I'm sorry.",
            "Santa just one cluster tree Mccluster more than one cluster.",
            "More than one cluster, so that's what the fringe threshold is for here, yes?",
            "Yes.",
            "Clustering them off the plastics.",
            "Dixon.",
            "Plastics is the rate limiting step, right?",
            "Tweak there's a lot of parameters you can tweak with lost in terms of the word lakes and things you're right.",
            "Sweet that speed up.",
            "Plastics, given what you're going to be doing this.",
            "Do too much.",
            "So I think by tweaking the parameters of plastics, the amount of reduction in time that can be obtained, it's actually actually very little, is what as I understand from the other from talking to the other biologists.",
            "But what we could do is what Megan also does is actually use plastics and only a small fraction of the reeds to just get a representation.",
            "Good, good, good idea of what the representation of the data set is like and then perform the composition based on it.",
            "Anymore.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first part is hybrid soft cusping of Mecca, genome risk.",
                    "label": 0
                },
                {
                    "sent": "Bite through the crack head.",
                    "label": 0
                },
                {
                    "sent": "Roger Italia, yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, very good afternoon to you all.",
                    "label": 0
                },
                {
                    "sent": "Today I will be presenting my talk on hybrid soft clustering algorithms for Metagenome reads.",
                    "label": 1
                },
                {
                    "sent": "So the good news that I have for you is Doctor Daniel Houston covered half my slides so my talk will be a lot shorter.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we all know what metagenomics us right now and we all know the two kinds of questions that metagenomics seeks to answer.",
                    "label": 0
                },
                {
                    "sent": "The first one being who is there and the second being what are they doing?",
                    "label": 1
                },
                {
                    "sent": "And we know the examples of the metagenome analysis, so the question that is who is there and how much of each Organism is there is answered by the sequence driven analysis and the questions regarding what these organisms are doing.",
                    "label": 0
                },
                {
                    "sent": "What are the functions of these organisms is answered by the function driven analysis.",
                    "label": 0
                },
                {
                    "sent": "So my talk will be concentrated on the sequence.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "She went analysis.",
                    "label": 0
                },
                {
                    "sent": "So what is the objective of my algorithm?",
                    "label": 0
                },
                {
                    "sent": "So the algorithm that we had?",
                    "label": 0
                },
                {
                    "sent": "So we basically want to taxonomically characterize the metagenome data set that is, given a metagenome sample containing greets from different organisms, we want to cluster them into separate bins.",
                    "label": 0
                },
                {
                    "sent": "Ideally each bench it contained reads from particular species at the same time we want to be quantifying the abundance of each of these species.",
                    "label": 0
                },
                {
                    "sent": "So the objective is to determine who's there.",
                    "label": 0
                },
                {
                    "sent": "And how much of each Organism is present?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some additional mixes are relatively new field that's been in existence for about a decade or so.",
                    "label": 0
                },
                {
                    "sent": "A number of tools have been developed for characterizing the metagenomics samples, so these approaches can be classified into 2 main categories.",
                    "label": 0
                },
                {
                    "sent": "Once the similarity based on the comparative approaches, the second one being the composition based approaches.",
                    "label": 0
                },
                {
                    "sent": "So the similarity based approaches align the reads to the existing databases using, say, blast, and hence they depend.",
                    "label": 0
                },
                {
                    "sent": "On the availability of closely related genomes in the existing databases, so Megan presented by Doctor Houston is the most represented example of this kind.",
                    "label": 0
                },
                {
                    "sent": "Now an obvious limitation of these problems is what do we do when we have read from novel species which do not give a hit to the existing databases, so these methods fail to find home logs for the new species, so they don't count the second kind of method, which is the composition based approach.",
                    "label": 0
                },
                {
                    "sent": "So composition based approach use the intrinsic features of the sequences, such as the oligo, more frequency, the codon usage preferences, or the GC content to distinguish reads belonging to different.",
                    "label": 1
                },
                {
                    "sent": "Different species, so a lot of the limitations of this kind of method is that reads that are shorter than a kilo base pair carry insufficient signal to separate reeds belonging to different species.",
                    "label": 0
                },
                {
                    "sent": "So as you can see, the two methods are kind of complementary, and in our algorithm we try to combine.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The two approaches.",
                    "label": 0
                },
                {
                    "sent": "So our algorithm was inspired by the works of two papers for the 1st, first one being the works of the Libya troll.",
                    "label": 0
                },
                {
                    "sent": "So here the authors propose a method for clustering the reads based on protein hits.",
                    "label": 0
                },
                {
                    "sent": "These protein hits are called as proxy jeans and they are obtained by blasting the reads against a reference protein database.",
                    "label": 0
                },
                {
                    "sent": "So the underlying basis of this method is that high sequence similarity between the read and the proxy gene implies that the organisms from which the region read in the proxy in originate are closely related and therefore the taxonomic annotation of the proxy gene can be used to assess that of the.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Beats.",
                    "label": 0
                },
                {
                    "sent": "Now the authors of this paper I'm pleased to know that the authors of this paper also present amongst us in the audience they extended the previous method to cluster the reads based on weighted proteins.",
                    "label": 0
                },
                {
                    "sent": "So the used method for assigning proteins weight based on the significance, the more significant the protein is, the lower is its weight, and they used a method and elegant method based on weighted set clustering to cluster the reads based on this.",
                    "label": 1
                },
                {
                    "sent": "So these two methods perform well when we have a significant fraction of our data set that gives us good match when used with BLAST.",
                    "label": 0
                },
                {
                    "sent": "But what happens when we have leads from new species?",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I said before, we are proposing a soft clustering approach.",
                    "label": 0
                },
                {
                    "sent": "Now white soft clustering.",
                    "label": 0
                },
                {
                    "sent": "So the metagenomics data is characterized by the presence of increased amounts of polymorphism.",
                    "label": 0
                },
                {
                    "sent": "Horizontal gene transfer over representation of certain concealed parts of the of the genomes leading to conflicts in assembly and clustering.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Closely related species are most likely to have Houma Logus sequences shared between them.",
                    "label": 1
                },
                {
                    "sent": "So where do we place such sequences with species to replace such sequences into?",
                    "label": 0
                },
                {
                    "sent": "Secondly, metagenomics data is characterized by incomplete and fragmentary nature of the data set, lowering the quality of annotation.",
                    "label": 1
                },
                {
                    "sent": "So in so in order to address these characteristics of the metagenomics data set we propose, we propose overlapping clusters.",
                    "label": 0
                },
                {
                    "sent": "We propose an algorithm to develop.",
                    "label": 0
                },
                {
                    "sent": "To implement overlapping clusters, so we hope to capture the Houma logus sequences and the low quality annotated reads into the soft boundaries of the clusters.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our basic algorithm is a fuzzy adaptation of incremental leader clustering algorithm.",
                    "label": 1
                },
                {
                    "sent": "Algorithm groups turrids into clusters.",
                    "label": 0
                },
                {
                    "sent": "Each cluster has a core of fringe and a leader.",
                    "label": 1
                },
                {
                    "sent": "So the core of the clusters contained reads that definitely belong to the cluster.",
                    "label": 0
                },
                {
                    "sent": "The fringes of one or more clusters may contain reads that overlap and each cluster has leader.",
                    "label": 0
                },
                {
                    "sent": "Leader is basically a Reed which is most representative of the cluster.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oh so our algorithm proceeds in two passes.",
                    "label": 0
                },
                {
                    "sent": "The first pass is the similarity based parser, the comparative pass in the second pass is the composition based fast.",
                    "label": 0
                },
                {
                    "sent": "So in the similarity based past we use blast to extract reference sequences from within the data set and cluster the reads based on their taxonomy similarity.",
                    "label": 1
                },
                {
                    "sent": "Basically, in the second pass we take the remaining reads that did not give a significant blast hits and we cluster them based on their composition.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So getting into the details of the first pass, which is the similarity based passed.",
                    "label": 0
                },
                {
                    "sent": "So we take the read from a genome data set and we blasted against a reference protein database.",
                    "label": 1
                },
                {
                    "sent": "So fraction of the rates will give us significant protein hits, so we extract the taxonomy of the protein hits from the NCBI database and we cluster the wreaths associated with the proteins based on the taxonomy of the proteins.",
                    "label": 1
                },
                {
                    "sent": "So the end of this step we basically have similarity based a taxonomy based clusters.",
                    "label": 0
                },
                {
                    "sent": "Now as a last step, we find a reader for each cluster.",
                    "label": 1
                },
                {
                    "sent": "Really there is one who serves, which is most representative of the cluster whose sum of sequence similarity from the remaining reads in the cluster is maximum.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the second step, we take the remaining great streets that did not give us a significant blast hit against the database, and we cluster them based on our incremental leader clustering algorithm.",
                    "label": 0
                },
                {
                    "sent": "So we determine the read similarity of each of the remaining creates with the existing read read leaders.",
                    "label": 0
                },
                {
                    "sent": "So if the read similarity is created in the code threshold we added to the core of the cluster, if it's created in the French threshold, the Reed gets added to fringes of one or more clusters.",
                    "label": 1
                },
                {
                    "sent": "Otherwise they read itself forms new cluster with itself as the reader.",
                    "label": 0
                },
                {
                    "sent": "So here the parameters code threshold and the French thresholds are determined based on our experiments on simulated datasets.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we perform their experiments on 12th simulated datasets containing 45454 reads of 100 base pairs in length of about 100 piece parent length and I will be presenting the results on one particular data set that contains 9 organisms at a coverage of .1 X.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So are you going to was able to successfully enriched the data set into a small number of clusters?",
                    "label": 1
                },
                {
                    "sent": "Now we wanted to quantify how representative our leaders are of each of the clusters.",
                    "label": 0
                },
                {
                    "sent": "So in order to do so, all the reads in the cluster were assigned the same tax as that of the leader.",
                    "label": 1
                },
                {
                    "sent": "And then we measured the taxonomic distribution represented by our leaders as opposed to the true distribution.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we see from the figure the true distribution is represented by the green line and the distribution determined by our leaders is represented by the yellow lines that the distribution determined by our algorithm is quite close to the true distribution at all ranks.",
                    "label": 0
                },
                {
                    "sent": "Therefore, leaders can be used as an accurate estimation of the of the taxonomic distribution of our data set.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the 2nd we wanted to measure how homogeneous or how pure are the clusters that we that we found.",
                    "label": 0
                },
                {
                    "sent": "So how much unity of the cluster is defined as the fraction of reads within the cluster which belong to the same taxonomy.",
                    "label": 0
                },
                {
                    "sent": "So here we define two kinds of cluster purity.",
                    "label": 0
                },
                {
                    "sent": "Once the total cost, cluster purity and other cool cluster purity.",
                    "label": 0
                },
                {
                    "sent": "So total cluster purity is the maximum fraction of the reeds belonging to the same taxonomy in the cluster and core cluster.",
                    "label": 1
                },
                {
                    "sent": "Purity is the maximum fraction of the reach within the.",
                    "label": 0
                },
                {
                    "sent": "Call of the cluster.",
                    "label": 0
                },
                {
                    "sent": "They belong to the same taxonomy and as we can see the core cluster purity is greater than the total cluster purity at all ranks, so this.",
                    "label": 0
                },
                {
                    "sent": "This asserts our algorithms ability to filter out the low quality reads into the fringes of the cluster.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So finally we wanted to measure how the cluster purity varies with the length of the oligomers and that and with the re threshold.",
                    "label": 0
                },
                {
                    "sent": "So we performed experiments for Loma length, very waiting from 3 primers to excimers and we found that excimers all have the best discriminatory power.",
                    "label": 1
                },
                {
                    "sent": "This is in agreement with the related work and as far as the re thresholds go we saw that with the increase in the re threshold the cluster purity increases.",
                    "label": 0
                },
                {
                    "sent": "Now possible justification for this could be that with the increase.",
                    "label": 0
                },
                {
                    "sent": "In the read thresholds, we have most stringent, more stricter criteria and the size of the clusters were smaller and hence are more likely to be pure, more likely to be pure.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, we proposed a semi supervised algorithm that is a hybrid of comparative and composition based approaches.",
                    "label": 0
                },
                {
                    "sent": "It's a soft clustering algorithm.",
                    "label": 1
                },
                {
                    "sent": "We have captured the ambiguity associated with Houma Logus sequences and low quality reads within the soft boundaries.",
                    "label": 0
                },
                {
                    "sent": "So the most time consuming part of our algorithm was that of the blast plastic of the reeds, and as future work we hope to investigate the scope.",
                    "label": 0
                },
                {
                    "sent": "So I presented this algorithm as opposed to yesterday, and I got quite some.",
                    "label": 0
                },
                {
                    "sent": "Constructive feedback from authors of related work and based on their feedback I hope to.",
                    "label": 0
                },
                {
                    "sent": "I want to investigate the scope of the soft boundaries of the clusters ahead and.",
                    "label": 1
                },
                {
                    "sent": "One of the ways of testing the robustness of the algorithm is to actually mask the best data.",
                    "label": 0
                },
                {
                    "sent": "Best blast hit return by best hit return by the blast, and see how our algorithm performs then just by using the composition based metric.",
                    "label": 0
                },
                {
                    "sent": "Secondly, so we've come a long way since we published this paper and in the present implementation of our algorithm we don't have as many parameters as is there in this particular algorithm, and we hope to use also use a better similarity.",
                    "label": 0
                },
                {
                    "sent": "Based metric in the future versions.",
                    "label": 0
                },
                {
                    "sent": "That's why.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll be happy to take any questions.",
                    "label": 0
                },
                {
                    "sent": "Frog.",
                    "label": 0
                },
                {
                    "sent": "Is this an effective procedure?",
                    "label": 0
                },
                {
                    "sent": "No no no.",
                    "label": 0
                },
                {
                    "sent": "Because you are doing being tried to Gloucester into the.",
                    "label": 0
                },
                {
                    "sent": "Organism originally present at the first step, you do blast X if you got hit, you have a group of reeds.",
                    "label": 0
                },
                {
                    "sent": "Would you look back?",
                    "label": 0
                },
                {
                    "sent": "Do a plus N because within this group probably if you look at plus 10 and summaries shouldn't be said.",
                    "label": 0
                },
                {
                    "sent": "You you, let's say you you being a group of reason according to Class X, right right?",
                    "label": 0
                },
                {
                    "sent": "And so in my algorithm I haven't know.",
                    "label": 0
                },
                {
                    "sent": "I'm assuming that if all the reads had the same species, same proteins belonging to the same species.",
                    "label": 0
                },
                {
                    "sent": "Sequences right, but if they, if they match the match of protein, which is the more conserved part?",
                    "label": 0
                },
                {
                    "sent": "I have more reason to believe that they belong to the same species.",
                    "label": 0
                },
                {
                    "sent": "I see your point.",
                    "label": 0
                },
                {
                    "sent": "Or higher level, but nothing suspicious, nothing.",
                    "label": 0
                },
                {
                    "sent": "I probably have to look into it further, yes.",
                    "label": 0
                },
                {
                    "sent": "Anymore questions.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Santa just one cluster tree Mccluster more than one cluster.",
                    "label": 0
                },
                {
                    "sent": "More than one cluster, so that's what the fringe threshold is for here, yes?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Clustering them off the plastics.",
                    "label": 0
                },
                {
                    "sent": "Dixon.",
                    "label": 0
                },
                {
                    "sent": "Plastics is the rate limiting step, right?",
                    "label": 0
                },
                {
                    "sent": "Tweak there's a lot of parameters you can tweak with lost in terms of the word lakes and things you're right.",
                    "label": 0
                },
                {
                    "sent": "Sweet that speed up.",
                    "label": 0
                },
                {
                    "sent": "Plastics, given what you're going to be doing this.",
                    "label": 0
                },
                {
                    "sent": "Do too much.",
                    "label": 0
                },
                {
                    "sent": "So I think by tweaking the parameters of plastics, the amount of reduction in time that can be obtained, it's actually actually very little, is what as I understand from the other from talking to the other biologists.",
                    "label": 0
                },
                {
                    "sent": "But what we could do is what Megan also does is actually use plastics and only a small fraction of the reeds to just get a representation.",
                    "label": 0
                },
                {
                    "sent": "Good, good, good idea of what the representation of the data set is like and then perform the composition based on it.",
                    "label": 0
                },
                {
                    "sent": "Anymore.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}