{
    "id": "6tudontoqrk4f47y6js535pnh5rkvr5g",
    "title": "Graphical models",
    "info": {
        "author": [
            "Zoubin Ghahramani, University of Cambridge"
        ],
        "published": "Feb. 5, 2008",
        "recorded": "January 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Graphical Models"
        ]
    },
    "url": "http://videolectures.net/epsrcws08_ghahramani_gm/",
    "segmentation": [
        [
            "OK, so.",
            "Next session will be.",
            "By Zubin ghahramani.",
            "2 minutes again.",
            "One of the leading lights in machine learning.",
            "He did his pH D with Mike Jordan when he was at MIT and then post talked with Jeff Hinton.",
            "He then first came to the UK when the Gatsby Computational Neuroscience Institute was set up and it's sort of a mark of his qualities that he was selected as one of the founding members of the Gaspee Unit.",
            "His research.",
            "Certainly up to that time he was the first person I believe to present a paper with expectation maximization algorithms at the next conference.",
            "He did an enormous amount of work with Mike Jordan and others to popularize the use of variational approximations in probabilistic models.",
            "And then since then, he's done an immense amount of work on lots of different types of Bayesian models.",
            "Always elegant, always interesting, and this was recognized for couple of years ago.",
            "I guess by his move from Gatsby to Cambridge Engineering, where he was appointed about as a chair.",
            "The most annoying thing about zoom in.",
            "I've got the 18 months.",
            "I already achieved probably far more in his career so far than I expect 20 in my entire career.",
            "We are extremely lucky to have him here, giving us an introduction to graphical models, an area in which he's been key in pushing forward in machine learning.",
            "Thanks Neil, I always know I'm going to cringe with your introduction.",
            "But that's very, very kind of you, thanks.",
            "OK.",
            "So I'm going to talk about graphical models and we have we would have had an hour and a half had it not been for a bit of traffic in a bit of getting lost, so we'll go fairly quickly through this, but I'll be around over lunch and you know, please ask questions throughout the day.",
            "So.",
            "I divided up into a few short lectures.",
            "In the first one I'm going to just introduce what graphical models are.",
            "Then I'm going to talk about inference in graphical models that I'm going to talk about learning in graphical models.",
            "So how many people have encountered graphical models before?",
            "OK. How many have not encountered graphical models?",
            "OK, good."
        ],
        [
            "Alright, so um graphical models are one of the most exciting things that have happened in machine learning in the last couple of decades.",
            "There essentially a way of representing probability distributions using graphs and their different kinds of graphical models are three main kinds, factor graphs, undirected graphs and directed graphs, and in all of these kinds of graphical models, the nodes correspond to random variables ABCD.",
            "For example, here, the edges represent statistical dependencies between those variables.",
            "And I'm going to focus on factor graphs a little bit, and then undirected graphs a lot, and I'm not really going to talk about on direct."
        ],
        [
            "Graphs very much.",
            "They're very similar to factor graphs.",
            "So why do we need these?",
            "We have probabilities.",
            "We can write down equations.",
            "Why would we need graphical models?",
            "Well, first of all, graphs are very intuitive to look at, and you know we have examples of graphs throughout many different fields of science and engineering.",
            "We like to draw graphs to represent relationships between things.",
            "So why not use those same intuitive diagrams for probabilistic models?",
            "The second reason graphical models are useful is that they allow us to represent conditional independence relationships between variables abstractly, without talking about the nitty gritty of the particular parametric forms of the probability distributions.",
            "So you can say A is independent from B without having to say whether A was a Gaussian distribution with mean one and variance 7 or.",
            "A binary variable with a Bernoulli distribution or anything like that, so they represent conditional independence.",
            "So just by looking at the graph, we can answer questions is a dependent on B given that we know the value of C. And finally, there's a computational reason why graphical models are very exciting.",
            "They allow us to define general message passing algorithms to implement probabilistic inference efficiently.",
            "So if we want to answer a question like what is the probability distribution over a given that we know variable C takes on some value little C?",
            "We can do this by sending messages on the graph, so when we implement things on a computer, we can do kind of object oriented implementation where each node sends messages to its neighbors an after a bunch of messages get passed, we can compute all the right probabilities that we're interested in.",
            "So graphical models really combine ideas from statistics from graph theory and computer science.",
            "And, um.",
            "Even if you, even if you don't use these message passing algorithms, you'll find the graphical models all over papers in machine learning and pattern recognition these days.",
            "So it's important to note."
        ],
        [
            "Exactly they mean OK.",
            "So fundamentally graphical models represent conditional independence, and we're going to use the following notation to denote conditional independence.",
            "This says X is.",
            "Independent of Y given V. And what that means is that the probability distribution over X given Y&V.",
            "Is equal to the probability distribution over X given V. That's you know.",
            "In other words, why doesn't really affect the distribution on X?",
            "Once we know the value of V. And this is just the technical condition, so that these things are well defined.",
            "These probabilities are well defined.",
            "Another way of thinking about this is X is independent of Y given V. If the joint distribution of X&Y given V factors into the distribution of X given V and the distribution of Y given V. And we can think of conditional independence between sets of variables in a completely analogous way.",
            "Bunch of variables X and a bunch of variables.",
            "Why are you going to be conditionally independent given V if the joint distribution factors in this way and the more traditional notion of independence, which is marginal independence, we can write like this that just says X is independent of Y, or in other words, X is independent of Y.",
            "Given the empty set of variables.",
            "If you want to write it in this conditional independence form that just says the joint distribution of X&Y factors into the distribution of X times of distribution of Y."
        ],
        [
            "OK, so you know we can think of a bunch of examples in the real world where you might have conditional or marginal independence.",
            "For example.",
            "The amount of speeding fines that you get.",
            "Should be independent of the type of car you're driving.",
            "Given the speed that you're caught driving.",
            "Otherwise, it wouldn't seem very fair.",
            "Uh, you know whether you have lung cancer.",
            "It is independent of whether you have teeth.",
            "Yellow teeth, sorry.",
            "Given that you're smoking all those, smoking can cause both lung cancer and your key to turn yellow.",
            "Etc so you know we can.",
            "We can imagine lots of different examples of marginal and conditional independence.",
            "And I won't go through all of them, but it's a little subtle to think about these things, because sometimes things can be marginally independent, like for example, if you have two teams playing each other with players chosen at random from a lot of large pool of players, then the ability of team A and the ability of Team B might be marginally independent.",
            "Variables, but given that you know the outcome of a game versus of a versus B, then these are no longer marginally independent.",
            "So for example, if we know that a beat B, then you would infer that the ability of team A is as likely to be greater than the ability of Team B, right?",
            "So they no longer remain independent.",
            "OK, so graphical models are way of representing conditional and marginal."
        ],
        [
            "Independence and I'm going to start just by talking about factor graphs.",
            "In factor graphs you have the nodes.",
            "You have two types of nodes.",
            "The circles represent random variables and these little filled dots represent factors in the joint distribution.",
            "So for example, this factor graph here represents the fact that the probability distribution over a through E factors into the product of a function of A&C, that's this.",
            "Are represented by this dot.",
            "Here a function of BC&D represented by this and a function of CD&E, and this one over zed is simply a normalization constant.",
            "This factor graph here on this side represents this factorization of the joint distribution.",
            "And the normalization constant is simply the sum over all the possible settings of all of the variables of the product of the factors.",
            "OK, so it's just what you need so that the probabilities sum to one.",
            "So.",
            "What these graphs represent is that is a family of probability distributions, so this graph here represents all probability distributions over.",
            "Five variables that can be written in this form.",
            "OK. And it in the graph we can talk about things like neighborhood relationships between nodes, and these are going to be important to figure out what the independence relationships are between the random variables.",
            "So two nodes are neighbors in a factor graph.",
            "They share a common factor, so A&C are neighbors.",
            "But A&B are not neighbor."
        ],
        [
            "OK.",
            "So this is just a recap of what I said on the previous slide.",
            "And now we can talk about how these graphs relate to the notion of conditional independence.",
            "So let's define a path to be a sequence of neighboring nodes.",
            "So for example, ACD is a path.",
            "Uh.",
            "And if we have a probability distribution that factors according to a factor graph, then it's not very hard to prove that X is independent of Y given a set of variables V. If every path between X&Y contains some node in the set V. Um?",
            "So for example, A is independent of D given C in this graph, because every path from A to D goes through C. And it's it's sort of intuitive, it's.",
            "The idea that if you know the value of C, then that blocks.",
            "The information flowing from A to D. It blocks the sort of relationship between A&B.",
            "So the corollary of this is that given the neighbors of a variable X, that variable X is conditionally independent of all other variables.",
            "So X is independent of Y given the neighbors of X where Y is any element of the set of.",
            "That doesn't.",
            "In you know the set of variables, not including X an.",
            "The neighbors of X OK. Alright, so that's the basic idea of a factor graph, an essentially the set of neighbors of a node Shields that variable from all the other variables in the sort of universe that you're trying to model.",
            "OK, so let me just say one other thing about this.",
            "Why would this be useful?",
            "Well, let's imagine we're trying to model a nuclear power plant, and we have hundreds of sensors and variables.",
            "We might be interested in in the nuclear power plant, one of which might be whether there is a meltdown going on of the core.",
            "OK, but we have all these sensors and we build a probabilistic model that tells us.",
            "How these variables are related to each other?",
            "We write it down as a factor graph and then we can take this graph and say given the following readings of variables that I can observe, what is the probability that the following event is happening that I can't directly observe?",
            "And.",
            "These notions of conditional independence come in very handy for figuring out which variables are relevant, which ones are irrelevant, and eventually for figuring out how to pass messages.",
            "OK, that's factor.",
            "Graphs will come back to factor graphs in a few minutes.",
            "Let me talk about the."
        ],
        [
            "Directed acyclic graphs, which are the most commonly used graphical model.",
            "These are sometimes called Bayesian networks, although there's a footnote here that says you don't have to learn them in a Bayesian manner, it doesn't necessarily mean that you're being completely Bayesian about inference in these, it's just the name that they've been given.",
            "But let's call them directed acyclic graphs for now, so.",
            "One of these directed acyclic graphs is essentially a graph where again you have nodes representing random variables, and now we have directed edges representing dependencies between those variables.",
            "An this DAG or Bayesian network corresponds to factorization of the joint probability distribution, so this particular graph corresponds to the idea that the joint distribution over a through E factors into the product of the distribution.",
            "Of a type of distribution of B.",
            "Times the distribution of C given A&B etc.",
            "And the pattern that I'm sure you've noticed is the factorization corresponds to each variable given its parents in the graph.",
            "So see, given its parents A&B or parents are just nodes that point to that variable.",
            "OK, A is apparent of CC is the child of a.",
            "So in general.",
            "A directed graph corresponds to the idea that the joint distribution over a bunch of variables factors into the product of each variable given its parents.",
            "OK."
        ],
        [
            "So the semantics of a directed graph are similar to the factor graph.",
            "Again, just by looking at the graph, we can say which variables are conditionally independent of which other variables, given some other set of variables.",
            "So in the factor graph it was really, really easy.",
            "We just needed to look at just paths connecting X&Y to see if they went through V. Here it's a bit more complicated.",
            "For a directed Graph, X is conditionally independent of Y given the set of variables V if the set of variables VD separates X from Y, it's just the notion of separation on the graph is called D separation.",
            "Because stands for dependency separation.",
            "So it makes X&Y independent.",
            "An to check for D separation.",
            "Is a little tricky.",
            "The definition is that VD separates X from Y if every undirected path between X&Y, that is past where we've ignored the directionality of the arrows.",
            "So we can go up or down arrows.",
            "If every undirected path between X&Y is blocked by V, so again, that feels a bit intuitive.",
            "V is blocking information flowing from X to Y and vice versa and therefore making X&Y independent of each other.",
            "Um?",
            "Now to check whether a path is blocked, you have to see if there is a node W on the path such that it satisfies either of these conditions and if it satisfies either of these conditions, then that path is blocked.",
            "Then you have to check all paths and then you know.",
            "Weather something V the separate sex from Y. OK.",
            "So the two conditions are a little technical.",
            "It takes a bit of time to figure out why these make sense.",
            "This condition is that W has converging arrows along the path.",
            "In other words, you go into W and then you flow out in this way and not either.",
            "W North descendants are observed.",
            "In other words, are members of the set V. The second condition is that W does not have converging arrows along the path.",
            "So you go either this way or that way and W is observed.",
            "OK, so if either of these two conditions are satisfied, then VD separates X from Y.",
            "And if you haven't seen this before, I don't expect you to look at this and say, ha ha, that immediately makes sense.",
            "Takes a little bit of time to think about it.",
            "I'm not going to go into details because I want to be able to get into the propagation algorithms and the learning, but there is a lot of good material that tries to explain this.",
            "Including longer tutorials of this kind that might be on line.",
            "So the corollary for Bayesian networks or directed graphs is that.",
            "The Markov boundary for X, that is, the set of variables that make X independent of all other variables, is the parents of X.",
            "The children of X and the parents of the children of X.",
            "So given those variables, X is independent of everything else that's similar to what we had in factor graphs here."
        ],
        [
            "OK.",
            "So let's let's just look at some examples.",
            "If we have this graph, A is independent of B. Um?",
            "Marginally independent since a CB is blocked by C. An AC DB is blocked by D etc, so all the paths between A&B are blocked because nothing is observed.",
            "None of these variables have have been observed.",
            "It's not true that A is independent of B given C, since a CB is not blocked.",
            "So given CA&B are dependent on each other.",
            "And this is a very important concept given.",
            "Given a particular symptom.",
            "The probability of having this disease or that disease that could have caused that symptom.",
            "These probabilities are going to be correlated OK, the joint probability is is not going to be independent, even if getting this disease and getting that disease could happen with independent probabilities.",
            "Ann, and Furthermore we can look at a few other things, like A is independent of D given B&CA&B are independent.",
            "Given B&C on this graph because all paths are blocked.",
            "It's."
        ],
        [
            "Cetera.",
            "OK so here is some.",
            "Useful notation that again you'll see in a lot of papers.",
            "You'll see this these boxes around some nodes with a little letter in the corner.",
            "This is called plate notation, an it represents repetitions of some variable.",
            "So consider N data points generated from a Gaussian.",
            "We have X one through X.",
            "Let's say that the Gaussian has mean mu, an standard deviation Sigma.",
            "We could write down a little probabilistic model where we have.",
            "P of mu being the prior on mu P of Sigma being the prior on Sigma and then the likelihood function corresponding to each of the data points.",
            "This is what the graph would look like for this factorization, right each node, given his parents is represented like this, But these are these guys are replicated N times.",
            "So to make the graph a little prettier and easier to look at, we can put a box around one of these nodes.",
            "And put an index.",
            "He ran that just means XN goes from N = 1, two big N. OK."
        ],
        [
            "That's plate notation.",
            "Alright, so that's the summary of the first mini lecture.",
            "Chopping this up into lots of little bits I introduced different kinds of graphical models focusing on factor graphs and directed graphs.",
            "I talked about marginal and conditional independence, Markov boundaries, an idea of the separation and plate notation.",
            "OK.",
            "So any questions while I pull up."
        ],
        [
            "The next.",
            "Little topic.",
            "No.",
            "OK. Out OK. Alright, so we've introduced graphical models very quickly.",
            "Now let's talk about inference and propagation algorithms.",
            "OK."
        ],
        [
            "So what is this inference problem?",
            "What are we talking about?",
            "Consider the following graph which represents this joint distribution that we had in the previous slides.",
            "That inference is the problem of evaluating the probability distribution for some set of variables given the values of some other set of variables.",
            "So for example, how could we compute the probability distribution over a given that C takes on the value little C?",
            "Alright, and you could imagine if you have a big graph corresponding to a nuclear power plan or a big medical diagnosis system.",
            "You input your sensor readings or your symptoms, and you want to find out the probability that there is a meltdown or that the patient has a particular disease.",
            "OK, that's the inference problem.",
            "Now assume each variable is binary.",
            "How would we compute this?",
            "Well, the naive method is we want to compute the probability of a given C. So we compute the probability of A&C.",
            "By summing over all the other variables.",
            "Um?",
            "And this takes 16 operations because we're summing over 8 different settings of BD&E, and we're looking at two possible settings of a, so 8.",
            "* 216 operations here.",
            "Um?",
            "Then we need to take this and we need to divide it by this.",
            "Well that takes 2 operations 'cause we can.",
            "Then just divide, sorry sum over both settings of a so there's two operations and then we want to compute P of a given C. So we divide the result of this by the result of that for each of two settings of a, so that takes another two operations.",
            "OK, so this is a naive method we.",
            "We computed the probability distribution we were interested in in 20 operations.",
            "Now if we have N variables and they're all binary, then these stages could take two to the N operations because we're summing over all possible settings of all variables and clearly in some cases we should be able to do a lot better if we have independence relation."
        ],
        [
            "Chips.",
            "So here is a slightly more efficient way of doing it.",
            "Let's take the probability of a given C, which was the sum over BD&E of that joint distribution.",
            "But now I'm going to write out that whole joint distribution, and then I'm going to take some of these sums and shift them in.",
            "Well, as far as I can, so the sum of her EI can shift all the way in here.",
            "The sum over DI can bring all the way in here and then the Silver B is here.",
            "Well, the good news is we know that the sum of RE of the probability distribution over E is 1 'cause probability distribution sum to one.",
            "So that's just one.",
            "We don't even need to compute that.",
            "Again, that's just one we don't need to compute that.",
            "So then we end up just with the sum over B of this term here.",
            "And we can compute this in for operations.",
            "So that was the first step.",
            "Instead of 16 operations we did it in four, 4 + 2 + 2 is 8 operations.",
            "Now what did we do there?",
            "Well, what we did was we used knowledge about the factorization of the joint distribution to simplify our computations.",
            "In fact, looking at the graph because E is hanging out here at the bottom, it turns out that we didn't need to sum over E if we wanted to know the probability of a given C. That sort of seems a bit intuitive.",
            "Just by looking at the graph, and we can formalize it here.",
            "So belief propagation methods are methods for using the conditional independent relate independence relationships in a graph to do efficient inference.",
            "And if your graph is singly connected.",
            "Which I'll talk about a little bit later.",
            "Then you can get exponential gains in efficiency, efficiency over the naive method of doing things.",
            "OK.",
            "So let's talk about this in a little more detail."
        ],
        [
            "Um?",
            "First we need to define what a singly connected graph is.",
            "So directed acyclic graph is singly connected if its underlying undirected graph is a tree or another way of thinking about this is if there is only one undirected path between any two nodes.",
            "So this graph here is singly connected because for any pair of nodes there's only one way of going between those.",
            "Pair that pair of nodes, whereas this is multiply connected.",
            "For example, to go from A to D, you can go a CD or you can go Acbd RACED.",
            "OK, so yes.",
            "We're looking at undirected paths, yeah?",
            "And really, it's relevant because information can flow both up and down these edges.",
            "Um?",
            "OK, now remember our goal is to is for some node X we want to compute the probability of X given some evidence E Some data E that we've observed.",
            "OK, so we might want to compute the probability of a given C like we did before.",
            "Now the good news about singly connected graphs is that information gets split up very nicely, so every node X in the graph divides the evidence into upstream and downstream evidence.",
            "So for example, C divides the observed stuff into the stuff that's observed upstream from C. In other words, with arrows pointing 2C and downstream from C. In other words, Paris arrows pointing from C. Now also, every edge divides the evidence into upstream and downstream parts, so the edge between.",
            "C&E divides the graph into this part of the downstream and this part that's upstream OK. And you can think of it.",
            "You know, even if it's downstream of upstream is still upstream.",
            "So imagine if you introduced some.",
            "Contaminant this is a River system and he introduced some contaminant in D. It would arrive at this branch of the River from upstream, so that's what it means to be.",
            "Upstream versus downstream.",
            "OK, so so in singly connected graphs stuff gets divided up into upstream and downstream components."
        ],
        [
            "And now belief propagation makes use of three basic ideas and put them together.",
            "Is nothing magical, is just the application of Bayes Rule 2 graphs that satisfy conditional independence relationships.",
            "But it turns out that you can write it efficiently if you use some of these ideas.",
            "So the first idea is that the probability of a variable X can be found by combining upstream and downstream evidence.",
            "So the probability of X given some observed data E. We can write that as the probability of X&E divided by the probability of E. Which we can write as the probability of X given upstream and downstream evidence divided by the joint probability of the upstream and downstream evidence.",
            "So I'm imagining that I have a big graph that I observed variables all over the place, so I've observed this variable here in that variable here in that variable.",
            "Here, some of our upstream, some of our downstream OK. Now, if we're interested in the distribution of X, then we don't care about things that are constants with respect to the values that X can take, so this denominator here is just a constant.",
            "So up to proportionality, we can ignore this constant and then renormalize afterwards.",
            "So then we take the joint distribution of X, the upstream and the downstream.",
            "Evidence and we divide it up into the distribution of X given upstream.",
            "Stuff coming up from above times the distribution of the downstream stuff given X and the upstream stuff.",
            "And now, because X separates the downstream from the upstream.",
            "The distribution of this stuff is downstream from X.",
            "Given X and the upstream stuff only depends on X, it's independent of the stuff that's upstream is blocked by X. OK, so this gets copied here and this distribution is independent of the upstream evidence, so it becomes the probability of the downstream evidence given X. Yep.",
            "No, he is sorry E can be a set of nodes.",
            "E is the observed values of many different nodes, some of which can be upstream, and some of which can be downstream from X. OK. Um?",
            "Now.",
            "The way you can think about this is that there's if you want to find the probability distribution over X.",
            "There's a source of information from above and a source of information from below.",
            "Anne Anne.",
            "You that Pearl, who wrote a classic texts on this and it developed belief propagation, largely called this the pie and the Lambda messages Peiffer prior an Lambda for likelihood.",
            "So the stuff from above.",
            "You can think of as analogous to a prior in the stuff from below.",
            "You can think of as analogous to a likelihood, and you're multiplying this prior and the likelihood and then re normalizing to compute the probability over X given the evidence.",
            "Um?",
            "So that's the first idea is just the separation between upstream and downstream components.",
            "The second idea is that this upstream and downstream evidence these messages, sorry, can be computed, but these probabilities, these things that you're trying to multiply can be computed via a local message passing algorithm between the nodes in the graph.",
            "So we'll see that later.",
            "And then the third idea is to make sure when you're sending messages not to send back to a node any part of the message is sent to you.",
            "So you basically want to send each node is sending messages to other nodes, but it needs to make sure that the message is sent to other nodes is only collecting information from all sources other than that that node OK. And only if you do that will you get the right probabilities coming out.",
            "But all this stuff is not sort of voodoo.",
            "It just follows.",
            "You know you can prove it all tediously just by applying Bayes rule and the factorization on the graph OK?"
        ],
        [
            "So again, I'm not going to go into the details of this because it would take, you know, actually, I've taught this before.",
            "It takes about an hour and a half or two hours just to understand the details of belief propagation.",
            "I want to give you a flavor and again you can kind of look this stuff up or try to code it up on your own at some point.",
            "So the belief propagation algorithm involves messages that are sent top down.",
            "In other words, from a node to its children.",
            "OK, so the message that UI sends to node X. Um is.",
            "The probability distribution over UI given all of the evidence that's upstream of the edge UI X. OK, then there also messages coming bottom up from downstream, so the message that YJ sends the X is the probability of the evidence that's downstream from the edge X to YJ.",
            "As a function of X, so these messages are.",
            "Are vectors I mean if we think about how we actually implement these messages.",
            "Let's say X is a binary random variable, so it can take two values, zero or one.",
            "Then this message is 2 valued vector with a value corresponding to the setting X = 0 and a value corresponding to the setting X = 1.",
            "And similarly this message would be a.",
            "Two element vector, so your your messages are being sent as little vectors that get multiplied together.",
            "For discrete random variables.",
            "And then the probability that we're interested the probability of X given all of the evidence is.",
            "The product of all of the downstream messages times all of the stuff coming from upstream, renormalized, and.",
            "These are just additional equations for how to compute these downstream."
        ],
        [
            "And upstream messages.",
            "So if you want all the gory details, you know this is all you need to actually implement this algorithm.",
            "If you wanted to.",
            "And of course, I'll make my slides available for the summer school.",
            "So belief propagation is.",
            "Very useful algorithm if you want to do inference in a large graph.",
            "You really need to do something like this.",
            "You can't exhaustively enumerate all settings of all variables.",
            "Now, if you want to actually code this up."
        ],
        [
            "Uh.",
            "It's easier to code it up in the formalism of factor graphs rather than directed graphs, so I'm just going to very quickly show you factor graph propagation as well, which is a similar set of propagation rules.",
            "Set where nodes are sending messages to us."
        ],
        [
            "Nodes.",
            "So.",
            "Just a reminder of what a factor graph is.",
            "A factor graph is just the way of representing a joint probability distribution as a product of.",
            "Functions on subsets of variables.",
            "So this is a normalization constant and this joint distribution is simply the product over functions.",
            "Each of these functions FJ is a non negative function of its arguments and this X sub SJ is just some subset of variables.",
            "Um?",
            "That this function is a function of, so you know, here you would have this dot corresponds to a function of A&CA non negative function can have negatives in there 'cause you're multiplying all these together to get a probability distribution.",
            "And then you need the normalizer so it sums to one when you sum over all the variables.",
            "So this is just a reminder of what a factor graph is.",
            "Um?"
        ],
        [
            "If you have a factor graph, you can talk about the neighbors of a node X.",
            "Let's let N of X be the factor nodes that are neighbors of X&N of FB.",
            "The variable nodes that are neighbors of factor F. So remember each node is connected.",
            "Each variable node is connected to some of these factor nodes and the factor nodes are connected to some variable nodes.",
            "Um?",
            "So factor graph propagation simply sends messages from variables to factors.",
            "And the messages look like this.",
            "A message from a variable to a factor is simply the product of the messages from all the factors that are neighbors of X to X is the product over all of the messages X is getting from the other factors, not including F OK. And then the message from a factor to a variable is.",
            "Uh.",
            "Again, a product of the messages from all of the variables that F is connected to.",
            "Going to F where the product is taken over all of the neighbors of F not including X and then you multiply it by the actual factor and then you sum out all the other variables.",
            "So it's just these two equations."
        ],
        [
            "An you can basically run these two equations which I've written down here and once all the variables one, sorry a variable is received, all messages from its neighboring factors.",
            "We can compute the probability distribution of that variable by multiplying all the messages an renormalizing.",
            "OK, so it's just these two equations is simpler than the belief propagation algorithm that I described previously, and it's really pretty easy to code up.",
            "These things are again functions of variables if this has.",
            "If this takes on K values, then this can be represented as a vector.",
            "Let K. OK. Alright."
        ],
        [
            "So that was a factor graph propagation.",
            "So how would this actually work?",
            "Well, imagine you had a factor graph that look like this.",
            "Let's say let's initialize all the messages to be ones.",
            "That means their vectors of all ones.",
            "Here is an example schedule of messages resulting in the computation of P of X probability of X4.",
            "OK, we want to compute the probability of X4.",
            "How are we going to do this well?",
            "X1 sends a message to F1.",
            "That message is.",
            "Uh, all one's message.",
            "Then X3 sends a message to F2.",
            "We could have done him in a different order if we'd wanted to.",
            "Now F1 sends a message to F2 according to the."
        ],
        [
            "Rules.",
            "We had before the message that that F function sensor variable is given by."
        ],
        [
            "Sorry this equation so F1 sends this message to X2 and that's the message it sends X2.",
            "Um?",
            "F2 sends this message to X2, so that's this message sent to X2.",
            "Then X2 has received the messages from F1 and F2 and it's ready to send out a message to F3.",
            "So X2 sends this message to F3, which is simply the product of the messages they got from F1 and F2.",
            "OK. And so F3 got that message and now F3 is ready to send a message to FX4.",
            "And the message that F3 cents X4 is according to.",
            "Again, this rule is the product of the messages it got in times the function itself summing out all the other variables.",
            "So it's the product of this message and this message that it got in.",
            "Times the function, its own function F3, which is a function of the variables X2 and X4 and then summing out all the other variables that is summing out X2.",
            "And so this is the final message that F3 Sense X4 and you can prove to yourself that if you take this and you normalize it to sum to one over the values of X4, that will be the probability distribution over X4.",
            "Represented by this factor graph.",
            "OK."
        ],
        [
            "Now, what about if we observe some evidence?",
            "Let's say we observe that X1 takes on the value a.",
            "You know, let's say.",
            "X1 is a binary variable, so a is 0 or something like that.",
            "Now how does this change those probabilities well?",
            "You initialize all the messages to be one, but then when you observe that X1 takes on the value a.",
            "Then the message that X1 cents F1 is a Delta function on the value X what equals a.",
            "So if X1 is a binary variable taking on the values zero and one instead of setting the vector of all ones, the message is 1 zero OK. Um?",
            "That's just to to represent the fact that X1 takes on the value 0.",
            "And then everything else follows through.",
            "In exactly the same way, but because this is a Delta function on X1, taking on the value a.",
            "When you send a message from F1 to X2, this product of that message times the factor here is just the function F1.",
            "As a function of X2, but with the value X1 set to a.",
            "And all of this follows through and then this is what you get as the message F3 Center X4 and again once you normalize this as a function of X4, you'll be able to confirm that this is the probability of X4 given X 1 = A. OK.",
            "So any questions about this?",
            "I'm sure this is pretty fast and quite hard to follow all of this, but I want to give you if you haven't encountered this before, I want to give you a sense for the algorithms for sending messages on these graphs and how they can correspond to computing probabilities.",
            "On these graphs.",
            "OK. Any questions?",
            "No.",
            "Everybody's ready for lunch already."
        ],
        [
            "Alright, so.",
            "So I've talked about factor graphs and directed graphs in the abstract, but you actually see them all over the place in the machine learning and pattern recognition literature.",
            "In fact, a lot of models that are very familiar to us like hidden Markov models and linear Gaussian state space models, can be very nicely represented as directed graphs or factor graphs.",
            "So here is the directed graph for.",
            "A hidden Markov model, which is also the same.",
            "Graph.",
            "For a state space model or Kalman filter model.",
            "You have a bunch of hidden state variables and you have a bunch of observations and you're modeling a time series of these observations.",
            "A shaded in these nodes to represent that you've observed these guys, and these guys are hidden.",
            "And the joint distribution of all of the hidden variables and all of the observed variables can be written as the probability of the first hidden variables.",
            "Variable times the probability of the first observed variable given the first hidden variable times the probability of each hidden variable given its previous hidden state variable and the probability of each observed variable given the corresponding hidden variable.",
            "So this graph corresponds to this factorization, which is true for Hmm's and state space models.",
            "The only difference between Hmm's and state space models is that in Hmm's, the states are assumed to be discreet whereas in linear, Gaussian state space models, the states are assumed to be real valued Gaussian vectors.",
            "Um?",
            "And now the interesting thing is that the belief propagation, an factor graph propagation algorithms that I've just briefly described, are actually generalizations of.",
            "The forward backward algorithm, which is an algorithm for doing inference in hidden Markov models and the Kalman smoothing algorithm, which is an algorithm for doing inference in state space models.",
            "Uh.",
            "So amazingly, when I was a grad student, I took a full term term long course on Kalman filtering.",
            "We spent the entire term on Kalman filtering and I was really bored at the end of it, and now I know why I was so bored and that was because you could learn about belief propagation and then common filtering is a special case.",
            "They didn't sort of know it at the time.",
            "Column filtering is a special case, you can describe it in a couple of slides as being a special case, and then you can say, uh, oh, by the way, belief propagation can be applied to hidden Markov models and all these other graphs as well.",
            "OK."
        ],
        [
            "So that's just an aside.",
            "Now, what do you do with multiply connected graphs?",
            "So we talked about singly connected graphs, but.",
            "The real world isn't always singly connected, so we have a few options, so there is an exact algorithm called the junction tree algorithm, which I won't describe, but I have in the appendix here.",
            "I have actually the description of the algorithm.",
            "In subsequent slides, the junction tree algorithm takes your multiple connected graph lumps, a bunch of variables together until it can form a singly connected graph.",
            "On the Super variables, these super variables are variables that you take by grouping together a bunch of variables in your original graph.",
            "And then it runs basically belief propagation on this super graph OK.",
            "Which is called the junction tree.",
            "Now the problem with this algorithm is that it's an exact algorithm.",
            "It will give you exactly the probabilities you want, but if you have a multiple connected graph, you have no guarantee that you're.",
            "Super nodes that you form are going to have a small number of states.",
            "So for example, if you have a bunch of binary variables and you lump.",
            "20 binary variables together.",
            "If you force the lump 20 binary variables together, then that supernode can take on a million different states.",
            "And you'd have to actually enumerate all of those states to run this algorithm.",
            "So the junction tree algorithm is exact, but it can be exponentially slow and it turns out there's no way of doing inference in a general graph.",
            "Where you're guaranteed always to be polynomial time in the number of nodes just because it's not possible, a general graph can involve a full conditional probability, full probability table involving exponentially many states, so it's not possible to do that, so that's what you get for the junction tree algorithm.",
            "Another thing you can do is called cutset conditioning, where essentially you take your multiply connected graph and you take some variables and you say, what?",
            "If I set this variable to this value and then you run belief propagation on the rest of the graph, and then you say, what if I set it to this other value, etc.",
            "So you sometimes called reasoning by assumptions because you assume different possible states for variables you haven't observed.",
            "And then you.",
            "Then you combine together the probabilities that you got from these different settings.",
            "Now you can only do this if you find a set of variables that renders the rest of the graph to be singly connected.",
            "So you need to take your graph, an surgically remove a bunch of nodes until you get the rest of the singly connected.",
            "So this doesn't always work.",
            "Very efficiently either, and this is exact as well.",
            "And the third thing you can do is you can take your multiply connected graph and you can simply run belief propagation on that multiply connected graph.",
            "So you can take factor graph propagation or belief propagation.",
            "Run the algorithm ignoring the fact that the graph is not singly connected.",
            "What happens there is that.",
            "Messages, whereas before messages would get propagated in One Direction or another and the algorithm would stop.",
            "Now messages can start to go around in loops like they go from one child to a parent to another parent.",
            "A child of that and child that and then end up in the same place.",
            "OK, so because you have these loops in the messages probabilities that you get out are not exact anymore, their approximate.",
            "Sometimes the algorithm doesn't converge at all.",
            "But it turns out often this works incredibly well, so this isn't a thing that one would advise people to do to try out on a multiple connected graph.",
            "If this doesn't seem to work, if it doesn't converge, or if it gives ridiculous answers, then there are other things one can try.",
            "OK. Yep.",
            "No, that's a very good question.",
            "What you're doing is you're keeping the same graph, but you're saying.",
            "Even though I didn't observe this variable.",
            "Imagine I did observe it.",
            "Let's imagine I did observe it is the rest of the graph are the other variables not including this one, singly connected.",
            "And so you don't really.",
            "You don't really remove that node, you just act as if you've observed that node.",
            "It's sort of like saying.",
            "Um?",
            "You know the reasoning by assumptions.",
            "Saying is like saying, should I invest in the stock market or should I buy a house?",
            "OK, let's imagine that the Bank of England cuts interest rates.",
            "What's going to happen then?",
            "Compute the probabilities of what's better?",
            "OK, let's imagine the Bank of England doesn't cut interest rates.",
            "Let's compute probabilities.",
            "OK, now how probable do I think the Bank of England is going to be to cut interest rates?",
            "And then I average those?",
            "And that's what I get finally.",
            "So I'm not removing the Bank of England variable.",
            "I'm just assuming that it can take on different values and then and then, hoping that the rest of the variables are singly connected, yeah?",
            "Yes, it turns out you can actually prove that.",
            "Any choice of cutset corresponds to a way of farming a junction tree.",
            "So they are actually going to end up being equivalent, but sometimes it's just more obvious how to do this sometimes this more obvious how to do this.",
            "And they're both going to be intractable in general.",
            "OK. You have other questions."
        ],
        [
            "OK, so that's basically the summary for this.",
            "I talked about inference and now I just want to spend the last few minutes talking about learning.",
            "And rather than take a break.",
            "What I'm suggesting is that I'll just go until 12:30 and then our break can be lunch so lunch will be sooner if we don't take a break now.",
            "Sure, well I'm switching sides, sure.",
            "Yep.",
            "Yes, good question.",
            "The graph is exactly the same for a Kalman filter.",
            "For example, state space model.",
            "The graph is exactly the same.",
            "Filtering is just sending messages in the forward direction.",
            "Smoothing is combining both messages that are being sent in the forward direction and in the backward direction.",
            "So filtering actually corresponds to computing all of those \u03c0 messages.",
            "And this one and just.",
            "The Lambda messages up to time T, whereas smoothing corresponds to computing all of the \u03a0 messages in all of the Lambda messages.",
            "OK.",
            "So.",
            "The last thing I want to talk about."
        ],
        [
            "Is.",
            "Is learning.",
            "Sorry.",
            "No, I don't want to print.",
            "OK.",
            "So we we talked about what graphs are.",
            "We've talked about inference algorithms and now let's talk about Lee."
        ],
        [
            "So what do we mean?",
            "What do we mean by learning?",
            "Imagine we have the following graph, which corresponds to the following factorization.",
            "Now assume that each variable is discrete and can take on Ki values.",
            "So variable XI takes on Ki values.",
            "So the parameters of this model, if all variables are discrete, can be represented as four tables.",
            "So Theta one are going to be the parameters controlling variable X1.",
            "And that just has K1 entries.",
            "Theta two are the parameters controlling X2, given X one and that has K 1 * K Two entries, because for every setting of X one we need to know what is the probability distribution over X2.",
            "So that's a table with K 1 * K, Two entries etc so.",
            "These things are called conditional probability tables.",
            "In the case where we have all discrete random variables, so here's an example of what a conditional probability table might look like.",
            "In this case, X1 is a binary variable, takes on two values, and X2 takes on three values, and the CPT the conditional probability table is just the table where the rows.",
            "Sub to one.",
            "OK, 'cause there are probability distributions over these three settings in this case, so the notation we're going to use is that.",
            "Theta 1K is the probability that variable X1 takes on value K. Um?",
            "In this case, Theta 2K K prime when variant and when that variable has parents, is the probability that variable 2 takes on the value K prime when its parents take on the value K?",
            "So if we have a bunch of parents for node, we take all of the states of those parents and we we combine them together into like a super state and that way we can keep this notation having only three indices rather than as many indices as the parents plus two or whatever, which would be a real pain.",
            "So these are just all tables that we're trying to learn.",
            "So assume we have a data set of observations of these variables.",
            "So we have N data points.",
            "These are cases where we've observed you know X1 takes on a particular value, asks 2, takes on some other value, etc, and we want to learn Theta from this data set."
        ],
        [
            "So how do we learn the parameters of this model?",
            "We assume we have this data set.",
            "We want to learn the parameters from this data set.",
            "Now our model says that the joint distribution of all the variables factors in this way, where I've explicitly written in the parameters and where where they live.",
            "So each parameter controls each of the variables.",
            "If we have N data points, the likelihood function, which is a function of the parameters, is the product over those end data points of the probability of each data point given the parameters.",
            "That's assuming that our data points were observed independently.",
            "From that model.",
            "And so if we take the log of the likelihood, if we combine this equation, which is a product over data points and this equation, which is a product over nodes.",
            "Then we take the log, then the log likelihood is a sum over data points coming from this product.",
            "When we take the log and a sum over variables or nodes in the graph, that's the sum over I of the log probability of each variable.",
            "XI in the NTH case.",
            "Given the settings of the parents of that variable and Theta I.",
            "Now the good news about this is that this log likelihood decomposes into a sum of functions of the parameters for each node, so each node.",
            "Um?",
            "Has his parents and there are these parameters Theta I controlling the probability of that node and we could learn essentially each of these Theta eyes in dependently?",
            "If we optimize the log likelihood then we get this incredibly intuitive equation.",
            "Once I explain it to you, it will be incredibly intuitive, which basically says that the maximum likelihood setting of the parameters.",
            "Corresponds to taking counts of how many times.",
            "Variable XI isn't state K prime.",
            "Given that his parents were in State K and making sure those counts normalized to one.",
            "So it's incredibly intuitive.",
            "Once I show you this picture.",
            "OK so imagine we have an observed data set.",
            "When we simply count how many times was X one in each of these two States and X2 in each of these three states, we fill up a table like this.",
            "With those counts.",
            "And then we take each of these rows and we normalize them to sum to one.",
            "OK, and then we get the maximum likelihood parameter settings for the data that we've observed.",
            "OK. That makes a lot of sense.",
            "You know, I, I've observed this happening twice and this happening three times.",
            "So given that X1 takes on the value zero as opposed to one in this row, then I believe that X2 is going to take on the value zero with probability .41 with probability .6 and two with probability 0.",
            "OK. That's simply the maximum likelihood estimates.",
            "And you can do.",
            "You can compute this by taking the derivative of the log likelihood and maximizing it subject to the constraint that these conditional probability table rows have to sub to one.",
            "OK, so that's the easy case that's learning parameters when you observe all of the variables."
        ],
        [
            "In your model.",
            "If you observe only some of the variables in your model, then you can still do maximum likelihood learning.",
            "So let's say you observe Y, but you haven't observed, the X is.",
            "You can still do maximum likelihood learning, But the problem is that the likelihood involves summing over all the possible settings of X.",
            "So your goal is to maximize the log likelihood given the observed data.",
            "That's this thing, but that involves the log of the sum over all the values of the variables.",
            "We didn't observe the hidden variables.",
            "Of this joint distribution.",
            "OK, and.",
            "The way you can maximize this likelihood is to use the well known EM algorithm, which is a nice general procedure for maximizing likelihoods when you have missing data.",
            "In this case."
        ],
        [
            "The X is.",
            "Have you been?",
            "Have you seen the EM algorithm this week yet?",
            "Yes.",
            "Great, that's very good for me.",
            "So the intuition is you fill in the missing data that hidden variables with the probability distribution over there possible hidden States and in the M steps you apply learning.",
            "Complete data learning this same kind of learning we applied before but with filled in.",
            "This filled in data, but the important thing is you're not filling it in with single values, you're filling it in with a probability distribution over the values.",
            "It can take each."
        ],
        [
            "These hidden variables, so I won't go into the details.",
            "The important point is at the bottom here.",
            "The eastep of the EM algorithm involves inference over the hidden variables.",
            "And if we have a graph, then we know how to do inference over the hidden variables.",
            "We simply need to apply the belief propagation algorithm.",
            "If it's singly connected or the junction tree or cutset conditioning algorithms if it's multiply connected.",
            "So in the eastep of the EM algorithm, we run one of these inference procedures and then in the M step we re estimate the parameters.",
            "And we iterate."
        ],
        [
            "This.",
            "So just to contrast, compare and contrast the EM algorithm with hidden variables to the complete data case.",
            "This is what we first talked about.",
            "The maximum likelihood parameters are simply normalized counts.",
            "If you have no hidden variables, if you have hidden variables, you iterate.",
            "E&M steps and in the M step the maximum.",
            "The current maximum likelihood estimate in the M step is exactly in the same form as it was when you have complete data, except that instead of actual counts, we use expected values of those counts where those expectations are taken with respect to.",
            "The distribution over the hidden variables.",
            "OK, so the difference here is.",
            "Expected counts versus actual."
        ],
        [
            "OK.",
            "So, um."
        ],
        [
            "So that was maximum likelihood learning with no hidden variables and with hidden variables.",
            "We can also do Bayesian learning.",
            "Of the."
        ],
        [
            "Parameters.",
            "Um?",
            "So again, this is just the way of writing out the probability of the data given the parameters as the product over each data point.",
            "The product over each variable XI of these conditional probability tables and if the variables XI are discreet than these conditional probabilities can be written in the form of Theta IJK to the power of NIJK.",
            "So every time you observe one of the IJK settings variable, I taking on setting K when his parents are in setting J you get one of these contributions data so.",
            "This is the likelihood function for.",
            "Graphical model directed graphical model with discrete variables.",
            "Now we want to do Bayesian learning for Theta.",
            "This is our likelihood function.",
            "Let's imagine we choose a prior on Theta.",
            "Are of the same form as this likelihood function, so the prior is going to look very similar to the likelihood function.",
            "There is a normalizing constant at the beginning here.",
            "Just because this prior has to integrate to one.",
            "When we integrate over Theta.",
            "And then these parameters of the prior, we're just going to call them Alpha I JKS.",
            "They're very analogous to NIJK and.",
            "There's a -- 1 here because.",
            "If all the alphas are set to ones, then this becomes the uniform distribution, and that's a particularly nice distribution here.",
            "Now, this form of distribution is called the Dirichlet distribution.",
            "This is a Dirichlet distribution.",
            "And it has a nice property that if you take this Dirichlet distribution and you multiply it by this discrete.",
            "Likelihood.",
            "Then you get another Dearsley distribution back, so this is called the conjugate prior.",
            "Did you hear bout conjugate priors?",
            "Yeah, and so if you choose this conjugate Dirichlet distribution then life is easy.",
            "So the posterior distribution is in the same form as the prior but with these alphas, now incremented by the counts."
        ],
        [
            "We've observed.",
            "So here is just a little reminder about what a deer sleigh distribution is."
        ],
        [
            "Which I'll skip.",
            "Here's some pictures of their state distributions when you're looking at three.",
            "3 dimensional vector that sums to one, so we only need to plot it.",
            "We can put it in 2D 'cause the third dimension is 1 minus Theta, 1 minus Theta two.",
            "So this is the Dirichlet 111 which is a uniform.",
            "Here's the richly 1010 ten, which is centered around 1/3 third third.",
            "Etc."
        ],
        [
            "Anne.",
            "For example, if we use the Dearsley 111.",
            "This uniform distribution, as our prior then we can do Bayesian learning and our posterior distribution over the parameters, is again a deer sleigh where the parameters are of that deer sleigh are the counts plus one sort of like just adding one to all the counts an if you wanted to do prediction.",
            "If you wanted to predict what is the probability that XI takes on value K given its parents taking on value J Anna data that you observed.",
            "Then it's an IJK plus one normalized.",
            "So it gets rid of that annoying zero doing zeros in the probabilities.",
            "When we were doing maximum likelihood inference, which was quite silly."
        ],
        [
            "Really.",
            "OK, so.",
            "So we're going in increasing complexity.",
            "You could also do Bayesian parameter learning when you have hidden variables.",
            "So that was the Bayesian parameter learning when you have."
        ],
        [
            "Fully observed data before."
        ],
        [
            "Sorry, now I'm going forward Bayesian parameter learning.",
            "When you have hidden variables an you can use MCMC methods or variational Bayesian method."
        ],
        [
            "Ed.",
            "Which I won't talk about.",
            "Just to recap, the summary of parameter learning maximum likelihood learning when you have complete data is very easy.",
            "You just calculate the frequencies and you renormalize.",
            "Bayesian learning when you have complete data is also very easy if you use Dirichlet priors, you just update dearsley distributions is about as computationally hard as doing the maximum likelihood.",
            "Learning things get hard when you have missing data or incomplete data.",
            "So in the maximum likelihood case you do EM in the base.",
            "In case you might do MCMC, or Viterbi, or this variational Bayesian TM.",
            "And.",
            "The last thing I'll just mention, 'cause we're a little overtime.",
            "Is."
        ],
        [
            "Uh.",
            "Is structured learning so I really, I mean I. I've gone I. I think you would probably agree I've gotten at about is faster pace.",
            "Assuming people don't have a lot of familiarity with graphical models, but I don't want to leave out.",
            "What structure learning is OK so?",
            "I've talked about graphical models and parameter learning so far under the assumption that you knew what the structure of the graph was.",
            "That is, you knew.",
            "Which.",
            "Nodes were parents and children, of which other nodes.",
            "But imagine all we observe is just some data and we want to actually learn the structure of the graph from the data.",
            "So if we have.",
            "Five variables, then, could we automatically learn?",
            "What structure to choose?",
            "From the data, so we're going to use M to denote the graph structure.",
            "That is, the set of edges going all the way from empty graphs through some more reasonable graphs all the way to complete graphs where.",
            "It corresponds to a full probability distribution with no factorizations.",
            "No conditional independence relationship, sorry.",
            "So that's what I wanted to just briefly."
        ],
        [
            "Mention.",
            "Are there different kinds of structure learning algorithms?",
            "There are two broad classes of structure learning algorithms, Constraint Basin, score base in constraint based learning.",
            "We use statistical tests of marginal and conditional independence.",
            "We group together we find a whole bunch of results of these tests and then we try to find a directed graph whose D separation relations match the results of these conditional independence tests as well as possible.",
            "In score based learning we use, we use a global score on the graph.",
            "Like the Bayesian marginal likelihood, which I think you've probably just heard about a little bit.",
            "And we try to find the structure that maximizes this score."
        ],
        [
            "Um?"
        ],
        [
            "The.",
            "Good news when you have complete data again, it seems that life is really easy when you have complete data and life gets hard when you have hidden variables or missing data.",
            "The good news is that if you assume the richley priors on your parameters and you have discrete data and you have complete data, then you could actually compute the score.",
            "Which is this?",
            "Marginal likelihood the probability of the data given the model structure.",
            "Integrating over all the parameters.",
            "So the log of the score, which is something you can optimize.",
            "Is.",
            "Is analytically tractable.",
            "You can just compute it based on counts from the data.",
            "So it's just a function an you just change different graph structures and find better and better graphs by optimizing this score.",
            "And you can do greedy search algorithms or MC."
        ],
        [
            "See and again, this story gets hard when you have hidden variables.",
            "You need to do some combination of Bayesian learning with EM for incomplete data like this."
        ],
        [
            "Bayesian structurally of algorithm."
        ],
        [
            "OK."
        ],
        [
            "Learning graphs, learning undirected graphs or factor graphs is harder because of the globalization constant, and we've done some work in that, but I won't really talk about."
        ],
        [
            "OK, so I'll summarize and conclude, so we've talked about parameter learning and directed graphs, and we talked about structure learning.",
            "And I really didn't talk about causality, but I just mentioned that parameter and structure learning is just much harder in undirected graphs.",
            "It's also harder when you have incomplete data.",
            "And it's harder when things are not discrete.",
            "So if you have general continuous random variables with non Gaussian distributions then things get hard.",
            "Just these sums and integrals get hard.",
            "OK.",
            "So that's it great."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Next session will be.",
                    "label": 0
                },
                {
                    "sent": "By Zubin ghahramani.",
                    "label": 0
                },
                {
                    "sent": "2 minutes again.",
                    "label": 0
                },
                {
                    "sent": "One of the leading lights in machine learning.",
                    "label": 0
                },
                {
                    "sent": "He did his pH D with Mike Jordan when he was at MIT and then post talked with Jeff Hinton.",
                    "label": 0
                },
                {
                    "sent": "He then first came to the UK when the Gatsby Computational Neuroscience Institute was set up and it's sort of a mark of his qualities that he was selected as one of the founding members of the Gaspee Unit.",
                    "label": 0
                },
                {
                    "sent": "His research.",
                    "label": 0
                },
                {
                    "sent": "Certainly up to that time he was the first person I believe to present a paper with expectation maximization algorithms at the next conference.",
                    "label": 0
                },
                {
                    "sent": "He did an enormous amount of work with Mike Jordan and others to popularize the use of variational approximations in probabilistic models.",
                    "label": 0
                },
                {
                    "sent": "And then since then, he's done an immense amount of work on lots of different types of Bayesian models.",
                    "label": 0
                },
                {
                    "sent": "Always elegant, always interesting, and this was recognized for couple of years ago.",
                    "label": 0
                },
                {
                    "sent": "I guess by his move from Gatsby to Cambridge Engineering, where he was appointed about as a chair.",
                    "label": 0
                },
                {
                    "sent": "The most annoying thing about zoom in.",
                    "label": 0
                },
                {
                    "sent": "I've got the 18 months.",
                    "label": 0
                },
                {
                    "sent": "I already achieved probably far more in his career so far than I expect 20 in my entire career.",
                    "label": 0
                },
                {
                    "sent": "We are extremely lucky to have him here, giving us an introduction to graphical models, an area in which he's been key in pushing forward in machine learning.",
                    "label": 1
                },
                {
                    "sent": "Thanks Neil, I always know I'm going to cringe with your introduction.",
                    "label": 0
                },
                {
                    "sent": "But that's very, very kind of you, thanks.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to talk about graphical models and we have we would have had an hour and a half had it not been for a bit of traffic in a bit of getting lost, so we'll go fairly quickly through this, but I'll be around over lunch and you know, please ask questions throughout the day.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I divided up into a few short lectures.",
                    "label": 0
                },
                {
                    "sent": "In the first one I'm going to just introduce what graphical models are.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to talk about inference in graphical models that I'm going to talk about learning in graphical models.",
                    "label": 0
                },
                {
                    "sent": "So how many people have encountered graphical models before?",
                    "label": 0
                },
                {
                    "sent": "OK. How many have not encountered graphical models?",
                    "label": 0
                },
                {
                    "sent": "OK, good.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so um graphical models are one of the most exciting things that have happened in machine learning in the last couple of decades.",
                    "label": 0
                },
                {
                    "sent": "There essentially a way of representing probability distributions using graphs and their different kinds of graphical models are three main kinds, factor graphs, undirected graphs and directed graphs, and in all of these kinds of graphical models, the nodes correspond to random variables ABCD.",
                    "label": 1
                },
                {
                    "sent": "For example, here, the edges represent statistical dependencies between those variables.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to focus on factor graphs a little bit, and then undirected graphs a lot, and I'm not really going to talk about on direct.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Graphs very much.",
                    "label": 0
                },
                {
                    "sent": "They're very similar to factor graphs.",
                    "label": 0
                },
                {
                    "sent": "So why do we need these?",
                    "label": 1
                },
                {
                    "sent": "We have probabilities.",
                    "label": 1
                },
                {
                    "sent": "We can write down equations.",
                    "label": 1
                },
                {
                    "sent": "Why would we need graphical models?",
                    "label": 0
                },
                {
                    "sent": "Well, first of all, graphs are very intuitive to look at, and you know we have examples of graphs throughout many different fields of science and engineering.",
                    "label": 0
                },
                {
                    "sent": "We like to draw graphs to represent relationships between things.",
                    "label": 0
                },
                {
                    "sent": "So why not use those same intuitive diagrams for probabilistic models?",
                    "label": 0
                },
                {
                    "sent": "The second reason graphical models are useful is that they allow us to represent conditional independence relationships between variables abstractly, without talking about the nitty gritty of the particular parametric forms of the probability distributions.",
                    "label": 0
                },
                {
                    "sent": "So you can say A is independent from B without having to say whether A was a Gaussian distribution with mean one and variance 7 or.",
                    "label": 0
                },
                {
                    "sent": "A binary variable with a Bernoulli distribution or anything like that, so they represent conditional independence.",
                    "label": 0
                },
                {
                    "sent": "So just by looking at the graph, we can answer questions is a dependent on B given that we know the value of C. And finally, there's a computational reason why graphical models are very exciting.",
                    "label": 1
                },
                {
                    "sent": "They allow us to define general message passing algorithms to implement probabilistic inference efficiently.",
                    "label": 0
                },
                {
                    "sent": "So if we want to answer a question like what is the probability distribution over a given that we know variable C takes on some value little C?",
                    "label": 0
                },
                {
                    "sent": "We can do this by sending messages on the graph, so when we implement things on a computer, we can do kind of object oriented implementation where each node sends messages to its neighbors an after a bunch of messages get passed, we can compute all the right probabilities that we're interested in.",
                    "label": 0
                },
                {
                    "sent": "So graphical models really combine ideas from statistics from graph theory and computer science.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "Even if you, even if you don't use these message passing algorithms, you'll find the graphical models all over papers in machine learning and pattern recognition these days.",
                    "label": 0
                },
                {
                    "sent": "So it's important to note.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Exactly they mean OK.",
                    "label": 0
                },
                {
                    "sent": "So fundamentally graphical models represent conditional independence, and we're going to use the following notation to denote conditional independence.",
                    "label": 1
                },
                {
                    "sent": "This says X is.",
                    "label": 0
                },
                {
                    "sent": "Independent of Y given V. And what that means is that the probability distribution over X given Y&V.",
                    "label": 0
                },
                {
                    "sent": "Is equal to the probability distribution over X given V. That's you know.",
                    "label": 0
                },
                {
                    "sent": "In other words, why doesn't really affect the distribution on X?",
                    "label": 0
                },
                {
                    "sent": "Once we know the value of V. And this is just the technical condition, so that these things are well defined.",
                    "label": 0
                },
                {
                    "sent": "These probabilities are well defined.",
                    "label": 0
                },
                {
                    "sent": "Another way of thinking about this is X is independent of Y given V. If the joint distribution of X&Y given V factors into the distribution of X given V and the distribution of Y given V. And we can think of conditional independence between sets of variables in a completely analogous way.",
                    "label": 1
                },
                {
                    "sent": "Bunch of variables X and a bunch of variables.",
                    "label": 0
                },
                {
                    "sent": "Why are you going to be conditionally independent given V if the joint distribution factors in this way and the more traditional notion of independence, which is marginal independence, we can write like this that just says X is independent of Y, or in other words, X is independent of Y.",
                    "label": 0
                },
                {
                    "sent": "Given the empty set of variables.",
                    "label": 0
                },
                {
                    "sent": "If you want to write it in this conditional independence form that just says the joint distribution of X&Y factors into the distribution of X times of distribution of Y.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so you know we can think of a bunch of examples in the real world where you might have conditional or marginal independence.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "The amount of speeding fines that you get.",
                    "label": 0
                },
                {
                    "sent": "Should be independent of the type of car you're driving.",
                    "label": 0
                },
                {
                    "sent": "Given the speed that you're caught driving.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, it wouldn't seem very fair.",
                    "label": 0
                },
                {
                    "sent": "Uh, you know whether you have lung cancer.",
                    "label": 0
                },
                {
                    "sent": "It is independent of whether you have teeth.",
                    "label": 0
                },
                {
                    "sent": "Yellow teeth, sorry.",
                    "label": 0
                },
                {
                    "sent": "Given that you're smoking all those, smoking can cause both lung cancer and your key to turn yellow.",
                    "label": 0
                },
                {
                    "sent": "Etc so you know we can.",
                    "label": 0
                },
                {
                    "sent": "We can imagine lots of different examples of marginal and conditional independence.",
                    "label": 0
                },
                {
                    "sent": "And I won't go through all of them, but it's a little subtle to think about these things, because sometimes things can be marginally independent, like for example, if you have two teams playing each other with players chosen at random from a lot of large pool of players, then the ability of team A and the ability of Team B might be marginally independent.",
                    "label": 0
                },
                {
                    "sent": "Variables, but given that you know the outcome of a game versus of a versus B, then these are no longer marginally independent.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we know that a beat B, then you would infer that the ability of team A is as likely to be greater than the ability of Team B, right?",
                    "label": 1
                },
                {
                    "sent": "So they no longer remain independent.",
                    "label": 0
                },
                {
                    "sent": "OK, so graphical models are way of representing conditional and marginal.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Independence and I'm going to start just by talking about factor graphs.",
                    "label": 0
                },
                {
                    "sent": "In factor graphs you have the nodes.",
                    "label": 1
                },
                {
                    "sent": "You have two types of nodes.",
                    "label": 1
                },
                {
                    "sent": "The circles represent random variables and these little filled dots represent factors in the joint distribution.",
                    "label": 1
                },
                {
                    "sent": "So for example, this factor graph here represents the fact that the probability distribution over a through E factors into the product of a function of A&C, that's this.",
                    "label": 0
                },
                {
                    "sent": "Are represented by this dot.",
                    "label": 0
                },
                {
                    "sent": "Here a function of BC&D represented by this and a function of CD&E, and this one over zed is simply a normalization constant.",
                    "label": 0
                },
                {
                    "sent": "This factor graph here on this side represents this factorization of the joint distribution.",
                    "label": 0
                },
                {
                    "sent": "And the normalization constant is simply the sum over all the possible settings of all of the variables of the product of the factors.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's just what you need so that the probabilities sum to one.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What these graphs represent is that is a family of probability distributions, so this graph here represents all probability distributions over.",
                    "label": 0
                },
                {
                    "sent": "Five variables that can be written in this form.",
                    "label": 0
                },
                {
                    "sent": "OK. And it in the graph we can talk about things like neighborhood relationships between nodes, and these are going to be important to figure out what the independence relationships are between the random variables.",
                    "label": 1
                },
                {
                    "sent": "So two nodes are neighbors in a factor graph.",
                    "label": 0
                },
                {
                    "sent": "They share a common factor, so A&C are neighbors.",
                    "label": 0
                },
                {
                    "sent": "But A&B are not neighbor.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is just a recap of what I said on the previous slide.",
                    "label": 0
                },
                {
                    "sent": "And now we can talk about how these graphs relate to the notion of conditional independence.",
                    "label": 0
                },
                {
                    "sent": "So let's define a path to be a sequence of neighboring nodes.",
                    "label": 1
                },
                {
                    "sent": "So for example, ACD is a path.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "And if we have a probability distribution that factors according to a factor graph, then it's not very hard to prove that X is independent of Y given a set of variables V. If every path between X&Y contains some node in the set V. Um?",
                    "label": 1
                },
                {
                    "sent": "So for example, A is independent of D given C in this graph, because every path from A to D goes through C. And it's it's sort of intuitive, it's.",
                    "label": 0
                },
                {
                    "sent": "The idea that if you know the value of C, then that blocks.",
                    "label": 0
                },
                {
                    "sent": "The information flowing from A to D. It blocks the sort of relationship between A&B.",
                    "label": 0
                },
                {
                    "sent": "So the corollary of this is that given the neighbors of a variable X, that variable X is conditionally independent of all other variables.",
                    "label": 1
                },
                {
                    "sent": "So X is independent of Y given the neighbors of X where Y is any element of the set of.",
                    "label": 0
                },
                {
                    "sent": "That doesn't.",
                    "label": 0
                },
                {
                    "sent": "In you know the set of variables, not including X an.",
                    "label": 0
                },
                {
                    "sent": "The neighbors of X OK. Alright, so that's the basic idea of a factor graph, an essentially the set of neighbors of a node Shields that variable from all the other variables in the sort of universe that you're trying to model.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me just say one other thing about this.",
                    "label": 0
                },
                {
                    "sent": "Why would this be useful?",
                    "label": 0
                },
                {
                    "sent": "Well, let's imagine we're trying to model a nuclear power plant, and we have hundreds of sensors and variables.",
                    "label": 0
                },
                {
                    "sent": "We might be interested in in the nuclear power plant, one of which might be whether there is a meltdown going on of the core.",
                    "label": 0
                },
                {
                    "sent": "OK, but we have all these sensors and we build a probabilistic model that tells us.",
                    "label": 0
                },
                {
                    "sent": "How these variables are related to each other?",
                    "label": 0
                },
                {
                    "sent": "We write it down as a factor graph and then we can take this graph and say given the following readings of variables that I can observe, what is the probability that the following event is happening that I can't directly observe?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "These notions of conditional independence come in very handy for figuring out which variables are relevant, which ones are irrelevant, and eventually for figuring out how to pass messages.",
                    "label": 0
                },
                {
                    "sent": "OK, that's factor.",
                    "label": 0
                },
                {
                    "sent": "Graphs will come back to factor graphs in a few minutes.",
                    "label": 0
                },
                {
                    "sent": "Let me talk about the.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Directed acyclic graphs, which are the most commonly used graphical model.",
                    "label": 1
                },
                {
                    "sent": "These are sometimes called Bayesian networks, although there's a footnote here that says you don't have to learn them in a Bayesian manner, it doesn't necessarily mean that you're being completely Bayesian about inference in these, it's just the name that they've been given.",
                    "label": 0
                },
                {
                    "sent": "But let's call them directed acyclic graphs for now, so.",
                    "label": 0
                },
                {
                    "sent": "One of these directed acyclic graphs is essentially a graph where again you have nodes representing random variables, and now we have directed edges representing dependencies between those variables.",
                    "label": 0
                },
                {
                    "sent": "An this DAG or Bayesian network corresponds to factorization of the joint probability distribution, so this particular graph corresponds to the idea that the joint distribution over a through E factors into the product of the distribution.",
                    "label": 1
                },
                {
                    "sent": "Of a type of distribution of B.",
                    "label": 0
                },
                {
                    "sent": "Times the distribution of C given A&B etc.",
                    "label": 0
                },
                {
                    "sent": "And the pattern that I'm sure you've noticed is the factorization corresponds to each variable given its parents in the graph.",
                    "label": 0
                },
                {
                    "sent": "So see, given its parents A&B or parents are just nodes that point to that variable.",
                    "label": 0
                },
                {
                    "sent": "OK, A is apparent of CC is the child of a.",
                    "label": 0
                },
                {
                    "sent": "So in general.",
                    "label": 0
                },
                {
                    "sent": "A directed graph corresponds to the idea that the joint distribution over a bunch of variables factors into the product of each variable given its parents.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the semantics of a directed graph are similar to the factor graph.",
                    "label": 0
                },
                {
                    "sent": "Again, just by looking at the graph, we can say which variables are conditionally independent of which other variables, given some other set of variables.",
                    "label": 0
                },
                {
                    "sent": "So in the factor graph it was really, really easy.",
                    "label": 0
                },
                {
                    "sent": "We just needed to look at just paths connecting X&Y to see if they went through V. Here it's a bit more complicated.",
                    "label": 0
                },
                {
                    "sent": "For a directed Graph, X is conditionally independent of Y given the set of variables V if the set of variables VD separates X from Y, it's just the notion of separation on the graph is called D separation.",
                    "label": 0
                },
                {
                    "sent": "Because stands for dependency separation.",
                    "label": 0
                },
                {
                    "sent": "So it makes X&Y independent.",
                    "label": 0
                },
                {
                    "sent": "An to check for D separation.",
                    "label": 0
                },
                {
                    "sent": "Is a little tricky.",
                    "label": 0
                },
                {
                    "sent": "The definition is that VD separates X from Y if every undirected path between X&Y, that is past where we've ignored the directionality of the arrows.",
                    "label": 0
                },
                {
                    "sent": "So we can go up or down arrows.",
                    "label": 0
                },
                {
                    "sent": "If every undirected path between X&Y is blocked by V, so again, that feels a bit intuitive.",
                    "label": 1
                },
                {
                    "sent": "V is blocking information flowing from X to Y and vice versa and therefore making X&Y independent of each other.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Now to check whether a path is blocked, you have to see if there is a node W on the path such that it satisfies either of these conditions and if it satisfies either of these conditions, then that path is blocked.",
                    "label": 1
                },
                {
                    "sent": "Then you have to check all paths and then you know.",
                    "label": 0
                },
                {
                    "sent": "Weather something V the separate sex from Y. OK.",
                    "label": 0
                },
                {
                    "sent": "So the two conditions are a little technical.",
                    "label": 0
                },
                {
                    "sent": "It takes a bit of time to figure out why these make sense.",
                    "label": 1
                },
                {
                    "sent": "This condition is that W has converging arrows along the path.",
                    "label": 0
                },
                {
                    "sent": "In other words, you go into W and then you flow out in this way and not either.",
                    "label": 0
                },
                {
                    "sent": "W North descendants are observed.",
                    "label": 1
                },
                {
                    "sent": "In other words, are members of the set V. The second condition is that W does not have converging arrows along the path.",
                    "label": 0
                },
                {
                    "sent": "So you go either this way or that way and W is observed.",
                    "label": 0
                },
                {
                    "sent": "OK, so if either of these two conditions are satisfied, then VD separates X from Y.",
                    "label": 0
                },
                {
                    "sent": "And if you haven't seen this before, I don't expect you to look at this and say, ha ha, that immediately makes sense.",
                    "label": 0
                },
                {
                    "sent": "Takes a little bit of time to think about it.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go into details because I want to be able to get into the propagation algorithms and the learning, but there is a lot of good material that tries to explain this.",
                    "label": 0
                },
                {
                    "sent": "Including longer tutorials of this kind that might be on line.",
                    "label": 0
                },
                {
                    "sent": "So the corollary for Bayesian networks or directed graphs is that.",
                    "label": 0
                },
                {
                    "sent": "The Markov boundary for X, that is, the set of variables that make X independent of all other variables, is the parents of X.",
                    "label": 0
                },
                {
                    "sent": "The children of X and the parents of the children of X.",
                    "label": 0
                },
                {
                    "sent": "So given those variables, X is independent of everything else that's similar to what we had in factor graphs here.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So let's let's just look at some examples.",
                    "label": 0
                },
                {
                    "sent": "If we have this graph, A is independent of B. Um?",
                    "label": 0
                },
                {
                    "sent": "Marginally independent since a CB is blocked by C. An AC DB is blocked by D etc, so all the paths between A&B are blocked because nothing is observed.",
                    "label": 1
                },
                {
                    "sent": "None of these variables have have been observed.",
                    "label": 0
                },
                {
                    "sent": "It's not true that A is independent of B given C, since a CB is not blocked.",
                    "label": 0
                },
                {
                    "sent": "So given CA&B are dependent on each other.",
                    "label": 0
                },
                {
                    "sent": "And this is a very important concept given.",
                    "label": 0
                },
                {
                    "sent": "Given a particular symptom.",
                    "label": 0
                },
                {
                    "sent": "The probability of having this disease or that disease that could have caused that symptom.",
                    "label": 0
                },
                {
                    "sent": "These probabilities are going to be correlated OK, the joint probability is is not going to be independent, even if getting this disease and getting that disease could happen with independent probabilities.",
                    "label": 0
                },
                {
                    "sent": "Ann, and Furthermore we can look at a few other things, like A is independent of D given B&CA&B are independent.",
                    "label": 0
                },
                {
                    "sent": "Given B&C on this graph because all paths are blocked.",
                    "label": 0
                },
                {
                    "sent": "It's.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cetera.",
                    "label": 0
                },
                {
                    "sent": "OK so here is some.",
                    "label": 0
                },
                {
                    "sent": "Useful notation that again you'll see in a lot of papers.",
                    "label": 0
                },
                {
                    "sent": "You'll see this these boxes around some nodes with a little letter in the corner.",
                    "label": 0
                },
                {
                    "sent": "This is called plate notation, an it represents repetitions of some variable.",
                    "label": 0
                },
                {
                    "sent": "So consider N data points generated from a Gaussian.",
                    "label": 1
                },
                {
                    "sent": "We have X one through X.",
                    "label": 0
                },
                {
                    "sent": "Let's say that the Gaussian has mean mu, an standard deviation Sigma.",
                    "label": 0
                },
                {
                    "sent": "We could write down a little probabilistic model where we have.",
                    "label": 0
                },
                {
                    "sent": "P of mu being the prior on mu P of Sigma being the prior on Sigma and then the likelihood function corresponding to each of the data points.",
                    "label": 0
                },
                {
                    "sent": "This is what the graph would look like for this factorization, right each node, given his parents is represented like this, But these are these guys are replicated N times.",
                    "label": 0
                },
                {
                    "sent": "So to make the graph a little prettier and easier to look at, we can put a box around one of these nodes.",
                    "label": 0
                },
                {
                    "sent": "And put an index.",
                    "label": 0
                },
                {
                    "sent": "He ran that just means XN goes from N = 1, two big N. OK.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's plate notation.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's the summary of the first mini lecture.",
                    "label": 0
                },
                {
                    "sent": "Chopping this up into lots of little bits I introduced different kinds of graphical models focusing on factor graphs and directed graphs.",
                    "label": 0
                },
                {
                    "sent": "I talked about marginal and conditional independence, Markov boundaries, an idea of the separation and plate notation.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So any questions while I pull up.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next.",
                    "label": 0
                },
                {
                    "sent": "Little topic.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "OK. Out OK. Alright, so we've introduced graphical models very quickly.",
                    "label": 0
                },
                {
                    "sent": "Now let's talk about inference and propagation algorithms.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is this inference problem?",
                    "label": 0
                },
                {
                    "sent": "What are we talking about?",
                    "label": 0
                },
                {
                    "sent": "Consider the following graph which represents this joint distribution that we had in the previous slides.",
                    "label": 0
                },
                {
                    "sent": "That inference is the problem of evaluating the probability distribution for some set of variables given the values of some other set of variables.",
                    "label": 0
                },
                {
                    "sent": "So for example, how could we compute the probability distribution over a given that C takes on the value little C?",
                    "label": 0
                },
                {
                    "sent": "Alright, and you could imagine if you have a big graph corresponding to a nuclear power plan or a big medical diagnosis system.",
                    "label": 0
                },
                {
                    "sent": "You input your sensor readings or your symptoms, and you want to find out the probability that there is a meltdown or that the patient has a particular disease.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the inference problem.",
                    "label": 0
                },
                {
                    "sent": "Now assume each variable is binary.",
                    "label": 0
                },
                {
                    "sent": "How would we compute this?",
                    "label": 0
                },
                {
                    "sent": "Well, the naive method is we want to compute the probability of a given C. So we compute the probability of A&C.",
                    "label": 0
                },
                {
                    "sent": "By summing over all the other variables.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And this takes 16 operations because we're summing over 8 different settings of BD&E, and we're looking at two possible settings of a, so 8.",
                    "label": 0
                },
                {
                    "sent": "* 216 operations here.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Then we need to take this and we need to divide it by this.",
                    "label": 0
                },
                {
                    "sent": "Well that takes 2 operations 'cause we can.",
                    "label": 0
                },
                {
                    "sent": "Then just divide, sorry sum over both settings of a so there's two operations and then we want to compute P of a given C. So we divide the result of this by the result of that for each of two settings of a, so that takes another two operations.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a naive method we.",
                    "label": 0
                },
                {
                    "sent": "We computed the probability distribution we were interested in in 20 operations.",
                    "label": 0
                },
                {
                    "sent": "Now if we have N variables and they're all binary, then these stages could take two to the N operations because we're summing over all possible settings of all variables and clearly in some cases we should be able to do a lot better if we have independence relation.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Chips.",
                    "label": 0
                },
                {
                    "sent": "So here is a slightly more efficient way of doing it.",
                    "label": 1
                },
                {
                    "sent": "Let's take the probability of a given C, which was the sum over BD&E of that joint distribution.",
                    "label": 0
                },
                {
                    "sent": "But now I'm going to write out that whole joint distribution, and then I'm going to take some of these sums and shift them in.",
                    "label": 0
                },
                {
                    "sent": "Well, as far as I can, so the sum of her EI can shift all the way in here.",
                    "label": 0
                },
                {
                    "sent": "The sum over DI can bring all the way in here and then the Silver B is here.",
                    "label": 0
                },
                {
                    "sent": "Well, the good news is we know that the sum of RE of the probability distribution over E is 1 'cause probability distribution sum to one.",
                    "label": 0
                },
                {
                    "sent": "So that's just one.",
                    "label": 0
                },
                {
                    "sent": "We don't even need to compute that.",
                    "label": 0
                },
                {
                    "sent": "Again, that's just one we don't need to compute that.",
                    "label": 0
                },
                {
                    "sent": "So then we end up just with the sum over B of this term here.",
                    "label": 1
                },
                {
                    "sent": "And we can compute this in for operations.",
                    "label": 0
                },
                {
                    "sent": "So that was the first step.",
                    "label": 0
                },
                {
                    "sent": "Instead of 16 operations we did it in four, 4 + 2 + 2 is 8 operations.",
                    "label": 0
                },
                {
                    "sent": "Now what did we do there?",
                    "label": 0
                },
                {
                    "sent": "Well, what we did was we used knowledge about the factorization of the joint distribution to simplify our computations.",
                    "label": 0
                },
                {
                    "sent": "In fact, looking at the graph because E is hanging out here at the bottom, it turns out that we didn't need to sum over E if we wanted to know the probability of a given C. That sort of seems a bit intuitive.",
                    "label": 0
                },
                {
                    "sent": "Just by looking at the graph, and we can formalize it here.",
                    "label": 1
                },
                {
                    "sent": "So belief propagation methods are methods for using the conditional independent relate independence relationships in a graph to do efficient inference.",
                    "label": 0
                },
                {
                    "sent": "And if your graph is singly connected.",
                    "label": 0
                },
                {
                    "sent": "Which I'll talk about a little bit later.",
                    "label": 0
                },
                {
                    "sent": "Then you can get exponential gains in efficiency, efficiency over the naive method of doing things.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So let's talk about this in a little more detail.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "First we need to define what a singly connected graph is.",
                    "label": 0
                },
                {
                    "sent": "So directed acyclic graph is singly connected if its underlying undirected graph is a tree or another way of thinking about this is if there is only one undirected path between any two nodes.",
                    "label": 0
                },
                {
                    "sent": "So this graph here is singly connected because for any pair of nodes there's only one way of going between those.",
                    "label": 0
                },
                {
                    "sent": "Pair that pair of nodes, whereas this is multiply connected.",
                    "label": 0
                },
                {
                    "sent": "For example, to go from A to D, you can go a CD or you can go Acbd RACED.",
                    "label": 0
                },
                {
                    "sent": "OK, so yes.",
                    "label": 0
                },
                {
                    "sent": "We're looking at undirected paths, yeah?",
                    "label": 0
                },
                {
                    "sent": "And really, it's relevant because information can flow both up and down these edges.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, now remember our goal is to is for some node X we want to compute the probability of X given some evidence E Some data E that we've observed.",
                    "label": 0
                },
                {
                    "sent": "OK, so we might want to compute the probability of a given C like we did before.",
                    "label": 0
                },
                {
                    "sent": "Now the good news about singly connected graphs is that information gets split up very nicely, so every node X in the graph divides the evidence into upstream and downstream evidence.",
                    "label": 0
                },
                {
                    "sent": "So for example, C divides the observed stuff into the stuff that's observed upstream from C. In other words, with arrows pointing 2C and downstream from C. In other words, Paris arrows pointing from C. Now also, every edge divides the evidence into upstream and downstream parts, so the edge between.",
                    "label": 0
                },
                {
                    "sent": "C&E divides the graph into this part of the downstream and this part that's upstream OK. And you can think of it.",
                    "label": 0
                },
                {
                    "sent": "You know, even if it's downstream of upstream is still upstream.",
                    "label": 0
                },
                {
                    "sent": "So imagine if you introduced some.",
                    "label": 0
                },
                {
                    "sent": "Contaminant this is a River system and he introduced some contaminant in D. It would arrive at this branch of the River from upstream, so that's what it means to be.",
                    "label": 0
                },
                {
                    "sent": "Upstream versus downstream.",
                    "label": 0
                },
                {
                    "sent": "OK, so so in singly connected graphs stuff gets divided up into upstream and downstream components.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now belief propagation makes use of three basic ideas and put them together.",
                    "label": 0
                },
                {
                    "sent": "Is nothing magical, is just the application of Bayes Rule 2 graphs that satisfy conditional independence relationships.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that you can write it efficiently if you use some of these ideas.",
                    "label": 0
                },
                {
                    "sent": "So the first idea is that the probability of a variable X can be found by combining upstream and downstream evidence.",
                    "label": 0
                },
                {
                    "sent": "So the probability of X given some observed data E. We can write that as the probability of X&E divided by the probability of E. Which we can write as the probability of X given upstream and downstream evidence divided by the joint probability of the upstream and downstream evidence.",
                    "label": 0
                },
                {
                    "sent": "So I'm imagining that I have a big graph that I observed variables all over the place, so I've observed this variable here in that variable here in that variable.",
                    "label": 0
                },
                {
                    "sent": "Here, some of our upstream, some of our downstream OK. Now, if we're interested in the distribution of X, then we don't care about things that are constants with respect to the values that X can take, so this denominator here is just a constant.",
                    "label": 0
                },
                {
                    "sent": "So up to proportionality, we can ignore this constant and then renormalize afterwards.",
                    "label": 0
                },
                {
                    "sent": "So then we take the joint distribution of X, the upstream and the downstream.",
                    "label": 0
                },
                {
                    "sent": "Evidence and we divide it up into the distribution of X given upstream.",
                    "label": 0
                },
                {
                    "sent": "Stuff coming up from above times the distribution of the downstream stuff given X and the upstream stuff.",
                    "label": 0
                },
                {
                    "sent": "And now, because X separates the downstream from the upstream.",
                    "label": 0
                },
                {
                    "sent": "The distribution of this stuff is downstream from X.",
                    "label": 0
                },
                {
                    "sent": "Given X and the upstream stuff only depends on X, it's independent of the stuff that's upstream is blocked by X. OK, so this gets copied here and this distribution is independent of the upstream evidence, so it becomes the probability of the downstream evidence given X. Yep.",
                    "label": 0
                },
                {
                    "sent": "No, he is sorry E can be a set of nodes.",
                    "label": 0
                },
                {
                    "sent": "E is the observed values of many different nodes, some of which can be upstream, and some of which can be downstream from X. OK. Um?",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "The way you can think about this is that there's if you want to find the probability distribution over X.",
                    "label": 0
                },
                {
                    "sent": "There's a source of information from above and a source of information from below.",
                    "label": 0
                },
                {
                    "sent": "Anne Anne.",
                    "label": 0
                },
                {
                    "sent": "You that Pearl, who wrote a classic texts on this and it developed belief propagation, largely called this the pie and the Lambda messages Peiffer prior an Lambda for likelihood.",
                    "label": 0
                },
                {
                    "sent": "So the stuff from above.",
                    "label": 0
                },
                {
                    "sent": "You can think of as analogous to a prior in the stuff from below.",
                    "label": 0
                },
                {
                    "sent": "You can think of as analogous to a likelihood, and you're multiplying this prior and the likelihood and then re normalizing to compute the probability over X given the evidence.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So that's the first idea is just the separation between upstream and downstream components.",
                    "label": 0
                },
                {
                    "sent": "The second idea is that this upstream and downstream evidence these messages, sorry, can be computed, but these probabilities, these things that you're trying to multiply can be computed via a local message passing algorithm between the nodes in the graph.",
                    "label": 0
                },
                {
                    "sent": "So we'll see that later.",
                    "label": 0
                },
                {
                    "sent": "And then the third idea is to make sure when you're sending messages not to send back to a node any part of the message is sent to you.",
                    "label": 0
                },
                {
                    "sent": "So you basically want to send each node is sending messages to other nodes, but it needs to make sure that the message is sent to other nodes is only collecting information from all sources other than that that node OK. And only if you do that will you get the right probabilities coming out.",
                    "label": 0
                },
                {
                    "sent": "But all this stuff is not sort of voodoo.",
                    "label": 0
                },
                {
                    "sent": "It just follows.",
                    "label": 0
                },
                {
                    "sent": "You know you can prove it all tediously just by applying Bayes rule and the factorization on the graph OK?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, I'm not going to go into the details of this because it would take, you know, actually, I've taught this before.",
                    "label": 0
                },
                {
                    "sent": "It takes about an hour and a half or two hours just to understand the details of belief propagation.",
                    "label": 0
                },
                {
                    "sent": "I want to give you a flavor and again you can kind of look this stuff up or try to code it up on your own at some point.",
                    "label": 0
                },
                {
                    "sent": "So the belief propagation algorithm involves messages that are sent top down.",
                    "label": 0
                },
                {
                    "sent": "In other words, from a node to its children.",
                    "label": 0
                },
                {
                    "sent": "OK, so the message that UI sends to node X. Um is.",
                    "label": 0
                },
                {
                    "sent": "The probability distribution over UI given all of the evidence that's upstream of the edge UI X. OK, then there also messages coming bottom up from downstream, so the message that YJ sends the X is the probability of the evidence that's downstream from the edge X to YJ.",
                    "label": 0
                },
                {
                    "sent": "As a function of X, so these messages are.",
                    "label": 0
                },
                {
                    "sent": "Are vectors I mean if we think about how we actually implement these messages.",
                    "label": 0
                },
                {
                    "sent": "Let's say X is a binary random variable, so it can take two values, zero or one.",
                    "label": 0
                },
                {
                    "sent": "Then this message is 2 valued vector with a value corresponding to the setting X = 0 and a value corresponding to the setting X = 1.",
                    "label": 0
                },
                {
                    "sent": "And similarly this message would be a.",
                    "label": 0
                },
                {
                    "sent": "Two element vector, so your your messages are being sent as little vectors that get multiplied together.",
                    "label": 0
                },
                {
                    "sent": "For discrete random variables.",
                    "label": 0
                },
                {
                    "sent": "And then the probability that we're interested the probability of X given all of the evidence is.",
                    "label": 0
                },
                {
                    "sent": "The product of all of the downstream messages times all of the stuff coming from upstream, renormalized, and.",
                    "label": 0
                },
                {
                    "sent": "These are just additional equations for how to compute these downstream.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And upstream messages.",
                    "label": 0
                },
                {
                    "sent": "So if you want all the gory details, you know this is all you need to actually implement this algorithm.",
                    "label": 0
                },
                {
                    "sent": "If you wanted to.",
                    "label": 0
                },
                {
                    "sent": "And of course, I'll make my slides available for the summer school.",
                    "label": 0
                },
                {
                    "sent": "So belief propagation is.",
                    "label": 0
                },
                {
                    "sent": "Very useful algorithm if you want to do inference in a large graph.",
                    "label": 0
                },
                {
                    "sent": "You really need to do something like this.",
                    "label": 0
                },
                {
                    "sent": "You can't exhaustively enumerate all settings of all variables.",
                    "label": 0
                },
                {
                    "sent": "Now, if you want to actually code this up.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "It's easier to code it up in the formalism of factor graphs rather than directed graphs, so I'm just going to very quickly show you factor graph propagation as well, which is a similar set of propagation rules.",
                    "label": 0
                },
                {
                    "sent": "Set where nodes are sending messages to us.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nodes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Just a reminder of what a factor graph is.",
                    "label": 1
                },
                {
                    "sent": "A factor graph is just the way of representing a joint probability distribution as a product of.",
                    "label": 0
                },
                {
                    "sent": "Functions on subsets of variables.",
                    "label": 1
                },
                {
                    "sent": "So this is a normalization constant and this joint distribution is simply the product over functions.",
                    "label": 1
                },
                {
                    "sent": "Each of these functions FJ is a non negative function of its arguments and this X sub SJ is just some subset of variables.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "That this function is a function of, so you know, here you would have this dot corresponds to a function of A&CA non negative function can have negatives in there 'cause you're multiplying all these together to get a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "And then you need the normalizer so it sums to one when you sum over all the variables.",
                    "label": 0
                },
                {
                    "sent": "So this is just a reminder of what a factor graph is.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you have a factor graph, you can talk about the neighbors of a node X.",
                    "label": 1
                },
                {
                    "sent": "Let's let N of X be the factor nodes that are neighbors of X&N of FB.",
                    "label": 1
                },
                {
                    "sent": "The variable nodes that are neighbors of factor F. So remember each node is connected.",
                    "label": 0
                },
                {
                    "sent": "Each variable node is connected to some of these factor nodes and the factor nodes are connected to some variable nodes.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So factor graph propagation simply sends messages from variables to factors.",
                    "label": 0
                },
                {
                    "sent": "And the messages look like this.",
                    "label": 0
                },
                {
                    "sent": "A message from a variable to a factor is simply the product of the messages from all the factors that are neighbors of X to X is the product over all of the messages X is getting from the other factors, not including F OK. And then the message from a factor to a variable is.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "Again, a product of the messages from all of the variables that F is connected to.",
                    "label": 0
                },
                {
                    "sent": "Going to F where the product is taken over all of the neighbors of F not including X and then you multiply it by the actual factor and then you sum out all the other variables.",
                    "label": 0
                },
                {
                    "sent": "So it's just these two equations.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An you can basically run these two equations which I've written down here and once all the variables one, sorry a variable is received, all messages from its neighboring factors.",
                    "label": 0
                },
                {
                    "sent": "We can compute the probability distribution of that variable by multiplying all the messages an renormalizing.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's just these two equations is simpler than the belief propagation algorithm that I described previously, and it's really pretty easy to code up.",
                    "label": 0
                },
                {
                    "sent": "These things are again functions of variables if this has.",
                    "label": 0
                },
                {
                    "sent": "If this takes on K values, then this can be represented as a vector.",
                    "label": 0
                },
                {
                    "sent": "Let K. OK. Alright.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that was a factor graph propagation.",
                    "label": 1
                },
                {
                    "sent": "So how would this actually work?",
                    "label": 0
                },
                {
                    "sent": "Well, imagine you had a factor graph that look like this.",
                    "label": 0
                },
                {
                    "sent": "Let's say let's initialize all the messages to be ones.",
                    "label": 0
                },
                {
                    "sent": "That means their vectors of all ones.",
                    "label": 1
                },
                {
                    "sent": "Here is an example schedule of messages resulting in the computation of P of X probability of X4.",
                    "label": 0
                },
                {
                    "sent": "OK, we want to compute the probability of X4.",
                    "label": 0
                },
                {
                    "sent": "How are we going to do this well?",
                    "label": 0
                },
                {
                    "sent": "X1 sends a message to F1.",
                    "label": 0
                },
                {
                    "sent": "That message is.",
                    "label": 0
                },
                {
                    "sent": "Uh, all one's message.",
                    "label": 0
                },
                {
                    "sent": "Then X3 sends a message to F2.",
                    "label": 0
                },
                {
                    "sent": "We could have done him in a different order if we'd wanted to.",
                    "label": 0
                },
                {
                    "sent": "Now F1 sends a message to F2 according to the.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rules.",
                    "label": 0
                },
                {
                    "sent": "We had before the message that that F function sensor variable is given by.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry this equation so F1 sends this message to X2 and that's the message it sends X2.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "F2 sends this message to X2, so that's this message sent to X2.",
                    "label": 0
                },
                {
                    "sent": "Then X2 has received the messages from F1 and F2 and it's ready to send out a message to F3.",
                    "label": 0
                },
                {
                    "sent": "So X2 sends this message to F3, which is simply the product of the messages they got from F1 and F2.",
                    "label": 0
                },
                {
                    "sent": "OK. And so F3 got that message and now F3 is ready to send a message to FX4.",
                    "label": 0
                },
                {
                    "sent": "And the message that F3 cents X4 is according to.",
                    "label": 0
                },
                {
                    "sent": "Again, this rule is the product of the messages it got in times the function itself summing out all the other variables.",
                    "label": 0
                },
                {
                    "sent": "So it's the product of this message and this message that it got in.",
                    "label": 0
                },
                {
                    "sent": "Times the function, its own function F3, which is a function of the variables X2 and X4 and then summing out all the other variables that is summing out X2.",
                    "label": 0
                },
                {
                    "sent": "And so this is the final message that F3 Sense X4 and you can prove to yourself that if you take this and you normalize it to sum to one over the values of X4, that will be the probability distribution over X4.",
                    "label": 0
                },
                {
                    "sent": "Represented by this factor graph.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, what about if we observe some evidence?",
                    "label": 0
                },
                {
                    "sent": "Let's say we observe that X1 takes on the value a.",
                    "label": 0
                },
                {
                    "sent": "You know, let's say.",
                    "label": 0
                },
                {
                    "sent": "X1 is a binary variable, so a is 0 or something like that.",
                    "label": 0
                },
                {
                    "sent": "Now how does this change those probabilities well?",
                    "label": 0
                },
                {
                    "sent": "You initialize all the messages to be one, but then when you observe that X1 takes on the value a.",
                    "label": 0
                },
                {
                    "sent": "Then the message that X1 cents F1 is a Delta function on the value X what equals a.",
                    "label": 0
                },
                {
                    "sent": "So if X1 is a binary variable taking on the values zero and one instead of setting the vector of all ones, the message is 1 zero OK. Um?",
                    "label": 0
                },
                {
                    "sent": "That's just to to represent the fact that X1 takes on the value 0.",
                    "label": 0
                },
                {
                    "sent": "And then everything else follows through.",
                    "label": 0
                },
                {
                    "sent": "In exactly the same way, but because this is a Delta function on X1, taking on the value a.",
                    "label": 0
                },
                {
                    "sent": "When you send a message from F1 to X2, this product of that message times the factor here is just the function F1.",
                    "label": 0
                },
                {
                    "sent": "As a function of X2, but with the value X1 set to a.",
                    "label": 0
                },
                {
                    "sent": "And all of this follows through and then this is what you get as the message F3 Center X4 and again once you normalize this as a function of X4, you'll be able to confirm that this is the probability of X4 given X 1 = A. OK.",
                    "label": 0
                },
                {
                    "sent": "So any questions about this?",
                    "label": 0
                },
                {
                    "sent": "I'm sure this is pretty fast and quite hard to follow all of this, but I want to give you if you haven't encountered this before, I want to give you a sense for the algorithms for sending messages on these graphs and how they can correspond to computing probabilities.",
                    "label": 0
                },
                {
                    "sent": "On these graphs.",
                    "label": 0
                },
                {
                    "sent": "OK. Any questions?",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Everybody's ready for lunch already.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "So I've talked about factor graphs and directed graphs in the abstract, but you actually see them all over the place in the machine learning and pattern recognition literature.",
                    "label": 0
                },
                {
                    "sent": "In fact, a lot of models that are very familiar to us like hidden Markov models and linear Gaussian state space models, can be very nicely represented as directed graphs or factor graphs.",
                    "label": 0
                },
                {
                    "sent": "So here is the directed graph for.",
                    "label": 0
                },
                {
                    "sent": "A hidden Markov model, which is also the same.",
                    "label": 0
                },
                {
                    "sent": "Graph.",
                    "label": 0
                },
                {
                    "sent": "For a state space model or Kalman filter model.",
                    "label": 0
                },
                {
                    "sent": "You have a bunch of hidden state variables and you have a bunch of observations and you're modeling a time series of these observations.",
                    "label": 0
                },
                {
                    "sent": "A shaded in these nodes to represent that you've observed these guys, and these guys are hidden.",
                    "label": 0
                },
                {
                    "sent": "And the joint distribution of all of the hidden variables and all of the observed variables can be written as the probability of the first hidden variables.",
                    "label": 0
                },
                {
                    "sent": "Variable times the probability of the first observed variable given the first hidden variable times the probability of each hidden variable given its previous hidden state variable and the probability of each observed variable given the corresponding hidden variable.",
                    "label": 0
                },
                {
                    "sent": "So this graph corresponds to this factorization, which is true for Hmm's and state space models.",
                    "label": 0
                },
                {
                    "sent": "The only difference between Hmm's and state space models is that in Hmm's, the states are assumed to be discreet whereas in linear, Gaussian state space models, the states are assumed to be real valued Gaussian vectors.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And now the interesting thing is that the belief propagation, an factor graph propagation algorithms that I've just briefly described, are actually generalizations of.",
                    "label": 0
                },
                {
                    "sent": "The forward backward algorithm, which is an algorithm for doing inference in hidden Markov models and the Kalman smoothing algorithm, which is an algorithm for doing inference in state space models.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "So amazingly, when I was a grad student, I took a full term term long course on Kalman filtering.",
                    "label": 0
                },
                {
                    "sent": "We spent the entire term on Kalman filtering and I was really bored at the end of it, and now I know why I was so bored and that was because you could learn about belief propagation and then common filtering is a special case.",
                    "label": 0
                },
                {
                    "sent": "They didn't sort of know it at the time.",
                    "label": 0
                },
                {
                    "sent": "Column filtering is a special case, you can describe it in a couple of slides as being a special case, and then you can say, uh, oh, by the way, belief propagation can be applied to hidden Markov models and all these other graphs as well.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's just an aside.",
                    "label": 0
                },
                {
                    "sent": "Now, what do you do with multiply connected graphs?",
                    "label": 0
                },
                {
                    "sent": "So we talked about singly connected graphs, but.",
                    "label": 0
                },
                {
                    "sent": "The real world isn't always singly connected, so we have a few options, so there is an exact algorithm called the junction tree algorithm, which I won't describe, but I have in the appendix here.",
                    "label": 0
                },
                {
                    "sent": "I have actually the description of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "In subsequent slides, the junction tree algorithm takes your multiple connected graph lumps, a bunch of variables together until it can form a singly connected graph.",
                    "label": 0
                },
                {
                    "sent": "On the Super variables, these super variables are variables that you take by grouping together a bunch of variables in your original graph.",
                    "label": 0
                },
                {
                    "sent": "And then it runs basically belief propagation on this super graph OK.",
                    "label": 0
                },
                {
                    "sent": "Which is called the junction tree.",
                    "label": 0
                },
                {
                    "sent": "Now the problem with this algorithm is that it's an exact algorithm.",
                    "label": 0
                },
                {
                    "sent": "It will give you exactly the probabilities you want, but if you have a multiple connected graph, you have no guarantee that you're.",
                    "label": 0
                },
                {
                    "sent": "Super nodes that you form are going to have a small number of states.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you have a bunch of binary variables and you lump.",
                    "label": 0
                },
                {
                    "sent": "20 binary variables together.",
                    "label": 0
                },
                {
                    "sent": "If you force the lump 20 binary variables together, then that supernode can take on a million different states.",
                    "label": 0
                },
                {
                    "sent": "And you'd have to actually enumerate all of those states to run this algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the junction tree algorithm is exact, but it can be exponentially slow and it turns out there's no way of doing inference in a general graph.",
                    "label": 0
                },
                {
                    "sent": "Where you're guaranteed always to be polynomial time in the number of nodes just because it's not possible, a general graph can involve a full conditional probability, full probability table involving exponentially many states, so it's not possible to do that, so that's what you get for the junction tree algorithm.",
                    "label": 0
                },
                {
                    "sent": "Another thing you can do is called cutset conditioning, where essentially you take your multiply connected graph and you take some variables and you say, what?",
                    "label": 0
                },
                {
                    "sent": "If I set this variable to this value and then you run belief propagation on the rest of the graph, and then you say, what if I set it to this other value, etc.",
                    "label": 0
                },
                {
                    "sent": "So you sometimes called reasoning by assumptions because you assume different possible states for variables you haven't observed.",
                    "label": 0
                },
                {
                    "sent": "And then you.",
                    "label": 0
                },
                {
                    "sent": "Then you combine together the probabilities that you got from these different settings.",
                    "label": 0
                },
                {
                    "sent": "Now you can only do this if you find a set of variables that renders the rest of the graph to be singly connected.",
                    "label": 0
                },
                {
                    "sent": "So you need to take your graph, an surgically remove a bunch of nodes until you get the rest of the singly connected.",
                    "label": 0
                },
                {
                    "sent": "So this doesn't always work.",
                    "label": 0
                },
                {
                    "sent": "Very efficiently either, and this is exact as well.",
                    "label": 0
                },
                {
                    "sent": "And the third thing you can do is you can take your multiply connected graph and you can simply run belief propagation on that multiply connected graph.",
                    "label": 0
                },
                {
                    "sent": "So you can take factor graph propagation or belief propagation.",
                    "label": 0
                },
                {
                    "sent": "Run the algorithm ignoring the fact that the graph is not singly connected.",
                    "label": 0
                },
                {
                    "sent": "What happens there is that.",
                    "label": 0
                },
                {
                    "sent": "Messages, whereas before messages would get propagated in One Direction or another and the algorithm would stop.",
                    "label": 0
                },
                {
                    "sent": "Now messages can start to go around in loops like they go from one child to a parent to another parent.",
                    "label": 0
                },
                {
                    "sent": "A child of that and child that and then end up in the same place.",
                    "label": 0
                },
                {
                    "sent": "OK, so because you have these loops in the messages probabilities that you get out are not exact anymore, their approximate.",
                    "label": 0
                },
                {
                    "sent": "Sometimes the algorithm doesn't converge at all.",
                    "label": 0
                },
                {
                    "sent": "But it turns out often this works incredibly well, so this isn't a thing that one would advise people to do to try out on a multiple connected graph.",
                    "label": 0
                },
                {
                    "sent": "If this doesn't seem to work, if it doesn't converge, or if it gives ridiculous answers, then there are other things one can try.",
                    "label": 1
                },
                {
                    "sent": "OK. Yep.",
                    "label": 0
                },
                {
                    "sent": "No, that's a very good question.",
                    "label": 0
                },
                {
                    "sent": "What you're doing is you're keeping the same graph, but you're saying.",
                    "label": 0
                },
                {
                    "sent": "Even though I didn't observe this variable.",
                    "label": 0
                },
                {
                    "sent": "Imagine I did observe it.",
                    "label": 0
                },
                {
                    "sent": "Let's imagine I did observe it is the rest of the graph are the other variables not including this one, singly connected.",
                    "label": 0
                },
                {
                    "sent": "And so you don't really.",
                    "label": 0
                },
                {
                    "sent": "You don't really remove that node, you just act as if you've observed that node.",
                    "label": 0
                },
                {
                    "sent": "It's sort of like saying.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You know the reasoning by assumptions.",
                    "label": 0
                },
                {
                    "sent": "Saying is like saying, should I invest in the stock market or should I buy a house?",
                    "label": 0
                },
                {
                    "sent": "OK, let's imagine that the Bank of England cuts interest rates.",
                    "label": 0
                },
                {
                    "sent": "What's going to happen then?",
                    "label": 0
                },
                {
                    "sent": "Compute the probabilities of what's better?",
                    "label": 0
                },
                {
                    "sent": "OK, let's imagine the Bank of England doesn't cut interest rates.",
                    "label": 0
                },
                {
                    "sent": "Let's compute probabilities.",
                    "label": 0
                },
                {
                    "sent": "OK, now how probable do I think the Bank of England is going to be to cut interest rates?",
                    "label": 0
                },
                {
                    "sent": "And then I average those?",
                    "label": 0
                },
                {
                    "sent": "And that's what I get finally.",
                    "label": 0
                },
                {
                    "sent": "So I'm not removing the Bank of England variable.",
                    "label": 0
                },
                {
                    "sent": "I'm just assuming that it can take on different values and then and then, hoping that the rest of the variables are singly connected, yeah?",
                    "label": 0
                },
                {
                    "sent": "Yes, it turns out you can actually prove that.",
                    "label": 0
                },
                {
                    "sent": "Any choice of cutset corresponds to a way of farming a junction tree.",
                    "label": 0
                },
                {
                    "sent": "So they are actually going to end up being equivalent, but sometimes it's just more obvious how to do this sometimes this more obvious how to do this.",
                    "label": 0
                },
                {
                    "sent": "And they're both going to be intractable in general.",
                    "label": 0
                },
                {
                    "sent": "OK. You have other questions.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's basically the summary for this.",
                    "label": 0
                },
                {
                    "sent": "I talked about inference and now I just want to spend the last few minutes talking about learning.",
                    "label": 0
                },
                {
                    "sent": "And rather than take a break.",
                    "label": 0
                },
                {
                    "sent": "What I'm suggesting is that I'll just go until 12:30 and then our break can be lunch so lunch will be sooner if we don't take a break now.",
                    "label": 0
                },
                {
                    "sent": "Sure, well I'm switching sides, sure.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Yes, good question.",
                    "label": 0
                },
                {
                    "sent": "The graph is exactly the same for a Kalman filter.",
                    "label": 0
                },
                {
                    "sent": "For example, state space model.",
                    "label": 0
                },
                {
                    "sent": "The graph is exactly the same.",
                    "label": 0
                },
                {
                    "sent": "Filtering is just sending messages in the forward direction.",
                    "label": 0
                },
                {
                    "sent": "Smoothing is combining both messages that are being sent in the forward direction and in the backward direction.",
                    "label": 0
                },
                {
                    "sent": "So filtering actually corresponds to computing all of those \u03c0 messages.",
                    "label": 0
                },
                {
                    "sent": "And this one and just.",
                    "label": 0
                },
                {
                    "sent": "The Lambda messages up to time T, whereas smoothing corresponds to computing all of the \u03a0 messages in all of the Lambda messages.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The last thing I want to talk about.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "Is learning.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "No, I don't want to print.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So we we talked about what graphs are.",
                    "label": 0
                },
                {
                    "sent": "We've talked about inference algorithms and now let's talk about Lee.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what do we mean?",
                    "label": 0
                },
                {
                    "sent": "What do we mean by learning?",
                    "label": 0
                },
                {
                    "sent": "Imagine we have the following graph, which corresponds to the following factorization.",
                    "label": 0
                },
                {
                    "sent": "Now assume that each variable is discrete and can take on Ki values.",
                    "label": 0
                },
                {
                    "sent": "So variable XI takes on Ki values.",
                    "label": 0
                },
                {
                    "sent": "So the parameters of this model, if all variables are discrete, can be represented as four tables.",
                    "label": 0
                },
                {
                    "sent": "So Theta one are going to be the parameters controlling variable X1.",
                    "label": 0
                },
                {
                    "sent": "And that just has K1 entries.",
                    "label": 0
                },
                {
                    "sent": "Theta two are the parameters controlling X2, given X one and that has K 1 * K Two entries, because for every setting of X one we need to know what is the probability distribution over X2.",
                    "label": 0
                },
                {
                    "sent": "So that's a table with K 1 * K, Two entries etc so.",
                    "label": 0
                },
                {
                    "sent": "These things are called conditional probability tables.",
                    "label": 0
                },
                {
                    "sent": "In the case where we have all discrete random variables, so here's an example of what a conditional probability table might look like.",
                    "label": 0
                },
                {
                    "sent": "In this case, X1 is a binary variable, takes on two values, and X2 takes on three values, and the CPT the conditional probability table is just the table where the rows.",
                    "label": 0
                },
                {
                    "sent": "Sub to one.",
                    "label": 0
                },
                {
                    "sent": "OK, 'cause there are probability distributions over these three settings in this case, so the notation we're going to use is that.",
                    "label": 0
                },
                {
                    "sent": "Theta 1K is the probability that variable X1 takes on value K. Um?",
                    "label": 0
                },
                {
                    "sent": "In this case, Theta 2K K prime when variant and when that variable has parents, is the probability that variable 2 takes on the value K prime when its parents take on the value K?",
                    "label": 0
                },
                {
                    "sent": "So if we have a bunch of parents for node, we take all of the states of those parents and we we combine them together into like a super state and that way we can keep this notation having only three indices rather than as many indices as the parents plus two or whatever, which would be a real pain.",
                    "label": 0
                },
                {
                    "sent": "So these are just all tables that we're trying to learn.",
                    "label": 0
                },
                {
                    "sent": "So assume we have a data set of observations of these variables.",
                    "label": 0
                },
                {
                    "sent": "So we have N data points.",
                    "label": 0
                },
                {
                    "sent": "These are cases where we've observed you know X1 takes on a particular value, asks 2, takes on some other value, etc, and we want to learn Theta from this data set.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we learn the parameters of this model?",
                    "label": 0
                },
                {
                    "sent": "We assume we have this data set.",
                    "label": 0
                },
                {
                    "sent": "We want to learn the parameters from this data set.",
                    "label": 0
                },
                {
                    "sent": "Now our model says that the joint distribution of all the variables factors in this way, where I've explicitly written in the parameters and where where they live.",
                    "label": 1
                },
                {
                    "sent": "So each parameter controls each of the variables.",
                    "label": 1
                },
                {
                    "sent": "If we have N data points, the likelihood function, which is a function of the parameters, is the product over those end data points of the probability of each data point given the parameters.",
                    "label": 0
                },
                {
                    "sent": "That's assuming that our data points were observed independently.",
                    "label": 0
                },
                {
                    "sent": "From that model.",
                    "label": 0
                },
                {
                    "sent": "And so if we take the log of the likelihood, if we combine this equation, which is a product over data points and this equation, which is a product over nodes.",
                    "label": 0
                },
                {
                    "sent": "Then we take the log, then the log likelihood is a sum over data points coming from this product.",
                    "label": 0
                },
                {
                    "sent": "When we take the log and a sum over variables or nodes in the graph, that's the sum over I of the log probability of each variable.",
                    "label": 0
                },
                {
                    "sent": "XI in the NTH case.",
                    "label": 0
                },
                {
                    "sent": "Given the settings of the parents of that variable and Theta I.",
                    "label": 0
                },
                {
                    "sent": "Now the good news about this is that this log likelihood decomposes into a sum of functions of the parameters for each node, so each node.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Has his parents and there are these parameters Theta I controlling the probability of that node and we could learn essentially each of these Theta eyes in dependently?",
                    "label": 0
                },
                {
                    "sent": "If we optimize the log likelihood then we get this incredibly intuitive equation.",
                    "label": 0
                },
                {
                    "sent": "Once I explain it to you, it will be incredibly intuitive, which basically says that the maximum likelihood setting of the parameters.",
                    "label": 0
                },
                {
                    "sent": "Corresponds to taking counts of how many times.",
                    "label": 0
                },
                {
                    "sent": "Variable XI isn't state K prime.",
                    "label": 0
                },
                {
                    "sent": "Given that his parents were in State K and making sure those counts normalized to one.",
                    "label": 0
                },
                {
                    "sent": "So it's incredibly intuitive.",
                    "label": 0
                },
                {
                    "sent": "Once I show you this picture.",
                    "label": 0
                },
                {
                    "sent": "OK so imagine we have an observed data set.",
                    "label": 0
                },
                {
                    "sent": "When we simply count how many times was X one in each of these two States and X2 in each of these three states, we fill up a table like this.",
                    "label": 0
                },
                {
                    "sent": "With those counts.",
                    "label": 0
                },
                {
                    "sent": "And then we take each of these rows and we normalize them to sum to one.",
                    "label": 0
                },
                {
                    "sent": "OK, and then we get the maximum likelihood parameter settings for the data that we've observed.",
                    "label": 0
                },
                {
                    "sent": "OK. That makes a lot of sense.",
                    "label": 0
                },
                {
                    "sent": "You know, I, I've observed this happening twice and this happening three times.",
                    "label": 0
                },
                {
                    "sent": "So given that X1 takes on the value zero as opposed to one in this row, then I believe that X2 is going to take on the value zero with probability .41 with probability .6 and two with probability 0.",
                    "label": 0
                },
                {
                    "sent": "OK. That's simply the maximum likelihood estimates.",
                    "label": 0
                },
                {
                    "sent": "And you can do.",
                    "label": 0
                },
                {
                    "sent": "You can compute this by taking the derivative of the log likelihood and maximizing it subject to the constraint that these conditional probability table rows have to sub to one.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the easy case that's learning parameters when you observe all of the variables.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In your model.",
                    "label": 0
                },
                {
                    "sent": "If you observe only some of the variables in your model, then you can still do maximum likelihood learning.",
                    "label": 0
                },
                {
                    "sent": "So let's say you observe Y, but you haven't observed, the X is.",
                    "label": 0
                },
                {
                    "sent": "You can still do maximum likelihood learning, But the problem is that the likelihood involves summing over all the possible settings of X.",
                    "label": 0
                },
                {
                    "sent": "So your goal is to maximize the log likelihood given the observed data.",
                    "label": 0
                },
                {
                    "sent": "That's this thing, but that involves the log of the sum over all the values of the variables.",
                    "label": 0
                },
                {
                    "sent": "We didn't observe the hidden variables.",
                    "label": 0
                },
                {
                    "sent": "Of this joint distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, and.",
                    "label": 0
                },
                {
                    "sent": "The way you can maximize this likelihood is to use the well known EM algorithm, which is a nice general procedure for maximizing likelihoods when you have missing data.",
                    "label": 0
                },
                {
                    "sent": "In this case.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The X is.",
                    "label": 0
                },
                {
                    "sent": "Have you been?",
                    "label": 0
                },
                {
                    "sent": "Have you seen the EM algorithm this week yet?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Great, that's very good for me.",
                    "label": 0
                },
                {
                    "sent": "So the intuition is you fill in the missing data that hidden variables with the probability distribution over there possible hidden States and in the M steps you apply learning.",
                    "label": 0
                },
                {
                    "sent": "Complete data learning this same kind of learning we applied before but with filled in.",
                    "label": 0
                },
                {
                    "sent": "This filled in data, but the important thing is you're not filling it in with single values, you're filling it in with a probability distribution over the values.",
                    "label": 0
                },
                {
                    "sent": "It can take each.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These hidden variables, so I won't go into the details.",
                    "label": 0
                },
                {
                    "sent": "The important point is at the bottom here.",
                    "label": 0
                },
                {
                    "sent": "The eastep of the EM algorithm involves inference over the hidden variables.",
                    "label": 0
                },
                {
                    "sent": "And if we have a graph, then we know how to do inference over the hidden variables.",
                    "label": 0
                },
                {
                    "sent": "We simply need to apply the belief propagation algorithm.",
                    "label": 0
                },
                {
                    "sent": "If it's singly connected or the junction tree or cutset conditioning algorithms if it's multiply connected.",
                    "label": 0
                },
                {
                    "sent": "So in the eastep of the EM algorithm, we run one of these inference procedures and then in the M step we re estimate the parameters.",
                    "label": 0
                },
                {
                    "sent": "And we iterate.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "So just to contrast, compare and contrast the EM algorithm with hidden variables to the complete data case.",
                    "label": 0
                },
                {
                    "sent": "This is what we first talked about.",
                    "label": 0
                },
                {
                    "sent": "The maximum likelihood parameters are simply normalized counts.",
                    "label": 0
                },
                {
                    "sent": "If you have no hidden variables, if you have hidden variables, you iterate.",
                    "label": 0
                },
                {
                    "sent": "E&M steps and in the M step the maximum.",
                    "label": 0
                },
                {
                    "sent": "The current maximum likelihood estimate in the M step is exactly in the same form as it was when you have complete data, except that instead of actual counts, we use expected values of those counts where those expectations are taken with respect to.",
                    "label": 0
                },
                {
                    "sent": "The distribution over the hidden variables.",
                    "label": 0
                },
                {
                    "sent": "OK, so the difference here is.",
                    "label": 0
                },
                {
                    "sent": "Expected counts versus actual.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that was maximum likelihood learning with no hidden variables and with hidden variables.",
                    "label": 0
                },
                {
                    "sent": "We can also do Bayesian learning.",
                    "label": 0
                },
                {
                    "sent": "Of the.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Parameters.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So again, this is just the way of writing out the probability of the data given the parameters as the product over each data point.",
                    "label": 0
                },
                {
                    "sent": "The product over each variable XI of these conditional probability tables and if the variables XI are discreet than these conditional probabilities can be written in the form of Theta IJK to the power of NIJK.",
                    "label": 1
                },
                {
                    "sent": "So every time you observe one of the IJK settings variable, I taking on setting K when his parents are in setting J you get one of these contributions data so.",
                    "label": 1
                },
                {
                    "sent": "This is the likelihood function for.",
                    "label": 0
                },
                {
                    "sent": "Graphical model directed graphical model with discrete variables.",
                    "label": 0
                },
                {
                    "sent": "Now we want to do Bayesian learning for Theta.",
                    "label": 0
                },
                {
                    "sent": "This is our likelihood function.",
                    "label": 0
                },
                {
                    "sent": "Let's imagine we choose a prior on Theta.",
                    "label": 1
                },
                {
                    "sent": "Are of the same form as this likelihood function, so the prior is going to look very similar to the likelihood function.",
                    "label": 0
                },
                {
                    "sent": "There is a normalizing constant at the beginning here.",
                    "label": 1
                },
                {
                    "sent": "Just because this prior has to integrate to one.",
                    "label": 0
                },
                {
                    "sent": "When we integrate over Theta.",
                    "label": 0
                },
                {
                    "sent": "And then these parameters of the prior, we're just going to call them Alpha I JKS.",
                    "label": 0
                },
                {
                    "sent": "They're very analogous to NIJK and.",
                    "label": 0
                },
                {
                    "sent": "There's a -- 1 here because.",
                    "label": 0
                },
                {
                    "sent": "If all the alphas are set to ones, then this becomes the uniform distribution, and that's a particularly nice distribution here.",
                    "label": 0
                },
                {
                    "sent": "Now, this form of distribution is called the Dirichlet distribution.",
                    "label": 1
                },
                {
                    "sent": "This is a Dirichlet distribution.",
                    "label": 0
                },
                {
                    "sent": "And it has a nice property that if you take this Dirichlet distribution and you multiply it by this discrete.",
                    "label": 0
                },
                {
                    "sent": "Likelihood.",
                    "label": 0
                },
                {
                    "sent": "Then you get another Dearsley distribution back, so this is called the conjugate prior.",
                    "label": 0
                },
                {
                    "sent": "Did you hear bout conjugate priors?",
                    "label": 0
                },
                {
                    "sent": "Yeah, and so if you choose this conjugate Dirichlet distribution then life is easy.",
                    "label": 0
                },
                {
                    "sent": "So the posterior distribution is in the same form as the prior but with these alphas, now incremented by the counts.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've observed.",
                    "label": 0
                },
                {
                    "sent": "So here is just a little reminder about what a deer sleigh distribution is.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which I'll skip.",
                    "label": 0
                },
                {
                    "sent": "Here's some pictures of their state distributions when you're looking at three.",
                    "label": 0
                },
                {
                    "sent": "3 dimensional vector that sums to one, so we only need to plot it.",
                    "label": 0
                },
                {
                    "sent": "We can put it in 2D 'cause the third dimension is 1 minus Theta, 1 minus Theta two.",
                    "label": 0
                },
                {
                    "sent": "So this is the Dirichlet 111 which is a uniform.",
                    "label": 0
                },
                {
                    "sent": "Here's the richly 1010 ten, which is centered around 1/3 third third.",
                    "label": 0
                },
                {
                    "sent": "Etc.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "For example, if we use the Dearsley 111.",
                    "label": 0
                },
                {
                    "sent": "This uniform distribution, as our prior then we can do Bayesian learning and our posterior distribution over the parameters, is again a deer sleigh where the parameters are of that deer sleigh are the counts plus one sort of like just adding one to all the counts an if you wanted to do prediction.",
                    "label": 0
                },
                {
                    "sent": "If you wanted to predict what is the probability that XI takes on value K given its parents taking on value J Anna data that you observed.",
                    "label": 0
                },
                {
                    "sent": "Then it's an IJK plus one normalized.",
                    "label": 0
                },
                {
                    "sent": "So it gets rid of that annoying zero doing zeros in the probabilities.",
                    "label": 0
                },
                {
                    "sent": "When we were doing maximum likelihood inference, which was quite silly.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Really.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So we're going in increasing complexity.",
                    "label": 0
                },
                {
                    "sent": "You could also do Bayesian parameter learning when you have hidden variables.",
                    "label": 0
                },
                {
                    "sent": "So that was the Bayesian parameter learning when you have.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fully observed data before.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry, now I'm going forward Bayesian parameter learning.",
                    "label": 0
                },
                {
                    "sent": "When you have hidden variables an you can use MCMC methods or variational Bayesian method.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ed.",
                    "label": 0
                },
                {
                    "sent": "Which I won't talk about.",
                    "label": 0
                },
                {
                    "sent": "Just to recap, the summary of parameter learning maximum likelihood learning when you have complete data is very easy.",
                    "label": 0
                },
                {
                    "sent": "You just calculate the frequencies and you renormalize.",
                    "label": 0
                },
                {
                    "sent": "Bayesian learning when you have complete data is also very easy if you use Dirichlet priors, you just update dearsley distributions is about as computationally hard as doing the maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "Learning things get hard when you have missing data or incomplete data.",
                    "label": 0
                },
                {
                    "sent": "So in the maximum likelihood case you do EM in the base.",
                    "label": 0
                },
                {
                    "sent": "In case you might do MCMC, or Viterbi, or this variational Bayesian TM.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The last thing I'll just mention, 'cause we're a little overtime.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "Is structured learning so I really, I mean I. I've gone I. I think you would probably agree I've gotten at about is faster pace.",
                    "label": 0
                },
                {
                    "sent": "Assuming people don't have a lot of familiarity with graphical models, but I don't want to leave out.",
                    "label": 0
                },
                {
                    "sent": "What structure learning is OK so?",
                    "label": 0
                },
                {
                    "sent": "I've talked about graphical models and parameter learning so far under the assumption that you knew what the structure of the graph was.",
                    "label": 0
                },
                {
                    "sent": "That is, you knew.",
                    "label": 0
                },
                {
                    "sent": "Which.",
                    "label": 0
                },
                {
                    "sent": "Nodes were parents and children, of which other nodes.",
                    "label": 0
                },
                {
                    "sent": "But imagine all we observe is just some data and we want to actually learn the structure of the graph from the data.",
                    "label": 0
                },
                {
                    "sent": "So if we have.",
                    "label": 0
                },
                {
                    "sent": "Five variables, then, could we automatically learn?",
                    "label": 0
                },
                {
                    "sent": "What structure to choose?",
                    "label": 0
                },
                {
                    "sent": "From the data, so we're going to use M to denote the graph structure.",
                    "label": 0
                },
                {
                    "sent": "That is, the set of edges going all the way from empty graphs through some more reasonable graphs all the way to complete graphs where.",
                    "label": 0
                },
                {
                    "sent": "It corresponds to a full probability distribution with no factorizations.",
                    "label": 0
                },
                {
                    "sent": "No conditional independence relationship, sorry.",
                    "label": 0
                },
                {
                    "sent": "So that's what I wanted to just briefly.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mention.",
                    "label": 0
                },
                {
                    "sent": "Are there different kinds of structure learning algorithms?",
                    "label": 0
                },
                {
                    "sent": "There are two broad classes of structure learning algorithms, Constraint Basin, score base in constraint based learning.",
                    "label": 0
                },
                {
                    "sent": "We use statistical tests of marginal and conditional independence.",
                    "label": 0
                },
                {
                    "sent": "We group together we find a whole bunch of results of these tests and then we try to find a directed graph whose D separation relations match the results of these conditional independence tests as well as possible.",
                    "label": 0
                },
                {
                    "sent": "In score based learning we use, we use a global score on the graph.",
                    "label": 0
                },
                {
                    "sent": "Like the Bayesian marginal likelihood, which I think you've probably just heard about a little bit.",
                    "label": 0
                },
                {
                    "sent": "And we try to find the structure that maximizes this score.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Good news when you have complete data again, it seems that life is really easy when you have complete data and life gets hard when you have hidden variables or missing data.",
                    "label": 0
                },
                {
                    "sent": "The good news is that if you assume the richley priors on your parameters and you have discrete data and you have complete data, then you could actually compute the score.",
                    "label": 0
                },
                {
                    "sent": "Which is this?",
                    "label": 0
                },
                {
                    "sent": "Marginal likelihood the probability of the data given the model structure.",
                    "label": 0
                },
                {
                    "sent": "Integrating over all the parameters.",
                    "label": 0
                },
                {
                    "sent": "So the log of the score, which is something you can optimize.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "Is analytically tractable.",
                    "label": 0
                },
                {
                    "sent": "You can just compute it based on counts from the data.",
                    "label": 0
                },
                {
                    "sent": "So it's just a function an you just change different graph structures and find better and better graphs by optimizing this score.",
                    "label": 0
                },
                {
                    "sent": "And you can do greedy search algorithms or MC.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See and again, this story gets hard when you have hidden variables.",
                    "label": 0
                },
                {
                    "sent": "You need to do some combination of Bayesian learning with EM for incomplete data like this.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bayesian structurally of algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learning graphs, learning undirected graphs or factor graphs is harder because of the globalization constant, and we've done some work in that, but I won't really talk about.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'll summarize and conclude, so we've talked about parameter learning and directed graphs, and we talked about structure learning.",
                    "label": 0
                },
                {
                    "sent": "And I really didn't talk about causality, but I just mentioned that parameter and structure learning is just much harder in undirected graphs.",
                    "label": 0
                },
                {
                    "sent": "It's also harder when you have incomplete data.",
                    "label": 0
                },
                {
                    "sent": "And it's harder when things are not discrete.",
                    "label": 0
                },
                {
                    "sent": "So if you have general continuous random variables with non Gaussian distributions then things get hard.",
                    "label": 0
                },
                {
                    "sent": "Just these sums and integrals get hard.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So that's it great.",
                    "label": 0
                }
            ]
        }
    }
}