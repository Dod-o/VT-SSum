{
    "id": "cduk6vd2tdnbzpx3pul5yw4h7hx5ige4",
    "title": "Monocular SLAM and Real-Time Scene Perception",
    "info": {
        "author": [
            "Andrew Davison, Department of Computing, Imperial College London"
        ],
        "published": "Oct. 9, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/bmvc2012_davison_scene_perception/",
    "segmentation": [
        [
            "So I'm going to talk to you really give you a bit of a run through for various work that I've been doing over the last 15 years, really, since the period that Terry was talking about when I was doing my PhD.",
            "But hopefully you'll see there's some kind of meaningful kind of flow to to the research that I've been doing in this area of monocular slam and real time scene perception so.",
            "Maya laugh now at Imperial College."
        ],
        [
            "Call it the the Robot Vision Lab and I feel like that in captures what I'm interested in quite well, so I'm interested in computer vision, but computer vision that works in a context that might be useful for robotics, but probably also for other things, so we're interested in vision systems that work in the real world, and pretty much always in real time in a real time loop, and possibly that could be used for something some application, although.",
            "You know, there's not always a an application for these systems.",
            "I'll show you and I think something I've really observed is that the fast progress of research in this robot vision area over there.",
            "Were not.",
            "Since I've been working in it, and I put that down to several reasons, the one that we should never underestimate is the continuing exponential increase in low cost computer power.",
            "That just means that we can do things now work that were completely unimaginable.",
            "10 or 15 years ago, and hopefully I'll show you some good examples of that.",
            "I think we've got a good common understanding of the key principles of dealing with uncertain data that you get from real sensors in the real world and how to combine those.",
            "And then another very important thing is think there's a wealth of tools out there, things that people know really work.",
            "So these are algorithms in papers, but also pieces of code that people can just download and start putting together into systems.",
            "So here's a few examples of what I would think of as robot vision type systems.",
            "So for outdoor autonomous vehicle navigation, this is the Willow garage robot.",
            "Aiming to do you know for indoor assistive robotics guided by high level vision robot vacuum cleaners?",
            "Something that I work on?",
            "But then also these kind of systems here where again there systems working in real time in the real world and have to have the same kind of performance as these robot systems.",
            "So the particular problem that I've centered on is what we call symbol."
        ],
        [
            "Chinese localization and mapping.",
            "So it's the essential problem that a robot or another source of body faces when it's dropped into an unknown world.",
            "So if you drop a robot on Mars or even into your house where it's never been before, and it's going to start moving around that world, it's got to build a map of that space.",
            "If it wants to be able to localize in a repeatable manner so.",
            "SLAM is, as is the acronym for.",
            "This is a tricky problem because it has this kind of chicken and egg character.",
            "You're building a map of a space without knowing exactly where you are, and then you're going to be localising against that map as you build it.",
            "So it's basically a joint estimation problem of where are the things in the world and where is my position relative to those things.",
            "And it turns out to be very important to think carefully about the character of that joint estimation problem and make sure you understand all the kind of correlations.",
            "That are involved by the fact that you are estimating these things at the same time.",
            "So this is just a little animation of a classic Slam algorithm that proceeds basically by propagating uncertainty.",
            "So at any point in time you have an estimate of where the robot is in the world, and you have an estimate of where some elements in the world which we can call features or landmarks are, and basically at any point in time we have a joint probability distribution over the uncertain positions of those things.",
            "Which we basically update through."
        ],
        [
            "Time as the robot moves, has it."
        ],
        [
            "Search new landmark."
        ],
        [
            "As."
        ],
        [
            "Comes back re observes."
        ],
        [
            "Old landmarks, so basically you start exploring the world.",
            "You see new things, you put them into your map.",
            "They have big uncertainty because you've only seen them once or twice.",
            "But as you move around, see them again and again from lots of different angles.",
            "Every time you see something that's basically a measurement of where that thing is relative to you, and that can reduce your uncertainty in both where that thing is and where you are.",
            "But you have to take care of of how that happens in a correlated way."
        ],
        [
            "So the classic old algorithm for implementing SLAM is the extended common filter.",
            "So basically you can build a state vector of all of the things that you're interested in.",
            "So in this state vector we would have some number of parameters representing the position of the robot that's moving through the world, and then some number of parameters for each of these landmarks in the world that we're interested in estimating its position.",
            "So we build a big state vector with all of these things, and then we're going to propagate through time.",
            "This state vector, but also a matrix which is representing uncertainty in the state vector.",
            "So this is the thing that's representing the shape of those Gray... that you saw in the previous animation, representing uncertainty.",
            "So big vector even bigger matrix every time we get new measurements, we have to harvest those measurements, suck out the useful data and then use them to update this uncertain representation of where the robot is and where the features are.",
            "So I'll just show you this very briefly."
        ],
        [
            "This was my PhD work in Oxford and the robot that Taylor mentioned without an active stereo head called Yorick.",
            "So three wheeled robots and moving around on the ground plane and you see what's basically going on is it's cameras are flicking around.",
            "Picking up visual landmarks in the world, repeatedly coming back and observing the same things and every time it sees one of those landmarks, it's basically getting a fixated stereo measurements of the distance and bearing to one of those landmarks.",
            "So by putting all those measurements together in the common filter, it can actually estimate its motion.",
            "So this is a very speeded up video, of course, but this probably took about 5 minutes I think really, but it was working in real time.",
            "Skyrim here OK."
        ],
        [
            "This is the output of that system, so this is actually the same experiment you saw in the last video to estimated trajectory of the robot calculated in real time and estimated map of features.",
            "So each one of these was one visual landmark.",
            "It observed and the size of the ellipse around this feature reflects the final uncertainty in the position of that landmark after the whole navigation so."
        ],
        [
            "So that was that was fine, and you know, very interesting at the time.",
            "But but after that I really started to think OK, can we do pretty much the same thing, but stripping away a lot of the hardware complexity of that system?",
            "So can we go from this robot with a stereo moving cameras, will odometry and all of those things to a system.",
            "That's really just a camera in the hand.",
            "So just a camera connected to a computer flying through the world.",
            "But can we still solve basically the same thing?",
            "So can we estimate the motion of that camera through the world and build a map of what it sees?",
            "So this is what we call monocular slam.",
            "And clearly this is a nice thing to try to do.",
            "'cause if you manage to make this work, you've got basically a very general purpose, real time position and mapping sensor that you can put onto almost anything it can be carried by a person can be carried by, you know all sorts of robots are flying robot we've removed.",
            "You know the constraints of needing wheels and stereo and all that kind of thing.",
            "So that that's nice, but but on the other hand, it's quite a bit harder than than the robot system, because we've we've removed some of the constraints that made that system easier, so we don't know anymore that we're moving on a ground plane.",
            "We're going to assume 3D motion.",
            "We're going to assume the motions quite fast.",
            "In general, would like to track dynamic motion.",
            "And we're not going to kind of assume anything in advance.",
            "Particularly strong about what that motion is, so we don't have any Wheeler dormitory.",
            "For instance, giving us a prior, but we still want to do is to build a local map of an area which is persistent and essentially enables drift free localization.",
            "So I'll show you in a second of kind of steps that we've taken along this monocular slam route.",
            "So from the first time we made it.",
            "Work until the kind of systems we have today, but I think what I'd like to try and get across is how I think this is now evolving gradually from systems that can just basically estimate camera motion and build a pretty sparse map of the world into hopefully something that's getting closer to a general real time 3D perception and seeing understanding capability.",
            "So that's where I think we're trying to move towards.",
            "If you really want a vision system for a robot that could enable it to come into a house.",
            "And do jobs like clear tables or, you know, deal with all your heart and your washing or something.",
            "It's going to need to know a lot more than just where it is and a few landmarks around the room.",
            "It's going to have to understand an awful lot of things, but I think that this basic approach of a sequential model based probabilistic estimation of what's going on in the world always running in real time is a good good way of building up.",
            "And I think that research then meets other more high level vision research coming from different angles and.",
            "As we get more and more processing power, we can pull more and more things in and make it more sophisticated, so I think that's sort of the routes that we're trying to follow in my.",
            "In my lab.",
            "So this is this."
        ],
        [
            "So we called mono slam which was first working in 2003 and was the first time that we made this real time monocular slam work.",
            "So this video shows a few things about how the system.",
            "Basically works.",
            "So here's the basic setup.",
            "So as I said, a handheld camera so it's just a fairly basic webcam capturing at 30 frames per second.",
            "Was capturing 320 by 240 resolution images at this time and you get an idea for the kind of dynamics that we want to try and track so fairly unconstrained and the type of scenes.",
            "Fairly normal scenes that we'd like to be pointing their system app, so this is showing you the basic.",
            "Main processing that's going on.",
            "So from the video stream that's coming from that camera, we are extracting fairly standard sort of corner features and.",
            "Then we're trying to track those features through the scene, so there's a few things in this system that are a bit different from what's often done in other sort of structural motion pipelines and so on.",
            "So we're not necessarily detecting all the features we can see in every image we're detecting features when we need to, so this green box flashing around is basically hunting for new features in spaces that aren't already well covered by existing features, so you'll see that we're initializing new features as new bits of.",
            "The scene come into view and then once new features appear within tracking them very stable.",
            "So this is a little bit more on how the tracking works, so that's also not done.",
            "Bottom up, it's done in a very productive way, so on every frame we have a current estimate of where the camera is, a current estimate of where this the features are in the world.",
            "So the estimate of where the camera is now is basically where was it on the last frame plus some kind of motion prediction with their next run certainty added to it to account for the fact that it has uncertain dynamics.",
            "But that enables us to basically predict which features should be visible.",
            "But also where in the image should they you know are we most likely to find them?",
            "So we're basically dynamically calculating a search region for each of these features on each frame, and then we're basically trying to match each of those features by a correlation search just within the small prediction regions on each frame.",
            "And that was one of the things in the early days that made this system fast and able to work in real time.",
            "So this then shows the output of that system, so running in real time at 30 frames per second here this thing flying around is an estimated 3D position of the camera, so 6 degrees of freedom for position and rotation displayed here as a kind of flying graphic.",
            "And then each one of these things here is one of the landmarks in the scene, so you'll see that it has a texture Patch associated with it, which is kind of its unique identifier.",
            "And then here we now see a 3D.",
            "Ellipse representing the uncertainty region.",
            "So you see that when new features are initialized, they appear in the map with big uncertainty, particularly in the depth coordinate.",
            "As we make more and more measurements, that uncertainty shrinks down.",
            "So a demo of what we could do with this system is some augmented reality.",
            "So here we're basically going to put some virtual objects into a real video, so this is straightforward if you've got a system which is giving you in real time a 6 degree of freedom position for the camera.",
            "Reframe all you do is send that position to open GL and say draw me a shelf as if from that position stick it on top of the real video and then if you're the quality of your camera motion estimation is good, then those shelves should look like they're really stuck to the real world.",
            "And we've got some goodies here for adjusting there.",
            "Positions in the world so you can see at this stage that the results are are quite good.",
            "The shelves certainly stayed pretty much in the right place and you can see there's some jitter, particularly when there's some occlusion of some of the features.",
            "But it's not bad.",
            "So just to show a couple of other."
        ],
        [
            "Applications of exactly the same algorithm, so this was an application to a humanoid robot in lab in Japan that I was collaborating with.",
            "So this is just a sequence.",
            "The robot walks around in a circle.",
            "Disguise, just this is just a cradle to capture in case it falls over.",
            "But the robot basically walked around in a circle, and then there's a camera in its head that we were running monitor."
        ],
        [
            "I'm on.",
            "And so this is the view from that cameras.",
            "It works.",
            "And then this is the estimated.",
            "Camera trajectory and map of features from from mono slam so you can see that we walk right round in a circle.",
            "Building a map of features.",
            "And.",
            "There's yeah, but basically the same kind of behavior.",
            "This video is particularly interesting 'cause it shows a loop closure so the robot comes all the way around and there's a point where suddenly these.",
            "Uncertainties snap from being quite big to suddenly getting much smaller again, and that's happens when the robot comes all the way around the loop and is able to re observe things that it's all very early in its trajectory, so those are landmarks that have very accurate positions in the world 'cause it saw them close to the time when it defined its coordinate frame at the start of SLAM.",
            "So once it kind of re registers with those.",
            "The other features that it's initialized more recently get pulled round with it and snap into much better.",
            "Estimated positions.",
            "So that's kind of classic slam behavior."
        ],
        [
            "Here's another.",
            "Demo this is something I did with welfare email who's now?",
            "At the University of Bristol, and you probably saw her running MVC next year, but he built back in his PhD.",
            "This so really cool a wearable camera system that he called a wearable robot that had.",
            "A camera on basically a servo actuated platform.",
            "And then so someone was wearing that collar moving around in this scene and we could do things like tell the camera to stay fixated on one particular object as the president was moving around, and then siked to fixate on another object.",
            "And stay looking at that.",
            "So all enabled by real time position estimation from."
        ],
        [
            "From slam so since those days we've grown quite a lot in the sophistication of what we can do in real time visual slam.",
            "And there's been a number of things kind of going on around the world in more general slam research and a lot of this research is not necessarily been in computer vision.",
            "It's happening in robotics where people are building robot mapping systems using completely different sorts of sensors, like laser range finders, but still the general character of these mapping problems is very much shared.",
            "So for instance, we now have a pretty good understanding of how to make really large scale.",
            "Mapping systems because basically if you can make something that can make a good map locally similar to what you've already seen, you can then as you start exploring large areas just basically make a chain of these local Maps.",
            "So start building 1 map when that gets too big, park it, start a new one.",
            "But remember the transformation between them.",
            "You get a chain of connected Maps and then if you have another component this is often enabled by an image retrieval type vision system.",
            "They can basically say hang on, I've just grabbed an image that looks really similar to one I grabbed.",
            "You know, 20 minutes ago I think.",
            "I'm back in same place I've been before then, even if there's some drift that's a curd in these in your chain of local Maps, which is inevitable 'cause they'll always be a little bit of error in each local map.",
            "Then you can correct it.",
            "You can say are.",
            "So this place actually joins up to this.",
            "I'll now enforce that constraint and do some kind of optimization over my whole map.",
            "And this image retrieval part can now be quite fast and robust that the correction of the map can also be quite fast and robust these days, and you can get back to globally consistent Maps.",
            "Something else that's happened is, I think the general character of the slam problem as a graph estimate."
        ],
        [
            "And the problem is now very well understood.",
            "I mean it now seems kind of so obvious that you wonder why we didn't quite realize this 15 years ago, but we didn't wait.",
            "There was just a problem.",
            "We applied a common filter too, but of course a common filter is just one example of an algorithm of solving the general graph of the variables that you're interested in in the slam problem.",
            "So in this particular graph problems there are variables we want to estimate are the historical positions of their camera or robot.",
            "That moves through the world.",
            "These are the axes here and the positions of these landmarks that were able to observe in the world these.",
            "Otherwise we can't directly observe those what we can observe are these image measurements.",
            "So each of these image measurements is, for instance the image position of one image feature that we match in an image.",
            "It depends on one position of the camera and one landmark.",
            "So these are the things we want.",
            "We have to basically do inference on the graph to solve for the X is and the wise.",
            "And so once you understand, the more you know the general character of this problem, you realize this other algorithms than the common filter that you can use, and some of them have bigger."
        ],
        [
            "Big advantages so.",
            "Something particularly useful was when in 2007, claim Murray produced a system called Peetam, which basically solves exactly the same problem as mono slam, but does it much better and in particularly does it better because they were able to.",
            "I build Maps of thousands of features rather than a few dozens or hundreds, which is all we were able to do and they were able to do that by basically solving.",
            "This graph problem in in a slightly different way and basically bringing in what was previously an offline technique bundle adjustment, which is basically the you know, the global least squares solution to these kind of networks.",
            "They what they weren't doing is taking an ever growing network like this and always solving it from scratch on every frame.",
            "It had to be cleverer than that."
        ],
        [
            "They they were really choosing which of the past data to keep and which of the past data to throw away, but by some careful management.",
            "And then of course more computer power that lets you run bundle adjustment in real time on the second thread.",
            "Then they were able to get really good."
        ],
        [
            "Results in this peetam system."
        ],
        [
            "So we really took that on board.",
            "First of all, we did a piece of work to figure out why Peetam was really better than the common filtering method that we were previously using and we were able to prove it to ourselves.",
            "It with this kind of analysis.",
            "So this was an experiment that we actually did in simulation.",
            "So imagine you've got a camera which is just moving sideways for half a second.",
            "So during that time it captures.",
            "15 frames in front of it is a scene where it can potentially measure a lot of features, so potentially there's 400 features.",
            "It can make measurements of on the wall in front.",
            "So if you want to estimate the motion between here and here, the best possible way to do it is to take all of those frames, take all of the feature measurements in all of the frames, all of the correspondence is bundle, adjust the whole lot.",
            "Offline, expensive, but that gives you a good a good solution.",
            "So the question was what happens to that good solution if we start?",
            "Kind of taking away the data.",
            "So first of all we can remove the number of intermediate frames that we use and the other thing we can do is reduce the number of points that we use.",
            "So this is a graph basically showing accuracy, so high is good here.",
            "So at this maximum point of using all of the frames so up to 15 frames here and using all of the points we get really good accuracy as we start to degrade the number of frames and the number of points.",
            "The accuracy reduces, but the interesting thing is when you degrade the number of intermediate frames that you use, it doesn't degrade very much at all, whereas when you degrade the number of points that you use, it really degrades a lot so.",
            "Definitely the first you know.",
            "Thirty 5000 points are really important to get accuracy, but even going beyond that to 203 hundred 400 points, you're still gaining accuracy.",
            "So the importance of that in the comparison of a filter and bundle adjustment is when you look at the computational complexity of those algorithms, and it turns out that a filter is.",
            "It's no problem to filter to include lots of frames, but it's a big problem to include lots of features 'cause this state vector kind of gets enormous.",
            "The covariance matrix gets huge whereas bundle adjustment.",
            "It's no problem too.",
            "Increase the number of features, it's just computation proportional to the number of features, but it's not good to increase the number of frames, but when the accuracy is coming from the features rather than the frames, that means that when you want high accuracy, you're better off doing it by repeatedly solving from scratch in bundle adjustment.",
            "Then you are by trying to do some kind of filtering.",
            "So having kind of proven that to ourselves, we've now built various systems which are much more used.",
            "This bundle adjustment kind of component at their core."
        ],
        [
            "But taking into account.",
            "The other things that we know about slam about, you know dealing with large.",
            "Motions where we kind of use more of a local blocking approach went once we tried to go to really big scales and then loop closure and what's the right thing to do at loop closure?",
            "We now have systems like like this, so this is called double window optimization and it's worked from.",
            "ICD last year by my students are how cursed raised at, so he's got this very efficient and scalable now optimization engine for feature based slam.",
            "So this is just a simulation experiment where basically these are simulated camera positions and these are simulated point positions and it basically does bundle adjustment style optimization on 2 levels.",
            "So we're very local window around where the camera is right now.",
            "It does full bundle adjustment and outer window.",
            "It does a slightly more approximate pose graph optimization, which is something very well known by Slam people and then things that are really far away.",
            "It doesn't even bother to optimize the tool, but it kind of stays OK.",
            "So so then here's some real examples.",
            "So here's now a large scale kind of outdoor.",
            "Slam monocular slam problem using this double window optimization framework.",
            "So now we're building a map of this area which has got.",
            "I think it must have 10s or hundreds of thousands of features altogether.",
            "Here are the estimated camera motions and then there's loop closure that goes on and keeps it all.",
            "Fully consistent.",
            "I'm.",
            "Yeah, so I mean there are similar systems from various.",
            "Groups around the world, but now quite we can get quite good.",
            "Results on large scale self consistent slam using cameras.",
            "And running in real time.",
            "Anne.",
            "So kind of alongside that work, or really starting a bit more recently."
        ],
        [
            "We thought, OK, well right raising computer power and better understanding of algorithms have allowed us to.",
            "Get better performance in slam by mean that the main thing is dramatically increasing the number of landmarks that we're using, so we've gone from in mono slam.",
            "I probably had, you know, one landmark here on one here and one here and one here.",
            "That's all I know about the world.",
            "It's just a few points in the world in the you know, the denser point methods we've probably got maybe 50 points on that monitor, and you know, a few 100 points on the desk altogether, but it's still not really telling us about the scene.",
            "It is definitely enough to give us a good.",
            "Estimate of where the camera is, but going back to this original goal of can we move towards more general?",
            "You know scene understanding capability.",
            "We want to also start understanding the world.",
            "As well, so if you're want this to use this system in a robot, are situation, it's no good if you just know about some sparse landmarks, or that all that's really useful for his localization, it's not going to help you with path planning, 'cause whenever there's a gap between two landmarks, you don't know whether that's empty space or just a solid textureless wall that you haven't been able to detect.",
            "So if you want to do path planning or various sorts of interaction, you need more so.",
            "We started to think about can we do real time slam which starts to work not not on points but on whole surfaces.",
            "So this work, you know we started to be motivated and start.",
            "We started to think this might be possible when we saw these kind of results coming out of various labs.",
            "So for instance in 2007 at T Gratz they were demonstrating very accurate real time dense optical flow running on the GPU.",
            "So what this basically means is.",
            "Imagine you've got a video stream going coming into a computer, and between every pair of frames what they're producing.",
            "Is this, so it's basically a motion field and optical flow field between 2 images.",
            "But importantly, it's completely dense, so there's a flow vector here for every single pixel, and the quality of this flow field is incredibly good, so it's subpixel, accurate too.",
            "I think, way way beyond a 10th of a pixel or something like that.",
            "And it has very nice sharp motion boundaries.",
            "Sorry it is accurate and so so these are results you know which at the time were definitely close to the very best optical flow that people had done with very offline type of algorithms.",
            "But excitingly this was now running in real time so they were using GPU's.",
            "I'm showing much better results than anyone had ever done before in real time, so.",
            "Just a few more details about how those methods kind of work.",
            "So if you want to solve for."
        ],
        [
            "A solution for some something at every pixel.",
            "Then you need to do a kind of global optimization, so these global optimization methods such as are used in the optical flow.",
            "There can be used for other problems as well, such as denoising and and stereo, but the basic thing that they do is to take advantage of the of the fact that so for instance, in the optical flow problem you're got a camera pointed at the world, but the world is not a random point cloud.",
            "The world consists presumably of some kind of.",
            "Coherent objects, so therefore, if you can measure the motion vector at one pixel, it's likely that the motion vector of nearby pixels are similar to that.",
            "So essentially what they do is try to solve for a motion vector for every pixel such that the whole solution has some kind of smoothness property.",
            "So you need this smoothness because if you're doing something like optical flow, there are always going to be parts of images where there isn't enough information at that particular pixel.",
            "To give you an accurate estimate, just using that local information so in there all the previous SLAM stuff I've showed you, we were only tracking.",
            "Basically, Landmark feature points, so these are places that give you a high corner score.",
            "They are the highly textured points of an image.",
            "Those are the things that are easy to match between multiple images.",
            "But if we want to reconstruct surface is we've got to get matches for all of the things in between as well.",
            "And if we're thinking of something in the middle of a fairly untextured surface, you won't detect a corner there.",
            "If you try correlating that little Patch in the other image, it will kind of slide around and give you a pretty good match.",
            "Anywhere, so these methods they.",
            "They they solve simultaneously for a solution for all of the pixels at the same time where they trade off 2 terms.",
            "One that's saying as far as possible, I want the appearance of this Patch in this image to look like the Patch in the other image, but I'll trade that off against a requirement that the whole solution has to be smooth.",
            "And of course there's various ways of specifying smoothness.",
            "One that works well, for instance is what's called total variation, so it's it's a measure of the kind of absolute gradients.",
            "Between neighboring pixels across the whole image, the nice thing about this particular measure is it has this property of preserving edges, so it wants to kind of produce solutions where you've got nice smooth behavior over a certain region, but then it's happy for there to be a jump to another region so it doesn't have this behavior of blurring across edges, which wouldn't be very good.",
            "So I mentioned that those things were running on on GPU's and.",
            "I pretty much in fact every."
        ],
        [
            "Thing we're doing in my lab now is running on on GPU's and I think if you look at this graph you can really understand why.",
            "So this is so the ones down at the bottom here are basically Pentium class, kind of.",
            "Systems so CPU type systems and then the green is the curve of commodity GPU units that are now available.",
            "So this is the processing power that I was running mono slam on.",
            "This is the processing power that I have now inside this laptop.",
            "This this has a GTX 580 card.",
            "So 1500 gigaflops GPU's are easily the most powerful processing resource you have inside a commodity PC today.",
            "And if you're doing real time vision and you're not.",
            "Using those you know you're going to get left models behind, I think so, so you know you know, few years ago people were starting to use GPS.",
            "Now now it's much easier programming tools and so on are really quite quite usable.",
            "Of course, that means you have to take that fully into account when you design your algorithms.",
            "They have to be parallelizable, but if you can make parallelizable algorithms, you can now harness incredible power.",
            "So the first steps that we took in using these kind of methods was really a quite simp."
        ],
        [
            "Bolt together sort of approach.",
            "I mean at the time it was, it was incredibly hard work and so this was mainly down to Richard Newcomb who's.",
            "Kind of outstanding PhD students in my group.",
            "So what he did was bolted together several things.",
            "Basically he took peetam, which is the.",
            "The feature based slam system that I showed you earlier that comes from the University of Oxford.",
            "So this is basically a system that can use feature based slam to give very nice accurate real time camera tracking over a desktop size scene so we know where the camera is in real time.",
            "We can consider that done for now then what he wanted to do was to use actually the optical flow code from the University of Gratz.",
            "What that can do is to take.",
            "A pair of images and give you a high-quality.",
            "Dense matching field between them, so of course if you've got a dense matching field between between 2 images and you know the positions of the cameras that took the two images, so these are not two different cameras there 2 frames from our moving camera.",
            "Of course you can then triangulate each pair of matching pixels to make a depth map, and then once you've got a depth map and you know where the cameras where you can turn the depth map into a vertex map in 3D and then you can build lots of depth Maps.",
            "And you can stick them together into a whole dense scene reconstruction.",
            "It wasn't quite as straightforward as that.",
            "'cause actually, for the kind of motions we wanted.",
            "To get reasonable parallax for depth estimation, you want the camera to have some reasonable movement, but as soon as you move the camera too far, optical flow might not work anymore to match them.",
            "So we did something a little more sophisticated, which involved making a prediction of what the flow field would be using a rough surface fitted through the 3D slam points that we'd reconstructed and use that as a prediction to get the optical flow started.",
            "I mean, that's kind of a detail now.",
            "But just to show you, then the kind of reconstructions we could do.",
            "So this is now a desk desktop, so each one of the colored regions was one separate depth map, and then we can glue that all into a reconstruction of the whole scene.",
            "And these are just some different.",
            "Renderings, but you saw that we can texture map it.",
            "This is a normal map which gives you a good indication of whether you've got accurate reconstruction of the smooth surfaces.",
            "So a fun thing.",
            "That we can do with this is to revisit the augmented reality.",
            "Anne.",
            "Application but now with our new level of capability 'cause we don't just know where the camera is now we know what's in the scene.",
            "So we have a full model of this desktop scene.",
            "So now when we drop this virtual car into the scene, the green car is virtual.",
            "You can see, for instance we can make it disappear behind a real Cup 'cause we've got a model of the Cup.",
            "We know that the Cup should include the car.",
            "But the other thing we can do is actually make it physically interact with the scene.",
            "So we can make ramps out of.",
            "The stuff that we find in the scene.",
            "So this is just by loading the mesh that we've generated into free physics simulator.",
            "And then make the car drive around on the surface.",
            "So that was.",
            "That that system we could live dense reconstruction.",
            "And that was, you know, a big big advance at the time.",
            "But that still didn't fully satisfy us.",
            "'cause we were pretty much still riding the point based slam system and then using optical flow on top of that we wanted a slam system that was kind of dense throughout."
        ],
        [
            "So a piece of work there was relevant to this that another PhD students in my lab, Steve Lovegrove, did at the time.",
            "Was he boater?",
            "A slam system for Mosaicing so this is if you like so panoramic mosaicing is a type of simple slam problem where.",
            "You want to estimate the 3D rotation of camera so it's 3 degrees of freedom.",
            "It's only rotating, it's not translating, and you want to build a map, and a map is basically the Panorama, so there's no depth to that map, it's just lies on a sphere.",
            "But he did this by a whole image alignment approach, so there's no features in this system at all.",
            "What he's doing is he's building a map of the Panorama by basically laying down keyframes.",
            "He's the relative pose of the camera.",
            "All times is found by taking the live image and doing a whole image alignment using a whole image.",
            "Lucas Kanade type method to find out what's the transform of this live image that brings it into best alignment with the with the map that I've got where our alignment is measured by, you know, sum of squared differences.",
            "Overall overlapping pixels implements on the GPU, of course, so it's very fast.",
            "There's a pyramid implementation, so it goes from low resolution to high resolution that makes it.",
            "Faster and more robust still.",
            "And so he was able to track really quite fast motion against this mosaic.",
            "So obviously we can combine."
        ],
        [
            "Those last two things pretty much so.",
            "Once we've been able to build a dense surface model of this desktop type scene, whynott then turn off the point based slam system altogether, and justice now track the position of the camera by real time alignment of the images that I'm getting for the camera against the model.",
            "I mean, we've got a textured model of the world.",
            "I need to know where the camera is, so all I need to do is find the projection of the textured model that agrees as well as possible with my new.",
            "Live image and it's not.",
            "We don't have to solve that from scratch all the time because we knew where the camera was on the last frame.",
            "So it's basically a Lucas Kanade style optimization still, but now in six degrees of freedom rather than three, so we also made some improvements on the actual reconstruction part.",
            "So in this paper that we called the Tam which is released I CV last year were now."
        ],
        [
            "Not using the Gratz optical flow library anymore, we have our own variational GPU solver for depth Maps, which is directly solving for depth Maps rather than trying to fit optical flow into depth."
        ],
        [
            "That estimation"
        ],
        [
            "But then we're now doing tracking of the camera against this whole dense model.",
            "So here's an example.",
            "So here first of all, we're just showing building a model of this scene, so it's building several depth Maps.",
            "It's basically just sticking those depth Maps next to each other to make a reconstruction of the whole scene.",
            "So you can see this is, you know, the speed that it actually runs out.",
            "You can see how fast it's able to build the reconstruction and now we can show how tracking works.",
            "So this is a kind of per pixel.",
            "Demonstration of.",
            "So, so we're optimizing for the position of the camera by minimizing the difference between.",
            "The reprojected model and the live image, and there's a gating built into that as well.",
            "So if the difference is too big at any particular pixel, we throw that pixel away, and it's not used in the optimization, so that's what the yellow areas are here.",
            "They are the regions that have been gated out.",
            "So for instance, if there's something including and now here we have a head to head comparison of the quality of tracking.",
            "We can now get soapy time on the right there point based system, which is actually very very good software, very, very highly optimized.",
            "But now we're going to test it for really, really fast motion.",
            "So the quality of tracking is displayed by this augmented car.",
            "But if the tracking is good, it should stay in the same place.",
            "The tracking is not so good.",
            "You should see it wobble around so we can cope with rapid motion, fast shaking, and even more remarkably.",
            "We can just so just for the hell of it.",
            "We tried the focusing the camera here so all of the point features that P times using get wiped out, but our dense method is still tracking pretty well because dense methods which are just subtracting all the images in a pixel in an image are going to still give you something pretty sensible at at the essentially solution situation that you have.",
            "With the.",
            "With a defocused camera.",
            "OK, so we've continued to be interested in."
        ],
        [
            "Can we make tracking faster and faster and you know track faster and faster motion so this is something that I've been interested in for a long time, so these are some videos I made a few years ago just to illustrate this point to people.",
            "So here's a really fast motion that we might want to track.",
            "So I dangerously sellotaped of quite expensive camera to a football.",
            "And kicked it.",
            "OK, so that's a real time 25 frames per second video.",
            "This is the slow down view of the 25 frames per second video, so you can see this is a really hard scene to track because the motion from each frame to the next is.",
            "He's obviously vast.",
            "Here's the same sequence at 2000 frames per second.",
            "So it was actually captured at 100 frames per second and the previous ones were just subsamples.",
            "I showed you so this looks like a much more trackable video, so we're kind of an obvious thing that speed up the frame rate and the interframe jumps or less, and you got this nice smooth looking motion again, so we've always been interested in thinking I should we increase the frame rate of all of our tracking systems to make them more robust, and this is an old video not of my work, but from the University of Tokyo they built a custom 1000 Hertz.",
            "Vision system so this was 15 years ago I think, so it's a one bit per pixel.",
            "Very low resolution system, but they showed just how easy tracking becomes once you get up to really high frame rates.",
            "So Interestingly, as you increase frame rate, your computational costs does not go up proportional to to frame rate.",
            "So the big problem of course of going up to 200 frames per second in the tracker is you think, well I can't.",
            "I can't iterate that fast in a real time system, but if you're in any type of tracking system that uses prediction, so such as armana same system that calculated those dynamic search regions on every frame or this newer Lucas Kanade type thing will just if you initialize it from closer because the motion increment is smaller.",
            "It will converge faster 'cause it needs fewer iterations.",
            "So when you increase frame rate, the cost per frame actually goes down.",
            "So when you increase frame rate, the overall cost does go up."
        ],
        [
            "But it definitely goes up in a sub linear way.",
            "So what we've done most recently is we wanted to do some systematic kind of experimentation into what?"
        ],
        [
            "It happens when you increase frame rate in tracking, so these are this is a new paper that we're going to be presenting at.",
            "Ecv so to do some systematic experimentation on this.",
            "It was actually quite hard to think of setting up real experiments to do this, 'cause we'd need really fast, you know, robot type motion.",
            "In fact, my my student anchor handler is doing those experiments now, but what we had at the time we did the paper is we decided to set up a synthetic framework for these experiments.",
            "So we generated very high-quality, we think close to photo realistic video using Ray tracing and then simulation.",
            "Of realistic noise and blur to see what really.",
            "Search to really generate videos.",
            "So let me let me show you some of that.",
            "So first of all.",
            "There are some frames here from pure raytracing, so we have a very dramatic camera motion, so shaking camera.",
            "And this is a what a 20 Hertz video sequence looks like.",
            "So this is this is the result of pure raytracing.",
            "So you see it looks very clean.",
            "But you know, it's not it's nice quality, so these are what the individual frames look like.",
            "And now what we will see in a second is what happens if we now add realistic effects to that.",
            "So of course, when the frame rate is quite low, the exposure time of your camera can be high and therefore the main effect that you see in individual images is blur.",
            "So so look at this one now.",
            "So I think I can be fooled that that's quite quite real sometimes.",
            "So here we are synthesizing blur and we're synthesizing noise.",
            "So at 20 frames per second.",
            "We got really bad blur, but not so much noise.",
            "This is 100 frames per second video, so you probably can barely see it, 'cause it's really dark, of course.",
            "So once you increase increase frame rate a lot, you have to decrease the exposure time.",
            "Basically the images gets dark.",
            "Here, we've brightened the image.",
            "By stretching the color space so you can see.",
            "Basically, the large amount of noise that's now in that image.",
            "I'm not sure how.",
            "Visible that is on screen there think you can probably see those images are very noisy, but the interframe motion is much smaller, so you know how does.",
            "How do these things trade off?",
            "Sorry, but the full.",
            "Before results are in the paper, but just to give you."
        ],
        [
            "Kind of flavor.",
            "I mean there are lots of interesting questions here of, you know, as we start varying frame rate, we should also think about.",
            "Well, instead of varying frame rate, I might have got better results in a tracker by, for instance, increasing resolution that increases computational cost, but it might make my results better.",
            "So we compared those two things and then we evaluated the performance of track of the tracking in terms of accuracy, computational cost and robustness, and what we basically get is a kind of curves like these which show.",
            "Possible choices, so depending on the processing load that you so that you are able to support so the processing resource that you have is on this scale and then these show accuracy of tracking as a function of both frame rate and resolution.",
            "So along the kind of bottom of these overlapping curves there's an envelope of interesting operating points.",
            "Basically, where you for a certain processing load you get the best possible accuracy of your tracker and you'll see that you sort of switch off between.",
            "Increasing frame rate and increasing resolution.",
            "So this particular curve is 4.",
            "A situation where we had a super well lit scene.",
            "In that case then.",
            "Even at high frame rate, there's very little noise.",
            "In that case, it's very clearly saying to us we should be pushing frame rates up a lot."
        ],
        [
            "So why not run our trackers at multiple hundreds of Hertz?",
            "There's no reason not to as well.",
            "It seems to be saying that's not quite so strong in real, more realistic lighting conditions where the thing against you going to really high frame rates is that the exposure time gets really short on your images.",
            "Get too noisy.",
            "Anyway, I still think there's a lot more research to do in this area.",
            "OK, so I'm going to show you just this last thing and hopefully a very quick demo before I run out of time."
        ],
        [
            "So the last thing was I showed you the reconstruction parts of the system where we're able to build depth Maps quite nicely, but in the in the videos I've shown you so far, those depth Maps are pretty much just put next to each other, and that's not a bad way of making a reconstruction of a scene.",
            "But of course pretty soon we're going to make depth Maps which overlap with each other.",
            "So if we are getting lots of depth Maps in the same place.",
            "Can we start fusing them into a much more representative scene representation?",
            "And ideally we'd like something which can represent arbitrary topology of surfaces in a scene so.",
            "Richard Newcomb, the same student who did the dense reconstruction work after that, went to do.",
            "He did an internship at Microsoft Cambridge, and while he was there, he got early access to this.",
            "The Connect camera and what that basically enabled was to think about OK.",
            "It was really, really hard to get good depth Maps from a single camera.",
            "This thing just pumps depth Maps out at me with no effort at all at 30 frames per second.",
            "So this is a good way to really start working on this problem of how can I fuse?",
            "Depth Maps and how and what do I achieve by doing that?",
            "So after having done that, he came back and has now done the same thing with a single camera and it's actually even even cooler.",
            "But just to show you what connect Fusion does, which is what this system is.",
            "So so the."
        ],
        [
            "The representation that it's using for the geometry of the world is a volumetric representation called the same distance function.",
            "So essentially you say I'm going to try and reconstruct a volume of space.",
            "I'll define a regular grid of voxels over that space, and then what I'm going to represent at every voxel of that grid is the estimated distance to the closest surface to that Vauxhall, so it has a has a sign such that.",
            "Free space which is in front of services has a positive distance and space which is behind services has a negative distance and the interpretation is that the crossing point from positive to negative.",
            "The Zero crossing is where the surface is, so you can later on go through with marching cubes or something and pull out a surface.",
            "If you want to make a mesh.",
            "So essentially we're grabbing lots of depth Maps were estimating where the motion of the can."
        ],
        [
            "Where is all the time so important Lee in in connect Fusion?",
            "We do that by not by any kind of frame to frame estimation, but we're always estimating the position of the camera by aligning it against the current fused model.",
            "So we're projecting the signed distance function.",
            "And then optimizing to such that the current camera pose is consistent with an observation of the full kind of fused."
        ],
        [
            "Volumetric"
        ],
        [
            "Model so they re fused images together."
        ],
        [
            "Get something like this, so let me just try a quick.",
            "Live demo.",
            "Cassie to come down to 'cause I think we need.",
            "We need a volunteer for this.",
            "He sure.",
            "I keep my head know anything should be fine, so if you'd like to sit there.",
            "OK, let's try this so yeah.",
            "OK, so you just gotta sit very still basically so choose how you want to sit and train, train, stay still.",
            "So yeah, here's their connect camera so you can see this is basically the raw output of a Connect camera turned into a.",
            "Basically a mesh here with a Fang.",
            "Rendering, so that's what a single Connect image looks like.",
            "You can see it's you know it's actually amazing what it gives you.",
            "Basically is the main word for it, but it's kind of noisy and it has gaps.",
            "So when you pointed at certain things like a monitor, you'll see there are gaps where the reflection doesn't really come back strongly.",
            "But what we do in connect Fusion is we're not just taking single images, we're going to start fusing them.",
            "So once I.",
            "Hit this button here.",
            "We're taking the stream of.",
            "Images and we're actually fusing them all into the same distance function, and you'll see this, so we now get this.",
            "Reconstruction, which is much smoother.",
            "And we should be able to go round and.",
            "Selling all of the holes.",
            "So everything is being done just from the raw depth map from connect, so there's no kind of external sensing tracking the position of this camera, it's all purely done to trans Transit.",
            "Still, if it's got lost, OK.",
            "I think I've probably moved too fast or something, but let's see if we should still have the model there.",
            "So this shows you their model that we've built.",
            "We've only really been able to look at this.",
            "This side let's just.",
            "Maybe I'll just have one more try and be a bit more careful.",
            "OK, ready to stay still.",
            "OK, so it's still tracking string around the back so you will see in some places that kind of limits of the volume that we set up, so it's only reconstructing things within that volume.",
            "So basically the size of this volume is currently mainly limited by memory, so.",
            "I think that's already lost track again, so we're already easily filling up.",
            "Yeah thanks.",
            "You can relax now.",
            "Thanks a lot.",
            "Let me just do this OK, so it's still still there.",
            "So yeah, so there's no kind of limit to topology we can go right right round people and so on.",
            "And you know, the more time you spend scanning in a certain area, the higher higher quality.",
            "You'll get.",
            "And then we can of course write write these.",
            "Meshes out, maybe I can just show you one like we captured in slightly more controlled.",
            "Circumstances.",
            "India should have done this.",
            "I know.",
            "So just open this one in meshlab.",
            "So basically scanning people is really good fun.",
            "We've had some people who've actually tried to 3D print knees and so on.",
            "I'm sure you can recognize who this is.",
            "And that works quite well too, so probably a lot of people will want to.",
            "Try this kind of system out and I think there's various pieces of software like this that will be coming out around the world.",
            "There are already some independent implementations of connect Fusion.",
            "Anne.",
            "So you can probably try playing around with something at yourself and we will hopefully be releasing Richards.",
            "Version of the code sometimes seem OK, so I'll just finish by showing you this."
        ],
        [
            "Video, which is results for signed distance function Fusion using now a single camera so the depth Maps are now being built by a single moving camera and then refusing all of those into a signed distance function and you can see where now you can actually pick out more detail from this single camera stereo type method.",
            "Then you can from connect 'cause connects resolution is ultimately a bit limited so we're picking out things like small cables.",
            "In this computer here.",
            "So I think a very nice point to finish on is just to compare these kind of results to the Mono Slam video that I showed you near the start and to make the point that you know is the same input right?",
            "It's a single camera moving through space.",
            "Maybe it's a slightly better camera, but not much, and it's basically the same commodity hardware, so in both cases those systems were running on 1500 pound laptops of the day with nothing else, a camera and a laptop.",
            "So I put most of that improvement down to processing.",
            "And how much that has?"
        ],
        [
            "Increased but yeah, very mind what's going to happen in the next 8 eight years.",
            "I think it's going to be a staggering so.",
            "OK, thanks a lot."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to talk to you really give you a bit of a run through for various work that I've been doing over the last 15 years, really, since the period that Terry was talking about when I was doing my PhD.",
                    "label": 0
                },
                {
                    "sent": "But hopefully you'll see there's some kind of meaningful kind of flow to to the research that I've been doing in this area of monocular slam and real time scene perception so.",
                    "label": 1
                },
                {
                    "sent": "Maya laugh now at Imperial College.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Call it the the Robot Vision Lab and I feel like that in captures what I'm interested in quite well, so I'm interested in computer vision, but computer vision that works in a context that might be useful for robotics, but probably also for other things, so we're interested in vision systems that work in the real world, and pretty much always in real time in a real time loop, and possibly that could be used for something some application, although.",
                    "label": 0
                },
                {
                    "sent": "You know, there's not always a an application for these systems.",
                    "label": 0
                },
                {
                    "sent": "I'll show you and I think something I've really observed is that the fast progress of research in this robot vision area over there.",
                    "label": 0
                },
                {
                    "sent": "Were not.",
                    "label": 0
                },
                {
                    "sent": "Since I've been working in it, and I put that down to several reasons, the one that we should never underestimate is the continuing exponential increase in low cost computer power.",
                    "label": 1
                },
                {
                    "sent": "That just means that we can do things now work that were completely unimaginable.",
                    "label": 0
                },
                {
                    "sent": "10 or 15 years ago, and hopefully I'll show you some good examples of that.",
                    "label": 0
                },
                {
                    "sent": "I think we've got a good common understanding of the key principles of dealing with uncertain data that you get from real sensors in the real world and how to combine those.",
                    "label": 1
                },
                {
                    "sent": "And then another very important thing is think there's a wealth of tools out there, things that people know really work.",
                    "label": 0
                },
                {
                    "sent": "So these are algorithms in papers, but also pieces of code that people can just download and start putting together into systems.",
                    "label": 0
                },
                {
                    "sent": "So here's a few examples of what I would think of as robot vision type systems.",
                    "label": 0
                },
                {
                    "sent": "So for outdoor autonomous vehicle navigation, this is the Willow garage robot.",
                    "label": 0
                },
                {
                    "sent": "Aiming to do you know for indoor assistive robotics guided by high level vision robot vacuum cleaners?",
                    "label": 0
                },
                {
                    "sent": "Something that I work on?",
                    "label": 0
                },
                {
                    "sent": "But then also these kind of systems here where again there systems working in real time in the real world and have to have the same kind of performance as these robot systems.",
                    "label": 0
                },
                {
                    "sent": "So the particular problem that I've centered on is what we call symbol.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Chinese localization and mapping.",
                    "label": 0
                },
                {
                    "sent": "So it's the essential problem that a robot or another source of body faces when it's dropped into an unknown world.",
                    "label": 1
                },
                {
                    "sent": "So if you drop a robot on Mars or even into your house where it's never been before, and it's going to start moving around that world, it's got to build a map of that space.",
                    "label": 0
                },
                {
                    "sent": "If it wants to be able to localize in a repeatable manner so.",
                    "label": 0
                },
                {
                    "sent": "SLAM is, as is the acronym for.",
                    "label": 0
                },
                {
                    "sent": "This is a tricky problem because it has this kind of chicken and egg character.",
                    "label": 0
                },
                {
                    "sent": "You're building a map of a space without knowing exactly where you are, and then you're going to be localising against that map as you build it.",
                    "label": 0
                },
                {
                    "sent": "So it's basically a joint estimation problem of where are the things in the world and where is my position relative to those things.",
                    "label": 0
                },
                {
                    "sent": "And it turns out to be very important to think carefully about the character of that joint estimation problem and make sure you understand all the kind of correlations.",
                    "label": 0
                },
                {
                    "sent": "That are involved by the fact that you are estimating these things at the same time.",
                    "label": 0
                },
                {
                    "sent": "So this is just a little animation of a classic Slam algorithm that proceeds basically by propagating uncertainty.",
                    "label": 0
                },
                {
                    "sent": "So at any point in time you have an estimate of where the robot is in the world, and you have an estimate of where some elements in the world which we can call features or landmarks are, and basically at any point in time we have a joint probability distribution over the uncertain positions of those things.",
                    "label": 0
                },
                {
                    "sent": "Which we basically update through.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time as the robot moves, has it.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Search new landmark.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Comes back re observes.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Old landmarks, so basically you start exploring the world.",
                    "label": 0
                },
                {
                    "sent": "You see new things, you put them into your map.",
                    "label": 0
                },
                {
                    "sent": "They have big uncertainty because you've only seen them once or twice.",
                    "label": 0
                },
                {
                    "sent": "But as you move around, see them again and again from lots of different angles.",
                    "label": 0
                },
                {
                    "sent": "Every time you see something that's basically a measurement of where that thing is relative to you, and that can reduce your uncertainty in both where that thing is and where you are.",
                    "label": 0
                },
                {
                    "sent": "But you have to take care of of how that happens in a correlated way.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the classic old algorithm for implementing SLAM is the extended common filter.",
                    "label": 0
                },
                {
                    "sent": "So basically you can build a state vector of all of the things that you're interested in.",
                    "label": 0
                },
                {
                    "sent": "So in this state vector we would have some number of parameters representing the position of the robot that's moving through the world, and then some number of parameters for each of these landmarks in the world that we're interested in estimating its position.",
                    "label": 0
                },
                {
                    "sent": "So we build a big state vector with all of these things, and then we're going to propagate through time.",
                    "label": 0
                },
                {
                    "sent": "This state vector, but also a matrix which is representing uncertainty in the state vector.",
                    "label": 0
                },
                {
                    "sent": "So this is the thing that's representing the shape of those Gray... that you saw in the previous animation, representing uncertainty.",
                    "label": 0
                },
                {
                    "sent": "So big vector even bigger matrix every time we get new measurements, we have to harvest those measurements, suck out the useful data and then use them to update this uncertain representation of where the robot is and where the features are.",
                    "label": 0
                },
                {
                    "sent": "So I'll just show you this very briefly.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This was my PhD work in Oxford and the robot that Taylor mentioned without an active stereo head called Yorick.",
                    "label": 0
                },
                {
                    "sent": "So three wheeled robots and moving around on the ground plane and you see what's basically going on is it's cameras are flicking around.",
                    "label": 0
                },
                {
                    "sent": "Picking up visual landmarks in the world, repeatedly coming back and observing the same things and every time it sees one of those landmarks, it's basically getting a fixated stereo measurements of the distance and bearing to one of those landmarks.",
                    "label": 0
                },
                {
                    "sent": "So by putting all those measurements together in the common filter, it can actually estimate its motion.",
                    "label": 0
                },
                {
                    "sent": "So this is a very speeded up video, of course, but this probably took about 5 minutes I think really, but it was working in real time.",
                    "label": 0
                },
                {
                    "sent": "Skyrim here OK.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the output of that system, so this is actually the same experiment you saw in the last video to estimated trajectory of the robot calculated in real time and estimated map of features.",
                    "label": 0
                },
                {
                    "sent": "So each one of these was one visual landmark.",
                    "label": 0
                },
                {
                    "sent": "It observed and the size of the ellipse around this feature reflects the final uncertainty in the position of that landmark after the whole navigation so.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that was that was fine, and you know, very interesting at the time.",
                    "label": 0
                },
                {
                    "sent": "But but after that I really started to think OK, can we do pretty much the same thing, but stripping away a lot of the hardware complexity of that system?",
                    "label": 0
                },
                {
                    "sent": "So can we go from this robot with a stereo moving cameras, will odometry and all of those things to a system.",
                    "label": 0
                },
                {
                    "sent": "That's really just a camera in the hand.",
                    "label": 0
                },
                {
                    "sent": "So just a camera connected to a computer flying through the world.",
                    "label": 0
                },
                {
                    "sent": "But can we still solve basically the same thing?",
                    "label": 1
                },
                {
                    "sent": "So can we estimate the motion of that camera through the world and build a map of what it sees?",
                    "label": 0
                },
                {
                    "sent": "So this is what we call monocular slam.",
                    "label": 1
                },
                {
                    "sent": "And clearly this is a nice thing to try to do.",
                    "label": 0
                },
                {
                    "sent": "'cause if you manage to make this work, you've got basically a very general purpose, real time position and mapping sensor that you can put onto almost anything it can be carried by a person can be carried by, you know all sorts of robots are flying robot we've removed.",
                    "label": 0
                },
                {
                    "sent": "You know the constraints of needing wheels and stereo and all that kind of thing.",
                    "label": 0
                },
                {
                    "sent": "So that that's nice, but but on the other hand, it's quite a bit harder than than the robot system, because we've we've removed some of the constraints that made that system easier, so we don't know anymore that we're moving on a ground plane.",
                    "label": 0
                },
                {
                    "sent": "We're going to assume 3D motion.",
                    "label": 1
                },
                {
                    "sent": "We're going to assume the motions quite fast.",
                    "label": 0
                },
                {
                    "sent": "In general, would like to track dynamic motion.",
                    "label": 0
                },
                {
                    "sent": "And we're not going to kind of assume anything in advance.",
                    "label": 0
                },
                {
                    "sent": "Particularly strong about what that motion is, so we don't have any Wheeler dormitory.",
                    "label": 0
                },
                {
                    "sent": "For instance, giving us a prior, but we still want to do is to build a local map of an area which is persistent and essentially enables drift free localization.",
                    "label": 0
                },
                {
                    "sent": "So I'll show you in a second of kind of steps that we've taken along this monocular slam route.",
                    "label": 0
                },
                {
                    "sent": "So from the first time we made it.",
                    "label": 0
                },
                {
                    "sent": "Work until the kind of systems we have today, but I think what I'd like to try and get across is how I think this is now evolving gradually from systems that can just basically estimate camera motion and build a pretty sparse map of the world into hopefully something that's getting closer to a general real time 3D perception and seeing understanding capability.",
                    "label": 1
                },
                {
                    "sent": "So that's where I think we're trying to move towards.",
                    "label": 1
                },
                {
                    "sent": "If you really want a vision system for a robot that could enable it to come into a house.",
                    "label": 0
                },
                {
                    "sent": "And do jobs like clear tables or, you know, deal with all your heart and your washing or something.",
                    "label": 0
                },
                {
                    "sent": "It's going to need to know a lot more than just where it is and a few landmarks around the room.",
                    "label": 0
                },
                {
                    "sent": "It's going to have to understand an awful lot of things, but I think that this basic approach of a sequential model based probabilistic estimation of what's going on in the world always running in real time is a good good way of building up.",
                    "label": 0
                },
                {
                    "sent": "And I think that research then meets other more high level vision research coming from different angles and.",
                    "label": 0
                },
                {
                    "sent": "As we get more and more processing power, we can pull more and more things in and make it more sophisticated, so I think that's sort of the routes that we're trying to follow in my.",
                    "label": 0
                },
                {
                    "sent": "In my lab.",
                    "label": 0
                },
                {
                    "sent": "So this is this.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we called mono slam which was first working in 2003 and was the first time that we made this real time monocular slam work.",
                    "label": 0
                },
                {
                    "sent": "So this video shows a few things about how the system.",
                    "label": 0
                },
                {
                    "sent": "Basically works.",
                    "label": 0
                },
                {
                    "sent": "So here's the basic setup.",
                    "label": 0
                },
                {
                    "sent": "So as I said, a handheld camera so it's just a fairly basic webcam capturing at 30 frames per second.",
                    "label": 0
                },
                {
                    "sent": "Was capturing 320 by 240 resolution images at this time and you get an idea for the kind of dynamics that we want to try and track so fairly unconstrained and the type of scenes.",
                    "label": 0
                },
                {
                    "sent": "Fairly normal scenes that we'd like to be pointing their system app, so this is showing you the basic.",
                    "label": 0
                },
                {
                    "sent": "Main processing that's going on.",
                    "label": 0
                },
                {
                    "sent": "So from the video stream that's coming from that camera, we are extracting fairly standard sort of corner features and.",
                    "label": 0
                },
                {
                    "sent": "Then we're trying to track those features through the scene, so there's a few things in this system that are a bit different from what's often done in other sort of structural motion pipelines and so on.",
                    "label": 0
                },
                {
                    "sent": "So we're not necessarily detecting all the features we can see in every image we're detecting features when we need to, so this green box flashing around is basically hunting for new features in spaces that aren't already well covered by existing features, so you'll see that we're initializing new features as new bits of.",
                    "label": 0
                },
                {
                    "sent": "The scene come into view and then once new features appear within tracking them very stable.",
                    "label": 0
                },
                {
                    "sent": "So this is a little bit more on how the tracking works, so that's also not done.",
                    "label": 0
                },
                {
                    "sent": "Bottom up, it's done in a very productive way, so on every frame we have a current estimate of where the camera is, a current estimate of where this the features are in the world.",
                    "label": 0
                },
                {
                    "sent": "So the estimate of where the camera is now is basically where was it on the last frame plus some kind of motion prediction with their next run certainty added to it to account for the fact that it has uncertain dynamics.",
                    "label": 0
                },
                {
                    "sent": "But that enables us to basically predict which features should be visible.",
                    "label": 0
                },
                {
                    "sent": "But also where in the image should they you know are we most likely to find them?",
                    "label": 0
                },
                {
                    "sent": "So we're basically dynamically calculating a search region for each of these features on each frame, and then we're basically trying to match each of those features by a correlation search just within the small prediction regions on each frame.",
                    "label": 0
                },
                {
                    "sent": "And that was one of the things in the early days that made this system fast and able to work in real time.",
                    "label": 0
                },
                {
                    "sent": "So this then shows the output of that system, so running in real time at 30 frames per second here this thing flying around is an estimated 3D position of the camera, so 6 degrees of freedom for position and rotation displayed here as a kind of flying graphic.",
                    "label": 0
                },
                {
                    "sent": "And then each one of these things here is one of the landmarks in the scene, so you'll see that it has a texture Patch associated with it, which is kind of its unique identifier.",
                    "label": 0
                },
                {
                    "sent": "And then here we now see a 3D.",
                    "label": 0
                },
                {
                    "sent": "Ellipse representing the uncertainty region.",
                    "label": 0
                },
                {
                    "sent": "So you see that when new features are initialized, they appear in the map with big uncertainty, particularly in the depth coordinate.",
                    "label": 0
                },
                {
                    "sent": "As we make more and more measurements, that uncertainty shrinks down.",
                    "label": 0
                },
                {
                    "sent": "So a demo of what we could do with this system is some augmented reality.",
                    "label": 0
                },
                {
                    "sent": "So here we're basically going to put some virtual objects into a real video, so this is straightforward if you've got a system which is giving you in real time a 6 degree of freedom position for the camera.",
                    "label": 0
                },
                {
                    "sent": "Reframe all you do is send that position to open GL and say draw me a shelf as if from that position stick it on top of the real video and then if you're the quality of your camera motion estimation is good, then those shelves should look like they're really stuck to the real world.",
                    "label": 0
                },
                {
                    "sent": "And we've got some goodies here for adjusting there.",
                    "label": 0
                },
                {
                    "sent": "Positions in the world so you can see at this stage that the results are are quite good.",
                    "label": 0
                },
                {
                    "sent": "The shelves certainly stayed pretty much in the right place and you can see there's some jitter, particularly when there's some occlusion of some of the features.",
                    "label": 0
                },
                {
                    "sent": "But it's not bad.",
                    "label": 0
                },
                {
                    "sent": "So just to show a couple of other.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Applications of exactly the same algorithm, so this was an application to a humanoid robot in lab in Japan that I was collaborating with.",
                    "label": 0
                },
                {
                    "sent": "So this is just a sequence.",
                    "label": 0
                },
                {
                    "sent": "The robot walks around in a circle.",
                    "label": 0
                },
                {
                    "sent": "Disguise, just this is just a cradle to capture in case it falls over.",
                    "label": 0
                },
                {
                    "sent": "But the robot basically walked around in a circle, and then there's a camera in its head that we were running monitor.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm on.",
                    "label": 0
                },
                {
                    "sent": "And so this is the view from that cameras.",
                    "label": 0
                },
                {
                    "sent": "It works.",
                    "label": 0
                },
                {
                    "sent": "And then this is the estimated.",
                    "label": 0
                },
                {
                    "sent": "Camera trajectory and map of features from from mono slam so you can see that we walk right round in a circle.",
                    "label": 0
                },
                {
                    "sent": "Building a map of features.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "There's yeah, but basically the same kind of behavior.",
                    "label": 0
                },
                {
                    "sent": "This video is particularly interesting 'cause it shows a loop closure so the robot comes all the way around and there's a point where suddenly these.",
                    "label": 1
                },
                {
                    "sent": "Uncertainties snap from being quite big to suddenly getting much smaller again, and that's happens when the robot comes all the way around the loop and is able to re observe things that it's all very early in its trajectory, so those are landmarks that have very accurate positions in the world 'cause it saw them close to the time when it defined its coordinate frame at the start of SLAM.",
                    "label": 0
                },
                {
                    "sent": "So once it kind of re registers with those.",
                    "label": 0
                },
                {
                    "sent": "The other features that it's initialized more recently get pulled round with it and snap into much better.",
                    "label": 0
                },
                {
                    "sent": "Estimated positions.",
                    "label": 0
                },
                {
                    "sent": "So that's kind of classic slam behavior.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's another.",
                    "label": 0
                },
                {
                    "sent": "Demo this is something I did with welfare email who's now?",
                    "label": 0
                },
                {
                    "sent": "At the University of Bristol, and you probably saw her running MVC next year, but he built back in his PhD.",
                    "label": 0
                },
                {
                    "sent": "This so really cool a wearable camera system that he called a wearable robot that had.",
                    "label": 1
                },
                {
                    "sent": "A camera on basically a servo actuated platform.",
                    "label": 0
                },
                {
                    "sent": "And then so someone was wearing that collar moving around in this scene and we could do things like tell the camera to stay fixated on one particular object as the president was moving around, and then siked to fixate on another object.",
                    "label": 0
                },
                {
                    "sent": "And stay looking at that.",
                    "label": 0
                },
                {
                    "sent": "So all enabled by real time position estimation from.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From slam so since those days we've grown quite a lot in the sophistication of what we can do in real time visual slam.",
                    "label": 0
                },
                {
                    "sent": "And there's been a number of things kind of going on around the world in more general slam research and a lot of this research is not necessarily been in computer vision.",
                    "label": 0
                },
                {
                    "sent": "It's happening in robotics where people are building robot mapping systems using completely different sorts of sensors, like laser range finders, but still the general character of these mapping problems is very much shared.",
                    "label": 0
                },
                {
                    "sent": "So for instance, we now have a pretty good understanding of how to make really large scale.",
                    "label": 0
                },
                {
                    "sent": "Mapping systems because basically if you can make something that can make a good map locally similar to what you've already seen, you can then as you start exploring large areas just basically make a chain of these local Maps.",
                    "label": 0
                },
                {
                    "sent": "So start building 1 map when that gets too big, park it, start a new one.",
                    "label": 0
                },
                {
                    "sent": "But remember the transformation between them.",
                    "label": 0
                },
                {
                    "sent": "You get a chain of connected Maps and then if you have another component this is often enabled by an image retrieval type vision system.",
                    "label": 0
                },
                {
                    "sent": "They can basically say hang on, I've just grabbed an image that looks really similar to one I grabbed.",
                    "label": 0
                },
                {
                    "sent": "You know, 20 minutes ago I think.",
                    "label": 0
                },
                {
                    "sent": "I'm back in same place I've been before then, even if there's some drift that's a curd in these in your chain of local Maps, which is inevitable 'cause they'll always be a little bit of error in each local map.",
                    "label": 0
                },
                {
                    "sent": "Then you can correct it.",
                    "label": 0
                },
                {
                    "sent": "You can say are.",
                    "label": 0
                },
                {
                    "sent": "So this place actually joins up to this.",
                    "label": 0
                },
                {
                    "sent": "I'll now enforce that constraint and do some kind of optimization over my whole map.",
                    "label": 0
                },
                {
                    "sent": "And this image retrieval part can now be quite fast and robust that the correction of the map can also be quite fast and robust these days, and you can get back to globally consistent Maps.",
                    "label": 0
                },
                {
                    "sent": "Something else that's happened is, I think the general character of the slam problem as a graph estimate.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the problem is now very well understood.",
                    "label": 0
                },
                {
                    "sent": "I mean it now seems kind of so obvious that you wonder why we didn't quite realize this 15 years ago, but we didn't wait.",
                    "label": 0
                },
                {
                    "sent": "There was just a problem.",
                    "label": 0
                },
                {
                    "sent": "We applied a common filter too, but of course a common filter is just one example of an algorithm of solving the general graph of the variables that you're interested in in the slam problem.",
                    "label": 0
                },
                {
                    "sent": "So in this particular graph problems there are variables we want to estimate are the historical positions of their camera or robot.",
                    "label": 0
                },
                {
                    "sent": "That moves through the world.",
                    "label": 0
                },
                {
                    "sent": "These are the axes here and the positions of these landmarks that were able to observe in the world these.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we can't directly observe those what we can observe are these image measurements.",
                    "label": 0
                },
                {
                    "sent": "So each of these image measurements is, for instance the image position of one image feature that we match in an image.",
                    "label": 0
                },
                {
                    "sent": "It depends on one position of the camera and one landmark.",
                    "label": 0
                },
                {
                    "sent": "So these are the things we want.",
                    "label": 0
                },
                {
                    "sent": "We have to basically do inference on the graph to solve for the X is and the wise.",
                    "label": 0
                },
                {
                    "sent": "And so once you understand, the more you know the general character of this problem, you realize this other algorithms than the common filter that you can use, and some of them have bigger.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Big advantages so.",
                    "label": 0
                },
                {
                    "sent": "Something particularly useful was when in 2007, claim Murray produced a system called Peetam, which basically solves exactly the same problem as mono slam, but does it much better and in particularly does it better because they were able to.",
                    "label": 0
                },
                {
                    "sent": "I build Maps of thousands of features rather than a few dozens or hundreds, which is all we were able to do and they were able to do that by basically solving.",
                    "label": 0
                },
                {
                    "sent": "This graph problem in in a slightly different way and basically bringing in what was previously an offline technique bundle adjustment, which is basically the you know, the global least squares solution to these kind of networks.",
                    "label": 0
                },
                {
                    "sent": "They what they weren't doing is taking an ever growing network like this and always solving it from scratch on every frame.",
                    "label": 0
                },
                {
                    "sent": "It had to be cleverer than that.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They they were really choosing which of the past data to keep and which of the past data to throw away, but by some careful management.",
                    "label": 0
                },
                {
                    "sent": "And then of course more computer power that lets you run bundle adjustment in real time on the second thread.",
                    "label": 0
                },
                {
                    "sent": "Then they were able to get really good.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Results in this peetam system.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we really took that on board.",
                    "label": 0
                },
                {
                    "sent": "First of all, we did a piece of work to figure out why Peetam was really better than the common filtering method that we were previously using and we were able to prove it to ourselves.",
                    "label": 0
                },
                {
                    "sent": "It with this kind of analysis.",
                    "label": 0
                },
                {
                    "sent": "So this was an experiment that we actually did in simulation.",
                    "label": 0
                },
                {
                    "sent": "So imagine you've got a camera which is just moving sideways for half a second.",
                    "label": 0
                },
                {
                    "sent": "So during that time it captures.",
                    "label": 0
                },
                {
                    "sent": "15 frames in front of it is a scene where it can potentially measure a lot of features, so potentially there's 400 features.",
                    "label": 0
                },
                {
                    "sent": "It can make measurements of on the wall in front.",
                    "label": 0
                },
                {
                    "sent": "So if you want to estimate the motion between here and here, the best possible way to do it is to take all of those frames, take all of the feature measurements in all of the frames, all of the correspondence is bundle, adjust the whole lot.",
                    "label": 0
                },
                {
                    "sent": "Offline, expensive, but that gives you a good a good solution.",
                    "label": 0
                },
                {
                    "sent": "So the question was what happens to that good solution if we start?",
                    "label": 0
                },
                {
                    "sent": "Kind of taking away the data.",
                    "label": 0
                },
                {
                    "sent": "So first of all we can remove the number of intermediate frames that we use and the other thing we can do is reduce the number of points that we use.",
                    "label": 0
                },
                {
                    "sent": "So this is a graph basically showing accuracy, so high is good here.",
                    "label": 0
                },
                {
                    "sent": "So at this maximum point of using all of the frames so up to 15 frames here and using all of the points we get really good accuracy as we start to degrade the number of frames and the number of points.",
                    "label": 0
                },
                {
                    "sent": "The accuracy reduces, but the interesting thing is when you degrade the number of intermediate frames that you use, it doesn't degrade very much at all, whereas when you degrade the number of points that you use, it really degrades a lot so.",
                    "label": 0
                },
                {
                    "sent": "Definitely the first you know.",
                    "label": 0
                },
                {
                    "sent": "Thirty 5000 points are really important to get accuracy, but even going beyond that to 203 hundred 400 points, you're still gaining accuracy.",
                    "label": 0
                },
                {
                    "sent": "So the importance of that in the comparison of a filter and bundle adjustment is when you look at the computational complexity of those algorithms, and it turns out that a filter is.",
                    "label": 0
                },
                {
                    "sent": "It's no problem to filter to include lots of frames, but it's a big problem to include lots of features 'cause this state vector kind of gets enormous.",
                    "label": 0
                },
                {
                    "sent": "The covariance matrix gets huge whereas bundle adjustment.",
                    "label": 0
                },
                {
                    "sent": "It's no problem too.",
                    "label": 0
                },
                {
                    "sent": "Increase the number of features, it's just computation proportional to the number of features, but it's not good to increase the number of frames, but when the accuracy is coming from the features rather than the frames, that means that when you want high accuracy, you're better off doing it by repeatedly solving from scratch in bundle adjustment.",
                    "label": 0
                },
                {
                    "sent": "Then you are by trying to do some kind of filtering.",
                    "label": 0
                },
                {
                    "sent": "So having kind of proven that to ourselves, we've now built various systems which are much more used.",
                    "label": 0
                },
                {
                    "sent": "This bundle adjustment kind of component at their core.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But taking into account.",
                    "label": 0
                },
                {
                    "sent": "The other things that we know about slam about, you know dealing with large.",
                    "label": 0
                },
                {
                    "sent": "Motions where we kind of use more of a local blocking approach went once we tried to go to really big scales and then loop closure and what's the right thing to do at loop closure?",
                    "label": 0
                },
                {
                    "sent": "We now have systems like like this, so this is called double window optimization and it's worked from.",
                    "label": 0
                },
                {
                    "sent": "ICD last year by my students are how cursed raised at, so he's got this very efficient and scalable now optimization engine for feature based slam.",
                    "label": 0
                },
                {
                    "sent": "So this is just a simulation experiment where basically these are simulated camera positions and these are simulated point positions and it basically does bundle adjustment style optimization on 2 levels.",
                    "label": 0
                },
                {
                    "sent": "So we're very local window around where the camera is right now.",
                    "label": 0
                },
                {
                    "sent": "It does full bundle adjustment and outer window.",
                    "label": 1
                },
                {
                    "sent": "It does a slightly more approximate pose graph optimization, which is something very well known by Slam people and then things that are really far away.",
                    "label": 0
                },
                {
                    "sent": "It doesn't even bother to optimize the tool, but it kind of stays OK.",
                    "label": 0
                },
                {
                    "sent": "So so then here's some real examples.",
                    "label": 0
                },
                {
                    "sent": "So here's now a large scale kind of outdoor.",
                    "label": 0
                },
                {
                    "sent": "Slam monocular slam problem using this double window optimization framework.",
                    "label": 0
                },
                {
                    "sent": "So now we're building a map of this area which has got.",
                    "label": 0
                },
                {
                    "sent": "I think it must have 10s or hundreds of thousands of features altogether.",
                    "label": 0
                },
                {
                    "sent": "Here are the estimated camera motions and then there's loop closure that goes on and keeps it all.",
                    "label": 0
                },
                {
                    "sent": "Fully consistent.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I mean there are similar systems from various.",
                    "label": 0
                },
                {
                    "sent": "Groups around the world, but now quite we can get quite good.",
                    "label": 0
                },
                {
                    "sent": "Results on large scale self consistent slam using cameras.",
                    "label": 1
                },
                {
                    "sent": "And running in real time.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So kind of alongside that work, or really starting a bit more recently.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We thought, OK, well right raising computer power and better understanding of algorithms have allowed us to.",
                    "label": 0
                },
                {
                    "sent": "Get better performance in slam by mean that the main thing is dramatically increasing the number of landmarks that we're using, so we've gone from in mono slam.",
                    "label": 0
                },
                {
                    "sent": "I probably had, you know, one landmark here on one here and one here and one here.",
                    "label": 0
                },
                {
                    "sent": "That's all I know about the world.",
                    "label": 0
                },
                {
                    "sent": "It's just a few points in the world in the you know, the denser point methods we've probably got maybe 50 points on that monitor, and you know, a few 100 points on the desk altogether, but it's still not really telling us about the scene.",
                    "label": 0
                },
                {
                    "sent": "It is definitely enough to give us a good.",
                    "label": 0
                },
                {
                    "sent": "Estimate of where the camera is, but going back to this original goal of can we move towards more general?",
                    "label": 0
                },
                {
                    "sent": "You know scene understanding capability.",
                    "label": 0
                },
                {
                    "sent": "We want to also start understanding the world.",
                    "label": 0
                },
                {
                    "sent": "As well, so if you're want this to use this system in a robot, are situation, it's no good if you just know about some sparse landmarks, or that all that's really useful for his localization, it's not going to help you with path planning, 'cause whenever there's a gap between two landmarks, you don't know whether that's empty space or just a solid textureless wall that you haven't been able to detect.",
                    "label": 0
                },
                {
                    "sent": "So if you want to do path planning or various sorts of interaction, you need more so.",
                    "label": 0
                },
                {
                    "sent": "We started to think about can we do real time slam which starts to work not not on points but on whole surfaces.",
                    "label": 0
                },
                {
                    "sent": "So this work, you know we started to be motivated and start.",
                    "label": 0
                },
                {
                    "sent": "We started to think this might be possible when we saw these kind of results coming out of various labs.",
                    "label": 0
                },
                {
                    "sent": "So for instance in 2007 at T Gratz they were demonstrating very accurate real time dense optical flow running on the GPU.",
                    "label": 1
                },
                {
                    "sent": "So what this basically means is.",
                    "label": 0
                },
                {
                    "sent": "Imagine you've got a video stream going coming into a computer, and between every pair of frames what they're producing.",
                    "label": 0
                },
                {
                    "sent": "Is this, so it's basically a motion field and optical flow field between 2 images.",
                    "label": 0
                },
                {
                    "sent": "But importantly, it's completely dense, so there's a flow vector here for every single pixel, and the quality of this flow field is incredibly good, so it's subpixel, accurate too.",
                    "label": 0
                },
                {
                    "sent": "I think, way way beyond a 10th of a pixel or something like that.",
                    "label": 0
                },
                {
                    "sent": "And it has very nice sharp motion boundaries.",
                    "label": 0
                },
                {
                    "sent": "Sorry it is accurate and so so these are results you know which at the time were definitely close to the very best optical flow that people had done with very offline type of algorithms.",
                    "label": 0
                },
                {
                    "sent": "But excitingly this was now running in real time so they were using GPU's.",
                    "label": 0
                },
                {
                    "sent": "I'm showing much better results than anyone had ever done before in real time, so.",
                    "label": 0
                },
                {
                    "sent": "Just a few more details about how those methods kind of work.",
                    "label": 0
                },
                {
                    "sent": "So if you want to solve for.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A solution for some something at every pixel.",
                    "label": 0
                },
                {
                    "sent": "Then you need to do a kind of global optimization, so these global optimization methods such as are used in the optical flow.",
                    "label": 0
                },
                {
                    "sent": "There can be used for other problems as well, such as denoising and and stereo, but the basic thing that they do is to take advantage of the of the fact that so for instance, in the optical flow problem you're got a camera pointed at the world, but the world is not a random point cloud.",
                    "label": 0
                },
                {
                    "sent": "The world consists presumably of some kind of.",
                    "label": 0
                },
                {
                    "sent": "Coherent objects, so therefore, if you can measure the motion vector at one pixel, it's likely that the motion vector of nearby pixels are similar to that.",
                    "label": 0
                },
                {
                    "sent": "So essentially what they do is try to solve for a motion vector for every pixel such that the whole solution has some kind of smoothness property.",
                    "label": 0
                },
                {
                    "sent": "So you need this smoothness because if you're doing something like optical flow, there are always going to be parts of images where there isn't enough information at that particular pixel.",
                    "label": 0
                },
                {
                    "sent": "To give you an accurate estimate, just using that local information so in there all the previous SLAM stuff I've showed you, we were only tracking.",
                    "label": 0
                },
                {
                    "sent": "Basically, Landmark feature points, so these are places that give you a high corner score.",
                    "label": 0
                },
                {
                    "sent": "They are the highly textured points of an image.",
                    "label": 0
                },
                {
                    "sent": "Those are the things that are easy to match between multiple images.",
                    "label": 0
                },
                {
                    "sent": "But if we want to reconstruct surface is we've got to get matches for all of the things in between as well.",
                    "label": 0
                },
                {
                    "sent": "And if we're thinking of something in the middle of a fairly untextured surface, you won't detect a corner there.",
                    "label": 0
                },
                {
                    "sent": "If you try correlating that little Patch in the other image, it will kind of slide around and give you a pretty good match.",
                    "label": 0
                },
                {
                    "sent": "Anywhere, so these methods they.",
                    "label": 0
                },
                {
                    "sent": "They they solve simultaneously for a solution for all of the pixels at the same time where they trade off 2 terms.",
                    "label": 0
                },
                {
                    "sent": "One that's saying as far as possible, I want the appearance of this Patch in this image to look like the Patch in the other image, but I'll trade that off against a requirement that the whole solution has to be smooth.",
                    "label": 0
                },
                {
                    "sent": "And of course there's various ways of specifying smoothness.",
                    "label": 0
                },
                {
                    "sent": "One that works well, for instance is what's called total variation, so it's it's a measure of the kind of absolute gradients.",
                    "label": 0
                },
                {
                    "sent": "Between neighboring pixels across the whole image, the nice thing about this particular measure is it has this property of preserving edges, so it wants to kind of produce solutions where you've got nice smooth behavior over a certain region, but then it's happy for there to be a jump to another region so it doesn't have this behavior of blurring across edges, which wouldn't be very good.",
                    "label": 0
                },
                {
                    "sent": "So I mentioned that those things were running on on GPU's and.",
                    "label": 0
                },
                {
                    "sent": "I pretty much in fact every.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing we're doing in my lab now is running on on GPU's and I think if you look at this graph you can really understand why.",
                    "label": 0
                },
                {
                    "sent": "So this is so the ones down at the bottom here are basically Pentium class, kind of.",
                    "label": 0
                },
                {
                    "sent": "Systems so CPU type systems and then the green is the curve of commodity GPU units that are now available.",
                    "label": 0
                },
                {
                    "sent": "So this is the processing power that I was running mono slam on.",
                    "label": 0
                },
                {
                    "sent": "This is the processing power that I have now inside this laptop.",
                    "label": 0
                },
                {
                    "sent": "This this has a GTX 580 card.",
                    "label": 0
                },
                {
                    "sent": "So 1500 gigaflops GPU's are easily the most powerful processing resource you have inside a commodity PC today.",
                    "label": 0
                },
                {
                    "sent": "And if you're doing real time vision and you're not.",
                    "label": 0
                },
                {
                    "sent": "Using those you know you're going to get left models behind, I think so, so you know you know, few years ago people were starting to use GPS.",
                    "label": 0
                },
                {
                    "sent": "Now now it's much easier programming tools and so on are really quite quite usable.",
                    "label": 0
                },
                {
                    "sent": "Of course, that means you have to take that fully into account when you design your algorithms.",
                    "label": 0
                },
                {
                    "sent": "They have to be parallelizable, but if you can make parallelizable algorithms, you can now harness incredible power.",
                    "label": 0
                },
                {
                    "sent": "So the first steps that we took in using these kind of methods was really a quite simp.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bolt together sort of approach.",
                    "label": 0
                },
                {
                    "sent": "I mean at the time it was, it was incredibly hard work and so this was mainly down to Richard Newcomb who's.",
                    "label": 0
                },
                {
                    "sent": "Kind of outstanding PhD students in my group.",
                    "label": 0
                },
                {
                    "sent": "So what he did was bolted together several things.",
                    "label": 0
                },
                {
                    "sent": "Basically he took peetam, which is the.",
                    "label": 0
                },
                {
                    "sent": "The feature based slam system that I showed you earlier that comes from the University of Oxford.",
                    "label": 0
                },
                {
                    "sent": "So this is basically a system that can use feature based slam to give very nice accurate real time camera tracking over a desktop size scene so we know where the camera is in real time.",
                    "label": 0
                },
                {
                    "sent": "We can consider that done for now then what he wanted to do was to use actually the optical flow code from the University of Gratz.",
                    "label": 0
                },
                {
                    "sent": "What that can do is to take.",
                    "label": 0
                },
                {
                    "sent": "A pair of images and give you a high-quality.",
                    "label": 0
                },
                {
                    "sent": "Dense matching field between them, so of course if you've got a dense matching field between between 2 images and you know the positions of the cameras that took the two images, so these are not two different cameras there 2 frames from our moving camera.",
                    "label": 0
                },
                {
                    "sent": "Of course you can then triangulate each pair of matching pixels to make a depth map, and then once you've got a depth map and you know where the cameras where you can turn the depth map into a vertex map in 3D and then you can build lots of depth Maps.",
                    "label": 1
                },
                {
                    "sent": "And you can stick them together into a whole dense scene reconstruction.",
                    "label": 0
                },
                {
                    "sent": "It wasn't quite as straightforward as that.",
                    "label": 0
                },
                {
                    "sent": "'cause actually, for the kind of motions we wanted.",
                    "label": 0
                },
                {
                    "sent": "To get reasonable parallax for depth estimation, you want the camera to have some reasonable movement, but as soon as you move the camera too far, optical flow might not work anymore to match them.",
                    "label": 0
                },
                {
                    "sent": "So we did something a little more sophisticated, which involved making a prediction of what the flow field would be using a rough surface fitted through the 3D slam points that we'd reconstructed and use that as a prediction to get the optical flow started.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's kind of a detail now.",
                    "label": 0
                },
                {
                    "sent": "But just to show you, then the kind of reconstructions we could do.",
                    "label": 0
                },
                {
                    "sent": "So this is now a desk desktop, so each one of the colored regions was one separate depth map, and then we can glue that all into a reconstruction of the whole scene.",
                    "label": 0
                },
                {
                    "sent": "And these are just some different.",
                    "label": 0
                },
                {
                    "sent": "Renderings, but you saw that we can texture map it.",
                    "label": 0
                },
                {
                    "sent": "This is a normal map which gives you a good indication of whether you've got accurate reconstruction of the smooth surfaces.",
                    "label": 0
                },
                {
                    "sent": "So a fun thing.",
                    "label": 0
                },
                {
                    "sent": "That we can do with this is to revisit the augmented reality.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Application but now with our new level of capability 'cause we don't just know where the camera is now we know what's in the scene.",
                    "label": 0
                },
                {
                    "sent": "So we have a full model of this desktop scene.",
                    "label": 0
                },
                {
                    "sent": "So now when we drop this virtual car into the scene, the green car is virtual.",
                    "label": 0
                },
                {
                    "sent": "You can see, for instance we can make it disappear behind a real Cup 'cause we've got a model of the Cup.",
                    "label": 0
                },
                {
                    "sent": "We know that the Cup should include the car.",
                    "label": 0
                },
                {
                    "sent": "But the other thing we can do is actually make it physically interact with the scene.",
                    "label": 0
                },
                {
                    "sent": "So we can make ramps out of.",
                    "label": 0
                },
                {
                    "sent": "The stuff that we find in the scene.",
                    "label": 0
                },
                {
                    "sent": "So this is just by loading the mesh that we've generated into free physics simulator.",
                    "label": 0
                },
                {
                    "sent": "And then make the car drive around on the surface.",
                    "label": 0
                },
                {
                    "sent": "So that was.",
                    "label": 1
                },
                {
                    "sent": "That that system we could live dense reconstruction.",
                    "label": 0
                },
                {
                    "sent": "And that was, you know, a big big advance at the time.",
                    "label": 0
                },
                {
                    "sent": "But that still didn't fully satisfy us.",
                    "label": 0
                },
                {
                    "sent": "'cause we were pretty much still riding the point based slam system and then using optical flow on top of that we wanted a slam system that was kind of dense throughout.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a piece of work there was relevant to this that another PhD students in my lab, Steve Lovegrove, did at the time.",
                    "label": 0
                },
                {
                    "sent": "Was he boater?",
                    "label": 0
                },
                {
                    "sent": "A slam system for Mosaicing so this is if you like so panoramic mosaicing is a type of simple slam problem where.",
                    "label": 0
                },
                {
                    "sent": "You want to estimate the 3D rotation of camera so it's 3 degrees of freedom.",
                    "label": 0
                },
                {
                    "sent": "It's only rotating, it's not translating, and you want to build a map, and a map is basically the Panorama, so there's no depth to that map, it's just lies on a sphere.",
                    "label": 0
                },
                {
                    "sent": "But he did this by a whole image alignment approach, so there's no features in this system at all.",
                    "label": 1
                },
                {
                    "sent": "What he's doing is he's building a map of the Panorama by basically laying down keyframes.",
                    "label": 0
                },
                {
                    "sent": "He's the relative pose of the camera.",
                    "label": 0
                },
                {
                    "sent": "All times is found by taking the live image and doing a whole image alignment using a whole image.",
                    "label": 1
                },
                {
                    "sent": "Lucas Kanade type method to find out what's the transform of this live image that brings it into best alignment with the with the map that I've got where our alignment is measured by, you know, sum of squared differences.",
                    "label": 0
                },
                {
                    "sent": "Overall overlapping pixels implements on the GPU, of course, so it's very fast.",
                    "label": 0
                },
                {
                    "sent": "There's a pyramid implementation, so it goes from low resolution to high resolution that makes it.",
                    "label": 1
                },
                {
                    "sent": "Faster and more robust still.",
                    "label": 0
                },
                {
                    "sent": "And so he was able to track really quite fast motion against this mosaic.",
                    "label": 0
                },
                {
                    "sent": "So obviously we can combine.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Those last two things pretty much so.",
                    "label": 0
                },
                {
                    "sent": "Once we've been able to build a dense surface model of this desktop type scene, whynott then turn off the point based slam system altogether, and justice now track the position of the camera by real time alignment of the images that I'm getting for the camera against the model.",
                    "label": 1
                },
                {
                    "sent": "I mean, we've got a textured model of the world.",
                    "label": 0
                },
                {
                    "sent": "I need to know where the camera is, so all I need to do is find the projection of the textured model that agrees as well as possible with my new.",
                    "label": 0
                },
                {
                    "sent": "Live image and it's not.",
                    "label": 0
                },
                {
                    "sent": "We don't have to solve that from scratch all the time because we knew where the camera was on the last frame.",
                    "label": 0
                },
                {
                    "sent": "So it's basically a Lucas Kanade style optimization still, but now in six degrees of freedom rather than three, so we also made some improvements on the actual reconstruction part.",
                    "label": 0
                },
                {
                    "sent": "So in this paper that we called the Tam which is released I CV last year were now.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not using the Gratz optical flow library anymore, we have our own variational GPU solver for depth Maps, which is directly solving for depth Maps rather than trying to fit optical flow into depth.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That estimation",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But then we're now doing tracking of the camera against this whole dense model.",
                    "label": 1
                },
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "So here first of all, we're just showing building a model of this scene, so it's building several depth Maps.",
                    "label": 0
                },
                {
                    "sent": "It's basically just sticking those depth Maps next to each other to make a reconstruction of the whole scene.",
                    "label": 0
                },
                {
                    "sent": "So you can see this is, you know, the speed that it actually runs out.",
                    "label": 0
                },
                {
                    "sent": "You can see how fast it's able to build the reconstruction and now we can show how tracking works.",
                    "label": 0
                },
                {
                    "sent": "So this is a kind of per pixel.",
                    "label": 1
                },
                {
                    "sent": "Demonstration of.",
                    "label": 0
                },
                {
                    "sent": "So, so we're optimizing for the position of the camera by minimizing the difference between.",
                    "label": 0
                },
                {
                    "sent": "The reprojected model and the live image, and there's a gating built into that as well.",
                    "label": 1
                },
                {
                    "sent": "So if the difference is too big at any particular pixel, we throw that pixel away, and it's not used in the optimization, so that's what the yellow areas are here.",
                    "label": 0
                },
                {
                    "sent": "They are the regions that have been gated out.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if there's something including and now here we have a head to head comparison of the quality of tracking.",
                    "label": 0
                },
                {
                    "sent": "We can now get soapy time on the right there point based system, which is actually very very good software, very, very highly optimized.",
                    "label": 1
                },
                {
                    "sent": "But now we're going to test it for really, really fast motion.",
                    "label": 0
                },
                {
                    "sent": "So the quality of tracking is displayed by this augmented car.",
                    "label": 0
                },
                {
                    "sent": "But if the tracking is good, it should stay in the same place.",
                    "label": 1
                },
                {
                    "sent": "The tracking is not so good.",
                    "label": 0
                },
                {
                    "sent": "You should see it wobble around so we can cope with rapid motion, fast shaking, and even more remarkably.",
                    "label": 0
                },
                {
                    "sent": "We can just so just for the hell of it.",
                    "label": 0
                },
                {
                    "sent": "We tried the focusing the camera here so all of the point features that P times using get wiped out, but our dense method is still tracking pretty well because dense methods which are just subtracting all the images in a pixel in an image are going to still give you something pretty sensible at at the essentially solution situation that you have.",
                    "label": 0
                },
                {
                    "sent": "With the.",
                    "label": 0
                },
                {
                    "sent": "With a defocused camera.",
                    "label": 0
                },
                {
                    "sent": "OK, so we've continued to be interested in.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can we make tracking faster and faster and you know track faster and faster motion so this is something that I've been interested in for a long time, so these are some videos I made a few years ago just to illustrate this point to people.",
                    "label": 0
                },
                {
                    "sent": "So here's a really fast motion that we might want to track.",
                    "label": 1
                },
                {
                    "sent": "So I dangerously sellotaped of quite expensive camera to a football.",
                    "label": 0
                },
                {
                    "sent": "And kicked it.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a real time 25 frames per second video.",
                    "label": 0
                },
                {
                    "sent": "This is the slow down view of the 25 frames per second video, so you can see this is a really hard scene to track because the motion from each frame to the next is.",
                    "label": 0
                },
                {
                    "sent": "He's obviously vast.",
                    "label": 0
                },
                {
                    "sent": "Here's the same sequence at 2000 frames per second.",
                    "label": 0
                },
                {
                    "sent": "So it was actually captured at 100 frames per second and the previous ones were just subsamples.",
                    "label": 0
                },
                {
                    "sent": "I showed you so this looks like a much more trackable video, so we're kind of an obvious thing that speed up the frame rate and the interframe jumps or less, and you got this nice smooth looking motion again, so we've always been interested in thinking I should we increase the frame rate of all of our tracking systems to make them more robust, and this is an old video not of my work, but from the University of Tokyo they built a custom 1000 Hertz.",
                    "label": 0
                },
                {
                    "sent": "Vision system so this was 15 years ago I think, so it's a one bit per pixel.",
                    "label": 0
                },
                {
                    "sent": "Very low resolution system, but they showed just how easy tracking becomes once you get up to really high frame rates.",
                    "label": 0
                },
                {
                    "sent": "So Interestingly, as you increase frame rate, your computational costs does not go up proportional to to frame rate.",
                    "label": 0
                },
                {
                    "sent": "So the big problem of course of going up to 200 frames per second in the tracker is you think, well I can't.",
                    "label": 0
                },
                {
                    "sent": "I can't iterate that fast in a real time system, but if you're in any type of tracking system that uses prediction, so such as armana same system that calculated those dynamic search regions on every frame or this newer Lucas Kanade type thing will just if you initialize it from closer because the motion increment is smaller.",
                    "label": 0
                },
                {
                    "sent": "It will converge faster 'cause it needs fewer iterations.",
                    "label": 0
                },
                {
                    "sent": "So when you increase frame rate, the cost per frame actually goes down.",
                    "label": 1
                },
                {
                    "sent": "So when you increase frame rate, the overall cost does go up.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But it definitely goes up in a sub linear way.",
                    "label": 0
                },
                {
                    "sent": "So what we've done most recently is we wanted to do some systematic kind of experimentation into what?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It happens when you increase frame rate in tracking, so these are this is a new paper that we're going to be presenting at.",
                    "label": 0
                },
                {
                    "sent": "Ecv so to do some systematic experimentation on this.",
                    "label": 0
                },
                {
                    "sent": "It was actually quite hard to think of setting up real experiments to do this, 'cause we'd need really fast, you know, robot type motion.",
                    "label": 0
                },
                {
                    "sent": "In fact, my my student anchor handler is doing those experiments now, but what we had at the time we did the paper is we decided to set up a synthetic framework for these experiments.",
                    "label": 0
                },
                {
                    "sent": "So we generated very high-quality, we think close to photo realistic video using Ray tracing and then simulation.",
                    "label": 1
                },
                {
                    "sent": "Of realistic noise and blur to see what really.",
                    "label": 1
                },
                {
                    "sent": "Search to really generate videos.",
                    "label": 0
                },
                {
                    "sent": "So let me let me show you some of that.",
                    "label": 0
                },
                {
                    "sent": "So first of all.",
                    "label": 0
                },
                {
                    "sent": "There are some frames here from pure raytracing, so we have a very dramatic camera motion, so shaking camera.",
                    "label": 0
                },
                {
                    "sent": "And this is a what a 20 Hertz video sequence looks like.",
                    "label": 0
                },
                {
                    "sent": "So this is this is the result of pure raytracing.",
                    "label": 0
                },
                {
                    "sent": "So you see it looks very clean.",
                    "label": 0
                },
                {
                    "sent": "But you know, it's not it's nice quality, so these are what the individual frames look like.",
                    "label": 0
                },
                {
                    "sent": "And now what we will see in a second is what happens if we now add realistic effects to that.",
                    "label": 0
                },
                {
                    "sent": "So of course, when the frame rate is quite low, the exposure time of your camera can be high and therefore the main effect that you see in individual images is blur.",
                    "label": 0
                },
                {
                    "sent": "So so look at this one now.",
                    "label": 0
                },
                {
                    "sent": "So I think I can be fooled that that's quite quite real sometimes.",
                    "label": 0
                },
                {
                    "sent": "So here we are synthesizing blur and we're synthesizing noise.",
                    "label": 0
                },
                {
                    "sent": "So at 20 frames per second.",
                    "label": 0
                },
                {
                    "sent": "We got really bad blur, but not so much noise.",
                    "label": 0
                },
                {
                    "sent": "This is 100 frames per second video, so you probably can barely see it, 'cause it's really dark, of course.",
                    "label": 0
                },
                {
                    "sent": "So once you increase increase frame rate a lot, you have to decrease the exposure time.",
                    "label": 0
                },
                {
                    "sent": "Basically the images gets dark.",
                    "label": 0
                },
                {
                    "sent": "Here, we've brightened the image.",
                    "label": 0
                },
                {
                    "sent": "By stretching the color space so you can see.",
                    "label": 0
                },
                {
                    "sent": "Basically, the large amount of noise that's now in that image.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure how.",
                    "label": 0
                },
                {
                    "sent": "Visible that is on screen there think you can probably see those images are very noisy, but the interframe motion is much smaller, so you know how does.",
                    "label": 0
                },
                {
                    "sent": "How do these things trade off?",
                    "label": 0
                },
                {
                    "sent": "Sorry, but the full.",
                    "label": 0
                },
                {
                    "sent": "Before results are in the paper, but just to give you.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kind of flavor.",
                    "label": 0
                },
                {
                    "sent": "I mean there are lots of interesting questions here of, you know, as we start varying frame rate, we should also think about.",
                    "label": 0
                },
                {
                    "sent": "Well, instead of varying frame rate, I might have got better results in a tracker by, for instance, increasing resolution that increases computational cost, but it might make my results better.",
                    "label": 0
                },
                {
                    "sent": "So we compared those two things and then we evaluated the performance of track of the tracking in terms of accuracy, computational cost and robustness, and what we basically get is a kind of curves like these which show.",
                    "label": 0
                },
                {
                    "sent": "Possible choices, so depending on the processing load that you so that you are able to support so the processing resource that you have is on this scale and then these show accuracy of tracking as a function of both frame rate and resolution.",
                    "label": 0
                },
                {
                    "sent": "So along the kind of bottom of these overlapping curves there's an envelope of interesting operating points.",
                    "label": 0
                },
                {
                    "sent": "Basically, where you for a certain processing load you get the best possible accuracy of your tracker and you'll see that you sort of switch off between.",
                    "label": 0
                },
                {
                    "sent": "Increasing frame rate and increasing resolution.",
                    "label": 0
                },
                {
                    "sent": "So this particular curve is 4.",
                    "label": 0
                },
                {
                    "sent": "A situation where we had a super well lit scene.",
                    "label": 0
                },
                {
                    "sent": "In that case then.",
                    "label": 0
                },
                {
                    "sent": "Even at high frame rate, there's very little noise.",
                    "label": 0
                },
                {
                    "sent": "In that case, it's very clearly saying to us we should be pushing frame rates up a lot.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So why not run our trackers at multiple hundreds of Hertz?",
                    "label": 0
                },
                {
                    "sent": "There's no reason not to as well.",
                    "label": 0
                },
                {
                    "sent": "It seems to be saying that's not quite so strong in real, more realistic lighting conditions where the thing against you going to really high frame rates is that the exposure time gets really short on your images.",
                    "label": 0
                },
                {
                    "sent": "Get too noisy.",
                    "label": 0
                },
                {
                    "sent": "Anyway, I still think there's a lot more research to do in this area.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to show you just this last thing and hopefully a very quick demo before I run out of time.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the last thing was I showed you the reconstruction parts of the system where we're able to build depth Maps quite nicely, but in the in the videos I've shown you so far, those depth Maps are pretty much just put next to each other, and that's not a bad way of making a reconstruction of a scene.",
                    "label": 0
                },
                {
                    "sent": "But of course pretty soon we're going to make depth Maps which overlap with each other.",
                    "label": 0
                },
                {
                    "sent": "So if we are getting lots of depth Maps in the same place.",
                    "label": 0
                },
                {
                    "sent": "Can we start fusing them into a much more representative scene representation?",
                    "label": 0
                },
                {
                    "sent": "And ideally we'd like something which can represent arbitrary topology of surfaces in a scene so.",
                    "label": 0
                },
                {
                    "sent": "Richard Newcomb, the same student who did the dense reconstruction work after that, went to do.",
                    "label": 0
                },
                {
                    "sent": "He did an internship at Microsoft Cambridge, and while he was there, he got early access to this.",
                    "label": 0
                },
                {
                    "sent": "The Connect camera and what that basically enabled was to think about OK.",
                    "label": 0
                },
                {
                    "sent": "It was really, really hard to get good depth Maps from a single camera.",
                    "label": 0
                },
                {
                    "sent": "This thing just pumps depth Maps out at me with no effort at all at 30 frames per second.",
                    "label": 0
                },
                {
                    "sent": "So this is a good way to really start working on this problem of how can I fuse?",
                    "label": 0
                },
                {
                    "sent": "Depth Maps and how and what do I achieve by doing that?",
                    "label": 0
                },
                {
                    "sent": "So after having done that, he came back and has now done the same thing with a single camera and it's actually even even cooler.",
                    "label": 0
                },
                {
                    "sent": "But just to show you what connect Fusion does, which is what this system is.",
                    "label": 0
                },
                {
                    "sent": "So so the.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The representation that it's using for the geometry of the world is a volumetric representation called the same distance function.",
                    "label": 1
                },
                {
                    "sent": "So essentially you say I'm going to try and reconstruct a volume of space.",
                    "label": 0
                },
                {
                    "sent": "I'll define a regular grid of voxels over that space, and then what I'm going to represent at every voxel of that grid is the estimated distance to the closest surface to that Vauxhall, so it has a has a sign such that.",
                    "label": 0
                },
                {
                    "sent": "Free space which is in front of services has a positive distance and space which is behind services has a negative distance and the interpretation is that the crossing point from positive to negative.",
                    "label": 0
                },
                {
                    "sent": "The Zero crossing is where the surface is, so you can later on go through with marching cubes or something and pull out a surface.",
                    "label": 0
                },
                {
                    "sent": "If you want to make a mesh.",
                    "label": 0
                },
                {
                    "sent": "So essentially we're grabbing lots of depth Maps were estimating where the motion of the can.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where is all the time so important Lee in in connect Fusion?",
                    "label": 0
                },
                {
                    "sent": "We do that by not by any kind of frame to frame estimation, but we're always estimating the position of the camera by aligning it against the current fused model.",
                    "label": 0
                },
                {
                    "sent": "So we're projecting the signed distance function.",
                    "label": 0
                },
                {
                    "sent": "And then optimizing to such that the current camera pose is consistent with an observation of the full kind of fused.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Volumetric",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Model so they re fused images together.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Get something like this, so let me just try a quick.",
                    "label": 0
                },
                {
                    "sent": "Live demo.",
                    "label": 0
                },
                {
                    "sent": "Cassie to come down to 'cause I think we need.",
                    "label": 0
                },
                {
                    "sent": "We need a volunteer for this.",
                    "label": 0
                },
                {
                    "sent": "He sure.",
                    "label": 0
                },
                {
                    "sent": "I keep my head know anything should be fine, so if you'd like to sit there.",
                    "label": 0
                },
                {
                    "sent": "OK, let's try this so yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, so you just gotta sit very still basically so choose how you want to sit and train, train, stay still.",
                    "label": 0
                },
                {
                    "sent": "So yeah, here's their connect camera so you can see this is basically the raw output of a Connect camera turned into a.",
                    "label": 0
                },
                {
                    "sent": "Basically a mesh here with a Fang.",
                    "label": 0
                },
                {
                    "sent": "Rendering, so that's what a single Connect image looks like.",
                    "label": 0
                },
                {
                    "sent": "You can see it's you know it's actually amazing what it gives you.",
                    "label": 0
                },
                {
                    "sent": "Basically is the main word for it, but it's kind of noisy and it has gaps.",
                    "label": 0
                },
                {
                    "sent": "So when you pointed at certain things like a monitor, you'll see there are gaps where the reflection doesn't really come back strongly.",
                    "label": 0
                },
                {
                    "sent": "But what we do in connect Fusion is we're not just taking single images, we're going to start fusing them.",
                    "label": 0
                },
                {
                    "sent": "So once I.",
                    "label": 0
                },
                {
                    "sent": "Hit this button here.",
                    "label": 0
                },
                {
                    "sent": "We're taking the stream of.",
                    "label": 0
                },
                {
                    "sent": "Images and we're actually fusing them all into the same distance function, and you'll see this, so we now get this.",
                    "label": 0
                },
                {
                    "sent": "Reconstruction, which is much smoother.",
                    "label": 0
                },
                {
                    "sent": "And we should be able to go round and.",
                    "label": 0
                },
                {
                    "sent": "Selling all of the holes.",
                    "label": 1
                },
                {
                    "sent": "So everything is being done just from the raw depth map from connect, so there's no kind of external sensing tracking the position of this camera, it's all purely done to trans Transit.",
                    "label": 0
                },
                {
                    "sent": "Still, if it's got lost, OK.",
                    "label": 0
                },
                {
                    "sent": "I think I've probably moved too fast or something, but let's see if we should still have the model there.",
                    "label": 0
                },
                {
                    "sent": "So this shows you their model that we've built.",
                    "label": 0
                },
                {
                    "sent": "We've only really been able to look at this.",
                    "label": 0
                },
                {
                    "sent": "This side let's just.",
                    "label": 0
                },
                {
                    "sent": "Maybe I'll just have one more try and be a bit more careful.",
                    "label": 0
                },
                {
                    "sent": "OK, ready to stay still.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's still tracking string around the back so you will see in some places that kind of limits of the volume that we set up, so it's only reconstructing things within that volume.",
                    "label": 0
                },
                {
                    "sent": "So basically the size of this volume is currently mainly limited by memory, so.",
                    "label": 0
                },
                {
                    "sent": "I think that's already lost track again, so we're already easily filling up.",
                    "label": 0
                },
                {
                    "sent": "Yeah thanks.",
                    "label": 0
                },
                {
                    "sent": "You can relax now.",
                    "label": 0
                },
                {
                    "sent": "Thanks a lot.",
                    "label": 0
                },
                {
                    "sent": "Let me just do this OK, so it's still still there.",
                    "label": 0
                },
                {
                    "sent": "So yeah, so there's no kind of limit to topology we can go right right round people and so on.",
                    "label": 0
                },
                {
                    "sent": "And you know, the more time you spend scanning in a certain area, the higher higher quality.",
                    "label": 0
                },
                {
                    "sent": "You'll get.",
                    "label": 0
                },
                {
                    "sent": "And then we can of course write write these.",
                    "label": 0
                },
                {
                    "sent": "Meshes out, maybe I can just show you one like we captured in slightly more controlled.",
                    "label": 0
                },
                {
                    "sent": "Circumstances.",
                    "label": 0
                },
                {
                    "sent": "India should have done this.",
                    "label": 0
                },
                {
                    "sent": "I know.",
                    "label": 0
                },
                {
                    "sent": "So just open this one in meshlab.",
                    "label": 0
                },
                {
                    "sent": "So basically scanning people is really good fun.",
                    "label": 0
                },
                {
                    "sent": "We've had some people who've actually tried to 3D print knees and so on.",
                    "label": 0
                },
                {
                    "sent": "I'm sure you can recognize who this is.",
                    "label": 0
                },
                {
                    "sent": "And that works quite well too, so probably a lot of people will want to.",
                    "label": 0
                },
                {
                    "sent": "Try this kind of system out and I think there's various pieces of software like this that will be coming out around the world.",
                    "label": 0
                },
                {
                    "sent": "There are already some independent implementations of connect Fusion.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So you can probably try playing around with something at yourself and we will hopefully be releasing Richards.",
                    "label": 0
                },
                {
                    "sent": "Version of the code sometimes seem OK, so I'll just finish by showing you this.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Video, which is results for signed distance function Fusion using now a single camera so the depth Maps are now being built by a single moving camera and then refusing all of those into a signed distance function and you can see where now you can actually pick out more detail from this single camera stereo type method.",
                    "label": 0
                },
                {
                    "sent": "Then you can from connect 'cause connects resolution is ultimately a bit limited so we're picking out things like small cables.",
                    "label": 0
                },
                {
                    "sent": "In this computer here.",
                    "label": 0
                },
                {
                    "sent": "So I think a very nice point to finish on is just to compare these kind of results to the Mono Slam video that I showed you near the start and to make the point that you know is the same input right?",
                    "label": 0
                },
                {
                    "sent": "It's a single camera moving through space.",
                    "label": 1
                },
                {
                    "sent": "Maybe it's a slightly better camera, but not much, and it's basically the same commodity hardware, so in both cases those systems were running on 1500 pound laptops of the day with nothing else, a camera and a laptop.",
                    "label": 0
                },
                {
                    "sent": "So I put most of that improvement down to processing.",
                    "label": 0
                },
                {
                    "sent": "And how much that has?",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Increased but yeah, very mind what's going to happen in the next 8 eight years.",
                    "label": 0
                },
                {
                    "sent": "I think it's going to be a staggering so.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks a lot.",
                    "label": 0
                }
            ]
        }
    }
}