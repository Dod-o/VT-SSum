{
    "id": "hfa4gs4e3vhizl44l7q7zrz3a6btyxdx",
    "title": "Optimizing the Performance for Concurrent RDF Stream Processing Queries",
    "info": {
        "author": [
            "Chan Le Van, Insight Centre for Data Analytics"
        ],
        "published": "July 10, 2017",
        "recorded": "May 2017",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2017_le_van_stream_processing_queries/",
    "segmentation": [
        [
            "I'm from the inside Center for Data Analytics Anuar, Galway, Ireland and today is my pleasure to be here to present my research in collaboration relation with some of the team members in my group.",
            "Also in insight and Spangle finished his PhD and back to China and currently I'm working with the alley.",
            "Is my group leader in there.",
            "So I will talk about."
        ],
        [
            "Optimizing the performance fall concurrently upstream processing queries.",
            "My present."
        ],
        [
            "Session includes five past.",
            "The first one, I'll give brief introduction about current RF stream processing.",
            "The second one I give.",
            "I'll talk about the foundation, which my resources based on and the second one is my actual actual work on optimizing the concurrent SQL queries and evaluation will be in the on the 4th section and the last section is the conclusion and feature works OK, so guess that.",
            "Let's get started."
        ],
        [
            "So as you know now what data stream everywhere we can have stream source from the mobile device such as location tracking or weather forecasts.",
            "Well, in the healthcare system there's a lot of sensor device to monitor heart, meatless pressure or financial banking system, financial stickers or on social media.",
            "It's there's a lot of strict rules.",
            "So the point is, you hit your genius characteristic of this stream source, make it difficult to be integrated, so researchers try to solve this problem by annotating.",
            "Datastream using following the idea.",
            "Data principle and it creates it makes this is the reason why Deepstream data appears, and when there's some of the engine to process as the upstream data, including."
        ],
        [
            "And she sparkled from Milan.",
            "I think Sparkle Stream format Rich and SQL is developed from the insights about the point is all of this.",
            "Engine has problem, instant process, the multiple queries an.",
            "That's why this is the motivation for us to improve our engines, which equals to make it have better performance on processing the multiple queries."
        ],
        [
            "So.",
            "Information and we in the financial section I will present about the sequels three processing framework and then I'll go over the idea of optimizing the performance of it by the giving the joint operation.",
            "Ann let next I will present about the share share, share resource among multiple session operator and in reality is called Network website join operators."
        ],
        [
            "So SQL is basically just an idea stream processing framework and it accept the sequels declarative declarative language which is extended from the sparkle query which is using in the RDF data.",
            "And sequels followed eager execution, eager execution approach.",
            "So there are two common approach that is eager execution, which means when the data arrives to the system then the process is trigger immediately and the periodic execution is like implemented in.",
            "The sparkle is excuse the data in every interval of time.",
            "So SQL follow the eager execution approach.",
            "So the processing is very heavy.",
            "And the final one is SQL can process both static and on the upstream data.",
            "Basically, in the current release version of sequels."
        ],
        [
            "In it is quite dumb.",
            "The point.",
            "For example, we have three streams that come into the Bush.",
            "Later do the sequels.",
            "There are one query executed over the on these three streams.",
            "Then inside the sequel it will create a thing cost execution plan.",
            "This is the how really data is really evaluated and this later from this stream source will be routed into the stream buffer of this execution plan and to process an.",
            "Generate the output so in case there are another queries.",
            "Execute on screen two and three, then another execution plan will be created and data up from scream two and three also be replicated and route into this execution plan and in similarity as many query comes as there will be a lot of execution plan created.",
            "So this."
        ],
        [
            "It really is not efficient at all because it consume a lot of memories and processing resource.",
            "And also there's a."
        ],
        [
            "Such that from this reference you can detail that claiming that the joint joint operation is the most expensive operator in the query pipeline in the execution plan.",
            "So they proposed the idea of sharing the data by the first one, the.",
            "It mentions about multi way join, so rather than normally using the binary join the multiplayer join, execute over multiple buffers rather more than two buffers, and when the data item comes then it uses incremental evaluation to execute to propagate the next data for an on the column of join an.",
            "With an index data structure to jump to."
        ],
        [
            "To my regular recursive recursive execution to create the final result.",
            "Anne taken."
        ],
        [
            "Other step they.",
            "It's mentioned about the surgery operator.",
            "So for example, we have three created three queries like this.",
            "An in case separately, it could be that three execution plan, but.",
            "As you can see, there are these three queries just refer to the same two inputstream, S1S as to so rather than execute them separately, we connect."
        ],
        [
            "Kill them.",
            "Just one time with the longer size of the windows and it will create it.",
            "A sense output result and this setup sailboat results contain all of the results of the relevant queries and this on this charger operator there will be a continued cause router that will refer back to the the window of each query to route the future that the output and route the data into the proper queries.",
            "So this is called a satchel operator an the final one."
        ],
        [
            "Is the network of such an operator?",
            "The point is in reality query register into the stream processing system, maybe no, maybe yes can share the same input stream.",
            "Or maybe they just said just a subset of it.",
            "But stream for example."
        ],
        [
            "In this query one query tool, they share the subset of stream one and stream two and three.",
            "Also in this query tree and query for they also share this S1S2S3 and S4.",
            "So the."
        ],
        [
            "Says if we consider only the subsets of the streams, we can form the scheduling operator I mentioned earlier and the thing and the output of this success can be further reduced to create the final result of the query.",
            "So this thing this create in."
        ],
        [
            "From the owner of the involved query, create a network of centroid operator an so those.",
            "Stream that would be associated adjoin graph like whenever the data comes.",
            "Then there would be the execution of this drug rap to loop.",
            "So to find to create the joint output can generate the final result.",
            "And what is the joint graph genre is just content of the best cost joint sequence of involved query an this joint signatures kind of the way the order of the buffer to be propagate and generate the final result.",
            "So our optimization."
        ],
        [
            "Work achieved 2 two things.",
            "The first thing is we put this network of such an operator in the sequel and extend sequels is consequent.",
            "Plus it has better performance equals.",
            "And we used.",
            "As I mentioned, there's a best cost joint sequence we're creating proposed touristic on this to create joint graph and the second one is we create the scalable system to boot multiple instance of sequels.",
            "Tameka so.",
            "To increase the performance of the multiple query SQL and in this model scalable system, we balance the performance of each instance by using different.",
            "Load balancing strategy that I will go into detail later on."
        ],
        [
            "Further artistic we used in the search on graph then basically this is the formalization of the.",
            "Something we proposed, but basically based on the joint variable.",
            "From on of involve queries an also the joint valuable position in the involved query.",
            "The joint variable help us identify if tool can be joined and the joint valuable position.",
            "Help us identify.",
            "How much how many queries a surgery can reduce the output?",
            "I don't want to go to need to mathematic but I will start giving."
        ],
        [
            "Example to show this more clear.",
            "So basically if I have, I take you for queries in this reference, you can to demonstrate it's basically a.",
            "In a scenario of a building has a static data, each of its flow, and then each of the Member has a knife ID so.",
            "If this query can have us informed participant inside.",
            "In the just enter a location or the query tool can notify if two people can be reached or collectively can count the number of Arthur in the same location on even some count the number of collocation appear in the nearby.",
            "The point is."
        ],
        [
            "In this with this query and using the schedule approach, then we just need 55 data before this.",
            "If we separated separate the execution, that would be 19 or 2020 data before created.",
            "And this this order the stream stream basic pattern will refer to the 1st first one because they have the same matching result and in similarity release the.",
            "The way it the data layer is organized an in here because it just has one stream data before it will create a joint graph.",
            "In this and the joint graph is created."
        ],
        [
            "Likely by like from this of this stream window, before we will go to the second one, and because we we, we use the recursive execution to create and the reason we choose the second one is because after this execution the search on will be reduced by three queries.",
            "And if they keep going with this way, then the query was we the the surgery in this.",
            "In this, after this step will be reduced by two queries and at this step then equal the router is is stick into this later.",
            "But for an RT pair the data to the query ones because query right now is covered and its similarity.",
            "You can see the set joy of the various joint result of the query.",
            "One can be reused for query tree as well an there is the.",
            "Although the health of the final join graph looks like."
        ],
        [
            "The second achievement buses after we have this optimized engine we cause in the centralization always has limitation in the query processing, so we scale it by federating multiple engines so we can stick it in, put it in a different physical location, for example, and in here we implement the client server architecture.",
            "And we proposed the way to balance the performance.",
            "When we register the query into different multiple instant, by the way, that the first one we.",
            "Register the query Robin is.",
            "For example, we have 5 incident with tankery.",
            "Each instance will stick with two queries.",
            "And the second one we choose the minimum average latency.",
            "It means we choose the next instant if.",
            "The latency of this incident is the minimum and the third one is we choose the minimum average website.",
            "That is, we choose that instant if indicates the size of all of the buffer inside the engine is minimum.",
            "Ann this is which we have to eval."
        ],
        [
            "Addition on these tools, achievement the first one is on the schedule operation and the second load balancing.",
            "We also check about the query registration time to see if it's practical in reality."
        ],
        [
            "With the joint performance we are conducted like because sequels is conducted in the LS man marked.",
            "So we reproduce the experiment on that benchmark and try to compare with our optimized version.",
            "And as you can see, there is the.",
            "Outperform the performance is almost always the original version.",
            "We didn't compare with this barcode 'cause the way is this barcode using another semantic of execution so we don't want to force the experiment.",
            "Like this, if it's more clear, we do and further.",
            "The scalable instant."
        ],
        [
            "And we try to.",
            "We use the Citibank match which allow us to.",
            "To get the latency of each the engine and in this experiment we try to scale, scale the number of instant from one to four and as you can see the first, the first thing we achieve is when we scale the number of instant, then the latency.",
            "We will decrease, but when it reached through the for instance, see the latency.",
            "Increase again, this is because when the overhead up.",
            "Threat allocation is always the.",
            "The performance and.",
            "In terms of different load balancing strategy, then we compare rotational latency.",
            "Average latency, an average mobile size.",
            "Then we conclude that the load balancing of buffer size strategy is the best one because it has the lowest latency.",
            "So we choose this one I conduct.",
            "Keep trying to evaluate the number of the stream of the can.",
            "This can this scalable system consume.",
            "Then this is not quite persuasive experiment, because basically that when the number of stream increased.",
            "Then the latency is increased, but you see too weird behavior as animal Stream 7 and symbol stream 20s.",
            "This because a bug in the concurrent modification that I fixed and I put the source code here so you can check."
        ],
        [
            "For the query registration time, when we submit the query, we record the time of submission an after the finish registration is sent back that we also recall the time.",
            "So you can see in this three different load balancing strategies than the first one, the rotational latency.",
            "One is more stable than the buffer size, one that is be cause if the query equivalently distributed to multiple instance than the the latency will be more stable, while in the upper side is really high fluctuation.",
            "Because if one engineer just the number of query.",
            "Distributed in different engine is really different and it created this.",
            "So."
        ],
        [
            "For the conclusion and future books, then the conclusion is you can see the the better performance of handling multiple already within hours, implemented version.",
            "And also we successfully federate multiple instance too with different load balancing strategies.",
            "But the point is, for the future work, there's a lot of things we can improve.",
            "For example, we have to decrease the query registration time and don't use the recursive implementation because it's very, it's very.",
            "Time consuming and also distributed model.",
            "Then we can create more efficient load balancing strategies.",
            "For example we can based on the selectivity of the joint operation inside each different level.",
            "Two to two to create a more efficient lot messaging strategies.",
            "And that's it.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm from the inside Center for Data Analytics Anuar, Galway, Ireland and today is my pleasure to be here to present my research in collaboration relation with some of the team members in my group.",
                    "label": 1
                },
                {
                    "sent": "Also in insight and Spangle finished his PhD and back to China and currently I'm working with the alley.",
                    "label": 0
                },
                {
                    "sent": "Is my group leader in there.",
                    "label": 0
                },
                {
                    "sent": "So I will talk about.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Optimizing the performance fall concurrently upstream processing queries.",
                    "label": 0
                },
                {
                    "sent": "My present.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Session includes five past.",
                    "label": 0
                },
                {
                    "sent": "The first one, I'll give brief introduction about current RF stream processing.",
                    "label": 0
                },
                {
                    "sent": "The second one I give.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about the foundation, which my resources based on and the second one is my actual actual work on optimizing the concurrent SQL queries and evaluation will be in the on the 4th section and the last section is the conclusion and feature works OK, so guess that.",
                    "label": 0
                },
                {
                    "sent": "Let's get started.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as you know now what data stream everywhere we can have stream source from the mobile device such as location tracking or weather forecasts.",
                    "label": 0
                },
                {
                    "sent": "Well, in the healthcare system there's a lot of sensor device to monitor heart, meatless pressure or financial banking system, financial stickers or on social media.",
                    "label": 0
                },
                {
                    "sent": "It's there's a lot of strict rules.",
                    "label": 0
                },
                {
                    "sent": "So the point is, you hit your genius characteristic of this stream source, make it difficult to be integrated, so researchers try to solve this problem by annotating.",
                    "label": 0
                },
                {
                    "sent": "Datastream using following the idea.",
                    "label": 0
                },
                {
                    "sent": "Data principle and it creates it makes this is the reason why Deepstream data appears, and when there's some of the engine to process as the upstream data, including.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And she sparkled from Milan.",
                    "label": 0
                },
                {
                    "sent": "I think Sparkle Stream format Rich and SQL is developed from the insights about the point is all of this.",
                    "label": 0
                },
                {
                    "sent": "Engine has problem, instant process, the multiple queries an.",
                    "label": 0
                },
                {
                    "sent": "That's why this is the motivation for us to improve our engines, which equals to make it have better performance on processing the multiple queries.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Information and we in the financial section I will present about the sequels three processing framework and then I'll go over the idea of optimizing the performance of it by the giving the joint operation.",
                    "label": 0
                },
                {
                    "sent": "Ann let next I will present about the share share, share resource among multiple session operator and in reality is called Network website join operators.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So SQL is basically just an idea stream processing framework and it accept the sequels declarative declarative language which is extended from the sparkle query which is using in the RDF data.",
                    "label": 1
                },
                {
                    "sent": "And sequels followed eager execution, eager execution approach.",
                    "label": 0
                },
                {
                    "sent": "So there are two common approach that is eager execution, which means when the data arrives to the system then the process is trigger immediately and the periodic execution is like implemented in.",
                    "label": 0
                },
                {
                    "sent": "The sparkle is excuse the data in every interval of time.",
                    "label": 0
                },
                {
                    "sent": "So SQL follow the eager execution approach.",
                    "label": 0
                },
                {
                    "sent": "So the processing is very heavy.",
                    "label": 0
                },
                {
                    "sent": "And the final one is SQL can process both static and on the upstream data.",
                    "label": 1
                },
                {
                    "sent": "Basically, in the current release version of sequels.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In it is quite dumb.",
                    "label": 0
                },
                {
                    "sent": "The point.",
                    "label": 0
                },
                {
                    "sent": "For example, we have three streams that come into the Bush.",
                    "label": 0
                },
                {
                    "sent": "Later do the sequels.",
                    "label": 0
                },
                {
                    "sent": "There are one query executed over the on these three streams.",
                    "label": 0
                },
                {
                    "sent": "Then inside the sequel it will create a thing cost execution plan.",
                    "label": 0
                },
                {
                    "sent": "This is the how really data is really evaluated and this later from this stream source will be routed into the stream buffer of this execution plan and to process an.",
                    "label": 0
                },
                {
                    "sent": "Generate the output so in case there are another queries.",
                    "label": 0
                },
                {
                    "sent": "Execute on screen two and three, then another execution plan will be created and data up from scream two and three also be replicated and route into this execution plan and in similarity as many query comes as there will be a lot of execution plan created.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It really is not efficient at all because it consume a lot of memories and processing resource.",
                    "label": 0
                },
                {
                    "sent": "And also there's a.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Such that from this reference you can detail that claiming that the joint joint operation is the most expensive operator in the query pipeline in the execution plan.",
                    "label": 0
                },
                {
                    "sent": "So they proposed the idea of sharing the data by the first one, the.",
                    "label": 0
                },
                {
                    "sent": "It mentions about multi way join, so rather than normally using the binary join the multiplayer join, execute over multiple buffers rather more than two buffers, and when the data item comes then it uses incremental evaluation to execute to propagate the next data for an on the column of join an.",
                    "label": 0
                },
                {
                    "sent": "With an index data structure to jump to.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To my regular recursive recursive execution to create the final result.",
                    "label": 0
                },
                {
                    "sent": "Anne taken.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other step they.",
                    "label": 0
                },
                {
                    "sent": "It's mentioned about the surgery operator.",
                    "label": 0
                },
                {
                    "sent": "So for example, we have three created three queries like this.",
                    "label": 0
                },
                {
                    "sent": "An in case separately, it could be that three execution plan, but.",
                    "label": 0
                },
                {
                    "sent": "As you can see, there are these three queries just refer to the same two inputstream, S1S as to so rather than execute them separately, we connect.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kill them.",
                    "label": 0
                },
                {
                    "sent": "Just one time with the longer size of the windows and it will create it.",
                    "label": 0
                },
                {
                    "sent": "A sense output result and this setup sailboat results contain all of the results of the relevant queries and this on this charger operator there will be a continued cause router that will refer back to the the window of each query to route the future that the output and route the data into the proper queries.",
                    "label": 0
                },
                {
                    "sent": "So this is called a satchel operator an the final one.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is the network of such an operator?",
                    "label": 1
                },
                {
                    "sent": "The point is in reality query register into the stream processing system, maybe no, maybe yes can share the same input stream.",
                    "label": 0
                },
                {
                    "sent": "Or maybe they just said just a subset of it.",
                    "label": 0
                },
                {
                    "sent": "But stream for example.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this query one query tool, they share the subset of stream one and stream two and three.",
                    "label": 0
                },
                {
                    "sent": "Also in this query tree and query for they also share this S1S2S3 and S4.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Says if we consider only the subsets of the streams, we can form the scheduling operator I mentioned earlier and the thing and the output of this success can be further reduced to create the final result of the query.",
                    "label": 0
                },
                {
                    "sent": "So this thing this create in.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From the owner of the involved query, create a network of centroid operator an so those.",
                    "label": 1
                },
                {
                    "sent": "Stream that would be associated adjoin graph like whenever the data comes.",
                    "label": 0
                },
                {
                    "sent": "Then there would be the execution of this drug rap to loop.",
                    "label": 0
                },
                {
                    "sent": "So to find to create the joint output can generate the final result.",
                    "label": 0
                },
                {
                    "sent": "And what is the joint graph genre is just content of the best cost joint sequence of involved query an this joint signatures kind of the way the order of the buffer to be propagate and generate the final result.",
                    "label": 0
                },
                {
                    "sent": "So our optimization.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work achieved 2 two things.",
                    "label": 0
                },
                {
                    "sent": "The first thing is we put this network of such an operator in the sequel and extend sequels is consequent.",
                    "label": 0
                },
                {
                    "sent": "Plus it has better performance equals.",
                    "label": 0
                },
                {
                    "sent": "And we used.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned, there's a best cost joint sequence we're creating proposed touristic on this to create joint graph and the second one is we create the scalable system to boot multiple instance of sequels.",
                    "label": 0
                },
                {
                    "sent": "Tameka so.",
                    "label": 0
                },
                {
                    "sent": "To increase the performance of the multiple query SQL and in this model scalable system, we balance the performance of each instance by using different.",
                    "label": 0
                },
                {
                    "sent": "Load balancing strategy that I will go into detail later on.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Further artistic we used in the search on graph then basically this is the formalization of the.",
                    "label": 0
                },
                {
                    "sent": "Something we proposed, but basically based on the joint variable.",
                    "label": 0
                },
                {
                    "sent": "From on of involve queries an also the joint valuable position in the involved query.",
                    "label": 0
                },
                {
                    "sent": "The joint variable help us identify if tool can be joined and the joint valuable position.",
                    "label": 0
                },
                {
                    "sent": "Help us identify.",
                    "label": 0
                },
                {
                    "sent": "How much how many queries a surgery can reduce the output?",
                    "label": 0
                },
                {
                    "sent": "I don't want to go to need to mathematic but I will start giving.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Example to show this more clear.",
                    "label": 0
                },
                {
                    "sent": "So basically if I have, I take you for queries in this reference, you can to demonstrate it's basically a.",
                    "label": 0
                },
                {
                    "sent": "In a scenario of a building has a static data, each of its flow, and then each of the Member has a knife ID so.",
                    "label": 1
                },
                {
                    "sent": "If this query can have us informed participant inside.",
                    "label": 0
                },
                {
                    "sent": "In the just enter a location or the query tool can notify if two people can be reached or collectively can count the number of Arthur in the same location on even some count the number of collocation appear in the nearby.",
                    "label": 1
                },
                {
                    "sent": "The point is.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this with this query and using the schedule approach, then we just need 55 data before this.",
                    "label": 0
                },
                {
                    "sent": "If we separated separate the execution, that would be 19 or 2020 data before created.",
                    "label": 0
                },
                {
                    "sent": "And this this order the stream stream basic pattern will refer to the 1st first one because they have the same matching result and in similarity release the.",
                    "label": 0
                },
                {
                    "sent": "The way it the data layer is organized an in here because it just has one stream data before it will create a joint graph.",
                    "label": 0
                },
                {
                    "sent": "In this and the joint graph is created.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Likely by like from this of this stream window, before we will go to the second one, and because we we, we use the recursive execution to create and the reason we choose the second one is because after this execution the search on will be reduced by three queries.",
                    "label": 0
                },
                {
                    "sent": "And if they keep going with this way, then the query was we the the surgery in this.",
                    "label": 0
                },
                {
                    "sent": "In this, after this step will be reduced by two queries and at this step then equal the router is is stick into this later.",
                    "label": 0
                },
                {
                    "sent": "But for an RT pair the data to the query ones because query right now is covered and its similarity.",
                    "label": 0
                },
                {
                    "sent": "You can see the set joy of the various joint result of the query.",
                    "label": 0
                },
                {
                    "sent": "One can be reused for query tree as well an there is the.",
                    "label": 0
                },
                {
                    "sent": "Although the health of the final join graph looks like.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second achievement buses after we have this optimized engine we cause in the centralization always has limitation in the query processing, so we scale it by federating multiple engines so we can stick it in, put it in a different physical location, for example, and in here we implement the client server architecture.",
                    "label": 0
                },
                {
                    "sent": "And we proposed the way to balance the performance.",
                    "label": 0
                },
                {
                    "sent": "When we register the query into different multiple instant, by the way, that the first one we.",
                    "label": 0
                },
                {
                    "sent": "Register the query Robin is.",
                    "label": 0
                },
                {
                    "sent": "For example, we have 5 incident with tankery.",
                    "label": 0
                },
                {
                    "sent": "Each instance will stick with two queries.",
                    "label": 0
                },
                {
                    "sent": "And the second one we choose the minimum average latency.",
                    "label": 1
                },
                {
                    "sent": "It means we choose the next instant if.",
                    "label": 0
                },
                {
                    "sent": "The latency of this incident is the minimum and the third one is we choose the minimum average website.",
                    "label": 0
                },
                {
                    "sent": "That is, we choose that instant if indicates the size of all of the buffer inside the engine is minimum.",
                    "label": 0
                },
                {
                    "sent": "Ann this is which we have to eval.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Addition on these tools, achievement the first one is on the schedule operation and the second load balancing.",
                    "label": 0
                },
                {
                    "sent": "We also check about the query registration time to see if it's practical in reality.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the joint performance we are conducted like because sequels is conducted in the LS man marked.",
                    "label": 0
                },
                {
                    "sent": "So we reproduce the experiment on that benchmark and try to compare with our optimized version.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, there is the.",
                    "label": 0
                },
                {
                    "sent": "Outperform the performance is almost always the original version.",
                    "label": 0
                },
                {
                    "sent": "We didn't compare with this barcode 'cause the way is this barcode using another semantic of execution so we don't want to force the experiment.",
                    "label": 0
                },
                {
                    "sent": "Like this, if it's more clear, we do and further.",
                    "label": 0
                },
                {
                    "sent": "The scalable instant.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we try to.",
                    "label": 0
                },
                {
                    "sent": "We use the Citibank match which allow us to.",
                    "label": 0
                },
                {
                    "sent": "To get the latency of each the engine and in this experiment we try to scale, scale the number of instant from one to four and as you can see the first, the first thing we achieve is when we scale the number of instant, then the latency.",
                    "label": 0
                },
                {
                    "sent": "We will decrease, but when it reached through the for instance, see the latency.",
                    "label": 0
                },
                {
                    "sent": "Increase again, this is because when the overhead up.",
                    "label": 0
                },
                {
                    "sent": "Threat allocation is always the.",
                    "label": 0
                },
                {
                    "sent": "The performance and.",
                    "label": 0
                },
                {
                    "sent": "In terms of different load balancing strategy, then we compare rotational latency.",
                    "label": 1
                },
                {
                    "sent": "Average latency, an average mobile size.",
                    "label": 0
                },
                {
                    "sent": "Then we conclude that the load balancing of buffer size strategy is the best one because it has the lowest latency.",
                    "label": 0
                },
                {
                    "sent": "So we choose this one I conduct.",
                    "label": 0
                },
                {
                    "sent": "Keep trying to evaluate the number of the stream of the can.",
                    "label": 0
                },
                {
                    "sent": "This can this scalable system consume.",
                    "label": 0
                },
                {
                    "sent": "Then this is not quite persuasive experiment, because basically that when the number of stream increased.",
                    "label": 0
                },
                {
                    "sent": "Then the latency is increased, but you see too weird behavior as animal Stream 7 and symbol stream 20s.",
                    "label": 0
                },
                {
                    "sent": "This because a bug in the concurrent modification that I fixed and I put the source code here so you can check.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the query registration time, when we submit the query, we record the time of submission an after the finish registration is sent back that we also recall the time.",
                    "label": 1
                },
                {
                    "sent": "So you can see in this three different load balancing strategies than the first one, the rotational latency.",
                    "label": 0
                },
                {
                    "sent": "One is more stable than the buffer size, one that is be cause if the query equivalently distributed to multiple instance than the the latency will be more stable, while in the upper side is really high fluctuation.",
                    "label": 0
                },
                {
                    "sent": "Because if one engineer just the number of query.",
                    "label": 0
                },
                {
                    "sent": "Distributed in different engine is really different and it created this.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the conclusion and future books, then the conclusion is you can see the the better performance of handling multiple already within hours, implemented version.",
                    "label": 1
                },
                {
                    "sent": "And also we successfully federate multiple instance too with different load balancing strategies.",
                    "label": 0
                },
                {
                    "sent": "But the point is, for the future work, there's a lot of things we can improve.",
                    "label": 1
                },
                {
                    "sent": "For example, we have to decrease the query registration time and don't use the recursive implementation because it's very, it's very.",
                    "label": 0
                },
                {
                    "sent": "Time consuming and also distributed model.",
                    "label": 0
                },
                {
                    "sent": "Then we can create more efficient load balancing strategies.",
                    "label": 0
                },
                {
                    "sent": "For example we can based on the selectivity of the joint operation inside each different level.",
                    "label": 0
                },
                {
                    "sent": "Two to two to create a more efficient lot messaging strategies.",
                    "label": 0
                },
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}