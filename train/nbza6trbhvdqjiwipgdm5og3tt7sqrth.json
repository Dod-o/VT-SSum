{
    "id": "nbza6trbhvdqjiwipgdm5og3tt7sqrth",
    "title": "Interactive Fingerprinting Codes and the Hardness of Preventing False Discovery",
    "info": {
        "author": [
            "Thomas Steinke, Harvard School of Engineering and Applied Sciences, Harvard University"
        ],
        "published": "Sept. 17, 2015",
        "recorded": "July 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2015_steinke_false_discovery/",
    "segmentation": [
        [
            "Alright good."
        ],
        [
            "So what's the motivation for this work?",
            "So we're motivated by this problem in science of false discovery, which means a scientist collect some data, does some analysis, reaches a conclusion, publishes it, and then it's wrong simply because their data doesn't reflect the real world in the matter that they're concerned about."
        ],
        [
            "So one potential cause of this is overuse of data or reuse of data.",
            "So in an ideal world, the way you use Sciences, you come with some hypothesis.",
            "You collect the data for it.",
            "You test the hypothesis and you throw away that data never to use it again.",
            "Of course, no one does this.",
            "We reuse our data all the time and the problem is that this can introduce all dependencies, so.",
            "Every time you do an analysis, the questions you're asking could depend on previous analysis of the same data set.",
            "So a good example of this is what's called Friedman's paradox.",
            "If you use the same data set to do variable selection.",
            "And then do a regression on that.",
            "You may end up discovering that there is a strong correlation there.",
            "Strong pattern, even though there's nothing there.",
            "So these things can cause serious problems."
        ],
        [
            "So how do we model this so that we can actually say something about this computer scientists?",
            "Well, we'll just assume that there's some sort of unknown population which will model as a probability distribution over some universe.",
            "And you collect some sample from that of size N so you don't have the full distribution and you plug that into your favorite statistical software, which will call the Oracle.",
            "And then you ask a bunch of queries to that those queries are going to be statistical queries, so you specify some predicate and then it will tell you approximately what the expectation of that predicate is over the distribution."
        ],
        [
            "So the key question which was first asked by Dwork Feldman, heart Pitassi wrangled and Roth.",
            "Is how many samples do I need if I'm going to ask a statistical queries and those queries are going to be adaptive queries?",
            "Some alternative formulation that's more in the machine learning languages.",
            "The following suppose I have a learning algorithm in the SQ fit framework.",
            "That means the task case artistical queries.",
            "And I want to turn this into the pack framework.",
            "That means it's going to get in samples and I'm just going to do this by answering statistical queries on my sample.",
            "How many samples do I need?",
            "So we're trying to understand the relationship between K&N."
        ],
        [
            "Great, so in the Nonadaptive case where I specify all my statistical queries up front.",
            "At once, and there's no dependency between them.",
            "We know that we only need logarithmically many samples and that's just a turnoff bound plus a union bound.",
            "But in the adaptive query setting we get very different results, so the main result of our work is that we need about square root K samples, so there's a lower bound.",
            "And this builds on previous work by Heart and Allman.",
            "Who gave a cube root K bound and now work improves on that and we know that our bound is approximately tide up to log rhythmic factors by the aforementioned work and some followups.",
            "And I should mention that we need some assumptions for our results hold.",
            "Either we need to be high dimensional data or we need to have some sort of computational assumptions.",
            "And if those assumptions are broken, these works so that we can actually do better, so these are necessary assumptions."
        ],
        [
            "OK, So what on Earth is going on here?",
            "What's the intuition for this?",
            "So suppose that the analyst like had complete knowledge of the data.",
            "And then could basically ask any query that she wanted.",
            "That could depend arbitrarily on the data.",
            "And should very easily overfit.",
            "There's nothing to stop her from asking queries that evaluates to one on the sample an zero everywhere else.",
            "And it actually turns out that if you ask enough statistical queries, you can identify what that sample is, and that's exactly how our result works.",
            "So you once you identify the sample, you can overfit it arbitrarily and we're just going to get no good soundness guarantees.",
            "And the key tool for analysis is what we call interactive fingerprinting codes, which also build on some earlier work.",
            "Thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright good.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what's the motivation for this work?",
                    "label": 0
                },
                {
                    "sent": "So we're motivated by this problem in science of false discovery, which means a scientist collect some data, does some analysis, reaches a conclusion, publishes it, and then it's wrong simply because their data doesn't reflect the real world in the matter that they're concerned about.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one potential cause of this is overuse of data or reuse of data.",
                    "label": 0
                },
                {
                    "sent": "So in an ideal world, the way you use Sciences, you come with some hypothesis.",
                    "label": 0
                },
                {
                    "sent": "You collect the data for it.",
                    "label": 0
                },
                {
                    "sent": "You test the hypothesis and you throw away that data never to use it again.",
                    "label": 0
                },
                {
                    "sent": "Of course, no one does this.",
                    "label": 0
                },
                {
                    "sent": "We reuse our data all the time and the problem is that this can introduce all dependencies, so.",
                    "label": 0
                },
                {
                    "sent": "Every time you do an analysis, the questions you're asking could depend on previous analysis of the same data set.",
                    "label": 1
                },
                {
                    "sent": "So a good example of this is what's called Friedman's paradox.",
                    "label": 1
                },
                {
                    "sent": "If you use the same data set to do variable selection.",
                    "label": 0
                },
                {
                    "sent": "And then do a regression on that.",
                    "label": 0
                },
                {
                    "sent": "You may end up discovering that there is a strong correlation there.",
                    "label": 0
                },
                {
                    "sent": "Strong pattern, even though there's nothing there.",
                    "label": 0
                },
                {
                    "sent": "So these things can cause serious problems.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we model this so that we can actually say something about this computer scientists?",
                    "label": 0
                },
                {
                    "sent": "Well, we'll just assume that there's some sort of unknown population which will model as a probability distribution over some universe.",
                    "label": 0
                },
                {
                    "sent": "And you collect some sample from that of size N so you don't have the full distribution and you plug that into your favorite statistical software, which will call the Oracle.",
                    "label": 1
                },
                {
                    "sent": "And then you ask a bunch of queries to that those queries are going to be statistical queries, so you specify some predicate and then it will tell you approximately what the expectation of that predicate is over the distribution.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the key question which was first asked by Dwork Feldman, heart Pitassi wrangled and Roth.",
                    "label": 0
                },
                {
                    "sent": "Is how many samples do I need if I'm going to ask a statistical queries and those queries are going to be adaptive queries?",
                    "label": 0
                },
                {
                    "sent": "Some alternative formulation that's more in the machine learning languages.",
                    "label": 0
                },
                {
                    "sent": "The following suppose I have a learning algorithm in the SQ fit framework.",
                    "label": 1
                },
                {
                    "sent": "That means the task case artistical queries.",
                    "label": 0
                },
                {
                    "sent": "And I want to turn this into the pack framework.",
                    "label": 0
                },
                {
                    "sent": "That means it's going to get in samples and I'm just going to do this by answering statistical queries on my sample.",
                    "label": 1
                },
                {
                    "sent": "How many samples do I need?",
                    "label": 0
                },
                {
                    "sent": "So we're trying to understand the relationship between K&N.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Great, so in the Nonadaptive case where I specify all my statistical queries up front.",
                    "label": 1
                },
                {
                    "sent": "At once, and there's no dependency between them.",
                    "label": 1
                },
                {
                    "sent": "We know that we only need logarithmically many samples and that's just a turnoff bound plus a union bound.",
                    "label": 0
                },
                {
                    "sent": "But in the adaptive query setting we get very different results, so the main result of our work is that we need about square root K samples, so there's a lower bound.",
                    "label": 0
                },
                {
                    "sent": "And this builds on previous work by Heart and Allman.",
                    "label": 0
                },
                {
                    "sent": "Who gave a cube root K bound and now work improves on that and we know that our bound is approximately tide up to log rhythmic factors by the aforementioned work and some followups.",
                    "label": 1
                },
                {
                    "sent": "And I should mention that we need some assumptions for our results hold.",
                    "label": 1
                },
                {
                    "sent": "Either we need to be high dimensional data or we need to have some sort of computational assumptions.",
                    "label": 0
                },
                {
                    "sent": "And if those assumptions are broken, these works so that we can actually do better, so these are necessary assumptions.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what on Earth is going on here?",
                    "label": 0
                },
                {
                    "sent": "What's the intuition for this?",
                    "label": 0
                },
                {
                    "sent": "So suppose that the analyst like had complete knowledge of the data.",
                    "label": 0
                },
                {
                    "sent": "And then could basically ask any query that she wanted.",
                    "label": 0
                },
                {
                    "sent": "That could depend arbitrarily on the data.",
                    "label": 0
                },
                {
                    "sent": "And should very easily overfit.",
                    "label": 1
                },
                {
                    "sent": "There's nothing to stop her from asking queries that evaluates to one on the sample an zero everywhere else.",
                    "label": 0
                },
                {
                    "sent": "And it actually turns out that if you ask enough statistical queries, you can identify what that sample is, and that's exactly how our result works.",
                    "label": 0
                },
                {
                    "sent": "So you once you identify the sample, you can overfit it arbitrarily and we're just going to get no good soundness guarantees.",
                    "label": 1
                },
                {
                    "sent": "And the key tool for analysis is what we call interactive fingerprinting codes, which also build on some earlier work.",
                    "label": 1
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        }
    }
}