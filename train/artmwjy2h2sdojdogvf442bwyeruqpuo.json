{
    "id": "artmwjy2h2sdojdogvf442bwyeruqpuo",
    "title": "Incremental Line-based 3D Reconstruction using Geometric Constraints",
    "info": {
        "author": [
            "Manuel Hofer, Institute for Computer Graphics and Vision, Graz University of Technology"
        ],
        "published": "April 3, 2014",
        "recorded": "September 2013",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/bmvc2013_hofer_geometric_constraints/",
    "segmentation": [
        [
            "I'm here to present our paper entitled Incremental Line based 3D reconstruction using geometric constraints and said this has been a joint work with understanding with our speech off.",
            "So this."
        ],
        [
            "Is a structure from motion paper basically so there have been a lot lots of structure for motion approaches presented over the years which enable us to reconstruct almost arbitrarily arbitrary scenes using several images from various viewpoints.",
            "Most for most of these approaches have in common is that they are usually based on interest points, so detection matching and matching of detection description of matching of interest points using for example sift, surf or whatever.",
            "And as you can expect, this usually delivers very accurate results for highly textured scenes where we have a lot of feature, a lot of lots of feature points.",
            "For example, in this scene here in the bottom we have sparsity reconstruction of a building using about 200 images, and the sparse reconstruction obtained by SIFT features already quite dense.",
            "But what is if you're encountering objects that do not have a lot of textures, or especially for assessing the right the virus structures?",
            "This is supposed to be the reconstruction of a power pile, and also using about 100.",
            "Images you can see that this is much sparser than this year.",
            "Well, this is obviously is also safe features, so it's obviously because even if you find features on this structure, then you can really describe these features.",
            "Something some kind of invariantly, because you just don't have a planner surface.",
            "So depending on how you look on this feature then you have a completely different Patch around this feature point and therefore you just cannot compute an accurate descriptor."
        ],
        [
            "So in order to overcome such problems, you could, for example uses an alternative line based reconstruction.",
            "They have also a lot of approaches being presented over the years, fewer than four point based, but still.",
            "And this is usually very suitable for the reconstruction of urban and especially also indoor scenes with textureless objects and also very objects.",
            "And the main procedure is pretty much similar.",
            "As for point features.",
            "So where we have here for example, when you see feature detection in the future description and matching, where could for example you shift you could there use the line segment detector, detect the line segments?",
            "You could use the mean standard line deviation descriptor to describe the segments and then you could use a pose estimation and reconstruction procedure.",
            "For example is this year.",
            "So I want to know."
        ],
        [
            "Focus a little bit more on the second part, the feature description and matching.",
            "Because you."
        ],
        [
            "Julie in the past for these approaches, this has been done.",
            "Also appearance based, so you could for example compute local line descriptor based on gradient color information such as.",
            "This means that line deviation or the scale invariant line transform.",
            "Or you could also use color histograms and long along the line segments As for example represented by being colleagues.",
            "But dear we have the problem that you wanted to overcome to reconstruct this virus structures is here also present.",
            "So this does obviously not work for various structures as well because so for this example we have.",
            "Two images for PowerPoint are from different viewpoints and the same part of the structure here is highlighted in yellow and if you now."
        ],
        [
            "Want to compute align descriptor based on the Patch which is here in this case at the left side of this line.",
            "So we will see the dispatches look very very don't look much like because of course these are different viewpoints.",
            "You can see through this structure and so you couldn't really just compute the descriptor from this from this.",
            "So doing."
        ],
        [
            "Research we stumbled across an appearance less approach, a very interesting one by Jane and colleagues presented at CPR 2010.",
            "They also made line based delivery construction, but you made it very differently than compared to previous approaches because first of all they assume that the cameras already known and what the what they did was they didn't really match the line segments across various views, but he tried rather to estimate for each line segment in each image individually.",
            "The most probably position in space.",
            "And then able at the end evaluate which positions have been estimated correctly using clustering.",
            "So for example here the for a line segment in one image, they would try to compute all possible locations in space needs to know the camera along in a certain sweeping range and for each of these positions they would back project the freelancing in neighboring images and then compute the gradient based score assuming that the correct position of the line segment in space would mean that this line.",
            "So it should be reasonably at least some other.",
            "Images and it should be somewhere where you have high gradients, because because this is usually how we detect line segments in images so and afterwards.",
            "So we have for each line.",
            "So we have done one hypothesis in space and what they did was they assume that if the alignment is visible in more than one image and we have estimated the position correctly in at least two images, then they would make spatial clustering by assuming that this estimated three positions should be closing space and line segments which they cannot find a valid cluster.",
            "I considered outliers and then removed.",
            "They showed very nice and very accurate results in the paper.",
            "But The thing is that this is very time consuming since you have this sweeping range and also the backprojection gradient scoring and this the reported that for a simple image sequence of let's say 102 hundred images, that would take several hours to compute so."
        ],
        [
            "Since we wanted to use this for our algorithms, we proposed earlier proposed modified approach where we said it doesn't make much sense to say that the line segment in one image could be anywhere in space, because we thought that might be might be able to compute as more of a discrete set of positions rather than discontinuous set.",
            "So what we did?"
        ],
        [
            "It was that we tried to find possible matches in the neighboring images using no appearance, but just weaker.",
            "People are constraints where we project were computed the epipolar lines for the endpoints of a line segment and then found possible matches.",
            "For example, saying that one of the endpoints of this segment here has to be near there.",
            "People are line even though we do not expect it to match correctly for both endpoints.",
            "But at least for one and the overlap has to be at least it's a 50%, but you can change these parameters very robustly.",
            "And then we have pasta set of possible matches in several neighboring images, and for each of these."
        ],
        [
            "Edges we can compute."
        ],
        [
            "Impossible for the location for this segment, using the triangulation of the endpoints in the intersection points with a polar lines, and this is now our discrete set of possible for the locations.",
            "Then we also evaluate the gradient based score by back projection and we kept the one with the highest score.",
            "Then afterwards you also performed.",
            "This is basically this clustering we have shown that this is much faster than the previous approach, but still it is probably slow."
        ],
        [
            "So we're short example.",
            "So for this pilot sequence with the sparse point cloud you have the cameras and you throw it.",
            "In our algorithm you would get the result like this.",
            "So especially at the bottom this is quite nice.",
            "At the top it's get a little noisy because these are ground level photographs, so these segments appear very are not very good detected in the images.",
            "And even though this is a better representation of the underlying structure rather than the sparse point cloud there is."
        ],
        [
            "Problem, so the runtime for this particular example was over 67 minutes on a multi threaded on a quad core E5.",
            "And yeah this is but this is the runtime for the line based delivery construction only.",
            "So you have to add to that the time you need to estimate where the cameras are.",
            "So this is not very satisfying, at least not for us."
        ],
        [
            "And so since we now knew in theory that we could reconstruct this complex objects objects as this virus structures, there are some challenging some challenges that remained.",
            "1st.",
            "One problem is that the cameras have to be known beforehand, so this is obviously not useful for real time applications.",
            "For example, is model based tracking for visual navigation tasks and the question was is it now possible to perform this appearance list language to the reconstruction also online?",
            "Second, this is very time consuming, so the bottlenecks are the gradient based scoring and the clustering procedure at the end where you have to cluster numerous 3D line hypothesis.",
            "So second question was, is it possible to avoid this?",
            "May be avoided scoring process at all in cluster corresponding poses already on the fly and sort the obviously reconstruction scale for this approach has to be known because we perform a spatial clustering and this would otherwise wouldn't be possible.",
            "We have to define a clustering radius so we have to know the scale and theater question.",
            "Is it possible to derive the clustering scale somehow from the image space from the observations in image space space without knowing the exact reconstruction scale?"
        ],
        [
            "So in order to do this was a motivation for our proposed approach and we wanted to develop this incremental reconstruction approach and therefore we needed something since we need still need the camera positions for the reconstruction, we needed an approach that is able to deliver this camera positions on the fly.",
            "Therefore we build up on or we wanted to integrate our process into an online structure for motion which was presented by my colleague Crystal Papa at last year's PC.",
            "To obtain this life camera poses so this works to follow in the following wave and a new image comes along there is an online structure for motion system using SIFT features and vocabulary trees.",
            "Then we get the sparse point cloud on the Flyers bundle adjustment, which is performed periodically.",
            "Also, this is surface extraction at the quality visualization, but it's important for us."
        ],
        [
            "And it is part, so the online structure for motion."
        ],
        [
            "Now given an image and given a camera post, we want to feed this in our language to the reconstruction."
        ],
        [
            "And we want to get incremental results for each new image.",
            "So."
        ],
        [
            "Now what we do is we adapt the line matching procedure from our previous approach, so we'll app this app.",
            "People are guided matching to find candidate matches.",
            "So basically one 2D line segment corresponds to a several possible matches in the neighboring images and therefore also several possible positions in space.",
            "But what we do differently now is instead of keeping one hypothesis with the maximum score today segment, we keep all the possibilities until we can make make a decision because The thing is, this is an incremental approach, so the same coverage maybe?",
            "Baby too small at a certain point that we cannot decide which opposes correct right now, because, for example, we only have 3 images.",
            "Then we can really make a good decision so.",
            "But we can also cannot rematch everything when more images are available.",
            "So we have to keep all of the things that we have computed so far.",
            "Then we want to perform an on the fly grouping to cluster corresponding lines directly together rather than doing this at the end.",
            "Because also we want to visualize the incremental results.",
            "And yeah, therefore we needed a way we need to develop a way to do that so that we get the results for each new image."
        ],
        [
            "So now it's an illustration of the reconstruction procedure so given."
        ],
        [
            "Two images and the camera corresponding cameras from the structure.",
            "For motion we want to match them together to create an initial hypothesis set.",
            "Capital H. Here this is a toy example.",
            "Here we have one line segment in this image in two and the other one, and the colors here indicate if they belong together or not.",
            "So I hope we can see this over the beamer.",
            "These two in blue should be matched together in fact.",
            "So what we do?"
        ],
        [
            "First, we also find the code matching candidates using the same people are constraints as I have already shown.",
            "And then for each."
        ],
        [
            "Possible match with."
        ],
        [
            "Create hypothesis."
        ],
        [
            "In space, by using about try also triangulate Ng the endpoints with the intersection points with everybody lines.",
            "So now but."
        ],
        [
            "These are hypothesis in our case hypothesis in our case consists of a triangulated line segment.",
            "It's consists of a set of corresponding to the line segments and the camera.",
            "So basically just point us to the structure from where they came from and Additionally we have a score and the corresponding camera.",
            "See star defined in the following way.",
            "The score for a hypothesis is just one minus the minimum of this function here, which is the absolute value of the unit directional vector of this triangulated segment and the unit directional vector of one of the cameras in this set.",
            "In see stars their foot in just the camera which maximizes the score.",
            "This means that the score is in this case high for help of thesis with a large angle between the camera and the segment itself, so that we avoid that we have offices has to ensure that this is a good visibility and corresponding camera.",
            "So."
        ],
        [
            "Now this if you have our.",
            "So initial set we want to do an incremental reconstruction, so if."
        ],
        [
            "A new image comes along.",
            "We have to find a set of neighboring images based on the angle between the camera race and overlapping feature points in world space.",
            "And now if we want to match this new image with the existing one."
        ],
        [
            "You also have to find the matching candidates as before and also before."
        ],
        [
            "Strangulation."
        ],
        [
            "But now, rather than also keeping this as a new hypothesis when cluster at the end as we did previously, we want to is now check if."
        ],
        [
            "Maybe this triangulated segment fits two or an existing hypothesis, so in this case you see."
        ],
        [
            "Yeah, it it fits to this apophysis and it doesn't fit to this one.",
            "So we want to integrate it into this to this existing offices."
        ],
        [
            "So how do we do that?",
            "Now we have to make a decision.",
            "When do we add line segment to an existing apophysis?",
            "In our case currently, we do that in a way that if the decision in 3D added distance in 3D is lower than a certain radius R and the distance in the image base is lower than a certain maximum uncertainty Sigma which is obtained by backprojection, we now we add the segment to this hypothesis.",
            "But the question is how do we estimate the thresholds?",
            "Because our our our usual obviously requires scale information which we do not have.",
            "And seeing that can be.",
            "Choosing more easily.",
            "For example, seeing we allow a maximum certainty in the image or for example one pixel.",
            "For example, if you have if you.",
            "Also, if you know your image size and we usually operate with images between 10 to 16 mega pixels."
        ],
        [
            "So what we want to do now we want to derive these are from this uncertainty Sigma.",
            "We do that by using a little trick we back project each new hypothesis in back into the images from which it came from, which which formed this hypothesis."
        ],
        [
            "Then shift this spectral segment by this value Sigma."
        ],
        [
            "Triangulated shifted Sigma and."
        ],
        [
            "Then define the this right radius Rs simply as the distance between the original and the shifted segment.",
            "One thing."
        ],
        [
            "Of course this.",
            "Doesn't necessarily necessarily mean that this is a very good estimation, because this depends on how far away hypothesis is from the camera or how good the triangulation angle is.",
            "So what we now do is.",
            "We compute characteristic grouping radios for for each camera by using simply median of all these, this radio rally from all the hypothesis which are referenced which are visible in this particular camera.",
            "Then for every further for every photo matching step forward which involves hypothesis we do not use this radius computer tier but rather the radius associated with characteristic camera."
        ],
        [
            "So therefore we do not very dependent of the reconstruction scale anymore."
        ],
        [
            "For incremental results we use a greedy algorithm.",
            "We sorta hypothesis that using the number of participating line segments and if this is equal we.",
            "If this is equally used, back projection, reprojection error and then we use iterate over this set and say if the hypothesize so the number of participating line segments is smaller is bigger than a certain value Lambda and the score is bigger than oh point 5, assuring a good visibility, we say is an inlier and therefore say this hypothesis is valid and can be visualized with.",
            "Then deactivate all hip of lines hypothesis that which are associated with any line segment which is also part part in this.",
            "Particularly purposes if the constraints are not fulfilled.",
            "We say it's an outlier.",
            "We then also remove unpromising people thesis from time to time, and so before I run out of time, there is a short visualization of the reconstruction procedure.",
            "So here basically you see how the cameras are integrated into the reconstruction.",
            "You can see how the point cloud along with the line model keeps growing overtime and to see also that the result gets denser and more images are available.",
            "This is not the real time reconstruction.",
            "This is an accelerated video, so usually it takes about 2 to 5 seconds per image.",
            "This is, I think this is 16 megapixel images.",
            "You can see that we are able to obtain a very nice reconstruction of this power Pi along without without variance to be outliers, so."
        ],
        [
            "This is a purely geometric approach.",
            "We do not perform any back projection and gradient based scoring anymore and we still are able to reconstruct this very structure very nicely.",
            "Justice for sure."
        ],
        [
            "Comparison, so this is the offline result.",
            "This is the online result.",
            "They look pretty similar, especially here, but the only result is much better at the top and."
        ],
        [
            "What difference very largely is?"
        ],
        [
            "Construction time, so this was 67 minutes only.",
            "The lines this was 9 minutes, but including the structure for motion.",
            "So we could basically reconstruct this on the fly through.",
            "Imagine how long a person would take to make the photos surrounding this object."
        ],
        [
            "So is lost with the evaluation using the timber frame sequence, which is synthetic sequence by this formula from Jane and colleagues we can see that this is our previous offline reconstruction.",
            "This is our online reconstruction.",
            "I guess we can see that the all three algorithms managed to reconstruct this model quite nicely and also the error to the ground truth model is comparably low."
        ],
        [
            "But what difference you very much is."
        ],
        [
            "Miss."
        ],
        [
            "Runtime so our approach took about 12 minutes.",
            "While this took several hours, this 45 minutes until 20 minutes, including including structure for motion so."
        ],
        [
            "Just a short conclusion, I hit these three questions and.",
            "What we have seen is that yes, it is possible to perform this.",
            "Iridium Online is also possible to avoid this scoring at all and cluster the corresponding processes on the fly and 3rd, it is also possible to derive the clustering radius from the image space without knowing the reconstruction scale."
        ],
        [
            "So sorry for too long, but thank you for attention and if you have further information, please visit our website.",
            "And if you have questions please ask them."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm here to present our paper entitled Incremental Line based 3D reconstruction using geometric constraints and said this has been a joint work with understanding with our speech off.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is a structure from motion paper basically so there have been a lot lots of structure for motion approaches presented over the years which enable us to reconstruct almost arbitrarily arbitrary scenes using several images from various viewpoints.",
                    "label": 0
                },
                {
                    "sent": "Most for most of these approaches have in common is that they are usually based on interest points, so detection matching and matching of detection description of matching of interest points using for example sift, surf or whatever.",
                    "label": 0
                },
                {
                    "sent": "And as you can expect, this usually delivers very accurate results for highly textured scenes where we have a lot of feature, a lot of lots of feature points.",
                    "label": 1
                },
                {
                    "sent": "For example, in this scene here in the bottom we have sparsity reconstruction of a building using about 200 images, and the sparse reconstruction obtained by SIFT features already quite dense.",
                    "label": 0
                },
                {
                    "sent": "But what is if you're encountering objects that do not have a lot of textures, or especially for assessing the right the virus structures?",
                    "label": 0
                },
                {
                    "sent": "This is supposed to be the reconstruction of a power pile, and also using about 100.",
                    "label": 0
                },
                {
                    "sent": "Images you can see that this is much sparser than this year.",
                    "label": 0
                },
                {
                    "sent": "Well, this is obviously is also safe features, so it's obviously because even if you find features on this structure, then you can really describe these features.",
                    "label": 0
                },
                {
                    "sent": "Something some kind of invariantly, because you just don't have a planner surface.",
                    "label": 0
                },
                {
                    "sent": "So depending on how you look on this feature then you have a completely different Patch around this feature point and therefore you just cannot compute an accurate descriptor.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in order to overcome such problems, you could, for example uses an alternative line based reconstruction.",
                    "label": 0
                },
                {
                    "sent": "They have also a lot of approaches being presented over the years, fewer than four point based, but still.",
                    "label": 0
                },
                {
                    "sent": "And this is usually very suitable for the reconstruction of urban and especially also indoor scenes with textureless objects and also very objects.",
                    "label": 1
                },
                {
                    "sent": "And the main procedure is pretty much similar.",
                    "label": 0
                },
                {
                    "sent": "As for point features.",
                    "label": 0
                },
                {
                    "sent": "So where we have here for example, when you see feature detection in the future description and matching, where could for example you shift you could there use the line segment detector, detect the line segments?",
                    "label": 0
                },
                {
                    "sent": "You could use the mean standard line deviation descriptor to describe the segments and then you could use a pose estimation and reconstruction procedure.",
                    "label": 0
                },
                {
                    "sent": "For example is this year.",
                    "label": 0
                },
                {
                    "sent": "So I want to know.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Focus a little bit more on the second part, the feature description and matching.",
                    "label": 0
                },
                {
                    "sent": "Because you.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Julie in the past for these approaches, this has been done.",
                    "label": 0
                },
                {
                    "sent": "Also appearance based, so you could for example compute local line descriptor based on gradient color information such as.",
                    "label": 1
                },
                {
                    "sent": "This means that line deviation or the scale invariant line transform.",
                    "label": 1
                },
                {
                    "sent": "Or you could also use color histograms and long along the line segments As for example represented by being colleagues.",
                    "label": 1
                },
                {
                    "sent": "But dear we have the problem that you wanted to overcome to reconstruct this virus structures is here also present.",
                    "label": 0
                },
                {
                    "sent": "So this does obviously not work for various structures as well because so for this example we have.",
                    "label": 0
                },
                {
                    "sent": "Two images for PowerPoint are from different viewpoints and the same part of the structure here is highlighted in yellow and if you now.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Want to compute align descriptor based on the Patch which is here in this case at the left side of this line.",
                    "label": 1
                },
                {
                    "sent": "So we will see the dispatches look very very don't look much like because of course these are different viewpoints.",
                    "label": 0
                },
                {
                    "sent": "You can see through this structure and so you couldn't really just compute the descriptor from this from this.",
                    "label": 0
                },
                {
                    "sent": "So doing.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Research we stumbled across an appearance less approach, a very interesting one by Jane and colleagues presented at CPR 2010.",
                    "label": 0
                },
                {
                    "sent": "They also made line based delivery construction, but you made it very differently than compared to previous approaches because first of all they assume that the cameras already known and what the what they did was they didn't really match the line segments across various views, but he tried rather to estimate for each line segment in each image individually.",
                    "label": 0
                },
                {
                    "sent": "The most probably position in space.",
                    "label": 0
                },
                {
                    "sent": "And then able at the end evaluate which positions have been estimated correctly using clustering.",
                    "label": 0
                },
                {
                    "sent": "So for example here the for a line segment in one image, they would try to compute all possible locations in space needs to know the camera along in a certain sweeping range and for each of these positions they would back project the freelancing in neighboring images and then compute the gradient based score assuming that the correct position of the line segment in space would mean that this line.",
                    "label": 1
                },
                {
                    "sent": "So it should be reasonably at least some other.",
                    "label": 0
                },
                {
                    "sent": "Images and it should be somewhere where you have high gradients, because because this is usually how we detect line segments in images so and afterwards.",
                    "label": 0
                },
                {
                    "sent": "So we have for each line.",
                    "label": 0
                },
                {
                    "sent": "So we have done one hypothesis in space and what they did was they assume that if the alignment is visible in more than one image and we have estimated the position correctly in at least two images, then they would make spatial clustering by assuming that this estimated three positions should be closing space and line segments which they cannot find a valid cluster.",
                    "label": 0
                },
                {
                    "sent": "I considered outliers and then removed.",
                    "label": 1
                },
                {
                    "sent": "They showed very nice and very accurate results in the paper.",
                    "label": 0
                },
                {
                    "sent": "But The thing is that this is very time consuming since you have this sweeping range and also the backprojection gradient scoring and this the reported that for a simple image sequence of let's say 102 hundred images, that would take several hours to compute so.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Since we wanted to use this for our algorithms, we proposed earlier proposed modified approach where we said it doesn't make much sense to say that the line segment in one image could be anywhere in space, because we thought that might be might be able to compute as more of a discrete set of positions rather than discontinuous set.",
                    "label": 0
                },
                {
                    "sent": "So what we did?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It was that we tried to find possible matches in the neighboring images using no appearance, but just weaker.",
                    "label": 0
                },
                {
                    "sent": "People are constraints where we project were computed the epipolar lines for the endpoints of a line segment and then found possible matches.",
                    "label": 0
                },
                {
                    "sent": "For example, saying that one of the endpoints of this segment here has to be near there.",
                    "label": 0
                },
                {
                    "sent": "People are line even though we do not expect it to match correctly for both endpoints.",
                    "label": 0
                },
                {
                    "sent": "But at least for one and the overlap has to be at least it's a 50%, but you can change these parameters very robustly.",
                    "label": 0
                },
                {
                    "sent": "And then we have pasta set of possible matches in several neighboring images, and for each of these.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Edges we can compute.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Impossible for the location for this segment, using the triangulation of the endpoints in the intersection points with a polar lines, and this is now our discrete set of possible for the locations.",
                    "label": 0
                },
                {
                    "sent": "Then we also evaluate the gradient based score by back projection and we kept the one with the highest score.",
                    "label": 0
                },
                {
                    "sent": "Then afterwards you also performed.",
                    "label": 0
                },
                {
                    "sent": "This is basically this clustering we have shown that this is much faster than the previous approach, but still it is probably slow.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're short example.",
                    "label": 0
                },
                {
                    "sent": "So for this pilot sequence with the sparse point cloud you have the cameras and you throw it.",
                    "label": 0
                },
                {
                    "sent": "In our algorithm you would get the result like this.",
                    "label": 0
                },
                {
                    "sent": "So especially at the bottom this is quite nice.",
                    "label": 0
                },
                {
                    "sent": "At the top it's get a little noisy because these are ground level photographs, so these segments appear very are not very good detected in the images.",
                    "label": 0
                },
                {
                    "sent": "And even though this is a better representation of the underlying structure rather than the sparse point cloud there is.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem, so the runtime for this particular example was over 67 minutes on a multi threaded on a quad core E5.",
                    "label": 0
                },
                {
                    "sent": "And yeah this is but this is the runtime for the line based delivery construction only.",
                    "label": 0
                },
                {
                    "sent": "So you have to add to that the time you need to estimate where the cameras are.",
                    "label": 0
                },
                {
                    "sent": "So this is not very satisfying, at least not for us.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so since we now knew in theory that we could reconstruct this complex objects objects as this virus structures, there are some challenging some challenges that remained.",
                    "label": 0
                },
                {
                    "sent": "1st.",
                    "label": 0
                },
                {
                    "sent": "One problem is that the cameras have to be known beforehand, so this is obviously not useful for real time applications.",
                    "label": 1
                },
                {
                    "sent": "For example, is model based tracking for visual navigation tasks and the question was is it now possible to perform this appearance list language to the reconstruction also online?",
                    "label": 1
                },
                {
                    "sent": "Second, this is very time consuming, so the bottlenecks are the gradient based scoring and the clustering procedure at the end where you have to cluster numerous 3D line hypothesis.",
                    "label": 1
                },
                {
                    "sent": "So second question was, is it possible to avoid this?",
                    "label": 0
                },
                {
                    "sent": "May be avoided scoring process at all in cluster corresponding poses already on the fly and sort the obviously reconstruction scale for this approach has to be known because we perform a spatial clustering and this would otherwise wouldn't be possible.",
                    "label": 0
                },
                {
                    "sent": "We have to define a clustering radius so we have to know the scale and theater question.",
                    "label": 0
                },
                {
                    "sent": "Is it possible to derive the clustering scale somehow from the image space from the observations in image space space without knowing the exact reconstruction scale?",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in order to do this was a motivation for our proposed approach and we wanted to develop this incremental reconstruction approach and therefore we needed something since we need still need the camera positions for the reconstruction, we needed an approach that is able to deliver this camera positions on the fly.",
                    "label": 0
                },
                {
                    "sent": "Therefore we build up on or we wanted to integrate our process into an online structure for motion which was presented by my colleague Crystal Papa at last year's PC.",
                    "label": 1
                },
                {
                    "sent": "To obtain this life camera poses so this works to follow in the following wave and a new image comes along there is an online structure for motion system using SIFT features and vocabulary trees.",
                    "label": 0
                },
                {
                    "sent": "Then we get the sparse point cloud on the Flyers bundle adjustment, which is performed periodically.",
                    "label": 0
                },
                {
                    "sent": "Also, this is surface extraction at the quality visualization, but it's important for us.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it is part, so the online structure for motion.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now given an image and given a camera post, we want to feed this in our language to the reconstruction.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we want to get incremental results for each new image.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now what we do is we adapt the line matching procedure from our previous approach, so we'll app this app.",
                    "label": 0
                },
                {
                    "sent": "People are guided matching to find candidate matches.",
                    "label": 0
                },
                {
                    "sent": "So basically one 2D line segment corresponds to a several possible matches in the neighboring images and therefore also several possible positions in space.",
                    "label": 1
                },
                {
                    "sent": "But what we do differently now is instead of keeping one hypothesis with the maximum score today segment, we keep all the possibilities until we can make make a decision because The thing is, this is an incremental approach, so the same coverage maybe?",
                    "label": 1
                },
                {
                    "sent": "Baby too small at a certain point that we cannot decide which opposes correct right now, because, for example, we only have 3 images.",
                    "label": 0
                },
                {
                    "sent": "Then we can really make a good decision so.",
                    "label": 0
                },
                {
                    "sent": "But we can also cannot rematch everything when more images are available.",
                    "label": 0
                },
                {
                    "sent": "So we have to keep all of the things that we have computed so far.",
                    "label": 0
                },
                {
                    "sent": "Then we want to perform an on the fly grouping to cluster corresponding lines directly together rather than doing this at the end.",
                    "label": 1
                },
                {
                    "sent": "Because also we want to visualize the incremental results.",
                    "label": 0
                },
                {
                    "sent": "And yeah, therefore we needed a way we need to develop a way to do that so that we get the results for each new image.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now it's an illustration of the reconstruction procedure so given.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two images and the camera corresponding cameras from the structure.",
                    "label": 0
                },
                {
                    "sent": "For motion we want to match them together to create an initial hypothesis set.",
                    "label": 1
                },
                {
                    "sent": "Capital H. Here this is a toy example.",
                    "label": 0
                },
                {
                    "sent": "Here we have one line segment in this image in two and the other one, and the colors here indicate if they belong together or not.",
                    "label": 0
                },
                {
                    "sent": "So I hope we can see this over the beamer.",
                    "label": 0
                },
                {
                    "sent": "These two in blue should be matched together in fact.",
                    "label": 0
                },
                {
                    "sent": "So what we do?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, we also find the code matching candidates using the same people are constraints as I have already shown.",
                    "label": 0
                },
                {
                    "sent": "And then for each.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Possible match with.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Create hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In space, by using about try also triangulate Ng the endpoints with the intersection points with everybody lines.",
                    "label": 0
                },
                {
                    "sent": "So now but.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These are hypothesis in our case hypothesis in our case consists of a triangulated line segment.",
                    "label": 1
                },
                {
                    "sent": "It's consists of a set of corresponding to the line segments and the camera.",
                    "label": 1
                },
                {
                    "sent": "So basically just point us to the structure from where they came from and Additionally we have a score and the corresponding camera.",
                    "label": 0
                },
                {
                    "sent": "See star defined in the following way.",
                    "label": 0
                },
                {
                    "sent": "The score for a hypothesis is just one minus the minimum of this function here, which is the absolute value of the unit directional vector of this triangulated segment and the unit directional vector of one of the cameras in this set.",
                    "label": 0
                },
                {
                    "sent": "In see stars their foot in just the camera which maximizes the score.",
                    "label": 0
                },
                {
                    "sent": "This means that the score is in this case high for help of thesis with a large angle between the camera and the segment itself, so that we avoid that we have offices has to ensure that this is a good visibility and corresponding camera.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now this if you have our.",
                    "label": 0
                },
                {
                    "sent": "So initial set we want to do an incremental reconstruction, so if.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A new image comes along.",
                    "label": 1
                },
                {
                    "sent": "We have to find a set of neighboring images based on the angle between the camera race and overlapping feature points in world space.",
                    "label": 0
                },
                {
                    "sent": "And now if we want to match this new image with the existing one.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You also have to find the matching candidates as before and also before.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Strangulation.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But now, rather than also keeping this as a new hypothesis when cluster at the end as we did previously, we want to is now check if.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe this triangulated segment fits two or an existing hypothesis, so in this case you see.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, it it fits to this apophysis and it doesn't fit to this one.",
                    "label": 0
                },
                {
                    "sent": "So we want to integrate it into this to this existing offices.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we do that?",
                    "label": 0
                },
                {
                    "sent": "Now we have to make a decision.",
                    "label": 0
                },
                {
                    "sent": "When do we add line segment to an existing apophysis?",
                    "label": 1
                },
                {
                    "sent": "In our case currently, we do that in a way that if the decision in 3D added distance in 3D is lower than a certain radius R and the distance in the image base is lower than a certain maximum uncertainty Sigma which is obtained by backprojection, we now we add the segment to this hypothesis.",
                    "label": 0
                },
                {
                    "sent": "But the question is how do we estimate the thresholds?",
                    "label": 0
                },
                {
                    "sent": "Because our our our usual obviously requires scale information which we do not have.",
                    "label": 0
                },
                {
                    "sent": "And seeing that can be.",
                    "label": 0
                },
                {
                    "sent": "Choosing more easily.",
                    "label": 0
                },
                {
                    "sent": "For example, seeing we allow a maximum certainty in the image or for example one pixel.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have if you.",
                    "label": 0
                },
                {
                    "sent": "Also, if you know your image size and we usually operate with images between 10 to 16 mega pixels.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we want to do now we want to derive these are from this uncertainty Sigma.",
                    "label": 0
                },
                {
                    "sent": "We do that by using a little trick we back project each new hypothesis in back into the images from which it came from, which which formed this hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then shift this spectral segment by this value Sigma.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Triangulated shifted Sigma and.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then define the this right radius Rs simply as the distance between the original and the shifted segment.",
                    "label": 0
                },
                {
                    "sent": "One thing.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of course this.",
                    "label": 0
                },
                {
                    "sent": "Doesn't necessarily necessarily mean that this is a very good estimation, because this depends on how far away hypothesis is from the camera or how good the triangulation angle is.",
                    "label": 0
                },
                {
                    "sent": "So what we now do is.",
                    "label": 0
                },
                {
                    "sent": "We compute characteristic grouping radios for for each camera by using simply median of all these, this radio rally from all the hypothesis which are referenced which are visible in this particular camera.",
                    "label": 1
                },
                {
                    "sent": "Then for every further for every photo matching step forward which involves hypothesis we do not use this radius computer tier but rather the radius associated with characteristic camera.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So therefore we do not very dependent of the reconstruction scale anymore.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For incremental results we use a greedy algorithm.",
                    "label": 1
                },
                {
                    "sent": "We sorta hypothesis that using the number of participating line segments and if this is equal we.",
                    "label": 1
                },
                {
                    "sent": "If this is equally used, back projection, reprojection error and then we use iterate over this set and say if the hypothesize so the number of participating line segments is smaller is bigger than a certain value Lambda and the score is bigger than oh point 5, assuring a good visibility, we say is an inlier and therefore say this hypothesis is valid and can be visualized with.",
                    "label": 0
                },
                {
                    "sent": "Then deactivate all hip of lines hypothesis that which are associated with any line segment which is also part part in this.",
                    "label": 0
                },
                {
                    "sent": "Particularly purposes if the constraints are not fulfilled.",
                    "label": 0
                },
                {
                    "sent": "We say it's an outlier.",
                    "label": 0
                },
                {
                    "sent": "We then also remove unpromising people thesis from time to time, and so before I run out of time, there is a short visualization of the reconstruction procedure.",
                    "label": 0
                },
                {
                    "sent": "So here basically you see how the cameras are integrated into the reconstruction.",
                    "label": 0
                },
                {
                    "sent": "You can see how the point cloud along with the line model keeps growing overtime and to see also that the result gets denser and more images are available.",
                    "label": 0
                },
                {
                    "sent": "This is not the real time reconstruction.",
                    "label": 0
                },
                {
                    "sent": "This is an accelerated video, so usually it takes about 2 to 5 seconds per image.",
                    "label": 1
                },
                {
                    "sent": "This is, I think this is 16 megapixel images.",
                    "label": 0
                },
                {
                    "sent": "You can see that we are able to obtain a very nice reconstruction of this power Pi along without without variance to be outliers, so.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a purely geometric approach.",
                    "label": 0
                },
                {
                    "sent": "We do not perform any back projection and gradient based scoring anymore and we still are able to reconstruct this very structure very nicely.",
                    "label": 0
                },
                {
                    "sent": "Justice for sure.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Comparison, so this is the offline result.",
                    "label": 0
                },
                {
                    "sent": "This is the online result.",
                    "label": 0
                },
                {
                    "sent": "They look pretty similar, especially here, but the only result is much better at the top and.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What difference very largely is?",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Construction time, so this was 67 minutes only.",
                    "label": 1
                },
                {
                    "sent": "The lines this was 9 minutes, but including the structure for motion.",
                    "label": 0
                },
                {
                    "sent": "So we could basically reconstruct this on the fly through.",
                    "label": 0
                },
                {
                    "sent": "Imagine how long a person would take to make the photos surrounding this object.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So is lost with the evaluation using the timber frame sequence, which is synthetic sequence by this formula from Jane and colleagues we can see that this is our previous offline reconstruction.",
                    "label": 0
                },
                {
                    "sent": "This is our online reconstruction.",
                    "label": 0
                },
                {
                    "sent": "I guess we can see that the all three algorithms managed to reconstruct this model quite nicely and also the error to the ground truth model is comparably low.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But what difference you very much is.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Miss.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Runtime so our approach took about 12 minutes.",
                    "label": 0
                },
                {
                    "sent": "While this took several hours, this 45 minutes until 20 minutes, including including structure for motion so.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just a short conclusion, I hit these three questions and.",
                    "label": 0
                },
                {
                    "sent": "What we have seen is that yes, it is possible to perform this.",
                    "label": 1
                },
                {
                    "sent": "Iridium Online is also possible to avoid this scoring at all and cluster the corresponding processes on the fly and 3rd, it is also possible to derive the clustering radius from the image space without knowing the reconstruction scale.",
                    "label": 1
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So sorry for too long, but thank you for attention and if you have further information, please visit our website.",
                    "label": 0
                },
                {
                    "sent": "And if you have questions please ask them.",
                    "label": 0
                }
            ]
        }
    }
}