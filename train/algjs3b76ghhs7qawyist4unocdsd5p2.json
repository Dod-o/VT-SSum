{
    "id": "algjs3b76ghhs7qawyist4unocdsd5p2",
    "title": "Assigning Semantic Labels to Data Sources",
    "info": {
        "author": [
            "Ramnandan Krishnamurthy, Indian Institute of Technology Madras"
        ],
        "published": "July 15, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2015_krishnamurthy_data_sources/",
    "segmentation": [
        [
            "So hi Rama from the Indian Institute of Technology, Madras.",
            "So this work titled Assigning Semantic labels to data sources was done with Craig, Knoblock, and Pedro's.",
            "Actually at the Information Sciences Institute last summer.",
            "So."
        ],
        [
            "Let me put our work in the bigger picture of why do we want to do it?",
            "And so and what do we want to achieve?",
            "So at the end we want to automatically construct a semantic model for a given set of data sources using a set of domain ontologies which are chosen by the user and so currently this is being done.",
            "But this is mostly being done manually and that is a very time consuming and tedious task and like and why do we want to do this is another question and there are many tasks which can be automated.",
            "Through through through the process of semantic modeling, and these include integration of heterogeneous data sources, building knowledge, graph service composition, discovery of data sources, and so on, and I'd like to add that process of semantic modeling has been implemented as an open source tool at the Information Sciences Institute, and it's called Karma.",
            "So you're welcome to check it out."
        ],
        [
            "OK, So what do we mean by a semantic model?",
            "So essentially it means it's a description of the data source in terms of concepts and relationships, which are from the domain Ontology which is specified by the user.",
            "So I'm just going through illustrative example here, so we have.",
            "So this is an example domain ontology.",
            "And as you can see it's just about persons, organisations and places and it's subclasses, which are against city, state.",
            "And here you have a data source which we want whose whose meaning we want to model.",
            "Using the ontology and so."
        ],
        [
            "This is the semantic model which we want to achieve at the end, so essentially we're capturing the intended meaning of the attributes of the data source through data properties and class properties of the ontology.",
            "So this is what we want to achieve at the end, but this is not so but our work.",
            "So this process of semantic modeling can be broken down into 2 steps and our work is essentially the 1st."
        ],
        [
            "Step, which is essentially the semantic labeling step.",
            "So essentially this step is the first step which is assigning a data property or a class from the ontology to each attribute of the data source.",
            "And as you can see this is.",
            "This is the first step in posts which you need to identify.",
            "What are the relationships between the data properties you have identified.",
            "So example so you can see that the first one represents the name of a person in the second third column is the name of an organization, but you need to identify the path in the ontology connecting these two concepts, which is essentially here.",
            "Would be that this person is working for this organization, but we're not going to go through that and our work is essentially tackling the first problem, which is called semantic labeling."
        ],
        [
            "Yeah, so to put it so odd works is like this.",
            "The first block in the overall work of semantic modeling, which was done by the Harry and again from the Information Sciences Institute.",
            "And you're welcome to look it up for the remainder portion of the framework and so traditionally prior to our work, most of the semantic labeling or was done using model based machine learning techniques and so at the examples of conditional random fields support vector machines.",
            "And conditional random fields which empirically found to be performing the best and that is what is implemented was implemented into Ariens work so but there are issues with model based techniques.",
            "So what are the issues?",
            "So they specific specifically for numeric data it has very low label prediction accuracy and again is scalability is poor in that as the number of data properties in the ontology increases there's explosion of sales search space and hence.",
            "Training time again exponentially increases, so I'll go into the details of why that happens, but the main reason is that these approaches essentially extract features from individual data values from the from the column which you want to assign a Type 2, and hence you and then.",
            "Then you build a model around it, but so essentially what we were trying to do is.",
            "So can we think of an alternate approach to this?"
        ],
        [
            "So this is the approach which we've developed, which is called Sam Typer.",
            "And So what we wanted to do is can we take a holistic view of the data values associated with the attribute and so in that way we can come up with a characteristic property of the data values associated with the semantic type.",
            "So our approach is again a hybrid approach where we decomposed between whether the attribute is a textual data attribute or a numeric data attribute.",
            "So the textual data attribute we use TF IDF cosine similarity based approach.",
            "And for numeric data we use the statistical hypothesis test called the Congressman of Tests, and I'll go into the details again.",
            "So, but what do we want to do?",
            "So, given an attribute of whose semantic type we want to predict, we predict the top K candidate semantic labels along with the confidence score we associate with each of them."
        ],
        [
            "Yeah, so this is what we do for the text for a.",
            "For now, given a attribute consisting of textual data texture, later values.",
            "So this is our approach.",
            "So in the training data for each semantic label, we treat the collection of data values associated with it as a document, and again at query time we we treat the attribute as a query document and we index the documents to improve query time efficiency.",
            "And before we index we also tokenize the data values.",
            "And we perform normalization such as the normal natural language processing techniques, such as stemming, removal of blank spaces, removal of stop words and etc.",
            "So I think I'll go use this example to make it a little more clear, so now so these correspond to add textual data attributes.",
            "So what we do is we construct a vector model representation for each document.",
            "So for example, the dimensions in the vector now correspond to the tokens you have extracted.",
            "So for example, if it's going to be something about.",
            "Dimensions and extends so the tokens are going to be like the ones we've shown here.",
            "HW in and the weights we assign to each token or the is the TF IDF score.",
            "And as you know.",
            "We captured the important notion of the token is going to be characteristic for a semantic type using the idea of value, which is basically the inverse document frequency.",
            "So now what do we do?",
            "So given A at query time for the query document in a pairwise fashion, we calculate the TF IDF cosine similarity to each of the documents corresponding to the semantic type in the training data, and we predict the top K semantic semantic labels from that."
        ],
        [
            "And now what about numeric data?",
            "So this was the major problem we faced in model based techniques.",
            "So what we do here is we identify that for numeric data, instead of extracting features from individual data values from which you obviously cannot come up with, we cannot predict what the semantic type is going to be from a single data value.",
            "But what we do is we extract the distribution of data values from corresponding to a semantic type.",
            "So obvious, obviously you know that the distribution of values for, say weights is going to be different from that for temperature.",
            "So what we do is so here.",
            "So so we tried.",
            "So we wanted a technique to compare the similarity of distribution.",
            "So we ended up using statistical hypothesis tests and we evaluated multiple tests in order to come up with which is going to be the best.",
            "So we use Welch's T test.",
            "We use Mann Whitney U test, graphs manifest and implicate empirically.",
            "We found that the congressman of test clearly bet all the other approaches.",
            "So what do we do in such an approach?",
            "So given two samples of data.",
            "Whose distribution we need to compare, such as the two here.",
            "So you know that both of these attributes essentially correspond to the same semantic type of population.",
            "So how do we capture that?",
            "So we essentially compute the cumulative distribution function from the two samples and we calculate the D statistic, which is basically the maximal separation between the two distributions.",
            "An Associated P value.",
            "So the P value is crucial in our approaches in that it captures how.",
            "So essentially it's correlated to the fact that the two samples.",
            "On from the same population and here population represents the same semantic type.",
            "So so once you have the P value is so now we identified that the P value is a measure of the similarity of distributions.",
            "So at query time for an attribute we in a pairwise fashion, we compute its computers P value with respect to the distributions in the training data and we predict the top K semantic types for the numeric data."
        ],
        [
            "So yeah, so not in the real world.",
            "We our approach is done as in so given an attribute if it's a textual attribute, we use the TF IDF cosine similarity, and if it's a numeric attribute we use statistical hypothesis testing.",
            "But this hardly happens in real life.",
            "So in real life we have a lot of noisy datasets in that when you're given an attribute it is a mixture of both textual and numeric value, so at so how do you identify what tests what is what is the approach we're going to follow for this?",
            "So this is what we do.",
            "So we follow a disambiguation approach in which at foreach semantic type in the training data, we computed the fraction of numeric values and for example, this is for one of the datasets.",
            "So if the fraction is less than 60%, we treat it as a textual column in that we index it using Apache Lucene and if it's greater than 80% we extract its distribution of the throwing out the next textual values and if it falls in the middle range where it's ambiguous between 60 and 80%.",
            "So there we.",
            "Index it assuming it's a textual date date attribute as well as extract its distribution.",
            "Assuming it's a numeric data column and at query time given, and you attribute again, we calculate its fraction of non numeric values and based on the threshold whether it's less than 70% or greater than 70%, we treat it as a textual or a numeric approach attribute so and the attributes the thresholds which are chosen for a data set are essentially obtained using a grid search.",
            "On a hotel headed outside."
        ],
        [
            "So yeah, now let's go into the evaluation, which we did, so we broke our evaluation down into three separate stages.",
            "So first we evaluated only textual data approach and we did that on a collection of 29.",
            "Your data sources from US museums and to evaluate our numeric data approach separately, we identified 32 numeric data properties corresponding to the city class in DB pedia.",
            "We extracted the data values and partition them into ten data sources.",
            "And for the effort to evaluate our overall approach on mixture of both textual and numeric semantic types, we identified an additional 22 textual data attributes from DB pedia.",
            "Combine that with the one we had chosen for numeric and came up with again a set of data.",
            "10 data sources to test the same type of approach and we also wanted to validate it on a couple of other domains to just make sure it's not secured in any sense.",
            "So hence we used datasets from the weather.",
            "Phone directory and flight domain which is already used in a previous work bandwidth."
        ],
        [
            "And So what are the metrics we use?",
            "So essentially we are predicting the topcase semantic labels for each attribute, so we needed a measure which captures the rank at which we predict the correct semantic label.",
            "So hence we use the main reciprocal rank.",
            "So just in case you're not too familiar, the so if you're predicting the top four semantic types for each attribute, if the correct label is predicted, the first position, you get an MRI score of 1 at the second you get .5, the third you get one by three and.",
            "At 4th, one by four, and if you don't do it, you get this code of zero and this captures the label prediction accuracy and we also wanted to capture the scalability, so hence we use the average we captured the average training time."
        ],
        [
            "So this is the first.",
            "This is the evaluation results for the textual data approach.",
            "So here we show the variation of mean reciprocal rank with the number of labeled data sources in the training data.",
            "So the approach is we compare here.",
            "RR is our approach, which is essentially the TF IDF cosine similarity approach against the model based technique, which is CRF and also the Jaccard similarity approach.",
            "So the Jaccard similarity approach was the was another approach we tried for textual data in which the weights you assign in each vector is going to be now not the TF IDF score, but just.",
            "A binary score of one or zero depending on whether the term is present in the vector or not.",
            "So essentially what happens is that a document now breaks down into a set and to compare the similarity of two sets we used the Jaccard similarity.",
            "So again, you see that the TF IDF approach clearly outperforms all the other approaches and it scales as well as the number of data sources in the in the training data increases.",
            "So one interesting observation is that for the Jaccard similarity approach you see that as you keep.",
            "Adding more label data sources, its performance actually decreases, so that is essentially because the binary weights were not informative enough to capture the fact that certain terms are more important than others."
        ],
        [
            "So this is for the numeric data approach.",
            "So again here we can see that the statistical hypothesis test, which is the Kolmogorov Smirnov test, clearly outperforms the other approaches.",
            "We have a step improvement and but again, the input on the interesting observation is that the Welch's T test is clearly the worst among them.",
            "That is because it's a fun factor that the Welch's T test makes, like underlying assumptions that population is Gaussian and that.",
            "Two samples have equal number of data values, which obviously is not satisfied in the real world.",
            "And."
        ],
        [
            "Yeah, this is the overall approach.",
            "The awesome typer approach on a collection of both numeric and textual semantic labels.",
            "So again here you can see that the semantic typer approach as a .1, which is a step improvement in terms of MRR over the CRF.",
            "An text TF IDF based approach, where in TF IDF approach based approach what we did, we assume that even the numeric data values is a textual document and we try to compute its TF IDF cosine similarity.",
            "And another major point is that we have not talked about the scalability here.",
            "So in terms of scalability, we can see that our approach is about 250 times faster than model based techniques such as CRF.",
            "And also we can see that we don't have the problem of exponential increase in training time as the number of labeled data sources increases as was the case for CRF."
        ],
        [
            "Yeah, and this was for the other domains we wanted to validate, which is basically the weather flight status and phone directory domains.",
            "So the 1st three columns are just basically a description of the data source in terms of number of sources as the fraction of textual and numeric semantic types, so again you can see that for the same type of approach has a marketing significant increase in MRR over the CRF and TF IDF based approaches.",
            "The thing is that the phone directory domain had mostly textual data and hence you can see that the same type of approach basically breaks down to be the same as the TF IDF based approach."
        ],
        [
            "Yeah, so OK, so just to show that we've compared against a variety of work which is already been done in this domain.",
            "So there's a group of work which is basically using model based machine learning techniques like the CRF, which is basically what goal at all had done and what these approaches do is, as I had said, they extract features from individual data values and build a model around it so they don't essentially capture a characteristic property which like which which you would if you had taken a holistic view of the data values.",
            "And again, these are not scalable in training graphical models.",
            "And the other set of approaches essentially use external knowledge, so for and they use actually leveraged data which is present on the web to create a database of like saying.",
            "This value essentially corresponds to this type and hence they assign a type to each data value and then like find the majority semantic type in the data values to assign a type to this amount to the entire column.",
            "So major flaw with these approaches is that they are restricted to domains where a large amount of web is.",
            "Data is present on the web and also their ontology specific in that.",
            "So you're training a model assuming DB pedia.",
            "So what if the user is giving you a new ontology which he has defined?",
            "So there's going to be a mismatch between these two.",
            "And we also like to.",
            "At time of present the work of Stonebraker who addressed essentially the problem of some schema matching, but we drew inspiration from the work in combining a collection of experts and the and essentially, which was not being done for in this domain earlier."
        ],
        [
            "So to conclude, what is our approach at the end, provide in terms of label prediction accuracy.",
            "We clearly outperform other techniques.",
            "Competing approaches as shown through MRR an we end as shown.",
            "We're about 250 times faster than a machine machine learning model based machine learning techniques such as conditional random fields and also we are able to capture the problem of handling noisy datasets through our disambiguation approach and another salient feature is that.",
            "Our approach is ontology agnostic in that we don't make any restrictions on the user in terms of the ontology from which we predict the labels, and we allow the user to choose the ontology from which the semantic types have to be predicted."
        ],
        [
            "Yes, so thank you in question.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So hi Rama from the Indian Institute of Technology, Madras.",
                    "label": 1
                },
                {
                    "sent": "So this work titled Assigning Semantic labels to data sources was done with Craig, Knoblock, and Pedro's.",
                    "label": 1
                },
                {
                    "sent": "Actually at the Information Sciences Institute last summer.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me put our work in the bigger picture of why do we want to do it?",
                    "label": 0
                },
                {
                    "sent": "And so and what do we want to achieve?",
                    "label": 0
                },
                {
                    "sent": "So at the end we want to automatically construct a semantic model for a given set of data sources using a set of domain ontologies which are chosen by the user and so currently this is being done.",
                    "label": 1
                },
                {
                    "sent": "But this is mostly being done manually and that is a very time consuming and tedious task and like and why do we want to do this is another question and there are many tasks which can be automated.",
                    "label": 0
                },
                {
                    "sent": "Through through through the process of semantic modeling, and these include integration of heterogeneous data sources, building knowledge, graph service composition, discovery of data sources, and so on, and I'd like to add that process of semantic modeling has been implemented as an open source tool at the Information Sciences Institute, and it's called Karma.",
                    "label": 0
                },
                {
                    "sent": "So you're welcome to check it out.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what do we mean by a semantic model?",
                    "label": 0
                },
                {
                    "sent": "So essentially it means it's a description of the data source in terms of concepts and relationships, which are from the domain Ontology which is specified by the user.",
                    "label": 1
                },
                {
                    "sent": "So I'm just going through illustrative example here, so we have.",
                    "label": 0
                },
                {
                    "sent": "So this is an example domain ontology.",
                    "label": 0
                },
                {
                    "sent": "And as you can see it's just about persons, organisations and places and it's subclasses, which are against city, state.",
                    "label": 0
                },
                {
                    "sent": "And here you have a data source which we want whose whose meaning we want to model.",
                    "label": 0
                },
                {
                    "sent": "Using the ontology and so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the semantic model which we want to achieve at the end, so essentially we're capturing the intended meaning of the attributes of the data source through data properties and class properties of the ontology.",
                    "label": 0
                },
                {
                    "sent": "So this is what we want to achieve at the end, but this is not so but our work.",
                    "label": 0
                },
                {
                    "sent": "So this process of semantic modeling can be broken down into 2 steps and our work is essentially the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Step, which is essentially the semantic labeling step.",
                    "label": 1
                },
                {
                    "sent": "So essentially this step is the first step which is assigning a data property or a class from the ontology to each attribute of the data source.",
                    "label": 1
                },
                {
                    "sent": "And as you can see this is.",
                    "label": 0
                },
                {
                    "sent": "This is the first step in posts which you need to identify.",
                    "label": 0
                },
                {
                    "sent": "What are the relationships between the data properties you have identified.",
                    "label": 0
                },
                {
                    "sent": "So example so you can see that the first one represents the name of a person in the second third column is the name of an organization, but you need to identify the path in the ontology connecting these two concepts, which is essentially here.",
                    "label": 0
                },
                {
                    "sent": "Would be that this person is working for this organization, but we're not going to go through that and our work is essentially tackling the first problem, which is called semantic labeling.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so to put it so odd works is like this.",
                    "label": 0
                },
                {
                    "sent": "The first block in the overall work of semantic modeling, which was done by the Harry and again from the Information Sciences Institute.",
                    "label": 0
                },
                {
                    "sent": "And you're welcome to look it up for the remainder portion of the framework and so traditionally prior to our work, most of the semantic labeling or was done using model based machine learning techniques and so at the examples of conditional random fields support vector machines.",
                    "label": 0
                },
                {
                    "sent": "And conditional random fields which empirically found to be performing the best and that is what is implemented was implemented into Ariens work so but there are issues with model based techniques.",
                    "label": 0
                },
                {
                    "sent": "So what are the issues?",
                    "label": 0
                },
                {
                    "sent": "So they specific specifically for numeric data it has very low label prediction accuracy and again is scalability is poor in that as the number of data properties in the ontology increases there's explosion of sales search space and hence.",
                    "label": 1
                },
                {
                    "sent": "Training time again exponentially increases, so I'll go into the details of why that happens, but the main reason is that these approaches essentially extract features from individual data values from the from the column which you want to assign a Type 2, and hence you and then.",
                    "label": 0
                },
                {
                    "sent": "Then you build a model around it, but so essentially what we were trying to do is.",
                    "label": 0
                },
                {
                    "sent": "So can we think of an alternate approach to this?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the approach which we've developed, which is called Sam Typer.",
                    "label": 0
                },
                {
                    "sent": "And So what we wanted to do is can we take a holistic view of the data values associated with the attribute and so in that way we can come up with a characteristic property of the data values associated with the semantic type.",
                    "label": 1
                },
                {
                    "sent": "So our approach is again a hybrid approach where we decomposed between whether the attribute is a textual data attribute or a numeric data attribute.",
                    "label": 1
                },
                {
                    "sent": "So the textual data attribute we use TF IDF cosine similarity based approach.",
                    "label": 0
                },
                {
                    "sent": "And for numeric data we use the statistical hypothesis test called the Congressman of Tests, and I'll go into the details again.",
                    "label": 0
                },
                {
                    "sent": "So, but what do we want to do?",
                    "label": 0
                },
                {
                    "sent": "So, given an attribute of whose semantic type we want to predict, we predict the top K candidate semantic labels along with the confidence score we associate with each of them.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so this is what we do for the text for a.",
                    "label": 0
                },
                {
                    "sent": "For now, given a attribute consisting of textual data texture, later values.",
                    "label": 0
                },
                {
                    "sent": "So this is our approach.",
                    "label": 0
                },
                {
                    "sent": "So in the training data for each semantic label, we treat the collection of data values associated with it as a document, and again at query time we we treat the attribute as a query document and we index the documents to improve query time efficiency.",
                    "label": 0
                },
                {
                    "sent": "And before we index we also tokenize the data values.",
                    "label": 0
                },
                {
                    "sent": "And we perform normalization such as the normal natural language processing techniques, such as stemming, removal of blank spaces, removal of stop words and etc.",
                    "label": 0
                },
                {
                    "sent": "So I think I'll go use this example to make it a little more clear, so now so these correspond to add textual data attributes.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we construct a vector model representation for each document.",
                    "label": 0
                },
                {
                    "sent": "So for example, the dimensions in the vector now correspond to the tokens you have extracted.",
                    "label": 0
                },
                {
                    "sent": "So for example, if it's going to be something about.",
                    "label": 0
                },
                {
                    "sent": "Dimensions and extends so the tokens are going to be like the ones we've shown here.",
                    "label": 0
                },
                {
                    "sent": "HW in and the weights we assign to each token or the is the TF IDF score.",
                    "label": 0
                },
                {
                    "sent": "And as you know.",
                    "label": 0
                },
                {
                    "sent": "We captured the important notion of the token is going to be characteristic for a semantic type using the idea of value, which is basically the inverse document frequency.",
                    "label": 0
                },
                {
                    "sent": "So now what do we do?",
                    "label": 0
                },
                {
                    "sent": "So given A at query time for the query document in a pairwise fashion, we calculate the TF IDF cosine similarity to each of the documents corresponding to the semantic type in the training data, and we predict the top K semantic semantic labels from that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now what about numeric data?",
                    "label": 1
                },
                {
                    "sent": "So this was the major problem we faced in model based techniques.",
                    "label": 0
                },
                {
                    "sent": "So what we do here is we identify that for numeric data, instead of extracting features from individual data values from which you obviously cannot come up with, we cannot predict what the semantic type is going to be from a single data value.",
                    "label": 0
                },
                {
                    "sent": "But what we do is we extract the distribution of data values from corresponding to a semantic type.",
                    "label": 0
                },
                {
                    "sent": "So obvious, obviously you know that the distribution of values for, say weights is going to be different from that for temperature.",
                    "label": 0
                },
                {
                    "sent": "So what we do is so here.",
                    "label": 0
                },
                {
                    "sent": "So so we tried.",
                    "label": 0
                },
                {
                    "sent": "So we wanted a technique to compare the similarity of distribution.",
                    "label": 1
                },
                {
                    "sent": "So we ended up using statistical hypothesis tests and we evaluated multiple tests in order to come up with which is going to be the best.",
                    "label": 0
                },
                {
                    "sent": "So we use Welch's T test.",
                    "label": 0
                },
                {
                    "sent": "We use Mann Whitney U test, graphs manifest and implicate empirically.",
                    "label": 0
                },
                {
                    "sent": "We found that the congressman of test clearly bet all the other approaches.",
                    "label": 0
                },
                {
                    "sent": "So what do we do in such an approach?",
                    "label": 0
                },
                {
                    "sent": "So given two samples of data.",
                    "label": 0
                },
                {
                    "sent": "Whose distribution we need to compare, such as the two here.",
                    "label": 0
                },
                {
                    "sent": "So you know that both of these attributes essentially correspond to the same semantic type of population.",
                    "label": 0
                },
                {
                    "sent": "So how do we capture that?",
                    "label": 0
                },
                {
                    "sent": "So we essentially compute the cumulative distribution function from the two samples and we calculate the D statistic, which is basically the maximal separation between the two distributions.",
                    "label": 0
                },
                {
                    "sent": "An Associated P value.",
                    "label": 0
                },
                {
                    "sent": "So the P value is crucial in our approaches in that it captures how.",
                    "label": 0
                },
                {
                    "sent": "So essentially it's correlated to the fact that the two samples.",
                    "label": 0
                },
                {
                    "sent": "On from the same population and here population represents the same semantic type.",
                    "label": 0
                },
                {
                    "sent": "So so once you have the P value is so now we identified that the P value is a measure of the similarity of distributions.",
                    "label": 0
                },
                {
                    "sent": "So at query time for an attribute we in a pairwise fashion, we compute its computers P value with respect to the distributions in the training data and we predict the top K semantic types for the numeric data.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So yeah, so not in the real world.",
                    "label": 0
                },
                {
                    "sent": "We our approach is done as in so given an attribute if it's a textual attribute, we use the TF IDF cosine similarity, and if it's a numeric attribute we use statistical hypothesis testing.",
                    "label": 0
                },
                {
                    "sent": "But this hardly happens in real life.",
                    "label": 0
                },
                {
                    "sent": "So in real life we have a lot of noisy datasets in that when you're given an attribute it is a mixture of both textual and numeric value, so at so how do you identify what tests what is what is the approach we're going to follow for this?",
                    "label": 1
                },
                {
                    "sent": "So this is what we do.",
                    "label": 1
                },
                {
                    "sent": "So we follow a disambiguation approach in which at foreach semantic type in the training data, we computed the fraction of numeric values and for example, this is for one of the datasets.",
                    "label": 0
                },
                {
                    "sent": "So if the fraction is less than 60%, we treat it as a textual column in that we index it using Apache Lucene and if it's greater than 80% we extract its distribution of the throwing out the next textual values and if it falls in the middle range where it's ambiguous between 60 and 80%.",
                    "label": 0
                },
                {
                    "sent": "So there we.",
                    "label": 0
                },
                {
                    "sent": "Index it assuming it's a textual date date attribute as well as extract its distribution.",
                    "label": 0
                },
                {
                    "sent": "Assuming it's a numeric data column and at query time given, and you attribute again, we calculate its fraction of non numeric values and based on the threshold whether it's less than 70% or greater than 70%, we treat it as a textual or a numeric approach attribute so and the attributes the thresholds which are chosen for a data set are essentially obtained using a grid search.",
                    "label": 1
                },
                {
                    "sent": "On a hotel headed outside.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So yeah, now let's go into the evaluation, which we did, so we broke our evaluation down into three separate stages.",
                    "label": 0
                },
                {
                    "sent": "So first we evaluated only textual data approach and we did that on a collection of 29.",
                    "label": 0
                },
                {
                    "sent": "Your data sources from US museums and to evaluate our numeric data approach separately, we identified 32 numeric data properties corresponding to the city class in DB pedia.",
                    "label": 1
                },
                {
                    "sent": "We extracted the data values and partition them into ten data sources.",
                    "label": 0
                },
                {
                    "sent": "And for the effort to evaluate our overall approach on mixture of both textual and numeric semantic types, we identified an additional 22 textual data attributes from DB pedia.",
                    "label": 0
                },
                {
                    "sent": "Combine that with the one we had chosen for numeric and came up with again a set of data.",
                    "label": 0
                },
                {
                    "sent": "10 data sources to test the same type of approach and we also wanted to validate it on a couple of other domains to just make sure it's not secured in any sense.",
                    "label": 0
                },
                {
                    "sent": "So hence we used datasets from the weather.",
                    "label": 1
                },
                {
                    "sent": "Phone directory and flight domain which is already used in a previous work bandwidth.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And So what are the metrics we use?",
                    "label": 0
                },
                {
                    "sent": "So essentially we are predicting the topcase semantic labels for each attribute, so we needed a measure which captures the rank at which we predict the correct semantic label.",
                    "label": 1
                },
                {
                    "sent": "So hence we use the main reciprocal rank.",
                    "label": 0
                },
                {
                    "sent": "So just in case you're not too familiar, the so if you're predicting the top four semantic types for each attribute, if the correct label is predicted, the first position, you get an MRI score of 1 at the second you get .5, the third you get one by three and.",
                    "label": 0
                },
                {
                    "sent": "At 4th, one by four, and if you don't do it, you get this code of zero and this captures the label prediction accuracy and we also wanted to capture the scalability, so hence we use the average we captured the average training time.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the first.",
                    "label": 0
                },
                {
                    "sent": "This is the evaluation results for the textual data approach.",
                    "label": 1
                },
                {
                    "sent": "So here we show the variation of mean reciprocal rank with the number of labeled data sources in the training data.",
                    "label": 0
                },
                {
                    "sent": "So the approach is we compare here.",
                    "label": 0
                },
                {
                    "sent": "RR is our approach, which is essentially the TF IDF cosine similarity approach against the model based technique, which is CRF and also the Jaccard similarity approach.",
                    "label": 0
                },
                {
                    "sent": "So the Jaccard similarity approach was the was another approach we tried for textual data in which the weights you assign in each vector is going to be now not the TF IDF score, but just.",
                    "label": 0
                },
                {
                    "sent": "A binary score of one or zero depending on whether the term is present in the vector or not.",
                    "label": 0
                },
                {
                    "sent": "So essentially what happens is that a document now breaks down into a set and to compare the similarity of two sets we used the Jaccard similarity.",
                    "label": 0
                },
                {
                    "sent": "So again, you see that the TF IDF approach clearly outperforms all the other approaches and it scales as well as the number of data sources in the in the training data increases.",
                    "label": 0
                },
                {
                    "sent": "So one interesting observation is that for the Jaccard similarity approach you see that as you keep.",
                    "label": 0
                },
                {
                    "sent": "Adding more label data sources, its performance actually decreases, so that is essentially because the binary weights were not informative enough to capture the fact that certain terms are more important than others.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is for the numeric data approach.",
                    "label": 1
                },
                {
                    "sent": "So again here we can see that the statistical hypothesis test, which is the Kolmogorov Smirnov test, clearly outperforms the other approaches.",
                    "label": 0
                },
                {
                    "sent": "We have a step improvement and but again, the input on the interesting observation is that the Welch's T test is clearly the worst among them.",
                    "label": 0
                },
                {
                    "sent": "That is because it's a fun factor that the Welch's T test makes, like underlying assumptions that population is Gaussian and that.",
                    "label": 0
                },
                {
                    "sent": "Two samples have equal number of data values, which obviously is not satisfied in the real world.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, this is the overall approach.",
                    "label": 0
                },
                {
                    "sent": "The awesome typer approach on a collection of both numeric and textual semantic labels.",
                    "label": 0
                },
                {
                    "sent": "So again here you can see that the semantic typer approach as a .1, which is a step improvement in terms of MRR over the CRF.",
                    "label": 0
                },
                {
                    "sent": "An text TF IDF based approach, where in TF IDF approach based approach what we did, we assume that even the numeric data values is a textual document and we try to compute its TF IDF cosine similarity.",
                    "label": 0
                },
                {
                    "sent": "And another major point is that we have not talked about the scalability here.",
                    "label": 0
                },
                {
                    "sent": "So in terms of scalability, we can see that our approach is about 250 times faster than model based techniques such as CRF.",
                    "label": 0
                },
                {
                    "sent": "And also we can see that we don't have the problem of exponential increase in training time as the number of labeled data sources increases as was the case for CRF.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, and this was for the other domains we wanted to validate, which is basically the weather flight status and phone directory domains.",
                    "label": 1
                },
                {
                    "sent": "So the 1st three columns are just basically a description of the data source in terms of number of sources as the fraction of textual and numeric semantic types, so again you can see that for the same type of approach has a marketing significant increase in MRR over the CRF and TF IDF based approaches.",
                    "label": 0
                },
                {
                    "sent": "The thing is that the phone directory domain had mostly textual data and hence you can see that the same type of approach basically breaks down to be the same as the TF IDF based approach.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so OK, so just to show that we've compared against a variety of work which is already been done in this domain.",
                    "label": 0
                },
                {
                    "sent": "So there's a group of work which is basically using model based machine learning techniques like the CRF, which is basically what goal at all had done and what these approaches do is, as I had said, they extract features from individual data values and build a model around it so they don't essentially capture a characteristic property which like which which you would if you had taken a holistic view of the data values.",
                    "label": 1
                },
                {
                    "sent": "And again, these are not scalable in training graphical models.",
                    "label": 0
                },
                {
                    "sent": "And the other set of approaches essentially use external knowledge, so for and they use actually leveraged data which is present on the web to create a database of like saying.",
                    "label": 1
                },
                {
                    "sent": "This value essentially corresponds to this type and hence they assign a type to each data value and then like find the majority semantic type in the data values to assign a type to this amount to the entire column.",
                    "label": 0
                },
                {
                    "sent": "So major flaw with these approaches is that they are restricted to domains where a large amount of web is.",
                    "label": 0
                },
                {
                    "sent": "Data is present on the web and also their ontology specific in that.",
                    "label": 0
                },
                {
                    "sent": "So you're training a model assuming DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So what if the user is giving you a new ontology which he has defined?",
                    "label": 0
                },
                {
                    "sent": "So there's going to be a mismatch between these two.",
                    "label": 1
                },
                {
                    "sent": "And we also like to.",
                    "label": 0
                },
                {
                    "sent": "At time of present the work of Stonebraker who addressed essentially the problem of some schema matching, but we drew inspiration from the work in combining a collection of experts and the and essentially, which was not being done for in this domain earlier.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude, what is our approach at the end, provide in terms of label prediction accuracy.",
                    "label": 1
                },
                {
                    "sent": "We clearly outperform other techniques.",
                    "label": 0
                },
                {
                    "sent": "Competing approaches as shown through MRR an we end as shown.",
                    "label": 0
                },
                {
                    "sent": "We're about 250 times faster than a machine machine learning model based machine learning techniques such as conditional random fields and also we are able to capture the problem of handling noisy datasets through our disambiguation approach and another salient feature is that.",
                    "label": 1
                },
                {
                    "sent": "Our approach is ontology agnostic in that we don't make any restrictions on the user in terms of the ontology from which we predict the labels, and we allow the user to choose the ontology from which the semantic types have to be predicted.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, so thank you in question.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}