{
    "id": "f57iw6r2izncecdt4yy4dcjeg4h273ox",
    "title": "Distribution-Independent Evolvability of Linear Threshold Functions",
    "info": {
        "author": [
            "Vitaly Feldman, IBM Almaden Research Center, IBM Research"
        ],
        "published": "Aug. 2, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Linear Models"
        ]
    },
    "url": "http://videolectures.net/colt2011_feldman_functions/",
    "segmentation": [
        [
            "I'll be talking about availability of linear threshold functions, and I imagine that linear threshold functions need no introduction here, so I'll give a short background on evolvability.",
            "Evil abilities model introduced by Leslie Valiant, which aims to understand how complex organisms and their complex and adaptive behavior can result from evolution.",
            "And despite like 150 years of study, there are still a lot of mysteries in this process.",
            "In fact, it is actually very stunning to me how little we know about the basic algorithms that brought us into existence.",
            "So Valiance model is based on sort of an insight that learning and evolution have a lot in common, and let me highlight these similarities for you."
        ],
        [
            "So in learning we in general are interested in predicting the outcome of some process on a large number of possibly unseen inputs.",
            "And similarly, the subject of evolution are organisms whose goal is to realize a process which can produce good responses in.",
            "And in many different conditions, some of which are unseen.",
            "In learning the reason what the thing which distinguishes learning from other algorithmic approaches that direct programming programming is either invisible or not cost effective, we're not going to program the sort of the entire model of the globe to just predict the weather.",
            "We're going to learn from past experiences and observations.",
            "Similarly, in availability, there is no programmer or one can say you need to 1st realize a programmer to talk about a programmer.",
            "And learning we use instead of directly program.",
            "We use examples of the of the process.",
            "We would like to predict.",
            "And similarly in availability, we do have a feedback from.",
            "From this sort of environment, as it is well known, Darwin's theory says that the basis basic process of adaptation is the following.",
            "You have a current realization.",
            "You try of some process, you try numerous mutations and the one which has performed the best ends up surviving.",
            "So you create mutations to the best one survive, survival of the fittest.",
            "So on the basis of these observations, Valiant has introduced a model which models evolve evolution.",
            "Our availability as a restricted form of learning, where restriction specifically models this restricted type of feedback.",
            "It should also be noted that that there are many different aspects of evolution which are studied by people.",
            "It means different things to different people and the availability does not address most of these aspects.",
            "It addresses one, I think key aspect and omits the others, and in this sense it is similar to sort of the relationship of all bolted to biological evolution is similar to that of computational learning to human brain.",
            "There are many other aspects of the human brain people study, but certainly learning is a key aspect of the process."
        ],
        [
            "One example, which will be very useful to keep in mind is that gene expression we can think of.",
            "Well noted biologist.",
            "The expression of each gene in the DNA is regulated by multiple proteins which are called transcription factors.",
            "And those are proteins.",
            "Basically detect various conditions of the environment, such as presence of absence of some other proteins present, absence of some chemical elements, temperature, light and other things, and they jointly determine how much of a certain protein will be produced from from the gene.",
            "And there are in the human genome.",
            "There are more than 2000 of them known, so the question is how do these regulation mechanisms with functions which determine how much protein to produce?",
            "How do they?",
            "Evolve.",
            "And for example, one can situation could be that.",
            "Optimally, some jeans should be expressed when several fixed but not known in advance.",
            "Transcription factors are jointly present and the question is whether this optimal combination can evolve efficiently.",
            "That is, without sort of trying all the possible combinations of the same segments or something like this.",
            "And this is the type of question the model tries to address."
        ],
        [
            "Let me now formally go to models more formally is based on the PAC learning model by also by less Valiant.",
            "Quick reminder, we have random examples which are pairs in pack model.",
            "We have random so which is just a point and value of some function F which comes from a set of from the concept class which is a set of some fixed set of functions and the point is randomly chosen from some distribution D over the domain.",
            "Also usually unknown and given access to these random algorithm.",
            "The goal of a linear learning algorithm is too.",
            "For every function F from the concept Class C, every distribution D and every positive accuracy parameter epsilon hypothesis, which is epsilon close to the unknown target function efficiently, which is here means sort of inverse polynomial in time polynomial in the inverse of the accuracy and some sort of complexity measures of the dimension of our.",
            "Of our domain and the target function.",
            "Similarly, the model availability is based on this model of feedback, which will is referred to as selection model and the mutation algorithms whose goal sort of given this selection model too.",
            "For every again, for every function distribution and epsilon accuracy parameter reach some hypothesis H. Which has the same guarantees epsilon close to the optimal function, and I'll describe those two in more details and both of these parts have to work sort of efficiently.",
            "They have to be biologically plausible, they work in time in polynomial time."
        ],
        [
            "So let me first describe the mutation algorithm, attention, or basically just a pair which is the R&M where R is just is the representation class of functions on which the mutations Act.",
            "For example, it could be just all representations of all linear threshold functions over there.",
            "Hypercube real value hypercube.",
            "And M. Is there some randomized algorithm which, given some current representation of a function in R, produces its random mutation and the only restriction is that it has to be polynomial in one over epsilon then?",
            "And here is a simple example for the for this representation class One could choose a random.",
            "They mention I and try to adjust the weight by minus 101 in that dimension for the linear threshold function and mutate the linear circle function.",
            "In this way."
        ],
        [
            "So for the model of selection.",
            "Is first of all one has to define what is what determines the fitness of the Organism.",
            "An Organism and or whatever over certain function of a certain representation and it will be some function between minus one and one and one in which the values model is based is the correlation which is effectively for Boolean function equivalent to looking at the just agreement between two functions?",
            "It's just up to some small linear transformation.",
            "And selection.",
            "Of mechanism that was defined in the Valiant model.",
            "Basically forgiven representation current representation R it's samples.",
            "This mutation algorithm sometimes and obtain this P mutations of the of that.",
            "Station and then for for for our itself, and for each of the mutation it estimates the empirical performance.",
            "Basically estimates this function on some samples and obtains this P~ of F and representation I.",
            "Then let's let's map them.",
            "For example, the.",
            "The empirical performance of all the mutations, and this is the empirical performance of the.",
            "Current state.",
            "Then the mechanism, if there are any, if there are any mutations whose performances is more than T above the current representation, then one of those is chosen randomly and output by the selection mechanism.",
            "If there are no mutations which are sort of beneficial, it looks at all those which are within T for some fixed T of the current one which are considered neutral and one of those is output randomly and there if there are none of those, one can basically out can stop the process of.",
            "Evolution and these parameter P as in 1 / T are sort of chosen to be visible or again polynomial in an one over epsilon.",
            "It will be our general we will use it as a measure of complexity of the model."
        ],
        [
            "So given this definition of a mutation and selection, we can define what does it mean to be valuable is basically we say that a class of function sees available over distribution D. If there is this a mutation algorithm, which is a pair on them and some polynomial number of generations L such that if for every function and starting representation are in the model in any accuracy parameter, if one starts a sequence of mutations and select select selections according.",
            "As described above, basically the next state is just chosen randomly by through this process of selection, using the current state and this mutation algorithm.",
            "Then after at most this polynomial number of steps will achieve performance which is close to the optimum app is not close to the optimum.",
            "And here we can also say, as in learning that something is available, distribution independently if it's available by for all distributions by the same mutation algorithm.",
            "And we can also use notation available weekly.",
            "If it achieves some sort of non trivial better than 0 performance."
        ],
        [
            "So let me briefly overview some of the relevant previous previous work.",
            "So it's easy to see that one can model or this evolution availability, impact model so so.",
            "Therefore everything which is available is also pack learnable.",
            "Valiant has observed that it actually SQL thing available is Eskew learnable.",
            "Where SQ is a statistical query learning model of currents which allows the learner to get doesn't show him example but allow him to estimate functions of examples efficiently.",
            "Computable functions of examples on the target distribution within some inverse.",
            "Accuracy and it's known that this Q is not as strongest back the first positive result was the talent show was that monotone conjunctions are available over the uniform distribution and it was later improved to general conjunctions by Jacobson and kind of Von and Valiant.",
            "It was I then showed that vulnerability is actually equivalent to learning but correlational statistical queries, which is are just the restriction of statistical queries to correlations of the target function with some other function.",
            "Ann, this implies that for fixed distribution we know that that it's the same.",
            "That durability is the same as learning by statistical queries, survey result of sodium myself.",
            "And finally, we also know that.",
            "Correlation statistically are over.",
            "If you look at the distribution dependent learning correction.",
            "Statistical queries are not as strong as it is.",
            "So queries, for example, general linear thresholds are not available even weakly.",
            "And the only class which is known to be bluestone independent was not to be evolvable.",
            "Decision independently is singletons with their functions, which are one at only a single point of."
        ],
        [
            "I mean.",
            "So in this work we ask the questions are the conjunctions available distribution independently it was asking listing several works including cultivate open problem and then one hand the evidence is there available weekly and single tools that are available which are also conjunctions of all the variables.",
            "On the other hand, we know the general rules are not available, so it's the answer was not.",
            "This question was not clear.",
            "And here we answer that.",
            "It's there not available.",
            "We show that they are not.",
            "By explaining this equivalence to correlation statistical queries, they're not.",
            "Learnable from correlation statistical queries.",
            "Basically, we show that monotone conjunctions of a super constant number of variables are not learnable from correlation.",
            "Statistical queries to any sub constant accuracy.",
            "And this in particular implies that we cannot use boosting because because they are available weekly, but they are not available strongly."
        ],
        [
            "Let me overview the technique is based on information information theoretic lower bound on on this SSQ learnability info sort of relatively long tradition of such lower bounds for statistical query learning which start was started by Blum and others.",
            "It was then extended by myself to week collection statistical query Learning which I already mentioned an in several recent work.",
            "It was similar techniques were used for.",
            "Statistical query learning over strong statistical query learning over fixed distribution D. And here we basically extended most both to distribution independent learning and strong, but only for correlation statistical queries and only the lower bound.",
            "All those were actually characterizations here will only give a lower bound.",
            "Lower bound is based on the following information theoretic bound is.",
            "We say that basically if a class is learnable from correlational statistical queries, distribution independently then for every function five with a range of minus one one.",
            "In any distribution D, there exists a smaller policies set of function G that can distinguish the function.",
            "Any target function F and any distribution D prime from 5 / D. And distinguishing here means that if we ask a correlational statistical query using a function, one of the function in G. For the target function F and distribution D prime, and also for the FI and distribution D, the outcomes will be different by at least some Tau which is inverse polynomial.",
            "Basically, the additional condition.",
            "We need that unless F happens to be epsilon close over the distribution D to some fixed hypothesis H, and this is because it's a strong learning and epsilon has to come in somehow into the picture.",
            "So this is the and it is actually not very hard to see that that learning implies implies this kind of distinguish distinguishing property.",
            "And let me show how this distinction property can be used to prove the result.",
            "Yes, classy yes."
        ],
        [
            "So our goal would be to build hard to distinguish distinguish function distribution pairs, where the function which we can functions which can use our conjunctions.",
            "So let's denote the conjunction of the variables in set 8 by TA and our methods will basically build some distribution.",
            "Define some distribution D of A and theater of a, which is just a function with range of minus one one size at first.",
            "Firstly, this this conjunction over this distribution DNA is indistinguishable from.",
            "Basically this function Theta a over the uniform distribution.",
            "Where also Theta A plus some fixed constant in minus one one.",
            "And on the other hand, we also know that if you look at 2 size K sets A&B, which share less than K / 3 variables.",
            "Then the correlations of these parts Theta a dysfunctional parts will be 0, so there will be mutually uncorrelated.",
            "When the sets are disjoint and we know that if you take super constant K, then there are super super polynomial number or this is proportional number of sets of size K which share less than K / 3 variables and basically this gives us.",
            "That gives us a super polynomial number of functions where who's up to this constant CR.",
            "Sort of uncorrelated relative to the uniform distribution, and therefore they cannot be distinguished using the distinguishing which we defined before from this constant.",
            "Just constant C over the uniform distribution.",
            "And this is also follow some models standard techniques for statistical for characterization of statistical query learning.",
            "So the only question is then how to basically achieve this?",
            "How to build this distribution D and Theta A with such properties and the main idea is to use.",
            "To observe that relative to the uniform distribution, the correlation is determined by Fourier coefficients, and if you look at the correlation of two conjunctions, the correlation will be determined by the coefficients for the sets which are in the intersection of the sets of the variables for two conjunctions, and therefore we build DNA which will erase all the order coefficients or up to the K / 3.",
            "Allowing us making sure that two conjunctions which share less than K / 3 variables will be unrelated.",
            "Giving us this result.",
            "Anyway, this finishes this negative result.",
            "Ann is the number of total number of variables to long referrals over which we have connections."
        ],
        [
            "So, so there are, in addition to the strong negatives, also some strong positive results, and but those are not for their.",
            "Let's not for the fitness, which is not the correlation but for the fitness which is determined which is defined to be which is based on the quadratic loss which is basically just the one to scale it into.",
            "This strange one has to make it 1 minus the quadratic loss of F relative to the function R and everything else works the same.",
            "But we also look at the.",
            "Algorithm which have additional property.",
            "And so correlation.",
            "We're no longer dealing with their so called strictly monotone.",
            "They always have some.",
            "They're guaranteed to have some.",
            "Mutation, which is, which improves the performance unless the performance is already very high and the reason why those are very interesting is.",
            "Is is that evolution with mutation algorithm which which is guaranteed to have strictly improving mutation basically does not depend on the details of how exactly do you select has some sort of robustness to the choice of selection mechanism which is important means that you don't need to care too much about how exactly the process goes is also robust to drift or change in the target function."
        ],
        [
            "So let me briefly review some related work.",
            "This this was first this quadratic loss evolution with quadratic loss and monotone evolution was first.",
            "Define and used by Michael to Evolve Decision list over the uniform distribution for if one doesn't require the monotonicity.",
            "I showed earlier that any statistical query learnable Class C is available.",
            "This result for single singletons also applies in this setting, so they are available monotonically over the distribution independently.",
            "For fixed distribution, again there is.",
            "One can learn any any statistical.",
            "Query learnable Class C. In more recent work, I show that conjunctions are actually learnable, monotonically distribution independently.",
            "Again, with this quadratic loss.",
            "And then I sort of our independent work.",
            "Well, Valiant showed that the linear functions are available also in with this quadratic loss, again monotonically."
        ],
        [
            "So this work will show that we strengthened this.",
            "These previous results by showing that it will have linear threshold functions where the result is.",
            "Again with quadratic loss it is polynomial in the inverse of the margin, so it basically allows only large margin linear threshold functions, and in particular implies conjunctions and any linear threshold functions with polynomial integer weights over the Boolean hypercube.",
            "And of course, everything which can efficiently efficiently embedded into linear threshold functions with margin is also would also be available.",
            "And the other advantage of the algorithm which we're going to show is has a simple mutation algorithm which the only thing it does it chooses some random variable, some random coordinate.",
            "Or constant adds or subtracts some this coordinates multiplied by the by the current by by the by some constant from the current hypothesis and also clips of the values to be in sort of everything which is outside of minus one one is clipped off to come back to minus one one.",
            "And we denote this by P of X.",
            "This clip of operation this mutation step by PRX an Alpha of XI.",
            "And can also be extended to several other loss functions.",
            "Has some other additional robustness proper."
        ],
        [
            "Let me very quickly overview how one can prove this.",
            "Basically what one proves that is that.",
            "Whenever a current representation is at least epsilon away in quadratic loss from the current function, then there is some coordinate in which if you make this mutation.",
            "With some appropriately chosen Alpha, you will decrease the loss by at least Alpha Square, and this is so called basically the stricted beneficial neighborhood properties, and it's easy to see that it will imply availability.",
            "Can all this decrease the loss?",
            "So the proof is also very simple.",
            "Basically one can observe that the gradient of this quadratic loss is at this point the current function is just minus two F of X minus error of X in function space.",
            "Then you can use a margin condition to show that the weight vector of the of the current of the linear stretch of the target linear threshold is correlated with this gradient with some some negligible amount.",
            "This we have some coffee Schwarz inequality implies that at least one of the coordinates is correlated with the gradient and this implies if you have a coordinate which is correlated with the gradient, if you make a step in that direction, you will decrease the loss.",
            "And then if you apply this projection, you will only reduce the loss.",
            "So basically giving the proof of this."
        ],
        [
            "Salt.",
            "And let me quickly conclude we showed that we cannot learn some strong concept classes by looking only a disagreement and correlation, but the same time, if one looks at quadratic loss or some other loss functions, one can robustly learn most of what's back learnable.",
            "There are a number of.",
            "Open questions which I think are interesting first, so we still don't understand the strong correlation statistical queries completely.",
            "The current methods don't allow me to sort of achieve any lower bound with constant accuracy.",
            "Other open problems are sort of monotone availability of decision lists of general thresh, linear threshold functions, functions which are not large margin, linear threshold functions.",
            "And also it would be interesting whether one can evolve with linear thresholds functions properly without using other representations.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll be talking about availability of linear threshold functions, and I imagine that linear threshold functions need no introduction here, so I'll give a short background on evolvability.",
                    "label": 1
                },
                {
                    "sent": "Evil abilities model introduced by Leslie Valiant, which aims to understand how complex organisms and their complex and adaptive behavior can result from evolution.",
                    "label": 0
                },
                {
                    "sent": "And despite like 150 years of study, there are still a lot of mysteries in this process.",
                    "label": 0
                },
                {
                    "sent": "In fact, it is actually very stunning to me how little we know about the basic algorithms that brought us into existence.",
                    "label": 0
                },
                {
                    "sent": "So Valiance model is based on sort of an insight that learning and evolution have a lot in common, and let me highlight these similarities for you.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in learning we in general are interested in predicting the outcome of some process on a large number of possibly unseen inputs.",
                    "label": 0
                },
                {
                    "sent": "And similarly, the subject of evolution are organisms whose goal is to realize a process which can produce good responses in.",
                    "label": 0
                },
                {
                    "sent": "And in many different conditions, some of which are unseen.",
                    "label": 0
                },
                {
                    "sent": "In learning the reason what the thing which distinguishes learning from other algorithmic approaches that direct programming programming is either invisible or not cost effective, we're not going to program the sort of the entire model of the globe to just predict the weather.",
                    "label": 1
                },
                {
                    "sent": "We're going to learn from past experiences and observations.",
                    "label": 1
                },
                {
                    "sent": "Similarly, in availability, there is no programmer or one can say you need to 1st realize a programmer to talk about a programmer.",
                    "label": 0
                },
                {
                    "sent": "And learning we use instead of directly program.",
                    "label": 0
                },
                {
                    "sent": "We use examples of the of the process.",
                    "label": 0
                },
                {
                    "sent": "We would like to predict.",
                    "label": 0
                },
                {
                    "sent": "And similarly in availability, we do have a feedback from.",
                    "label": 0
                },
                {
                    "sent": "From this sort of environment, as it is well known, Darwin's theory says that the basis basic process of adaptation is the following.",
                    "label": 0
                },
                {
                    "sent": "You have a current realization.",
                    "label": 0
                },
                {
                    "sent": "You try of some process, you try numerous mutations and the one which has performed the best ends up surviving.",
                    "label": 0
                },
                {
                    "sent": "So you create mutations to the best one survive, survival of the fittest.",
                    "label": 0
                },
                {
                    "sent": "So on the basis of these observations, Valiant has introduced a model which models evolve evolution.",
                    "label": 0
                },
                {
                    "sent": "Our availability as a restricted form of learning, where restriction specifically models this restricted type of feedback.",
                    "label": 0
                },
                {
                    "sent": "It should also be noted that that there are many different aspects of evolution which are studied by people.",
                    "label": 0
                },
                {
                    "sent": "It means different things to different people and the availability does not address most of these aspects.",
                    "label": 0
                },
                {
                    "sent": "It addresses one, I think key aspect and omits the others, and in this sense it is similar to sort of the relationship of all bolted to biological evolution is similar to that of computational learning to human brain.",
                    "label": 1
                },
                {
                    "sent": "There are many other aspects of the human brain people study, but certainly learning is a key aspect of the process.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One example, which will be very useful to keep in mind is that gene expression we can think of.",
                    "label": 0
                },
                {
                    "sent": "Well noted biologist.",
                    "label": 0
                },
                {
                    "sent": "The expression of each gene in the DNA is regulated by multiple proteins which are called transcription factors.",
                    "label": 1
                },
                {
                    "sent": "And those are proteins.",
                    "label": 0
                },
                {
                    "sent": "Basically detect various conditions of the environment, such as presence of absence of some other proteins present, absence of some chemical elements, temperature, light and other things, and they jointly determine how much of a certain protein will be produced from from the gene.",
                    "label": 0
                },
                {
                    "sent": "And there are in the human genome.",
                    "label": 0
                },
                {
                    "sent": "There are more than 2000 of them known, so the question is how do these regulation mechanisms with functions which determine how much protein to produce?",
                    "label": 0
                },
                {
                    "sent": "How do they?",
                    "label": 0
                },
                {
                    "sent": "Evolve.",
                    "label": 0
                },
                {
                    "sent": "And for example, one can situation could be that.",
                    "label": 0
                },
                {
                    "sent": "Optimally, some jeans should be expressed when several fixed but not known in advance.",
                    "label": 0
                },
                {
                    "sent": "Transcription factors are jointly present and the question is whether this optimal combination can evolve efficiently.",
                    "label": 0
                },
                {
                    "sent": "That is, without sort of trying all the possible combinations of the same segments or something like this.",
                    "label": 0
                },
                {
                    "sent": "And this is the type of question the model tries to address.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me now formally go to models more formally is based on the PAC learning model by also by less Valiant.",
                    "label": 1
                },
                {
                    "sent": "Quick reminder, we have random examples which are pairs in pack model.",
                    "label": 0
                },
                {
                    "sent": "We have random so which is just a point and value of some function F which comes from a set of from the concept class which is a set of some fixed set of functions and the point is randomly chosen from some distribution D over the domain.",
                    "label": 0
                },
                {
                    "sent": "Also usually unknown and given access to these random algorithm.",
                    "label": 0
                },
                {
                    "sent": "The goal of a linear learning algorithm is too.",
                    "label": 0
                },
                {
                    "sent": "For every function F from the concept Class C, every distribution D and every positive accuracy parameter epsilon hypothesis, which is epsilon close to the unknown target function efficiently, which is here means sort of inverse polynomial in time polynomial in the inverse of the accuracy and some sort of complexity measures of the dimension of our.",
                    "label": 0
                },
                {
                    "sent": "Of our domain and the target function.",
                    "label": 0
                },
                {
                    "sent": "Similarly, the model availability is based on this model of feedback, which will is referred to as selection model and the mutation algorithms whose goal sort of given this selection model too.",
                    "label": 0
                },
                {
                    "sent": "For every again, for every function distribution and epsilon accuracy parameter reach some hypothesis H. Which has the same guarantees epsilon close to the optimal function, and I'll describe those two in more details and both of these parts have to work sort of efficiently.",
                    "label": 0
                },
                {
                    "sent": "They have to be biologically plausible, they work in time in polynomial time.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me first describe the mutation algorithm, attention, or basically just a pair which is the R&M where R is just is the representation class of functions on which the mutations Act.",
                    "label": 0
                },
                {
                    "sent": "For example, it could be just all representations of all linear threshold functions over there.",
                    "label": 0
                },
                {
                    "sent": "Hypercube real value hypercube.",
                    "label": 0
                },
                {
                    "sent": "And M. Is there some randomized algorithm which, given some current representation of a function in R, produces its random mutation and the only restriction is that it has to be polynomial in one over epsilon then?",
                    "label": 0
                },
                {
                    "sent": "And here is a simple example for the for this representation class One could choose a random.",
                    "label": 0
                },
                {
                    "sent": "They mention I and try to adjust the weight by minus 101 in that dimension for the linear threshold function and mutate the linear circle function.",
                    "label": 0
                },
                {
                    "sent": "In this way.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the model of selection.",
                    "label": 0
                },
                {
                    "sent": "Is first of all one has to define what is what determines the fitness of the Organism.",
                    "label": 0
                },
                {
                    "sent": "An Organism and or whatever over certain function of a certain representation and it will be some function between minus one and one and one in which the values model is based is the correlation which is effectively for Boolean function equivalent to looking at the just agreement between two functions?",
                    "label": 0
                },
                {
                    "sent": "It's just up to some small linear transformation.",
                    "label": 0
                },
                {
                    "sent": "And selection.",
                    "label": 0
                },
                {
                    "sent": "Of mechanism that was defined in the Valiant model.",
                    "label": 0
                },
                {
                    "sent": "Basically forgiven representation current representation R it's samples.",
                    "label": 0
                },
                {
                    "sent": "This mutation algorithm sometimes and obtain this P mutations of the of that.",
                    "label": 0
                },
                {
                    "sent": "Station and then for for for our itself, and for each of the mutation it estimates the empirical performance.",
                    "label": 0
                },
                {
                    "sent": "Basically estimates this function on some samples and obtains this P~ of F and representation I.",
                    "label": 0
                },
                {
                    "sent": "Then let's let's map them.",
                    "label": 0
                },
                {
                    "sent": "For example, the.",
                    "label": 0
                },
                {
                    "sent": "The empirical performance of all the mutations, and this is the empirical performance of the.",
                    "label": 1
                },
                {
                    "sent": "Current state.",
                    "label": 0
                },
                {
                    "sent": "Then the mechanism, if there are any, if there are any mutations whose performances is more than T above the current representation, then one of those is chosen randomly and output by the selection mechanism.",
                    "label": 0
                },
                {
                    "sent": "If there are no mutations which are sort of beneficial, it looks at all those which are within T for some fixed T of the current one which are considered neutral and one of those is output randomly and there if there are none of those, one can basically out can stop the process of.",
                    "label": 0
                },
                {
                    "sent": "Evolution and these parameter P as in 1 / T are sort of chosen to be visible or again polynomial in an one over epsilon.",
                    "label": 0
                },
                {
                    "sent": "It will be our general we will use it as a measure of complexity of the model.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So given this definition of a mutation and selection, we can define what does it mean to be valuable is basically we say that a class of function sees available over distribution D. If there is this a mutation algorithm, which is a pair on them and some polynomial number of generations L such that if for every function and starting representation are in the model in any accuracy parameter, if one starts a sequence of mutations and select select selections according.",
                    "label": 0
                },
                {
                    "sent": "As described above, basically the next state is just chosen randomly by through this process of selection, using the current state and this mutation algorithm.",
                    "label": 0
                },
                {
                    "sent": "Then after at most this polynomial number of steps will achieve performance which is close to the optimum app is not close to the optimum.",
                    "label": 0
                },
                {
                    "sent": "And here we can also say, as in learning that something is available, distribution independently if it's available by for all distributions by the same mutation algorithm.",
                    "label": 0
                },
                {
                    "sent": "And we can also use notation available weekly.",
                    "label": 0
                },
                {
                    "sent": "If it achieves some sort of non trivial better than 0 performance.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me briefly overview some of the relevant previous previous work.",
                    "label": 0
                },
                {
                    "sent": "So it's easy to see that one can model or this evolution availability, impact model so so.",
                    "label": 0
                },
                {
                    "sent": "Therefore everything which is available is also pack learnable.",
                    "label": 0
                },
                {
                    "sent": "Valiant has observed that it actually SQL thing available is Eskew learnable.",
                    "label": 0
                },
                {
                    "sent": "Where SQ is a statistical query learning model of currents which allows the learner to get doesn't show him example but allow him to estimate functions of examples efficiently.",
                    "label": 0
                },
                {
                    "sent": "Computable functions of examples on the target distribution within some inverse.",
                    "label": 0
                },
                {
                    "sent": "Accuracy and it's known that this Q is not as strongest back the first positive result was the talent show was that monotone conjunctions are available over the uniform distribution and it was later improved to general conjunctions by Jacobson and kind of Von and Valiant.",
                    "label": 0
                },
                {
                    "sent": "It was I then showed that vulnerability is actually equivalent to learning but correlational statistical queries, which is are just the restriction of statistical queries to correlations of the target function with some other function.",
                    "label": 0
                },
                {
                    "sent": "Ann, this implies that for fixed distribution we know that that it's the same.",
                    "label": 0
                },
                {
                    "sent": "That durability is the same as learning by statistical queries, survey result of sodium myself.",
                    "label": 0
                },
                {
                    "sent": "And finally, we also know that.",
                    "label": 0
                },
                {
                    "sent": "Correlation statistically are over.",
                    "label": 0
                },
                {
                    "sent": "If you look at the distribution dependent learning correction.",
                    "label": 0
                },
                {
                    "sent": "Statistical queries are not as strong as it is.",
                    "label": 0
                },
                {
                    "sent": "So queries, for example, general linear thresholds are not available even weakly.",
                    "label": 0
                },
                {
                    "sent": "And the only class which is known to be bluestone independent was not to be evolvable.",
                    "label": 0
                },
                {
                    "sent": "Decision independently is singletons with their functions, which are one at only a single point of.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean.",
                    "label": 0
                },
                {
                    "sent": "So in this work we ask the questions are the conjunctions available distribution independently it was asking listing several works including cultivate open problem and then one hand the evidence is there available weekly and single tools that are available which are also conjunctions of all the variables.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we know the general rules are not available, so it's the answer was not.",
                    "label": 0
                },
                {
                    "sent": "This question was not clear.",
                    "label": 0
                },
                {
                    "sent": "And here we answer that.",
                    "label": 0
                },
                {
                    "sent": "It's there not available.",
                    "label": 0
                },
                {
                    "sent": "We show that they are not.",
                    "label": 0
                },
                {
                    "sent": "By explaining this equivalence to correlation statistical queries, they're not.",
                    "label": 0
                },
                {
                    "sent": "Learnable from correlation statistical queries.",
                    "label": 0
                },
                {
                    "sent": "Basically, we show that monotone conjunctions of a super constant number of variables are not learnable from correlation.",
                    "label": 0
                },
                {
                    "sent": "Statistical queries to any sub constant accuracy.",
                    "label": 0
                },
                {
                    "sent": "And this in particular implies that we cannot use boosting because because they are available weekly, but they are not available strongly.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me overview the technique is based on information information theoretic lower bound on on this SSQ learnability info sort of relatively long tradition of such lower bounds for statistical query learning which start was started by Blum and others.",
                    "label": 0
                },
                {
                    "sent": "It was then extended by myself to week collection statistical query Learning which I already mentioned an in several recent work.",
                    "label": 0
                },
                {
                    "sent": "It was similar techniques were used for.",
                    "label": 0
                },
                {
                    "sent": "Statistical query learning over strong statistical query learning over fixed distribution D. And here we basically extended most both to distribution independent learning and strong, but only for correlation statistical queries and only the lower bound.",
                    "label": 0
                },
                {
                    "sent": "All those were actually characterizations here will only give a lower bound.",
                    "label": 0
                },
                {
                    "sent": "Lower bound is based on the following information theoretic bound is.",
                    "label": 0
                },
                {
                    "sent": "We say that basically if a class is learnable from correlational statistical queries, distribution independently then for every function five with a range of minus one one.",
                    "label": 0
                },
                {
                    "sent": "In any distribution D, there exists a smaller policies set of function G that can distinguish the function.",
                    "label": 0
                },
                {
                    "sent": "Any target function F and any distribution D prime from 5 / D. And distinguishing here means that if we ask a correlational statistical query using a function, one of the function in G. For the target function F and distribution D prime, and also for the FI and distribution D, the outcomes will be different by at least some Tau which is inverse polynomial.",
                    "label": 0
                },
                {
                    "sent": "Basically, the additional condition.",
                    "label": 0
                },
                {
                    "sent": "We need that unless F happens to be epsilon close over the distribution D to some fixed hypothesis H, and this is because it's a strong learning and epsilon has to come in somehow into the picture.",
                    "label": 0
                },
                {
                    "sent": "So this is the and it is actually not very hard to see that that learning implies implies this kind of distinguish distinguishing property.",
                    "label": 0
                },
                {
                    "sent": "And let me show how this distinction property can be used to prove the result.",
                    "label": 0
                },
                {
                    "sent": "Yes, classy yes.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our goal would be to build hard to distinguish distinguish function distribution pairs, where the function which we can functions which can use our conjunctions.",
                    "label": 1
                },
                {
                    "sent": "So let's denote the conjunction of the variables in set 8 by TA and our methods will basically build some distribution.",
                    "label": 0
                },
                {
                    "sent": "Define some distribution D of A and theater of a, which is just a function with range of minus one one size at first.",
                    "label": 0
                },
                {
                    "sent": "Firstly, this this conjunction over this distribution DNA is indistinguishable from.",
                    "label": 0
                },
                {
                    "sent": "Basically this function Theta a over the uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "Where also Theta A plus some fixed constant in minus one one.",
                    "label": 0
                },
                {
                    "sent": "And on the other hand, we also know that if you look at 2 size K sets A&B, which share less than K / 3 variables.",
                    "label": 0
                },
                {
                    "sent": "Then the correlations of these parts Theta a dysfunctional parts will be 0, so there will be mutually uncorrelated.",
                    "label": 0
                },
                {
                    "sent": "When the sets are disjoint and we know that if you take super constant K, then there are super super polynomial number or this is proportional number of sets of size K which share less than K / 3 variables and basically this gives us.",
                    "label": 0
                },
                {
                    "sent": "That gives us a super polynomial number of functions where who's up to this constant CR.",
                    "label": 0
                },
                {
                    "sent": "Sort of uncorrelated relative to the uniform distribution, and therefore they cannot be distinguished using the distinguishing which we defined before from this constant.",
                    "label": 0
                },
                {
                    "sent": "Just constant C over the uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "And this is also follow some models standard techniques for statistical for characterization of statistical query learning.",
                    "label": 0
                },
                {
                    "sent": "So the only question is then how to basically achieve this?",
                    "label": 0
                },
                {
                    "sent": "How to build this distribution D and Theta A with such properties and the main idea is to use.",
                    "label": 0
                },
                {
                    "sent": "To observe that relative to the uniform distribution, the correlation is determined by Fourier coefficients, and if you look at the correlation of two conjunctions, the correlation will be determined by the coefficients for the sets which are in the intersection of the sets of the variables for two conjunctions, and therefore we build DNA which will erase all the order coefficients or up to the K / 3.",
                    "label": 0
                },
                {
                    "sent": "Allowing us making sure that two conjunctions which share less than K / 3 variables will be unrelated.",
                    "label": 0
                },
                {
                    "sent": "Giving us this result.",
                    "label": 0
                },
                {
                    "sent": "Anyway, this finishes this negative result.",
                    "label": 0
                },
                {
                    "sent": "Ann is the number of total number of variables to long referrals over which we have connections.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so there are, in addition to the strong negatives, also some strong positive results, and but those are not for their.",
                    "label": 0
                },
                {
                    "sent": "Let's not for the fitness, which is not the correlation but for the fitness which is determined which is defined to be which is based on the quadratic loss which is basically just the one to scale it into.",
                    "label": 0
                },
                {
                    "sent": "This strange one has to make it 1 minus the quadratic loss of F relative to the function R and everything else works the same.",
                    "label": 0
                },
                {
                    "sent": "But we also look at the.",
                    "label": 0
                },
                {
                    "sent": "Algorithm which have additional property.",
                    "label": 0
                },
                {
                    "sent": "And so correlation.",
                    "label": 0
                },
                {
                    "sent": "We're no longer dealing with their so called strictly monotone.",
                    "label": 1
                },
                {
                    "sent": "They always have some.",
                    "label": 0
                },
                {
                    "sent": "They're guaranteed to have some.",
                    "label": 0
                },
                {
                    "sent": "Mutation, which is, which improves the performance unless the performance is already very high and the reason why those are very interesting is.",
                    "label": 1
                },
                {
                    "sent": "Is is that evolution with mutation algorithm which which is guaranteed to have strictly improving mutation basically does not depend on the details of how exactly do you select has some sort of robustness to the choice of selection mechanism which is important means that you don't need to care too much about how exactly the process goes is also robust to drift or change in the target function.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me briefly review some related work.",
                    "label": 0
                },
                {
                    "sent": "This this was first this quadratic loss evolution with quadratic loss and monotone evolution was first.",
                    "label": 0
                },
                {
                    "sent": "Define and used by Michael to Evolve Decision list over the uniform distribution for if one doesn't require the monotonicity.",
                    "label": 0
                },
                {
                    "sent": "I showed earlier that any statistical query learnable Class C is available.",
                    "label": 0
                },
                {
                    "sent": "This result for single singletons also applies in this setting, so they are available monotonically over the distribution independently.",
                    "label": 0
                },
                {
                    "sent": "For fixed distribution, again there is.",
                    "label": 0
                },
                {
                    "sent": "One can learn any any statistical.",
                    "label": 0
                },
                {
                    "sent": "Query learnable Class C. In more recent work, I show that conjunctions are actually learnable, monotonically distribution independently.",
                    "label": 0
                },
                {
                    "sent": "Again, with this quadratic loss.",
                    "label": 0
                },
                {
                    "sent": "And then I sort of our independent work.",
                    "label": 0
                },
                {
                    "sent": "Well, Valiant showed that the linear functions are available also in with this quadratic loss, again monotonically.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this work will show that we strengthened this.",
                    "label": 1
                },
                {
                    "sent": "These previous results by showing that it will have linear threshold functions where the result is.",
                    "label": 0
                },
                {
                    "sent": "Again with quadratic loss it is polynomial in the inverse of the margin, so it basically allows only large margin linear threshold functions, and in particular implies conjunctions and any linear threshold functions with polynomial integer weights over the Boolean hypercube.",
                    "label": 0
                },
                {
                    "sent": "And of course, everything which can efficiently efficiently embedded into linear threshold functions with margin is also would also be available.",
                    "label": 0
                },
                {
                    "sent": "And the other advantage of the algorithm which we're going to show is has a simple mutation algorithm which the only thing it does it chooses some random variable, some random coordinate.",
                    "label": 0
                },
                {
                    "sent": "Or constant adds or subtracts some this coordinates multiplied by the by the current by by the by some constant from the current hypothesis and also clips of the values to be in sort of everything which is outside of minus one one is clipped off to come back to minus one one.",
                    "label": 0
                },
                {
                    "sent": "And we denote this by P of X.",
                    "label": 0
                },
                {
                    "sent": "This clip of operation this mutation step by PRX an Alpha of XI.",
                    "label": 0
                },
                {
                    "sent": "And can also be extended to several other loss functions.",
                    "label": 0
                },
                {
                    "sent": "Has some other additional robustness proper.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me very quickly overview how one can prove this.",
                    "label": 0
                },
                {
                    "sent": "Basically what one proves that is that.",
                    "label": 0
                },
                {
                    "sent": "Whenever a current representation is at least epsilon away in quadratic loss from the current function, then there is some coordinate in which if you make this mutation.",
                    "label": 0
                },
                {
                    "sent": "With some appropriately chosen Alpha, you will decrease the loss by at least Alpha Square, and this is so called basically the stricted beneficial neighborhood properties, and it's easy to see that it will imply availability.",
                    "label": 0
                },
                {
                    "sent": "Can all this decrease the loss?",
                    "label": 0
                },
                {
                    "sent": "So the proof is also very simple.",
                    "label": 0
                },
                {
                    "sent": "Basically one can observe that the gradient of this quadratic loss is at this point the current function is just minus two F of X minus error of X in function space.",
                    "label": 0
                },
                {
                    "sent": "Then you can use a margin condition to show that the weight vector of the of the current of the linear stretch of the target linear threshold is correlated with this gradient with some some negligible amount.",
                    "label": 0
                },
                {
                    "sent": "This we have some coffee Schwarz inequality implies that at least one of the coordinates is correlated with the gradient and this implies if you have a coordinate which is correlated with the gradient, if you make a step in that direction, you will decrease the loss.",
                    "label": 0
                },
                {
                    "sent": "And then if you apply this projection, you will only reduce the loss.",
                    "label": 0
                },
                {
                    "sent": "So basically giving the proof of this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Salt.",
                    "label": 0
                },
                {
                    "sent": "And let me quickly conclude we showed that we cannot learn some strong concept classes by looking only a disagreement and correlation, but the same time, if one looks at quadratic loss or some other loss functions, one can robustly learn most of what's back learnable.",
                    "label": 1
                },
                {
                    "sent": "There are a number of.",
                    "label": 0
                },
                {
                    "sent": "Open questions which I think are interesting first, so we still don't understand the strong correlation statistical queries completely.",
                    "label": 1
                },
                {
                    "sent": "The current methods don't allow me to sort of achieve any lower bound with constant accuracy.",
                    "label": 0
                },
                {
                    "sent": "Other open problems are sort of monotone availability of decision lists of general thresh, linear threshold functions, functions which are not large margin, linear threshold functions.",
                    "label": 0
                },
                {
                    "sent": "And also it would be interesting whether one can evolve with linear thresholds functions properly without using other representations.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}