{
    "id": "i2fuveln7nxomwdlvqb2kldlpz3jrade",
    "title": "Stochastic Methods for L1 Regularized Loss Minimization",
    "info": {
        "author": [
            "Ambuj Tewari, Toyota Technological Institute at Chicago"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Optimization Methods"
        ]
    },
    "url": "http://videolectures.net/icml09_tewari_smrl/",
    "segmentation": [
        [
            "Alright, so special cases of this problem are the less Uber we choose the last."
        ],
        [
            "To be the squared loss function, another very popular special case of this problem is the L1 regularize logistic regression, where we choose the function to be the logistic function.",
            "And of course you can also consider your favorite loss function.",
            "For example, the hinge loss function, the hinge loss function with the L1 regularization.",
            "So why does it become popular?"
        ],
        [
            "Well, one of the reasons is that the element penalty is known to encourage sparsity, and Moreover, if you choose your loss function to be convex, overall problem is also convex.",
            "So you might think that the problem is solved because you know there are off the shelf convex optimizers out there, so you can choose your favorite toolbox and solve the problem.",
            "That's not quite the case because for example runtime of some of the sophisticated interior point methods typically scales cubically in the relevant parameters, and this is really bad.",
            "Large datasets.",
            "And the key observation is that we don't need to solve these problems too.",
            "High degree of accuracy.",
            "So usually we can live with a worse dependence on one over epsilon, where epsilon is the accuracy to which you want to solve the problem.",
            "An R contribution here is to give two practical methods for solving the L1 regularizer problem in the large data set regime."
        ],
        [
            "OK, and the one take home message of the stock."
        ],
        [
            "Is mentioned here is that many simple updates are often much more efficient than a few sophisticated updates, and randomness is key idea.",
            "In our work to achieve this efficiency, so the two algorithms we propose.",
            "One of them will work along features so it will choose a random feature an make the local update whereby a local update.",
            "I mean it will just look on, it will just work on that column of the data matrix.",
            "So I view my data matrix as having examples on the Rose.",
            "OK so it has."
        ],
        [
            "Be columns where D is the number of features an MI will use as the total number of examples OK, and the second algorithm I propose will work along rows.",
            "It will choose an example randomly and then just work with that example."
        ],
        [
            "OK.",
            "So now we have the talk is that?",
            "I'll pretend the stochastic coordinate descent algorithm.",
            "I'll review very briefly some of the recent work that uses coordinate descent for L1 followed by our algorithm, and then some ideas about efficient implementation and a runtime bound.",
            "And I'll do this."
        ],
        [
            "Name for Smith Smith stands for.",
            "Stochastic medicine made spots, but we'll look at that in detail and then I'll go."
        ],
        [
            "Included some experiments OK.",
            "So.",
            "OK so off too.",
            "The stochastic coordinate descent."
        ],
        [
            "So just a very brief reminder of what coordinate descent does in general."
        ],
        [
            "So that's the general coordinate is an algorithm has to minimize."
        ],
        [
            "A certain function of several variables W one through WD.",
            "It's very simple."
        ],
        [
            "So just run some iterations.",
            "It chooses a coordinate J from one through D."
        ],
        [
            "This is the selection step is up to that."
        ],
        [
            "Designer so which coordinate you want to select update at different at particular step is up to you."
        ],
        [
            "And then updates that particular coordinate.",
            "So that the objective function because and that's where the name coordinate descent comes from.",
            "Because you choose a coordinate and then you do."
        ],
        [
            "OK so here.",
            "2 interesting quotes from recent papers.",
            "The first one is from a paper by Friedman HD encryption.",
            "Ronnie published in 2007, where this say Coordinatewise descent algorithms deserve more attention in convex optimization.",
            "There are simple and well suited to large problems.",
            "An another code by Ruin Lunch, another recent paper where they say that there are reasons for liking coordinate descent.",
            "Boiled down to simplicity, speed and stability, and hereby stability the mean numerical stable so it is gaining a lot of attention."
        ],
        [
            "And here's just a very small subset of recent activity in this area.",
            "So ganking Lucian Madigan in 2007 proposed algorithm for minimizing L1 regularize loss using quadratic approximation in like they fixed on a variable, and then use a quadratic approximation along that variable and then make a step and then iterate Freedman an coauthors.",
            "Very nice empirical study showing that coordinate descent is actually very competitive for this problem.",
            "And they were using the cyclic selection rules, so they were just cycling along coordinates didn't have formal guarantees, and then this paper by ruin.",
            "Lange also considered cyclic.",
            "It also considers greedy coordinate selection rules where to select the coordinate.",
            "You basically look at the gradient and then choose the coordinate where you get the most.",
            "The gradient values is highest in absolute value, so if you were just making breaking that One Direction, they choose the direction which gives you the maximum.",
            "Decrease in the objective, so that's proof of convergence, but again, no rights were given and then sang.",
            "Yoon sang in June in some recent work they've actually analyzed theoretically and given convergence rate bounds for coordinate descent.",
            "But then they have a pretty sophisticated convergent selection rule that takes ordered the time to implement because they essentially have to go through all the features to select a good feature to go to select a good coordinate update.",
            "OK, so before we present before I present our algorithm."
        ],
        [
            "There's a little transformation we need to make so that the problem really falls into our framework.",
            "So recall that this is the problem we're trying to solve, so we just double the dimensions standard tricks.",
            "You just append the negative of every instance.",
            "Onto it to double the dimension and then you also double the dimension of your weight vector W an.",
            "The reason we do that is that the so the L1 norm is the sum of absolute values in each absolute value can be written out of some of the positive part of that real number and negative part.",
            "So what happens is that the objective.",
            "Can you see it down, down here and everyone?",
            "So I'll just read out.",
            "So what we do is so this part remains the same, except that the dimensionality has doubled and X gets replaced by X hat.",
            "And here you can just write it as Lambda times some of the two D components of the new WJ.",
            "So The thing is, you absorb all the non differentiability into the constraint and the objective becomes differentiable.",
            "Well, as long as well as differential objectives, differential and all the non differentiability in the constraints."
        ],
        [
            "So here's the stochastic coordinate in algorithm."
        ],
        [
            "So beta is some number which is fixed once the loss function is fixed.",
            "For example, it's one for the lawsuit case.",
            "It's basically an upper bound."
        ],
        [
            "The second derivative of the function and the selection."
        ],
        [
            "It is extremely simple, so you just choose a coordinate ranking OK, so."
        ],
        [
            "So really simple rule takes constant amount of time to implement and then the update step."
        ],
        [
            "Is you?",
            "Just look at that particular entry in the gradient an.",
            "You"
        ],
        [
            "Make this update.",
            "This is the standard gradient update in One Direction, but then you project onto the positive axis.",
            "OK, so that's."
        ],
        [
            "Because if you remember the transformation.",
            "We had this constraint so all coordinates of double have to be positive, so we just enforce that loss.",
            "OK."
        ],
        [
            "OK, so if if your data matrix happens to be sparse then you can implement that algorithm even more efficiently by just so you choose a random feature.",
            "And in so, if you."
        ],
        [
            "Sure, the matrix intelligently, you only need to go through the nonzero entries of that column in order to implement that step.",
            "So it turns out just don't take long to realize that so."
        ],
        [
            "Oh, so the update really takes time proportional to the density of that particular column."
        ],
        [
            "OK.",
            "So it's pretty simple selection rule.",
            "It's parameter free, so you have found crying was talking about parameter free algorithm yesterday, so this is actually very simple code.",
            "You don't have to set any parameters, there are no Hessian computations online searches."
        ],
        [
            "And yet, Interestingly, we can show.",
            "Pretty much the best generations guarantee among these classic algorithms, so the time to achieve its expected epsilon accuracy, and we believe this expectation guarantee can actually be turned into a high probability guarantee.",
            "So this is that I'm not the number of iterations, so the actual time needed to get to epsilon accuracy is basically number of examples, number of features.",
            "This is some constant, like one or two depends on the loss function and then the two norm of the solution squared over epsilon.",
            "And then.",
            "The."
        ],
        [
            "Sending units bound where they had a sophisticated rule to select the coordinate is MD squared and then the rest of The thing is the same and essentially an extra extra factors becomes in because they have to spend time choosing the coordinate intelligently and we basically show that if you basically are using very simplistic strategy which is just random, you can show a better bound.",
            "OK, so that basically ends my one just one more flight on."
        ],
        [
            "Proof strategy I don't have time to go into the proof.",
            "There's a really cute idea here.",
            "If you."
        ],
        [
            "Get the proof is that we use the double potential, so usually you track the algorithm by defining a potential which decreases along the way and typical potentials used our distance from the solution or the objective function itself.",
            "And we use a mixed potential function and somehow we play some if you play some nice tricks with the expectation it turns out it's quite easy to get that guarantee."
        ],
        [
            "OK, so the next part is about Smith.",
            "So this is an algorithm based on this stochastic gradient descent idea, which is another idea which has been gaining popularity in this large data set regime.",
            "So what's the idea?",
            "So if you."
        ],
        [
            "Look at the gradient of the loss part, so gradient of the part that Justin was lost in the data.",
            "That's an average, right?",
            "It's an average over your sample.",
            "So very simple idea, but turns out to be keys that you can get an unbiased estimate of this gradient, but just using one randomly chosen example, right?",
            "So I just choose I randomly and then I just this quantity here will be unbiased estimate of the gradient of this loss and then you can use it to perform a gradient descent step and the hope is that when you do lots of these somehow the averaging will take care of fact that you're going in the right direction and it avoids incurring an M dependence because to calculate this gradient you really need to go through.",
            "Whole data set, but to get an unbiased estimate you just need to look at one example.",
            "It has been shown to be actually.",
            "It leads to state of the art methods for large datasets."
        ],
        [
            "OK, but we have a complication in that we have this additional term due to the L1 norm.",
            "So here I'm actually is not mathematically correct because it's not differentiable, but if W is nonzero then this is the gradient of the album loss.",
            "Otherwise you have to work with subdifferential and things like that.",
            "But the problem is that the stochastic gradient idea applied directly will this actually observed by Langford and Zhang.",
            "They said that they observed that.",
            "Two so when you make the gradient update, you'll be adding basically two real numbers and they will almost never add up to exactly 0.",
            "So the idea that idea applied directly to this problem fails to give sparsity.",
            "So one fix."
        ],
        [
            "Is to work with the constraint formulation right?",
            "So remove the regularization, go to a constraint ball.",
            "And then just minimize the loss over that L1 constraint board.",
            "OK, Ann has been some recent recent work by Duchenne coauthors to show how these so you use a projected gradient algorithm, and they show how to compute these predictions efficiently.",
            "The second phase fix, which I think is."
        ],
        [
            "Pretty elegant is due to Lankford and Zheng where they call their algorithm truncated gradient so they do the gradient step based on this formula.",
            "But the truncate the Wii to 0 if it crosses zero during an update.",
            "OK so that seems like a simple like.",
            "Seems like acoustic right?",
            "But it turns out you can prove formally that formally approved bounds for this algorithm and R. Smith.",
            "This algorithm is basically just combining this."
        ],
        [
            "Cute idea, but the idea of familiar descent.",
            "OK, so why wouldn't become clear in a few?"
        ],
        [
            "Sides, but just like 1 slide introduction to mirror descent for those who don't know it.",
            "So I believe everyone knows what gradient descent is, right?",
            "So you have you take some estimate of the gradient or the actual gradient and you just track you some learning rate and you subtract to get the next iterate.",
            "Well, mirror dissent is similar except that you go in some so called mirrored."
        ],
        [
            "Space using a link function.",
            "So you apply the link function to your original plan parameter.",
            "You go to the mirror space."
        ],
        [
            "Make the gradient update there.",
            "That gives you the next iterate in the middle space and you come back using the universal Link functions link function has to be invertible.",
            "An depending on what you're trying, your prior knowledge.",
            "Honda Blue is.",
            "You might want to choose a funk."
        ],
        [
            "Which is different from the identity, because if F is identity, then these two are the same.",
            "But in general if you choose F to be some nontrivial function, then you will get."
        ],
        [
            "A different algorithm, so we use.",
            "The link function which is appeared in the literature before it is the gradient of the Q norm squared an.",
            "So so it turns out that when you when you're doing optimization on like the simplex, so on the set of vectors whose sum whose components are positive and some to one, then you want to use something like the relative entropy an this function actually is a good proxy for Q near one for the relative entropy.",
            "Regularizer and there's a reason why we use this, which will become clearer when I present the algorithm in the next slide."
        ],
        [
            "So OK, so we have one parameter for this algorithm.",
            "And so that's the learning rate, because this is like a gradient descent kind of algorithm.",
            "So you need."
        ],
        [
            "Learning rate, so initialize everything to 0 used."
        ],
        [
            "Doing iterations, so again the same idea of randomness.",
            "This time we're choosing example randomly, not a feature.",
            "You get an unbiased estimate of the gradient OK, and then you do the truncated gradient step in the mirrored step."
        ],
        [
            "So this is just the usual gradient step and this is just truncating it to 0.",
            "If if the step happens to Crown 0.",
            "OK, and then the most important line."
        ],
        [
            "Actually, here is this.",
            "So you use the inverse link function to go back and the point is that the function we chose.",
            "This becomes clear if you write down the function.",
            "You can come to the poster for details, but it turns out that this inverse."
        ],
        [
            "Function preserves the sparsity pattern, so we don't lose the sparsity which we gain here at this step.",
            "When we go back to the loop.",
            "OK, so that's just the property of the link function.",
            "That's why we can't use like something like the relative entropy, because that will not lead to this property.",
            "OK, so you can use the same ideas before."
        ],
        [
            "You choose an example randomly and in."
        ],
        [
            "Buses you can implement that update an if you can.",
            "Again shoe store things you know exploit."
        ],
        [
            "Firstly, so here's the convergence guarantee that."
        ],
        [
            "Again, the time to achieve expected epsilon accuracy is D log D, dimension.",
            "And then the Infinity norm of the instances squared and then the one norm of their solution squared over epsilon squared.",
            "OK, so this is good and this is bad because.",
            "Sorry this is bad and this is good when you compare the bound to the truncated gradient bound because the two norm of the instance is always going to be larger than the Infinity norm, but the two norm is going to be smaller than the one Now, so this bound is bad and worse depending on which situation you are."
        ],
        [
            "So here's one situation where this one is better is when you when you in the solution is sparse, but the axes are dense, right?",
            "So if the axes are.",
            "The W is started sparse, then you don't get hurt too much by having this term here, but you gain a lot by having the Infinity Norm as opposed to the two norm because the axes are dense."
        ],
        [
            "On the other hand, if the X is are sparse, but the solution is dense, then of course the sound is better and but these are just bound right?",
            "So we did some preliminary experiments to see if this is actually reflected in practice, so."
        ],
        [
            "Just I just couldn't do without some two datasets, one real and one.",
            "Synthetic for.",
            "For other experiments, you welcome to come to our poster, so the four algorithms we compared were so of course we have the SDS needles from this paper.",
            "Then there's a deterministic variant of coordinate descent, which is along the lines of women loungewear.",
            "You greedily choose a coordinate to update an you actually turned out to be really slow and experiments because you that I'm used to choose a good coordinate which was just too much because of high dimensionality.",
            "And then the 4th algorithm is 1 version of the truncated gradient algorithm of line full."
        ],
        [
            "So the last two algorithms need a parameter an.",
            "We gave these algorithms actually an edge because we searched over an exponentially spaced grid and are we reporting results for the best data.",
            "So if you take into account the time involved in choosing best data, than these algorithms will do worse.",
            "OK, so do datasets.",
            "One is the latest."
        ],
        [
            "Direct from writers, about 800,000 examples.",
            "400,000 features very sparse .03% sparsity level, and the synthetic data is actually real data set.",
            "We added just thousand random plus minus one featured features to it to make it a dense data set.",
            "Because remember, I told that on dense datasets and will double started sparse.",
            "We expects meters to do better than truncated gradients.",
            "We just wanted to verify that an example and hear the sparse level is basically 100% because I mean.",
            "Most of the features by designer are dense."
        ],
        [
            "OK, so here's the form and songwriters weather when the regulation parameter is 10 to the minus six.",
            "So on the Y axis is the loss, and on the X axis is actually not time, but sort of an implementation independent quantity, which is the number of times the algorithm accessed the data matrix that's, I think a good proxy for the time.",
            "So here CD does extremely well and.",
            "The two gradient descent algorithms don't do that well.",
            "Might be because we didn't quite search the parameter space well, but in any case it shows that you know.",
            "There are problems in using using algorithms that have a parameter, because you either this performance is bad because the algorithms don't do well on this data set, or it's the case that even though we searched over like eight are in the link in like across 7 orders of magnitude, we."
        ],
        [
            "Somehow didn't locate the right data, although that seems unlikely.",
            "Um?"
        ],
        [
            "And this is the again, the regularised loss as a function of the number of accesses to the data matrix.",
            "For these four algorithms here smears and the gradient descent algorithms meters an truncated gradient, are doing better than just a cost stochastic coordinate descent.",
            "And then this is the deterministic version always does worse because it takes a lot of time to achieve the same accuracy because it spends a lot of time choosing the feature intelligently, while you could just.",
            "This record shows that you could just choose the feature randomly and you get.",
            "Don't lose much.",
            "This is a last experiment actually, so this is showing that smooth jazz is actually able to maintain sparsity all along the way.",
            "OK, so this is again on the dense data set.",
            "Partially synthetic datasets were showing that as iterations proceed it loses sparsity, but is able to at least the initial phases and it's able to retain sparsity of the vector along the way.",
            "OK, so that brings me to the end of my top."
        ],
        [
            "So the data."
        ],
        [
            "Message is that both of these algorithms perform really simple, almost stupid updates, but there are lots of them using coupled with randomization and contrast this with the sophisticated methods like interior point methods where you do few, but each update is pretty sophisticated and despite the simplicity we can actually prove convergence bounds, which I showed you in earlier slides, and these bounds are not like quadratic or cubic in MMD.",
            "Anna preliminary experiment suggests that.",
            "All these algorithms have the potential to be successful in practice, thank you.",
            "Corrections."
        ],
        [
            "Do not depend on the condition, number of the other problem.",
            "Can you comment on that?",
            "Yeah, so so condition number so.",
            "So do you mean the why don't depend on the eigenvalues of the X matrix?",
            "So it turns out that for stochastic coordinate descent, the only thing that matters is the sort of the smoothness of the loss function that so that is quantified by beta.",
            "And for the gradient descent, actually.",
            "So if you look at the objective function we showed you, it had a.",
            "So the regulation term is basically linear, so.",
            "All we use essentially is.",
            "You know so inherently, we just use the strong convexity in our link function.",
            "So the link function actually comes from a regularizer, right?",
            "So somehow we don't depend on the convexity present in the data, so that's probably the reason at least.",
            "My best guess why the condition number or the curvature present in the data doesn't appear in our bounds.",
            "I'm sure that if, maybe perhaps you could show like a faster convergence if you made assumptions about the data.",
            "I don't know if you do have something to add about.",
            "Crystal meth another $10 now.",
            "Condition.",
            "Programs to choose much better dark skin problems don't care about one person.",
            "In this case, it's a.",
            "It's a good deal.",
            "Yeah, so we already have some minutes behind our schedule could be continued discussion of the poster.",
            "OK, let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so special cases of this problem are the less Uber we choose the last.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To be the squared loss function, another very popular special case of this problem is the L1 regularize logistic regression, where we choose the function to be the logistic function.",
                    "label": 0
                },
                {
                    "sent": "And of course you can also consider your favorite loss function.",
                    "label": 0
                },
                {
                    "sent": "For example, the hinge loss function, the hinge loss function with the L1 regularization.",
                    "label": 0
                },
                {
                    "sent": "So why does it become popular?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, one of the reasons is that the element penalty is known to encourage sparsity, and Moreover, if you choose your loss function to be convex, overall problem is also convex.",
                    "label": 0
                },
                {
                    "sent": "So you might think that the problem is solved because you know there are off the shelf convex optimizers out there, so you can choose your favorite toolbox and solve the problem.",
                    "label": 0
                },
                {
                    "sent": "That's not quite the case because for example runtime of some of the sophisticated interior point methods typically scales cubically in the relevant parameters, and this is really bad.",
                    "label": 0
                },
                {
                    "sent": "Large datasets.",
                    "label": 0
                },
                {
                    "sent": "And the key observation is that we don't need to solve these problems too.",
                    "label": 0
                },
                {
                    "sent": "High degree of accuracy.",
                    "label": 0
                },
                {
                    "sent": "So usually we can live with a worse dependence on one over epsilon, where epsilon is the accuracy to which you want to solve the problem.",
                    "label": 1
                },
                {
                    "sent": "An R contribution here is to give two practical methods for solving the L1 regularizer problem in the large data set regime.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and the one take home message of the stock.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is mentioned here is that many simple updates are often much more efficient than a few sophisticated updates, and randomness is key idea.",
                    "label": 1
                },
                {
                    "sent": "In our work to achieve this efficiency, so the two algorithms we propose.",
                    "label": 0
                },
                {
                    "sent": "One of them will work along features so it will choose a random feature an make the local update whereby a local update.",
                    "label": 0
                },
                {
                    "sent": "I mean it will just look on, it will just work on that column of the data matrix.",
                    "label": 0
                },
                {
                    "sent": "So I view my data matrix as having examples on the Rose.",
                    "label": 0
                },
                {
                    "sent": "OK so it has.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be columns where D is the number of features an MI will use as the total number of examples OK, and the second algorithm I propose will work along rows.",
                    "label": 0
                },
                {
                    "sent": "It will choose an example randomly and then just work with that example.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now we have the talk is that?",
                    "label": 0
                },
                {
                    "sent": "I'll pretend the stochastic coordinate descent algorithm.",
                    "label": 1
                },
                {
                    "sent": "I'll review very briefly some of the recent work that uses coordinate descent for L1 followed by our algorithm, and then some ideas about efficient implementation and a runtime bound.",
                    "label": 1
                },
                {
                    "sent": "And I'll do this.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Name for Smith Smith stands for.",
                    "label": 0
                },
                {
                    "sent": "Stochastic medicine made spots, but we'll look at that in detail and then I'll go.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Included some experiments OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK so off too.",
                    "label": 0
                },
                {
                    "sent": "The stochastic coordinate descent.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just a very brief reminder of what coordinate descent does in general.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the general coordinate is an algorithm has to minimize.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A certain function of several variables W one through WD.",
                    "label": 0
                },
                {
                    "sent": "It's very simple.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just run some iterations.",
                    "label": 0
                },
                {
                    "sent": "It chooses a coordinate J from one through D.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the selection step is up to that.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Designer so which coordinate you want to select update at different at particular step is up to you.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then updates that particular coordinate.",
                    "label": 0
                },
                {
                    "sent": "So that the objective function because and that's where the name coordinate descent comes from.",
                    "label": 1
                },
                {
                    "sent": "Because you choose a coordinate and then you do.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so here.",
                    "label": 0
                },
                {
                    "sent": "2 interesting quotes from recent papers.",
                    "label": 0
                },
                {
                    "sent": "The first one is from a paper by Friedman HD encryption.",
                    "label": 0
                },
                {
                    "sent": "Ronnie published in 2007, where this say Coordinatewise descent algorithms deserve more attention in convex optimization.",
                    "label": 1
                },
                {
                    "sent": "There are simple and well suited to large problems.",
                    "label": 1
                },
                {
                    "sent": "An another code by Ruin Lunch, another recent paper where they say that there are reasons for liking coordinate descent.",
                    "label": 0
                },
                {
                    "sent": "Boiled down to simplicity, speed and stability, and hereby stability the mean numerical stable so it is gaining a lot of attention.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here's just a very small subset of recent activity in this area.",
                    "label": 1
                },
                {
                    "sent": "So ganking Lucian Madigan in 2007 proposed algorithm for minimizing L1 regularize loss using quadratic approximation in like they fixed on a variable, and then use a quadratic approximation along that variable and then make a step and then iterate Freedman an coauthors.",
                    "label": 1
                },
                {
                    "sent": "Very nice empirical study showing that coordinate descent is actually very competitive for this problem.",
                    "label": 0
                },
                {
                    "sent": "And they were using the cyclic selection rules, so they were just cycling along coordinates didn't have formal guarantees, and then this paper by ruin.",
                    "label": 0
                },
                {
                    "sent": "Lange also considered cyclic.",
                    "label": 0
                },
                {
                    "sent": "It also considers greedy coordinate selection rules where to select the coordinate.",
                    "label": 1
                },
                {
                    "sent": "You basically look at the gradient and then choose the coordinate where you get the most.",
                    "label": 1
                },
                {
                    "sent": "The gradient values is highest in absolute value, so if you were just making breaking that One Direction, they choose the direction which gives you the maximum.",
                    "label": 0
                },
                {
                    "sent": "Decrease in the objective, so that's proof of convergence, but again, no rights were given and then sang.",
                    "label": 0
                },
                {
                    "sent": "Yoon sang in June in some recent work they've actually analyzed theoretically and given convergence rate bounds for coordinate descent.",
                    "label": 0
                },
                {
                    "sent": "But then they have a pretty sophisticated convergent selection rule that takes ordered the time to implement because they essentially have to go through all the features to select a good feature to go to select a good coordinate update.",
                    "label": 0
                },
                {
                    "sent": "OK, so before we present before I present our algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's a little transformation we need to make so that the problem really falls into our framework.",
                    "label": 0
                },
                {
                    "sent": "So recall that this is the problem we're trying to solve, so we just double the dimensions standard tricks.",
                    "label": 0
                },
                {
                    "sent": "You just append the negative of every instance.",
                    "label": 0
                },
                {
                    "sent": "Onto it to double the dimension and then you also double the dimension of your weight vector W an.",
                    "label": 0
                },
                {
                    "sent": "The reason we do that is that the so the L1 norm is the sum of absolute values in each absolute value can be written out of some of the positive part of that real number and negative part.",
                    "label": 0
                },
                {
                    "sent": "So what happens is that the objective.",
                    "label": 0
                },
                {
                    "sent": "Can you see it down, down here and everyone?",
                    "label": 0
                },
                {
                    "sent": "So I'll just read out.",
                    "label": 0
                },
                {
                    "sent": "So what we do is so this part remains the same, except that the dimensionality has doubled and X gets replaced by X hat.",
                    "label": 0
                },
                {
                    "sent": "And here you can just write it as Lambda times some of the two D components of the new WJ.",
                    "label": 0
                },
                {
                    "sent": "So The thing is, you absorb all the non differentiability into the constraint and the objective becomes differentiable.",
                    "label": 0
                },
                {
                    "sent": "Well, as long as well as differential objectives, differential and all the non differentiability in the constraints.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's the stochastic coordinate in algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So beta is some number which is fixed once the loss function is fixed.",
                    "label": 0
                },
                {
                    "sent": "For example, it's one for the lawsuit case.",
                    "label": 0
                },
                {
                    "sent": "It's basically an upper bound.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second derivative of the function and the selection.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is extremely simple, so you just choose a coordinate ranking OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So really simple rule takes constant amount of time to implement and then the update step.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is you?",
                    "label": 0
                },
                {
                    "sent": "Just look at that particular entry in the gradient an.",
                    "label": 1
                },
                {
                    "sent": "You",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Make this update.",
                    "label": 0
                },
                {
                    "sent": "This is the standard gradient update in One Direction, but then you project onto the positive axis.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because if you remember the transformation.",
                    "label": 0
                },
                {
                    "sent": "We had this constraint so all coordinates of double have to be positive, so we just enforce that loss.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so if if your data matrix happens to be sparse then you can implement that algorithm even more efficiently by just so you choose a random feature.",
                    "label": 0
                },
                {
                    "sent": "And in so, if you.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sure, the matrix intelligently, you only need to go through the nonzero entries of that column in order to implement that step.",
                    "label": 0
                },
                {
                    "sent": "So it turns out just don't take long to realize that so.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh, so the update really takes time proportional to the density of that particular column.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So it's pretty simple selection rule.",
                    "label": 0
                },
                {
                    "sent": "It's parameter free, so you have found crying was talking about parameter free algorithm yesterday, so this is actually very simple code.",
                    "label": 0
                },
                {
                    "sent": "You don't have to set any parameters, there are no Hessian computations online searches.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And yet, Interestingly, we can show.",
                    "label": 0
                },
                {
                    "sent": "Pretty much the best generations guarantee among these classic algorithms, so the time to achieve its expected epsilon accuracy, and we believe this expectation guarantee can actually be turned into a high probability guarantee.",
                    "label": 0
                },
                {
                    "sent": "So this is that I'm not the number of iterations, so the actual time needed to get to epsilon accuracy is basically number of examples, number of features.",
                    "label": 0
                },
                {
                    "sent": "This is some constant, like one or two depends on the loss function and then the two norm of the solution squared over epsilon.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sending units bound where they had a sophisticated rule to select the coordinate is MD squared and then the rest of The thing is the same and essentially an extra extra factors becomes in because they have to spend time choosing the coordinate intelligently and we basically show that if you basically are using very simplistic strategy which is just random, you can show a better bound.",
                    "label": 0
                },
                {
                    "sent": "OK, so that basically ends my one just one more flight on.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Proof strategy I don't have time to go into the proof.",
                    "label": 0
                },
                {
                    "sent": "There's a really cute idea here.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Get the proof is that we use the double potential, so usually you track the algorithm by defining a potential which decreases along the way and typical potentials used our distance from the solution or the objective function itself.",
                    "label": 0
                },
                {
                    "sent": "And we use a mixed potential function and somehow we play some if you play some nice tricks with the expectation it turns out it's quite easy to get that guarantee.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the next part is about Smith.",
                    "label": 0
                },
                {
                    "sent": "So this is an algorithm based on this stochastic gradient descent idea, which is another idea which has been gaining popularity in this large data set regime.",
                    "label": 1
                },
                {
                    "sent": "So what's the idea?",
                    "label": 0
                },
                {
                    "sent": "So if you.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look at the gradient of the loss part, so gradient of the part that Justin was lost in the data.",
                    "label": 0
                },
                {
                    "sent": "That's an average, right?",
                    "label": 0
                },
                {
                    "sent": "It's an average over your sample.",
                    "label": 0
                },
                {
                    "sent": "So very simple idea, but turns out to be keys that you can get an unbiased estimate of this gradient, but just using one randomly chosen example, right?",
                    "label": 0
                },
                {
                    "sent": "So I just choose I randomly and then I just this quantity here will be unbiased estimate of the gradient of this loss and then you can use it to perform a gradient descent step and the hope is that when you do lots of these somehow the averaging will take care of fact that you're going in the right direction and it avoids incurring an M dependence because to calculate this gradient you really need to go through.",
                    "label": 1
                },
                {
                    "sent": "Whole data set, but to get an unbiased estimate you just need to look at one example.",
                    "label": 1
                },
                {
                    "sent": "It has been shown to be actually.",
                    "label": 0
                },
                {
                    "sent": "It leads to state of the art methods for large datasets.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, but we have a complication in that we have this additional term due to the L1 norm.",
                    "label": 0
                },
                {
                    "sent": "So here I'm actually is not mathematically correct because it's not differentiable, but if W is nonzero then this is the gradient of the album loss.",
                    "label": 0
                },
                {
                    "sent": "Otherwise you have to work with subdifferential and things like that.",
                    "label": 1
                },
                {
                    "sent": "But the problem is that the stochastic gradient idea applied directly will this actually observed by Langford and Zhang.",
                    "label": 1
                },
                {
                    "sent": "They said that they observed that.",
                    "label": 0
                },
                {
                    "sent": "Two so when you make the gradient update, you'll be adding basically two real numbers and they will almost never add up to exactly 0.",
                    "label": 0
                },
                {
                    "sent": "So the idea that idea applied directly to this problem fails to give sparsity.",
                    "label": 1
                },
                {
                    "sent": "So one fix.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is to work with the constraint formulation right?",
                    "label": 0
                },
                {
                    "sent": "So remove the regularization, go to a constraint ball.",
                    "label": 0
                },
                {
                    "sent": "And then just minimize the loss over that L1 constraint board.",
                    "label": 0
                },
                {
                    "sent": "OK, Ann has been some recent recent work by Duchenne coauthors to show how these so you use a projected gradient algorithm, and they show how to compute these predictions efficiently.",
                    "label": 0
                },
                {
                    "sent": "The second phase fix, which I think is.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pretty elegant is due to Lankford and Zheng where they call their algorithm truncated gradient so they do the gradient step based on this formula.",
                    "label": 0
                },
                {
                    "sent": "But the truncate the Wii to 0 if it crosses zero during an update.",
                    "label": 1
                },
                {
                    "sent": "OK so that seems like a simple like.",
                    "label": 0
                },
                {
                    "sent": "Seems like acoustic right?",
                    "label": 0
                },
                {
                    "sent": "But it turns out you can prove formally that formally approved bounds for this algorithm and R. Smith.",
                    "label": 0
                },
                {
                    "sent": "This algorithm is basically just combining this.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cute idea, but the idea of familiar descent.",
                    "label": 0
                },
                {
                    "sent": "OK, so why wouldn't become clear in a few?",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sides, but just like 1 slide introduction to mirror descent for those who don't know it.",
                    "label": 1
                },
                {
                    "sent": "So I believe everyone knows what gradient descent is, right?",
                    "label": 1
                },
                {
                    "sent": "So you have you take some estimate of the gradient or the actual gradient and you just track you some learning rate and you subtract to get the next iterate.",
                    "label": 0
                },
                {
                    "sent": "Well, mirror dissent is similar except that you go in some so called mirrored.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Space using a link function.",
                    "label": 1
                },
                {
                    "sent": "So you apply the link function to your original plan parameter.",
                    "label": 0
                },
                {
                    "sent": "You go to the mirror space.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Make the gradient update there.",
                    "label": 0
                },
                {
                    "sent": "That gives you the next iterate in the middle space and you come back using the universal Link functions link function has to be invertible.",
                    "label": 0
                },
                {
                    "sent": "An depending on what you're trying, your prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "Honda Blue is.",
                    "label": 0
                },
                {
                    "sent": "You might want to choose a funk.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is different from the identity, because if F is identity, then these two are the same.",
                    "label": 0
                },
                {
                    "sent": "But in general if you choose F to be some nontrivial function, then you will get.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A different algorithm, so we use.",
                    "label": 0
                },
                {
                    "sent": "The link function which is appeared in the literature before it is the gradient of the Q norm squared an.",
                    "label": 0
                },
                {
                    "sent": "So so it turns out that when you when you're doing optimization on like the simplex, so on the set of vectors whose sum whose components are positive and some to one, then you want to use something like the relative entropy an this function actually is a good proxy for Q near one for the relative entropy.",
                    "label": 0
                },
                {
                    "sent": "Regularizer and there's a reason why we use this, which will become clearer when I present the algorithm in the next slide.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, so we have one parameter for this algorithm.",
                    "label": 0
                },
                {
                    "sent": "And so that's the learning rate, because this is like a gradient descent kind of algorithm.",
                    "label": 0
                },
                {
                    "sent": "So you need.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learning rate, so initialize everything to 0 used.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doing iterations, so again the same idea of randomness.",
                    "label": 0
                },
                {
                    "sent": "This time we're choosing example randomly, not a feature.",
                    "label": 0
                },
                {
                    "sent": "You get an unbiased estimate of the gradient OK, and then you do the truncated gradient step in the mirrored step.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is just the usual gradient step and this is just truncating it to 0.",
                    "label": 0
                },
                {
                    "sent": "If if the step happens to Crown 0.",
                    "label": 0
                },
                {
                    "sent": "OK, and then the most important line.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, here is this.",
                    "label": 0
                },
                {
                    "sent": "So you use the inverse link function to go back and the point is that the function we chose.",
                    "label": 0
                },
                {
                    "sent": "This becomes clear if you write down the function.",
                    "label": 0
                },
                {
                    "sent": "You can come to the poster for details, but it turns out that this inverse.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function preserves the sparsity pattern, so we don't lose the sparsity which we gain here at this step.",
                    "label": 0
                },
                {
                    "sent": "When we go back to the loop.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's just the property of the link function.",
                    "label": 0
                },
                {
                    "sent": "That's why we can't use like something like the relative entropy, because that will not lead to this property.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can use the same ideas before.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You choose an example randomly and in.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Buses you can implement that update an if you can.",
                    "label": 0
                },
                {
                    "sent": "Again shoe store things you know exploit.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Firstly, so here's the convergence guarantee that.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again, the time to achieve expected epsilon accuracy is D log D, dimension.",
                    "label": 1
                },
                {
                    "sent": "And then the Infinity norm of the instances squared and then the one norm of their solution squared over epsilon squared.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is good and this is bad because.",
                    "label": 1
                },
                {
                    "sent": "Sorry this is bad and this is good when you compare the bound to the truncated gradient bound because the two norm of the instance is always going to be larger than the Infinity norm, but the two norm is going to be smaller than the one Now, so this bound is bad and worse depending on which situation you are.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's one situation where this one is better is when you when you in the solution is sparse, but the axes are dense, right?",
                    "label": 0
                },
                {
                    "sent": "So if the axes are.",
                    "label": 0
                },
                {
                    "sent": "The W is started sparse, then you don't get hurt too much by having this term here, but you gain a lot by having the Infinity Norm as opposed to the two norm because the axes are dense.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the other hand, if the X is are sparse, but the solution is dense, then of course the sound is better and but these are just bound right?",
                    "label": 0
                },
                {
                    "sent": "So we did some preliminary experiments to see if this is actually reflected in practice, so.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just I just couldn't do without some two datasets, one real and one.",
                    "label": 0
                },
                {
                    "sent": "Synthetic for.",
                    "label": 0
                },
                {
                    "sent": "For other experiments, you welcome to come to our poster, so the four algorithms we compared were so of course we have the SDS needles from this paper.",
                    "label": 0
                },
                {
                    "sent": "Then there's a deterministic variant of coordinate descent, which is along the lines of women loungewear.",
                    "label": 0
                },
                {
                    "sent": "You greedily choose a coordinate to update an you actually turned out to be really slow and experiments because you that I'm used to choose a good coordinate which was just too much because of high dimensionality.",
                    "label": 0
                },
                {
                    "sent": "And then the 4th algorithm is 1 version of the truncated gradient algorithm of line full.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the last two algorithms need a parameter an.",
                    "label": 1
                },
                {
                    "sent": "We gave these algorithms actually an edge because we searched over an exponentially spaced grid and are we reporting results for the best data.",
                    "label": 1
                },
                {
                    "sent": "So if you take into account the time involved in choosing best data, than these algorithms will do worse.",
                    "label": 0
                },
                {
                    "sent": "OK, so do datasets.",
                    "label": 0
                },
                {
                    "sent": "One is the latest.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Direct from writers, about 800,000 examples.",
                    "label": 0
                },
                {
                    "sent": "400,000 features very sparse .03% sparsity level, and the synthetic data is actually real data set.",
                    "label": 0
                },
                {
                    "sent": "We added just thousand random plus minus one featured features to it to make it a dense data set.",
                    "label": 0
                },
                {
                    "sent": "Because remember, I told that on dense datasets and will double started sparse.",
                    "label": 0
                },
                {
                    "sent": "We expects meters to do better than truncated gradients.",
                    "label": 0
                },
                {
                    "sent": "We just wanted to verify that an example and hear the sparse level is basically 100% because I mean.",
                    "label": 0
                },
                {
                    "sent": "Most of the features by designer are dense.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's the form and songwriters weather when the regulation parameter is 10 to the minus six.",
                    "label": 0
                },
                {
                    "sent": "So on the Y axis is the loss, and on the X axis is actually not time, but sort of an implementation independent quantity, which is the number of times the algorithm accessed the data matrix that's, I think a good proxy for the time.",
                    "label": 0
                },
                {
                    "sent": "So here CD does extremely well and.",
                    "label": 0
                },
                {
                    "sent": "The two gradient descent algorithms don't do that well.",
                    "label": 0
                },
                {
                    "sent": "Might be because we didn't quite search the parameter space well, but in any case it shows that you know.",
                    "label": 0
                },
                {
                    "sent": "There are problems in using using algorithms that have a parameter, because you either this performance is bad because the algorithms don't do well on this data set, or it's the case that even though we searched over like eight are in the link in like across 7 orders of magnitude, we.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Somehow didn't locate the right data, although that seems unlikely.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is the again, the regularised loss as a function of the number of accesses to the data matrix.",
                    "label": 1
                },
                {
                    "sent": "For these four algorithms here smears and the gradient descent algorithms meters an truncated gradient, are doing better than just a cost stochastic coordinate descent.",
                    "label": 1
                },
                {
                    "sent": "And then this is the deterministic version always does worse because it takes a lot of time to achieve the same accuracy because it spends a lot of time choosing the feature intelligently, while you could just.",
                    "label": 0
                },
                {
                    "sent": "This record shows that you could just choose the feature randomly and you get.",
                    "label": 0
                },
                {
                    "sent": "Don't lose much.",
                    "label": 0
                },
                {
                    "sent": "This is a last experiment actually, so this is showing that smooth jazz is actually able to maintain sparsity all along the way.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is again on the dense data set.",
                    "label": 0
                },
                {
                    "sent": "Partially synthetic datasets were showing that as iterations proceed it loses sparsity, but is able to at least the initial phases and it's able to retain sparsity of the vector along the way.",
                    "label": 0
                },
                {
                    "sent": "OK, so that brings me to the end of my top.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the data.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Message is that both of these algorithms perform really simple, almost stupid updates, but there are lots of them using coupled with randomization and contrast this with the sophisticated methods like interior point methods where you do few, but each update is pretty sophisticated and despite the simplicity we can actually prove convergence bounds, which I showed you in earlier slides, and these bounds are not like quadratic or cubic in MMD.",
                    "label": 0
                },
                {
                    "sent": "Anna preliminary experiment suggests that.",
                    "label": 0
                },
                {
                    "sent": "All these algorithms have the potential to be successful in practice, thank you.",
                    "label": 1
                },
                {
                    "sent": "Corrections.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do not depend on the condition, number of the other problem.",
                    "label": 0
                },
                {
                    "sent": "Can you comment on that?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so condition number so.",
                    "label": 0
                },
                {
                    "sent": "So do you mean the why don't depend on the eigenvalues of the X matrix?",
                    "label": 0
                },
                {
                    "sent": "So it turns out that for stochastic coordinate descent, the only thing that matters is the sort of the smoothness of the loss function that so that is quantified by beta.",
                    "label": 1
                },
                {
                    "sent": "And for the gradient descent, actually.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the objective function we showed you, it had a.",
                    "label": 0
                },
                {
                    "sent": "So the regulation term is basically linear, so.",
                    "label": 0
                },
                {
                    "sent": "All we use essentially is.",
                    "label": 0
                },
                {
                    "sent": "You know so inherently, we just use the strong convexity in our link function.",
                    "label": 0
                },
                {
                    "sent": "So the link function actually comes from a regularizer, right?",
                    "label": 0
                },
                {
                    "sent": "So somehow we don't depend on the convexity present in the data, so that's probably the reason at least.",
                    "label": 0
                },
                {
                    "sent": "My best guess why the condition number or the curvature present in the data doesn't appear in our bounds.",
                    "label": 0
                },
                {
                    "sent": "I'm sure that if, maybe perhaps you could show like a faster convergence if you made assumptions about the data.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you do have something to add about.",
                    "label": 0
                },
                {
                    "sent": "Crystal meth another $10 now.",
                    "label": 0
                },
                {
                    "sent": "Condition.",
                    "label": 0
                },
                {
                    "sent": "Programs to choose much better dark skin problems don't care about one person.",
                    "label": 0
                },
                {
                    "sent": "In this case, it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a good deal.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we already have some minutes behind our schedule could be continued discussion of the poster.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}