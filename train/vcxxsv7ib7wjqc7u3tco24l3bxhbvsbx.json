{
    "id": "vcxxsv7ib7wjqc7u3tco24l3bxhbvsbx",
    "title": "Mining visual actions from movies",
    "info": {
        "author": [
            "Adrien Gaidon, INRIA Grenoble Rh\u00f4ne-Alpes"
        ],
        "published": "Dec. 1, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Computer Vision->Motion and Tracking",
            "Top->Computer Science->Computer Vision->Video Analysis",
            "Top->Computer Science->Computer Vision->Image & Video Retrieval"
        ]
    },
    "url": "http://videolectures.net/bmvc09_gaidon_mva/",
    "segmentation": [
        [
            "Good morning, my name is Adrian get and I'm a PhD student of the year.",
            "Team of the INRIA Grenoble Research Center.",
            "Like Alex and I'm actually honored to be the last talk of this conference.",
            "So I'm here to present my paper entitled mining visual actions from movies.",
            "And this is joint work with marching matherly"
        ],
        [
            "Can Cordia schmitz?",
            "In this paper, we're interested in visual human actions, so we're interested in human actions because they are major visual events in movies news.",
            "Many other video types, and we're also interested in real world videos.",
            "So it means we have to face complex emerging conditions, large interclass variations visually I'll defined concepts and so on.",
            "And in order to help the analysis of large amounts of realistic videos, we would like to, for instance, discover what actions are performed or we would like to collect action samples for action recognition systems.",
            "So in this paper we propose to do this by mining actions from movies by using."
        ],
        [
            "Envision.",
            "So why movies?",
            "Simply because there are a large source of high quality, realistic videos.",
            "So they provide a huge amount really of diversified and representative action examples which are very useful for scene modeling, action, action modeling, etc.",
            "And what's also nice about movies is that they generally come with precise textual description of the events occurring in the movie, and these are the transcription screenplay.",
            "So you must be pretty familiar now with this.",
            "So in this paper we consider the TV series Buffy the Vampire Slayer's data sets.",
            "Buffy is actually becoming pretty famous and computer vision community right now, so we're interested.",
            "So we're using the full sets of the 39 DVDs, which amounts to approximately 100 hours of videos or 10,000,000."
        ],
        [
            "So it's a huge collection.",
            "So our approach to mine actions from movies using both text and vision consists of four steps.",
            "First, we synchronize the transcripts with the videos.",
            "Then we segment the movies.",
            "The full length movies into short clips.",
            "We then mine actions from the transcripts and finally there comes the vision.",
            "We ranked the text retrieval actions by visual relevance, so our main contributions are how we rank the text.",
            "Mine actions by using visual consistency.",
            "How we handle a kind of weak supervision that we obtain automatically an we also propose a novel approach to use such a weak supervision.",
            "This is an iterative re ranking algorithm using regression.",
            "It's called iterative SCR."
        ],
        [
            "Related work has been done recently on realistic videos, for instance by Koratala TC 08 on temporal segmentation of TV series.",
            "Also, there has been work SVR 08 by even lapped F An Super 09 by marching marszalek unsupervised action classification.",
            "This Hollywood two data set and the similar approaches have been investigated in order to build collections of images for specific object classes but also for naming characters and images and videos.",
            "There's this famous paper by every gamma tile at BMV 06.",
            "Also using Buffy.",
            "Um?"
        ],
        [
            "The first step in our action mining framework is to extract actions from videos by using textual information."
        ],
        [
            "So we start with a text driven temporal segmentation of the full length movies into short clips.",
            "Several 100 frames, let's say.",
            "Following every metallic VCO six, we align the transcripts so up there on the right with the videos.",
            "So here by using subtitles up there.",
            "So using the synchronized transcripts, it means the transcripts with temporal information.",
            "We can decompose the videos into short clips.",
            "A clip is defined as a video between two consecutive subtitles.",
            "Let's say this one, the blue one and the degree one Ann.",
            "Thanks to the transcript, there's associated text to each clip.",
            "It simply did transcript part that is between the corresponding dialogue lines.",
            "But it's a bit short.",
            "I'm sorry, but here it's written.",
            "They come out of the classroom, man walk down the hole.",
            "So it's a precise description of the events occurring in this time range.",
            "So using this."
        ],
        [
            "Textual information associated to each clips.",
            "Then we can actually mine actions from text by simply extracting verbs.",
            "An action examples are then defined as cliffs whose textual description simply contain the corresponding verb.",
            "Here you see the results on all of the Buffy episodes, so our text mining approach gives approximately 15,000 clips.",
            "An here you see the most commonly occurring verb on the left, so maybe can't read it's walk and it's actually occurring in more than 750 clips."
        ],
        [
            "So at this stage we have a list of action candidates.",
            "Let's say for query action walk and this list is examples.",
            "Are examples retrieved from text.",
            "So now we're going to see how we rank those action clips by using visual consistency."
        ],
        [
            "So the problem with this textual retrieval process I mentioned earlier is that some textually relevant samples are visually irrelevant.",
            "So our goal is to visually rank this retrieved list by by using visual relevance.",
            "And in order to do so, we make a simple assumption.",
            "We assume that the relevant documents in this list, so the documents that actually contain the action of interest.",
            "They must share some common visual characteristics.",
            "And the consequences of the simple assumption is actually nice.",
            "It's that the retrieval errors, which means the sample that we want to deal with.",
            "There are simply the inconsistent samples in this list.",
            "So therefore we can approximate relevance by consistency and therefore in order to rank this list, we're going to rank by visual consistency.",
            "So moron."
        ],
        [
            "After this slide, so this is how we represent our videos.",
            "So we use state of the art approach on realistic videos which is a bag of spatial, temporal, visual words.",
            "So very shortly we detect spatial temporal interest points using the Harris 3D operator.",
            "Alex has just talked about.",
            "Then we described those special temporal keyboards using histogram of oriented gradients and we compute the bag of features representation using a visual Dictionary of 1000 words.",
            "And visual similarity.",
            "We use state of the art chisquare kernel.",
            "So."
        ],
        [
            "In order to use the week in order to use to rank the samples, we first investigated unsupervised methods and then before using our proposed week, weekly supervised approach.",
            "So for us."
        ],
        [
            "Revised estimation of an inconsistent score that will be used to rank the samples.",
            "We propose to use outlier detection methods.",
            "So why is that?",
            "Simply because outliers can be defined as samples that deviate markedly from others, or more Interestingly, as samples are inconsistent with the remainder of the data.",
            "So we see that Outlier Ness is a very good inconsistent score.",
            "So we investigate 2 baseline approaches in order to do so, we investigated distance based approach.",
            "One class SVM support vector machines.",
            "There's an unsupervised protecting machine, and the in consensus score we get from this from this algorithm is a distance from a boundary of normality around most of the data.",
            "We also investigate another approach to compute an inconsistent score that will induce a good ranking.",
            "This is a density based approach.",
            "We searched for dense components and the similarity graph, so this is something that has been used in faces in the news, etc.",
            "And the inconsistent samples are Arden concerned as samples are in sparse regions of the feature space."
        ],
        [
            "So these were the baseline unsupervised methods in order to compute an inconsistent score for each clip in the retrieved list.",
            "Now I'm going to detail our proposed approach, which is ranking with weak supervision.",
            "So we."
        ],
        [
            "I wasn't really satisfied with the unsupervised methods because generally supervised methods.",
            "There are more efficient, right?",
            "But the problem is that they require training data and this is really a problem for videos because manually annotating videos is really a lot more expensive than annotating objects and images.",
            "So we wanted to use supervision, but we didn't want to pay this manually.",
            "To make this painstakingly manually annotation, so we propose to use a kind of weak supervision.",
            "So bye week supervision or imperfekt or bad supervision.",
            "There's no standard term, I mean, annotated training data with uncontrolled quality.",
            "So in our in our case, to be precise, we considered as positive examples all of the retrieved examples.",
            "So therefore we have many false positives.",
            "So actually as many false positives as the errors from the text retrieval process.",
            "As negative examples, which means inconsistent, they should model inconsistent examples.",
            "We simply randomly sampled the whole collection for small clips, and as we have a very large collection, then our false negative rate is very low.",
            "So this week supervision is pretty nice because actually it's automatic so you can handle any action query.",
            "You really don't need to work with the Predator Minton set of actions and label videos for them, so that's nice.",
            "That's what we wanted.",
            "But the problem there is no free lunch, right?",
            "So this supervision is actually might contain errors and informative samples, and in practice it does with fair amount.",
            "So two tests."
        ],
        [
            "How could we use this this week supervision?",
            "We first proposed to try a baseline classification approach, so we classify between the consistent and inconsistent samples.",
            "So in order to do this, we trained binary SVM on the noisy positives and the random negatives finding and hyperplane separating those and the inconsistency score we get from this classifier is simply the distance from the separating hyperplane.",
            "The efficiency of this baseline method is based on regularization and the generalization capabilities offered a new SVM.",
            "Which is the kind of SVM we use."
        ],
        [
            "The problem with this is that when you learn with weak supervision, when you have errors in your training data, then what you get is a weak model.",
            "So the previous approach doesn't take this fact into accounts.",
            "It just hopes that it's robust enough to deal with the errors present.",
            "So we want to actually take into account the fact that we know it's a weak supervision, that there are errors an what we know is that when you learn week supervision, your week model might still be able to correctly decide.",
            "In the easiest cases, meaning it might be able to decide what are the most obvious inconsistent samples.",
            "So in order to benefit from this fact, actually we are inspired by some work and some supervised learning, and the idea is to iteratively Re label an retrain.",
            "So first you learn your week model.",
            "Right, thanks to this assumption, the weak model will be able to detect what are the most obvious inconsistent samples.",
            "Let's say if in the middle of your walking retrieve list you have someone sleeping.",
            "You hope you might be able to detect it.",
            "An then you switch the label of those most obvious inconsistent samples.",
            "You get an improved training data, and then when you retrain you should get an improved model.",
            "You can iterate this process until convergence.",
            "Actually, that's not so simple."
        ],
        [
            "There are many problems with this approach, so we tried it in practice and it didn't work.",
            "So we tried to understand why.",
            "First reason is how would you evaluate what are the most obvious inconsistent samples.",
            "You feel that there are some hidden perimetre or threshold or something behind this.",
            "So what happens if you wrongly relabel your data?",
            "Let's say, oh, this is actually not working sample, so I put it from the positives to the negatives.",
            "But if it's wrong, then you make it pretty hard decision, and it's pretty strong mistake and solution then might drift and you can never never go back to correct solution.",
            "And there also convergence issues with this iterative process.",
            "You might fall into a loop, switching constantly the label.",
            "So in order to solve those problems, we propose to reformulate the problem as a regression one.",
            "So it means that we are going to iteratively learn a regression function that is quantifying inconsistency, and also we're going to softly relabel all of the retrieved samples at each iteration."
        ],
        [
            "So how do we do this?",
            "So this is our proposed method iterative SVR algorithm.",
            "So as you are stands for support vector regression machine, it's the core regulation tool we are using and the iterative retraining of this as you are with weak supervision is depicted in this pseudocode.",
            "First is the initialization step the positives or the retrieved samples and noisy positives are assigned to target value of plus one initially.",
            "The target values of the random negatives are assigned target value minus one.",
            "We learn our as you are our regression function F. On those target values, we normalize the outputs and then we replace, so that's the soft relabelling part.",
            "We replace the target values of the positives by the computed regressed values.",
            "We go back to Step 2 until convergence and the consistency score we get from this algorithm is at the final regressed values.",
            "So I made some."
        ],
        [
            "Parents on the Buffy data set.",
            "Us"
        ],
        [
            "So the action examples we considered were automatically minds from the Buffy transcripts using the previously mentioned text retrieval approach, and we considered 6 action classes, walk, fall, punch, Kick Kiss an get up.",
            "And here in this table you can see a performance comparison of the four methods we investigated.",
            "So the two unsupervised baseline methods, the weakly supervised baseline, and our iterative as your algorithm.",
            "On the last line.",
            "So the performance is an average precision and on the last line you see text, it means that it's the performance of the text retrieval results that were manually evaluated in order to compute those numbers.",
            "What you can notice from this table is actually the best method.",
            "So on five out of six classes and also on average, is are iterative as your method, which is nice.",
            "And you get actually fairly high results.",
            "So 91 average precision for realistic video data, it's pretty pretty good when you it's at the same level as what you get what people get on KTH data set for instance.",
            "Also, what you can notice on this table and what's actually one of the most interesting facts is that the text based retrieval results are always improved by using vision.",
            "So even if you take the unsupervised methods, they will still improve by quite a fair amount, actually 10%.",
            "The text based retrieval results so ranking visually is really useful and ranking by consistency makes also sense and you can see that on average you can gain plus 12.4% an up to approximately 17% for default action."
        ],
        [
            "This barplot actually depicts a comparison.",
            "So, on average, precision is the performance once again between the text results in Blue, the SVR without retraining in yellow and the ITR SVR algorithm in red.",
            "You are without retraining is simply the first iteration of our iterative as you algorithm.",
            "And what is interesting in this figure is the gap between the yellow bar and the red bar.",
            "It's pretty significant gap, especially for the default class and bunch class.",
            "And this means that there is a strong improvement due to iteratively ranking, so it's really worth like this softly, iteratively re labeling processes really worth it.",
            "An on average you gain plus 4.4% between the first iteration in the last iteration of our it."
        ],
        [
            "Purchase your them.",
            "Here are two curves depicting precision at the top end ranks, so precision of the five first resultan first results, etc.",
            "For a kiss and fall action and what you can see very quickly is that you have high precision that low recall, which is nice and also weakly supervised methods and red and blue.",
            "They they consistently outperform the unsupervised ones.",
            "So in a sense it could mean that even a bad teacher is better than no teacher at all.",
            "Here you have the ranking results."
        ],
        [
            "For a walk action using our iterative SDR approach.",
            "So this is number 1.",
            "So actually what's interesting is you see this is real World video data you have.",
            "Like for instance, you don't observe the legs of the people walking, but is still recognized walking action.",
            "You have camera movements.",
            "You have multiple characters.",
            "You have varying lighting conditions.",
            "Background clutter camera movements once again.",
            "You have complex motions.",
            "It's not simply someone passing by.",
            "Viewpoint changes.",
            "Occlusions.",
            "Also, what's interesting is that the action examples they all clearly contain The Walking action, but they still look fairly different, so it's pretty good for a supervised action recognition system because it will allow to."
        ],
        [
            "System to have a good generalization.",
            "So Twitter nutshell.",
            "Our contributions.",
            "First, we provide an automatic approach to mine actions from large real world video collections using both visual consistency and text.",
            "We also have shown that weak supervision is very useful.",
            "It has the same cost as unsupervised methods, so an it's it's better.",
            "So we provided a way to use it efficiently.",
            "This iterative as your algorithm is inexpensive and outperforms the unsupervised methods.",
            "So another thing that's not written here is that the Zetor is your algorithm after the ranking process can be used as a classifier actually.",
            "For future work, we plan to add final textual and visual representations because this is like pretty basic.",
            "What we did here and we also think that's working on joint model of Texan vision.",
            "Might be interesting because here it's only sequentially text and then vision.",
            "And finally, we think that action localization is really crucial, especially on movies and TV series, both in the spatial and temporal domain.",
            "So if you have any questions, feel free to ask them.",
            "If not, you can watch it."
        ],
        [
            "Get up ranking results.",
            "Thank you very much, thanks.",
            "Yeah, so that's that's exactly it.",
            "So if you look at the transcript, actually, transcript is built."
        ],
        [
            "Dialogue lines an between the dialogue lines you have description of the events occurring in them.",
            "So if character performs an action generally which can hope is that there is this verb depicting this action that is present.",
            "So it's very basic approach.",
            "I agree it's the natural language.",
            "Processing is very basic, but still if you watch.",
            "At this table, the last line."
        ],
        [
            "You already see that this simple approach gives OK results an if you go afterwards with this visual ranking process, then you get very good results, like for instance orchis class or they walk class.",
            "So, so we just retrieved the verbs and to retrieve the verbs we used in grammar.",
            "But you could use part of speech tagging or things like this.",
            "No no no no no.",
            "They are textually relevant.",
            "But they are not visually relevant.",
            "They might not be visually run, so that's why we need this ranking visual ranking process after it.",
            "So we're not aiming at having a perfect semantic approach and finding from the transcripts what are the exact examples.",
            "And I think you can do it even because there might be some errors even if you have a perfect natural language processing tool, there might be some errors that cannot be resolved from text like alignment errors or things that happening outside of the of the camera.",
            "Stuff like that so.",
            "Yeah, you can do everything with text even with perfect text, so I have actually some additional slide, so it's not exactly this, but it's so here you see the keyframe of the 1st results."
        ],
        [
            "First ranking results and the first false positive.",
            "Here below you have the rank of those first false positive an actually you can.",
            "So I made some some experiments in order to see what are those false positives.",
            "So there's a full course of confusion at the text level, so there's ambiguities in the words we use, but also some visually ambiguous videos.",
            "There might be multiple events or complex motions, only partial observations, or for instance, like I don't know if you can see it, but this kiss action.",
            "This false negative is actually someone speaking, but saying probably M and like this like.",
            "And it seems like he's kissing in midair.",
            "So visually it's very difficult to disambiguate such cases.",
            "And actually, I won't say all the errors are like this, but a great part of it is actually like this."
        ],
        [
            "Not exactly shot."
        ],
        [
            "Also we are.",
            "Yeah, OK, so yeah, that's a good point actually so.",
            "So this is like the first slide.",
            "Yeah, this text from temporal segmentation.",
            "So yeah, the basic idea if you wanted to do a visually driven temporal segmentation of the movies into short sequences, you would consider shots as you're basically temporal unit.",
            "But the problem is that shots do not wise convey meaning.",
            "Like there's this falling action, so I can show you examples later following action might occur on several shots like you have a camera filming the beginning of the falling action and then the camera switches an films the end of the action.",
            "So dividing the clips into shots leads to very partial observations, so we instead considered segmenting the videos by using subtitles as boundaries.",
            "An actually when you use these subtitles at boundaries, the clips you obtain makes more sense.",
            "Exactly, so we take the transcripts.",
            "We take two dialogue lines, mine, etc, so it's fully automatic.",
            "Yeah, so so.",
            "So first there is an interesting movies by themselves, right?",
            "So people are always discussing with someone from BBC they are interested in actually like being explained to being able to explain what's happening in movies so movies.",
            "So I had a review from from a few of few months ago from someone saying I'm movies are interesting.",
            "That's not true for industry industry people are interested in this.",
            "But I agree it will be interesting to see how we could transfer because movies are high quality.",
            "They have textual description extra so it's great to learn on them.",
            "It would be interesting to transfer to video types where you don't have such information, so it's real world in the sense that it's unconstrained compared to CDH.",
            "So I agree it's not like we didn't reach the end in terms of realistic data, but it's like still the first step compared to weitsman or or CDH data sets, so it's more realistic than KTH.",
            "Maybe that's more correct."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good morning, my name is Adrian get and I'm a PhD student of the year.",
                    "label": 0
                },
                {
                    "sent": "Team of the INRIA Grenoble Research Center.",
                    "label": 1
                },
                {
                    "sent": "Like Alex and I'm actually honored to be the last talk of this conference.",
                    "label": 0
                },
                {
                    "sent": "So I'm here to present my paper entitled mining visual actions from movies.",
                    "label": 1
                },
                {
                    "sent": "And this is joint work with marching matherly",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can Cordia schmitz?",
                    "label": 0
                },
                {
                    "sent": "In this paper, we're interested in visual human actions, so we're interested in human actions because they are major visual events in movies news.",
                    "label": 1
                },
                {
                    "sent": "Many other video types, and we're also interested in real world videos.",
                    "label": 0
                },
                {
                    "sent": "So it means we have to face complex emerging conditions, large interclass variations visually I'll defined concepts and so on.",
                    "label": 0
                },
                {
                    "sent": "And in order to help the analysis of large amounts of realistic videos, we would like to, for instance, discover what actions are performed or we would like to collect action samples for action recognition systems.",
                    "label": 1
                },
                {
                    "sent": "So in this paper we propose to do this by mining actions from movies by using.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Envision.",
                    "label": 0
                },
                {
                    "sent": "So why movies?",
                    "label": 0
                },
                {
                    "sent": "Simply because there are a large source of high quality, realistic videos.",
                    "label": 1
                },
                {
                    "sent": "So they provide a huge amount really of diversified and representative action examples which are very useful for scene modeling, action, action modeling, etc.",
                    "label": 0
                },
                {
                    "sent": "And what's also nice about movies is that they generally come with precise textual description of the events occurring in the movie, and these are the transcription screenplay.",
                    "label": 0
                },
                {
                    "sent": "So you must be pretty familiar now with this.",
                    "label": 0
                },
                {
                    "sent": "So in this paper we consider the TV series Buffy the Vampire Slayer's data sets.",
                    "label": 0
                },
                {
                    "sent": "Buffy is actually becoming pretty famous and computer vision community right now, so we're interested.",
                    "label": 1
                },
                {
                    "sent": "So we're using the full sets of the 39 DVDs, which amounts to approximately 100 hours of videos or 10,000,000.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's a huge collection.",
                    "label": 0
                },
                {
                    "sent": "So our approach to mine actions from movies using both text and vision consists of four steps.",
                    "label": 1
                },
                {
                    "sent": "First, we synchronize the transcripts with the videos.",
                    "label": 1
                },
                {
                    "sent": "Then we segment the movies.",
                    "label": 1
                },
                {
                    "sent": "The full length movies into short clips.",
                    "label": 0
                },
                {
                    "sent": "We then mine actions from the transcripts and finally there comes the vision.",
                    "label": 0
                },
                {
                    "sent": "We ranked the text retrieval actions by visual relevance, so our main contributions are how we rank the text.",
                    "label": 1
                },
                {
                    "sent": "Mine actions by using visual consistency.",
                    "label": 0
                },
                {
                    "sent": "How we handle a kind of weak supervision that we obtain automatically an we also propose a novel approach to use such a weak supervision.",
                    "label": 0
                },
                {
                    "sent": "This is an iterative re ranking algorithm using regression.",
                    "label": 0
                },
                {
                    "sent": "It's called iterative SCR.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Related work has been done recently on realistic videos, for instance by Koratala TC 08 on temporal segmentation of TV series.",
                    "label": 1
                },
                {
                    "sent": "Also, there has been work SVR 08 by even lapped F An Super 09 by marching marszalek unsupervised action classification.",
                    "label": 0
                },
                {
                    "sent": "This Hollywood two data set and the similar approaches have been investigated in order to build collections of images for specific object classes but also for naming characters and images and videos.",
                    "label": 1
                },
                {
                    "sent": "There's this famous paper by every gamma tile at BMV 06.",
                    "label": 0
                },
                {
                    "sent": "Also using Buffy.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first step in our action mining framework is to extract actions from videos by using textual information.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we start with a text driven temporal segmentation of the full length movies into short clips.",
                    "label": 0
                },
                {
                    "sent": "Several 100 frames, let's say.",
                    "label": 0
                },
                {
                    "sent": "Following every metallic VCO six, we align the transcripts so up there on the right with the videos.",
                    "label": 0
                },
                {
                    "sent": "So here by using subtitles up there.",
                    "label": 1
                },
                {
                    "sent": "So using the synchronized transcripts, it means the transcripts with temporal information.",
                    "label": 0
                },
                {
                    "sent": "We can decompose the videos into short clips.",
                    "label": 1
                },
                {
                    "sent": "A clip is defined as a video between two consecutive subtitles.",
                    "label": 0
                },
                {
                    "sent": "Let's say this one, the blue one and the degree one Ann.",
                    "label": 0
                },
                {
                    "sent": "Thanks to the transcript, there's associated text to each clip.",
                    "label": 0
                },
                {
                    "sent": "It simply did transcript part that is between the corresponding dialogue lines.",
                    "label": 0
                },
                {
                    "sent": "But it's a bit short.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, but here it's written.",
                    "label": 0
                },
                {
                    "sent": "They come out of the classroom, man walk down the hole.",
                    "label": 0
                },
                {
                    "sent": "So it's a precise description of the events occurring in this time range.",
                    "label": 0
                },
                {
                    "sent": "So using this.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Textual information associated to each clips.",
                    "label": 0
                },
                {
                    "sent": "Then we can actually mine actions from text by simply extracting verbs.",
                    "label": 0
                },
                {
                    "sent": "An action examples are then defined as cliffs whose textual description simply contain the corresponding verb.",
                    "label": 1
                },
                {
                    "sent": "Here you see the results on all of the Buffy episodes, so our text mining approach gives approximately 15,000 clips.",
                    "label": 1
                },
                {
                    "sent": "An here you see the most commonly occurring verb on the left, so maybe can't read it's walk and it's actually occurring in more than 750 clips.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So at this stage we have a list of action candidates.",
                    "label": 0
                },
                {
                    "sent": "Let's say for query action walk and this list is examples.",
                    "label": 0
                },
                {
                    "sent": "Are examples retrieved from text.",
                    "label": 0
                },
                {
                    "sent": "So now we're going to see how we rank those action clips by using visual consistency.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the problem with this textual retrieval process I mentioned earlier is that some textually relevant samples are visually irrelevant.",
                    "label": 0
                },
                {
                    "sent": "So our goal is to visually rank this retrieved list by by using visual relevance.",
                    "label": 0
                },
                {
                    "sent": "And in order to do so, we make a simple assumption.",
                    "label": 0
                },
                {
                    "sent": "We assume that the relevant documents in this list, so the documents that actually contain the action of interest.",
                    "label": 0
                },
                {
                    "sent": "They must share some common visual characteristics.",
                    "label": 1
                },
                {
                    "sent": "And the consequences of the simple assumption is actually nice.",
                    "label": 0
                },
                {
                    "sent": "It's that the retrieval errors, which means the sample that we want to deal with.",
                    "label": 1
                },
                {
                    "sent": "There are simply the inconsistent samples in this list.",
                    "label": 0
                },
                {
                    "sent": "So therefore we can approximate relevance by consistency and therefore in order to rank this list, we're going to rank by visual consistency.",
                    "label": 1
                },
                {
                    "sent": "So moron.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After this slide, so this is how we represent our videos.",
                    "label": 0
                },
                {
                    "sent": "So we use state of the art approach on realistic videos which is a bag of spatial, temporal, visual words.",
                    "label": 1
                },
                {
                    "sent": "So very shortly we detect spatial temporal interest points using the Harris 3D operator.",
                    "label": 0
                },
                {
                    "sent": "Alex has just talked about.",
                    "label": 0
                },
                {
                    "sent": "Then we described those special temporal keyboards using histogram of oriented gradients and we compute the bag of features representation using a visual Dictionary of 1000 words.",
                    "label": 0
                },
                {
                    "sent": "And visual similarity.",
                    "label": 0
                },
                {
                    "sent": "We use state of the art chisquare kernel.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In order to use the week in order to use to rank the samples, we first investigated unsupervised methods and then before using our proposed week, weekly supervised approach.",
                    "label": 0
                },
                {
                    "sent": "So for us.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Revised estimation of an inconsistent score that will be used to rank the samples.",
                    "label": 0
                },
                {
                    "sent": "We propose to use outlier detection methods.",
                    "label": 0
                },
                {
                    "sent": "So why is that?",
                    "label": 0
                },
                {
                    "sent": "Simply because outliers can be defined as samples that deviate markedly from others, or more Interestingly, as samples are inconsistent with the remainder of the data.",
                    "label": 1
                },
                {
                    "sent": "So we see that Outlier Ness is a very good inconsistent score.",
                    "label": 0
                },
                {
                    "sent": "So we investigate 2 baseline approaches in order to do so, we investigated distance based approach.",
                    "label": 0
                },
                {
                    "sent": "One class SVM support vector machines.",
                    "label": 1
                },
                {
                    "sent": "There's an unsupervised protecting machine, and the in consensus score we get from this from this algorithm is a distance from a boundary of normality around most of the data.",
                    "label": 0
                },
                {
                    "sent": "We also investigate another approach to compute an inconsistent score that will induce a good ranking.",
                    "label": 0
                },
                {
                    "sent": "This is a density based approach.",
                    "label": 1
                },
                {
                    "sent": "We searched for dense components and the similarity graph, so this is something that has been used in faces in the news, etc.",
                    "label": 0
                },
                {
                    "sent": "And the inconsistent samples are Arden concerned as samples are in sparse regions of the feature space.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these were the baseline unsupervised methods in order to compute an inconsistent score for each clip in the retrieved list.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to detail our proposed approach, which is ranking with weak supervision.",
                    "label": 1
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I wasn't really satisfied with the unsupervised methods because generally supervised methods.",
                    "label": 0
                },
                {
                    "sent": "There are more efficient, right?",
                    "label": 1
                },
                {
                    "sent": "But the problem is that they require training data and this is really a problem for videos because manually annotating videos is really a lot more expensive than annotating objects and images.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to use supervision, but we didn't want to pay this manually.",
                    "label": 0
                },
                {
                    "sent": "To make this painstakingly manually annotation, so we propose to use a kind of weak supervision.",
                    "label": 0
                },
                {
                    "sent": "So bye week supervision or imperfekt or bad supervision.",
                    "label": 0
                },
                {
                    "sent": "There's no standard term, I mean, annotated training data with uncontrolled quality.",
                    "label": 1
                },
                {
                    "sent": "So in our in our case, to be precise, we considered as positive examples all of the retrieved examples.",
                    "label": 0
                },
                {
                    "sent": "So therefore we have many false positives.",
                    "label": 0
                },
                {
                    "sent": "So actually as many false positives as the errors from the text retrieval process.",
                    "label": 0
                },
                {
                    "sent": "As negative examples, which means inconsistent, they should model inconsistent examples.",
                    "label": 0
                },
                {
                    "sent": "We simply randomly sampled the whole collection for small clips, and as we have a very large collection, then our false negative rate is very low.",
                    "label": 0
                },
                {
                    "sent": "So this week supervision is pretty nice because actually it's automatic so you can handle any action query.",
                    "label": 0
                },
                {
                    "sent": "You really don't need to work with the Predator Minton set of actions and label videos for them, so that's nice.",
                    "label": 0
                },
                {
                    "sent": "That's what we wanted.",
                    "label": 0
                },
                {
                    "sent": "But the problem there is no free lunch, right?",
                    "label": 0
                },
                {
                    "sent": "So this supervision is actually might contain errors and informative samples, and in practice it does with fair amount.",
                    "label": 0
                },
                {
                    "sent": "So two tests.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How could we use this this week supervision?",
                    "label": 0
                },
                {
                    "sent": "We first proposed to try a baseline classification approach, so we classify between the consistent and inconsistent samples.",
                    "label": 0
                },
                {
                    "sent": "So in order to do this, we trained binary SVM on the noisy positives and the random negatives finding and hyperplane separating those and the inconsistency score we get from this classifier is simply the distance from the separating hyperplane.",
                    "label": 0
                },
                {
                    "sent": "The efficiency of this baseline method is based on regularization and the generalization capabilities offered a new SVM.",
                    "label": 0
                },
                {
                    "sent": "Which is the kind of SVM we use.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem with this is that when you learn with weak supervision, when you have errors in your training data, then what you get is a weak model.",
                    "label": 0
                },
                {
                    "sent": "So the previous approach doesn't take this fact into accounts.",
                    "label": 0
                },
                {
                    "sent": "It just hopes that it's robust enough to deal with the errors present.",
                    "label": 0
                },
                {
                    "sent": "So we want to actually take into account the fact that we know it's a weak supervision, that there are errors an what we know is that when you learn week supervision, your week model might still be able to correctly decide.",
                    "label": 0
                },
                {
                    "sent": "In the easiest cases, meaning it might be able to decide what are the most obvious inconsistent samples.",
                    "label": 1
                },
                {
                    "sent": "So in order to benefit from this fact, actually we are inspired by some work and some supervised learning, and the idea is to iteratively Re label an retrain.",
                    "label": 0
                },
                {
                    "sent": "So first you learn your week model.",
                    "label": 0
                },
                {
                    "sent": "Right, thanks to this assumption, the weak model will be able to detect what are the most obvious inconsistent samples.",
                    "label": 0
                },
                {
                    "sent": "Let's say if in the middle of your walking retrieve list you have someone sleeping.",
                    "label": 0
                },
                {
                    "sent": "You hope you might be able to detect it.",
                    "label": 0
                },
                {
                    "sent": "An then you switch the label of those most obvious inconsistent samples.",
                    "label": 0
                },
                {
                    "sent": "You get an improved training data, and then when you retrain you should get an improved model.",
                    "label": 0
                },
                {
                    "sent": "You can iterate this process until convergence.",
                    "label": 0
                },
                {
                    "sent": "Actually, that's not so simple.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are many problems with this approach, so we tried it in practice and it didn't work.",
                    "label": 0
                },
                {
                    "sent": "So we tried to understand why.",
                    "label": 0
                },
                {
                    "sent": "First reason is how would you evaluate what are the most obvious inconsistent samples.",
                    "label": 1
                },
                {
                    "sent": "You feel that there are some hidden perimetre or threshold or something behind this.",
                    "label": 0
                },
                {
                    "sent": "So what happens if you wrongly relabel your data?",
                    "label": 0
                },
                {
                    "sent": "Let's say, oh, this is actually not working sample, so I put it from the positives to the negatives.",
                    "label": 0
                },
                {
                    "sent": "But if it's wrong, then you make it pretty hard decision, and it's pretty strong mistake and solution then might drift and you can never never go back to correct solution.",
                    "label": 0
                },
                {
                    "sent": "And there also convergence issues with this iterative process.",
                    "label": 0
                },
                {
                    "sent": "You might fall into a loop, switching constantly the label.",
                    "label": 0
                },
                {
                    "sent": "So in order to solve those problems, we propose to reformulate the problem as a regression one.",
                    "label": 0
                },
                {
                    "sent": "So it means that we are going to iteratively learn a regression function that is quantifying inconsistency, and also we're going to softly relabel all of the retrieved samples at each iteration.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we do this?",
                    "label": 0
                },
                {
                    "sent": "So this is our proposed method iterative SVR algorithm.",
                    "label": 0
                },
                {
                    "sent": "So as you are stands for support vector regression machine, it's the core regulation tool we are using and the iterative retraining of this as you are with weak supervision is depicted in this pseudocode.",
                    "label": 1
                },
                {
                    "sent": "First is the initialization step the positives or the retrieved samples and noisy positives are assigned to target value of plus one initially.",
                    "label": 0
                },
                {
                    "sent": "The target values of the random negatives are assigned target value minus one.",
                    "label": 0
                },
                {
                    "sent": "We learn our as you are our regression function F. On those target values, we normalize the outputs and then we replace, so that's the soft relabelling part.",
                    "label": 0
                },
                {
                    "sent": "We replace the target values of the positives by the computed regressed values.",
                    "label": 0
                },
                {
                    "sent": "We go back to Step 2 until convergence and the consistency score we get from this algorithm is at the final regressed values.",
                    "label": 1
                },
                {
                    "sent": "So I made some.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parents on the Buffy data set.",
                    "label": 0
                },
                {
                    "sent": "Us",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the action examples we considered were automatically minds from the Buffy transcripts using the previously mentioned text retrieval approach, and we considered 6 action classes, walk, fall, punch, Kick Kiss an get up.",
                    "label": 1
                },
                {
                    "sent": "And here in this table you can see a performance comparison of the four methods we investigated.",
                    "label": 0
                },
                {
                    "sent": "So the two unsupervised baseline methods, the weakly supervised baseline, and our iterative as your algorithm.",
                    "label": 0
                },
                {
                    "sent": "On the last line.",
                    "label": 0
                },
                {
                    "sent": "So the performance is an average precision and on the last line you see text, it means that it's the performance of the text retrieval results that were manually evaluated in order to compute those numbers.",
                    "label": 0
                },
                {
                    "sent": "What you can notice from this table is actually the best method.",
                    "label": 0
                },
                {
                    "sent": "So on five out of six classes and also on average, is are iterative as your method, which is nice.",
                    "label": 0
                },
                {
                    "sent": "And you get actually fairly high results.",
                    "label": 0
                },
                {
                    "sent": "So 91 average precision for realistic video data, it's pretty pretty good when you it's at the same level as what you get what people get on KTH data set for instance.",
                    "label": 0
                },
                {
                    "sent": "Also, what you can notice on this table and what's actually one of the most interesting facts is that the text based retrieval results are always improved by using vision.",
                    "label": 0
                },
                {
                    "sent": "So even if you take the unsupervised methods, they will still improve by quite a fair amount, actually 10%.",
                    "label": 0
                },
                {
                    "sent": "The text based retrieval results so ranking visually is really useful and ranking by consistency makes also sense and you can see that on average you can gain plus 12.4% an up to approximately 17% for default action.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This barplot actually depicts a comparison.",
                    "label": 0
                },
                {
                    "sent": "So, on average, precision is the performance once again between the text results in Blue, the SVR without retraining in yellow and the ITR SVR algorithm in red.",
                    "label": 1
                },
                {
                    "sent": "You are without retraining is simply the first iteration of our iterative as you algorithm.",
                    "label": 0
                },
                {
                    "sent": "And what is interesting in this figure is the gap between the yellow bar and the red bar.",
                    "label": 0
                },
                {
                    "sent": "It's pretty significant gap, especially for the default class and bunch class.",
                    "label": 0
                },
                {
                    "sent": "And this means that there is a strong improvement due to iteratively ranking, so it's really worth like this softly, iteratively re labeling processes really worth it.",
                    "label": 1
                },
                {
                    "sent": "An on average you gain plus 4.4% between the first iteration in the last iteration of our it.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Purchase your them.",
                    "label": 0
                },
                {
                    "sent": "Here are two curves depicting precision at the top end ranks, so precision of the five first resultan first results, etc.",
                    "label": 1
                },
                {
                    "sent": "For a kiss and fall action and what you can see very quickly is that you have high precision that low recall, which is nice and also weakly supervised methods and red and blue.",
                    "label": 0
                },
                {
                    "sent": "They they consistently outperform the unsupervised ones.",
                    "label": 0
                },
                {
                    "sent": "So in a sense it could mean that even a bad teacher is better than no teacher at all.",
                    "label": 0
                },
                {
                    "sent": "Here you have the ranking results.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For a walk action using our iterative SDR approach.",
                    "label": 0
                },
                {
                    "sent": "So this is number 1.",
                    "label": 0
                },
                {
                    "sent": "So actually what's interesting is you see this is real World video data you have.",
                    "label": 0
                },
                {
                    "sent": "Like for instance, you don't observe the legs of the people walking, but is still recognized walking action.",
                    "label": 0
                },
                {
                    "sent": "You have camera movements.",
                    "label": 0
                },
                {
                    "sent": "You have multiple characters.",
                    "label": 0
                },
                {
                    "sent": "You have varying lighting conditions.",
                    "label": 0
                },
                {
                    "sent": "Background clutter camera movements once again.",
                    "label": 0
                },
                {
                    "sent": "You have complex motions.",
                    "label": 0
                },
                {
                    "sent": "It's not simply someone passing by.",
                    "label": 0
                },
                {
                    "sent": "Viewpoint changes.",
                    "label": 0
                },
                {
                    "sent": "Occlusions.",
                    "label": 0
                },
                {
                    "sent": "Also, what's interesting is that the action examples they all clearly contain The Walking action, but they still look fairly different, so it's pretty good for a supervised action recognition system because it will allow to.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "System to have a good generalization.",
                    "label": 0
                },
                {
                    "sent": "So Twitter nutshell.",
                    "label": 0
                },
                {
                    "sent": "Our contributions.",
                    "label": 0
                },
                {
                    "sent": "First, we provide an automatic approach to mine actions from large real world video collections using both visual consistency and text.",
                    "label": 1
                },
                {
                    "sent": "We also have shown that weak supervision is very useful.",
                    "label": 0
                },
                {
                    "sent": "It has the same cost as unsupervised methods, so an it's it's better.",
                    "label": 0
                },
                {
                    "sent": "So we provided a way to use it efficiently.",
                    "label": 0
                },
                {
                    "sent": "This iterative as your algorithm is inexpensive and outperforms the unsupervised methods.",
                    "label": 0
                },
                {
                    "sent": "So another thing that's not written here is that the Zetor is your algorithm after the ranking process can be used as a classifier actually.",
                    "label": 1
                },
                {
                    "sent": "For future work, we plan to add final textual and visual representations because this is like pretty basic.",
                    "label": 0
                },
                {
                    "sent": "What we did here and we also think that's working on joint model of Texan vision.",
                    "label": 0
                },
                {
                    "sent": "Might be interesting because here it's only sequentially text and then vision.",
                    "label": 0
                },
                {
                    "sent": "And finally, we think that action localization is really crucial, especially on movies and TV series, both in the spatial and temporal domain.",
                    "label": 0
                },
                {
                    "sent": "So if you have any questions, feel free to ask them.",
                    "label": 0
                },
                {
                    "sent": "If not, you can watch it.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Get up ranking results.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much, thanks.",
                    "label": 1
                },
                {
                    "sent": "Yeah, so that's that's exactly it.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the transcript, actually, transcript is built.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dialogue lines an between the dialogue lines you have description of the events occurring in them.",
                    "label": 0
                },
                {
                    "sent": "So if character performs an action generally which can hope is that there is this verb depicting this action that is present.",
                    "label": 0
                },
                {
                    "sent": "So it's very basic approach.",
                    "label": 0
                },
                {
                    "sent": "I agree it's the natural language.",
                    "label": 0
                },
                {
                    "sent": "Processing is very basic, but still if you watch.",
                    "label": 0
                },
                {
                    "sent": "At this table, the last line.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You already see that this simple approach gives OK results an if you go afterwards with this visual ranking process, then you get very good results, like for instance orchis class or they walk class.",
                    "label": 0
                },
                {
                    "sent": "So, so we just retrieved the verbs and to retrieve the verbs we used in grammar.",
                    "label": 0
                },
                {
                    "sent": "But you could use part of speech tagging or things like this.",
                    "label": 0
                },
                {
                    "sent": "No no no no no.",
                    "label": 0
                },
                {
                    "sent": "They are textually relevant.",
                    "label": 0
                },
                {
                    "sent": "But they are not visually relevant.",
                    "label": 0
                },
                {
                    "sent": "They might not be visually run, so that's why we need this ranking visual ranking process after it.",
                    "label": 0
                },
                {
                    "sent": "So we're not aiming at having a perfect semantic approach and finding from the transcripts what are the exact examples.",
                    "label": 0
                },
                {
                    "sent": "And I think you can do it even because there might be some errors even if you have a perfect natural language processing tool, there might be some errors that cannot be resolved from text like alignment errors or things that happening outside of the of the camera.",
                    "label": 0
                },
                {
                    "sent": "Stuff like that so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you can do everything with text even with perfect text, so I have actually some additional slide, so it's not exactly this, but it's so here you see the keyframe of the 1st results.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First ranking results and the first false positive.",
                    "label": 1
                },
                {
                    "sent": "Here below you have the rank of those first false positive an actually you can.",
                    "label": 0
                },
                {
                    "sent": "So I made some some experiments in order to see what are those false positives.",
                    "label": 0
                },
                {
                    "sent": "So there's a full course of confusion at the text level, so there's ambiguities in the words we use, but also some visually ambiguous videos.",
                    "label": 1
                },
                {
                    "sent": "There might be multiple events or complex motions, only partial observations, or for instance, like I don't know if you can see it, but this kiss action.",
                    "label": 1
                },
                {
                    "sent": "This false negative is actually someone speaking, but saying probably M and like this like.",
                    "label": 0
                },
                {
                    "sent": "And it seems like he's kissing in midair.",
                    "label": 0
                },
                {
                    "sent": "So visually it's very difficult to disambiguate such cases.",
                    "label": 0
                },
                {
                    "sent": "And actually, I won't say all the errors are like this, but a great part of it is actually like this.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not exactly shot.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also we are.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so yeah, that's a good point actually so.",
                    "label": 0
                },
                {
                    "sent": "So this is like the first slide.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this text from temporal segmentation.",
                    "label": 0
                },
                {
                    "sent": "So yeah, the basic idea if you wanted to do a visually driven temporal segmentation of the movies into short sequences, you would consider shots as you're basically temporal unit.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that shots do not wise convey meaning.",
                    "label": 0
                },
                {
                    "sent": "Like there's this falling action, so I can show you examples later following action might occur on several shots like you have a camera filming the beginning of the falling action and then the camera switches an films the end of the action.",
                    "label": 0
                },
                {
                    "sent": "So dividing the clips into shots leads to very partial observations, so we instead considered segmenting the videos by using subtitles as boundaries.",
                    "label": 0
                },
                {
                    "sent": "An actually when you use these subtitles at boundaries, the clips you obtain makes more sense.",
                    "label": 0
                },
                {
                    "sent": "Exactly, so we take the transcripts.",
                    "label": 0
                },
                {
                    "sent": "We take two dialogue lines, mine, etc, so it's fully automatic.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so.",
                    "label": 0
                },
                {
                    "sent": "So first there is an interesting movies by themselves, right?",
                    "label": 0
                },
                {
                    "sent": "So people are always discussing with someone from BBC they are interested in actually like being explained to being able to explain what's happening in movies so movies.",
                    "label": 0
                },
                {
                    "sent": "So I had a review from from a few of few months ago from someone saying I'm movies are interesting.",
                    "label": 0
                },
                {
                    "sent": "That's not true for industry industry people are interested in this.",
                    "label": 0
                },
                {
                    "sent": "But I agree it will be interesting to see how we could transfer because movies are high quality.",
                    "label": 0
                },
                {
                    "sent": "They have textual description extra so it's great to learn on them.",
                    "label": 0
                },
                {
                    "sent": "It would be interesting to transfer to video types where you don't have such information, so it's real world in the sense that it's unconstrained compared to CDH.",
                    "label": 0
                },
                {
                    "sent": "So I agree it's not like we didn't reach the end in terms of realistic data, but it's like still the first step compared to weitsman or or CDH data sets, so it's more realistic than KTH.",
                    "label": 0
                },
                {
                    "sent": "Maybe that's more correct.",
                    "label": 0
                }
            ]
        }
    }
}