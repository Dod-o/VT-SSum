{
    "id": "6e56fszedzwvlczfkgoiugpglautm2d7",
    "title": "Text Annotation using Background Knowledge",
    "info": {
        "author": [
            "Delia Rusu, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Jan. 30, 2015",
        "recorded": "December 2014",
        "category": [
            "Top->Computer Science->Text Mining"
        ]
    },
    "url": "http://videolectures.net/single_rusu_text_annotation/",
    "segmentation": [
        [
            "The topic of my thesis or title is text notation using background knowledge."
        ],
        [
            "I will start with a very brief introduction.",
            "I will mention the main contributions of the thesis.",
            "And I will summarize the main code."
        ],
        [
            "And so."
        ],
        [
            "Text annotation but um text annotation is very similar to text or entity linking, or you will also find some communities talking about versus disambiguation.",
            "The computational linguistics community.",
            "But what it basically means is identifying the meaning of words given a certain context.",
            "And.",
            "More than that, we would like to identify corresponding concepts and these concepts are defined in background knowledge datasets.",
            "So the talk will be about concepts about background knowledge datasets.",
            "How to choose the background knowledge datasets?",
            "How to identify the concepts and more importantly how to label text with this concept?"
        ],
        [
            "So.",
            "One possibility is to choose linked data as background knowledge.",
            "Um?",
            "Now Link data there a set of principles for publishing and interlinking structured data on the Web and Tim Berners Lee a few years ago, stated.",
            "And since then, alot of datasets have been published using these principles.",
            "And important properties.",
            "That make these making data very valuable for this thesis.",
            "The fact that they enable the text annotation solution which is not tailored to specific a specific type of structured data, so a specific ontology or a specific knowledge base.",
            "In this way we can also annotate concepts which are interlinked due to the nature of link data.",
            "And the Third Point, which is very important, is that we obtain machine readable representations of text at different levels of granularity."
        ],
        [
            "So allow me to exemplify this with the short short sentence.",
            "So if we would have the Slovenia has beautiful mountain, the lakes and we would get quite a few concepts in Word.",
            "Net might be WN and quite a few indie pedia and just one inside for the Word Mountain and similar for Lake.",
            "What we would want to end up with."
        ],
        [
            "Is.",
            "2.",
            "Link the word Mountains with the concept mountain, which is a landmass in Wordnet or the mountain geography.",
            "Topological feature.",
            "Sorry.",
            "Topographical feature in psych or mountain landform.",
            "The Pedia and similar for Lake in the three ontologies or knowledge basis."
        ],
        [
            "Sorry.",
            "More formally, the M of this thesis is to propose, apply, evaluate or generic text annotation framework based on background knowledge datasets which rely on to main properties.",
            "These datasets are part of Link data.",
            "Does having the common characteristics.",
            "And also to have different types of information provided by the background knowledge datasets."
        ],
        [
            "OK.",
            "So the main scientific contributions of the thesis are a number of concepts, relatedness, approaches, and each of these approaches leverage either the concept definitions or the data set structure and also hybrid approach which combines the two.",
            "Then a second contribution is a modular and generic text annotation framework based on these relatedness methods.",
            "And then the third one.",
            "Our number of applications means how can we take Wordnet, Opencyc and pedia and use them to annotate our text.",
            "And.",
            "The the articles which are related to this thesis were published in Applied Ontology Journal.",
            "Then we have another publication and the review for the sorry language resources and evaluation and another seven Journal conference on workshop contributions."
        ],
        [
            "OK, let's let me briefly catch my breath.",
            "So constant relatedness approaches."
        ],
        [
            "As I mentioned, we are looking at three different types of constant relatedness approaches.",
            "One that mainly deals with the definition in the ontologies or knowledge bases which we entitle, extended definition vectors, then another one which is based on the structure which we called the basic concepts and the hybrid approach which combines the two."
        ],
        [
            "So extended definition vectors.",
            "We are using the background vector space model and our approach is a generalization of definition vectors proposed in 2003 and which address 3 main limitations as we identified them.",
            "So one thing is that the concept definitions.",
            "Are augmented with connective concepts, but these concepts they are directly linked.",
            "And you will see in a moment why this is a limitation.",
            "Another problem is that.",
            "All these definitions are treated as being equally important, and the third issue is that, like this, you cannot differentiate between connective concept definitions based on the type.",
            "Is there all treated the same so?"
        ],
        [
            "So coming back to our example, if we again have.",
            "The words, mountains and lakes and you would want to label them with word, net.",
            "And let's say that we picked two concepts which conveniently we picked in this case to be exactly the ones that we.",
            "Would like to annotate with now the method.",
            "Says OK, let's link them to the directly connected concepts which were mounted would be elevation and volcano for example, as the hypernym and hyponym respectively, and similar for lakes, but may be valuable information that would give us additional hints regarding to the annotation would be not necessarily in this first level of.",
            "Connected concepts, but rather further down in the in the taxonomy or further up depending.",
            "So maybe we would like to include another hypernym like geological formation.",
            "And so forth.",
            "And maybe Hypernyms are more useful than hyponyms, so we would want to figure out a way in which we could treat relations based on their type differently.",
            "We could.",
            "Speak different concepts irrespective of how long the path is in the.",
            "In the taxonomy or in the graph in the ontology graph."
        ],
        [
            "So our proposal is to take into account weighted weighted contribution of each concept definition.",
            "So like this we are able to include an arbitrary number of connected concept definitions.",
            "Not all of these concepts will be equally important, and we can also assign weights to different types of relations."
        ],
        [
            "The other relatedness measure that we proposed was, as I said structure based and it was relying.",
            "Integrated concepts pass and you are assigning weights at different layers.",
            "So first of all it was about concept weights.",
            "So these enable us to distinguish between abstract and specific concepts and I will show you what I mean by that.",
            "Then we had the relation weights which basically define the function to aggregate these two edges and concepts, and we also had the concept relatedness measure, which is determined by.",
            "Building a shortest path through the graph, having these weights set."
        ],
        [
            "So I promise that further explanation will come regarding more abstract and more specific concepts.",
            "So again in this example with.",
            "With the Slovenian mountains and lakes.",
            "More abstract concepts would be in this case geological formation, or in the case of Lake thing or body of water, whereas further down in the word net taxonomy you would find very specific concepts like pond, which is a specific kind of Lake.",
            "All volcano is a specific kind amount and."
        ],
        [
            "And finally, the hybrid approach combines these two.",
            "These two methods in order to ideally take the best of both worlds to have the definitions to have the structure of the ontology and to compensate for the.",
            "Things that we don't find using either of the two.",
            "The two approaches."
        ],
        [
            "OK, now moving forward to the text annotation framework.",
            "So."
        ],
        [
            "Of the text annotation framework, we basically have two kinds of input.",
            "On one hand, we have our plaintext and on the other side we have the ontology or knowledge base.",
            "And.",
            "For in the case of text we would have.",
            "Typical preprocessing steps.",
            "So we would have their tokenization part of speech tagging and so on.",
            "Then we would need to identify the concepts which are good candidates for annotating.",
            "Words in text with.",
            "And there afterwards we would need to.",
            "To rank these concepts and the way that we rank the concept is using.",
            "Their relatedness information so aggregating relatedness scores in order to come up for each for each candidate concept with a unique aggregated score and then to choose the best score for the task at hand.",
            "So for example, if we want to see how similar the concepts are or how distant the concepts are, then we would choose accordingly among the candidate ranked concepts."
        ],
        [
            "And the text annotation algorithm uses sliding window approach and we are basically looking through text.",
            "Choosing a context window, we call it and then using the relay relatedness between concepts within that context window in order to identify the scores for the candidate concepts.",
            "So for example, here, let's say that we would have a concept.",
            "W 1 sorry award W one which would we would like to annotate with one of three possible candidate concepts and let's also assume that we would have in the context window of this word W one we would have another 4 words W2 to W5 and each of them will have.",
            "Different number of candidate concepts.",
            "Now I don't know if you see but from W2 to W5 the area is shaded.",
            "That means that all these.",
            "All.",
            "These concepts here belong to the.",
            "Candidate concept window.",
            "So what we would want to do is compute the relatedness score between each of these candidate concepts and any of the concepts in the context window.",
            "After we compute this score, each of these each of these candidate concepts are going to have specific score assigned based on aggregate values of pairwise relatedness chords.",
            "So in Step 2, let's assume that we already picked one of these as the contact.",
            "The concepts to annotate W one.",
            "We proceed with W2 in a similar way, just in this case we don't need to take into account the entire set of concepts that we had before, but rather we discard the ones that we already decided that are not good candidates for annotating WN and.",
            "Keep only the the concept chosen for annotation, and by this we shrink the size.",
            "Of the let's call it search space of our problem.",
            "Similarly in Step 3.",
            "We identified the first concept.",
            "So in Step 2, let's say that we identified the first concept as being the one to annotate W2 it, and in step step three we are going to have now.",
            "Only the concepts marked in blue plus the additional.",
            "Concepts in the window to compute the score.",
            "And finally, in step four, we identify the entire.",
            "The entire notations for this window."
        ],
        [
            "K. As I mentioned, there are three applications, so we're net open Titan DB pedia.",
            "Now we were using different kind of datasets for evaluation.",
            "We were using standard datasets and we were also looking at.",
            "Applying our relatedness measures in a clustering scenario.",
            "I'm just going to show briefly some evaluation results."
        ],
        [
            "So for example, I'm showing epscor measures for word net.",
            "These are constant relatedness scores.",
            "And.",
            "What we had here are the three types of methods or definition, structure and hybrid on three different kinds of datasets and CRG and words in which are standard datasets using the Community and I'm.",
            "I'm also showing the three systems that we compare against.",
            "Now the main point here is that the hybrid approach combining the definition and the structure information has the best score in this case.",
            "Um?",
            "So.",
            "It was it was very useful to have textual information from the definitions as well as the.",
            "Taxonomy structure."
        ],
        [
            "For text annotation, we were looking at different datasets from the Summer Fall Workshop.",
            "And the.",
            "So, given the relatedness scores, and given that we could now aggregate the scores, identify the concept to annotate weed.",
            "We where we plotted different kinds of results so.",
            "With Blue, we plotted averaging, averaging across the relatedness course, or choosing the media or choosing the Max.",
            "And basically what the results show is that if you take into account all the relatedness scores that you obtain for candidate concept, then that is much more relevant than just choosing.",
            "The maximum value.",
            "You can also see that the maximum value is.",
            "Quite unstable becausw.",
            "There's.",
            "First of all, there's quite a bit of noise then as more concepts get added to the window, you have more chances to miss annotations.",
            "But this is not the case with averaging or with choosing the median.",
            "So if you take into account more concepts.",
            "And but nevertheless, look at.",
            "All the scores instead of picking the maximum, you have much better chance of.",
            "Labeling your word with the correct annotation."
        ],
        [
            "Evaluation for opencyc.",
            "So again for concept relating us and again F1 scores.",
            "Here we are only looking at the definition and the structure, and this is be cause opencyc has.",
            "Is designed with a slightly different purpose in mind.",
            "And the definitions they are much harder to interpret.",
            "And using our our technique we got quite low scores.",
            "However, the structure of the ontologies.",
            "Very useful for this task.",
            "So in the absence of definitions or the definitions.",
            "Harder to tackle then the structure is a very good candidate and outperforms similar similar methods."
        ],
        [
            "And finally for DBPR again, we had the same datasets again, F1 scores and again the definition structure and hybrid measure, and similarly toward net hybrid measure, is the one outperforming the others which shows that.",
            "Even if we have different datasets, we have different properties.",
            "They were designed for completely different tasks.",
            "They have completely different types of concepts in there.",
            "We can still obtain good results and outperform.",
            "Other other approaches on the same data."
        ],
        [
            "Um?",
            "Again, for the deep evaluation on the text annotation part.",
            "Here we are looking at quite a few combinations because the period they have.",
            "You can build different types of graphs from DP.",
            "You can look at the entire concept graph.",
            "You can look at.",
            "The graph of.",
            "Of the concepts in the DBPR ontology, you can look at the graph formed by DPR categories.",
            "And here I'm showing results using DPI categories.",
            "I'm using the DPI category graph and the similar toward that.",
            "You see that if you average or take the median of the relatedness course.",
            "This provides you with reliable annotations.",
            "Also, as you increase the window size.",
            "Whereas similar towards the maximum.",
            "Aggregation has similar disadvantages."
        ],
        [
            "So to sum up.",
            "For concept relatedness.",
            "We obtain consistent results across different types of knowledge basis.",
            "This means constant relatedness and text annotation.",
            "Now the best results was as I mentioned using a hybrid approach.",
            "In both cases of word and pedia.",
            "And if you do not have concept definitions.",
            "The structure of the ontology or knowledge base provides useful information that you can use for reliably annotating task text."
        ],
        [
            "For in the case of text annotation, we did not use any additional domain specific information yet.",
            "Our results were compatible with state of the art systems.",
            "And the proposed approaches can be extended to other datasets.",
            "Part of Link data because.",
            "As they shared similar similar structure, it's very easy to integrate.",
            "But these should have similar properties to the ones mentioned before, so word, net DB pedia open site."
        ],
        [
            "So.",
            "To sum up, the three major contributions of the thesis were the concept relatedness approaches, which we're leveraging the definitions, the data set structure, and the hybrid approach, and this was published in the Applied Ontology Journal.",
            "Then, um.",
            "The text annotation framework based on concept relatedness, which was.",
            "Which is under review in the language, resources and evaluation Journal and the applications.",
            "You will find them in all three journals, Applied Ontology, language resources and.",
            "Also, Informatika touches on that plus.",
            "Their conference and workshops papers."
        ],
        [
            "As future work we.",
            "Quite some parts to go.",
            "So we could evaluate exploitation frameworks using smaller datasets which are more domain specific, as were all Wordnet piano per cycle.",
            "Very general datasets.",
            "So for example, we could use music or biology specific ontologies or knowledge basis.",
            "We could also use a combination of datasets published as linked data as input we could take into account interlinking.",
            "Testing the annotation framework or mountain lingered knowledge basis as this is not language specific approach.",
            "And also tests on real world application.",
            "So for example we were particularly looking at event detection and I mentioned here the Workshop paper.",
            "That addresses this particular topic.",
            "So."
        ],
        [
            "Thank you and if you have any questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The topic of my thesis or title is text notation using background knowledge.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will start with a very brief introduction.",
                    "label": 0
                },
                {
                    "sent": "I will mention the main contributions of the thesis.",
                    "label": 0
                },
                {
                    "sent": "And I will summarize the main code.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Text annotation but um text annotation is very similar to text or entity linking, or you will also find some communities talking about versus disambiguation.",
                    "label": 1
                },
                {
                    "sent": "The computational linguistics community.",
                    "label": 0
                },
                {
                    "sent": "But what it basically means is identifying the meaning of words given a certain context.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "More than that, we would like to identify corresponding concepts and these concepts are defined in background knowledge datasets.",
                    "label": 0
                },
                {
                    "sent": "So the talk will be about concepts about background knowledge datasets.",
                    "label": 0
                },
                {
                    "sent": "How to choose the background knowledge datasets?",
                    "label": 0
                },
                {
                    "sent": "How to identify the concepts and more importantly how to label text with this concept?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One possibility is to choose linked data as background knowledge.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Now Link data there a set of principles for publishing and interlinking structured data on the Web and Tim Berners Lee a few years ago, stated.",
                    "label": 1
                },
                {
                    "sent": "And since then, alot of datasets have been published using these principles.",
                    "label": 0
                },
                {
                    "sent": "And important properties.",
                    "label": 0
                },
                {
                    "sent": "That make these making data very valuable for this thesis.",
                    "label": 0
                },
                {
                    "sent": "The fact that they enable the text annotation solution which is not tailored to specific a specific type of structured data, so a specific ontology or a specific knowledge base.",
                    "label": 1
                },
                {
                    "sent": "In this way we can also annotate concepts which are interlinked due to the nature of link data.",
                    "label": 0
                },
                {
                    "sent": "And the Third Point, which is very important, is that we obtain machine readable representations of text at different levels of granularity.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So allow me to exemplify this with the short short sentence.",
                    "label": 0
                },
                {
                    "sent": "So if we would have the Slovenia has beautiful mountain, the lakes and we would get quite a few concepts in Word.",
                    "label": 0
                },
                {
                    "sent": "Net might be WN and quite a few indie pedia and just one inside for the Word Mountain and similar for Lake.",
                    "label": 0
                },
                {
                    "sent": "What we would want to end up with.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "Link the word Mountains with the concept mountain, which is a landmass in Wordnet or the mountain geography.",
                    "label": 0
                },
                {
                    "sent": "Topological feature.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Topographical feature in psych or mountain landform.",
                    "label": 1
                },
                {
                    "sent": "The Pedia and similar for Lake in the three ontologies or knowledge basis.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "More formally, the M of this thesis is to propose, apply, evaluate or generic text annotation framework based on background knowledge datasets which rely on to main properties.",
                    "label": 1
                },
                {
                    "sent": "These datasets are part of Link data.",
                    "label": 0
                },
                {
                    "sent": "Does having the common characteristics.",
                    "label": 1
                },
                {
                    "sent": "And also to have different types of information provided by the background knowledge datasets.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the main scientific contributions of the thesis are a number of concepts, relatedness, approaches, and each of these approaches leverage either the concept definitions or the data set structure and also hybrid approach which combines the two.",
                    "label": 1
                },
                {
                    "sent": "Then a second contribution is a modular and generic text annotation framework based on these relatedness methods.",
                    "label": 1
                },
                {
                    "sent": "And then the third one.",
                    "label": 0
                },
                {
                    "sent": "Our number of applications means how can we take Wordnet, Opencyc and pedia and use them to annotate our text.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "The the articles which are related to this thesis were published in Applied Ontology Journal.",
                    "label": 0
                },
                {
                    "sent": "Then we have another publication and the review for the sorry language resources and evaluation and another seven Journal conference on workshop contributions.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let's let me briefly catch my breath.",
                    "label": 0
                },
                {
                    "sent": "So constant relatedness approaches.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I mentioned, we are looking at three different types of constant relatedness approaches.",
                    "label": 0
                },
                {
                    "sent": "One that mainly deals with the definition in the ontologies or knowledge bases which we entitle, extended definition vectors, then another one which is based on the structure which we called the basic concepts and the hybrid approach which combines the two.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So extended definition vectors.",
                    "label": 0
                },
                {
                    "sent": "We are using the background vector space model and our approach is a generalization of definition vectors proposed in 2003 and which address 3 main limitations as we identified them.",
                    "label": 0
                },
                {
                    "sent": "So one thing is that the concept definitions.",
                    "label": 0
                },
                {
                    "sent": "Are augmented with connective concepts, but these concepts they are directly linked.",
                    "label": 1
                },
                {
                    "sent": "And you will see in a moment why this is a limitation.",
                    "label": 0
                },
                {
                    "sent": "Another problem is that.",
                    "label": 0
                },
                {
                    "sent": "All these definitions are treated as being equally important, and the third issue is that, like this, you cannot differentiate between connective concept definitions based on the type.",
                    "label": 1
                },
                {
                    "sent": "Is there all treated the same so?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So coming back to our example, if we again have.",
                    "label": 0
                },
                {
                    "sent": "The words, mountains and lakes and you would want to label them with word, net.",
                    "label": 0
                },
                {
                    "sent": "And let's say that we picked two concepts which conveniently we picked in this case to be exactly the ones that we.",
                    "label": 0
                },
                {
                    "sent": "Would like to annotate with now the method.",
                    "label": 0
                },
                {
                    "sent": "Says OK, let's link them to the directly connected concepts which were mounted would be elevation and volcano for example, as the hypernym and hyponym respectively, and similar for lakes, but may be valuable information that would give us additional hints regarding to the annotation would be not necessarily in this first level of.",
                    "label": 0
                },
                {
                    "sent": "Connected concepts, but rather further down in the in the taxonomy or further up depending.",
                    "label": 0
                },
                {
                    "sent": "So maybe we would like to include another hypernym like geological formation.",
                    "label": 0
                },
                {
                    "sent": "And so forth.",
                    "label": 0
                },
                {
                    "sent": "And maybe Hypernyms are more useful than hyponyms, so we would want to figure out a way in which we could treat relations based on their type differently.",
                    "label": 0
                },
                {
                    "sent": "We could.",
                    "label": 0
                },
                {
                    "sent": "Speak different concepts irrespective of how long the path is in the.",
                    "label": 0
                },
                {
                    "sent": "In the taxonomy or in the graph in the ontology graph.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our proposal is to take into account weighted weighted contribution of each concept definition.",
                    "label": 1
                },
                {
                    "sent": "So like this we are able to include an arbitrary number of connected concept definitions.",
                    "label": 0
                },
                {
                    "sent": "Not all of these concepts will be equally important, and we can also assign weights to different types of relations.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other relatedness measure that we proposed was, as I said structure based and it was relying.",
                    "label": 0
                },
                {
                    "sent": "Integrated concepts pass and you are assigning weights at different layers.",
                    "label": 0
                },
                {
                    "sent": "So first of all it was about concept weights.",
                    "label": 1
                },
                {
                    "sent": "So these enable us to distinguish between abstract and specific concepts and I will show you what I mean by that.",
                    "label": 1
                },
                {
                    "sent": "Then we had the relation weights which basically define the function to aggregate these two edges and concepts, and we also had the concept relatedness measure, which is determined by.",
                    "label": 0
                },
                {
                    "sent": "Building a shortest path through the graph, having these weights set.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I promise that further explanation will come regarding more abstract and more specific concepts.",
                    "label": 1
                },
                {
                    "sent": "So again in this example with.",
                    "label": 0
                },
                {
                    "sent": "With the Slovenian mountains and lakes.",
                    "label": 1
                },
                {
                    "sent": "More abstract concepts would be in this case geological formation, or in the case of Lake thing or body of water, whereas further down in the word net taxonomy you would find very specific concepts like pond, which is a specific kind of Lake.",
                    "label": 1
                },
                {
                    "sent": "All volcano is a specific kind amount and.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, the hybrid approach combines these two.",
                    "label": 1
                },
                {
                    "sent": "These two methods in order to ideally take the best of both worlds to have the definitions to have the structure of the ontology and to compensate for the.",
                    "label": 1
                },
                {
                    "sent": "Things that we don't find using either of the two.",
                    "label": 0
                },
                {
                    "sent": "The two approaches.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now moving forward to the text annotation framework.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the text annotation framework, we basically have two kinds of input.",
                    "label": 1
                },
                {
                    "sent": "On one hand, we have our plaintext and on the other side we have the ontology or knowledge base.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "For in the case of text we would have.",
                    "label": 0
                },
                {
                    "sent": "Typical preprocessing steps.",
                    "label": 0
                },
                {
                    "sent": "So we would have their tokenization part of speech tagging and so on.",
                    "label": 0
                },
                {
                    "sent": "Then we would need to identify the concepts which are good candidates for annotating.",
                    "label": 0
                },
                {
                    "sent": "Words in text with.",
                    "label": 0
                },
                {
                    "sent": "And there afterwards we would need to.",
                    "label": 0
                },
                {
                    "sent": "To rank these concepts and the way that we rank the concept is using.",
                    "label": 0
                },
                {
                    "sent": "Their relatedness information so aggregating relatedness scores in order to come up for each for each candidate concept with a unique aggregated score and then to choose the best score for the task at hand.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we want to see how similar the concepts are or how distant the concepts are, then we would choose accordingly among the candidate ranked concepts.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the text annotation algorithm uses sliding window approach and we are basically looking through text.",
                    "label": 1
                },
                {
                    "sent": "Choosing a context window, we call it and then using the relay relatedness between concepts within that context window in order to identify the scores for the candidate concepts.",
                    "label": 0
                },
                {
                    "sent": "So for example, here, let's say that we would have a concept.",
                    "label": 0
                },
                {
                    "sent": "W 1 sorry award W one which would we would like to annotate with one of three possible candidate concepts and let's also assume that we would have in the context window of this word W one we would have another 4 words W2 to W5 and each of them will have.",
                    "label": 0
                },
                {
                    "sent": "Different number of candidate concepts.",
                    "label": 0
                },
                {
                    "sent": "Now I don't know if you see but from W2 to W5 the area is shaded.",
                    "label": 0
                },
                {
                    "sent": "That means that all these.",
                    "label": 0
                },
                {
                    "sent": "All.",
                    "label": 0
                },
                {
                    "sent": "These concepts here belong to the.",
                    "label": 0
                },
                {
                    "sent": "Candidate concept window.",
                    "label": 0
                },
                {
                    "sent": "So what we would want to do is compute the relatedness score between each of these candidate concepts and any of the concepts in the context window.",
                    "label": 0
                },
                {
                    "sent": "After we compute this score, each of these each of these candidate concepts are going to have specific score assigned based on aggregate values of pairwise relatedness chords.",
                    "label": 0
                },
                {
                    "sent": "So in Step 2, let's assume that we already picked one of these as the contact.",
                    "label": 0
                },
                {
                    "sent": "The concepts to annotate W one.",
                    "label": 0
                },
                {
                    "sent": "We proceed with W2 in a similar way, just in this case we don't need to take into account the entire set of concepts that we had before, but rather we discard the ones that we already decided that are not good candidates for annotating WN and.",
                    "label": 0
                },
                {
                    "sent": "Keep only the the concept chosen for annotation, and by this we shrink the size.",
                    "label": 0
                },
                {
                    "sent": "Of the let's call it search space of our problem.",
                    "label": 0
                },
                {
                    "sent": "Similarly in Step 3.",
                    "label": 0
                },
                {
                    "sent": "We identified the first concept.",
                    "label": 0
                },
                {
                    "sent": "So in Step 2, let's say that we identified the first concept as being the one to annotate W2 it, and in step step three we are going to have now.",
                    "label": 0
                },
                {
                    "sent": "Only the concepts marked in blue plus the additional.",
                    "label": 0
                },
                {
                    "sent": "Concepts in the window to compute the score.",
                    "label": 0
                },
                {
                    "sent": "And finally, in step four, we identify the entire.",
                    "label": 0
                },
                {
                    "sent": "The entire notations for this window.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "K. As I mentioned, there are three applications, so we're net open Titan DB pedia.",
                    "label": 0
                },
                {
                    "sent": "Now we were using different kind of datasets for evaluation.",
                    "label": 0
                },
                {
                    "sent": "We were using standard datasets and we were also looking at.",
                    "label": 0
                },
                {
                    "sent": "Applying our relatedness measures in a clustering scenario.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to show briefly some evaluation results.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example, I'm showing epscor measures for word net.",
                    "label": 0
                },
                {
                    "sent": "These are constant relatedness scores.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "What we had here are the three types of methods or definition, structure and hybrid on three different kinds of datasets and CRG and words in which are standard datasets using the Community and I'm.",
                    "label": 0
                },
                {
                    "sent": "I'm also showing the three systems that we compare against.",
                    "label": 0
                },
                {
                    "sent": "Now the main point here is that the hybrid approach combining the definition and the structure information has the best score in this case.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It was it was very useful to have textual information from the definitions as well as the.",
                    "label": 0
                },
                {
                    "sent": "Taxonomy structure.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For text annotation, we were looking at different datasets from the Summer Fall Workshop.",
                    "label": 1
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "So, given the relatedness scores, and given that we could now aggregate the scores, identify the concept to annotate weed.",
                    "label": 0
                },
                {
                    "sent": "We where we plotted different kinds of results so.",
                    "label": 0
                },
                {
                    "sent": "With Blue, we plotted averaging, averaging across the relatedness course, or choosing the media or choosing the Max.",
                    "label": 0
                },
                {
                    "sent": "And basically what the results show is that if you take into account all the relatedness scores that you obtain for candidate concept, then that is much more relevant than just choosing.",
                    "label": 0
                },
                {
                    "sent": "The maximum value.",
                    "label": 0
                },
                {
                    "sent": "You can also see that the maximum value is.",
                    "label": 0
                },
                {
                    "sent": "Quite unstable becausw.",
                    "label": 0
                },
                {
                    "sent": "There's.",
                    "label": 0
                },
                {
                    "sent": "First of all, there's quite a bit of noise then as more concepts get added to the window, you have more chances to miss annotations.",
                    "label": 0
                },
                {
                    "sent": "But this is not the case with averaging or with choosing the median.",
                    "label": 0
                },
                {
                    "sent": "So if you take into account more concepts.",
                    "label": 0
                },
                {
                    "sent": "And but nevertheless, look at.",
                    "label": 0
                },
                {
                    "sent": "All the scores instead of picking the maximum, you have much better chance of.",
                    "label": 0
                },
                {
                    "sent": "Labeling your word with the correct annotation.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Evaluation for opencyc.",
                    "label": 0
                },
                {
                    "sent": "So again for concept relating us and again F1 scores.",
                    "label": 0
                },
                {
                    "sent": "Here we are only looking at the definition and the structure, and this is be cause opencyc has.",
                    "label": 0
                },
                {
                    "sent": "Is designed with a slightly different purpose in mind.",
                    "label": 0
                },
                {
                    "sent": "And the definitions they are much harder to interpret.",
                    "label": 0
                },
                {
                    "sent": "And using our our technique we got quite low scores.",
                    "label": 0
                },
                {
                    "sent": "However, the structure of the ontologies.",
                    "label": 0
                },
                {
                    "sent": "Very useful for this task.",
                    "label": 0
                },
                {
                    "sent": "So in the absence of definitions or the definitions.",
                    "label": 0
                },
                {
                    "sent": "Harder to tackle then the structure is a very good candidate and outperforms similar similar methods.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally for DBPR again, we had the same datasets again, F1 scores and again the definition structure and hybrid measure, and similarly toward net hybrid measure, is the one outperforming the others which shows that.",
                    "label": 0
                },
                {
                    "sent": "Even if we have different datasets, we have different properties.",
                    "label": 0
                },
                {
                    "sent": "They were designed for completely different tasks.",
                    "label": 0
                },
                {
                    "sent": "They have completely different types of concepts in there.",
                    "label": 0
                },
                {
                    "sent": "We can still obtain good results and outperform.",
                    "label": 0
                },
                {
                    "sent": "Other other approaches on the same data.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Again, for the deep evaluation on the text annotation part.",
                    "label": 1
                },
                {
                    "sent": "Here we are looking at quite a few combinations because the period they have.",
                    "label": 0
                },
                {
                    "sent": "You can build different types of graphs from DP.",
                    "label": 0
                },
                {
                    "sent": "You can look at the entire concept graph.",
                    "label": 0
                },
                {
                    "sent": "You can look at.",
                    "label": 0
                },
                {
                    "sent": "The graph of.",
                    "label": 0
                },
                {
                    "sent": "Of the concepts in the DBPR ontology, you can look at the graph formed by DPR categories.",
                    "label": 0
                },
                {
                    "sent": "And here I'm showing results using DPI categories.",
                    "label": 0
                },
                {
                    "sent": "I'm using the DPI category graph and the similar toward that.",
                    "label": 0
                },
                {
                    "sent": "You see that if you average or take the median of the relatedness course.",
                    "label": 0
                },
                {
                    "sent": "This provides you with reliable annotations.",
                    "label": 0
                },
                {
                    "sent": "Also, as you increase the window size.",
                    "label": 0
                },
                {
                    "sent": "Whereas similar towards the maximum.",
                    "label": 0
                },
                {
                    "sent": "Aggregation has similar disadvantages.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to sum up.",
                    "label": 0
                },
                {
                    "sent": "For concept relatedness.",
                    "label": 0
                },
                {
                    "sent": "We obtain consistent results across different types of knowledge basis.",
                    "label": 1
                },
                {
                    "sent": "This means constant relatedness and text annotation.",
                    "label": 1
                },
                {
                    "sent": "Now the best results was as I mentioned using a hybrid approach.",
                    "label": 1
                },
                {
                    "sent": "In both cases of word and pedia.",
                    "label": 0
                },
                {
                    "sent": "And if you do not have concept definitions.",
                    "label": 0
                },
                {
                    "sent": "The structure of the ontology or knowledge base provides useful information that you can use for reliably annotating task text.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For in the case of text annotation, we did not use any additional domain specific information yet.",
                    "label": 0
                },
                {
                    "sent": "Our results were compatible with state of the art systems.",
                    "label": 0
                },
                {
                    "sent": "And the proposed approaches can be extended to other datasets.",
                    "label": 1
                },
                {
                    "sent": "Part of Link data because.",
                    "label": 0
                },
                {
                    "sent": "As they shared similar similar structure, it's very easy to integrate.",
                    "label": 0
                },
                {
                    "sent": "But these should have similar properties to the ones mentioned before, so word, net DB pedia open site.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "To sum up, the three major contributions of the thesis were the concept relatedness approaches, which we're leveraging the definitions, the data set structure, and the hybrid approach, and this was published in the Applied Ontology Journal.",
                    "label": 1
                },
                {
                    "sent": "Then, um.",
                    "label": 1
                },
                {
                    "sent": "The text annotation framework based on concept relatedness, which was.",
                    "label": 0
                },
                {
                    "sent": "Which is under review in the language, resources and evaluation Journal and the applications.",
                    "label": 0
                },
                {
                    "sent": "You will find them in all three journals, Applied Ontology, language resources and.",
                    "label": 0
                },
                {
                    "sent": "Also, Informatika touches on that plus.",
                    "label": 0
                },
                {
                    "sent": "Their conference and workshops papers.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As future work we.",
                    "label": 0
                },
                {
                    "sent": "Quite some parts to go.",
                    "label": 0
                },
                {
                    "sent": "So we could evaluate exploitation frameworks using smaller datasets which are more domain specific, as were all Wordnet piano per cycle.",
                    "label": 0
                },
                {
                    "sent": "Very general datasets.",
                    "label": 0
                },
                {
                    "sent": "So for example, we could use music or biology specific ontologies or knowledge basis.",
                    "label": 1
                },
                {
                    "sent": "We could also use a combination of datasets published as linked data as input we could take into account interlinking.",
                    "label": 1
                },
                {
                    "sent": "Testing the annotation framework or mountain lingered knowledge basis as this is not language specific approach.",
                    "label": 0
                },
                {
                    "sent": "And also tests on real world application.",
                    "label": 0
                },
                {
                    "sent": "So for example we were particularly looking at event detection and I mentioned here the Workshop paper.",
                    "label": 0
                },
                {
                    "sent": "That addresses this particular topic.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you and if you have any questions.",
                    "label": 0
                }
            ]
        }
    }
}