{
    "id": "3jnnpfaahxk24yx5ypgbfdrw7dmqf33r",
    "title": "Efficient and Effective Link Analysis with Precomputed SALSA Maps",
    "info": {
        "author": [
            "Marc Najork, Microsoft Research"
        ],
        "published": "Nov. 19, 2008",
        "recorded": "October 2008",
        "category": [
            "Top->Computer Science->Web Mining->Link Analysis"
        ]
    },
    "url": "http://videolectures.net/cikm08_najork_eaela/",
    "segmentation": [
        [
            "The outline of my talk is I'm gonna first tell you what the problem is.",
            "I'm going to give you our experimental framework and some previous results.",
            "Then I'm going to do a review of the salsa algorithm.",
            "I will introduce a new algorithm, CS also, which is an online algorithm, and I'm going to give you 4 different algorithms for computing cells are offline starting with a straw man.",
            "That doesn't work very well, and working up to something which is actually fairly decent.",
            "And then I will also do some breakdowns by query specificity.",
            "And covered it work and conclude."
        ],
        [
            "OK, so the problem we're trying to address is.",
            "Hyperlinks are useful signal in the ranking of search results and of course in the real search engine.",
            "Use it in combination with other things such as textual features and such as traffic on the search engine or traffic in general as obtained by say, toolbars.",
            "And known crew dependent.",
            "I think best ranking algorithm such as cells are have been shown to provide a much better signal than query independent ones such as page rank.",
            "But the problem is that because I query independent, you have to do the work at query time and.",
            "Is that conflict with the fact that most search engines tried to return results in a sub second time frame page rank?",
            "On the other hand, is precomputed and all you have to do at runtime at query time is to look up one scorp result.",
            "And so the question is, can we precompute cells or scores while preserving the signal?",
            "Retaining this"
        ],
        [
            "Launch over page rank.",
            "Oh, experimental framework consists of a large web graph on the order of half a billion crawled pages which induce on the order of 3 billion distinct URLs and 17.7 billion distinct edges, and that is combined.",
            "There's a large test set about 28,000 queries which are assembled from the live search log.",
            "With each associate with each query is a set of results.",
            "Close to 3000 and some small fraction of those results were labeled by human judges on a 6 point scale.",
            "We use stand up performance measures to evaluate the performance of our algorithms.",
            "Mean average precision, mean reciprocal rank and N DCG.",
            "Here in this paper I'm only going to use and ECG, but the other things are covered in the paper.",
            "And we use we use the same data set in the same performance measures in earlier papers at Sigur R 2007, second 2007 for 2007, and the upcoming Wisdom.",
            "So this is all the numbers are compareable among those pay."
        ],
        [
            "OK, so here is a quick review of previous results.",
            "So we when experiments were compared, the effectiveness of page rank versus strong climax, it's algorithms versus doing the simplest thing, possibly 2.",
            "Counting the incoming links to pages, links coming in from other web pages on different domains and salsa.",
            "And then we also compare this against text based performance techspace feature, namely PM 25 F which actually does use anchor text so.",
            "That's a little bit of links being used, and you can see first of all that the.",
            "The scoring function based on textual features.",
            "That's a lot better, but B you can see that salsa in particular does much better than the query independent once, and also does better than hits and the rightmost bar, by the way, is just the random squaring function.",
            "If you toss a coin."
        ],
        [
            "OK, so before I tell you about the algorithms that may introduce some notation.",
            "So we have the whole web graph, which is a graph of the vertex set in edge set, and we eliminate the edges between web pages in the same domain form the edge set.",
            "I'm going to call URLs UV&W.",
            "I know right?",
            "I of weed to denote the set of pages linking to a particular webpage, weaselly in Linkous and avoid all of you to denote the pages that you links to.",
            "And then I will use the letter R to note the results of the query.",
            "The web page is the URL so that being returned."
        ],
        [
            "Response to query Q. OK, and the other thing I'm going to use is sampling.",
            "So we use two different sampling techniques, uniform random sampling, which is just sounds like an consistent sampling which is unbiased, just like uniform random sampling butts deterministic.",
            "If you sample the same set twice in a row, you will get the same results and Moreover consistent sampling preserves set similarity.",
            "If you have two sets A&B and you compute their drakkar coefficient and then you assemble those sets and compute the Jaccard coefficient of the two sample sets.",
            "That will be an expectation the same, and that turns out to be very, very powerful, and lots of the."
        ],
        [
            "Man's OK.",
            "So the size that goes in, which was invented by by running rampant rumor and Bacon 2000, takes us input a web graph.",
            "The whole web and result set to a query and reforms out of this.",
            "A neighborhood graph consisting of the resultset and web pages at this since 1.",
            "To this result, set one hop away in the web graph, but because some pages might have millions, millions of incoming links, they suggested to take a uniform random sample of the in linkers.",
            "If there is more than a certain special and then the neighborhood edge set is just the set of edges that is induced by projecting those sets those vertices in the base set onto the full web graph."
        ],
        [
            "And then what cells are computes on that is it forms two matrices inverse in degree matrix, which is for it's a matrix with dimensionality is the set of vertices in the debates adverted systems are basic vertices and if there is an edge in the neighborhood said it takes one of the in degree of the destination vertex.",
            "And zero otherwise, and the inverse outdegree matrix is defined very similarly if there is an edge in the neighborhood edge set, it takes one of the out degree of the source vertex and then you multiply together the transpose of the Indus River matrix Times matrix and compute the first principle eigenvector and dentist."
        ],
        [
            "It's also sports.",
            "Running a stone operation, we can also view it as a random walk over graph for every transition.",
            "This random walk consists of taking one step backward in the link Rev and then take another step forward.",
            "Just repeat, repeat, repeat and the stationary probability distribution is a probability at any given vertex at some point in time."
        ],
        [
            "OK, I'm going to tell you a very slight modification.",
            "What if we replace?",
            "The uniform random sampling part of sales are by consistent sampling.",
            "And what if we also sample outgoing adjust as opposed to just the incoming ones?",
            "So now we have an algorithm is 2 free sampling parameters and we can tune it to find the best settings."
        ],
        [
            "An amazing enough this algorithm does.",
            "Very very well for very low sampling values.",
            "If you sample just two in linkers and just one out linker then we get an NDC G at 12:50 point, 0.182 which is a lot more than it was for uniform random.",
            "So so just so .158.",
            "I'm not gonna tell you more about why that is, but there is a paper coming up at the next Wisdom conference that goes into."
        ],
        [
            "Tails.",
            "I bought this effect.",
            "It's OK now back up.",
            "All of this has to be done in create time, and that's unfortunately 'cause it takes a lot of time.",
            "What if we could move this opposition offline?",
            "There's two things we could do.",
            "We could try to compute salsa, taking the whole web graph as our result set.",
            "That's one extreme.",
            "We're not going to do that.",
            "I'll be able to say, well, let's just assume that we compute salsa and pretend that every single vertex is its own data result set and then computes ulcer on the neighborhood graph of that Singleton result.",
            "Well."
        ],
        [
            "Let's see how this works.",
            "So astroman approaches to do exactly, but it just said take a single result set, one for every vertex in the web graph, compute cells on it, and save the score.",
            "The cells or score of this one without it.",
            "And then online we look up those scores and."
        ],
        [
            "He was in for scoring.",
            "And it turns out that doesn't work very well at all when you can see here, we get the highest value for sampling 20 in linkers, and no out linkers.",
            "And this is a lot worse in Page rank.",
            "That's disappointing.",
            "But well, maybe there is something to be gained if we explore the cells or scores that we computed for other vertices in the base set of this."
        ],
        [
            "Single result, so now we have a modified algorithm where we.",
            "Compute for everybody in the web graph, not just a single score, but instead of score map that contains its score in the score of all the neighboring vertices that happened to be assembled into the base set.",
            "So at in the offline phase, we store a score map for every vertex on the web and in the online phase we just.",
            "Set up all the scores for all the vertices in the result set."
        ],
        [
            "OK. And you can see that this algorithm does.",
            "Better than page rank.",
            "Certainly Patrick was I think, 0.9 two or so.",
            "And you see, there's a 0.13.",
            "97 so.",
            "What we need to do here is we need 4 to retain.",
            "A score for every vertex in the neighborhood graph, and if we sample 5 in linkers and 10 out Linkous then we have to store 15 scores for.",
            "Parizade well, let's see if we can do."
        ],
        [
            "Any better, so the next refinement is that the sample that we go further out in the web graph instead of just sampling the in lingers in the out lingers we sample.",
            "Also the out linger some of the out lingers of the Enlink, as in some of the in lingers of the sample out linkers.",
            "So if we stretch this metaphor of parents and children, the web graph, this would be the siblings and the mates.",
            "And so now this algorithm is 4 free parameters."
        ],
        [
            "And what happens when we try to tune them?",
            "We see that we reach a maximum value.",
            "Sampling no in Linkous at all, taking all the out linkers.",
            "Taking none of the mates.",
            "Said word taking.",
            "None of the siblings and taking 75 of the meds.",
            "And you can see that the performance of this algorithm tops out at 0.157, which is not as good as the online sales are.",
            "That middle squared isn't the problem is, that is the space cost this huge.",
            "So if you assume that the average or degree on the web is about 100 links, leaving each web page, which is a fairly accurate number.",
            "Then this would take up 7500 scores for every page in the corpus.",
            "And we need obviously to retain SI ahead of the URL plus score.",
            "So that comes out at 12 bytes for every entry.",
            "So this will be massive."
        ],
        [
            "So.",
            "Well, what if we bind?",
            "If we bought the size list format, well, if we retain only the key higher scores for some value of K. So we take the SSL CERT, two algorithm and we retain only the highest scores.",
            "And note that this might not.",
            "Necessarily include the original seed.",
            "Note that see that there is the base set.",
            "Original Singleton result."
        ],
        [
            "And so this table here gives you the effectiveness for various values of case, and you can see even if we retain as little as two scores were already doing better than any query independent measure like page rank or in degree.",
            "And if it take say, 10 scores, we get pretty close to the value that we would aesthetically, which as we go out towards retaining all the scores."
        ],
        [
            "So here is all this data presented.",
            "One about shot the.",
            "Light green guys are the new offline versions of sales and just for comparison, I throw in this new online version.",
            "Consistent sampling salsa and you can see that the offline versions.",
            "Two, if you don't care about space as good as the original cells are, algorithm as well as usual so awesome.",
            "And if you do care about space, you still get within striking distance.",
            "There will be the middle bar there, although it's not as effective as the.",
            "Then you consistent sampling version."
        ],
        [
            "OK, So what happens if we break things down by query specificity with square specificity?",
            "I mean, if the query is very general or very narrow, one way to quantify this would be by the size of results that in for strange reasons we actually don't have this number.",
            "So what I instead did I summed up the inverse document frequencies of the."
        ],
        [
            "Terms what you can see here is.",
            "That or the link based sinks too particularly well for very general queries.",
            "Low numbers are more general.",
            "The right side high numbers are more specific queries, whereas PM 25FA textural feature does better for medium specific ways.",
            "That shouldn't be very surprising.",
            "'cause if you have more meaningful terms in the query of course about, but use very focused results that but what's encouraging here is that the.",
            "SSL is a sweet version, the one that uses.",
            "Little memory does in particular, in the very general part, as well as the one that uses a lot more memory.",
            "So you really lose very little by moving to the memory constrained version, but again, it's by far not as good as the online version."
        ],
        [
            "OK, just very quick coverage of related work.",
            "The notion of using hyperlinks was introduced by Massimo Sphere, Mercury, and 97.",
            "There's of course the Pagerank algorithm.",
            "Page pin would wanna be be knocked out in 98.",
            "There is the hits algorithm due to John Kleinberg, but the same time sales are by Lamplight Moron introduced in 2000.",
            "We had another paper at last year's workshop on algorithms so that graph and we also tried to precompute salsa scores, but.",
            "Instead of computing the scores, become precomputed sketch of the neighborhood graph.",
            "Combined them at runtime.",
            "And then there's another paper coming forward at the Wisdom conference that tells you about an online version which is very, very fast and a lot more effective."
        ],
        [
            "So at this point I will give you a little bit critique of this work.",
            "So one issue is that the data set isn't publicly available and they had one reviewer for the most recent paper, the Wisdom Paper.",
            "Coming back and saying, well, I mean, this is all very nice.",
            "You clearly have a very big data set here, but.",
            "We can't validate it and so one plan for future workers to repeat.",
            "Those experiments using standard collections.",
            "If you have good ideas about what collections use, please come and see me after."
        ],
        [
            "That's.",
            "Another one is that the data set is fairly old.",
            "The web graph was called in 2002.",
            "Small fraction of the results is judged and the intersection within the graph and the results that it's actually fairly modest.",
            "Again, I mean by doing this on a larger newer data set, maybe can overcome some of those issues.",
            "The third one is here.",
            "We looked only at the effectiveness of isolated features we didn't describe in the paper.",
            "We did look at linear combinations being 25 F and you still get improvement, but improvement is a good deal smaller and so one piece for future work is are there better ways for combining evidence than linear combination?",
            "And then finally well.",
            "Is this actually a good tradeoff between speed and quality?",
            "And I guess you have to be the judge on that depends on the application.",
            "Questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The outline of my talk is I'm gonna first tell you what the problem is.",
                    "label": 0
                },
                {
                    "sent": "I'm going to give you our experimental framework and some previous results.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to do a review of the salsa algorithm.",
                    "label": 0
                },
                {
                    "sent": "I will introduce a new algorithm, CS also, which is an online algorithm, and I'm going to give you 4 different algorithms for computing cells are offline starting with a straw man.",
                    "label": 0
                },
                {
                    "sent": "That doesn't work very well, and working up to something which is actually fairly decent.",
                    "label": 0
                },
                {
                    "sent": "And then I will also do some breakdowns by query specificity.",
                    "label": 0
                },
                {
                    "sent": "And covered it work and conclude.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the problem we're trying to address is.",
                    "label": 0
                },
                {
                    "sent": "Hyperlinks are useful signal in the ranking of search results and of course in the real search engine.",
                    "label": 0
                },
                {
                    "sent": "Use it in combination with other things such as textual features and such as traffic on the search engine or traffic in general as obtained by say, toolbars.",
                    "label": 0
                },
                {
                    "sent": "And known crew dependent.",
                    "label": 0
                },
                {
                    "sent": "I think best ranking algorithm such as cells are have been shown to provide a much better signal than query independent ones such as page rank.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that because I query independent, you have to do the work at query time and.",
                    "label": 0
                },
                {
                    "sent": "Is that conflict with the fact that most search engines tried to return results in a sub second time frame page rank?",
                    "label": 0
                },
                {
                    "sent": "On the other hand, is precomputed and all you have to do at runtime at query time is to look up one scorp result.",
                    "label": 0
                },
                {
                    "sent": "And so the question is, can we precompute cells or scores while preserving the signal?",
                    "label": 0
                },
                {
                    "sent": "Retaining this",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Launch over page rank.",
                    "label": 0
                },
                {
                    "sent": "Oh, experimental framework consists of a large web graph on the order of half a billion crawled pages which induce on the order of 3 billion distinct URLs and 17.7 billion distinct edges, and that is combined.",
                    "label": 0
                },
                {
                    "sent": "There's a large test set about 28,000 queries which are assembled from the live search log.",
                    "label": 0
                },
                {
                    "sent": "With each associate with each query is a set of results.",
                    "label": 0
                },
                {
                    "sent": "Close to 3000 and some small fraction of those results were labeled by human judges on a 6 point scale.",
                    "label": 0
                },
                {
                    "sent": "We use stand up performance measures to evaluate the performance of our algorithms.",
                    "label": 0
                },
                {
                    "sent": "Mean average precision, mean reciprocal rank and N DCG.",
                    "label": 0
                },
                {
                    "sent": "Here in this paper I'm only going to use and ECG, but the other things are covered in the paper.",
                    "label": 0
                },
                {
                    "sent": "And we use we use the same data set in the same performance measures in earlier papers at Sigur R 2007, second 2007 for 2007, and the upcoming Wisdom.",
                    "label": 1
                },
                {
                    "sent": "So this is all the numbers are compareable among those pay.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here is a quick review of previous results.",
                    "label": 0
                },
                {
                    "sent": "So we when experiments were compared, the effectiveness of page rank versus strong climax, it's algorithms versus doing the simplest thing, possibly 2.",
                    "label": 0
                },
                {
                    "sent": "Counting the incoming links to pages, links coming in from other web pages on different domains and salsa.",
                    "label": 0
                },
                {
                    "sent": "And then we also compare this against text based performance techspace feature, namely PM 25 F which actually does use anchor text so.",
                    "label": 0
                },
                {
                    "sent": "That's a little bit of links being used, and you can see first of all that the.",
                    "label": 0
                },
                {
                    "sent": "The scoring function based on textual features.",
                    "label": 0
                },
                {
                    "sent": "That's a lot better, but B you can see that salsa in particular does much better than the query independent once, and also does better than hits and the rightmost bar, by the way, is just the random squaring function.",
                    "label": 0
                },
                {
                    "sent": "If you toss a coin.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so before I tell you about the algorithms that may introduce some notation.",
                    "label": 0
                },
                {
                    "sent": "So we have the whole web graph, which is a graph of the vertex set in edge set, and we eliminate the edges between web pages in the same domain form the edge set.",
                    "label": 0
                },
                {
                    "sent": "I'm going to call URLs UV&W.",
                    "label": 0
                },
                {
                    "sent": "I know right?",
                    "label": 0
                },
                {
                    "sent": "I of weed to denote the set of pages linking to a particular webpage, weaselly in Linkous and avoid all of you to denote the pages that you links to.",
                    "label": 0
                },
                {
                    "sent": "And then I will use the letter R to note the results of the query.",
                    "label": 0
                },
                {
                    "sent": "The web page is the URL so that being returned.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Response to query Q. OK, and the other thing I'm going to use is sampling.",
                    "label": 0
                },
                {
                    "sent": "So we use two different sampling techniques, uniform random sampling, which is just sounds like an consistent sampling which is unbiased, just like uniform random sampling butts deterministic.",
                    "label": 0
                },
                {
                    "sent": "If you sample the same set twice in a row, you will get the same results and Moreover consistent sampling preserves set similarity.",
                    "label": 0
                },
                {
                    "sent": "If you have two sets A&B and you compute their drakkar coefficient and then you assemble those sets and compute the Jaccard coefficient of the two sample sets.",
                    "label": 0
                },
                {
                    "sent": "That will be an expectation the same, and that turns out to be very, very powerful, and lots of the.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Man's OK.",
                    "label": 0
                },
                {
                    "sent": "So the size that goes in, which was invented by by running rampant rumor and Bacon 2000, takes us input a web graph.",
                    "label": 0
                },
                {
                    "sent": "The whole web and result set to a query and reforms out of this.",
                    "label": 0
                },
                {
                    "sent": "A neighborhood graph consisting of the resultset and web pages at this since 1.",
                    "label": 0
                },
                {
                    "sent": "To this result, set one hop away in the web graph, but because some pages might have millions, millions of incoming links, they suggested to take a uniform random sample of the in linkers.",
                    "label": 0
                },
                {
                    "sent": "If there is more than a certain special and then the neighborhood edge set is just the set of edges that is induced by projecting those sets those vertices in the base set onto the full web graph.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then what cells are computes on that is it forms two matrices inverse in degree matrix, which is for it's a matrix with dimensionality is the set of vertices in the debates adverted systems are basic vertices and if there is an edge in the neighborhood said it takes one of the in degree of the destination vertex.",
                    "label": 0
                },
                {
                    "sent": "And zero otherwise, and the inverse outdegree matrix is defined very similarly if there is an edge in the neighborhood edge set, it takes one of the out degree of the source vertex and then you multiply together the transpose of the Indus River matrix Times matrix and compute the first principle eigenvector and dentist.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's also sports.",
                    "label": 0
                },
                {
                    "sent": "Running a stone operation, we can also view it as a random walk over graph for every transition.",
                    "label": 0
                },
                {
                    "sent": "This random walk consists of taking one step backward in the link Rev and then take another step forward.",
                    "label": 0
                },
                {
                    "sent": "Just repeat, repeat, repeat and the stationary probability distribution is a probability at any given vertex at some point in time.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I'm going to tell you a very slight modification.",
                    "label": 0
                },
                {
                    "sent": "What if we replace?",
                    "label": 0
                },
                {
                    "sent": "The uniform random sampling part of sales are by consistent sampling.",
                    "label": 0
                },
                {
                    "sent": "And what if we also sample outgoing adjust as opposed to just the incoming ones?",
                    "label": 0
                },
                {
                    "sent": "So now we have an algorithm is 2 free sampling parameters and we can tune it to find the best settings.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An amazing enough this algorithm does.",
                    "label": 0
                },
                {
                    "sent": "Very very well for very low sampling values.",
                    "label": 0
                },
                {
                    "sent": "If you sample just two in linkers and just one out linker then we get an NDC G at 12:50 point, 0.182 which is a lot more than it was for uniform random.",
                    "label": 0
                },
                {
                    "sent": "So so just so .158.",
                    "label": 0
                },
                {
                    "sent": "I'm not gonna tell you more about why that is, but there is a paper coming up at the next Wisdom conference that goes into.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Tails.",
                    "label": 0
                },
                {
                    "sent": "I bought this effect.",
                    "label": 0
                },
                {
                    "sent": "It's OK now back up.",
                    "label": 0
                },
                {
                    "sent": "All of this has to be done in create time, and that's unfortunately 'cause it takes a lot of time.",
                    "label": 0
                },
                {
                    "sent": "What if we could move this opposition offline?",
                    "label": 0
                },
                {
                    "sent": "There's two things we could do.",
                    "label": 0
                },
                {
                    "sent": "We could try to compute salsa, taking the whole web graph as our result set.",
                    "label": 1
                },
                {
                    "sent": "That's one extreme.",
                    "label": 0
                },
                {
                    "sent": "We're not going to do that.",
                    "label": 0
                },
                {
                    "sent": "I'll be able to say, well, let's just assume that we compute salsa and pretend that every single vertex is its own data result set and then computes ulcer on the neighborhood graph of that Singleton result.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see how this works.",
                    "label": 0
                },
                {
                    "sent": "So astroman approaches to do exactly, but it just said take a single result set, one for every vertex in the web graph, compute cells on it, and save the score.",
                    "label": 0
                },
                {
                    "sent": "The cells or score of this one without it.",
                    "label": 0
                },
                {
                    "sent": "And then online we look up those scores and.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He was in for scoring.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that doesn't work very well at all when you can see here, we get the highest value for sampling 20 in linkers, and no out linkers.",
                    "label": 0
                },
                {
                    "sent": "And this is a lot worse in Page rank.",
                    "label": 0
                },
                {
                    "sent": "That's disappointing.",
                    "label": 0
                },
                {
                    "sent": "But well, maybe there is something to be gained if we explore the cells or scores that we computed for other vertices in the base set of this.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Single result, so now we have a modified algorithm where we.",
                    "label": 0
                },
                {
                    "sent": "Compute for everybody in the web graph, not just a single score, but instead of score map that contains its score in the score of all the neighboring vertices that happened to be assembled into the base set.",
                    "label": 0
                },
                {
                    "sent": "So at in the offline phase, we store a score map for every vertex on the web and in the online phase we just.",
                    "label": 0
                },
                {
                    "sent": "Set up all the scores for all the vertices in the result set.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. And you can see that this algorithm does.",
                    "label": 0
                },
                {
                    "sent": "Better than page rank.",
                    "label": 0
                },
                {
                    "sent": "Certainly Patrick was I think, 0.9 two or so.",
                    "label": 0
                },
                {
                    "sent": "And you see, there's a 0.13.",
                    "label": 0
                },
                {
                    "sent": "97 so.",
                    "label": 0
                },
                {
                    "sent": "What we need to do here is we need 4 to retain.",
                    "label": 0
                },
                {
                    "sent": "A score for every vertex in the neighborhood graph, and if we sample 5 in linkers and 10 out Linkous then we have to store 15 scores for.",
                    "label": 0
                },
                {
                    "sent": "Parizade well, let's see if we can do.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any better, so the next refinement is that the sample that we go further out in the web graph instead of just sampling the in lingers in the out lingers we sample.",
                    "label": 0
                },
                {
                    "sent": "Also the out linger some of the out lingers of the Enlink, as in some of the in lingers of the sample out linkers.",
                    "label": 0
                },
                {
                    "sent": "So if we stretch this metaphor of parents and children, the web graph, this would be the siblings and the mates.",
                    "label": 0
                },
                {
                    "sent": "And so now this algorithm is 4 free parameters.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what happens when we try to tune them?",
                    "label": 0
                },
                {
                    "sent": "We see that we reach a maximum value.",
                    "label": 0
                },
                {
                    "sent": "Sampling no in Linkous at all, taking all the out linkers.",
                    "label": 0
                },
                {
                    "sent": "Taking none of the mates.",
                    "label": 1
                },
                {
                    "sent": "Said word taking.",
                    "label": 0
                },
                {
                    "sent": "None of the siblings and taking 75 of the meds.",
                    "label": 0
                },
                {
                    "sent": "And you can see that the performance of this algorithm tops out at 0.157, which is not as good as the online sales are.",
                    "label": 0
                },
                {
                    "sent": "That middle squared isn't the problem is, that is the space cost this huge.",
                    "label": 0
                },
                {
                    "sent": "So if you assume that the average or degree on the web is about 100 links, leaving each web page, which is a fairly accurate number.",
                    "label": 0
                },
                {
                    "sent": "Then this would take up 7500 scores for every page in the corpus.",
                    "label": 1
                },
                {
                    "sent": "And we need obviously to retain SI ahead of the URL plus score.",
                    "label": 0
                },
                {
                    "sent": "So that comes out at 12 bytes for every entry.",
                    "label": 0
                },
                {
                    "sent": "So this will be massive.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Well, what if we bind?",
                    "label": 0
                },
                {
                    "sent": "If we bought the size list format, well, if we retain only the key higher scores for some value of K. So we take the SSL CERT, two algorithm and we retain only the highest scores.",
                    "label": 0
                },
                {
                    "sent": "And note that this might not.",
                    "label": 0
                },
                {
                    "sent": "Necessarily include the original seed.",
                    "label": 0
                },
                {
                    "sent": "Note that see that there is the base set.",
                    "label": 0
                },
                {
                    "sent": "Original Singleton result.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so this table here gives you the effectiveness for various values of case, and you can see even if we retain as little as two scores were already doing better than any query independent measure like page rank or in degree.",
                    "label": 0
                },
                {
                    "sent": "And if it take say, 10 scores, we get pretty close to the value that we would aesthetically, which as we go out towards retaining all the scores.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is all this data presented.",
                    "label": 0
                },
                {
                    "sent": "One about shot the.",
                    "label": 0
                },
                {
                    "sent": "Light green guys are the new offline versions of sales and just for comparison, I throw in this new online version.",
                    "label": 0
                },
                {
                    "sent": "Consistent sampling salsa and you can see that the offline versions.",
                    "label": 0
                },
                {
                    "sent": "Two, if you don't care about space as good as the original cells are, algorithm as well as usual so awesome.",
                    "label": 0
                },
                {
                    "sent": "And if you do care about space, you still get within striking distance.",
                    "label": 0
                },
                {
                    "sent": "There will be the middle bar there, although it's not as effective as the.",
                    "label": 0
                },
                {
                    "sent": "Then you consistent sampling version.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what happens if we break things down by query specificity with square specificity?",
                    "label": 1
                },
                {
                    "sent": "I mean, if the query is very general or very narrow, one way to quantify this would be by the size of results that in for strange reasons we actually don't have this number.",
                    "label": 0
                },
                {
                    "sent": "So what I instead did I summed up the inverse document frequencies of the.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Terms what you can see here is.",
                    "label": 0
                },
                {
                    "sent": "That or the link based sinks too particularly well for very general queries.",
                    "label": 0
                },
                {
                    "sent": "Low numbers are more general.",
                    "label": 0
                },
                {
                    "sent": "The right side high numbers are more specific queries, whereas PM 25FA textural feature does better for medium specific ways.",
                    "label": 0
                },
                {
                    "sent": "That shouldn't be very surprising.",
                    "label": 0
                },
                {
                    "sent": "'cause if you have more meaningful terms in the query of course about, but use very focused results that but what's encouraging here is that the.",
                    "label": 0
                },
                {
                    "sent": "SSL is a sweet version, the one that uses.",
                    "label": 0
                },
                {
                    "sent": "Little memory does in particular, in the very general part, as well as the one that uses a lot more memory.",
                    "label": 0
                },
                {
                    "sent": "So you really lose very little by moving to the memory constrained version, but again, it's by far not as good as the online version.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, just very quick coverage of related work.",
                    "label": 0
                },
                {
                    "sent": "The notion of using hyperlinks was introduced by Massimo Sphere, Mercury, and 97.",
                    "label": 0
                },
                {
                    "sent": "There's of course the Pagerank algorithm.",
                    "label": 0
                },
                {
                    "sent": "Page pin would wanna be be knocked out in 98.",
                    "label": 0
                },
                {
                    "sent": "There is the hits algorithm due to John Kleinberg, but the same time sales are by Lamplight Moron introduced in 2000.",
                    "label": 0
                },
                {
                    "sent": "We had another paper at last year's workshop on algorithms so that graph and we also tried to precompute salsa scores, but.",
                    "label": 0
                },
                {
                    "sent": "Instead of computing the scores, become precomputed sketch of the neighborhood graph.",
                    "label": 0
                },
                {
                    "sent": "Combined them at runtime.",
                    "label": 0
                },
                {
                    "sent": "And then there's another paper coming forward at the Wisdom conference that tells you about an online version which is very, very fast and a lot more effective.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So at this point I will give you a little bit critique of this work.",
                    "label": 0
                },
                {
                    "sent": "So one issue is that the data set isn't publicly available and they had one reviewer for the most recent paper, the Wisdom Paper.",
                    "label": 0
                },
                {
                    "sent": "Coming back and saying, well, I mean, this is all very nice.",
                    "label": 0
                },
                {
                    "sent": "You clearly have a very big data set here, but.",
                    "label": 0
                },
                {
                    "sent": "We can't validate it and so one plan for future workers to repeat.",
                    "label": 0
                },
                {
                    "sent": "Those experiments using standard collections.",
                    "label": 0
                },
                {
                    "sent": "If you have good ideas about what collections use, please come and see me after.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's.",
                    "label": 0
                },
                {
                    "sent": "Another one is that the data set is fairly old.",
                    "label": 0
                },
                {
                    "sent": "The web graph was called in 2002.",
                    "label": 0
                },
                {
                    "sent": "Small fraction of the results is judged and the intersection within the graph and the results that it's actually fairly modest.",
                    "label": 0
                },
                {
                    "sent": "Again, I mean by doing this on a larger newer data set, maybe can overcome some of those issues.",
                    "label": 0
                },
                {
                    "sent": "The third one is here.",
                    "label": 0
                },
                {
                    "sent": "We looked only at the effectiveness of isolated features we didn't describe in the paper.",
                    "label": 0
                },
                {
                    "sent": "We did look at linear combinations being 25 F and you still get improvement, but improvement is a good deal smaller and so one piece for future work is are there better ways for combining evidence than linear combination?",
                    "label": 0
                },
                {
                    "sent": "And then finally well.",
                    "label": 0
                },
                {
                    "sent": "Is this actually a good tradeoff between speed and quality?",
                    "label": 0
                },
                {
                    "sent": "And I guess you have to be the judge on that depends on the application.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                }
            ]
        }
    }
}