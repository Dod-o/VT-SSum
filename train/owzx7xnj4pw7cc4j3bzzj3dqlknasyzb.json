{
    "id": "owzx7xnj4pw7cc4j3bzzj3dqlknasyzb",
    "title": "Streaming Hierarchical Video Segmentation",
    "info": {
        "chairman": [
            "Bernt Schiele, Max Planck Institut Informatik, Max Planck Institute",
            "David Forsyth, Department of Computer Science, University of Illinois at Urbana-Champaign"
        ],
        "author": [
            "Jason Corso, University at Buffalo"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision->Video Analysis"
        ]
    },
    "url": "http://videolectures.net/eccv2012_corso_video/",
    "segmentation": [
        [
            "OK, thank you so I'm actually quite excited that this talk comes right after the last talk because I'd really like to run this method on that data.",
            "Really think it's a.",
            "Well organized session, so I'm happy to present our paper on streaming hierarchical video segmentation on behalf of my students.",
            "Channeling it's I mean who couldn't be here."
        ],
        [
            "Because of some visa problems.",
            "Now, if you take a look at the work and video understanding for the last two or whatever 1015 years, you'll notice that the vast variety of methods that you see are dominated by local interest point methods.",
            "It's in trajectory upon them, and so unlike the spacetime interest points you see here, and I'll despite the fact that these methods have really taken our community quite far like activity recognition.",
            "For example, many, many good methods are based upon these, you know they're lacking in some regards.",
            "For example, they can provide space for temporal boundaries.",
            "So the main emphasis of this work is to explore a complementary feature, namely video segmentation, that can accomplish."
        ],
        [
            "And local interest point operators to also provide space time."
        ],
        [
            "Boundaries and so on.",
            "OK, so the operant premise in our in our paper here is that video segmentation can provide a rich feature space on which to do video understanding.",
            "OK, so let me explain the video you see here.",
            "Just 'cause you'll see a few of these throughout the talk.",
            "OK, in the top left quadrant you see the raw, the input video, and then the other three quadrants are three different layers out of the video segmentation hierarchy.",
            "The bottom left is the lowest level, the bottom right is a little in the middle, so I think this is 11th level on the top right.",
            "Is a level up higher in the hierarchy OK?"
        ],
        [
            "Despite an obviously rich feature space on which to do video understanding methods like object segmentation so on video segmentation lags quite far behind that of image segmentation for the corresponding problems of video and image understanding.",
            "Not exactly sure."
        ],
        [
            "Why despite considering the fact that there are dozens of quite good segmentation methods that can be extended into the video domain, we think the basic reason for this is simply that video has too many pixels.",
            "Just there are too many pixels to process and we don't know how to deal with that."
        ],
        [
            "And why is that right?",
            "So most of the video the image segmentation methods that could be extended to video tacitly assume that one can load the whole entire video into memory for a video that's 10 seconds.",
            "That's fine, but for video that's 10 minutes.",
            "No modern computer can handle that in memory.",
            "OK, in some cases take mobile robotics for example.",
            "You may not even know how long the video is.",
            "If the robots moving around an environment, it needs to process video online.",
            "OK, so to handle this this memory issue, a number of works have moved to frame by frame method."
        ],
        [
            "It's where instead of loading the whole video memory, they'll just take one frame at a time.",
            "Bang Bang, bang, do the processing and obviously it gets over the memory problem, but it introduces another a new problem, one of temporal coherence.",
            "OK, so if you think of these two classes of methods."
        ],
        [
            "As two ends of a continuum in the middle are methods that are called streaming methods or clip based methods where you know you, you decide on some clip length or you do shot segmentation and you load just small sets of frames into memory at once, you avoid the temporal coherence problem, which is good, and the difficulty there is essentially can you bound the memory needs to allow the method to handle arbitrary long videos without sacrificing the quality of the segmentation.",
            "OK, so a number of streaming methods have been proposed already, such as the Paris mean shift method or the grammar running at all paper from CPR couple years ago.",
            "But the main issue the main limitation of these existing streaming methods is that they probably underperform the corresponding hierarchical methods.",
            "So add CPR this year we had carried out a quantitative evaluation of."
        ],
        [
            "We have five different suits, video segmentation methods and we kind of roughly sampled the space of algorithms SWA, a graph based some nicer approximation.",
            "So on.",
            "Here are some examples of the videos at the bottom of the slide, and we pitted these five methods in a quantitative assessment for for a few new quantitative measures such as 3D boundary call explained variation.",
            "So on and by and large what we found in our experiment were that the two methods, namely segmentation by weighted aggregation by.",
            "Done it all and Grundman at also GBH, hierarchical graph based method.",
            "These two methods recompute similarity in the hierarchy so as they go up in the hierarchy they'll move from just simple color similarities to histograms over colors and so on, and that greatly less that greatly lessen outperform the other.",
            "The other measures.",
            "OK, so armed with."
        ],
        [
            "GBH, the main contribution of this paper is essentially to embed the GBH method in approximation framework that allows us to do streaming segmentation of videos.",
            "OK, we incorporate two ideas from data streams that allow us to guarantee a constant and indeed quite small, memory requirement method that we can handle arbitrary long and even streaming video, and indeed, we'll see that there's a nice balance between how much memory we have available and the overall quantitative performance.",
            "Of the segmentation method.",
            "Alright, so a basic problem statement is."
        ],
        [
            "Is quite simple, right?",
            "So you're looking to output a segmentation estar, which is the minimum segmentation over a set of plausable segmentations under some energy function E. Given a video input V right?",
            "So these space of energy functions is quite large.",
            "You can have everything from porch are, you know, quite quite classical method all the way modern through modern conditional random fields and so on.",
            "The actual energy function that we use is the minimum spanning tree method we build upon that from our fellowship.",
            "Huttenlocher, just like the GBH method did, so each segmentation output will be a set of segmentation layers S1S2 through SH where each layer is a full bona fide segmentation over the over the pixels at that of the video at that layer OK will really take two quite simple ideas from data streams to build upon for our for our approximation framework.",
            "OK, the first idea is that will introduce a stream pointer T that indexes into the video and essentially allows us to consider the video as a set of clips, V1V2 and so on.",
            "OK, and the key, though from data streams builds up on that stream pointer and it's that it's a constraint saying that once we've processed up to the stream pointer T hat, we may not manipulate in the past.",
            "So once we have our segmentation hierarchy for T hat, it's fixed and standard and even will see it serves as a supervised set of labels as we're doing the next next iteration there next time step segmentation.",
            "OK, we use that.",
            "As I said, we use the Filson swabbing huttenlocher admin, spending first method."
        ],
        [
            "For implementing our approximation framework, but ultimately the method generalizes to a variety of energy functions.",
            "OK, so in case we need to review the DB method, basically take your video, build a voxel lattice on the graph, would say 26 connectivity, similarity across the edges.",
            "We just use color.",
            "There's no motion, optical flow or anything right now on that voxel lattice you essentially call edges from the graph based on their similarity."
        ],
        [
            "Until until there are no edge."
        ],
        [
            "To call based on based on the ultimate objective function, right?",
            "So that's graph based segmentation, then ultimately from that will make a higher."
        ],
        [
            "Tickle Markov assumption that says every layer J is dependent only upon the most previous layer, J -- 1 and the actual video pixels themselves, and this lets us re evaluate the similarity at the multiple scales through the hierarchy.",
            "OK, this is essentially right.",
            "Now this is the GBH method from CPR 2010 so we're just going to build it."
        ],
        [
            "That the first thing we do is basically make a streaming Markov assumption that says we can factor our energy function yllanes given V into a set of energy function E1S1V1, which is the first, the first clip and then summing over all pairwise can factors in a chain E1 SI given V ISI minus one VI minus one and so on."
        ],
        [
            "After that, streaming Markov assumption will again use the hierarchical Markov assumption that says every layer J at time I is a function only of layer J at time I minus one and the previous layers down, so they're J -- 1 at time I and time I minus one.",
            "So everytime were processing a particular layer, we're doing that independent of everything below it below 2 layers down and two times."
        ],
        [
            "Forehand, OK, so the basic computation that goes into computing that segmentation for layer J at time I is essentially a modified minimum spanning forest method.",
            "That is, one can consider it kind of like a semi supervised problem, right?",
            "So since from the data streams algorithms we know that we can modify the previous time J -- I -- 1 segmentation.",
            "We essentially treat those those segments as a set of classes to which we can either assign new segments to at time I.",
            "Or let let time I generate new segments and we implement this by ascential a set of modified grouping rules that essentially allow us to avoid ambiguities in the interest of time.",
            "I can't really go through the details of them, but you can check the paper for some more details.",
            "It essentially boils down to three rules that essentially doesn't let us kind of pushes up decisions to merge anything that would have affected time time on."
        ],
        [
            "This one OK, so once we once we can do one layer at one layer.",
            "Ji time I will just go up the hierarchy and continue."
        ],
        [
            "So on and then that lets us advance the stream pointer.",
            "We offload memory from all time I minus one an upload memory from time I plus one."
        ],
        [
            "Actually run the same mill again."
        ],
        [
            "And again, until we've processed."
        ],
        [
            "The clips in the video OK and at the end of the day we can consider them as one complete video."
        ],
        [
            "Segmentation OK, so here's an example from this.",
            "I think this is some skateboarding in Chicago where you can see you know some interesting things to pull out so the motion is quite quite fast in here.",
            "There's a lot of people around the cameras panning around, but if you look at the bottom left quadrant the methods fairly fairly consistent at obeying object boundaries.",
            "Now clearly this is an over segmentation, but we don't see much bleeding at such a low level.",
            "I think this is level 8th if I think 18 total layers, but if you look at the top level.",
            "We're still able to do a decent job at getting object boundaries, although you notice that there is some bleeding that starts to happen.",
            "If you notice on the guys back right there and the bleeding happens because of the clip length, essentially.",
            "So if we were able to make the clip longer, that bleeding would would be less less a problem OK."
        ],
        [
            "So of course we've tried to quantitatively evaluate our method, and for that we use the libdvdcss as video segmentation benchmark that we released at CPR this year.",
            "Just a quick overview.",
            "So essentially the benchmark uses 3 datasets that have a variety of annotations.",
            "One some have no no human annotations.",
            "The said tract data set have a single object moving through the video and then a data set from our group called Chen zip.org essentially does segmentation full frame segmentation into the SRC 21 object classes.",
            "And so on.",
            "It you just see an example from that data set at the bottom of the slide and the metrics are three under segmentation error and so on.",
            "OK, so we asked 2 questions."
        ],
        [
            "Isn't there more results in the paper?",
            "But I wanted to let you to make the point for the talk.",
            "OK, the first question was does stream GBH, which is our method balance between frame to frame methods and full video method.",
            "So how good a job is it doing?",
            "OK so if you look at the graphs here the blue curve is the full GBH method so this is the assumption that we can load the whole video into memory at once.",
            "OK in the horizontal axis there is the number of super voxels, so this is essentially a summary graph over the whole hierarchy, right?",
            "So we're going over layers of the hierarchy.",
            "There's increasing number of super voxels as you go down.",
            "OK, in the vertical graph is a 3D boundary call, right?",
            "So the GBH full video segmentation is kind of like an upper bound.",
            "In some sense.",
            "The frame by frame method is like a lower bound, right?",
            "That's the red curve there in the middle.",
            "We found a happy medium with stream GBH and this is what the clip length of.",
            "Only 10 frames.",
            "And so if you if you very K higher and very lower then you'll see the curve go up and down.",
            "The other three curves are for the non hierarchical comparison for GB Stream GB and frame to frame stream BGB."
        ],
        [
            "OK, the second method compares the new stream GBH method against the existing streaming video segmentation methods.",
            "So just to point out again, stream GBHS to the best of our knowledge, is the first streaming hierarchical methods.",
            "So all these other methods are non hierarchical OK.",
            "The two points of comparisons are the Clip GB which is the Grundman streaming method that only works at the pixel level and the mean shift method from Paris at all the CVO 8 and again you see the green curve, which is stream GBH is performing correspondingly better than the other two?",
            "OK to wrap up."
        ],
        [
            "So the main contribution is the streaming approximation framework for hierarchical segmentation.",
            "We can guarantee a constant and fairly low memory requirement handle streaming an arbitrary long videos so that the skateboarding video for example, is something like 5 minutes long and were able to process it with no problem, and so this is a general approximation framework for other segmentation methods.",
            "OK, the take home message is simply that this is a streaming method and it really can vary depending on how much memory you have at your.",
            "On your machine or on your system, it can really vary between the frame to frame on one end of the continuum and on the whole video on the other end of the continuum.",
            "Just one current limitation that we're aware of in terms of the implementation is that the method runs at something like one to four seconds per frame right now.",
            "OK, so it's not.",
            "It's not real time by any means, but we're currently paralyzing it and we hope to release that pretty soon."
        ],
        [
            "Thanks for your attention.",
            "I just want to make more points before taking questions.",
            "One is that the codes available, please download it.",
            "It's been available for awhile now.",
            "If you have any questions I'd be happy to hear suggestions.",
            "Would be great.",
            "Another is that I have a postdoc opening in my group on this problem joint with activity recognition and so if you're interested just find me.",
            "OK, thanks for your attention.",
            "So the results are a bit counter intuitive to me, but maybe you haven't shown long results, but I would imagine that some K the subsequence length you would simply, you know, be equal to full video length performance.",
            "So do you have a sense of what that number K is and how it varies for different videos?",
            "So I think this is very dependent on the actual content of the video, so if the video doesn't have too much drastic motion.",
            "Then the cake can be pretty low and you'll be equal to the videos full video.",
            "But if, like the skateboarding video with a lot of motion and so on, I think the cable need to be fairly large, and so if you look at the results that are on this frame here, so these are all on the Chen ZIP code or data, which is, I think they're all 85 frames, and so we've chosen essentially about whatever 15% of the full video, and we're getting a curve that in the green there as we increase K, we do approach it.",
            "But but we don't have any sort of systematic model that can tell you what Kay needs to be as a function of the the motion estimates.",
            "But once your intuition in terms of what case should be to get sort of full length video performance, I I mean, I'd be speculating, but from what I've seen in the labs on the order of certainly less than 100 for a very typical video, thanks.",
            "You should."
        ],
        [
            "Honda recall and I was wondering what are your thoughts?",
            "So is this deliberate that you actually are interested in, say super voxels or you know?",
            "In contrast, you could look at something like you know more object like segmentation evaluation metrics like intersection over Union for the kind of op pixelwise intersection over Union for the objects of interest, yes, so you know this, this says that you know the kind of plot we see says that you know you do a great job of finding.",
            "Boundaries is based time.",
            "But now yeah, does this stuff right so that that's a good point.",
            "So actually there are two.",
            "There are two comments I would like to make on that one is that I've kind of so.",
            "So there are four metrics within the benchmark boundary called just one that I sort of arbitrarily chosen them.",
            "The same types of results appear there, but the other point indeed is that the benchmarks designed for super voxel assessment, not for overall object segmentation assessment, and that's why I'm so excited about the previous paper, because that's we can now get kind of full object assessments, and then we can introduce.",
            "Measures like you're suggesting kind of like object intersection, but that's for something in the future.",
            "Yeah, if you go back to the Flower garden sequence seemed to me like you were grouping together the trees in the front and in the back in your segmentation."
        ],
        [
            "Yes, seems to be totally wrong.",
            "Why?",
            "Why does that happen?",
            "So the labeling is done in terms of semantic fix, so it's a data set for semantic segmentation.",
            "So in terms of motion, they have completely different motions.",
            "Yes, this is true.",
            "Yeah, so in this data set, that's a limitation of these annotations.",
            "Yeah, so in terms of the other data set, this extract data set.",
            "It accounts for those types of of foreground object dominant and that's moving through the video.",
            "So we use so that I think it's good to have.",
            "That's why we've incorporated both the datasets into the benchmark, right?",
            "So one of them is assessing essentially dominant object motion in the front in the foreground, the other one is assessing more semantic boundaries.",
            "OK.",
            "Thanks.",
            "There's one question that has to be a very short last question, I'm afraid, yeah, sure.",
            "So the question was during your segmentation.",
            "The hierarchical segmentation you vary the grouping rules as you go up the hierarchy.",
            "And how do you decide when to vary this and what do you do overtime?",
            "So the grouping is a direct implementation of the minimum spanning method, so it's essentially a function of the essentially the Max similarity in a region, an you regularize that in terms of hand tuned parameter, which is.",
            "So there's a single parameter in terms of in the method, and you can raise or lower that parameter based on how similar you want things to be.",
            "Yeah.",
            "Thank you, OK, thank you, but we thank the speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, thank you so I'm actually quite excited that this talk comes right after the last talk because I'd really like to run this method on that data.",
                    "label": 0
                },
                {
                    "sent": "Really think it's a.",
                    "label": 0
                },
                {
                    "sent": "Well organized session, so I'm happy to present our paper on streaming hierarchical video segmentation on behalf of my students.",
                    "label": 1
                },
                {
                    "sent": "Channeling it's I mean who couldn't be here.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because of some visa problems.",
                    "label": 0
                },
                {
                    "sent": "Now, if you take a look at the work and video understanding for the last two or whatever 1015 years, you'll notice that the vast variety of methods that you see are dominated by local interest point methods.",
                    "label": 0
                },
                {
                    "sent": "It's in trajectory upon them, and so unlike the spacetime interest points you see here, and I'll despite the fact that these methods have really taken our community quite far like activity recognition.",
                    "label": 0
                },
                {
                    "sent": "For example, many, many good methods are based upon these, you know they're lacking in some regards.",
                    "label": 0
                },
                {
                    "sent": "For example, they can provide space for temporal boundaries.",
                    "label": 0
                },
                {
                    "sent": "So the main emphasis of this work is to explore a complementary feature, namely video segmentation, that can accomplish.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And local interest point operators to also provide space time.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Boundaries and so on.",
                    "label": 0
                },
                {
                    "sent": "OK, so the operant premise in our in our paper here is that video segmentation can provide a rich feature space on which to do video understanding.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me explain the video you see here.",
                    "label": 0
                },
                {
                    "sent": "Just 'cause you'll see a few of these throughout the talk.",
                    "label": 0
                },
                {
                    "sent": "OK, in the top left quadrant you see the raw, the input video, and then the other three quadrants are three different layers out of the video segmentation hierarchy.",
                    "label": 1
                },
                {
                    "sent": "The bottom left is the lowest level, the bottom right is a little in the middle, so I think this is 11th level on the top right.",
                    "label": 0
                },
                {
                    "sent": "Is a level up higher in the hierarchy OK?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Despite an obviously rich feature space on which to do video understanding methods like object segmentation so on video segmentation lags quite far behind that of image segmentation for the corresponding problems of video and image understanding.",
                    "label": 0
                },
                {
                    "sent": "Not exactly sure.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why despite considering the fact that there are dozens of quite good segmentation methods that can be extended into the video domain, we think the basic reason for this is simply that video has too many pixels.",
                    "label": 0
                },
                {
                    "sent": "Just there are too many pixels to process and we don't know how to deal with that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And why is that right?",
                    "label": 0
                },
                {
                    "sent": "So most of the video the image segmentation methods that could be extended to video tacitly assume that one can load the whole entire video into memory for a video that's 10 seconds.",
                    "label": 1
                },
                {
                    "sent": "That's fine, but for video that's 10 minutes.",
                    "label": 0
                },
                {
                    "sent": "No modern computer can handle that in memory.",
                    "label": 0
                },
                {
                    "sent": "OK, in some cases take mobile robotics for example.",
                    "label": 0
                },
                {
                    "sent": "You may not even know how long the video is.",
                    "label": 1
                },
                {
                    "sent": "If the robots moving around an environment, it needs to process video online.",
                    "label": 0
                },
                {
                    "sent": "OK, so to handle this this memory issue, a number of works have moved to frame by frame method.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's where instead of loading the whole video memory, they'll just take one frame at a time.",
                    "label": 0
                },
                {
                    "sent": "Bang Bang, bang, do the processing and obviously it gets over the memory problem, but it introduces another a new problem, one of temporal coherence.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you think of these two classes of methods.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As two ends of a continuum in the middle are methods that are called streaming methods or clip based methods where you know you, you decide on some clip length or you do shot segmentation and you load just small sets of frames into memory at once, you avoid the temporal coherence problem, which is good, and the difficulty there is essentially can you bound the memory needs to allow the method to handle arbitrary long videos without sacrificing the quality of the segmentation.",
                    "label": 1
                },
                {
                    "sent": "OK, so a number of streaming methods have been proposed already, such as the Paris mean shift method or the grammar running at all paper from CPR couple years ago.",
                    "label": 0
                },
                {
                    "sent": "But the main issue the main limitation of these existing streaming methods is that they probably underperform the corresponding hierarchical methods.",
                    "label": 0
                },
                {
                    "sent": "So add CPR this year we had carried out a quantitative evaluation of.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have five different suits, video segmentation methods and we kind of roughly sampled the space of algorithms SWA, a graph based some nicer approximation.",
                    "label": 0
                },
                {
                    "sent": "So on.",
                    "label": 0
                },
                {
                    "sent": "Here are some examples of the videos at the bottom of the slide, and we pitted these five methods in a quantitative assessment for for a few new quantitative measures such as 3D boundary call explained variation.",
                    "label": 1
                },
                {
                    "sent": "So on and by and large what we found in our experiment were that the two methods, namely segmentation by weighted aggregation by.",
                    "label": 0
                },
                {
                    "sent": "Done it all and Grundman at also GBH, hierarchical graph based method.",
                    "label": 0
                },
                {
                    "sent": "These two methods recompute similarity in the hierarchy so as they go up in the hierarchy they'll move from just simple color similarities to histograms over colors and so on, and that greatly less that greatly lessen outperform the other.",
                    "label": 0
                },
                {
                    "sent": "The other measures.",
                    "label": 0
                },
                {
                    "sent": "OK, so armed with.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "GBH, the main contribution of this paper is essentially to embed the GBH method in approximation framework that allows us to do streaming segmentation of videos.",
                    "label": 1
                },
                {
                    "sent": "OK, we incorporate two ideas from data streams that allow us to guarantee a constant and indeed quite small, memory requirement method that we can handle arbitrary long and even streaming video, and indeed, we'll see that there's a nice balance between how much memory we have available and the overall quantitative performance.",
                    "label": 1
                },
                {
                    "sent": "Of the segmentation method.",
                    "label": 0
                },
                {
                    "sent": "Alright, so a basic problem statement is.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is quite simple, right?",
                    "label": 0
                },
                {
                    "sent": "So you're looking to output a segmentation estar, which is the minimum segmentation over a set of plausable segmentations under some energy function E. Given a video input V right?",
                    "label": 0
                },
                {
                    "sent": "So these space of energy functions is quite large.",
                    "label": 0
                },
                {
                    "sent": "You can have everything from porch are, you know, quite quite classical method all the way modern through modern conditional random fields and so on.",
                    "label": 0
                },
                {
                    "sent": "The actual energy function that we use is the minimum spanning tree method we build upon that from our fellowship.",
                    "label": 0
                },
                {
                    "sent": "Huttenlocher, just like the GBH method did, so each segmentation output will be a set of segmentation layers S1S2 through SH where each layer is a full bona fide segmentation over the over the pixels at that of the video at that layer OK will really take two quite simple ideas from data streams to build upon for our for our approximation framework.",
                    "label": 0
                },
                {
                    "sent": "OK, the first idea is that will introduce a stream pointer T that indexes into the video and essentially allows us to consider the video as a set of clips, V1V2 and so on.",
                    "label": 1
                },
                {
                    "sent": "OK, and the key, though from data streams builds up on that stream pointer and it's that it's a constraint saying that once we've processed up to the stream pointer T hat, we may not manipulate in the past.",
                    "label": 0
                },
                {
                    "sent": "So once we have our segmentation hierarchy for T hat, it's fixed and standard and even will see it serves as a supervised set of labels as we're doing the next next iteration there next time step segmentation.",
                    "label": 0
                },
                {
                    "sent": "OK, we use that.",
                    "label": 0
                },
                {
                    "sent": "As I said, we use the Filson swabbing huttenlocher admin, spending first method.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For implementing our approximation framework, but ultimately the method generalizes to a variety of energy functions.",
                    "label": 1
                },
                {
                    "sent": "OK, so in case we need to review the DB method, basically take your video, build a voxel lattice on the graph, would say 26 connectivity, similarity across the edges.",
                    "label": 0
                },
                {
                    "sent": "We just use color.",
                    "label": 1
                },
                {
                    "sent": "There's no motion, optical flow or anything right now on that voxel lattice you essentially call edges from the graph based on their similarity.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Until until there are no edge.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To call based on based on the ultimate objective function, right?",
                    "label": 0
                },
                {
                    "sent": "So that's graph based segmentation, then ultimately from that will make a higher.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tickle Markov assumption that says every layer J is dependent only upon the most previous layer, J -- 1 and the actual video pixels themselves, and this lets us re evaluate the similarity at the multiple scales through the hierarchy.",
                    "label": 0
                },
                {
                    "sent": "OK, this is essentially right.",
                    "label": 0
                },
                {
                    "sent": "Now this is the GBH method from CPR 2010 so we're just going to build it.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That the first thing we do is basically make a streaming Markov assumption that says we can factor our energy function yllanes given V into a set of energy function E1S1V1, which is the first, the first clip and then summing over all pairwise can factors in a chain E1 SI given V ISI minus one VI minus one and so on.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After that, streaming Markov assumption will again use the hierarchical Markov assumption that says every layer J at time I is a function only of layer J at time I minus one and the previous layers down, so they're J -- 1 at time I and time I minus one.",
                    "label": 0
                },
                {
                    "sent": "So everytime were processing a particular layer, we're doing that independent of everything below it below 2 layers down and two times.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Forehand, OK, so the basic computation that goes into computing that segmentation for layer J at time I is essentially a modified minimum spanning forest method.",
                    "label": 0
                },
                {
                    "sent": "That is, one can consider it kind of like a semi supervised problem, right?",
                    "label": 0
                },
                {
                    "sent": "So since from the data streams algorithms we know that we can modify the previous time J -- I -- 1 segmentation.",
                    "label": 0
                },
                {
                    "sent": "We essentially treat those those segments as a set of classes to which we can either assign new segments to at time I.",
                    "label": 0
                },
                {
                    "sent": "Or let let time I generate new segments and we implement this by ascential a set of modified grouping rules that essentially allow us to avoid ambiguities in the interest of time.",
                    "label": 1
                },
                {
                    "sent": "I can't really go through the details of them, but you can check the paper for some more details.",
                    "label": 0
                },
                {
                    "sent": "It essentially boils down to three rules that essentially doesn't let us kind of pushes up decisions to merge anything that would have affected time time on.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one OK, so once we once we can do one layer at one layer.",
                    "label": 0
                },
                {
                    "sent": "Ji time I will just go up the hierarchy and continue.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So on and then that lets us advance the stream pointer.",
                    "label": 0
                },
                {
                    "sent": "We offload memory from all time I minus one an upload memory from time I plus one.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually run the same mill again.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again, until we've processed.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The clips in the video OK and at the end of the day we can consider them as one complete video.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Segmentation OK, so here's an example from this.",
                    "label": 0
                },
                {
                    "sent": "I think this is some skateboarding in Chicago where you can see you know some interesting things to pull out so the motion is quite quite fast in here.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of people around the cameras panning around, but if you look at the bottom left quadrant the methods fairly fairly consistent at obeying object boundaries.",
                    "label": 0
                },
                {
                    "sent": "Now clearly this is an over segmentation, but we don't see much bleeding at such a low level.",
                    "label": 0
                },
                {
                    "sent": "I think this is level 8th if I think 18 total layers, but if you look at the top level.",
                    "label": 0
                },
                {
                    "sent": "We're still able to do a decent job at getting object boundaries, although you notice that there is some bleeding that starts to happen.",
                    "label": 0
                },
                {
                    "sent": "If you notice on the guys back right there and the bleeding happens because of the clip length, essentially.",
                    "label": 0
                },
                {
                    "sent": "So if we were able to make the clip longer, that bleeding would would be less less a problem OK.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So of course we've tried to quantitatively evaluate our method, and for that we use the libdvdcss as video segmentation benchmark that we released at CPR this year.",
                    "label": 1
                },
                {
                    "sent": "Just a quick overview.",
                    "label": 0
                },
                {
                    "sent": "So essentially the benchmark uses 3 datasets that have a variety of annotations.",
                    "label": 0
                },
                {
                    "sent": "One some have no no human annotations.",
                    "label": 1
                },
                {
                    "sent": "The said tract data set have a single object moving through the video and then a data set from our group called Chen zip.org essentially does segmentation full frame segmentation into the SRC 21 object classes.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 1
                },
                {
                    "sent": "It you just see an example from that data set at the bottom of the slide and the metrics are three under segmentation error and so on.",
                    "label": 0
                },
                {
                    "sent": "OK, so we asked 2 questions.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Isn't there more results in the paper?",
                    "label": 0
                },
                {
                    "sent": "But I wanted to let you to make the point for the talk.",
                    "label": 0
                },
                {
                    "sent": "OK, the first question was does stream GBH, which is our method balance between frame to frame methods and full video method.",
                    "label": 1
                },
                {
                    "sent": "So how good a job is it doing?",
                    "label": 0
                },
                {
                    "sent": "OK so if you look at the graphs here the blue curve is the full GBH method so this is the assumption that we can load the whole video into memory at once.",
                    "label": 0
                },
                {
                    "sent": "OK in the horizontal axis there is the number of super voxels, so this is essentially a summary graph over the whole hierarchy, right?",
                    "label": 0
                },
                {
                    "sent": "So we're going over layers of the hierarchy.",
                    "label": 0
                },
                {
                    "sent": "There's increasing number of super voxels as you go down.",
                    "label": 0
                },
                {
                    "sent": "OK, in the vertical graph is a 3D boundary call, right?",
                    "label": 0
                },
                {
                    "sent": "So the GBH full video segmentation is kind of like an upper bound.",
                    "label": 1
                },
                {
                    "sent": "In some sense.",
                    "label": 0
                },
                {
                    "sent": "The frame by frame method is like a lower bound, right?",
                    "label": 0
                },
                {
                    "sent": "That's the red curve there in the middle.",
                    "label": 0
                },
                {
                    "sent": "We found a happy medium with stream GBH and this is what the clip length of.",
                    "label": 0
                },
                {
                    "sent": "Only 10 frames.",
                    "label": 0
                },
                {
                    "sent": "And so if you if you very K higher and very lower then you'll see the curve go up and down.",
                    "label": 0
                },
                {
                    "sent": "The other three curves are for the non hierarchical comparison for GB Stream GB and frame to frame stream BGB.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, the second method compares the new stream GBH method against the existing streaming video segmentation methods.",
                    "label": 1
                },
                {
                    "sent": "So just to point out again, stream GBHS to the best of our knowledge, is the first streaming hierarchical methods.",
                    "label": 0
                },
                {
                    "sent": "So all these other methods are non hierarchical OK.",
                    "label": 0
                },
                {
                    "sent": "The two points of comparisons are the Clip GB which is the Grundman streaming method that only works at the pixel level and the mean shift method from Paris at all the CVO 8 and again you see the green curve, which is stream GBH is performing correspondingly better than the other two?",
                    "label": 0
                },
                {
                    "sent": "OK to wrap up.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main contribution is the streaming approximation framework for hierarchical segmentation.",
                    "label": 0
                },
                {
                    "sent": "We can guarantee a constant and fairly low memory requirement handle streaming an arbitrary long videos so that the skateboarding video for example, is something like 5 minutes long and were able to process it with no problem, and so this is a general approximation framework for other segmentation methods.",
                    "label": 1
                },
                {
                    "sent": "OK, the take home message is simply that this is a streaming method and it really can vary depending on how much memory you have at your.",
                    "label": 0
                },
                {
                    "sent": "On your machine or on your system, it can really vary between the frame to frame on one end of the continuum and on the whole video on the other end of the continuum.",
                    "label": 1
                },
                {
                    "sent": "Just one current limitation that we're aware of in terms of the implementation is that the method runs at something like one to four seconds per frame right now.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not real time by any means, but we're currently paralyzing it and we hope to release that pretty soon.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thanks for your attention.",
                    "label": 0
                },
                {
                    "sent": "I just want to make more points before taking questions.",
                    "label": 0
                },
                {
                    "sent": "One is that the codes available, please download it.",
                    "label": 0
                },
                {
                    "sent": "It's been available for awhile now.",
                    "label": 0
                },
                {
                    "sent": "If you have any questions I'd be happy to hear suggestions.",
                    "label": 0
                },
                {
                    "sent": "Would be great.",
                    "label": 0
                },
                {
                    "sent": "Another is that I have a postdoc opening in my group on this problem joint with activity recognition and so if you're interested just find me.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks for your attention.",
                    "label": 0
                },
                {
                    "sent": "So the results are a bit counter intuitive to me, but maybe you haven't shown long results, but I would imagine that some K the subsequence length you would simply, you know, be equal to full video length performance.",
                    "label": 0
                },
                {
                    "sent": "So do you have a sense of what that number K is and how it varies for different videos?",
                    "label": 0
                },
                {
                    "sent": "So I think this is very dependent on the actual content of the video, so if the video doesn't have too much drastic motion.",
                    "label": 0
                },
                {
                    "sent": "Then the cake can be pretty low and you'll be equal to the videos full video.",
                    "label": 0
                },
                {
                    "sent": "But if, like the skateboarding video with a lot of motion and so on, I think the cable need to be fairly large, and so if you look at the results that are on this frame here, so these are all on the Chen ZIP code or data, which is, I think they're all 85 frames, and so we've chosen essentially about whatever 15% of the full video, and we're getting a curve that in the green there as we increase K, we do approach it.",
                    "label": 0
                },
                {
                    "sent": "But but we don't have any sort of systematic model that can tell you what Kay needs to be as a function of the the motion estimates.",
                    "label": 0
                },
                {
                    "sent": "But once your intuition in terms of what case should be to get sort of full length video performance, I I mean, I'd be speculating, but from what I've seen in the labs on the order of certainly less than 100 for a very typical video, thanks.",
                    "label": 0
                },
                {
                    "sent": "You should.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Honda recall and I was wondering what are your thoughts?",
                    "label": 0
                },
                {
                    "sent": "So is this deliberate that you actually are interested in, say super voxels or you know?",
                    "label": 0
                },
                {
                    "sent": "In contrast, you could look at something like you know more object like segmentation evaluation metrics like intersection over Union for the kind of op pixelwise intersection over Union for the objects of interest, yes, so you know this, this says that you know the kind of plot we see says that you know you do a great job of finding.",
                    "label": 0
                },
                {
                    "sent": "Boundaries is based time.",
                    "label": 0
                },
                {
                    "sent": "But now yeah, does this stuff right so that that's a good point.",
                    "label": 0
                },
                {
                    "sent": "So actually there are two.",
                    "label": 0
                },
                {
                    "sent": "There are two comments I would like to make on that one is that I've kind of so.",
                    "label": 0
                },
                {
                    "sent": "So there are four metrics within the benchmark boundary called just one that I sort of arbitrarily chosen them.",
                    "label": 0
                },
                {
                    "sent": "The same types of results appear there, but the other point indeed is that the benchmarks designed for super voxel assessment, not for overall object segmentation assessment, and that's why I'm so excited about the previous paper, because that's we can now get kind of full object assessments, and then we can introduce.",
                    "label": 0
                },
                {
                    "sent": "Measures like you're suggesting kind of like object intersection, but that's for something in the future.",
                    "label": 0
                },
                {
                    "sent": "Yeah, if you go back to the Flower garden sequence seemed to me like you were grouping together the trees in the front and in the back in your segmentation.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, seems to be totally wrong.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Why does that happen?",
                    "label": 0
                },
                {
                    "sent": "So the labeling is done in terms of semantic fix, so it's a data set for semantic segmentation.",
                    "label": 0
                },
                {
                    "sent": "So in terms of motion, they have completely different motions.",
                    "label": 0
                },
                {
                    "sent": "Yes, this is true.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so in this data set, that's a limitation of these annotations.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so in terms of the other data set, this extract data set.",
                    "label": 0
                },
                {
                    "sent": "It accounts for those types of of foreground object dominant and that's moving through the video.",
                    "label": 0
                },
                {
                    "sent": "So we use so that I think it's good to have.",
                    "label": 0
                },
                {
                    "sent": "That's why we've incorporated both the datasets into the benchmark, right?",
                    "label": 0
                },
                {
                    "sent": "So one of them is assessing essentially dominant object motion in the front in the foreground, the other one is assessing more semantic boundaries.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "There's one question that has to be a very short last question, I'm afraid, yeah, sure.",
                    "label": 0
                },
                {
                    "sent": "So the question was during your segmentation.",
                    "label": 0
                },
                {
                    "sent": "The hierarchical segmentation you vary the grouping rules as you go up the hierarchy.",
                    "label": 0
                },
                {
                    "sent": "And how do you decide when to vary this and what do you do overtime?",
                    "label": 0
                },
                {
                    "sent": "So the grouping is a direct implementation of the minimum spanning method, so it's essentially a function of the essentially the Max similarity in a region, an you regularize that in terms of hand tuned parameter, which is.",
                    "label": 0
                },
                {
                    "sent": "So there's a single parameter in terms of in the method, and you can raise or lower that parameter based on how similar you want things to be.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Thank you, OK, thank you, but we thank the speaker.",
                    "label": 0
                }
            ]
        }
    }
}