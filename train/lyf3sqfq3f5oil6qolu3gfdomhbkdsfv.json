{
    "id": "lyf3sqfq3f5oil6qolu3gfdomhbkdsfv",
    "title": "Learning and Reasoning with Qualitative Models of Physical Behavior",
    "info": {
        "author": [
            "Scott E. Friedman, Northwestern University"
        ],
        "published": "July 22, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/qr09_friedman_lrq/",
    "segmentation": [
        [
            "I'm still Scott and today I'm talking about learning and reasoning with qualitative models of physical behavior.",
            "This work was coauthored with Ken Forbis and Jason Taylor at the Qualitative Reasoning Group Northwestern University."
        ],
        [
            "So people have misconceptions about force and motion.",
            "Lot of researchers have characterized some of these misconceptions is similar to the medieval impetus theory.",
            "Arista Tilian models of dynamics, so that's still in debate.",
            "Also in debate is the Systematis city and cohesiveness of these intuitive models.",
            "But I'm one thing that's pretty obvious is that infants and students don't walk into a classroom with scientifically correct Newtonian models of force and motion.",
            "So there's also agreement that these intuitive models are qualitative and also tenacious.",
            "Good performance and proficiency in mathematics and proficiency with physics equations is not indicative of performance on the qualitative side of physics, and also these misconceptions persist after physics instruction in University and in high school, and it also they also persist in honors students as well."
        ],
        [
            "So.",
            "They learn from experience and this much is.",
            "Agreed upon the literature.",
            "When the scientifically incorrect.",
            "These misconceptions might occur from improperly generalizing or contextual Ising experience, so the question we'd like to answer here is how our naive qualitative models learn from experience, and one Ave that we've identified here is that by temporally encoding examples from experience, analogically generalizing the exemplars, and then parameterising the generalizations, we can actually arrive at.",
            "Qualitative models of physical behave."
        ],
        [
            "Cheers.",
            "So we've created a computational cognitive model to test this hypothesis.",
            "Our system is given multi modal input stimuli in the form of sort of comic strips, which I'll describe shortly and a set of target concepts can't sit down, ever.",
            "In this case the target concepts are moving, pushing and blocking.",
            "The system automatically learns intuitive models of these target concepts from the given stimuli.",
            "And we evaluate the models learned by asking our system to perform similar tasks to students from the literature 1 task from Brown and one from Destiny's Atolls Force concept inventory."
        ],
        [
            "So it all starts with our multimodal stimuli."
        ],
        [
            "We used Cox cats just like John does for his research.",
            "Similar here on multistate comic strips, the comic strips are divided into frames like you normally see, and frames are divided by qualitative behaviors, such as when objects start or stop touching started, stop moving or when agent starts or stopped acting.",
            "We also have temporal relations between the states, the arrows, the annotations there starts after ending of which, though the directionality of arrow seems a little counterintuitive, it's using a relationship opencyc that designates the temporal priority which the system can understand.",
            "Each stimulus contains one or more example of the target concepts.",
            "Pushing, moving, or blocking.",
            "We also have an English blurb which is attached to each stimulus.",
            "Here the child child 13.",
            "Is playing with the truck truck 13 so Child 13 and truck 13.",
            "Those tokens refer to entities or glyphs within the sketch so that the English and the sketch can describe the same scene, the same entities.",
            "So we use COGS sketch to process the sketch input, an EA Natural Language Understanding Unit also developed in our group to process the simplified English.",
            "Both of these knowledge capture tools use the open Cyc knowledge base, which is where our ontology nor Cal comes from.",
            "We have 17 such stimuli used as our learning stimuli.",
            "All in the same, of course.",
            "They describe different situations, but they have the same mode."
        ],
        [
            "Bodies.",
            "The next step is to take these stimuli and create temporally encoded exemplars of the concepts, which is all done automat."
        ],
        [
            "As well.",
            "So at the left we have the sketch I showed you before the comic strip and on the right is a three state expansion of some of these facts.",
            "Of course it's just a few facts.",
            "There are many more within this stimulus.",
            "Some facts spend one state, two states, or all three.",
            "This is all depending on the presence in the sketch.",
            "The system's first step is to automatically identify target concepts within this stimulus.",
            "In this case, it has four.",
            "Distance of the child pushing the truck to the right.",
            "The truck pushing the car to the right and the truck in the car, both moving to right.",
            "In the 3rd state."
        ],
        [
            "After this, so has that create the temple in code examples for each instance.",
            "So that means we identified four concepts, which means it needs to create 4 exemplars here for the first, for the first concept instance, child pushing the truck to the right.",
            "Every fact within this stimulus is related somehow temporally to the state of the child pushing the truck.",
            "The right some of the facts are temporally coterminal, but start before some temporally subsumed this fact.",
            "Some hold in the same state as a fact and some start after the ending up.",
            "There's other temporal relations based on Alan's 1983 temporal calculus.",
            "All of these facts and all of the temporal relations are stored in a new representation for this exemplar, and these temporal relations.",
            "Add structure to the representation which is useful for analogical reasoning and also for causal reasoning, which I'll discuss later."
        ],
        [
            "If we have our exemplars comes the next phase of SQL Generalization."
        ],
        [
            "So SQL is a model of analogical generalization.",
            "And when the simulation begins, separate context is set up for each target concept.",
            "So pushing, moving in blocking those are the ones that we gave the system, so it could automatically creates three contexts for generalizations.",
            "All the exemplars that arrive in the system are associated with that generalization.",
            "I'm sorry with that context based on which concept instances they represent.",
            "So for the example."
        ],
        [
            "So we just created and last step the child pushing the truck to the right.",
            "The first step is for sequel to identify the destination context for this issue."
        ],
        [
            "Templar.",
            "In this case, that's a pushing example, so within the pushing context, the next step is to compare the new exemplar to each generalization that exists, and in the context, using the structure mapping engine, SMAP, and I'll discuss that in a second.",
            "The first generalization that sequel finds where the SMB similarity score is above some constant threshold, actually merges that exemplar with the generalization, and then the process ends.",
            "How SMEs operates by having an input of a base and a target representation and then automatically computes mappings here.",
            "So each mapping has entity and target correspondence is a structural evaluation or similarity score, which is what we use for SQL that determine if it's above a threshold, and it can be normalized, and it also has Canada differences or inferences that can actually be taken from one representation to another based on support from the mapping.",
            "And the mapping itself is used to merge with the representations along the analogical mapping.",
            "If however, the exemplar is not similar enough."
        ],
        [
            "To an existing generalization, we sequel compares the Exemplar 2 on generalized exemplars on a simulated exemplars.",
            "Within that context, if then it's above a constant assimilation threshold, it gets merged into a new generalization, then put into context."
        ],
        [
            "It's still structurally dissimilar from all the exemplars.",
            "Then we just add the exemplar to the list of unassimilated exemplars inside that counts."
        ],
        [
            "So the result of doing this?",
            "We had 17 stimuli and which actually yielded 50 concept exemplars.",
            "Since there were 50 instances of the concepts within the stimuli, so those exemplars were generalized automatically with SQL, which yielded 10 generalizations and 12 on a simulated exemplars.",
            "Within all three contexts across all three.",
            "So the 10 generalizations are.",
            "Distinct behaviors of each concept instance and or its concept and the other similar.",
            "Exemplars were instances that weren't very similar to the existing behaviors."
        ],
        [
            "So which generalization?",
            "There is probabilistic abstractions of their constituent exemplars, so entities that correspond analogically in two exemplars, for example Miranda generalization, become generalized entities or genets here in the generalization.",
            "So Child 13 and truck 13, which I showed you don't exist inside the abstraction, because they've become.",
            "They've corresponded something that's already there, so they're abstracted each fact inside the generalization also has an associated probability which reflects the facts frequency in the constituent exemplars.",
            "The idea here is to capture the central behavior of this generalization and create a formal, qualitative causal model of it."
        ],
        [
            "So we choose to, so we build."
        ],
        [
            "Capsule histories from these generalizations we chose the encapsulated history formalism because encapsulated histories can represent categories of behavior across different States and across the span of time, so they can refer to they can refer to multiple States and multiple concepts and describe the causal relationships between the concepts, which is what we want to do here to create descriptive causal models of typical behavior.",
            "So these are descriptive models, meaning they don't represent the actual mechanisms of change.",
            "That's future work.",
            "So in future work we want to actually represent the physical process models that qualitative proportionalities direct influences between quantities, etc.",
            "So these encapsulate histories are used for reasoning.",
            "By having the participants and the conditions of that in caps and history hold, and then once those hold the facts and the consequences of the in caps and histories are assumed to hold as well, is automatically generated within the system by taking the sequel generalizations from the last Step and parameterising that."
        ],
        [
            "So not all the generalizations that we created.",
            "We created 10.",
            "Remember that are good for causal reasoning.",
            "Some are actually quite poor.",
            "Some generalizations don't capture the relationship between concepts, so therefore building a causal model of something that doesn't relate multiple concepts is not going to be very fruitful for reasoning, so we can actually filter these out.",
            "The first step is to find correlated concepts within a conceptual context.",
            "Means finding concepts where the probability of the concept is above some threshold and at least one general generalization.",
            "Within that context.",
            "We take all such concepts and those become are highly correlated concepts.",
            "But then filter generalizations outside of that context, or filter them out from within the context by using the binary entropy function and testing whether the entropy of the probability of that concept is above the entropy of that threshold and entropy is the right binary entropy is right.",
            "Measure the use here because it measures information gain.",
            "High entropy is low gain, so if generalization is somewhat indecisive with respect to the rule of a highly correlated concept, it should be filtered out."
        ],
        [
            "So we have more proving to do, though now the generalizations since I told you they were probabilistic abstractions, we want to filter out facts below the probability threshold.",
            "We want to use temporal relations also.",
            "The ones that we embedded before properly subsuming etc to hypothesize the causal role of each fact with respect to the concept.",
            "So if the fact starts with or before the concept, the fact might cause the concept.",
            "If fact starts with or after the concept, the concept might cause the fact in fact might be a effect.",
            "If the fact always temporally subsumes the concept, that means that the fact might be a operating condition in the fact might have to hold in order for the concept to hold throughout the entire duration."
        ],
        [
            "So the result of all this is an encapsulated history definition which has participants, conditions and consequences.",
            "Now, the resulting encapsulated histories are actually more general than the initial stimuli.",
            "The initial stimulus.",
            "Very colorful.",
            "It had trucks and cars and kids playing with things and very exciting.",
            "But what's left here is after SQL generalizes things, all of the low probability attributes and relations actually got filtered out, so now we only have the high probability behaviors.",
            "So these described actual behaviors of the instances of these concepts.",
            "These can be used for reasoning about new scenarios, as long as the new scenarios use the same ontology and vocabulary.",
            "As initial learning stimuli.",
            "So when we activate encapsulate history on an instance of a concept.",
            "It's like flagging that concept as normal or typical because these encapsulated histories were learned from experience.",
            "Therefore, that concept instance is typical of previous experience.",
            "Failure to activate any encapsulated history on a concept instance means that it's actually anomalous, since are encapsulated histories represent our kind of Bank of prototypical conceptual instances.",
            "Then, if we can't, if we can't activate encapsulate history, an instance that means that's.",
            "Unexplainable with respect to our previous experience, so these are effective for simple, simple, simple counterfactual reasoning, and for indirect proof."
        ],
        [
            "As I'll show you shortly.",
            "So the result of this, remember, we had 10 generalizations from SQL.",
            "Four of the ten were filtered out for being causally irrelevant.",
            "Remaining six were automatically parameterized into encapsulated histories.",
            "How does that go through some of these briefly?",
            "So in the black in context, we have entity one touch.",
            "Can pushing entity two in the direction in some direction which is blocked by entity three in that direction in terms of pushing context, we have entity one pushing 82 in a direction, causing it to move in the direction of the push and entity one touching and pushing entity two causing sorry caused by anyone moving in this direction and then which results in the entity two moving in that direction.",
            "So it's kind of like billiard ball causality.",
            "For that one and then three for moving as well."
        ],
        [
            "So how do these hold up during reasoning?",
            "Are they similar to student models, etc."
        ],
        [
            "This is the next step to test.",
            "We use two problem solving tasks, one from David Brown's assessment of students mental models involving a book on a table and destinies at all.",
            "His force concept inventory of problem that describing a puck on a frictionless surface.",
            "So that's my sketch up there and that's a question from the test down there, and I think you'll agree that mines a little better problem scenarios were actually provided in the same modalities as a learning stimuli, namely.",
            "The comic strips and English blurbs.",
            "So the simulator reason through both scenarios that problem solving by instantiating an activating all of its encapsulated histories and it also has some contradiction detection.",
            "So we can do indirect proofs.",
            "So we'll compare this results with."
        ],
        [
            "Human results after we look at the human results briefly.",
            "So Brown's task asked 73 high school students whether a table exerts an upward force against a book at rest on the table surface.",
            "The most popular answer was that yes, the table does exert a force, and they provided a nice Newtonian answer there.",
            "It musta counter downward force of the book, or else there'd be acceleration in some direction, and there's not.",
            "So the majority of the students, however, decided that.",
            "The table did not exert an upward force and they gave some varying explanations which Brown kind of grouped into five here, such as gravity pushes the book and the book exerts a force on the table, but the table just supports the book.",
            "It doesn't push.",
            "Also, the table requires energy to push the tables, not pushing or pulling the tables.",
            "Just blocking the book or the book would move if the table did exert a force, which is a nice counter factual explanation there."
        ],
        [
            "From the first concept inventory with force concept inventory in general is a.",
            "Assessment of.",
            "What students believe as to the relations of mass, velocity, acceleration and force.",
            "This is one question from it.",
            "So high school and college students were given the scenario of a poop apuc moving constant velocity along a frictionless surface, which is then given an instantaneous kick, orthogonal or perpendicular to the direction of motion.",
            "So most students said, or most students were incorrect here, but the most popular answer was that.",
            "It would move diagonally, which is also the correct answer."
        ],
        [
            "So before we get into the simulation results, so as far as learning what went as I discussed earlier, there were 17 stimuli with target concepts of pushing movement and blocking.",
            "The thresholds were set as illustrated here and we did all of our learning and reasoning on companions cognitive architecture.",
            "And the output from learning is.",
            "We had 50 concept exemplars, 10 generalizations and six in caps and histories, all generated automatically.",
            "So the system reasoned with these."
        ],
        [
            "Learn models and the system found two active instances of encapsulant history in the table scenario with Brown without even giving it the query yet.",
            "In caps in history was the blocking one that I mentioned before, so entity so gravity pushes the book against the table, but the book blocks the table, saw the table, blocks the book gravity, pushes the table against the ground and the ground blocks the table.",
            "So the system infers that the book pushes the table and at the table pushes the ground.",
            "And that both are being blocked, but in these are novel inferences that weren't actually in the problem scenario when we did give it the query, the system could not conclude naturally at the table pushed the book.",
            "So it tried to do an indirect proof.",
            "It assumed at the table did push against the book and then try to instantiate encapsulated histories and it did activate one.",
            "It used the in caps of history entity one pushing 82 in the direction, causing it to to move in the direction.",
            "And the consequence of this is the book moving upwards, which is not actually visible in this scenario.",
            "So it reached a contradiction.",
            "In comparison with the human results.",
            "The system did conclude that gravity push the book and that the book starts force that pushes the table, but it didn't talk about support because support wasn't learned as a concept here also.",
            "The system did say that the table is blocking the book and the system did come up with a counter factual answer that the book would move if the table exerted a force.",
            "So those that did not come up with a scientifically correct answer it didn't model."
        ],
        [
            "The majority of students actually so.",
            "In terms of the force concept inventory task, here's my drawing of the problem.",
            "System reserved a branch after the SEC state, which then took to be multiple choice so it activated and encapsulate history instance on all these choices to determine which choice is viable.",
            "So the only one that was actually viable was the first choice of the puck moving directly upwards.",
            "So.",
            "It concluded that the foot touches and pushes the puck upwards in the direction, causing the park to move up, and it could not activate any in capsule histories and other choices because of direction mismatches.",
            "So I concluded that a was the correct answer, which was the second most popular answer with students and the most."
        ],
        [
            "Your misconception.",
            "So in conclusion, we've shown a simulation that learns naive qualitative physics models from multimodal stimuli, and it does this by trampling coding examples of concepts, generalizing the concepts, and then qualitative models were generated from the probabilistic abstractions.",
            "This is.",
            "Tested, I'm sorry this resulted in explanations that are compatible with the student explanations on two problem solving tasks and says evidence that night physics models can be learned via analogical generalization with humans or AI system."
        ],
        [
            "In the future, this is a lot to do.",
            "I'd like to incorporate other physical concepts besides movement, pushing, and.",
            "Blocking and complete the whole force concept inventory and in a way that's similar to human um.",
            "Also we would like to go deeper with our domain theories and automatically induce physical process models to develop deeper domain theories.",
            "Also, right now is in batch mode and I'd like to shift this to an anomaly response model so that we can incorporate this with agent interaction with kind of with the Companion of Architecture.",
            "Also, I'm developing a computational process model and conceptual change and learning misconceptions is a big part of that, so this fits nicely into that larger picture."
        ],
        [
            "How?",
            "Our input modalities have been used to learn spatial prepositions and also.",
            "Lockwood does some learning of simple machines with from a Navy Navy manual.",
            "Also, there are computational models that change their concepts, but these don't learn from multimodal stimuli, and they also don't develop realistic misconceptions to start off with.",
            "There are concept learning and causal learning approaches.",
            "While these are machine learning approaches that use.",
            "Can the user input vectors instead of structured representations like we do or multimodal representations and a lot of them use Bayesian networks which are not qualitative models too?"
        ],
        [
            "So thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm still Scott and today I'm talking about learning and reasoning with qualitative models of physical behavior.",
                    "label": 0
                },
                {
                    "sent": "This work was coauthored with Ken Forbis and Jason Taylor at the Qualitative Reasoning Group Northwestern University.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So people have misconceptions about force and motion.",
                    "label": 1
                },
                {
                    "sent": "Lot of researchers have characterized some of these misconceptions is similar to the medieval impetus theory.",
                    "label": 0
                },
                {
                    "sent": "Arista Tilian models of dynamics, so that's still in debate.",
                    "label": 1
                },
                {
                    "sent": "Also in debate is the Systematis city and cohesiveness of these intuitive models.",
                    "label": 1
                },
                {
                    "sent": "But I'm one thing that's pretty obvious is that infants and students don't walk into a classroom with scientifically correct Newtonian models of force and motion.",
                    "label": 0
                },
                {
                    "sent": "So there's also agreement that these intuitive models are qualitative and also tenacious.",
                    "label": 1
                },
                {
                    "sent": "Good performance and proficiency in mathematics and proficiency with physics equations is not indicative of performance on the qualitative side of physics, and also these misconceptions persist after physics instruction in University and in high school, and it also they also persist in honors students as well.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "They learn from experience and this much is.",
                    "label": 0
                },
                {
                    "sent": "Agreed upon the literature.",
                    "label": 0
                },
                {
                    "sent": "When the scientifically incorrect.",
                    "label": 0
                },
                {
                    "sent": "These misconceptions might occur from improperly generalizing or contextual Ising experience, so the question we'd like to answer here is how our naive qualitative models learn from experience, and one Ave that we've identified here is that by temporally encoding examples from experience, analogically generalizing the exemplars, and then parameterising the generalizations, we can actually arrive at.",
                    "label": 1
                },
                {
                    "sent": "Qualitative models of physical behave.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cheers.",
                    "label": 0
                },
                {
                    "sent": "So we've created a computational cognitive model to test this hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Our system is given multi modal input stimuli in the form of sort of comic strips, which I'll describe shortly and a set of target concepts can't sit down, ever.",
                    "label": 1
                },
                {
                    "sent": "In this case the target concepts are moving, pushing and blocking.",
                    "label": 1
                },
                {
                    "sent": "The system automatically learns intuitive models of these target concepts from the given stimuli.",
                    "label": 0
                },
                {
                    "sent": "And we evaluate the models learned by asking our system to perform similar tasks to students from the literature 1 task from Brown and one from Destiny's Atolls Force concept inventory.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it all starts with our multimodal stimuli.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We used Cox cats just like John does for his research.",
                    "label": 0
                },
                {
                    "sent": "Similar here on multistate comic strips, the comic strips are divided into frames like you normally see, and frames are divided by qualitative behaviors, such as when objects start or stop touching started, stop moving or when agent starts or stopped acting.",
                    "label": 1
                },
                {
                    "sent": "We also have temporal relations between the states, the arrows, the annotations there starts after ending of which, though the directionality of arrow seems a little counterintuitive, it's using a relationship opencyc that designates the temporal priority which the system can understand.",
                    "label": 1
                },
                {
                    "sent": "Each stimulus contains one or more example of the target concepts.",
                    "label": 0
                },
                {
                    "sent": "Pushing, moving, or blocking.",
                    "label": 1
                },
                {
                    "sent": "We also have an English blurb which is attached to each stimulus.",
                    "label": 0
                },
                {
                    "sent": "Here the child child 13.",
                    "label": 0
                },
                {
                    "sent": "Is playing with the truck truck 13 so Child 13 and truck 13.",
                    "label": 1
                },
                {
                    "sent": "Those tokens refer to entities or glyphs within the sketch so that the English and the sketch can describe the same scene, the same entities.",
                    "label": 0
                },
                {
                    "sent": "So we use COGS sketch to process the sketch input, an EA Natural Language Understanding Unit also developed in our group to process the simplified English.",
                    "label": 0
                },
                {
                    "sent": "Both of these knowledge capture tools use the open Cyc knowledge base, which is where our ontology nor Cal comes from.",
                    "label": 0
                },
                {
                    "sent": "We have 17 such stimuli used as our learning stimuli.",
                    "label": 0
                },
                {
                    "sent": "All in the same, of course.",
                    "label": 0
                },
                {
                    "sent": "They describe different situations, but they have the same mode.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bodies.",
                    "label": 0
                },
                {
                    "sent": "The next step is to take these stimuli and create temporally encoded exemplars of the concepts, which is all done automat.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As well.",
                    "label": 0
                },
                {
                    "sent": "So at the left we have the sketch I showed you before the comic strip and on the right is a three state expansion of some of these facts.",
                    "label": 0
                },
                {
                    "sent": "Of course it's just a few facts.",
                    "label": 0
                },
                {
                    "sent": "There are many more within this stimulus.",
                    "label": 0
                },
                {
                    "sent": "Some facts spend one state, two states, or all three.",
                    "label": 0
                },
                {
                    "sent": "This is all depending on the presence in the sketch.",
                    "label": 0
                },
                {
                    "sent": "The system's first step is to automatically identify target concepts within this stimulus.",
                    "label": 1
                },
                {
                    "sent": "In this case, it has four.",
                    "label": 0
                },
                {
                    "sent": "Distance of the child pushing the truck to the right.",
                    "label": 1
                },
                {
                    "sent": "The truck pushing the car to the right and the truck in the car, both moving to right.",
                    "label": 0
                },
                {
                    "sent": "In the 3rd state.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After this, so has that create the temple in code examples for each instance.",
                    "label": 0
                },
                {
                    "sent": "So that means we identified four concepts, which means it needs to create 4 exemplars here for the first, for the first concept instance, child pushing the truck to the right.",
                    "label": 0
                },
                {
                    "sent": "Every fact within this stimulus is related somehow temporally to the state of the child pushing the truck.",
                    "label": 0
                },
                {
                    "sent": "The right some of the facts are temporally coterminal, but start before some temporally subsumed this fact.",
                    "label": 0
                },
                {
                    "sent": "Some hold in the same state as a fact and some start after the ending up.",
                    "label": 0
                },
                {
                    "sent": "There's other temporal relations based on Alan's 1983 temporal calculus.",
                    "label": 1
                },
                {
                    "sent": "All of these facts and all of the temporal relations are stored in a new representation for this exemplar, and these temporal relations.",
                    "label": 1
                },
                {
                    "sent": "Add structure to the representation which is useful for analogical reasoning and also for causal reasoning, which I'll discuss later.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we have our exemplars comes the next phase of SQL Generalization.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So SQL is a model of analogical generalization.",
                    "label": 0
                },
                {
                    "sent": "And when the simulation begins, separate context is set up for each target concept.",
                    "label": 0
                },
                {
                    "sent": "So pushing, moving in blocking those are the ones that we gave the system, so it could automatically creates three contexts for generalizations.",
                    "label": 0
                },
                {
                    "sent": "All the exemplars that arrive in the system are associated with that generalization.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry with that context based on which concept instances they represent.",
                    "label": 0
                },
                {
                    "sent": "So for the example.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we just created and last step the child pushing the truck to the right.",
                    "label": 0
                },
                {
                    "sent": "The first step is for sequel to identify the destination context for this issue.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Templar.",
                    "label": 0
                },
                {
                    "sent": "In this case, that's a pushing example, so within the pushing context, the next step is to compare the new exemplar to each generalization that exists, and in the context, using the structure mapping engine, SMAP, and I'll discuss that in a second.",
                    "label": 1
                },
                {
                    "sent": "The first generalization that sequel finds where the SMB similarity score is above some constant threshold, actually merges that exemplar with the generalization, and then the process ends.",
                    "label": 1
                },
                {
                    "sent": "How SMEs operates by having an input of a base and a target representation and then automatically computes mappings here.",
                    "label": 0
                },
                {
                    "sent": "So each mapping has entity and target correspondence is a structural evaluation or similarity score, which is what we use for SQL that determine if it's above a threshold, and it can be normalized, and it also has Canada differences or inferences that can actually be taken from one representation to another based on support from the mapping.",
                    "label": 0
                },
                {
                    "sent": "And the mapping itself is used to merge with the representations along the analogical mapping.",
                    "label": 0
                },
                {
                    "sent": "If however, the exemplar is not similar enough.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To an existing generalization, we sequel compares the Exemplar 2 on generalized exemplars on a simulated exemplars.",
                    "label": 0
                },
                {
                    "sent": "Within that context, if then it's above a constant assimilation threshold, it gets merged into a new generalization, then put into context.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's still structurally dissimilar from all the exemplars.",
                    "label": 0
                },
                {
                    "sent": "Then we just add the exemplar to the list of unassimilated exemplars inside that counts.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the result of doing this?",
                    "label": 1
                },
                {
                    "sent": "We had 17 stimuli and which actually yielded 50 concept exemplars.",
                    "label": 1
                },
                {
                    "sent": "Since there were 50 instances of the concepts within the stimuli, so those exemplars were generalized automatically with SQL, which yielded 10 generalizations and 12 on a simulated exemplars.",
                    "label": 0
                },
                {
                    "sent": "Within all three contexts across all three.",
                    "label": 1
                },
                {
                    "sent": "So the 10 generalizations are.",
                    "label": 0
                },
                {
                    "sent": "Distinct behaviors of each concept instance and or its concept and the other similar.",
                    "label": 0
                },
                {
                    "sent": "Exemplars were instances that weren't very similar to the existing behaviors.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So which generalization?",
                    "label": 0
                },
                {
                    "sent": "There is probabilistic abstractions of their constituent exemplars, so entities that correspond analogically in two exemplars, for example Miranda generalization, become generalized entities or genets here in the generalization.",
                    "label": 1
                },
                {
                    "sent": "So Child 13 and truck 13, which I showed you don't exist inside the abstraction, because they've become.",
                    "label": 0
                },
                {
                    "sent": "They've corresponded something that's already there, so they're abstracted each fact inside the generalization also has an associated probability which reflects the facts frequency in the constituent exemplars.",
                    "label": 1
                },
                {
                    "sent": "The idea here is to capture the central behavior of this generalization and create a formal, qualitative causal model of it.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we choose to, so we build.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Capsule histories from these generalizations we chose the encapsulated history formalism because encapsulated histories can represent categories of behavior across different States and across the span of time, so they can refer to they can refer to multiple States and multiple concepts and describe the causal relationships between the concepts, which is what we want to do here to create descriptive causal models of typical behavior.",
                    "label": 1
                },
                {
                    "sent": "So these are descriptive models, meaning they don't represent the actual mechanisms of change.",
                    "label": 0
                },
                {
                    "sent": "That's future work.",
                    "label": 0
                },
                {
                    "sent": "So in future work we want to actually represent the physical process models that qualitative proportionalities direct influences between quantities, etc.",
                    "label": 1
                },
                {
                    "sent": "So these encapsulate histories are used for reasoning.",
                    "label": 0
                },
                {
                    "sent": "By having the participants and the conditions of that in caps and history hold, and then once those hold the facts and the consequences of the in caps and histories are assumed to hold as well, is automatically generated within the system by taking the sequel generalizations from the last Step and parameterising that.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So not all the generalizations that we created.",
                    "label": 1
                },
                {
                    "sent": "We created 10.",
                    "label": 0
                },
                {
                    "sent": "Remember that are good for causal reasoning.",
                    "label": 1
                },
                {
                    "sent": "Some are actually quite poor.",
                    "label": 1
                },
                {
                    "sent": "Some generalizations don't capture the relationship between concepts, so therefore building a causal model of something that doesn't relate multiple concepts is not going to be very fruitful for reasoning, so we can actually filter these out.",
                    "label": 1
                },
                {
                    "sent": "The first step is to find correlated concepts within a conceptual context.",
                    "label": 0
                },
                {
                    "sent": "Means finding concepts where the probability of the concept is above some threshold and at least one general generalization.",
                    "label": 0
                },
                {
                    "sent": "Within that context.",
                    "label": 0
                },
                {
                    "sent": "We take all such concepts and those become are highly correlated concepts.",
                    "label": 0
                },
                {
                    "sent": "But then filter generalizations outside of that context, or filter them out from within the context by using the binary entropy function and testing whether the entropy of the probability of that concept is above the entropy of that threshold and entropy is the right binary entropy is right.",
                    "label": 0
                },
                {
                    "sent": "Measure the use here because it measures information gain.",
                    "label": 0
                },
                {
                    "sent": "High entropy is low gain, so if generalization is somewhat indecisive with respect to the rule of a highly correlated concept, it should be filtered out.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have more proving to do, though now the generalizations since I told you they were probabilistic abstractions, we want to filter out facts below the probability threshold.",
                    "label": 0
                },
                {
                    "sent": "We want to use temporal relations also.",
                    "label": 1
                },
                {
                    "sent": "The ones that we embedded before properly subsuming etc to hypothesize the causal role of each fact with respect to the concept.",
                    "label": 1
                },
                {
                    "sent": "So if the fact starts with or before the concept, the fact might cause the concept.",
                    "label": 0
                },
                {
                    "sent": "If fact starts with or after the concept, the concept might cause the fact in fact might be a effect.",
                    "label": 1
                },
                {
                    "sent": "If the fact always temporally subsumes the concept, that means that the fact might be a operating condition in the fact might have to hold in order for the concept to hold throughout the entire duration.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the result of all this is an encapsulated history definition which has participants, conditions and consequences.",
                    "label": 0
                },
                {
                    "sent": "Now, the resulting encapsulated histories are actually more general than the initial stimuli.",
                    "label": 1
                },
                {
                    "sent": "The initial stimulus.",
                    "label": 0
                },
                {
                    "sent": "Very colorful.",
                    "label": 0
                },
                {
                    "sent": "It had trucks and cars and kids playing with things and very exciting.",
                    "label": 1
                },
                {
                    "sent": "But what's left here is after SQL generalizes things, all of the low probability attributes and relations actually got filtered out, so now we only have the high probability behaviors.",
                    "label": 1
                },
                {
                    "sent": "So these described actual behaviors of the instances of these concepts.",
                    "label": 0
                },
                {
                    "sent": "These can be used for reasoning about new scenarios, as long as the new scenarios use the same ontology and vocabulary.",
                    "label": 1
                },
                {
                    "sent": "As initial learning stimuli.",
                    "label": 0
                },
                {
                    "sent": "So when we activate encapsulate history on an instance of a concept.",
                    "label": 0
                },
                {
                    "sent": "It's like flagging that concept as normal or typical because these encapsulated histories were learned from experience.",
                    "label": 1
                },
                {
                    "sent": "Therefore, that concept instance is typical of previous experience.",
                    "label": 0
                },
                {
                    "sent": "Failure to activate any encapsulated history on a concept instance means that it's actually anomalous, since are encapsulated histories represent our kind of Bank of prototypical conceptual instances.",
                    "label": 1
                },
                {
                    "sent": "Then, if we can't, if we can't activate encapsulate history, an instance that means that's.",
                    "label": 0
                },
                {
                    "sent": "Unexplainable with respect to our previous experience, so these are effective for simple, simple, simple counterfactual reasoning, and for indirect proof.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As I'll show you shortly.",
                    "label": 0
                },
                {
                    "sent": "So the result of this, remember, we had 10 generalizations from SQL.",
                    "label": 0
                },
                {
                    "sent": "Four of the ten were filtered out for being causally irrelevant.",
                    "label": 1
                },
                {
                    "sent": "Remaining six were automatically parameterized into encapsulated histories.",
                    "label": 0
                },
                {
                    "sent": "How does that go through some of these briefly?",
                    "label": 0
                },
                {
                    "sent": "So in the black in context, we have entity one touch.",
                    "label": 0
                },
                {
                    "sent": "Can pushing entity two in the direction in some direction which is blocked by entity three in that direction in terms of pushing context, we have entity one pushing 82 in a direction, causing it to move in the direction of the push and entity one touching and pushing entity two causing sorry caused by anyone moving in this direction and then which results in the entity two moving in that direction.",
                    "label": 1
                },
                {
                    "sent": "So it's kind of like billiard ball causality.",
                    "label": 0
                },
                {
                    "sent": "For that one and then three for moving as well.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do these hold up during reasoning?",
                    "label": 0
                },
                {
                    "sent": "Are they similar to student models, etc.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the next step to test.",
                    "label": 0
                },
                {
                    "sent": "We use two problem solving tasks, one from David Brown's assessment of students mental models involving a book on a table and destinies at all.",
                    "label": 1
                },
                {
                    "sent": "His force concept inventory of problem that describing a puck on a frictionless surface.",
                    "label": 0
                },
                {
                    "sent": "So that's my sketch up there and that's a question from the test down there, and I think you'll agree that mines a little better problem scenarios were actually provided in the same modalities as a learning stimuli, namely.",
                    "label": 1
                },
                {
                    "sent": "The comic strips and English blurbs.",
                    "label": 1
                },
                {
                    "sent": "So the simulator reason through both scenarios that problem solving by instantiating an activating all of its encapsulated histories and it also has some contradiction detection.",
                    "label": 0
                },
                {
                    "sent": "So we can do indirect proofs.",
                    "label": 0
                },
                {
                    "sent": "So we'll compare this results with.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Human results after we look at the human results briefly.",
                    "label": 0
                },
                {
                    "sent": "So Brown's task asked 73 high school students whether a table exerts an upward force against a book at rest on the table surface.",
                    "label": 1
                },
                {
                    "sent": "The most popular answer was that yes, the table does exert a force, and they provided a nice Newtonian answer there.",
                    "label": 0
                },
                {
                    "sent": "It musta counter downward force of the book, or else there'd be acceleration in some direction, and there's not.",
                    "label": 0
                },
                {
                    "sent": "So the majority of the students, however, decided that.",
                    "label": 0
                },
                {
                    "sent": "The table did not exert an upward force and they gave some varying explanations which Brown kind of grouped into five here, such as gravity pushes the book and the book exerts a force on the table, but the table just supports the book.",
                    "label": 1
                },
                {
                    "sent": "It doesn't push.",
                    "label": 1
                },
                {
                    "sent": "Also, the table requires energy to push the tables, not pushing or pulling the tables.",
                    "label": 0
                },
                {
                    "sent": "Just blocking the book or the book would move if the table did exert a force, which is a nice counter factual explanation there.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From the first concept inventory with force concept inventory in general is a.",
                    "label": 1
                },
                {
                    "sent": "Assessment of.",
                    "label": 0
                },
                {
                    "sent": "What students believe as to the relations of mass, velocity, acceleration and force.",
                    "label": 0
                },
                {
                    "sent": "This is one question from it.",
                    "label": 0
                },
                {
                    "sent": "So high school and college students were given the scenario of a poop apuc moving constant velocity along a frictionless surface, which is then given an instantaneous kick, orthogonal or perpendicular to the direction of motion.",
                    "label": 1
                },
                {
                    "sent": "So most students said, or most students were incorrect here, but the most popular answer was that.",
                    "label": 0
                },
                {
                    "sent": "It would move diagonally, which is also the correct answer.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before we get into the simulation results, so as far as learning what went as I discussed earlier, there were 17 stimuli with target concepts of pushing movement and blocking.",
                    "label": 0
                },
                {
                    "sent": "The thresholds were set as illustrated here and we did all of our learning and reasoning on companions cognitive architecture.",
                    "label": 1
                },
                {
                    "sent": "And the output from learning is.",
                    "label": 0
                },
                {
                    "sent": "We had 50 concept exemplars, 10 generalizations and six in caps and histories, all generated automatically.",
                    "label": 1
                },
                {
                    "sent": "So the system reasoned with these.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learn models and the system found two active instances of encapsulant history in the table scenario with Brown without even giving it the query yet.",
                    "label": 1
                },
                {
                    "sent": "In caps in history was the blocking one that I mentioned before, so entity so gravity pushes the book against the table, but the book blocks the table, saw the table, blocks the book gravity, pushes the table against the ground and the ground blocks the table.",
                    "label": 1
                },
                {
                    "sent": "So the system infers that the book pushes the table and at the table pushes the ground.",
                    "label": 1
                },
                {
                    "sent": "And that both are being blocked, but in these are novel inferences that weren't actually in the problem scenario when we did give it the query, the system could not conclude naturally at the table pushed the book.",
                    "label": 0
                },
                {
                    "sent": "So it tried to do an indirect proof.",
                    "label": 0
                },
                {
                    "sent": "It assumed at the table did push against the book and then try to instantiate encapsulated histories and it did activate one.",
                    "label": 0
                },
                {
                    "sent": "It used the in caps of history entity one pushing 82 in the direction, causing it to to move in the direction.",
                    "label": 1
                },
                {
                    "sent": "And the consequence of this is the book moving upwards, which is not actually visible in this scenario.",
                    "label": 0
                },
                {
                    "sent": "So it reached a contradiction.",
                    "label": 0
                },
                {
                    "sent": "In comparison with the human results.",
                    "label": 0
                },
                {
                    "sent": "The system did conclude that gravity push the book and that the book starts force that pushes the table, but it didn't talk about support because support wasn't learned as a concept here also.",
                    "label": 0
                },
                {
                    "sent": "The system did say that the table is blocking the book and the system did come up with a counter factual answer that the book would move if the table exerted a force.",
                    "label": 1
                },
                {
                    "sent": "So those that did not come up with a scientifically correct answer it didn't model.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The majority of students actually so.",
                    "label": 0
                },
                {
                    "sent": "In terms of the force concept inventory task, here's my drawing of the problem.",
                    "label": 1
                },
                {
                    "sent": "System reserved a branch after the SEC state, which then took to be multiple choice so it activated and encapsulate history instance on all these choices to determine which choice is viable.",
                    "label": 1
                },
                {
                    "sent": "So the only one that was actually viable was the first choice of the puck moving directly upwards.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It concluded that the foot touches and pushes the puck upwards in the direction, causing the park to move up, and it could not activate any in capsule histories and other choices because of direction mismatches.",
                    "label": 1
                },
                {
                    "sent": "So I concluded that a was the correct answer, which was the second most popular answer with students and the most.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Your misconception.",
                    "label": 0
                },
                {
                    "sent": "So in conclusion, we've shown a simulation that learns naive qualitative physics models from multimodal stimuli, and it does this by trampling coding examples of concepts, generalizing the concepts, and then qualitative models were generated from the probabilistic abstractions.",
                    "label": 1
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "Tested, I'm sorry this resulted in explanations that are compatible with the student explanations on two problem solving tasks and says evidence that night physics models can be learned via analogical generalization with humans or AI system.",
                    "label": 1
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the future, this is a lot to do.",
                    "label": 0
                },
                {
                    "sent": "I'd like to incorporate other physical concepts besides movement, pushing, and.",
                    "label": 1
                },
                {
                    "sent": "Blocking and complete the whole force concept inventory and in a way that's similar to human um.",
                    "label": 1
                },
                {
                    "sent": "Also we would like to go deeper with our domain theories and automatically induce physical process models to develop deeper domain theories.",
                    "label": 1
                },
                {
                    "sent": "Also, right now is in batch mode and I'd like to shift this to an anomaly response model so that we can incorporate this with agent interaction with kind of with the Companion of Architecture.",
                    "label": 0
                },
                {
                    "sent": "Also, I'm developing a computational process model and conceptual change and learning misconceptions is a big part of that, so this fits nicely into that larger picture.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "Our input modalities have been used to learn spatial prepositions and also.",
                    "label": 0
                },
                {
                    "sent": "Lockwood does some learning of simple machines with from a Navy Navy manual.",
                    "label": 0
                },
                {
                    "sent": "Also, there are computational models that change their concepts, but these don't learn from multimodal stimuli, and they also don't develop realistic misconceptions to start off with.",
                    "label": 0
                },
                {
                    "sent": "There are concept learning and causal learning approaches.",
                    "label": 0
                },
                {
                    "sent": "While these are machine learning approaches that use.",
                    "label": 0
                },
                {
                    "sent": "Can the user input vectors instead of structured representations like we do or multimodal representations and a lot of them use Bayesian networks which are not qualitative models too?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thank you.",
                    "label": 0
                }
            ]
        }
    }
}