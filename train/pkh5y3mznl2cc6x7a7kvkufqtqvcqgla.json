{
    "id": "pkh5y3mznl2cc6x7a7kvkufqtqvcqgla",
    "title": "Food Recognition Using Statistics of Pairwise Local Features",
    "info": {
        "author": [
            "Shulin (Lynn) Yang, Department of Computer Science and Engineering, University of Washington"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Object Recognition"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_yang_frus/",
    "segmentation": [
        [
            "Our work is motivated from 2 aspects.",
            "First, food recognition itself is a very interesting and challenging computer vision problem.",
            "You can see from the images.",
            "Food items has a highly varied appearance and also the inner structure of the food item is very deformable but important in determining is type.",
            "So this makes it different from the general domain of object recognition and on the other aspect solution to this problem can be used for in many applications.",
            "Such as ability control, diatomite monitoring, and so on."
        ],
        [
            "So to tackle this problem.",
            "There are mainly two challenges.",
            "The first challenge is how can we identify all the food ingredients from the.",
            "For the pixels you can see from the image in the first line bread exhibit a great variety at the pixel level, and it's hard to determine whether a pixel is Brad Pixel or not, and the second challenges.",
            "Even if you identified the food ingredients, how can we represent the spatial relationship between the food ingredients you can see from image in the second line, the relative location of the lattice and Brad various lot, while these three images are the same type of food.",
            "And it's hard to represent even any of this spatial jump relationship."
        ],
        [
            "And since it's not a typical recognition problem, there have been relatively little work in this area, and these are the relative work we found in 2009 last year of fast food data set has been collected and previous to that there also systems targeting at food recognition.",
            "But those systems either focused either on single food object, such as recognizing apples and orange, or their semi automatic and request human interaction and our system different from that.",
            "Focused at the complicated man, made fast food and the classification of food is automatic is fully automatic."
        ],
        [
            "So this is the basic flow of our approach.",
            "We started from the food images and we will first label all the image pixels two to several basic category of food ingredients like bread tomato trees which are coming in fast food and then we were trying to propose an image representation which to capture the geometric relationship between different food ingredients.",
            "And after we done that, we will classify image using the image presentation from the previous step."
        ],
        [
            "So these are the images we used.",
            "There are real there photos of real food."
        ],
        [
            "And then to label the image pixel."
        ],
        [
            "We selected night types of food ingredient which we think are common, commonly appeared in fast foods, and then we use a soft way to label other image pixels, which means using a vector of probabilities to represent the likelihood each pixels each pixel belong to each category, and these images are visualization of the soft labeling.",
            "Each Gray image represents an ingredient, food, ingredient type and the brighter pixel.",
            "Is the larger the probability this pixel belongs to this food ingredient category and here the soft labels might be wrong, but it gives it enough information for our approach and we don't require a perfect perfect passing at the pixel level.",
            "So the soft label can be solved in many ways and here we use it works.",
            "Semantic tech stone forest from the work into CPR 2008.",
            "This method soft label or pixels based on some local low level information such as the color information of the nearby pixels.",
            "So after."
        ],
        [
            "Our pixels has been labeled to the categories we try to.",
            "Represent their geometric relationship of the ingredient of the food ingredients and we can see the hard task to do to do that, because you can see the soft label result.",
            "Different ingredient pixels are mixed with each other."
        ],
        [
            "So."
        ],
        [
            "So here we use what we called pairwise feature distribution.",
            "The pairwise feature simply means."
        ],
        [
            "Any feature that involves two pixels at the same time, for example, the pairwise feature of Brad Pixel and tomato pixel can be their distance."
        ],
        [
            "So this is a very intuitive and simple feature, so we extract such feature for all type for all ingredient pairs, pairs of ingredients such As for bread and tomato and veg."
        ],
        [
            "Opponent beef and so on, and here distance is just one simple feature."
        ],
        [
            "Can also use other simple other pairwise features like the orientation of the line segment connecting each pair of points or the midpoint category, which means the category of the the ingredient category of the midpoint of each pair, or the ingredient category of other points between each pair."
        ],
        [
            "And so after we extracted the pairwise features for our point pals, we were collecting the statistics of this pairwise features.",
            "These these statistics are used to represent some shape regularity between our ingredient pals and such as how often would a bread and pixel with a distance of 10 pick.",
            "With a distance of 10 pixels appear be seen.",
            "In the image and, these statistics are represented as histograms."
        ],
        [
            "For example, this bread and tomato histogram.",
            "It counts the number of.",
            "It counts number of tomato and bread pal with certain distance in the image.",
            "So.",
            "Each pixel PAL will contribute to a.",
            "In the histogram, based on its future value, here it is there distance and waited by the soft label of these two points."
        ],
        [
            "And.",
            "This is we can also construct the histogram for other pairs of ingredients.",
            "This is a tomato and bread."
        ],
        [
            "And also we can do."
        ],
        [
            "For beef and cheese."
        ],
        [
            "Beef and bread and so on."
        ],
        [
            "And we can also replace the distance feature with other feature as we mentioned above like orientation and midpoint."
        ],
        [
            "So till now we have the image represented as a bunch of histograms and now we want to classify all the image based on this representation."
        ],
        [
            "And here we just use this SVM with precomputed classical kernel.",
            "Casco is used here to compute histogram distance and then the image distance.",
            "Image similarity is calculated as the sum of casco distance of all their corresponding histograms."
        ],
        [
            "So back to the main framework.",
            "We started from food image and we soft labeled other pixels and represent all the image as histograms and at last we classify them to some specific food type."
        ],
        [
            "So we test our algorithm on the PF ID Pittsburgh fast food image data set in this state that there are 61 category.",
            "The 60 one categories of fast food from 13 chain restaurants.",
            "These are very specific type of fast food such as spicy chicken from Wendy's Italian sandwich from subway and so on.",
            "And in each category they are three instances.",
            "Three different object item and for each one six photos are taken from 6 different angle and so this data set covers most common type of fast food and such as sandwich salad tricking.",
            "And we use the stage set version with background with background segmented from the food item.",
            "And."
        ],
        [
            "Then in the soft label step we use STF with the input of 16 manually labeled image and the algorithm will automatically generate the soft labels for other images.",
            "For other image in the data set."
        ],
        [
            "And then we for classification we trained it on 2/3 of the data set using using two instance from each category and using the other one for testing and did a three fold cross validation and then classic classification is based on 2 two ways to for category definition.",
            "The first is using the original 61 for the category and then we group these 60 one categories into seven major types.",
            "As you can see here and perform classification based on this.",
            "Larger groups."
        ],
        [
            "This is a result on 60 one categories we can see.",
            "This is a very hard problem."
        ],
        [
            "Because the chance accuracy is only 1.6%.",
            "And so for comparison, we implemented 2 baseline approaches, color, histogram and bag of SIFT features.",
            "And then we conducted experiments using our algorithm with the parallel with the full power feature as we mentioned before alone and then you and then for the combination of some of them and we can see the best performance is achieved that using the pairwise feature with distance, orientation and midpoint together.",
            "And this is more than double the accuracy of the.",
            "Baseline approach."
        ],
        [
            "And this is the result on classification on the seven major groups, and we can see our best result outperforms the baseline approaches for.",
            "Over 20%."
        ],
        [
            "So after this we want to test how our approach can generalize to other computer vision problem.",
            "So we tested tested it on scene recognition, seeing image and food image are very similar, have some similar characteristics because you can see the see image also composed of some basic ingredients such as the cost thing has the Sky has water trees and also the geometric geometric relationship between the ingredients are very similar to what food images has.",
            "And so we tested it on the MIT Outdoor data set."
        ],
        [
            "So in implementation we selected 10 basic ingredients.",
            "Which are the basic elements in seeing images and then use semantic texton forests too soft label and to test how the pairwise feature works, we first combined the pairwise feature together with the gist feature and and perform classification and compare its result with using this feature alone, our preliminary results shows that the accuracy is boosted about 3% by adding our pairwise feature."
        ],
        [
            "So in conclusion, when we proposed the use of statistical pairwise features to try to capture the shape regularity in images and we apply this method to fool the recognition problem, an hour experiment result shows that we outperform the baseline approaches a lot by using our method.",
            "So in future there are several things we can do.",
            "We can design and test some new pairwise features.",
            "We can generalize our approach to some other vision.",
            "Problems and we can build some real applications for food.",
            "Thanks."
        ],
        [
            "You're welcome to our post to discuss.",
            "Will you offering some food at your foster?",
            "So will questions.",
            "Yeah, nice work.",
            "I want to ask you the invariant by is your image representation is invariant to perspective distortion or off invariant invariant two what?",
            "A friendly perspective distortion because your image representation uses angle of the OR distance of local features.",
            "Yeah, our features like orientation or distance on all normalized.",
            "Those are details and they didn't mention here.",
            "So and for the perspective because in our data set there are photos from all different perspective, like for each item they are six photos from different angles, so it covers most of the protective.",
            "OK so no questions.",
            "So you compare it in the data set of fast foods food, right?",
            "And I think this food is very similar in appearance from because there is like the standard procedure how it's made right?",
            "So.",
            "You think your method would apply to food estate and made it like in homemade conditions, which is like more varying and also don't you think like for this kind of data, nearest neighbor approach would work very well because like Big Mac looks always like a Big Mac, it's very standard.",
            "Well, this data set is also difficult in that there's Big Mac, but there's also some very similar looking burgers from Wendy's or from other places.",
            "And away or Brad covers was inside is hard.",
            "Sometimes it's hard to see what's inside, so it's hard as well.",
            "And for the homemade homemade, I think first you will need new training data because this is trained on this and tested on this, it will not generate.",
            "You can directly use this classifier 2 for others, but if you train on more data it can be generalized.",
            "Tofu burger with the foyer system.",
            "You know, tough burger.",
            "Just one comment.",
            "I think it's three.",
            "PR has always been very colorful and fun and I'm happy to see that becoming tasteful as well.",
            "Thanks.",
            "OK, so let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our work is motivated from 2 aspects.",
                    "label": 0
                },
                {
                    "sent": "First, food recognition itself is a very interesting and challenging computer vision problem.",
                    "label": 1
                },
                {
                    "sent": "You can see from the images.",
                    "label": 0
                },
                {
                    "sent": "Food items has a highly varied appearance and also the inner structure of the food item is very deformable but important in determining is type.",
                    "label": 0
                },
                {
                    "sent": "So this makes it different from the general domain of object recognition and on the other aspect solution to this problem can be used for in many applications.",
                    "label": 1
                },
                {
                    "sent": "Such as ability control, diatomite monitoring, and so on.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to tackle this problem.",
                    "label": 0
                },
                {
                    "sent": "There are mainly two challenges.",
                    "label": 0
                },
                {
                    "sent": "The first challenge is how can we identify all the food ingredients from the.",
                    "label": 0
                },
                {
                    "sent": "For the pixels you can see from the image in the first line bread exhibit a great variety at the pixel level, and it's hard to determine whether a pixel is Brad Pixel or not, and the second challenges.",
                    "label": 0
                },
                {
                    "sent": "Even if you identified the food ingredients, how can we represent the spatial relationship between the food ingredients you can see from image in the second line, the relative location of the lattice and Brad various lot, while these three images are the same type of food.",
                    "label": 1
                },
                {
                    "sent": "And it's hard to represent even any of this spatial jump relationship.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And since it's not a typical recognition problem, there have been relatively little work in this area, and these are the relative work we found in 2009 last year of fast food data set has been collected and previous to that there also systems targeting at food recognition.",
                    "label": 0
                },
                {
                    "sent": "But those systems either focused either on single food object, such as recognizing apples and orange, or their semi automatic and request human interaction and our system different from that.",
                    "label": 0
                },
                {
                    "sent": "Focused at the complicated man, made fast food and the classification of food is automatic is fully automatic.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the basic flow of our approach.",
                    "label": 0
                },
                {
                    "sent": "We started from the food images and we will first label all the image pixels two to several basic category of food ingredients like bread tomato trees which are coming in fast food and then we were trying to propose an image representation which to capture the geometric relationship between different food ingredients.",
                    "label": 1
                },
                {
                    "sent": "And after we done that, we will classify image using the image presentation from the previous step.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are the images we used.",
                    "label": 0
                },
                {
                    "sent": "There are real there photos of real food.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then to label the image pixel.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We selected night types of food ingredient which we think are common, commonly appeared in fast foods, and then we use a soft way to label other image pixels, which means using a vector of probabilities to represent the likelihood each pixels each pixel belong to each category, and these images are visualization of the soft labeling.",
                    "label": 1
                },
                {
                    "sent": "Each Gray image represents an ingredient, food, ingredient type and the brighter pixel.",
                    "label": 1
                },
                {
                    "sent": "Is the larger the probability this pixel belongs to this food ingredient category and here the soft labels might be wrong, but it gives it enough information for our approach and we don't require a perfect perfect passing at the pixel level.",
                    "label": 0
                },
                {
                    "sent": "So the soft label can be solved in many ways and here we use it works.",
                    "label": 0
                },
                {
                    "sent": "Semantic tech stone forest from the work into CPR 2008.",
                    "label": 0
                },
                {
                    "sent": "This method soft label or pixels based on some local low level information such as the color information of the nearby pixels.",
                    "label": 0
                },
                {
                    "sent": "So after.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our pixels has been labeled to the categories we try to.",
                    "label": 0
                },
                {
                    "sent": "Represent their geometric relationship of the ingredient of the food ingredients and we can see the hard task to do to do that, because you can see the soft label result.",
                    "label": 0
                },
                {
                    "sent": "Different ingredient pixels are mixed with each other.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here we use what we called pairwise feature distribution.",
                    "label": 0
                },
                {
                    "sent": "The pairwise feature simply means.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any feature that involves two pixels at the same time, for example, the pairwise feature of Brad Pixel and tomato pixel can be their distance.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a very intuitive and simple feature, so we extract such feature for all type for all ingredient pairs, pairs of ingredients such As for bread and tomato and veg.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Opponent beef and so on, and here distance is just one simple feature.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can also use other simple other pairwise features like the orientation of the line segment connecting each pair of points or the midpoint category, which means the category of the the ingredient category of the midpoint of each pair, or the ingredient category of other points between each pair.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so after we extracted the pairwise features for our point pals, we were collecting the statistics of this pairwise features.",
                    "label": 0
                },
                {
                    "sent": "These these statistics are used to represent some shape regularity between our ingredient pals and such as how often would a bread and pixel with a distance of 10 pick.",
                    "label": 0
                },
                {
                    "sent": "With a distance of 10 pixels appear be seen.",
                    "label": 0
                },
                {
                    "sent": "In the image and, these statistics are represented as histograms.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, this bread and tomato histogram.",
                    "label": 0
                },
                {
                    "sent": "It counts the number of.",
                    "label": 0
                },
                {
                    "sent": "It counts number of tomato and bread pal with certain distance in the image.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Each pixel PAL will contribute to a.",
                    "label": 0
                },
                {
                    "sent": "In the histogram, based on its future value, here it is there distance and waited by the soft label of these two points.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This is we can also construct the histogram for other pairs of ingredients.",
                    "label": 0
                },
                {
                    "sent": "This is a tomato and bread.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also we can do.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For beef and cheese.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Beef and bread and so on.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can also replace the distance feature with other feature as we mentioned above like orientation and midpoint.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So till now we have the image represented as a bunch of histograms and now we want to classify all the image based on this representation.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here we just use this SVM with precomputed classical kernel.",
                    "label": 0
                },
                {
                    "sent": "Casco is used here to compute histogram distance and then the image distance.",
                    "label": 0
                },
                {
                    "sent": "Image similarity is calculated as the sum of casco distance of all their corresponding histograms.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So back to the main framework.",
                    "label": 0
                },
                {
                    "sent": "We started from food image and we soft labeled other pixels and represent all the image as histograms and at last we classify them to some specific food type.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we test our algorithm on the PF ID Pittsburgh fast food image data set in this state that there are 61 category.",
                    "label": 0
                },
                {
                    "sent": "The 60 one categories of fast food from 13 chain restaurants.",
                    "label": 1
                },
                {
                    "sent": "These are very specific type of fast food such as spicy chicken from Wendy's Italian sandwich from subway and so on.",
                    "label": 1
                },
                {
                    "sent": "And in each category they are three instances.",
                    "label": 0
                },
                {
                    "sent": "Three different object item and for each one six photos are taken from 6 different angle and so this data set covers most common type of fast food and such as sandwich salad tricking.",
                    "label": 0
                },
                {
                    "sent": "And we use the stage set version with background with background segmented from the food item.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then in the soft label step we use STF with the input of 16 manually labeled image and the algorithm will automatically generate the soft labels for other images.",
                    "label": 0
                },
                {
                    "sent": "For other image in the data set.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we for classification we trained it on 2/3 of the data set using using two instance from each category and using the other one for testing and did a three fold cross validation and then classic classification is based on 2 two ways to for category definition.",
                    "label": 0
                },
                {
                    "sent": "The first is using the original 61 for the category and then we group these 60 one categories into seven major types.",
                    "label": 0
                },
                {
                    "sent": "As you can see here and perform classification based on this.",
                    "label": 0
                },
                {
                    "sent": "Larger groups.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a result on 60 one categories we can see.",
                    "label": 0
                },
                {
                    "sent": "This is a very hard problem.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because the chance accuracy is only 1.6%.",
                    "label": 0
                },
                {
                    "sent": "And so for comparison, we implemented 2 baseline approaches, color, histogram and bag of SIFT features.",
                    "label": 0
                },
                {
                    "sent": "And then we conducted experiments using our algorithm with the parallel with the full power feature as we mentioned before alone and then you and then for the combination of some of them and we can see the best performance is achieved that using the pairwise feature with distance, orientation and midpoint together.",
                    "label": 0
                },
                {
                    "sent": "And this is more than double the accuracy of the.",
                    "label": 0
                },
                {
                    "sent": "Baseline approach.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the result on classification on the seven major groups, and we can see our best result outperforms the baseline approaches for.",
                    "label": 0
                },
                {
                    "sent": "Over 20%.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So after this we want to test how our approach can generalize to other computer vision problem.",
                    "label": 0
                },
                {
                    "sent": "So we tested tested it on scene recognition, seeing image and food image are very similar, have some similar characteristics because you can see the see image also composed of some basic ingredients such as the cost thing has the Sky has water trees and also the geometric geometric relationship between the ingredients are very similar to what food images has.",
                    "label": 1
                },
                {
                    "sent": "And so we tested it on the MIT Outdoor data set.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in implementation we selected 10 basic ingredients.",
                    "label": 0
                },
                {
                    "sent": "Which are the basic elements in seeing images and then use semantic texton forests too soft label and to test how the pairwise feature works, we first combined the pairwise feature together with the gist feature and and perform classification and compare its result with using this feature alone, our preliminary results shows that the accuracy is boosted about 3% by adding our pairwise feature.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, when we proposed the use of statistical pairwise features to try to capture the shape regularity in images and we apply this method to fool the recognition problem, an hour experiment result shows that we outperform the baseline approaches a lot by using our method.",
                    "label": 0
                },
                {
                    "sent": "So in future there are several things we can do.",
                    "label": 0
                },
                {
                    "sent": "We can design and test some new pairwise features.",
                    "label": 1
                },
                {
                    "sent": "We can generalize our approach to some other vision.",
                    "label": 0
                },
                {
                    "sent": "Problems and we can build some real applications for food.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You're welcome to our post to discuss.",
                    "label": 0
                },
                {
                    "sent": "Will you offering some food at your foster?",
                    "label": 0
                },
                {
                    "sent": "So will questions.",
                    "label": 0
                },
                {
                    "sent": "Yeah, nice work.",
                    "label": 0
                },
                {
                    "sent": "I want to ask you the invariant by is your image representation is invariant to perspective distortion or off invariant invariant two what?",
                    "label": 0
                },
                {
                    "sent": "A friendly perspective distortion because your image representation uses angle of the OR distance of local features.",
                    "label": 0
                },
                {
                    "sent": "Yeah, our features like orientation or distance on all normalized.",
                    "label": 0
                },
                {
                    "sent": "Those are details and they didn't mention here.",
                    "label": 0
                },
                {
                    "sent": "So and for the perspective because in our data set there are photos from all different perspective, like for each item they are six photos from different angles, so it covers most of the protective.",
                    "label": 0
                },
                {
                    "sent": "OK so no questions.",
                    "label": 0
                },
                {
                    "sent": "So you compare it in the data set of fast foods food, right?",
                    "label": 0
                },
                {
                    "sent": "And I think this food is very similar in appearance from because there is like the standard procedure how it's made right?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You think your method would apply to food estate and made it like in homemade conditions, which is like more varying and also don't you think like for this kind of data, nearest neighbor approach would work very well because like Big Mac looks always like a Big Mac, it's very standard.",
                    "label": 0
                },
                {
                    "sent": "Well, this data set is also difficult in that there's Big Mac, but there's also some very similar looking burgers from Wendy's or from other places.",
                    "label": 0
                },
                {
                    "sent": "And away or Brad covers was inside is hard.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's hard to see what's inside, so it's hard as well.",
                    "label": 0
                },
                {
                    "sent": "And for the homemade homemade, I think first you will need new training data because this is trained on this and tested on this, it will not generate.",
                    "label": 0
                },
                {
                    "sent": "You can directly use this classifier 2 for others, but if you train on more data it can be generalized.",
                    "label": 0
                },
                {
                    "sent": "Tofu burger with the foyer system.",
                    "label": 0
                },
                {
                    "sent": "You know, tough burger.",
                    "label": 0
                },
                {
                    "sent": "Just one comment.",
                    "label": 0
                },
                {
                    "sent": "I think it's three.",
                    "label": 0
                },
                {
                    "sent": "PR has always been very colorful and fun and I'm happy to see that becoming tasteful as well.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}