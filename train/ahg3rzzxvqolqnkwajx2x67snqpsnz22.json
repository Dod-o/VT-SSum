{
    "id": "ahg3rzzxvqolqnkwajx2x67snqpsnz22",
    "title": "Collective Annotation of Wikipedia Entities in Web Text",
    "info": {
        "author": [
            "Sayali Kulkarni, Department of Computer Science and Engineering, Indian Institute of Technology Bombay"
        ],
        "published": "Sept. 14, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Data Mining->Social Content"
        ]
    },
    "url": "http://videolectures.net/kdd09_chakrabarti_caowe/",
    "segmentation": [
        [
            "Good afternoon everyone.",
            "So I'm slightly from Indian Institute of Technology, Bombay.",
            "Today I'll be presenting our work on a collective annotation of Wikipedia entities in web text.",
            "This is jointly done with Amit Singh and with the guidance of Professor Ganesh Rama Krishnan professor so major property."
        ],
        [
            "So to begin, the aim of developing this system is to perform aggressive open domain annotations in unstructured web text and identify entities which are which can be linked to some social media.",
            "Now, since we are interested in doing an open domain annotation, Wikipedia is the obvious social media that that we pick for selecting the entities.",
            "The motivation behind doing this is to use the annotations for search and mining tasks.",
            "So with this."
        ],
        [
            "The outline for today is as follows.",
            "We will begin by using some terminologies that would help us understand our system.",
            "Then we will look at some of the concepts used in entity disambiguation.",
            "Then we will move on to what are our contributions in this field.",
            "An evaluation of our system followed by the results, and then we would conclude."
        ],
        [
            "So this is the news article which is which forms an unstructured data source.",
            "This is just plain text which we wish to annotate.",
            "Up now."
        ],
        [
            "Some of the words or phrases might appear on the page which are termed as spots.",
            "These are shown in blue.",
            "These are these parts are basically occurrences in the text that can be possibly linked to Wikipedia article.",
            "We will use the term S 0 to denote all the candidates that all the candidate spots that appear on a web page, and we would use the letter small S which is a, which would be a part of SO or to donate, donate denote a particular spot and the surrounding context of this part."
        ],
        [
            "Now in this part on the Wikipedia on the web page might be linked to one or more Wikipedia entities, which is termed as the attachments.",
            "So basically attachments is the list of Wikipedia entities that can be linked to a sport.",
            "So just as we had some notations for spots, we also have some notations for denoting the attachments.",
            "So Gamma S is used to represent the set of candidate entity labels for the Spot S which is on the page where is, zero would be used to represent the list of the set of all candidates labels for the page.",
            "So in the diagram, if you see the spot that we're considering is Tuesday and the possible entities that are associated that can be associated with this spot.",
            "Is Tuesday the week of the day or Tuesday the band, the book, etc.",
            "Now moving on to what exact?"
        ],
        [
            "The entity disambiguation means.",
            "Consider the diagram on the left, which shows some running text.",
            "Now suppose that we want to disambiguate the word Jaguar, which is marked in blue.",
            "So basically there are multiple senses that a word can have, and hence it can be associated with more than one Wikipedia entities.",
            "So for example, in this case, Jaguar could mean Jaguar, the car, or it could mean Jaguar the animal.",
            "Now we believe that there could be clues from the local context that can help us to disambiguate the entity that we are considering.",
            "For example, the.",
            "In this case, there are some words which are marked in red like automotive technology, backlight engine etc which might.",
            "Which will help us to disambiguate the word that we're trying to annotate, which is Jaguar, and in this case it is clear that this is Jaguar the car and not the animal.",
            "So pictorially, if we see a document will have multiple spots on it like two of them are shown here is scream each of this part will have possible candidate label set which is shown as gamma S and one of the possible gamma is one of the possible attachments would be associated with this part.",
            "For example gamma in this case.",
            "So this is what we term as the compatibility between the spot and the label.",
            "Some of the related work is done by the system called a SIM tag and seeker.",
            "Which does consider such local compatibility for doing entity disambiguation."
        ],
        [
            "So moving further, not just the local clues, might be enough in order to disambiguate the entities.",
            "There could be other spots on the page that might also help in entity disambiguation.",
            "So for example, if you see the the figure on the left again, there are multiple spots which are marked in blue, three of them.",
            "Here, Michael Jordan, Air Jordan, and Chicago Bulls.",
            "So if you want to disambiguate each of these, then there are multiple senses associated with each of the spots as shown.",
            "So, for example, Michael Jordan has got three senses, Air Jordan has got two, and Chicago Bulls has just one.",
            "And now we believe that all the spots that appear on a page would belong to the same context or to the same subject and hence it would help us to determine what exact final configuration would be associated with this part.",
            "So in this case Michael Jordan would get associated with the basketball player.",
            "Air Jordan would be associated with the Nike Shoes, and Chicago Bulls might be associated with the basketball team.",
            "So again, considering the picture that we extending the picture that we saw earlier, we have the document and the spots and the possible attachments.",
            "Now every Wikipedia article that we have which is gamma would be mapped onto some space using a feature vector which we term as G gamma as is shown in the diagram on the right.",
            "So to define how coherent two labels are, we will use these feature vectors which are mapped onto the space as is shown, and we will use the disambiguation we will do the disambiguation of entities based not just on the local compatibility, but also include the coherence between the labels that will be clear from the map space.",
            "So some of the related work which considers coherence of labels is was done by users and an building."
        ],
        [
            "So since the relatedness is associated with the Wikipedia articles, we get some information about the relatedness from the entity catalog, which is Wikipedia in our case.",
            "So to define relatedness between two Wikipedia articles, say gamma and gamma prime, we could use a simple dot product like G gamma dot G gamma prime to represent the relatedness.",
            "Or it could be some other relatedness measure."
        ],
        [
            "So Christian proposed using a cosine measure to define the relatedness between the Wikipedia entities."
        ],
        [
            "Where is Miller gave a proposal which used in links to define the feature vector which is the G gamma and gave.",
            "The formula is shown in the equation which is similar to Jacquard which would mean how related two given Wikipedia entities are."
        ],
        [
            "So with this background we will see what our contributions to this field of work are.",
            "So first important contribution is that we post the entity disambiguation problem as an optimization problem, where we propose a single objective which is to be optimized.",
            "We also provide heuristics and methods to solve this object.",
            "If first is using integer linear programs, since it is NP hard, you provide some relaxation and rounding mechanisms to find the final assignments, and we also provide some heuristics to get approximate solutions which is based on Hill climbing, which will be discussed.",
            "Apart from that, as we saw that we also model some local compatibility between the spot and the label, which for which we use rich node features and use systematic learning to define a node score which is used to model the local compatibility of the spot and the label.",
            "Apart from that, we also provide a mechanism which would allow us to perform controlled annotations so that all the spots that are found on a page might not be annotated.",
            "So this is what we call as the backup strategy."
        ],
        [
            "So let us look into details of how exactly we model the local compatibility, which means the compatibility between a spot and Wikipedia article.",
            "So we define a feature vector which is termed as FS, which would be mapped on a D dimensional space.",
            "This would express the local textual compatibility between the spot and the candidate label Gamma.",
            "So the components of this feature vector come as follows.",
            "First is the spot side features and 2nd is the Wikipedia site features on the spot side we have got the context of this part, which is the TF IDF feature vector of the context in which the spot appears.",
            "And on the Wikipedia side we define 4 features.",
            "1st is the snippet which is the first descriptive paragraph of the Wikipedia article.",
            "Second is the full text, which is the entire text of the article.",
            "Third is the anchor text, which is the in links that appear on the article.",
            "Because we believe that they would give good clues on describing the Wikipedia article.",
            "And 4th is the anchor text with some context around that anchor text.",
            "This is again on the Wikipedia site.",
            "So now that we have the feature vector on the spot side and the Wikipedia side, we combine these two using three different similarity measures.",
            "One is the dot product, second is the cosine similarity, and 3rd is the Jaccard similarity.",
            "So in all we get 12 different components which which are a part of the feature vector that we define to model the local compatibility.",
            "Apart from that, we also have one more feature which is which we call as a sense probability prior, which is the probability that Wikipedia entity can be associated with the spot.",
            "So that is nothing more probability of gamma being associated with the spot.",
            "So probability of gamma given is.",
            "So this will also be appended to the component as one of the components of FS,"
        ],
        [
            "So now that we know that we get clues from local compatibility as well as some label coherence, that of the labels that appear on a page.",
            "We define the components of our objective using two different scores.",
            "First is the node score which will, which will model the local compatibility.",
            "So here we use the model that is learned based on the feature vector that we just define and define a score which will be termed as W, transpose, FS, and RW is learned using a training set collected from ground truth.",
            "I using linear adaptation of rank as well.",
            "And for the click score, which is to define the how close are two labels associated with the spot our views, some measure that is described by many others.",
            "So the total objective would comprise of the node score and the click school.",
            "The node score.",
            "As I said that it would be W transpose FSYS, where Y is the final set of assignments on the page and click score would be the relatedness that would be comprising of the final assignments.",
            "The labels of pair of labels of final assignments.",
            "Now note that the number of terms that contributes to the node score would be equal to the number of spots on the page, whereas the number of terms that contribute to the click score would be equal to the number of pairs of spots in the page and hence we need to normalize each of the terms."
        ],
        [
            "Appropriately, so we normalized the node score by zero and normalize the click score by a zero.",
            "Choose two since there are pairs of spots that are considered in the click score component."
        ],
        [
            "Note that till now we have considered that every spot is associated with some Wikipedia article, but that might not be the case.",
            "Not all sports might have to be tagged, so we allow our algorithm to back off from tagging certain spots.",
            "If we're not confident about assigning any particular Wikipedia article to, that's what we do this by assigning a special label which we call as Na, which which denotes no attachment.",
            "We model this by assigning a special value which we call as reward.",
            "For this part, for assigning any value which is the are any value.",
            "So this is basically the handle that we have to decide how aggressive our tagging needs to be.",
            "Now note that as the value of RNA is smaller, the tagging will be more aggressive because we're not rewarding much for assigning an NA2A spot."
        ],
        [
            "Now with this we have the little objective, slightly modified.",
            "Since the number of the spots that appear on a page are divided into two categories.",
            "Now one is the NO, which is the spots which are assigned as any and 2nd is the remaining spots which have some Wikipedia article assigned to it.",
            "So the North score is now basically composed of two parts, one that comes from the spots which are in is and the second which is.",
            "Having some Wikipedia article assigned to it, where is the click score, still remains the same, just the difference is that the spots which are which have some Wikipedia article assigned to it will contribute to the click score.",
            "The spots which are marked as any will not contribute to the click score anymore."
        ],
        [
            "So with this we will see what are the methods that we use for solving the objective.",
            "First we have the integer linear program based formulation where we cast our problem as a 01 integer linear program.",
            "Here we have got a gamma 0 plus, 0 squared variables where gamma zero is the total number of possible attachments that can happen on a particular page.",
            "So it is basically.",
            "All the possible labels that can be associated on any of the spots on the page.",
            "So since this is an NP hard problem, we will relax it to an LP and find rounding mechanisms to determine the final assignment for the page.",
            "Apart from that, we also provide some simpler heuristics which is based on Hill climbing for solving the objective."
        ],
        [
            "We evaluate our system based on a 3 different measures.",
            "First is the precision which is defined as the number of spots tagged correctly out of the total number of spots tagged by the algorithm.",
            "2nd is the recall, which is the number of spots tagged correctly out of the total number of spots in the ground truth and F measure which is based on the precision and recall to determine the accuracy of our annotations."
        ],
        [
            "So the data set that we use for evaluation is.",
            "There are two different datasets that we use.",
            "Basically first is collected locally at IIT which is crawled from which are some web pages crawled from popular websites coming from different sources like Sports, technology, news articles etc.",
            "And 2nd is the publicly available Caesar data set which is from the Cousens experiments.",
            "We have around 100 documents in our data set and about 17,000 spots in our data set.",
            "And these are all manually annotated web pages.",
            "That are cruel.",
            "So."
        ],
        [
            "To see some of the results of evaluation of the evaluation of our system, we have seen that we use learned W in order to define the node score.",
            "You observe that using this learned W would definitely be helpful.",
            "Then using individual scores in isolation."
        ],
        [
            "Fact it is enough to outperform other baseline measures that we compare ourselves with.",
            "Also, if we add additional components to the two defining the node score, which is the sense probability prior, just that the one we saw it would help to increase the precision without losing on recall.",
            "So as you can see that the line that is marked in red is shown to have the precision and recall curve for using the local plus the sense probability prior and the one in blue is the one with mark with just.",
            "No score without the sense probability, right?"
        ],
        [
            "Going beyond this, we also see what are the benefits that we get from using collective inferencing.",
            "So apart from the node score, we also have the click score which which contributes to the collective inferencing that we use.",
            "So as we have two different methodologies we hillclimbing based and the LP based approach.",
            "We see that at the same recall we do get improvements in precision when we use collective inferencing as as seen in the diagram above.",
            "So basically adding collective inference or definitely adds to the accuracy of the annotations."
        ],
        [
            "So to summarize, selecting the features for defining the node score is definitely important as we saw.",
            "Also, collective inference improves the accuracy further and we are able to gain high recall without sacrificing much on precision, and this is the main goal since we need to have these annotations which will be used in further search system.",
            "So as you can see in the chart of the recall and precision is fairly good.",
            "An inside accuracy measure is outperforming most of the existing systems that we compare ourselves with.",
            "So."
        ],
        [
            "Give what are our future work that we plan for assets we plan to extend the current collective inferencing which is just restricted to page level collective inferencing currently too beyond page level boundaries and we also plan to associate some kind of confidence measure with the annotations that we currently do so currently we're just having a score which is associated with every annotation but we need to have some global confidence value that can be associated with these annotations.",
            "That can be used for further search system where will be using these annotations?",
            "Apart from that, we also plan to reduce the cognitive load that might be there during the process of manual annotations by using the spots which are already tagged.",
            "Most importantly, we we are also building a entity search system over these annotations where the annotations are being indexed and we provide some search and search facilities above this index."
        ],
        [
            "So we have a demo of this tomorrow from 5:30 onwards."
        ],
        [
            "That's all, thank you.",
            "Works at the beginning.",
            "OK, so we have the entity catalog which is Wikipedia.",
            "We build a prefix tree out of all the Wikipedia titles that we have, and we do a scan of the text that we are wanting to annotate and we find the longest possible match.",
            "In this prefix tree, and that is how we get this parts.",
            "Or context in.",
            "So you mean to say that whether we have considered different context belonging, different spots belonging to different contexts?",
            "No, no I'm saying.",
            "You want to configuration for each spot.",
            "Crosses.",
            "This pop would be.",
            "Yeah.",
            "Right, so we have not thought much into these lines, but that's good.",
            "Yeah.",
            "So.",
            "Problem so happens that the qualification.",
            "It depends not only on the configuration, and it isn't spots, but also configuration at far off here.",
            "So we therefore resort to complete graph instead of just listening edgy.",
            "Yeah, so currently we are restricting to find the longest possible match that that can appear in a running text.",
            "So basically if there is an entity in Wikipedia, Jordan is an entity in Wikipedia and Air Jordan is an entity in Wikipedia, then we restrict to define our spot as Air Jordan, since that is the longest possible spot that we can get.",
            "So this is based on the entities that we are trying to annotate."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "So I'm slightly from Indian Institute of Technology, Bombay.",
                    "label": 0
                },
                {
                    "sent": "Today I'll be presenting our work on a collective annotation of Wikipedia entities in web text.",
                    "label": 1
                },
                {
                    "sent": "This is jointly done with Amit Singh and with the guidance of Professor Ganesh Rama Krishnan professor so major property.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to begin, the aim of developing this system is to perform aggressive open domain annotations in unstructured web text and identify entities which are which can be linked to some social media.",
                    "label": 0
                },
                {
                    "sent": "Now, since we are interested in doing an open domain annotation, Wikipedia is the obvious social media that that we pick for selecting the entities.",
                    "label": 0
                },
                {
                    "sent": "The motivation behind doing this is to use the annotations for search and mining tasks.",
                    "label": 1
                },
                {
                    "sent": "So with this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The outline for today is as follows.",
                    "label": 1
                },
                {
                    "sent": "We will begin by using some terminologies that would help us understand our system.",
                    "label": 0
                },
                {
                    "sent": "Then we will look at some of the concepts used in entity disambiguation.",
                    "label": 0
                },
                {
                    "sent": "Then we will move on to what are our contributions in this field.",
                    "label": 0
                },
                {
                    "sent": "An evaluation of our system followed by the results, and then we would conclude.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the news article which is which forms an unstructured data source.",
                    "label": 1
                },
                {
                    "sent": "This is just plain text which we wish to annotate.",
                    "label": 0
                },
                {
                    "sent": "Up now.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some of the words or phrases might appear on the page which are termed as spots.",
                    "label": 0
                },
                {
                    "sent": "These are shown in blue.",
                    "label": 0
                },
                {
                    "sent": "These are these parts are basically occurrences in the text that can be possibly linked to Wikipedia article.",
                    "label": 1
                },
                {
                    "sent": "We will use the term S 0 to denote all the candidates that all the candidate spots that appear on a web page, and we would use the letter small S which is a, which would be a part of SO or to donate, donate denote a particular spot and the surrounding context of this part.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now in this part on the Wikipedia on the web page might be linked to one or more Wikipedia entities, which is termed as the attachments.",
                    "label": 0
                },
                {
                    "sent": "So basically attachments is the list of Wikipedia entities that can be linked to a sport.",
                    "label": 1
                },
                {
                    "sent": "So just as we had some notations for spots, we also have some notations for denoting the attachments.",
                    "label": 0
                },
                {
                    "sent": "So Gamma S is used to represent the set of candidate entity labels for the Spot S which is on the page where is, zero would be used to represent the list of the set of all candidates labels for the page.",
                    "label": 1
                },
                {
                    "sent": "So in the diagram, if you see the spot that we're considering is Tuesday and the possible entities that are associated that can be associated with this spot.",
                    "label": 0
                },
                {
                    "sent": "Is Tuesday the week of the day or Tuesday the band, the book, etc.",
                    "label": 0
                },
                {
                    "sent": "Now moving on to what exact?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The entity disambiguation means.",
                    "label": 0
                },
                {
                    "sent": "Consider the diagram on the left, which shows some running text.",
                    "label": 0
                },
                {
                    "sent": "Now suppose that we want to disambiguate the word Jaguar, which is marked in blue.",
                    "label": 0
                },
                {
                    "sent": "So basically there are multiple senses that a word can have, and hence it can be associated with more than one Wikipedia entities.",
                    "label": 0
                },
                {
                    "sent": "So for example, in this case, Jaguar could mean Jaguar, the car, or it could mean Jaguar the animal.",
                    "label": 0
                },
                {
                    "sent": "Now we believe that there could be clues from the local context that can help us to disambiguate the entity that we are considering.",
                    "label": 1
                },
                {
                    "sent": "For example, the.",
                    "label": 0
                },
                {
                    "sent": "In this case, there are some words which are marked in red like automotive technology, backlight engine etc which might.",
                    "label": 0
                },
                {
                    "sent": "Which will help us to disambiguate the word that we're trying to annotate, which is Jaguar, and in this case it is clear that this is Jaguar the car and not the animal.",
                    "label": 0
                },
                {
                    "sent": "So pictorially, if we see a document will have multiple spots on it like two of them are shown here is scream each of this part will have possible candidate label set which is shown as gamma S and one of the possible gamma is one of the possible attachments would be associated with this part.",
                    "label": 0
                },
                {
                    "sent": "For example gamma in this case.",
                    "label": 1
                },
                {
                    "sent": "So this is what we term as the compatibility between the spot and the label.",
                    "label": 1
                },
                {
                    "sent": "Some of the related work is done by the system called a SIM tag and seeker.",
                    "label": 0
                },
                {
                    "sent": "Which does consider such local compatibility for doing entity disambiguation.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So moving further, not just the local clues, might be enough in order to disambiguate the entities.",
                    "label": 0
                },
                {
                    "sent": "There could be other spots on the page that might also help in entity disambiguation.",
                    "label": 1
                },
                {
                    "sent": "So for example, if you see the the figure on the left again, there are multiple spots which are marked in blue, three of them.",
                    "label": 0
                },
                {
                    "sent": "Here, Michael Jordan, Air Jordan, and Chicago Bulls.",
                    "label": 0
                },
                {
                    "sent": "So if you want to disambiguate each of these, then there are multiple senses associated with each of the spots as shown.",
                    "label": 0
                },
                {
                    "sent": "So, for example, Michael Jordan has got three senses, Air Jordan has got two, and Chicago Bulls has just one.",
                    "label": 0
                },
                {
                    "sent": "And now we believe that all the spots that appear on a page would belong to the same context or to the same subject and hence it would help us to determine what exact final configuration would be associated with this part.",
                    "label": 0
                },
                {
                    "sent": "So in this case Michael Jordan would get associated with the basketball player.",
                    "label": 0
                },
                {
                    "sent": "Air Jordan would be associated with the Nike Shoes, and Chicago Bulls might be associated with the basketball team.",
                    "label": 0
                },
                {
                    "sent": "So again, considering the picture that we extending the picture that we saw earlier, we have the document and the spots and the possible attachments.",
                    "label": 0
                },
                {
                    "sent": "Now every Wikipedia article that we have which is gamma would be mapped onto some space using a feature vector which we term as G gamma as is shown in the diagram on the right.",
                    "label": 0
                },
                {
                    "sent": "So to define how coherent two labels are, we will use these feature vectors which are mapped onto the space as is shown, and we will use the disambiguation we will do the disambiguation of entities based not just on the local compatibility, but also include the coherence between the labels that will be clear from the map space.",
                    "label": 0
                },
                {
                    "sent": "So some of the related work which considers coherence of labels is was done by users and an building.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So since the relatedness is associated with the Wikipedia articles, we get some information about the relatedness from the entity catalog, which is Wikipedia in our case.",
                    "label": 0
                },
                {
                    "sent": "So to define relatedness between two Wikipedia articles, say gamma and gamma prime, we could use a simple dot product like G gamma dot G gamma prime to represent the relatedness.",
                    "label": 0
                },
                {
                    "sent": "Or it could be some other relatedness measure.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Christian proposed using a cosine measure to define the relatedness between the Wikipedia entities.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where is Miller gave a proposal which used in links to define the feature vector which is the G gamma and gave.",
                    "label": 0
                },
                {
                    "sent": "The formula is shown in the equation which is similar to Jacquard which would mean how related two given Wikipedia entities are.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So with this background we will see what our contributions to this field of work are.",
                    "label": 0
                },
                {
                    "sent": "So first important contribution is that we post the entity disambiguation problem as an optimization problem, where we propose a single objective which is to be optimized.",
                    "label": 1
                },
                {
                    "sent": "We also provide heuristics and methods to solve this object.",
                    "label": 1
                },
                {
                    "sent": "If first is using integer linear programs, since it is NP hard, you provide some relaxation and rounding mechanisms to find the final assignments, and we also provide some heuristics to get approximate solutions which is based on Hill climbing, which will be discussed.",
                    "label": 0
                },
                {
                    "sent": "Apart from that, as we saw that we also model some local compatibility between the spot and the label, which for which we use rich node features and use systematic learning to define a node score which is used to model the local compatibility of the spot and the label.",
                    "label": 0
                },
                {
                    "sent": "Apart from that, we also provide a mechanism which would allow us to perform controlled annotations so that all the spots that are found on a page might not be annotated.",
                    "label": 0
                },
                {
                    "sent": "So this is what we call as the backup strategy.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let us look into details of how exactly we model the local compatibility, which means the compatibility between a spot and Wikipedia article.",
                    "label": 0
                },
                {
                    "sent": "So we define a feature vector which is termed as FS, which would be mapped on a D dimensional space.",
                    "label": 0
                },
                {
                    "sent": "This would express the local textual compatibility between the spot and the candidate label Gamma.",
                    "label": 1
                },
                {
                    "sent": "So the components of this feature vector come as follows.",
                    "label": 0
                },
                {
                    "sent": "First is the spot side features and 2nd is the Wikipedia site features on the spot side we have got the context of this part, which is the TF IDF feature vector of the context in which the spot appears.",
                    "label": 0
                },
                {
                    "sent": "And on the Wikipedia side we define 4 features.",
                    "label": 0
                },
                {
                    "sent": "1st is the snippet which is the first descriptive paragraph of the Wikipedia article.",
                    "label": 0
                },
                {
                    "sent": "Second is the full text, which is the entire text of the article.",
                    "label": 0
                },
                {
                    "sent": "Third is the anchor text, which is the in links that appear on the article.",
                    "label": 0
                },
                {
                    "sent": "Because we believe that they would give good clues on describing the Wikipedia article.",
                    "label": 0
                },
                {
                    "sent": "And 4th is the anchor text with some context around that anchor text.",
                    "label": 0
                },
                {
                    "sent": "This is again on the Wikipedia site.",
                    "label": 0
                },
                {
                    "sent": "So now that we have the feature vector on the spot side and the Wikipedia side, we combine these two using three different similarity measures.",
                    "label": 0
                },
                {
                    "sent": "One is the dot product, second is the cosine similarity, and 3rd is the Jaccard similarity.",
                    "label": 0
                },
                {
                    "sent": "So in all we get 12 different components which which are a part of the feature vector that we define to model the local compatibility.",
                    "label": 0
                },
                {
                    "sent": "Apart from that, we also have one more feature which is which we call as a sense probability prior, which is the probability that Wikipedia entity can be associated with the spot.",
                    "label": 1
                },
                {
                    "sent": "So that is nothing more probability of gamma being associated with the spot.",
                    "label": 0
                },
                {
                    "sent": "So probability of gamma given is.",
                    "label": 0
                },
                {
                    "sent": "So this will also be appended to the component as one of the components of FS,",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now that we know that we get clues from local compatibility as well as some label coherence, that of the labels that appear on a page.",
                    "label": 0
                },
                {
                    "sent": "We define the components of our objective using two different scores.",
                    "label": 1
                },
                {
                    "sent": "First is the node score which will, which will model the local compatibility.",
                    "label": 0
                },
                {
                    "sent": "So here we use the model that is learned based on the feature vector that we just define and define a score which will be termed as W, transpose, FS, and RW is learned using a training set collected from ground truth.",
                    "label": 1
                },
                {
                    "sent": "I using linear adaptation of rank as well.",
                    "label": 1
                },
                {
                    "sent": "And for the click score, which is to define the how close are two labels associated with the spot our views, some measure that is described by many others.",
                    "label": 0
                },
                {
                    "sent": "So the total objective would comprise of the node score and the click school.",
                    "label": 0
                },
                {
                    "sent": "The node score.",
                    "label": 0
                },
                {
                    "sent": "As I said that it would be W transpose FSYS, where Y is the final set of assignments on the page and click score would be the relatedness that would be comprising of the final assignments.",
                    "label": 1
                },
                {
                    "sent": "The labels of pair of labels of final assignments.",
                    "label": 0
                },
                {
                    "sent": "Now note that the number of terms that contributes to the node score would be equal to the number of spots on the page, whereas the number of terms that contribute to the click score would be equal to the number of pairs of spots in the page and hence we need to normalize each of the terms.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Appropriately, so we normalized the node score by zero and normalize the click score by a zero.",
                    "label": 0
                },
                {
                    "sent": "Choose two since there are pairs of spots that are considered in the click score component.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Note that till now we have considered that every spot is associated with some Wikipedia article, but that might not be the case.",
                    "label": 0
                },
                {
                    "sent": "Not all sports might have to be tagged, so we allow our algorithm to back off from tagging certain spots.",
                    "label": 1
                },
                {
                    "sent": "If we're not confident about assigning any particular Wikipedia article to, that's what we do this by assigning a special label which we call as Na, which which denotes no attachment.",
                    "label": 0
                },
                {
                    "sent": "We model this by assigning a special value which we call as reward.",
                    "label": 0
                },
                {
                    "sent": "For this part, for assigning any value which is the are any value.",
                    "label": 0
                },
                {
                    "sent": "So this is basically the handle that we have to decide how aggressive our tagging needs to be.",
                    "label": 0
                },
                {
                    "sent": "Now note that as the value of RNA is smaller, the tagging will be more aggressive because we're not rewarding much for assigning an NA2A spot.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now with this we have the little objective, slightly modified.",
                    "label": 0
                },
                {
                    "sent": "Since the number of the spots that appear on a page are divided into two categories.",
                    "label": 0
                },
                {
                    "sent": "Now one is the NO, which is the spots which are assigned as any and 2nd is the remaining spots which have some Wikipedia article assigned to it.",
                    "label": 1
                },
                {
                    "sent": "So the North score is now basically composed of two parts, one that comes from the spots which are in is and the second which is.",
                    "label": 0
                },
                {
                    "sent": "Having some Wikipedia article assigned to it, where is the click score, still remains the same, just the difference is that the spots which are which have some Wikipedia article assigned to it will contribute to the click score.",
                    "label": 0
                },
                {
                    "sent": "The spots which are marked as any will not contribute to the click score anymore.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So with this we will see what are the methods that we use for solving the objective.",
                    "label": 0
                },
                {
                    "sent": "First we have the integer linear program based formulation where we cast our problem as a 01 integer linear program.",
                    "label": 1
                },
                {
                    "sent": "Here we have got a gamma 0 plus, 0 squared variables where gamma zero is the total number of possible attachments that can happen on a particular page.",
                    "label": 0
                },
                {
                    "sent": "So it is basically.",
                    "label": 0
                },
                {
                    "sent": "All the possible labels that can be associated on any of the spots on the page.",
                    "label": 0
                },
                {
                    "sent": "So since this is an NP hard problem, we will relax it to an LP and find rounding mechanisms to determine the final assignment for the page.",
                    "label": 0
                },
                {
                    "sent": "Apart from that, we also provide some simpler heuristics which is based on Hill climbing for solving the objective.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We evaluate our system based on a 3 different measures.",
                    "label": 0
                },
                {
                    "sent": "First is the precision which is defined as the number of spots tagged correctly out of the total number of spots tagged by the algorithm.",
                    "label": 1
                },
                {
                    "sent": "2nd is the recall, which is the number of spots tagged correctly out of the total number of spots in the ground truth and F measure which is based on the precision and recall to determine the accuracy of our annotations.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the data set that we use for evaluation is.",
                    "label": 1
                },
                {
                    "sent": "There are two different datasets that we use.",
                    "label": 1
                },
                {
                    "sent": "Basically first is collected locally at IIT which is crawled from which are some web pages crawled from popular websites coming from different sources like Sports, technology, news articles etc.",
                    "label": 1
                },
                {
                    "sent": "And 2nd is the publicly available Caesar data set which is from the Cousens experiments.",
                    "label": 0
                },
                {
                    "sent": "We have around 100 documents in our data set and about 17,000 spots in our data set.",
                    "label": 0
                },
                {
                    "sent": "And these are all manually annotated web pages.",
                    "label": 0
                },
                {
                    "sent": "That are cruel.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To see some of the results of evaluation of the evaluation of our system, we have seen that we use learned W in order to define the node score.",
                    "label": 1
                },
                {
                    "sent": "You observe that using this learned W would definitely be helpful.",
                    "label": 0
                },
                {
                    "sent": "Then using individual scores in isolation.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fact it is enough to outperform other baseline measures that we compare ourselves with.",
                    "label": 1
                },
                {
                    "sent": "Also, if we add additional components to the two defining the node score, which is the sense probability prior, just that the one we saw it would help to increase the precision without losing on recall.",
                    "label": 0
                },
                {
                    "sent": "So as you can see that the line that is marked in red is shown to have the precision and recall curve for using the local plus the sense probability prior and the one in blue is the one with mark with just.",
                    "label": 0
                },
                {
                    "sent": "No score without the sense probability, right?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going beyond this, we also see what are the benefits that we get from using collective inferencing.",
                    "label": 0
                },
                {
                    "sent": "So apart from the node score, we also have the click score which which contributes to the collective inferencing that we use.",
                    "label": 0
                },
                {
                    "sent": "So as we have two different methodologies we hillclimbing based and the LP based approach.",
                    "label": 0
                },
                {
                    "sent": "We see that at the same recall we do get improvements in precision when we use collective inferencing as as seen in the diagram above.",
                    "label": 0
                },
                {
                    "sent": "So basically adding collective inference or definitely adds to the accuracy of the annotations.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to summarize, selecting the features for defining the node score is definitely important as we saw.",
                    "label": 1
                },
                {
                    "sent": "Also, collective inference improves the accuracy further and we are able to gain high recall without sacrificing much on precision, and this is the main goal since we need to have these annotations which will be used in further search system.",
                    "label": 1
                },
                {
                    "sent": "So as you can see in the chart of the recall and precision is fairly good.",
                    "label": 0
                },
                {
                    "sent": "An inside accuracy measure is outperforming most of the existing systems that we compare ourselves with.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Give what are our future work that we plan for assets we plan to extend the current collective inferencing which is just restricted to page level collective inferencing currently too beyond page level boundaries and we also plan to associate some kind of confidence measure with the annotations that we currently do so currently we're just having a score which is associated with every annotation but we need to have some global confidence value that can be associated with these annotations.",
                    "label": 0
                },
                {
                    "sent": "That can be used for further search system where will be using these annotations?",
                    "label": 0
                },
                {
                    "sent": "Apart from that, we also plan to reduce the cognitive load that might be there during the process of manual annotations by using the spots which are already tagged.",
                    "label": 1
                },
                {
                    "sent": "Most importantly, we we are also building a entity search system over these annotations where the annotations are being indexed and we provide some search and search facilities above this index.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have a demo of this tomorrow from 5:30 onwards.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's all, thank you.",
                    "label": 0
                },
                {
                    "sent": "Works at the beginning.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have the entity catalog which is Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "We build a prefix tree out of all the Wikipedia titles that we have, and we do a scan of the text that we are wanting to annotate and we find the longest possible match.",
                    "label": 0
                },
                {
                    "sent": "In this prefix tree, and that is how we get this parts.",
                    "label": 0
                },
                {
                    "sent": "Or context in.",
                    "label": 0
                },
                {
                    "sent": "So you mean to say that whether we have considered different context belonging, different spots belonging to different contexts?",
                    "label": 0
                },
                {
                    "sent": "No, no I'm saying.",
                    "label": 0
                },
                {
                    "sent": "You want to configuration for each spot.",
                    "label": 0
                },
                {
                    "sent": "Crosses.",
                    "label": 0
                },
                {
                    "sent": "This pop would be.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Right, so we have not thought much into these lines, but that's good.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Problem so happens that the qualification.",
                    "label": 0
                },
                {
                    "sent": "It depends not only on the configuration, and it isn't spots, but also configuration at far off here.",
                    "label": 0
                },
                {
                    "sent": "So we therefore resort to complete graph instead of just listening edgy.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so currently we are restricting to find the longest possible match that that can appear in a running text.",
                    "label": 0
                },
                {
                    "sent": "So basically if there is an entity in Wikipedia, Jordan is an entity in Wikipedia and Air Jordan is an entity in Wikipedia, then we restrict to define our spot as Air Jordan, since that is the longest possible spot that we can get.",
                    "label": 0
                },
                {
                    "sent": "So this is based on the entities that we are trying to annotate.",
                    "label": 0
                }
            ]
        }
    }
}