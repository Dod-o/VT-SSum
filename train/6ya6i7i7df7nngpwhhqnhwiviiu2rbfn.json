{
    "id": "6ya6i7i7df7nngpwhhqnhwiviiu2rbfn",
    "title": "Data Mining with Differential Privacy",
    "info": {
        "author": [
            "Arik Friedman, Computer Science Department, Technion - Israel Institute of Technology"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Data Mining->Security & Privacy",
            "Top->Computer Science->Databases"
        ]
    },
    "url": "http://videolectures.net/kdd2010_friedman_dmdp/",
    "segmentation": [
        [
            "This work is about privacy preserving data mining, where we have two goals on one hand."
        ],
        [
            "Well, on one hand we want to extract new patterns and knowledge from data we have.",
            "For example, if you want to build a classifier, we can evaluate the utility we get from it by measuring it its accuracy or it's error rate on a test set.",
            "On the other hand, we want to protect the privacy of individuals who are represented in the data.",
            "To this end it to make this happen, we need to limit what can be learned from the data, so we can expect it when we have stronger privacy requirements.",
            "This will result in an increased error rate, so we have this tradeoff between privacy and accuracy.",
            "Different algorithms can present different tradeoffs, and in economics, a situation in which we can improve one algorithm, one parameter without harming the other is called the improvement.",
            "And when a point cannot be further Pareto improved, we say it's part efficient.",
            "So the collection of all the proficient points gives us the predator frontier, and this gives us the best tradeoff we can get between privacy and utility.",
            "So one question you can ask is how to choose a point on the part of Frontier, and we're not dealing with this question.",
            "This may depend on the application or on social norms or a regulation, our goal.",
            "Is to seek ways how we can extend operator Frontier so we can get a better tradeoff between privacy and utility.",
            "So in the context of data mining.",
            "And there are well established methods out to measure the utility we get from the algorithm, but there is still ongoing work on defining and measuring privacy."
        ],
        [
            "And in this talk, and I'm going to rely on differential privacy, recent definition of privacy by work.",
            "Make sure in some it.",
            "And intuitively, differential privacy requires that computation we insensitive to changes in any particular individuals record.",
            "So from the individual's point of view, if there is one data set where the individual circuit appears and there is another data set which is the same expect except it doesn't contain this record, and then we would want that any outcome of the computation that we get on one data set will be almost a is equally likely.",
            "When we run it on the other data set, so anything that the adversary learns by running on one data set, it will probably with very high likelihood will learn from the other data set as well.",
            "Formally, differential privacy requires that for any data sets and be with symmetric difference one and for any possible set of outcomes of the computation, the probability to get an outcome when executing the algorithm on one data set.",
            "Will be the same as running on the other data set up to a multiplicative factor of exponent N epsilon, and we really think of epsilon is a small number below one, which means that this probability should be a close to each other.",
            "So this is the worst case definition.",
            "It has the advantage that it does not depend on the burger.",
            "No knowledge of the attacker or the computational power that Icarus and it has a nice property of compatibility, which means that if the adversary is access to two, a independent invocations of M of the computation and each each invocation maintains epsilon differential privacy, then the probability of any outcome would shift by at most two epsilon.",
            "And this actually allows use the concept of privacy budget, where the data provider sets a limit epsilon on how much personal information can be leaked in the process, and then the data miner can choose whether to run one computation which is epsilon, differentially private, or two computations which each of them a half epsilon, differentially private, or any combination of computations that will consume a total privacy budget of epsilon."
        ],
        [
            "So differential privacy is the property of the computation, and there are several ways we can apply to data mining.",
            "One way is to give the data miner full access to the data and its data minus responsibility to ensure that the outcome of the computation preserves differential privacy.",
            "And there were several recent works that use this approach."
        ],
        [
            "Another approach was featured in a system called Pink Privacy Integrated queries by Maturing an.",
            "In this approach we have a data access layer that enforces differential privacy.",
            "It exposes an interface to the data miner and as long as the data miner accesses the data only through this interface.",
            "Element doesn't really have to understand how privacy is enforced in stacking carried by this interface."
        ],
        [
            "A third approach is to use a process that maintains differential privacy to create a synthetic data set that preserves some properties of the original data set, and in this approach, the data miner just runs the algorithm on the synthetic data set just as if it were the original data and the catching.",
            "This approach is that if we want their strong theoretical results that say that if you want the queries to get accurate answers.",
            "This process should be tailored to the exact kind of course that we're going to ask, and in some cases it even might not be possible."
        ],
        [
            "And in this talk, we're going to focus on the second approach, where we have this interface, and we assume that we have."
        ],
        [
            "2.",
            "Mechanisms that we can invoke through this interface.",
            "One is the Laplace mechanism proposed by work mature.",
            "In this image, Smith and the central element is mechanism.",
            "Is the concept of sensitivity of a function.",
            "The sensitivity of the function is the largest possible change in the value of the function after changing a single record in the input.",
            "So for example, if we have a count query and changing a single record would change the outcome back most one if we sum elements over elements, attack values between zero and Lambda.",
            "Then changing a single input will change the output of the sum at most Lambda and the Laplace mechanism.",
            "It calculates the exact value of the function and then it adds to its noise that is distributed.",
            "The sample from the Laplace distribution, which is asymmetric exponential distribution that looks like this.",
            "And by calibrating this distribution with the sensitivity of the function with parameter epsilon, we can ensure that this output maintains differential privacy and you can see that a using data plus mechanism or noisy crowd noise is some.",
            "A the notes that we had your actually doesn't depend on the size of the data set, and the implication is that actually the tradeoff that we have is not just between privacy, the accuracy, but we can also trade off the size of the data set.",
            "So if you want to get better accuracy, one option is to increase epsilon and then we lose privacy.",
            "Or if possible we can get additional samples work on a larger data set and then the relative impact of the noise will be smaller."
        ],
        [
            "Another mechanism that they rely on is the exponential mechanism, which was proposed by Mcsharry interval in the.",
            "Context of game theory and mechanism design and get theory.",
            "And this mechanism gets a query function function that gives a score to each output of of the computation depending on the database.",
            "And this query function is used to induce a probability distribution over the outcomes and one hand this distribution is set such that outcomes with higher score are more likely to be chosen by this mechanism.",
            "On the other hand, it's calibrated with sensitivity of the query function it with epsilon to ensure that the sampling process maintains differential privacy, and you can see that when epsilons are very small and we're very strong privacy, this distribution becomes flat.",
            "And as we have higher epsilon.",
            "A higher scoring outcomes are much more likely to be chosen, so will this work on differential privacy?",
            "We now shift to discuss the decision trees which are determining application.",
            "We focus on this paper and in decision trees we have several attributes and we want to use them to predict a class attribute.",
            "An basic algorithm for ID 3 is for this introduction is ID 3 by Quillen, and.",
            "Basically, the algorithm works recursively.",
            "At each step we choose the attribute that helps us the most in predicting the class value.",
            "This is done by using a measure called information gain.",
            "And after we choose this attribute, we split the learning samples according to the value that they take on this attribute, and we repeat the process recursively on each subset and this process stops either when we are out of attributes or when we have node where all the records have the same class value, in which case we turn the node into a lift and in both cases the lift is labeled with the majority class."
        ],
        [
            "So if you want to have a differential private version of this algorithm, there are several needs things with."
        ],
        [
            "To do first of all, because we have a limited privacy budget, we also introduce a limit on the tree depth.",
            "This allows us to know in advance how many queries we are going to ask, and then we can set the privacy budget for each query accordingly.",
            "A second in the leaf we cannot accurately get the majority class.",
            "Instead we use noisy counts to evaluate the number of records to take each class value, and we use this approximation to take the majority class.",
            "And the problem is that if we have two few records in the lift, then the noise will overcome the accurate counts and we will do will choose the wrong class.",
            "So to avoid this we introduce threshold.",
            "It depends on the magnitude of noise that we had and once the number of cuts drops below this threshold will not further split the tree."
        ],
        [
            "Finally, the way we choose an attribute should also preserve differential privacy, and there are several ways we can."
        ],
        [
            "To do this, one way was proposed in the context of the sublinear queries framework predecessor differential privacy by blood work and sharing the same, and this approach they approximate information gain using noisy counts, so we need a lot of queries to make one decision.",
            "Picking an attribute and this approach introduces a lot of noise to the process.",
            "Instead we evaluated.",
            "We decided to use the exponential mechanism and we evaluated three candidate query functions to score each attribute.",
            "So we looked into information gain from the ID 3 algorithm algorithm.",
            "We looked into Gini index which is used in another decision tree algorithm called CART and we use the Max splitting criterion which simply counts the number of records to take the maximum.",
            "The majority class in each leaf.",
            "And here is the important point.",
            "There was several works that the evaluated try to evaluate which splitting criterion is the best and there is no clear winner an all methods provide about the same accuracy, but this changes completely when we have privacy considerations in the picture because each of these methods as a different sensitivity.",
            "The Max score is sensitivity 1 gene in excess sensitivity two, and the sensitivity of information gain depends on the size of the data set and this means that for given a specific privacy budget we need to introduce different amounts of noise when we use each of these math."
        ],
        [
            "And to evaluate the differences, we started by looking into a single split.",
            "We created a synthetic data using the small tree to the left and some of the experiment we introduce noise.",
            "We fix the privacy budget to 0.1 and we tested the accuracy we get with the different sizes of the data sets.",
            "And the algorithm that uses only noisy counts and it didn't do very well because the number of sample was just not enough to overcome the noise and the exponential mechanism with the information gain query function did a little better, but still not good enough.",
            "And the information and the Max score and the Genie score, which have lower sensitivity, did much better and in some cases we even got accuracy that is better than the ID 3 baseline.",
            "Without privacy becausw the ID 3 algorithm overfits the learning sample.",
            "It actually learns the noise while the privacy restriction and limiting the tree depth prevented this from happening.",
            "In the other algorithms and in the paper will show additional examples with deeper trees and with the real data.",
            "And we see this phenomenon in a.",
            "Actually all the cases, the sensitivity of the function is quite an impact on the accuracy that we get, and there is an advantage is an advantage to the algorithm with the lowest sensitivity."
        ],
        [
            "So to conclude, a.",
            "Despite the privacy constraints of differential privacy, we were able to get reasonable accuracy on the average case in with algorithms and the key factor was to take the privacy consideration into account when designing the algorithm.",
            "We want to choose methods that have lower sensitivity to get better accuracy, and still there is a lot of room for improvement.",
            "First of all, when we build algorithm an, we split the budget between the queries.",
            "We just split it equally and we could probably do better if we took a smarter approach to how to manage the budget.",
            "In addition, there was a lot of variance in results in some of the cases, especially when we have very low epsilons with high privacy.",
            "Possible way to handle this might be to do several decision trees as was done in another work by Jonathan and coauthors on a random forests.",
            "And finally.",
            "There is a rapid progress in theory and mechanisms of differential privacy, and by adopting advanced techniques we can probably increase the accuracy of the algorithms that we use.",
            "So thank you for attention.",
            "Yeah, thanks for the presentation again.",
            "We have time for a few questions.",
            "And please don't forget to use the mic.",
            "So you were mentioning the possibility to run multiple executions of the decision tree induction algorithm, and you are also presenting average results, but how does that refer to the fact that every time you re run the same algorithm on the same data, you have to compensate that with the privacy budget?",
            "That's correct, so there is actually another tradeoff here, because if you want to induce several trees, it means that you need to split the budget between the trees.",
            "So the question is so there is a tradeoff here, because on one hand you can lose some accuracy because each decision tree gets smaller budget.",
            "But then maybe you can get some advantage from using the collective process of using several trees.",
            "So there is a trade off.",
            "I mean, if you generate too many trees are public, each tree will just give you meaningless results and so it's another trade problem.",
            "And in some cases you can still get.",
            "You might get good results in that, so it's something that needs to be looked into.",
            "So the method you discussed, you're sort of doing 11 split at a time.",
            "Did you consider trying to?",
            "Increase the look ahead and kind of use this exponential mechanism to sample, say from depth two or depth tree depth 3 trees like they understand what I mean.",
            "To jump further ahead in the computation and so I guess this would cost you in terms of time and possibly privacy else.",
            "Yeah, so I didn't try to do this, but this could be an interesting approach.",
            "To check here.",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This work is about privacy preserving data mining, where we have two goals on one hand.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, on one hand we want to extract new patterns and knowledge from data we have.",
                    "label": 0
                },
                {
                    "sent": "For example, if you want to build a classifier, we can evaluate the utility we get from it by measuring it its accuracy or it's error rate on a test set.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we want to protect the privacy of individuals who are represented in the data.",
                    "label": 0
                },
                {
                    "sent": "To this end it to make this happen, we need to limit what can be learned from the data, so we can expect it when we have stronger privacy requirements.",
                    "label": 0
                },
                {
                    "sent": "This will result in an increased error rate, so we have this tradeoff between privacy and accuracy.",
                    "label": 1
                },
                {
                    "sent": "Different algorithms can present different tradeoffs, and in economics, a situation in which we can improve one algorithm, one parameter without harming the other is called the improvement.",
                    "label": 0
                },
                {
                    "sent": "And when a point cannot be further Pareto improved, we say it's part efficient.",
                    "label": 0
                },
                {
                    "sent": "So the collection of all the proficient points gives us the predator frontier, and this gives us the best tradeoff we can get between privacy and utility.",
                    "label": 0
                },
                {
                    "sent": "So one question you can ask is how to choose a point on the part of Frontier, and we're not dealing with this question.",
                    "label": 0
                },
                {
                    "sent": "This may depend on the application or on social norms or a regulation, our goal.",
                    "label": 0
                },
                {
                    "sent": "Is to seek ways how we can extend operator Frontier so we can get a better tradeoff between privacy and utility.",
                    "label": 0
                },
                {
                    "sent": "So in the context of data mining.",
                    "label": 1
                },
                {
                    "sent": "And there are well established methods out to measure the utility we get from the algorithm, but there is still ongoing work on defining and measuring privacy.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in this talk, and I'm going to rely on differential privacy, recent definition of privacy by work.",
                    "label": 0
                },
                {
                    "sent": "Make sure in some it.",
                    "label": 0
                },
                {
                    "sent": "And intuitively, differential privacy requires that computation we insensitive to changes in any particular individuals record.",
                    "label": 1
                },
                {
                    "sent": "So from the individual's point of view, if there is one data set where the individual circuit appears and there is another data set which is the same expect except it doesn't contain this record, and then we would want that any outcome of the computation that we get on one data set will be almost a is equally likely.",
                    "label": 0
                },
                {
                    "sent": "When we run it on the other data set, so anything that the adversary learns by running on one data set, it will probably with very high likelihood will learn from the other data set as well.",
                    "label": 1
                },
                {
                    "sent": "Formally, differential privacy requires that for any data sets and be with symmetric difference one and for any possible set of outcomes of the computation, the probability to get an outcome when executing the algorithm on one data set.",
                    "label": 1
                },
                {
                    "sent": "Will be the same as running on the other data set up to a multiplicative factor of exponent N epsilon, and we really think of epsilon is a small number below one, which means that this probability should be a close to each other.",
                    "label": 0
                },
                {
                    "sent": "So this is the worst case definition.",
                    "label": 0
                },
                {
                    "sent": "It has the advantage that it does not depend on the burger.",
                    "label": 0
                },
                {
                    "sent": "No knowledge of the attacker or the computational power that Icarus and it has a nice property of compatibility, which means that if the adversary is access to two, a independent invocations of M of the computation and each each invocation maintains epsilon differential privacy, then the probability of any outcome would shift by at most two epsilon.",
                    "label": 0
                },
                {
                    "sent": "And this actually allows use the concept of privacy budget, where the data provider sets a limit epsilon on how much personal information can be leaked in the process, and then the data miner can choose whether to run one computation which is epsilon, differentially private, or two computations which each of them a half epsilon, differentially private, or any combination of computations that will consume a total privacy budget of epsilon.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So differential privacy is the property of the computation, and there are several ways we can apply to data mining.",
                    "label": 1
                },
                {
                    "sent": "One way is to give the data miner full access to the data and its data minus responsibility to ensure that the outcome of the computation preserves differential privacy.",
                    "label": 1
                },
                {
                    "sent": "And there were several recent works that use this approach.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another approach was featured in a system called Pink Privacy Integrated queries by Maturing an.",
                    "label": 1
                },
                {
                    "sent": "In this approach we have a data access layer that enforces differential privacy.",
                    "label": 0
                },
                {
                    "sent": "It exposes an interface to the data miner and as long as the data miner accesses the data only through this interface.",
                    "label": 1
                },
                {
                    "sent": "Element doesn't really have to understand how privacy is enforced in stacking carried by this interface.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A third approach is to use a process that maintains differential privacy to create a synthetic data set that preserves some properties of the original data set, and in this approach, the data miner just runs the algorithm on the synthetic data set just as if it were the original data and the catching.",
                    "label": 1
                },
                {
                    "sent": "This approach is that if we want their strong theoretical results that say that if you want the queries to get accurate answers.",
                    "label": 1
                },
                {
                    "sent": "This process should be tailored to the exact kind of course that we're going to ask, and in some cases it even might not be possible.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this talk, we're going to focus on the second approach, where we have this interface, and we assume that we have.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "Mechanisms that we can invoke through this interface.",
                    "label": 0
                },
                {
                    "sent": "One is the Laplace mechanism proposed by work mature.",
                    "label": 1
                },
                {
                    "sent": "In this image, Smith and the central element is mechanism.",
                    "label": 0
                },
                {
                    "sent": "Is the concept of sensitivity of a function.",
                    "label": 1
                },
                {
                    "sent": "The sensitivity of the function is the largest possible change in the value of the function after changing a single record in the input.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we have a count query and changing a single record would change the outcome back most one if we sum elements over elements, attack values between zero and Lambda.",
                    "label": 0
                },
                {
                    "sent": "Then changing a single input will change the output of the sum at most Lambda and the Laplace mechanism.",
                    "label": 0
                },
                {
                    "sent": "It calculates the exact value of the function and then it adds to its noise that is distributed.",
                    "label": 0
                },
                {
                    "sent": "The sample from the Laplace distribution, which is asymmetric exponential distribution that looks like this.",
                    "label": 0
                },
                {
                    "sent": "And by calibrating this distribution with the sensitivity of the function with parameter epsilon, we can ensure that this output maintains differential privacy and you can see that a using data plus mechanism or noisy crowd noise is some.",
                    "label": 0
                },
                {
                    "sent": "A the notes that we had your actually doesn't depend on the size of the data set, and the implication is that actually the tradeoff that we have is not just between privacy, the accuracy, but we can also trade off the size of the data set.",
                    "label": 0
                },
                {
                    "sent": "So if you want to get better accuracy, one option is to increase epsilon and then we lose privacy.",
                    "label": 0
                },
                {
                    "sent": "Or if possible we can get additional samples work on a larger data set and then the relative impact of the noise will be smaller.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another mechanism that they rely on is the exponential mechanism, which was proposed by Mcsharry interval in the.",
                    "label": 1
                },
                {
                    "sent": "Context of game theory and mechanism design and get theory.",
                    "label": 0
                },
                {
                    "sent": "And this mechanism gets a query function function that gives a score to each output of of the computation depending on the database.",
                    "label": 1
                },
                {
                    "sent": "And this query function is used to induce a probability distribution over the outcomes and one hand this distribution is set such that outcomes with higher score are more likely to be chosen by this mechanism.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, it's calibrated with sensitivity of the query function it with epsilon to ensure that the sampling process maintains differential privacy, and you can see that when epsilons are very small and we're very strong privacy, this distribution becomes flat.",
                    "label": 0
                },
                {
                    "sent": "And as we have higher epsilon.",
                    "label": 0
                },
                {
                    "sent": "A higher scoring outcomes are much more likely to be chosen, so will this work on differential privacy?",
                    "label": 0
                },
                {
                    "sent": "We now shift to discuss the decision trees which are determining application.",
                    "label": 0
                },
                {
                    "sent": "We focus on this paper and in decision trees we have several attributes and we want to use them to predict a class attribute.",
                    "label": 0
                },
                {
                    "sent": "An basic algorithm for ID 3 is for this introduction is ID 3 by Quillen, and.",
                    "label": 0
                },
                {
                    "sent": "Basically, the algorithm works recursively.",
                    "label": 0
                },
                {
                    "sent": "At each step we choose the attribute that helps us the most in predicting the class value.",
                    "label": 0
                },
                {
                    "sent": "This is done by using a measure called information gain.",
                    "label": 0
                },
                {
                    "sent": "And after we choose this attribute, we split the learning samples according to the value that they take on this attribute, and we repeat the process recursively on each subset and this process stops either when we are out of attributes or when we have node where all the records have the same class value, in which case we turn the node into a lift and in both cases the lift is labeled with the majority class.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you want to have a differential private version of this algorithm, there are several needs things with.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To do first of all, because we have a limited privacy budget, we also introduce a limit on the tree depth.",
                    "label": 0
                },
                {
                    "sent": "This allows us to know in advance how many queries we are going to ask, and then we can set the privacy budget for each query accordingly.",
                    "label": 0
                },
                {
                    "sent": "A second in the leaf we cannot accurately get the majority class.",
                    "label": 0
                },
                {
                    "sent": "Instead we use noisy counts to evaluate the number of records to take each class value, and we use this approximation to take the majority class.",
                    "label": 0
                },
                {
                    "sent": "And the problem is that if we have two few records in the lift, then the noise will overcome the accurate counts and we will do will choose the wrong class.",
                    "label": 0
                },
                {
                    "sent": "So to avoid this we introduce threshold.",
                    "label": 0
                },
                {
                    "sent": "It depends on the magnitude of noise that we had and once the number of cuts drops below this threshold will not further split the tree.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, the way we choose an attribute should also preserve differential privacy, and there are several ways we can.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To do this, one way was proposed in the context of the sublinear queries framework predecessor differential privacy by blood work and sharing the same, and this approach they approximate information gain using noisy counts, so we need a lot of queries to make one decision.",
                    "label": 1
                },
                {
                    "sent": "Picking an attribute and this approach introduces a lot of noise to the process.",
                    "label": 1
                },
                {
                    "sent": "Instead we evaluated.",
                    "label": 0
                },
                {
                    "sent": "We decided to use the exponential mechanism and we evaluated three candidate query functions to score each attribute.",
                    "label": 0
                },
                {
                    "sent": "So we looked into information gain from the ID 3 algorithm algorithm.",
                    "label": 0
                },
                {
                    "sent": "We looked into Gini index which is used in another decision tree algorithm called CART and we use the Max splitting criterion which simply counts the number of records to take the maximum.",
                    "label": 1
                },
                {
                    "sent": "The majority class in each leaf.",
                    "label": 0
                },
                {
                    "sent": "And here is the important point.",
                    "label": 0
                },
                {
                    "sent": "There was several works that the evaluated try to evaluate which splitting criterion is the best and there is no clear winner an all methods provide about the same accuracy, but this changes completely when we have privacy considerations in the picture because each of these methods as a different sensitivity.",
                    "label": 0
                },
                {
                    "sent": "The Max score is sensitivity 1 gene in excess sensitivity two, and the sensitivity of information gain depends on the size of the data set and this means that for given a specific privacy budget we need to introduce different amounts of noise when we use each of these math.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to evaluate the differences, we started by looking into a single split.",
                    "label": 1
                },
                {
                    "sent": "We created a synthetic data using the small tree to the left and some of the experiment we introduce noise.",
                    "label": 0
                },
                {
                    "sent": "We fix the privacy budget to 0.1 and we tested the accuracy we get with the different sizes of the data sets.",
                    "label": 0
                },
                {
                    "sent": "And the algorithm that uses only noisy counts and it didn't do very well because the number of sample was just not enough to overcome the noise and the exponential mechanism with the information gain query function did a little better, but still not good enough.",
                    "label": 0
                },
                {
                    "sent": "And the information and the Max score and the Genie score, which have lower sensitivity, did much better and in some cases we even got accuracy that is better than the ID 3 baseline.",
                    "label": 0
                },
                {
                    "sent": "Without privacy becausw the ID 3 algorithm overfits the learning sample.",
                    "label": 1
                },
                {
                    "sent": "It actually learns the noise while the privacy restriction and limiting the tree depth prevented this from happening.",
                    "label": 0
                },
                {
                    "sent": "In the other algorithms and in the paper will show additional examples with deeper trees and with the real data.",
                    "label": 0
                },
                {
                    "sent": "And we see this phenomenon in a.",
                    "label": 0
                },
                {
                    "sent": "Actually all the cases, the sensitivity of the function is quite an impact on the accuracy that we get, and there is an advantage is an advantage to the algorithm with the lowest sensitivity.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude, a.",
                    "label": 0
                },
                {
                    "sent": "Despite the privacy constraints of differential privacy, we were able to get reasonable accuracy on the average case in with algorithms and the key factor was to take the privacy consideration into account when designing the algorithm.",
                    "label": 1
                },
                {
                    "sent": "We want to choose methods that have lower sensitivity to get better accuracy, and still there is a lot of room for improvement.",
                    "label": 0
                },
                {
                    "sent": "First of all, when we build algorithm an, we split the budget between the queries.",
                    "label": 0
                },
                {
                    "sent": "We just split it equally and we could probably do better if we took a smarter approach to how to manage the budget.",
                    "label": 0
                },
                {
                    "sent": "In addition, there was a lot of variance in results in some of the cases, especially when we have very low epsilons with high privacy.",
                    "label": 0
                },
                {
                    "sent": "Possible way to handle this might be to do several decision trees as was done in another work by Jonathan and coauthors on a random forests.",
                    "label": 0
                },
                {
                    "sent": "And finally.",
                    "label": 1
                },
                {
                    "sent": "There is a rapid progress in theory and mechanisms of differential privacy, and by adopting advanced techniques we can probably increase the accuracy of the algorithms that we use.",
                    "label": 0
                },
                {
                    "sent": "So thank you for attention.",
                    "label": 0
                },
                {
                    "sent": "Yeah, thanks for the presentation again.",
                    "label": 0
                },
                {
                    "sent": "We have time for a few questions.",
                    "label": 0
                },
                {
                    "sent": "And please don't forget to use the mic.",
                    "label": 0
                },
                {
                    "sent": "So you were mentioning the possibility to run multiple executions of the decision tree induction algorithm, and you are also presenting average results, but how does that refer to the fact that every time you re run the same algorithm on the same data, you have to compensate that with the privacy budget?",
                    "label": 0
                },
                {
                    "sent": "That's correct, so there is actually another tradeoff here, because if you want to induce several trees, it means that you need to split the budget between the trees.",
                    "label": 0
                },
                {
                    "sent": "So the question is so there is a tradeoff here, because on one hand you can lose some accuracy because each decision tree gets smaller budget.",
                    "label": 0
                },
                {
                    "sent": "But then maybe you can get some advantage from using the collective process of using several trees.",
                    "label": 0
                },
                {
                    "sent": "So there is a trade off.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you generate too many trees are public, each tree will just give you meaningless results and so it's another trade problem.",
                    "label": 0
                },
                {
                    "sent": "And in some cases you can still get.",
                    "label": 0
                },
                {
                    "sent": "You might get good results in that, so it's something that needs to be looked into.",
                    "label": 0
                },
                {
                    "sent": "So the method you discussed, you're sort of doing 11 split at a time.",
                    "label": 0
                },
                {
                    "sent": "Did you consider trying to?",
                    "label": 0
                },
                {
                    "sent": "Increase the look ahead and kind of use this exponential mechanism to sample, say from depth two or depth tree depth 3 trees like they understand what I mean.",
                    "label": 0
                },
                {
                    "sent": "To jump further ahead in the computation and so I guess this would cost you in terms of time and possibly privacy else.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I didn't try to do this, but this could be an interesting approach.",
                    "label": 0
                },
                {
                    "sent": "To check here.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}