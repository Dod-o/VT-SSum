{
    "id": "id2fcxuspjtvu5zfqydb2n4atq5utp6b",
    "title": "Scaling Out Big Data Missing Value Imputations",
    "info": {
        "author": [
            "Christos Anagnostopoulos, School of Computing Science, University of Glasgow"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Knowledge Extraction",
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/kdd2014_anagnostopoulos_value_iputations/",
    "segmentation": [
        [
            "Good morning, my name is Chris Pharmaceuticals from Universal class code.",
            "We talk about scaling out big data, missing value possessions."
        ],
        [
            "The middle problem mean productive quality in big data processing is the presence of missing values, especially when we're dealing with a multidimensional piece of data.",
            "We're going to see missing values in survey databases.",
            "Didn't expression microarray data sets, etc.",
            "So the problem is that bias might be introduced into the interest knowledge."
        ],
        [
            ", solutions to the missing value problem is that we can ignore or exclude missing data.",
            "Mixing value data.",
            "Which is the simplest one, OK and the other one is to fill in missing values that is also known as reputation that we have to define a missing value substitution algorithm in order to replace the missing values with most possible data.",
            "However, this supposes an imputation error, which is defined as the difference between the between the actual I guess the unknown value with the with the predicted already imputed Polygon."
        ],
        [
            "Nowadays, most of the missing value substitution algorithms.",
            "To ensure low lower however they are computationally expensive, especially their performance.",
            "They perform dimensional data size.",
            "On the other hand, we have to deal with large scale data set which grow significantly with time and the fact that missing valutation requests arrival rate is getting higher higher when we have to.",
            "Dealing with when the user community is getting larger."
        ],
        [
            "Moreover, not old missing basic traditional algorithm tascar paralyzable.",
            "If so, that is if we could define and parallelizable missing by substitution algorithm.",
            "That is.",
            "For example, we can adapt the map reduce paradigm.",
            "We can see that note all data space of the data set are relevant for reputation that there are some specific regions in the data set that can negatively contributed to the final estimate."
        ],
        [
            "We can see here an example.",
            "He rings up, have considered well given 2 dimensional data space and were given the probability density function and consider we have a point here which is the first dimension is known.",
            "But the second mission is missing.",
            "We claim that it is better for the missing punches beautician Alworth to take into consideration only the pieces that close to this one, close to there to the red 1 instead of using all piece of the data set."
        ],
        [
            "So what we have up to now is a single machine.",
            "Let me call it Godzilla 'cause it able to contain security data set and then the example to serving to serve missing validation request by through the performance evaluation algorithm.",
            "Now a similar idea of obtaining scalability and efficiency is to.",
            "Is."
        ],
        [
            "After replacing these codes will OK through another by and up by fixed number of Community machines, also called US cohort, that this idea is to partition the big data settings.",
            "Smaller data set is smaller data set OK and then to assign it.",
            "Cohort to this to smaller data set and then so the cost is able to run locally.",
            "The missing value absolution element and then we can aggregate all partial estimate in order to conclude on the on the file and estimate.",
            "We obtain efficiency because now the cohort is able to run the missing value.",
            "Substitution or smaller part of the city said over huge one OK and scalability where I said that we can add or remove cohort."
        ],
        [
            "However, we have to examine the impact of this idea on the mutation error.",
            "That is considered out again we have Godzilla and we can we have say 30 cohorts.",
            "OK and were given a missing validation request and we measure the relative root mean square error.",
            "That is a realization of the imputation error.",
            "Here we can see the Godzilla error and here we plot the error of obtained by each cohort and we also plotted in increasing order.",
            "We can see that there are some cohorts who that correspond to higher than that.",
            "Godzilla, but more individuals in there recently.",
            "There are some cohorts whose error is compatible or lower than that of Godzilla.",
            "This means that you have to identify this subset.",
            "Of course, in order to against them in parallel for proceeding with the missing validation request.",
            "So in order to deal with this problem, OK, which achieves eficiency scalability and compatible, or even a better accuracy than that of Godzilla."
        ],
        [
            "We define a centralized system called Pythia, which is able to predict the most appropriate subsets of cohort for against them, in part, in performing this value algorithm parallel, this means that that fear has to locali maintain a very specific information which derives from the data set of its course in order to conclude on the best appropriate subset of cohort, we call this information our signature, and we define the letter so.",
            "The benefit here of the of the second idea is that we can achieve better clarity instead of engaging all cohorts in parallel and then aggregate their corresponding results or using only Godzilla."
        ],
        [
            "As I've said before, the signatories they formation that could be exploited by before in order to proceed with the best appropriate subset of cohort in our paper signature refers to a class ring structure over the data set of each cohort.",
            "That is, each code incrementally clusters its data by adopting the by adopting the adaptive resonance theory, computing division algorithm, and then signature is consists of a set of all cluster heads that correspond to the data set finally collects.",
            "Call signature and stores are local.",
            "No."
        ],
        [
            "One Peter has called his own signature collected.",
            "We can proceed with the coupon code prediction that is considerable that were given missing value.",
            "Potential request that is a multi dimensional P data vector that certain dimensions are missing.",
            "That is, certain values of the dimensional missing and then Pythia claims that a code is candidate for performing the miscible substitution algorithm if and only if the input OK.",
            "This means the application requests is classified.",
            "At least one class ahead of the corresponding data sets conquered the data set, and we say that I need with classifieds to classic it if and only if the Euclidean distance or any well defined distance of the non missing values values of the input with the corresponding values of the classic.",
            "It is below a threshold which is defined as the parameter as a function of the vigilance parametrically adaptive resonance theory algorithm."
        ],
        [
            "So here is our idea.",
            "We have a huge data set or partition in certain smaller smaller part.",
            "We assign a cohort.",
            "It's part.",
            "Here we define Pythia, it's called local, generated is seen as a signature and sent it back to Pythia, and then Pythia, upon request of a missing value, imputation requests is able to identify the best possible subset of copper in order to proceed with the missing value creation process."
        ],
        [
            "We propose two cohort subset selection algorithms.",
            "The first algorithm is cost aware algorithm, which we try to minimize the communication between PC and cohort.",
            "Actually, in this algorithm, PYTHIA communicates, communicates with only one cohort whose cluster head is the closest to the input among all the predicted cohorts."
        ],
        [
            "And.",
            "The second algorithm is accuracy where where algorithm in which communicates community only with each predicted cohort, and then each cohort is recently, is responsible for local performing vessels in the missing value substitution algorithm and then thier by adopting a wait aggregation operator is able to receive all partial estimates and then to proceed with the final decision."
        ],
        [
            "Now it turns on in terms of for four months were interested in production efficiency and accuracy when we talk about implementation efficiency, women's latency, that is the time that we fear takes in order to process a missing value request speed up how fast typifies compared to Godzilla and throughput, the rate of reputation delivered by Bethea and professional accuracy.",
            "We measure the rhythmic square error and we experimented with two well known reputation algorithm, the weight.",
            "Nearest neighbors and the question mark variate regression."
        ],
        [
            "Here we can float the rate of reputations versus the number of cohorts.",
            "For high dimensional pieces of data, all we can see.",
            "You can see all that yet as I see here is the throughput achieved by Godzilla and here is the throughput achieved by the idea of engaging all cohort in parallel for for amputation requests.",
            "And here is the throughput achieved by by the idea of engaging only a small part only the most possible subset of cohorts in order to achieve the same.",
            "In order to proceed with reputation requests."
        ],
        [
            "In terms of accuracy, we measure the root mean squared error of versus the number of cohorts, and we can see here that the there are active like Godzilla and error of the accuracy where and the cost aware algorithm.",
            "And here is the error of the of the idea of engaging all code parallel.",
            "That is, apart from scalability and efficiency, will conceive compatible or even lower error than that of Godzilla.",
            "Game."
        ],
        [
            "Thank you very much for your attention.",
            "OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning, my name is Chris Pharmaceuticals from Universal class code.",
                    "label": 0
                },
                {
                    "sent": "We talk about scaling out big data, missing value possessions.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The middle problem mean productive quality in big data processing is the presence of missing values, especially when we're dealing with a multidimensional piece of data.",
                    "label": 1
                },
                {
                    "sent": "We're going to see missing values in survey databases.",
                    "label": 1
                },
                {
                    "sent": "Didn't expression microarray data sets, etc.",
                    "label": 1
                },
                {
                    "sent": "So the problem is that bias might be introduced into the interest knowledge.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": ", solutions to the missing value problem is that we can ignore or exclude missing data.",
                    "label": 1
                },
                {
                    "sent": "Mixing value data.",
                    "label": 0
                },
                {
                    "sent": "Which is the simplest one, OK and the other one is to fill in missing values that is also known as reputation that we have to define a missing value substitution algorithm in order to replace the missing values with most possible data.",
                    "label": 0
                },
                {
                    "sent": "However, this supposes an imputation error, which is defined as the difference between the between the actual I guess the unknown value with the with the predicted already imputed Polygon.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nowadays, most of the missing value substitution algorithms.",
                    "label": 0
                },
                {
                    "sent": "To ensure low lower however they are computationally expensive, especially their performance.",
                    "label": 1
                },
                {
                    "sent": "They perform dimensional data size.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we have to deal with large scale data set which grow significantly with time and the fact that missing valutation requests arrival rate is getting higher higher when we have to.",
                    "label": 1
                },
                {
                    "sent": "Dealing with when the user community is getting larger.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Moreover, not old missing basic traditional algorithm tascar paralyzable.",
                    "label": 0
                },
                {
                    "sent": "If so, that is if we could define and parallelizable missing by substitution algorithm.",
                    "label": 1
                },
                {
                    "sent": "That is.",
                    "label": 0
                },
                {
                    "sent": "For example, we can adapt the map reduce paradigm.",
                    "label": 0
                },
                {
                    "sent": "We can see that note all data space of the data set are relevant for reputation that there are some specific regions in the data set that can negatively contributed to the final estimate.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can see here an example.",
                    "label": 0
                },
                {
                    "sent": "He rings up, have considered well given 2 dimensional data space and were given the probability density function and consider we have a point here which is the first dimension is known.",
                    "label": 0
                },
                {
                    "sent": "But the second mission is missing.",
                    "label": 0
                },
                {
                    "sent": "We claim that it is better for the missing punches beautician Alworth to take into consideration only the pieces that close to this one, close to there to the red 1 instead of using all piece of the data set.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we have up to now is a single machine.",
                    "label": 1
                },
                {
                    "sent": "Let me call it Godzilla 'cause it able to contain security data set and then the example to serving to serve missing validation request by through the performance evaluation algorithm.",
                    "label": 0
                },
                {
                    "sent": "Now a similar idea of obtaining scalability and efficiency is to.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After replacing these codes will OK through another by and up by fixed number of Community machines, also called US cohort, that this idea is to partition the big data settings.",
                    "label": 1
                },
                {
                    "sent": "Smaller data set is smaller data set OK and then to assign it.",
                    "label": 0
                },
                {
                    "sent": "Cohort to this to smaller data set and then so the cost is able to run locally.",
                    "label": 0
                },
                {
                    "sent": "The missing value absolution element and then we can aggregate all partial estimate in order to conclude on the on the file and estimate.",
                    "label": 0
                },
                {
                    "sent": "We obtain efficiency because now the cohort is able to run the missing value.",
                    "label": 1
                },
                {
                    "sent": "Substitution or smaller part of the city said over huge one OK and scalability where I said that we can add or remove cohort.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, we have to examine the impact of this idea on the mutation error.",
                    "label": 0
                },
                {
                    "sent": "That is considered out again we have Godzilla and we can we have say 30 cohorts.",
                    "label": 0
                },
                {
                    "sent": "OK and were given a missing validation request and we measure the relative root mean square error.",
                    "label": 0
                },
                {
                    "sent": "That is a realization of the imputation error.",
                    "label": 0
                },
                {
                    "sent": "Here we can see the Godzilla error and here we plot the error of obtained by each cohort and we also plotted in increasing order.",
                    "label": 1
                },
                {
                    "sent": "We can see that there are some cohorts who that correspond to higher than that.",
                    "label": 0
                },
                {
                    "sent": "Godzilla, but more individuals in there recently.",
                    "label": 0
                },
                {
                    "sent": "There are some cohorts whose error is compatible or lower than that of Godzilla.",
                    "label": 0
                },
                {
                    "sent": "This means that you have to identify this subset.",
                    "label": 0
                },
                {
                    "sent": "Of course, in order to against them in parallel for proceeding with the missing validation request.",
                    "label": 0
                },
                {
                    "sent": "So in order to deal with this problem, OK, which achieves eficiency scalability and compatible, or even a better accuracy than that of Godzilla.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We define a centralized system called Pythia, which is able to predict the most appropriate subsets of cohort for against them, in part, in performing this value algorithm parallel, this means that that fear has to locali maintain a very specific information which derives from the data set of its course in order to conclude on the best appropriate subset of cohort, we call this information our signature, and we define the letter so.",
                    "label": 0
                },
                {
                    "sent": "The benefit here of the of the second idea is that we can achieve better clarity instead of engaging all cohorts in parallel and then aggregate their corresponding results or using only Godzilla.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As I've said before, the signatories they formation that could be exploited by before in order to proceed with the best appropriate subset of cohort in our paper signature refers to a class ring structure over the data set of each cohort.",
                    "label": 0
                },
                {
                    "sent": "That is, each code incrementally clusters its data by adopting the by adopting the adaptive resonance theory, computing division algorithm, and then signature is consists of a set of all cluster heads that correspond to the data set finally collects.",
                    "label": 1
                },
                {
                    "sent": "Call signature and stores are local.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One Peter has called his own signature collected.",
                    "label": 0
                },
                {
                    "sent": "We can proceed with the coupon code prediction that is considerable that were given missing value.",
                    "label": 0
                },
                {
                    "sent": "Potential request that is a multi dimensional P data vector that certain dimensions are missing.",
                    "label": 0
                },
                {
                    "sent": "That is, certain values of the dimensional missing and then Pythia claims that a code is candidate for performing the miscible substitution algorithm if and only if the input OK.",
                    "label": 0
                },
                {
                    "sent": "This means the application requests is classified.",
                    "label": 0
                },
                {
                    "sent": "At least one class ahead of the corresponding data sets conquered the data set, and we say that I need with classifieds to classic it if and only if the Euclidean distance or any well defined distance of the non missing values values of the input with the corresponding values of the classic.",
                    "label": 1
                },
                {
                    "sent": "It is below a threshold which is defined as the parameter as a function of the vigilance parametrically adaptive resonance theory algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is our idea.",
                    "label": 0
                },
                {
                    "sent": "We have a huge data set or partition in certain smaller smaller part.",
                    "label": 0
                },
                {
                    "sent": "We assign a cohort.",
                    "label": 0
                },
                {
                    "sent": "It's part.",
                    "label": 0
                },
                {
                    "sent": "Here we define Pythia, it's called local, generated is seen as a signature and sent it back to Pythia, and then Pythia, upon request of a missing value, imputation requests is able to identify the best possible subset of copper in order to proceed with the missing value creation process.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We propose two cohort subset selection algorithms.",
                    "label": 0
                },
                {
                    "sent": "The first algorithm is cost aware algorithm, which we try to minimize the communication between PC and cohort.",
                    "label": 0
                },
                {
                    "sent": "Actually, in this algorithm, PYTHIA communicates, communicates with only one cohort whose cluster head is the closest to the input among all the predicted cohorts.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The second algorithm is accuracy where where algorithm in which communicates community only with each predicted cohort, and then each cohort is recently, is responsible for local performing vessels in the missing value substitution algorithm and then thier by adopting a wait aggregation operator is able to receive all partial estimates and then to proceed with the final decision.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now it turns on in terms of for four months were interested in production efficiency and accuracy when we talk about implementation efficiency, women's latency, that is the time that we fear takes in order to process a missing value request speed up how fast typifies compared to Godzilla and throughput, the rate of reputation delivered by Bethea and professional accuracy.",
                    "label": 1
                },
                {
                    "sent": "We measure the rhythmic square error and we experimented with two well known reputation algorithm, the weight.",
                    "label": 0
                },
                {
                    "sent": "Nearest neighbors and the question mark variate regression.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here we can float the rate of reputations versus the number of cohorts.",
                    "label": 1
                },
                {
                    "sent": "For high dimensional pieces of data, all we can see.",
                    "label": 0
                },
                {
                    "sent": "You can see all that yet as I see here is the throughput achieved by Godzilla and here is the throughput achieved by the idea of engaging all cohort in parallel for for amputation requests.",
                    "label": 0
                },
                {
                    "sent": "And here is the throughput achieved by by the idea of engaging only a small part only the most possible subset of cohorts in order to achieve the same.",
                    "label": 0
                },
                {
                    "sent": "In order to proceed with reputation requests.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In terms of accuracy, we measure the root mean squared error of versus the number of cohorts, and we can see here that the there are active like Godzilla and error of the accuracy where and the cost aware algorithm.",
                    "label": 1
                },
                {
                    "sent": "And here is the error of the of the idea of engaging all code parallel.",
                    "label": 0
                },
                {
                    "sent": "That is, apart from scalability and efficiency, will conceive compatible or even lower error than that of Godzilla.",
                    "label": 0
                },
                {
                    "sent": "Game.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        }
    }
}