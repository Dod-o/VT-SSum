{
    "id": "tofcalq4kqa3nzkayykvi6iksr7fiweh",
    "title": "Iguana : A Generic Framework for Benchmarking the Read-Write Performance of Triple Stores",
    "info": {
        "author": [
            "Felix Conrads, Agile Knowledge Engineering and Semantic Web (AKSW), University of Leipzig"
        ],
        "published": "Nov. 28, 2017",
        "recorded": "October 2017",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2017_conrads_triple_stores/",
    "segmentation": [
        [
            "Hey so I'm phase conrads and this is joint work with Jens Lehmann moment Sally, moment, Moze and Axel and Ganga iguana is a generic generic framework for benchmarking.",
            "Read, write performance of triple stores.",
            "So why do we need that?",
            "We have several benchmarks and like Berlin, Sparker benchmark, SP2B, Alabama three PDS Parker Benchmark and they are great.",
            "But what we don't have is stress test."
        ],
        [
            "So we're using crowing all the time we create a DB pedia all day and do it parallels.",
            "So what we do have?",
            "Is an endpoint which has to be really robust about parallel request.",
            "And if you want to update it life like DB Pedia life does.",
            "You have to also considering updates and except for BS PM, no.",
            "None of those benchmarks acid further."
        ],
        [
            "We don't have a unified benchmark execution, which means our results are incomparable.",
            "But to challenge this, retried to implement Iguana, and we done this with the."
        ],
        [
            "For Cara sticks.",
            "For benchmarks we try to be relevant.",
            "We try to be portable, scalable and understandable so we return results.",
            "Using standard measures will be returned, crows per second, cromix is power and everybody understands that falls on its scalable.",
            "It doesn't matter which data set you use or which benchmark or how many users you want to simulate.",
            "You can just configure it.",
            "And iguanas written in Java so it's completely portable.",
            "And."
        ],
        [
            "Yeah, this is basically the architecture we have.",
            "The core and the result processing module.",
            "The core, just simple, executes a stress test and get the results to send them to the result processing, which then converts, converts results to the metrics."
        ],
        [
            "Let's start with the court.",
            "Especially the stress test.",
            "So as I said, we want to show the real case like parallel requests while updating so you don't have to do updates.",
            "DB Pedia doesn't do it obviously.",
            "But the stress test starts.",
            "There were several sparker workers simulating several users and does the same with update workers.",
            "So we provide."
        ],
        [
            "Realistic scenario simulating these users and also in the rare case you have users directly at the endpoint and over the whole world, so you can configure network latency froze on you don't work on a cold cache so you have to do a warm up to insert queries in the cache.",
            "Phone you can choose between restriction time limit or number of Chrome mixes.",
            "So when the test ends, like if you want like 5000 premixes then that you can just config."
        ],
        [
            "So let's see how this Parker worker works.",
            "The workflow is pretty easy like you have a Crow set for each sparkle worker and it starts at a random query and goes just looping and looping until the end restriction was reached.",
            "And to be fair, it starts always at the same query for each triple store.",
            "Just park workers support source.",
            "Parker 1.1 Crow is so select ask, describe and construct and also supports query patterns as seen in the debut PDS Barker Benchmark.",
            "Joe."
        ],
        [
            "As seen here, we have some variables like person, person V1 and V2 and we want to instantiate and with real data so you have a reference and point and it converts the actual query to the lower one and just get some results.",
            "Real results for V1 and V2 and can instantiate the Crow pattern of them so you can limit.",
            "So we have a K there a limit of K so you can incent Cape cake rose.",
            "For one particular pattern, just is done to prevent caching.",
            "For more details."
        ],
        [
            "DBPR Sparkle benchmark did a lot of work down the same."
        ],
        [
            "If the update worker it has update queries on a file on an update in an update folder, if you use an update folder, you have to do this in this particular format.",
            "This is this has advantage that you can sort all this updates you don't have like random updating, but you most cases you have like first random then and at first then random removable then again and at addition to the Triple Store.",
            "So you have an update strategy.",
            "And according to this update, strategies worker starts and will execute the next update and will ever made amount of time and then executes the next update and distance onto the tasks and or there are no more updates.",
            "The waiting among."
        ],
        [
            "Of time is too.",
            "Achieve a distributed updating, like if you down in one hour benchmark.",
            "You don't want the updates in the first 10 minutes.",
            "You want him distribute it so you can see actually the performance of crowing while updating.",
            "So.",
            "The result."
        ],
        [
            "Processing modules support the following metrics queries per second.",
            "Premixes power the number of courage power and if you want to see the caching of extra queries you can also save every query execution.",
            "The metrics are easily extendable.",
            "And the."
        ],
        [
            "Complete results will be stored as as a CSV file or as an amplifier, or as I recommend, and triple stores so you can query the lights directly with sparkle."
        ],
        [
            "As I said, iguana is very extensible.",
            "You can extend almost everything like the task like the stress test data.",
            "You can use data generators, you can add Crow hand us if the pattern is not working for you, you cannot metrics you can at result storage, so you can also implement the DIA fat to task if you want to."
        ],
        [
            "And so we did an evaluation as well.",
            "And we did it obviously on the same measure you can see the complete specs in our paper and we used to main datasets, especially DB pedia and semantic web dog food for the pedia.",
            "We used the initial data set with around 400 million triples and re cut it in half and enter 10%.",
            "So we have four datasets with different sizes.",
            "Two comparisons of Semantic Web dog food.",
            "Triple triples are like in 35,000, so it's a.",
            "Very, very small triple set.",
            "We did, the other configurations are token from the DPS Parker benchmark framework, DPS Barker benchmarks.",
            "Sorry with one our execution time and a 20 minute warm up and instead of using the GPS, Parker queries reused feasable to get generate query logs and to generate crowds out of a Crow log.",
            "So we use real data or so we use real data sets and real queries and all.",
            "All of those 250 crows are very complex.",
            "And you will see it in our relations."
        ],
        [
            "So for the updates we use DB pedia life change set for the paideia.",
            "Again, real data for Semantic Web dog food we have to generate an.",
            "We did check the dump of Semantic Web dog food and the endpoint and just choose the one who's not anymore in there and choose additional in there.",
            "So we have our change set again with real data.",
            "We simulate 1, four and 16 spark workers and with and without updates."
        ],
        [
            "So let's look at our baseline.",
            "This looks pretty well, right?",
            "It's going to be high as a data set gets.",
            "The last cruise can be executed, and especially so, but if you see like the difference between vetoes.",
            "Oh, and for example, blazegraph ozeki, there's a lot of difference for the flaky and bless you have couldn't even handle 100 of those queries.",
            "And if you've seen the DPS Barker benchmark, they could have almost like two 1000 to 10,000 queries of the.",
            "DPS Parker benchmark rares.",
            "The vehicles are one still got 10,000 crabbies for the semantic Web.",
            "Dog food is even higher and."
        ],
        [
            "We added some users so as you can see.",
            "If we add some users to it so parallel requests.",
            "All of the other.",
            "All of our triple stores perform more queries so they can handle parallel requests and very good.",
            "Actually, the amount of troubles taken get through as is getting higher and higher while the user just don't have and have a problem.",
            "They still getting 1000 queries.",
            "True, so this is for all of the datasets there's no problem.",
            "So we."
        ],
        [
            "Try to do based on with updates so to check what's effect of updates and again as you can see here.",
            "There is no effect.",
            "We don't see an effect in this diagrams.",
            "In the left one there should be 6 lines and almost not at Delmos tree.",
            "Um Jason minimal effect.",
            "You don't care.",
            "You don't need to care about and.",
            "Especially in the semantic Web dog food you can't see probably, but brace graph with updates was a little bit faster even without updates, so you can really see updates without parallel quest doesn't matter.",
            "So again, let's add some spa."
        ],
        [
            "To use us to it.",
            "And again, as you can see.",
            "We still have no problem with updates, so especially expect for the semantic Web dog food, but on the others on the other, on the DPD a data set.",
            "We don't have a problem.",
            "The effect is minimal.",
            "And for the semantic Web dog food.",
            "You can see there isn't.",
            "There isn't a fact.",
            "But this can also be due to our change set as we generated them and so we have to look into this further, obviously to check if updates affect.",
            "If you can optimize updates.",
            "If this other DPD alive ones optimized.",
            "This is semantic web dog food just too much as we took it, so we can really check how do we can update the endpoints life while they're getting requests and."
        ],
        [
            "Call jets basically Dan.",
            "I hope I can could show you that Iguana provides a unified Spark benchmark execution framework.",
            "And that provides new insights and further on that it's generic so it can execute on every data set an point and Sparkle, sparkle, update queries.",
            "So for the outlook I had a demonstration on mine and talked with a lot of people and I couldn't fit in all the outlooks.",
            "I was suggested to input and I hope I can do all of them, but for particular I want to add sparkle so additive streaming support.",
            "Add ref configuration so you don't have so you just can add a tribble at an RDF file into Andover.",
            "Just generate the benchmark if you have any suggestions, please let me know.",
            "I'm happy to actually invent and implement the fate.",
            "And."
        ],
        [
            "Death rate iguanas open source if you want to code with us.",
            "Feel free to.",
            "Yeah, any questions.",
            "You you said that you run everything in the one single machine, but sometimes when you are running everything on the single machine you have interference between the system because you are you are writing at the same disk.",
            "You can saturate some part of a system.",
            "My question is how?",
            "How you can be sure of your measurement about time, especially in clients.",
            "That's a very good question, actually, um.",
            "I can show you I can tell you the process we do and so we use Jenna.",
            "And we just took the time, the system time from our from our execution server and just go until the.",
            "The results are reached so so we checking the results.",
            "If there are any.",
            "So it's not just like oh they can.",
            "They can cheat.",
            "But they have to actually get results, even though if they empty that's OK, but they have to bring back results and then we just stop and so we count that time.",
            "It's really hard to just count the time that actually triplestore needs.",
            "But you have to ask yourself if you want to be cause if you career triple store you don't have.",
            "You don't took the time of the triple Swords House, but the user performance.",
            "Like the performance you get if you creating the endpoint directly."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hey so I'm phase conrads and this is joint work with Jens Lehmann moment Sally, moment, Moze and Axel and Ganga iguana is a generic generic framework for benchmarking.",
                    "label": 1
                },
                {
                    "sent": "Read, write performance of triple stores.",
                    "label": 1
                },
                {
                    "sent": "So why do we need that?",
                    "label": 0
                },
                {
                    "sent": "We have several benchmarks and like Berlin, Sparker benchmark, SP2B, Alabama three PDS Parker Benchmark and they are great.",
                    "label": 0
                },
                {
                    "sent": "But what we don't have is stress test.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're using crowing all the time we create a DB pedia all day and do it parallels.",
                    "label": 0
                },
                {
                    "sent": "So what we do have?",
                    "label": 0
                },
                {
                    "sent": "Is an endpoint which has to be really robust about parallel request.",
                    "label": 0
                },
                {
                    "sent": "And if you want to update it life like DB Pedia life does.",
                    "label": 0
                },
                {
                    "sent": "You have to also considering updates and except for BS PM, no.",
                    "label": 0
                },
                {
                    "sent": "None of those benchmarks acid further.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We don't have a unified benchmark execution, which means our results are incomparable.",
                    "label": 0
                },
                {
                    "sent": "But to challenge this, retried to implement Iguana, and we done this with the.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For Cara sticks.",
                    "label": 0
                },
                {
                    "sent": "For benchmarks we try to be relevant.",
                    "label": 0
                },
                {
                    "sent": "We try to be portable, scalable and understandable so we return results.",
                    "label": 0
                },
                {
                    "sent": "Using standard measures will be returned, crows per second, cromix is power and everybody understands that falls on its scalable.",
                    "label": 1
                },
                {
                    "sent": "It doesn't matter which data set you use or which benchmark or how many users you want to simulate.",
                    "label": 0
                },
                {
                    "sent": "You can just configure it.",
                    "label": 0
                },
                {
                    "sent": "And iguanas written in Java so it's completely portable.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, this is basically the architecture we have.",
                    "label": 0
                },
                {
                    "sent": "The core and the result processing module.",
                    "label": 0
                },
                {
                    "sent": "The core, just simple, executes a stress test and get the results to send them to the result processing, which then converts, converts results to the metrics.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's start with the court.",
                    "label": 0
                },
                {
                    "sent": "Especially the stress test.",
                    "label": 0
                },
                {
                    "sent": "So as I said, we want to show the real case like parallel requests while updating so you don't have to do updates.",
                    "label": 0
                },
                {
                    "sent": "DB Pedia doesn't do it obviously.",
                    "label": 0
                },
                {
                    "sent": "But the stress test starts.",
                    "label": 0
                },
                {
                    "sent": "There were several sparker workers simulating several users and does the same with update workers.",
                    "label": 0
                },
                {
                    "sent": "So we provide.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Realistic scenario simulating these users and also in the rare case you have users directly at the endpoint and over the whole world, so you can configure network latency froze on you don't work on a cold cache so you have to do a warm up to insert queries in the cache.",
                    "label": 0
                },
                {
                    "sent": "Phone you can choose between restriction time limit or number of Chrome mixes.",
                    "label": 1
                },
                {
                    "sent": "So when the test ends, like if you want like 5000 premixes then that you can just config.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's see how this Parker worker works.",
                    "label": 0
                },
                {
                    "sent": "The workflow is pretty easy like you have a Crow set for each sparkle worker and it starts at a random query and goes just looping and looping until the end restriction was reached.",
                    "label": 1
                },
                {
                    "sent": "And to be fair, it starts always at the same query for each triple store.",
                    "label": 0
                },
                {
                    "sent": "Just park workers support source.",
                    "label": 0
                },
                {
                    "sent": "Parker 1.1 Crow is so select ask, describe and construct and also supports query patterns as seen in the debut PDS Barker Benchmark.",
                    "label": 0
                },
                {
                    "sent": "Joe.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As seen here, we have some variables like person, person V1 and V2 and we want to instantiate and with real data so you have a reference and point and it converts the actual query to the lower one and just get some results.",
                    "label": 0
                },
                {
                    "sent": "Real results for V1 and V2 and can instantiate the Crow pattern of them so you can limit.",
                    "label": 0
                },
                {
                    "sent": "So we have a K there a limit of K so you can incent Cape cake rose.",
                    "label": 0
                },
                {
                    "sent": "For one particular pattern, just is done to prevent caching.",
                    "label": 0
                },
                {
                    "sent": "For more details.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "DBPR Sparkle benchmark did a lot of work down the same.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If the update worker it has update queries on a file on an update in an update folder, if you use an update folder, you have to do this in this particular format.",
                    "label": 1
                },
                {
                    "sent": "This is this has advantage that you can sort all this updates you don't have like random updating, but you most cases you have like first random then and at first then random removable then again and at addition to the Triple Store.",
                    "label": 0
                },
                {
                    "sent": "So you have an update strategy.",
                    "label": 0
                },
                {
                    "sent": "And according to this update, strategies worker starts and will execute the next update and will ever made amount of time and then executes the next update and distance onto the tasks and or there are no more updates.",
                    "label": 0
                },
                {
                    "sent": "The waiting among.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of time is too.",
                    "label": 0
                },
                {
                    "sent": "Achieve a distributed updating, like if you down in one hour benchmark.",
                    "label": 0
                },
                {
                    "sent": "You don't want the updates in the first 10 minutes.",
                    "label": 0
                },
                {
                    "sent": "You want him distribute it so you can see actually the performance of crowing while updating.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The result.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Processing modules support the following metrics queries per second.",
                    "label": 1
                },
                {
                    "sent": "Premixes power the number of courage power and if you want to see the caching of extra queries you can also save every query execution.",
                    "label": 0
                },
                {
                    "sent": "The metrics are easily extendable.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Complete results will be stored as as a CSV file or as an amplifier, or as I recommend, and triple stores so you can query the lights directly with sparkle.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I said, iguana is very extensible.",
                    "label": 0
                },
                {
                    "sent": "You can extend almost everything like the task like the stress test data.",
                    "label": 0
                },
                {
                    "sent": "You can use data generators, you can add Crow hand us if the pattern is not working for you, you cannot metrics you can at result storage, so you can also implement the DIA fat to task if you want to.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so we did an evaluation as well.",
                    "label": 0
                },
                {
                    "sent": "And we did it obviously on the same measure you can see the complete specs in our paper and we used to main datasets, especially DB pedia and semantic web dog food for the pedia.",
                    "label": 1
                },
                {
                    "sent": "We used the initial data set with around 400 million triples and re cut it in half and enter 10%.",
                    "label": 0
                },
                {
                    "sent": "So we have four datasets with different sizes.",
                    "label": 0
                },
                {
                    "sent": "Two comparisons of Semantic Web dog food.",
                    "label": 0
                },
                {
                    "sent": "Triple triples are like in 35,000, so it's a.",
                    "label": 0
                },
                {
                    "sent": "Very, very small triple set.",
                    "label": 0
                },
                {
                    "sent": "We did, the other configurations are token from the DPS Parker benchmark framework, DPS Barker benchmarks.",
                    "label": 0
                },
                {
                    "sent": "Sorry with one our execution time and a 20 minute warm up and instead of using the GPS, Parker queries reused feasable to get generate query logs and to generate crowds out of a Crow log.",
                    "label": 0
                },
                {
                    "sent": "So we use real data or so we use real data sets and real queries and all.",
                    "label": 0
                },
                {
                    "sent": "All of those 250 crows are very complex.",
                    "label": 0
                },
                {
                    "sent": "And you will see it in our relations.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the updates we use DB pedia life change set for the paideia.",
                    "label": 0
                },
                {
                    "sent": "Again, real data for Semantic Web dog food we have to generate an.",
                    "label": 0
                },
                {
                    "sent": "We did check the dump of Semantic Web dog food and the endpoint and just choose the one who's not anymore in there and choose additional in there.",
                    "label": 0
                },
                {
                    "sent": "So we have our change set again with real data.",
                    "label": 0
                },
                {
                    "sent": "We simulate 1, four and 16 spark workers and with and without updates.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at our baseline.",
                    "label": 0
                },
                {
                    "sent": "This looks pretty well, right?",
                    "label": 0
                },
                {
                    "sent": "It's going to be high as a data set gets.",
                    "label": 0
                },
                {
                    "sent": "The last cruise can be executed, and especially so, but if you see like the difference between vetoes.",
                    "label": 0
                },
                {
                    "sent": "Oh, and for example, blazegraph ozeki, there's a lot of difference for the flaky and bless you have couldn't even handle 100 of those queries.",
                    "label": 0
                },
                {
                    "sent": "And if you've seen the DPS Barker benchmark, they could have almost like two 1000 to 10,000 queries of the.",
                    "label": 0
                },
                {
                    "sent": "DPS Parker benchmark rares.",
                    "label": 0
                },
                {
                    "sent": "The vehicles are one still got 10,000 crabbies for the semantic Web.",
                    "label": 0
                },
                {
                    "sent": "Dog food is even higher and.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We added some users so as you can see.",
                    "label": 0
                },
                {
                    "sent": "If we add some users to it so parallel requests.",
                    "label": 0
                },
                {
                    "sent": "All of the other.",
                    "label": 0
                },
                {
                    "sent": "All of our triple stores perform more queries so they can handle parallel requests and very good.",
                    "label": 0
                },
                {
                    "sent": "Actually, the amount of troubles taken get through as is getting higher and higher while the user just don't have and have a problem.",
                    "label": 0
                },
                {
                    "sent": "They still getting 1000 queries.",
                    "label": 0
                },
                {
                    "sent": "True, so this is for all of the datasets there's no problem.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Try to do based on with updates so to check what's effect of updates and again as you can see here.",
                    "label": 0
                },
                {
                    "sent": "There is no effect.",
                    "label": 0
                },
                {
                    "sent": "We don't see an effect in this diagrams.",
                    "label": 0
                },
                {
                    "sent": "In the left one there should be 6 lines and almost not at Delmos tree.",
                    "label": 0
                },
                {
                    "sent": "Um Jason minimal effect.",
                    "label": 0
                },
                {
                    "sent": "You don't care.",
                    "label": 0
                },
                {
                    "sent": "You don't need to care about and.",
                    "label": 0
                },
                {
                    "sent": "Especially in the semantic Web dog food you can't see probably, but brace graph with updates was a little bit faster even without updates, so you can really see updates without parallel quest doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "So again, let's add some spa.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To use us to it.",
                    "label": 0
                },
                {
                    "sent": "And again, as you can see.",
                    "label": 0
                },
                {
                    "sent": "We still have no problem with updates, so especially expect for the semantic Web dog food, but on the others on the other, on the DPD a data set.",
                    "label": 0
                },
                {
                    "sent": "We don't have a problem.",
                    "label": 0
                },
                {
                    "sent": "The effect is minimal.",
                    "label": 0
                },
                {
                    "sent": "And for the semantic Web dog food.",
                    "label": 0
                },
                {
                    "sent": "You can see there isn't.",
                    "label": 0
                },
                {
                    "sent": "There isn't a fact.",
                    "label": 0
                },
                {
                    "sent": "But this can also be due to our change set as we generated them and so we have to look into this further, obviously to check if updates affect.",
                    "label": 0
                },
                {
                    "sent": "If you can optimize updates.",
                    "label": 0
                },
                {
                    "sent": "If this other DPD alive ones optimized.",
                    "label": 0
                },
                {
                    "sent": "This is semantic web dog food just too much as we took it, so we can really check how do we can update the endpoints life while they're getting requests and.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Call jets basically Dan.",
                    "label": 0
                },
                {
                    "sent": "I hope I can could show you that Iguana provides a unified Spark benchmark execution framework.",
                    "label": 1
                },
                {
                    "sent": "And that provides new insights and further on that it's generic so it can execute on every data set an point and Sparkle, sparkle, update queries.",
                    "label": 0
                },
                {
                    "sent": "So for the outlook I had a demonstration on mine and talked with a lot of people and I couldn't fit in all the outlooks.",
                    "label": 0
                },
                {
                    "sent": "I was suggested to input and I hope I can do all of them, but for particular I want to add sparkle so additive streaming support.",
                    "label": 0
                },
                {
                    "sent": "Add ref configuration so you don't have so you just can add a tribble at an RDF file into Andover.",
                    "label": 0
                },
                {
                    "sent": "Just generate the benchmark if you have any suggestions, please let me know.",
                    "label": 0
                },
                {
                    "sent": "I'm happy to actually invent and implement the fate.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Death rate iguanas open source if you want to code with us.",
                    "label": 1
                },
                {
                    "sent": "Feel free to.",
                    "label": 0
                },
                {
                    "sent": "Yeah, any questions.",
                    "label": 0
                },
                {
                    "sent": "You you said that you run everything in the one single machine, but sometimes when you are running everything on the single machine you have interference between the system because you are you are writing at the same disk.",
                    "label": 0
                },
                {
                    "sent": "You can saturate some part of a system.",
                    "label": 0
                },
                {
                    "sent": "My question is how?",
                    "label": 0
                },
                {
                    "sent": "How you can be sure of your measurement about time, especially in clients.",
                    "label": 0
                },
                {
                    "sent": "That's a very good question, actually, um.",
                    "label": 0
                },
                {
                    "sent": "I can show you I can tell you the process we do and so we use Jenna.",
                    "label": 0
                },
                {
                    "sent": "And we just took the time, the system time from our from our execution server and just go until the.",
                    "label": 0
                },
                {
                    "sent": "The results are reached so so we checking the results.",
                    "label": 0
                },
                {
                    "sent": "If there are any.",
                    "label": 0
                },
                {
                    "sent": "So it's not just like oh they can.",
                    "label": 0
                },
                {
                    "sent": "They can cheat.",
                    "label": 0
                },
                {
                    "sent": "But they have to actually get results, even though if they empty that's OK, but they have to bring back results and then we just stop and so we count that time.",
                    "label": 0
                },
                {
                    "sent": "It's really hard to just count the time that actually triplestore needs.",
                    "label": 0
                },
                {
                    "sent": "But you have to ask yourself if you want to be cause if you career triple store you don't have.",
                    "label": 0
                },
                {
                    "sent": "You don't took the time of the triple Swords House, but the user performance.",
                    "label": 0
                },
                {
                    "sent": "Like the performance you get if you creating the endpoint directly.",
                    "label": 0
                }
            ]
        }
    }
}