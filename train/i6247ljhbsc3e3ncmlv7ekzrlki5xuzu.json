{
    "id": "i6247ljhbsc3e3ncmlv7ekzrlki5xuzu",
    "title": "CRNN's",
    "info": {
        "author": [
            "Jean-Baptiste Alayrac, INRIA - SIERRA project-team",
            "R\u00e9mi Leblond, INRIA - SIERRA project-team"
        ],
        "published": "July 27, 2017",
        "recorded": "July 2017",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2017_leblond_alayrac_searnn/",
    "segmentation": [
        [
            "So everyone so together with me we are going to present our work which propose alternative methods to train our means.",
            "So this method is inspired from a structure prediction technique called learning to search.",
            "So first of all I would start by just doing a quick recap of what is on our end."
        ],
        [
            "So as we have seen during a useless lecture, ornaments are models for sequential data.",
            "And they produce a sequence of eigenstates by repeatedly applying the same operation on their inputs, and they do prediction by using their previous outputs."
        ],
        [
            "So in this work will focus on a specific architecture, which is the encoder decoder framework which has already been mentioned several times in the lectures.",
            "So these models are used to output a sequence given another sequence as inputs such As for example for machine translation.",
            "In this framework we have two islands, so the first one is called the encoder and it process.",
            "It processes the input sequence and transform it into a vector which is then fed to the signal RN called the decoder.",
            "The role of this signal R&M is to predict the output sequence.",
            "One of the key properties that each cell of the decoder has access to the all input sequence through this initial state.",
            "Him over as we see in this drawing, every state of the decoder depends on the previous prediction.",
            "Here you can see that the W for example is given to the next cell to predict stored."
        ],
        [
            "So to train this model we make use of the natural probabilistic interpretation of Arnolds.",
            "Indeed, we can consider that the output of every cell of DRM is a probability distribution over the values that waiting can take condition on the input and on the past decision.",
            "So this is the first equation in this slide.",
            "Thanks to this we can use the chain rule to obtain the probability of any given given output sequence condition on the given input sequence.",
            "Given this observation, we can use maximum likelihood to train ordinance where the objective is just to maximize the probability of the ground truth, input output sequence pairs.",
            "So even if this framework is very nice, it comes with a number of non limitation that Joshua mentioned during this lecture.",
            "And I would just recap three of them.",
            "So first, the likelihood is is only a surrogate loss that may be different from the real metric you care about.",
            "So for example, you can care about edit distance or blue score if you do machine translation, say gun.",
            "It is also a problem that it is all or nothing flavor.",
            "As mentioned this morning during the NLP lecture.",
            "Indeed, it's only trying to maximize the probability of the ground truth, and this ignores the information that some candidate sequence can be pretty good close to the ground truth, while other might be very bad.",
            "And finally, as mentioned by usual on Tuesday, it's the first from exposure bias.",
            "So since we use the drop off thing for doing maximum likelihood, we essentially always force the prediction the prediction path.",
            "But at this time we don't have access to this ground path and therefore when we deviate from its we find ourselves in situation we've never seen during training, so we don't really know what to do and this can lead to to company errors.",
            "So there have been some efforts in the literature to to elevate these problems, and some of these works notably use ideas from reinforcement learning.",
            "But here instead we cast the problem that are addressed by our names as a structure prediction task, and we look for ideas there."
        ],
        [
            "So let me just recall briefly what is structure prediction.",
            "So the goal of structure prediction is to learn a mapping between some input X and some structured outputs wide.",
            "So when I when I say outputs switch outputs, it's because I assume that Y is made of interrelated parts that are often subjects to constraints, so as illustrated here, this is not to be the case for optical character recognition, where you might want to use the previous letter to previous next to predict the next ones.",
            "So the main difficulty with Twinkle prediction is that you have an exponential number of possible outputs with respect to the input size.",
            "So in this example, if your alphabet sizes of size K&L is the size of your word, you have K to the L possible worlds.",
            "So there exists under approaches to tackle these challenges, such as truthful as them or conditional random fields.",
            "But here we focus on another one which is called learning to sell."
        ],
        [
            "So learning to search is based on the idea that instead of predicting the whole why in one shot, you can make Creation 1 by 1 where each prediction depends on the previous ones to the core idea here is reaction where you reduce the original complicated structure problem into easier subproblems.",
            "In that case, we reduced down to what is called cost sensitive classification, where the goal is to train a shared classifier.",
            "That is going to predict every element.",
            "Why I of the output sequences and cost sensitive here simply means that instead of standard classification where we only have one target or class, we have one associated cost for each target, which allows to differentiate the possible decisions.",
            "Long to search is backed up with some theoretical guarantees that ensure that if you are able to solve the simple problem, you will do well on the initial complicated problem, But most importantly.",
            "The method and resists the non problems that we talk about for a maximum likelihood."
        ],
        [
            "So now the question is, how do you train this short classifier that I just talked about?",
            "So let's imagine we want some training signal for this cell which is in red deer.",
            "So first we will do a trajectory according to the current policy to get until this cell signal and we will try every possible action or decision to determine that global structured cost.",
            "The first phase is called role in its role is to do some exploration for the network.",
            "The second phase is called Royals and its role is to determine the cost of every action.",
            "Once you obtain discussed you through the loss and you can train the cell, we will come back in more details to this later in the talk."
        ],
        [
            "So as you might have already guessed, there are some strong links between this learning to search approach and the harness, and we really want to leverage this year.",
            "So indeed, both rely on decomposing structured tasks into some sequential prediction that are conditioned on the past decisions.",
            "So they both use the same shop classifiers that is applied over and over to make the full prediction.",
            "But what I did can we share between the two?",
            "Well, why are names are built in runnings?",
            "For example, teacher forcing can be seen as a method of exploring the space.",
            "They don't really have the notion of rollouts because the target is usually simply offend.",
            "By looking at the ground truth targets.",
            "So the question is, can we adapt this ideas for and ends and now we wait for me to answer.",
            "Question."
        ],
        [
            "So how do we incorporate ideas from L2 S in order to drive better training procedures for RNN and hopefully avoid the problems that geometers talk to talk about?",
            "So the one idea we want to focus on is to compute the costs of each token at every time step through the introduction of rollouts.",
            "In the decoder, RNN and our hope is that we can leverage these costs in order to define better training officers.",
            "There are closer to the test error.",
            "The algorithm is very simple.",
            "The first step is to compute the cost vectors with the role in the roll apps.",
            "The second step is to use these costs to derive a training loss.",
            "The third step is to take a gradient step associated with the loss, and finally we repeat one through 3 until final convergence."
        ],
        [
            "So let me try to give a little bit more intuition into this whole roll in roll out business.",
            "Here's an example on the singer XL again, and so you had the role in part where you start the exploration you predict.",
            "See you feed it back.",
            "You pretty oh feedback.",
            "And then you arrive at the cell where we want to compute the costs of output in every possible ticket.",
            "Here the first one is M, so we start with this one and then we use the roll out policy to finish the predicted sequence.",
            "And then we can compute the cost of M by applying the test error on the full predicted sequence.",
            "But here it's command, right?",
            "So now we have a cost for M and we do the same thing for N and four.",
            "Oh, and for everything this and so in the end we get one cost vector with one cost for each possible took.",
            "In this example you can really see that the rolling controls how the algorithm explores the search space, whereas the rollout determines how the costs are evaluated."
        ],
        [
            "Alright, so here things get a little bit more complicated, but I've left out in the cost computation parts, so the first step in the algorithm is that there are several possible choices for both roll in and roll out for rolling.",
            "You can use what's called the reference policy, and that means to always explore underground true style.",
            "That sort of the same as teacher force.",
            "On the other hand, you can use a learn policy where you go where the model will guide you and so this helps you alleviate the problem of exposure bias.",
            "For the rollout, you can decide to finish the sequence with a good known policy, because in some cases you have access to one or you can rather decide to see where the cart model would take you, and maybe that this gives you.",
            "Costs are a bit more realistic.",
            "Fortunately, exploring these different combinations already been done into traditional learning research literature, so we have already have some guidelines on what works best and actually very neat points is that we can recover.",
            "Emily is a special case of our method using a reference role in reference rollout and a specific loss, so it's a very useful family check.",
            "Alright, so this was set one.",
            "Computing the costs and now onto set to.",
            "Once we have the costs we have to actually pick the loss.",
            "They will leverage them.",
            "That would leverage all of this information.",
            "So we tried a bunch of different losses including structured SVM loss and other traditional structured prediction loss, as well as losses that were more structurally similar to me and so very basically in this case we use the cost information to replace the ground truth targets in the Emily objective.",
            "By the best performing token at this step and one final issue we have is that computing all of these costs gives us very meaningful information, but it's quite expensive.",
            "This it means doing a large number of four passes if we hope to apply CRN 2 large scale problems with big vocabulary size, we need to find a way to keep that combination of costs under control whenever it leads to you subsampling.",
            "So we only compute a subset of all costs.",
            "But then new questions arise.",
            "How much do we sample and what do we sell?",
            "Well, according to?"
        ],
        [
            "Right, so let me just recap why we believe CRN can outperform entity.",
            "First we make use of the test error when we compute the costs and so ultimately we have it in our loss or loss is not exactly the same as a tester, but it's all closer than Eddie where you basically simply disregard the test error.",
            "This in turn allows us to leverage the structured information that the loss yields by comparing the costs for different tokens.",
            "Again, this is in contrast to.",
            "Emily, which does not compare costs or make a distinction between a decent and terrible candidate because it's only concerned in maximizing the probability of the ground truth.",
            "Another advantage of our losses that they bring global information because we compute a cost on full full sequence to the local level and in the center approach you have local information at the local level and in the reinforcement learning approaches you have global information at the global level.",
            "The problem with the global information purchases that their information is very very sparse and so often they cannot convert from scratch and they require weren't starting from a good Amity train model."
        ],
        [
            "But enough talk.",
            "So see some numbers.",
            "We're on CNN without sampling on three classical structures.",
            "Predicted tasks which are OCR text chunking, an spelling correction.",
            "So here are the results where you have the energy baseline and then our performance with two different losses and three roll in roll up combinations.",
            "Here you can see in red that we outperformed Emily by one point.",
            "In the case of Yahweh, Emily is already pretty good and by a more significant margin.",
            "In the case of spelling.",
            "And we liked it pretty bad.",
            "Then we ran the sampling version of CNN with only 10% of tokens on the OCR task and the sampling task, and we tried five different sampling factors."
        ],
        [
            "Right, So what do these experiments tell us?",
            "But first and most importantly, we achieve significant improvements over the enemy baseline on all three tasks, which validates our idea that using training losses that are closer to the tester actually works.",
            "And as a matter of fact, the heart of the task is the bigger the improvements we see.",
            "So when the basic reference box he gets really bad, our method shines more.",
            "Going back to our policy decisions, rolling rollout, we observe that in accordance to the theoretical results from learning to search the best performing strategy is learned.",
            "Roll in and a mixed rollout, which is reassuring.",
            "And the best performing loss, or at least the one that was easiest to optimize for, are actually those that are structurally close to me.",
            "Additionally, our global local losses enables enable us to train from scratch, contrary to the reinforcement learning approaches, and we argue that it's pretty important because it means we can explore wider regions of parameter space and potentially find better minimum.",
            "And finally, our sampling strategy works because we are able to maintain improvements at a fraction of the cost.",
            "Interestingly, sometimes we even have better improvements, although we don't yet have theory for that."
        ],
        [
            "Right, so while these results are promising, there are still a number of things that we want to do.",
            "The biggest one is to make CNN scale to the point where it can handle problem with large vocabularies such as machine translation, and we're currently following two main leads.",
            "The first one is to use smarter sampling strategies rather than the pretty basic ones we we tried and that I haven't talked about yet.",
            "Ideas include harco sampling, where we first predicted class and then precise elements of the class and there was mentioned in the talk this morning and also curriculum sampling where we changed the amount of samples as the optimization goes along.",
            "So maybe we start with a lot of sampling and then the further we go, the less sample we do.",
            "And the last possibility is of course trainable sampling.",
            "If we can pull that off.",
            "And our second main lead is to divide smarter methods of cost approximation rather than doing rollouts all the time and this may bring us closer to the actor critic model that was actually explored in the context of Aaron and here at Mila."
        ],
        [
            "Right, that's it for us and we're happy to answer any questions.",
            "Right now.",
            "Will be there on Saturday to answer even more.",
            "And if you are interested, please check out our paper on archive, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So everyone so together with me we are going to present our work which propose alternative methods to train our means.",
                    "label": 0
                },
                {
                    "sent": "So this method is inspired from a structure prediction technique called learning to search.",
                    "label": 0
                },
                {
                    "sent": "So first of all I would start by just doing a quick recap of what is on our end.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as we have seen during a useless lecture, ornaments are models for sequential data.",
                    "label": 0
                },
                {
                    "sent": "And they produce a sequence of eigenstates by repeatedly applying the same operation on their inputs, and they do prediction by using their previous outputs.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this work will focus on a specific architecture, which is the encoder decoder framework which has already been mentioned several times in the lectures.",
                    "label": 0
                },
                {
                    "sent": "So these models are used to output a sequence given another sequence as inputs such As for example for machine translation.",
                    "label": 0
                },
                {
                    "sent": "In this framework we have two islands, so the first one is called the encoder and it process.",
                    "label": 0
                },
                {
                    "sent": "It processes the input sequence and transform it into a vector which is then fed to the signal RN called the decoder.",
                    "label": 1
                },
                {
                    "sent": "The role of this signal R&M is to predict the output sequence.",
                    "label": 0
                },
                {
                    "sent": "One of the key properties that each cell of the decoder has access to the all input sequence through this initial state.",
                    "label": 1
                },
                {
                    "sent": "Him over as we see in this drawing, every state of the decoder depends on the previous prediction.",
                    "label": 0
                },
                {
                    "sent": "Here you can see that the W for example is given to the next cell to predict stored.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to train this model we make use of the natural probabilistic interpretation of Arnolds.",
                    "label": 1
                },
                {
                    "sent": "Indeed, we can consider that the output of every cell of DRM is a probability distribution over the values that waiting can take condition on the input and on the past decision.",
                    "label": 0
                },
                {
                    "sent": "So this is the first equation in this slide.",
                    "label": 1
                },
                {
                    "sent": "Thanks to this we can use the chain rule to obtain the probability of any given given output sequence condition on the given input sequence.",
                    "label": 0
                },
                {
                    "sent": "Given this observation, we can use maximum likelihood to train ordinance where the objective is just to maximize the probability of the ground truth, input output sequence pairs.",
                    "label": 0
                },
                {
                    "sent": "So even if this framework is very nice, it comes with a number of non limitation that Joshua mentioned during this lecture.",
                    "label": 0
                },
                {
                    "sent": "And I would just recap three of them.",
                    "label": 0
                },
                {
                    "sent": "So first, the likelihood is is only a surrogate loss that may be different from the real metric you care about.",
                    "label": 1
                },
                {
                    "sent": "So for example, you can care about edit distance or blue score if you do machine translation, say gun.",
                    "label": 0
                },
                {
                    "sent": "It is also a problem that it is all or nothing flavor.",
                    "label": 0
                },
                {
                    "sent": "As mentioned this morning during the NLP lecture.",
                    "label": 0
                },
                {
                    "sent": "Indeed, it's only trying to maximize the probability of the ground truth, and this ignores the information that some candidate sequence can be pretty good close to the ground truth, while other might be very bad.",
                    "label": 1
                },
                {
                    "sent": "And finally, as mentioned by usual on Tuesday, it's the first from exposure bias.",
                    "label": 0
                },
                {
                    "sent": "So since we use the drop off thing for doing maximum likelihood, we essentially always force the prediction the prediction path.",
                    "label": 0
                },
                {
                    "sent": "But at this time we don't have access to this ground path and therefore when we deviate from its we find ourselves in situation we've never seen during training, so we don't really know what to do and this can lead to to company errors.",
                    "label": 0
                },
                {
                    "sent": "So there have been some efforts in the literature to to elevate these problems, and some of these works notably use ideas from reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "But here instead we cast the problem that are addressed by our names as a structure prediction task, and we look for ideas there.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me just recall briefly what is structure prediction.",
                    "label": 0
                },
                {
                    "sent": "So the goal of structure prediction is to learn a mapping between some input X and some structured outputs wide.",
                    "label": 1
                },
                {
                    "sent": "So when I when I say outputs switch outputs, it's because I assume that Y is made of interrelated parts that are often subjects to constraints, so as illustrated here, this is not to be the case for optical character recognition, where you might want to use the previous letter to previous next to predict the next ones.",
                    "label": 0
                },
                {
                    "sent": "So the main difficulty with Twinkle prediction is that you have an exponential number of possible outputs with respect to the input size.",
                    "label": 1
                },
                {
                    "sent": "So in this example, if your alphabet sizes of size K&L is the size of your word, you have K to the L possible worlds.",
                    "label": 0
                },
                {
                    "sent": "So there exists under approaches to tackle these challenges, such as truthful as them or conditional random fields.",
                    "label": 0
                },
                {
                    "sent": "But here we focus on another one which is called learning to sell.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So learning to search is based on the idea that instead of predicting the whole why in one shot, you can make Creation 1 by 1 where each prediction depends on the previous ones to the core idea here is reaction where you reduce the original complicated structure problem into easier subproblems.",
                    "label": 1
                },
                {
                    "sent": "In that case, we reduced down to what is called cost sensitive classification, where the goal is to train a shared classifier.",
                    "label": 0
                },
                {
                    "sent": "That is going to predict every element.",
                    "label": 0
                },
                {
                    "sent": "Why I of the output sequences and cost sensitive here simply means that instead of standard classification where we only have one target or class, we have one associated cost for each target, which allows to differentiate the possible decisions.",
                    "label": 0
                },
                {
                    "sent": "Long to search is backed up with some theoretical guarantees that ensure that if you are able to solve the simple problem, you will do well on the initial complicated problem, But most importantly.",
                    "label": 0
                },
                {
                    "sent": "The method and resists the non problems that we talk about for a maximum likelihood.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now the question is, how do you train this short classifier that I just talked about?",
                    "label": 0
                },
                {
                    "sent": "So let's imagine we want some training signal for this cell which is in red deer.",
                    "label": 0
                },
                {
                    "sent": "So first we will do a trajectory according to the current policy to get until this cell signal and we will try every possible action or decision to determine that global structured cost.",
                    "label": 0
                },
                {
                    "sent": "The first phase is called role in its role is to do some exploration for the network.",
                    "label": 0
                },
                {
                    "sent": "The second phase is called Royals and its role is to determine the cost of every action.",
                    "label": 0
                },
                {
                    "sent": "Once you obtain discussed you through the loss and you can train the cell, we will come back in more details to this later in the talk.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as you might have already guessed, there are some strong links between this learning to search approach and the harness, and we really want to leverage this year.",
                    "label": 0
                },
                {
                    "sent": "So indeed, both rely on decomposing structured tasks into some sequential prediction that are conditioned on the past decisions.",
                    "label": 1
                },
                {
                    "sent": "So they both use the same shop classifiers that is applied over and over to make the full prediction.",
                    "label": 1
                },
                {
                    "sent": "But what I did can we share between the two?",
                    "label": 0
                },
                {
                    "sent": "Well, why are names are built in runnings?",
                    "label": 0
                },
                {
                    "sent": "For example, teacher forcing can be seen as a method of exploring the space.",
                    "label": 0
                },
                {
                    "sent": "They don't really have the notion of rollouts because the target is usually simply offend.",
                    "label": 0
                },
                {
                    "sent": "By looking at the ground truth targets.",
                    "label": 0
                },
                {
                    "sent": "So the question is, can we adapt this ideas for and ends and now we wait for me to answer.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we incorporate ideas from L2 S in order to drive better training procedures for RNN and hopefully avoid the problems that geometers talk to talk about?",
                    "label": 0
                },
                {
                    "sent": "So the one idea we want to focus on is to compute the costs of each token at every time step through the introduction of rollouts.",
                    "label": 0
                },
                {
                    "sent": "In the decoder, RNN and our hope is that we can leverage these costs in order to define better training officers.",
                    "label": 0
                },
                {
                    "sent": "There are closer to the test error.",
                    "label": 0
                },
                {
                    "sent": "The algorithm is very simple.",
                    "label": 0
                },
                {
                    "sent": "The first step is to compute the cost vectors with the role in the roll apps.",
                    "label": 0
                },
                {
                    "sent": "The second step is to use these costs to derive a training loss.",
                    "label": 0
                },
                {
                    "sent": "The third step is to take a gradient step associated with the loss, and finally we repeat one through 3 until final convergence.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me try to give a little bit more intuition into this whole roll in roll out business.",
                    "label": 0
                },
                {
                    "sent": "Here's an example on the singer XL again, and so you had the role in part where you start the exploration you predict.",
                    "label": 0
                },
                {
                    "sent": "See you feed it back.",
                    "label": 0
                },
                {
                    "sent": "You pretty oh feedback.",
                    "label": 0
                },
                {
                    "sent": "And then you arrive at the cell where we want to compute the costs of output in every possible ticket.",
                    "label": 1
                },
                {
                    "sent": "Here the first one is M, so we start with this one and then we use the roll out policy to finish the predicted sequence.",
                    "label": 1
                },
                {
                    "sent": "And then we can compute the cost of M by applying the test error on the full predicted sequence.",
                    "label": 0
                },
                {
                    "sent": "But here it's command, right?",
                    "label": 0
                },
                {
                    "sent": "So now we have a cost for M and we do the same thing for N and four.",
                    "label": 0
                },
                {
                    "sent": "Oh, and for everything this and so in the end we get one cost vector with one cost for each possible took.",
                    "label": 0
                },
                {
                    "sent": "In this example you can really see that the rolling controls how the algorithm explores the search space, whereas the rollout determines how the costs are evaluated.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so here things get a little bit more complicated, but I've left out in the cost computation parts, so the first step in the algorithm is that there are several possible choices for both roll in and roll out for rolling.",
                    "label": 0
                },
                {
                    "sent": "You can use what's called the reference policy, and that means to always explore underground true style.",
                    "label": 0
                },
                {
                    "sent": "That sort of the same as teacher force.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, you can use a learn policy where you go where the model will guide you and so this helps you alleviate the problem of exposure bias.",
                    "label": 0
                },
                {
                    "sent": "For the rollout, you can decide to finish the sequence with a good known policy, because in some cases you have access to one or you can rather decide to see where the cart model would take you, and maybe that this gives you.",
                    "label": 0
                },
                {
                    "sent": "Costs are a bit more realistic.",
                    "label": 0
                },
                {
                    "sent": "Fortunately, exploring these different combinations already been done into traditional learning research literature, so we have already have some guidelines on what works best and actually very neat points is that we can recover.",
                    "label": 0
                },
                {
                    "sent": "Emily is a special case of our method using a reference role in reference rollout and a specific loss, so it's a very useful family check.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this was set one.",
                    "label": 0
                },
                {
                    "sent": "Computing the costs and now onto set to.",
                    "label": 0
                },
                {
                    "sent": "Once we have the costs we have to actually pick the loss.",
                    "label": 1
                },
                {
                    "sent": "They will leverage them.",
                    "label": 0
                },
                {
                    "sent": "That would leverage all of this information.",
                    "label": 1
                },
                {
                    "sent": "So we tried a bunch of different losses including structured SVM loss and other traditional structured prediction loss, as well as losses that were more structurally similar to me and so very basically in this case we use the cost information to replace the ground truth targets in the Emily objective.",
                    "label": 0
                },
                {
                    "sent": "By the best performing token at this step and one final issue we have is that computing all of these costs gives us very meaningful information, but it's quite expensive.",
                    "label": 0
                },
                {
                    "sent": "This it means doing a large number of four passes if we hope to apply CRN 2 large scale problems with big vocabulary size, we need to find a way to keep that combination of costs under control whenever it leads to you subsampling.",
                    "label": 0
                },
                {
                    "sent": "So we only compute a subset of all costs.",
                    "label": 0
                },
                {
                    "sent": "But then new questions arise.",
                    "label": 0
                },
                {
                    "sent": "How much do we sample and what do we sell?",
                    "label": 0
                },
                {
                    "sent": "Well, according to?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so let me just recap why we believe CRN can outperform entity.",
                    "label": 0
                },
                {
                    "sent": "First we make use of the test error when we compute the costs and so ultimately we have it in our loss or loss is not exactly the same as a tester, but it's all closer than Eddie where you basically simply disregard the test error.",
                    "label": 0
                },
                {
                    "sent": "This in turn allows us to leverage the structured information that the loss yields by comparing the costs for different tokens.",
                    "label": 0
                },
                {
                    "sent": "Again, this is in contrast to.",
                    "label": 0
                },
                {
                    "sent": "Emily, which does not compare costs or make a distinction between a decent and terrible candidate because it's only concerned in maximizing the probability of the ground truth.",
                    "label": 0
                },
                {
                    "sent": "Another advantage of our losses that they bring global information because we compute a cost on full full sequence to the local level and in the center approach you have local information at the local level and in the reinforcement learning approaches you have global information at the global level.",
                    "label": 0
                },
                {
                    "sent": "The problem with the global information purchases that their information is very very sparse and so often they cannot convert from scratch and they require weren't starting from a good Amity train model.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But enough talk.",
                    "label": 0
                },
                {
                    "sent": "So see some numbers.",
                    "label": 0
                },
                {
                    "sent": "We're on CNN without sampling on three classical structures.",
                    "label": 0
                },
                {
                    "sent": "Predicted tasks which are OCR text chunking, an spelling correction.",
                    "label": 0
                },
                {
                    "sent": "So here are the results where you have the energy baseline and then our performance with two different losses and three roll in roll up combinations.",
                    "label": 0
                },
                {
                    "sent": "Here you can see in red that we outperformed Emily by one point.",
                    "label": 0
                },
                {
                    "sent": "In the case of Yahweh, Emily is already pretty good and by a more significant margin.",
                    "label": 0
                },
                {
                    "sent": "In the case of spelling.",
                    "label": 0
                },
                {
                    "sent": "And we liked it pretty bad.",
                    "label": 0
                },
                {
                    "sent": "Then we ran the sampling version of CNN with only 10% of tokens on the OCR task and the sampling task, and we tried five different sampling factors.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, So what do these experiments tell us?",
                    "label": 0
                },
                {
                    "sent": "But first and most importantly, we achieve significant improvements over the enemy baseline on all three tasks, which validates our idea that using training losses that are closer to the tester actually works.",
                    "label": 0
                },
                {
                    "sent": "And as a matter of fact, the heart of the task is the bigger the improvements we see.",
                    "label": 0
                },
                {
                    "sent": "So when the basic reference box he gets really bad, our method shines more.",
                    "label": 0
                },
                {
                    "sent": "Going back to our policy decisions, rolling rollout, we observe that in accordance to the theoretical results from learning to search the best performing strategy is learned.",
                    "label": 0
                },
                {
                    "sent": "Roll in and a mixed rollout, which is reassuring.",
                    "label": 0
                },
                {
                    "sent": "And the best performing loss, or at least the one that was easiest to optimize for, are actually those that are structurally close to me.",
                    "label": 0
                },
                {
                    "sent": "Additionally, our global local losses enables enable us to train from scratch, contrary to the reinforcement learning approaches, and we argue that it's pretty important because it means we can explore wider regions of parameter space and potentially find better minimum.",
                    "label": 0
                },
                {
                    "sent": "And finally, our sampling strategy works because we are able to maintain improvements at a fraction of the cost.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, sometimes we even have better improvements, although we don't yet have theory for that.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so while these results are promising, there are still a number of things that we want to do.",
                    "label": 0
                },
                {
                    "sent": "The biggest one is to make CNN scale to the point where it can handle problem with large vocabularies such as machine translation, and we're currently following two main leads.",
                    "label": 0
                },
                {
                    "sent": "The first one is to use smarter sampling strategies rather than the pretty basic ones we we tried and that I haven't talked about yet.",
                    "label": 0
                },
                {
                    "sent": "Ideas include harco sampling, where we first predicted class and then precise elements of the class and there was mentioned in the talk this morning and also curriculum sampling where we changed the amount of samples as the optimization goes along.",
                    "label": 0
                },
                {
                    "sent": "So maybe we start with a lot of sampling and then the further we go, the less sample we do.",
                    "label": 0
                },
                {
                    "sent": "And the last possibility is of course trainable sampling.",
                    "label": 0
                },
                {
                    "sent": "If we can pull that off.",
                    "label": 0
                },
                {
                    "sent": "And our second main lead is to divide smarter methods of cost approximation rather than doing rollouts all the time and this may bring us closer to the actor critic model that was actually explored in the context of Aaron and here at Mila.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, that's it for us and we're happy to answer any questions.",
                    "label": 0
                },
                {
                    "sent": "Right now.",
                    "label": 0
                },
                {
                    "sent": "Will be there on Saturday to answer even more.",
                    "label": 0
                },
                {
                    "sent": "And if you are interested, please check out our paper on archive, thanks.",
                    "label": 0
                }
            ]
        }
    }
}