{
    "id": "bxc3dhc2uxgct65e72z5keeuderd4fcb",
    "title": "Distributed and Scalable OWL EL Reasoning",
    "info": {
        "author": [
            "Raghava Mutharaju, Department of Computer Science and Engineering (CSE), Wright State University"
        ],
        "published": "July 15, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2015_mutharaju_scalable_reasoning/",
    "segmentation": [
        [
            "My name is Robert.",
            "I'm from Wright State University and this work is in collaboration with the two other professors, from Wright State Pascal, who is my supervisor.",
            "An apart from editing as well as Freddie from IBM research."
        ],
        [
            "I'll just go over the motivation first, then the primaries, and then I'll go into my approach and end it with the result."
        ],
        [
            "So all the existing reasons that are there, say for example the well known ones like pallet, elk and back plus plus all of them run their unknown only single machine and so they are constrained by the resources that are present only on that machine like the RAM or the hard disk that is available.",
            "No, all the current ontologies are most of the popular ones.",
            "There are hand big so.",
            "There the number of exams that are in ontologies.",
            "There might be between said thousands to a maximum of 1,000,000.",
            "So in these cases the existing business are sufficient, but.",
            "If you go to automatic generation of axioms, say from sensor data such as traffic and tweets and text, then it might be go to large number of axioms and the ontologies can be very big.",
            "And these already happening like say in the in my evaluation results I take the traffic data from Dublin, which was generated automatically from the sensor data.",
            "And there's also work where they parse the biomedical text and generate these biomedical ontologies.",
            "So in this case this is running.",
            "These ontologies are the reasoning process on a single machine will be.",
            "They might run out of memory and it'll be time consuming as well.",
            "So one of the proposed solution are possible.",
            "Solution is to use distributed systems are distributed daily and that is what we will be focusing on here."
        ],
        [
            "I'll briefly give the profile out profile that we are targeting are focusing on it's called L plus plus, and it's a it's the description logic that is underlying out to your profile, which is one of the profiles of all 2.",
            "And in this one, axioms fall into two categories.",
            "One is the general concept inclusion and the other one is the role inclusions.",
            "General general concept inclusions.",
            "So in this one they support.",
            "Other that supports top concept bottom concept.",
            "And existentials, nominals, as well as the intersections.",
            "And in the role properties we have the role hierarchies as well as the role genes.",
            "So we don't support the completely at plus plus.",
            "So, axioms of this form with other then they are not supported, so so it's not the complete year plus work, but for the data that we looked into, this exams are not correct.",
            "So that's something for future."
        ],
        [
            "And.",
            "We do some kind of preprocessing which is called normalization on all the axioms.",
            "From the exams can be complex an in this preprocessing step which is normalization we reduce all the exams to one of these four forms at the top and all the roller exams to the ones at the bottom.",
            "And in this process some additional concepts could be added, and they're all like auto generated months."
        ],
        [
            "Did I sound reasoning tasks and the ones that and the one that we focus on is called classification?",
            "And we use one of the main things named us.",
            "So in this process we we take each concept in the ontology and then compute all its superclass.",
            "And for this work we are using a set of rules to classify the given near Christmas ontology."
        ],
        [
            "OK, I won't be going through all the boost is just the important thing is to notice the input column.",
            "So each rule is associated with one particular type of exam, so given.",
            "And I think that we can easily figure out the rule that needs to be applied on the tags.",
            "And.",
            "So this sort of.",
            "Neatly divides the ontology into eight parts.",
            "You have the item QR sets which are which hold intermediate exams which are generated during the classification process, and they use.",
            "That is where the results are cold."
        ],
        [
            "So since there are eight types of exams, we can neatly divide the online tier ontology into eight parts which are mutually disjoint.",
            "And this is how the data distribution happens.",
            "So each part is given to 1 sub cluster in the story one sub cluster in the entire cluster and the sub cluster consists of a set of machines which could be one.",
            "So once we divide the data this way, we can easily choose the rule that needs to be applied on that particular cluster.",
            "So if there are same three machines in one sub one sub cluster, then all the three machines will apply the same rule.",
            "But the thing to notice the data within these three machines, they are not duplicated, so they are further divided into the under these three machines."
        ],
        [
            "So this is the float on the dependency diagram.",
            "The rectangles represent each individual node in the cluster, and the ovals represent the subclusters which is denoted by C. Um?",
            "And the adults they show their dependency.",
            "So for example, the cluster.",
            "As for a free food which works on rule out food, it depends on the rain.",
            "Put further depends on the output of.",
            "The Subcluster one and two, as well as the output of Subcluster Creek.",
            "So they did because of these dependencies, it has some effect on the performance which we look at later.",
            "And for simplicity we only showed one node which holds all the results.",
            "But there can be there can in theory be more than one node which holds the results.",
            "So they made.",
            "The classification happens is all the rules are applied repeatedly on the given data set.",
            "Until there are no new axioms that are generated, so this is called a fixed point iteration."
        ],
        [
            "And termination on a single machine is easier to detect because we'll just go through keep track of the axioms that are newly created, and there is no new creation and return it.",
            "But in a distributed system it's a little harder so.",
            "That's why maybe make use of something called barrier synchronization.",
            "So the first step is to apply rule are one on the particular ontology subset over one.",
            "Going and then he represents the number of updates that are done to these sets.",
            "Are you and you likely saw earlier?",
            "If gay is 0 then the process PSA BA waits for other.",
            "Gaze from the other machines.",
            "User presented by these broadcasts of K and in the third step it waits until it receives the K from other machines.",
            "And if all the cases are zeros, that means no updates are done to these sets itself terminates, or else all the process they go to the next iteration."
        ],
        [
            "These are primarily the three optimizations that we used.",
            "One is the dynamic load balancing, so different rules they have.",
            "They take different amount of processing time and different they have they work on different number of axioms.",
            "Whom the processing time of that particular cluster or the node varies from node to node, so they'll be ideal notes as well as busy nodes in the cluster.",
            "And add it to the days this barrier synchronization.",
            "So some some process made finish faster and they might be waiting.",
            "Another process may be busy.",
            "Still Doctor, why did we have this dynamic load balancing where?",
            "The busy notes they tried to steal some work out piece of work from the North side of the ideal notes right to see, steal some work from the busy roads and then they help the busy nodes.",
            "This will lead to some more communication overhead, but in the in our experiments we.",
            "Observe that the communication overhead.",
            "Other performance outweighs the communication overhead.",
            "The second optimization is the rule dependencies.",
            "Um?",
            "So from the figure."
        ],
        [
            "We see that not all rules are dependent on each other, so there are some rules which are.",
            "They are full.",
            "This depends on the same cluster on a 2 and then subclass IC 3 for example.",
            "So unless there are no new outputs from these two subclasses, it need not go to the next iteration."
        ],
        [
            "So that is the about rule dependencies and the third.",
            "Optimization is the data partitioning strategy that we use.",
            "Because of the way that we divide the data which is based on the exam type, most of the rule application can be done locally.",
            "Although it still needs some more additional input, but.",
            "Majority of the processing can be done locally."
        ],
        [
            "This was implemented in Java and the name of this reasoner is distant.",
            "It's available has open sourced from the GitHub link.",
            "For the database we use the key value store called Radius and experiments that I'm going to show they were all done on Amazon's EC2M3 Dot X large cluster instances.",
            "Um?",
            "Do you want it to keep the configuration close to a regular laptop or a commodity machine so?",
            "Windows Defender configuration."
        ],
        [
            "I cannot do that.",
            "So these are some of the biomedical ontologies.",
            "Go is the gene ontology and there's no mid is the largest biomedical ontology available, so it has.",
            "The second column shows the number of axioms before the classification process, and then after the classification process some axioms will be added, so that is the number after the classification.",
            "Seems for some cases.",
            "The number of exams after classification is as much as say 14 times or 15 times move and in the case of traffic data it's three times more.",
            "We replicated this moment just to test the scalability of the system, so snow made times 2 * 3 and times fire just.",
            "Two times duplicated the same contact.",
            "And the traffic data is from Dublin City, which IBM collects regularly."
        ],
        [
            "So these are the numbers which are which are obtained after running it on some existing reasons.",
            "Um?",
            "So I missed out of memory transit run out of memory at different stages.",
            "So for example a sorry beast when.",
            "During the incremental classification case so.",
            "If the data is streaming, like in the case of static data, we need to, the reasoner should be able to support the streaming process, are sort of incremental progress.",
            "Instead of recomputing the whole thing every time a new piece of data is added to it.",
            "But some of the reasons they don't support the incremental classification, and in those cases we simply combine all the different ontology pieces into one big chunk and it was given to it.",
            "So as you can see, for the big ones, big ontologies like the Snowman, Times 5 and number Times 3, as well as a traffic control, you see it runs out of memory, but for the small ones.",
            "Apartment is very good."
        ],
        [
            "This is the classification time for our distributed original.",
            "Um?",
            "So we the initial base setup is with eight notes and we went on till 64 notes.",
            "Spell the small one leg, say go.",
            "There is a deep as well as raising the performance time, but for the big ones as the number of nodes increase, we can see that the classification time decreases until it hits the largest cluster which is 64 nodes.",
            "So when it comes to 64 nodes, that communication overhead dominates the performance gain, so that's very generally knowledge case.",
            "It's the performance decreases with the largest cluster."
        ],
        [
            "So as I mentioned, we use Redis as the key value store or the database for our system, and these are the memory footprints taken by radius on different machines.",
            "It does use some sort of compression internally, and that's why.",
            "On all these machines, the memories taken by it is various.",
            "So total comes up to close to 5."
        ],
        [
            "This one we already observed this two slides back.",
            "Like as with the increase in the number of nodes, the speedup also increases until it hits the largest cluster, which is 64 nodes."
        ],
        [
            "From the government's lights, it's clear that there's still some work to be done like we are able to complete the classification process, but the performance is not that good.",
            "So the future future work involves.",
            "Couple of things to do with respect to performance, say, can we use a different ontology partitioning strategy or a different ruleset?",
            "The ones say for example, the ones used by El prisoner, which might give a better performance.",
            "And.",
            "Fine grained analysis of the performance is still we had to do that.",
            "This implementation is single threaded, which is not good, so we are planning to use threads to make it faster or see the effect of threads on the performance.",
            "And the data structures also played crucial role in the performance.",
            "So we are trying to check the there.",
            "Any alternatives are alternatives to release?"
        ],
        [
            "So in this work, during this presentation I introduced a distributed regional card distance and in the evaluation we notice that the existing reasoners which are announcing machine.",
            "They don't scale up very well to large ontologies and we are able to classify these large ontologies in.",
            "Not very quickly, but in a reasonable amount of time, and we're able to finish the task.",
            "And it also shows good speedup with increasing number of nodes."
        ],
        [
            "That's about it, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Robert.",
                    "label": 0
                },
                {
                    "sent": "I'm from Wright State University and this work is in collaboration with the two other professors, from Wright State Pascal, who is my supervisor.",
                    "label": 0
                },
                {
                    "sent": "An apart from editing as well as Freddie from IBM research.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll just go over the motivation first, then the primaries, and then I'll go into my approach and end it with the result.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So all the existing reasons that are there, say for example the well known ones like pallet, elk and back plus plus all of them run their unknown only single machine and so they are constrained by the resources that are present only on that machine like the RAM or the hard disk that is available.",
                    "label": 1
                },
                {
                    "sent": "No, all the current ontologies are most of the popular ones.",
                    "label": 0
                },
                {
                    "sent": "There are hand big so.",
                    "label": 0
                },
                {
                    "sent": "There the number of exams that are in ontologies.",
                    "label": 1
                },
                {
                    "sent": "There might be between said thousands to a maximum of 1,000,000.",
                    "label": 0
                },
                {
                    "sent": "So in these cases the existing business are sufficient, but.",
                    "label": 0
                },
                {
                    "sent": "If you go to automatic generation of axioms, say from sensor data such as traffic and tweets and text, then it might be go to large number of axioms and the ontologies can be very big.",
                    "label": 0
                },
                {
                    "sent": "And these already happening like say in the in my evaluation results I take the traffic data from Dublin, which was generated automatically from the sensor data.",
                    "label": 0
                },
                {
                    "sent": "And there's also work where they parse the biomedical text and generate these biomedical ontologies.",
                    "label": 0
                },
                {
                    "sent": "So in this case this is running.",
                    "label": 0
                },
                {
                    "sent": "These ontologies are the reasoning process on a single machine will be.",
                    "label": 1
                },
                {
                    "sent": "They might run out of memory and it'll be time consuming as well.",
                    "label": 0
                },
                {
                    "sent": "So one of the proposed solution are possible.",
                    "label": 0
                },
                {
                    "sent": "Solution is to use distributed systems are distributed daily and that is what we will be focusing on here.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll briefly give the profile out profile that we are targeting are focusing on it's called L plus plus, and it's a it's the description logic that is underlying out to your profile, which is one of the profiles of all 2.",
                    "label": 1
                },
                {
                    "sent": "And in this one, axioms fall into two categories.",
                    "label": 0
                },
                {
                    "sent": "One is the general concept inclusion and the other one is the role inclusions.",
                    "label": 0
                },
                {
                    "sent": "General general concept inclusions.",
                    "label": 0
                },
                {
                    "sent": "So in this one they support.",
                    "label": 0
                },
                {
                    "sent": "Other that supports top concept bottom concept.",
                    "label": 0
                },
                {
                    "sent": "And existentials, nominals, as well as the intersections.",
                    "label": 0
                },
                {
                    "sent": "And in the role properties we have the role hierarchies as well as the role genes.",
                    "label": 0
                },
                {
                    "sent": "So we don't support the completely at plus plus.",
                    "label": 0
                },
                {
                    "sent": "So, axioms of this form with other then they are not supported, so so it's not the complete year plus work, but for the data that we looked into, this exams are not correct.",
                    "label": 1
                },
                {
                    "sent": "So that's something for future.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We do some kind of preprocessing which is called normalization on all the axioms.",
                    "label": 0
                },
                {
                    "sent": "From the exams can be complex an in this preprocessing step which is normalization we reduce all the exams to one of these four forms at the top and all the roller exams to the ones at the bottom.",
                    "label": 0
                },
                {
                    "sent": "And in this process some additional concepts could be added, and they're all like auto generated months.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Did I sound reasoning tasks and the ones that and the one that we focus on is called classification?",
                    "label": 1
                },
                {
                    "sent": "And we use one of the main things named us.",
                    "label": 0
                },
                {
                    "sent": "So in this process we we take each concept in the ontology and then compute all its superclass.",
                    "label": 0
                },
                {
                    "sent": "And for this work we are using a set of rules to classify the given near Christmas ontology.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I won't be going through all the boost is just the important thing is to notice the input column.",
                    "label": 0
                },
                {
                    "sent": "So each rule is associated with one particular type of exam, so given.",
                    "label": 0
                },
                {
                    "sent": "And I think that we can easily figure out the rule that needs to be applied on the tags.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So this sort of.",
                    "label": 0
                },
                {
                    "sent": "Neatly divides the ontology into eight parts.",
                    "label": 0
                },
                {
                    "sent": "You have the item QR sets which are which hold intermediate exams which are generated during the classification process, and they use.",
                    "label": 0
                },
                {
                    "sent": "That is where the results are cold.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So since there are eight types of exams, we can neatly divide the online tier ontology into eight parts which are mutually disjoint.",
                    "label": 1
                },
                {
                    "sent": "And this is how the data distribution happens.",
                    "label": 0
                },
                {
                    "sent": "So each part is given to 1 sub cluster in the story one sub cluster in the entire cluster and the sub cluster consists of a set of machines which could be one.",
                    "label": 1
                },
                {
                    "sent": "So once we divide the data this way, we can easily choose the rule that needs to be applied on that particular cluster.",
                    "label": 1
                },
                {
                    "sent": "So if there are same three machines in one sub one sub cluster, then all the three machines will apply the same rule.",
                    "label": 0
                },
                {
                    "sent": "But the thing to notice the data within these three machines, they are not duplicated, so they are further divided into the under these three machines.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the float on the dependency diagram.",
                    "label": 0
                },
                {
                    "sent": "The rectangles represent each individual node in the cluster, and the ovals represent the subclusters which is denoted by C. Um?",
                    "label": 0
                },
                {
                    "sent": "And the adults they show their dependency.",
                    "label": 0
                },
                {
                    "sent": "So for example, the cluster.",
                    "label": 0
                },
                {
                    "sent": "As for a free food which works on rule out food, it depends on the rain.",
                    "label": 0
                },
                {
                    "sent": "Put further depends on the output of.",
                    "label": 0
                },
                {
                    "sent": "The Subcluster one and two, as well as the output of Subcluster Creek.",
                    "label": 0
                },
                {
                    "sent": "So they did because of these dependencies, it has some effect on the performance which we look at later.",
                    "label": 0
                },
                {
                    "sent": "And for simplicity we only showed one node which holds all the results.",
                    "label": 0
                },
                {
                    "sent": "But there can be there can in theory be more than one node which holds the results.",
                    "label": 0
                },
                {
                    "sent": "So they made.",
                    "label": 0
                },
                {
                    "sent": "The classification happens is all the rules are applied repeatedly on the given data set.",
                    "label": 0
                },
                {
                    "sent": "Until there are no new axioms that are generated, so this is called a fixed point iteration.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And termination on a single machine is easier to detect because we'll just go through keep track of the axioms that are newly created, and there is no new creation and return it.",
                    "label": 0
                },
                {
                    "sent": "But in a distributed system it's a little harder so.",
                    "label": 0
                },
                {
                    "sent": "That's why maybe make use of something called barrier synchronization.",
                    "label": 1
                },
                {
                    "sent": "So the first step is to apply rule are one on the particular ontology subset over one.",
                    "label": 0
                },
                {
                    "sent": "Going and then he represents the number of updates that are done to these sets.",
                    "label": 1
                },
                {
                    "sent": "Are you and you likely saw earlier?",
                    "label": 0
                },
                {
                    "sent": "If gay is 0 then the process PSA BA waits for other.",
                    "label": 0
                },
                {
                    "sent": "Gaze from the other machines.",
                    "label": 0
                },
                {
                    "sent": "User presented by these broadcasts of K and in the third step it waits until it receives the K from other machines.",
                    "label": 0
                },
                {
                    "sent": "And if all the cases are zeros, that means no updates are done to these sets itself terminates, or else all the process they go to the next iteration.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These are primarily the three optimizations that we used.",
                    "label": 0
                },
                {
                    "sent": "One is the dynamic load balancing, so different rules they have.",
                    "label": 1
                },
                {
                    "sent": "They take different amount of processing time and different they have they work on different number of axioms.",
                    "label": 0
                },
                {
                    "sent": "Whom the processing time of that particular cluster or the node varies from node to node, so they'll be ideal notes as well as busy nodes in the cluster.",
                    "label": 0
                },
                {
                    "sent": "And add it to the days this barrier synchronization.",
                    "label": 0
                },
                {
                    "sent": "So some some process made finish faster and they might be waiting.",
                    "label": 0
                },
                {
                    "sent": "Another process may be busy.",
                    "label": 0
                },
                {
                    "sent": "Still Doctor, why did we have this dynamic load balancing where?",
                    "label": 0
                },
                {
                    "sent": "The busy notes they tried to steal some work out piece of work from the North side of the ideal notes right to see, steal some work from the busy roads and then they help the busy nodes.",
                    "label": 1
                },
                {
                    "sent": "This will lead to some more communication overhead, but in the in our experiments we.",
                    "label": 0
                },
                {
                    "sent": "Observe that the communication overhead.",
                    "label": 1
                },
                {
                    "sent": "Other performance outweighs the communication overhead.",
                    "label": 0
                },
                {
                    "sent": "The second optimization is the rule dependencies.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So from the figure.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We see that not all rules are dependent on each other, so there are some rules which are.",
                    "label": 0
                },
                {
                    "sent": "They are full.",
                    "label": 0
                },
                {
                    "sent": "This depends on the same cluster on a 2 and then subclass IC 3 for example.",
                    "label": 0
                },
                {
                    "sent": "So unless there are no new outputs from these two subclasses, it need not go to the next iteration.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that is the about rule dependencies and the third.",
                    "label": 0
                },
                {
                    "sent": "Optimization is the data partitioning strategy that we use.",
                    "label": 0
                },
                {
                    "sent": "Because of the way that we divide the data which is based on the exam type, most of the rule application can be done locally.",
                    "label": 0
                },
                {
                    "sent": "Although it still needs some more additional input, but.",
                    "label": 0
                },
                {
                    "sent": "Majority of the processing can be done locally.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This was implemented in Java and the name of this reasoner is distant.",
                    "label": 0
                },
                {
                    "sent": "It's available has open sourced from the GitHub link.",
                    "label": 0
                },
                {
                    "sent": "For the database we use the key value store called Radius and experiments that I'm going to show they were all done on Amazon's EC2M3 Dot X large cluster instances.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Do you want it to keep the configuration close to a regular laptop or a commodity machine so?",
                    "label": 0
                },
                {
                    "sent": "Windows Defender configuration.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I cannot do that.",
                    "label": 0
                },
                {
                    "sent": "So these are some of the biomedical ontologies.",
                    "label": 0
                },
                {
                    "sent": "Go is the gene ontology and there's no mid is the largest biomedical ontology available, so it has.",
                    "label": 0
                },
                {
                    "sent": "The second column shows the number of axioms before the classification process, and then after the classification process some axioms will be added, so that is the number after the classification.",
                    "label": 0
                },
                {
                    "sent": "Seems for some cases.",
                    "label": 0
                },
                {
                    "sent": "The number of exams after classification is as much as say 14 times or 15 times move and in the case of traffic data it's three times more.",
                    "label": 0
                },
                {
                    "sent": "We replicated this moment just to test the scalability of the system, so snow made times 2 * 3 and times fire just.",
                    "label": 0
                },
                {
                    "sent": "Two times duplicated the same contact.",
                    "label": 0
                },
                {
                    "sent": "And the traffic data is from Dublin City, which IBM collects regularly.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are the numbers which are which are obtained after running it on some existing reasons.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So I missed out of memory transit run out of memory at different stages.",
                    "label": 0
                },
                {
                    "sent": "So for example a sorry beast when.",
                    "label": 0
                },
                {
                    "sent": "During the incremental classification case so.",
                    "label": 0
                },
                {
                    "sent": "If the data is streaming, like in the case of static data, we need to, the reasoner should be able to support the streaming process, are sort of incremental progress.",
                    "label": 0
                },
                {
                    "sent": "Instead of recomputing the whole thing every time a new piece of data is added to it.",
                    "label": 0
                },
                {
                    "sent": "But some of the reasons they don't support the incremental classification, and in those cases we simply combine all the different ontology pieces into one big chunk and it was given to it.",
                    "label": 0
                },
                {
                    "sent": "So as you can see, for the big ones, big ontologies like the Snowman, Times 5 and number Times 3, as well as a traffic control, you see it runs out of memory, but for the small ones.",
                    "label": 0
                },
                {
                    "sent": "Apartment is very good.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the classification time for our distributed original.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So we the initial base setup is with eight notes and we went on till 64 notes.",
                    "label": 0
                },
                {
                    "sent": "Spell the small one leg, say go.",
                    "label": 0
                },
                {
                    "sent": "There is a deep as well as raising the performance time, but for the big ones as the number of nodes increase, we can see that the classification time decreases until it hits the largest cluster which is 64 nodes.",
                    "label": 0
                },
                {
                    "sent": "So when it comes to 64 nodes, that communication overhead dominates the performance gain, so that's very generally knowledge case.",
                    "label": 0
                },
                {
                    "sent": "It's the performance decreases with the largest cluster.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as I mentioned, we use Redis as the key value store or the database for our system, and these are the memory footprints taken by radius on different machines.",
                    "label": 0
                },
                {
                    "sent": "It does use some sort of compression internally, and that's why.",
                    "label": 0
                },
                {
                    "sent": "On all these machines, the memories taken by it is various.",
                    "label": 0
                },
                {
                    "sent": "So total comes up to close to 5.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one we already observed this two slides back.",
                    "label": 0
                },
                {
                    "sent": "Like as with the increase in the number of nodes, the speedup also increases until it hits the largest cluster, which is 64 nodes.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From the government's lights, it's clear that there's still some work to be done like we are able to complete the classification process, but the performance is not that good.",
                    "label": 0
                },
                {
                    "sent": "So the future future work involves.",
                    "label": 1
                },
                {
                    "sent": "Couple of things to do with respect to performance, say, can we use a different ontology partitioning strategy or a different ruleset?",
                    "label": 0
                },
                {
                    "sent": "The ones say for example, the ones used by El prisoner, which might give a better performance.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Fine grained analysis of the performance is still we had to do that.",
                    "label": 0
                },
                {
                    "sent": "This implementation is single threaded, which is not good, so we are planning to use threads to make it faster or see the effect of threads on the performance.",
                    "label": 0
                },
                {
                    "sent": "And the data structures also played crucial role in the performance.",
                    "label": 0
                },
                {
                    "sent": "So we are trying to check the there.",
                    "label": 0
                },
                {
                    "sent": "Any alternatives are alternatives to release?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this work, during this presentation I introduced a distributed regional card distance and in the evaluation we notice that the existing reasoners which are announcing machine.",
                    "label": 0
                },
                {
                    "sent": "They don't scale up very well to large ontologies and we are able to classify these large ontologies in.",
                    "label": 0
                },
                {
                    "sent": "Not very quickly, but in a reasonable amount of time, and we're able to finish the task.",
                    "label": 0
                },
                {
                    "sent": "And it also shows good speedup with increasing number of nodes.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's about it, thank you.",
                    "label": 0
                }
            ]
        }
    }
}