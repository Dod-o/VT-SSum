{
    "id": "wn43bziuoyzny3qztum3vues3ba74cl3",
    "title": "The Minimum Transfer Cost Principle for Model-Order Selection",
    "info": {
        "produced by": [
            "Data & Web Mining Lab"
        ],
        "author": [
            "Morteza Haghir Chehreghani, Department of Computer Science, ETH Zurich"
        ],
        "published": "Nov. 30, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Supervised Learning"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2011_haghir_chehreghani_principle/",
    "segmentation": [
        [
            "So very calm everybody to this attack.",
            "I'm Morteza, Haggerty, Allegany and I want to present a joint talk with a joint work with Margot Frank and Walking Woman from each rig.",
            "I will talk about principle for model orders collection.",
            "We call it the minimum transfer cost principle."
        ],
        [
            "So I I started describing on introducing this principle and then I will explain how we can apply this principle in different application including.",
            "Translator SVD for denoising matrices and finding the number of clustering in different clustering problems."
        ],
        [
            "Assume that we have set up an objects with corresponding measurement measurement given by case.",
            "We consider two instance scenario, which means we assume that we have two datasets or one or two with corresponding measure measurements.",
            "EXPAND An extrude from from the same source.",
            "Then in this settings, the model is characterized by a cost function and the parameters RSX&K is the set of measurement and is a solution.",
            "For example, in the case of Chinese clustering, the solution is the assignment valuables plus the centroids.",
            "And K is the number of clusters.",
            "In general, K is the model order for unsupervised problem.",
            "The fundamental question in learning, particularly in supervised learning, is about the up to about the optimal number of clusters, or more generally, about the appropriate model order."
        ],
        [
            "To answer this fundamental question, we consider cross validation or generalization error in this setting, which means good selection of model order based on the first data set should give us good solutions.",
            "Also, in the second data set.",
            "And of course, the goodness of a solution is qualified by a cost function.",
            "So this means that we should be able to translate a solution from one data set to the second data set and then investigate the quality of this solution.",
            "So the new question here is that how we can transfer a solution from one data set to another data set.",
            "I think in supervised setting up articularly in classification we have labels for test data set and this means that then this question is straightforward and trivial because we can use the labels for test data attempts and then we can compute prediction are organizational.",
            "In the case of super unsupervised learning, we don't have any labels for data and then it is not obvious how we can do this transformation."
        ],
        [
            "For the sake of simplicity of explanation, I assume that the cost function is factorial.",
            "I will explain later on how we can generalize the results to non factorial cost function.",
            "This means that the cost function can be written down in this form here.",
            "Which is sum of partial cost for all objects.",
            "In this way we define an object wise mapping between the object wise mapping between objects of second data set and the first data set.",
            "More accurately, we map.",
            "Each object from the second data set and given the set of two measurements through an object from the first data set.",
            "In fact, this mapping function or side function Maps is for each object from the second data set, finds its nearest neighbor from the first data set.",
            "Now we can use this mapping function and then calculate new cost.",
            "Caltrans called transfer costs.",
            "Which is computed in this thing for each object from the second data set using this indicator function.",
            "Here we find its nearest neighbor in the first data set.",
            "And then we consider the solution which corresponds to the objects that we have found in the first data set and the athlete dissolution through the objects that will happen in the second data set and calculate the cost.",
            "And then we sum over all objects in the second data set and take the average.",
            "And in this way we can compute an estimator for.",
            "In this case, we can find an estimator for generaliza."
        ],
        [
            "Metal.",
            "Normally we propose to use the minimum transfer cost principle or empty.",
            "See this principle suggest to use model order for which the transfer costs are minimal.",
            "This means that for different.",
            "For example, in a clustering problem for different number of clusters, we can compute this transfer costs and choose the number for which the corresponding transfer cost is.",
            "The lowest.",
            "It follows the fee is that if you have two simple model then this means that this model will not will not be able to explain both X1 and X2.",
            "On the other hand, if you have two complicated model then this means that it will be able to explain its politics one but fails to explain it's too because of different noise realizations in explain annex too."
        ],
        [
            "So now as I start explaining how we can apply this principle in different unsupervised setting setting problems, the first problem is denoising matrices via truncated SVD.",
            "Assume that we have this metrics.",
            "And the rules are objects and the columns of features and we want to do.",
            "Is it the method which is used in that in the literature?",
            "Is that to do singular value decomposition and then choose the first K component and then we construct a matrix.",
            "This method is called Lola low rank approximation.",
            "The important and critical question here is that.",
            "How many components or how many racks?",
            "We want to choose.",
            "Or if we consider the spectrum of.",
            "Singular values there we bound to the question is that where we want to cut off this spectrum?",
            "So we propose to use MTC.",
            "The minimum transfer cost principle to answer this question.",
            "We use nearest neighbor mapping objects around the second data set to the first data set and we calculate the transfer cost in this way.",
            "As you see here we map, we transfer the second data set to the first data set and then apply the solution that we already have and we have inferred from the first data set.",
            "It is like this.",
            "We have first data set, an second data set.",
            "We map this to the second data set to the first data set an.",
            "Assign the solution that we have for the first data set.",
            "We assign it to the second data set and we calculate, discussed and the experiments show that.",
            "This principle finds the correct number, correct model order, correct number of ranks, which is 5."
        ],
        [
            "We have applied this principle to real world datasets.",
            "And application comes from denoising access access control matrix is that they are binary matrices that we have users and roles and the entries are noisy and we want to do.",
            "Is this bundling active?",
            "So we I can use SVD 2 truncated SVD to.",
            "To do this task.",
            "And here you see the results for four different real world datasets and this Red Square shows the optimal rank and this yellow bond.",
            "The lowest price shows the rank that is selected by MPC and these are the other competitive principles in the literature.",
            "And as you can observe from this plot.",
            "The MTC principle.",
            "Is more consistent than other principles in the literature.",
            "With the optimal rank."
        ],
        [
            "We have also applied this principle to different clustering models and then we have shown that how dispensable is able to find the correct number of clusters in different for different clustering algorithms and methods?",
            "For example, here we consider an important graph partitioning function or clustering problem called correlation clustering.",
            "We assume that we have set of objects and we have set up a device.",
            "Similarities which are either plus one or minus one.",
            "In fact, this cost function.",
            "This model is frequently used in analyzing social networks or other kinds of networks, for particular solution for a particular clustering and given set of measurements, then the cost function is defined in this way, as you see, which is in fact the number of disagreement, which means the number of positive edges that are inside clusters here plus number of.",
            "Sorry, which is the number of negative edges which are inside clusters plus number of positive edges that are between clusters.",
            "Because the goal is to maximize the currency.",
            "And then so we have this model and we assume that we have two datasets, two instances from the from the same source.",
            "And we want to analyze this.",
            "Principle, so we consider the objects that we have in the second data set for each object from the second data set.",
            "The calculated distance that we calculate the distance between these objects and each of the clusters that we have infant insert from the first data set.",
            "So we have set of clusters that you have inferred from the first data set for each object from the second data set, we calculate this distance using this metric, which is constantly discussed function and then choose the cluster with minimum distance and assign its index as cluster label for this object."
        ],
        [
            "I had to do experiments.",
            "We generate two datasets with three clusters and we apply different noise models.",
            "And here you see the results.",
            "So for different number of clusters we calculated the transfer costs as you see here.",
            "This principle is able to find the correct number of clusters which where the noise rate is zero point.",
            "8.",
            "We have compared results with instability index, which is another principle in spirit of cross validation, but its application is limited.",
            "You can see here that the results are consistent.",
            "And the other cases case study is when the noise level is zero 95.",
            "Under this noise level then there is almost no structure in data, which means that we prefer to have only one cluster as we see here, this principle MTC is able to report one cluster as a profile number of clusters, while instability propose two clusters.",
            "The reason is that instability index is not defined for the case when the number of clusters is bunk.",
            "In the paper you can see other case studies with other noise models and noise realizations that this MTC principle works."
        ],
        [
            "We have uploaded also dispensable to mixture of Gaussians and we have showed how this principle can be used to infer the correct number of clusters.",
            "Now we consider a case where we have model mismatch.",
            "Assume that we generate two datasets using mixture of Gaussians.",
            "But instead of using EM algorithm to infer the parameters we use K means to find the clusters.",
            "So and then we find the number of clusters with minimal transfer costs.",
            "He had his motive here.",
            "We have model mismatch because in K means there is no variance.",
            "So we only estimated Centrals and in fact the problem then is converted to vector quantization.",
            "You know that in vector quantization we prefer the number of clusters, or in better words, the number of cells to be at the level of granularity of data."
        ],
        [
            "OK. And here you see the experimental studies for this case.",
            "For the case we have homogeneous clusters.",
            "This means that the assume that clusters are generated from the same source, but it different means the variance developments of the classes are identical.",
            "If you upload this empty principle with nearest neighbor, as you can see here, by increasing the number of clusters.",
            "By increasing the number of clusters, transfer transfer costs reduce and as I said, the reason is that K means is more vector quantization problem rather than clustering, solution is more vector quantization solution than clustering solution.",
            "By the way, to sub and to overcome this model mismatch, we propose to use self mapping or probabilistic mapping.",
            "So for assigning each object from the second data set through the objects from the first data set, we define a gift distribution and this keeps distribution is controlled by a temperature without parameter.",
            "And then we tune this beta parameter according to the variance of whole data set.",
            "And then we do this probabilistic mapping and calculate transfer costs for different number of clusters.",
            "And as you see here from this blue curve, then you see that this works then.",
            "Soft mapping or probabilistic mapping is able to find the true number of clusters, which is 3 and we have also considered the generated mapping.",
            "Generated mapping means that we map the objects from the second data set to the first data data set based on the value based on the order that they have generated in artificial data.",
            "We have this mapping, but in real world data we don't have this mapping."
        ],
        [
            "And finally we consider a more complicated case for this model mismatch study.",
            "And here you see that we have clusters but with different scales.",
            "And.",
            "And now the question is not how many clusters we have.",
            "Again, if the upload MTC with nearest neighbor mapping, you see that because of vector quantization, nature of this algorithm it decreases until the level of ground with your data.",
            "And then you see that generated mapping which is applicable only for synthetic data, finds three clusters.",
            "And if you use a soft mapping or probabilistic mapping, it prefers two clusters in step three cluster.",
            "The reason is that.",
            "Then we define this.",
            "The soft mapping or probabilistic mapping.",
            "Then we have a global parameter which is temperature in Gibbs distribute distribution.",
            "And then we tune this global parameter according to the variance of data.",
            "So we have some kind of global variants.",
            "But if if you have clusters with different scales with different variances, then it fails to capture this probability of clusters because we have only one parameter that can be that we can tune for this global soft mapping while in clusters at cluster level we have different finances for each cluster because of this inconsistency we are not able to capture.",
            "The properties of each cluster."
        ],
        [
            "So I started the talk with introducing.",
            "MTC minimum transfer costs, which is applicable for model order selection in different applications.",
            "We don't see any limitation for uploading this impossible, so we think that we can apply this for any unsupervised problem.",
            "An interpreter we have tried to cover different unsupervised problems so.",
            "You can see the application of this principle in Gaussian mixture models, different clustering models.",
            "Graph Parching models are just correlation, clustering or truncated truncated SVD for denoising images or boolean matrices or for Boolean matrix factorization and then for the case that we have model mismatch, we propose to use task mapping, probabilistic mapping and.",
            "Chemistry different data centers.",
            "Thank you very much for your attention.",
            "Questions.",
            "Definition of this transfer cost you.",
            "You make use of a nearest neighbor mapping in fact."
        ],
        [
            "Yes, my question.",
            "My question is whether it would not be perhaps more reasonable to solve really an assignment problem.",
            "Cause if you do it like this then the mapping is not unique, so potentially you may map several points from the 1st.",
            "Solution to the second one to the same point of the 2nd.",
            "The second one, also, it's not.",
            "It's not an assignment in a sense.",
            "You mean it is better to have one to one assignment?",
            "Yes, but I think it is not true because based on the way that we split the data into train and test, we might have some patterns more.",
            "Some pattern is stronger in one data set and other so it is better to have.",
            "It is better to provide possibility of assigning different several objects to one object.",
            "Question in the back.",
            "You need your own Mike.",
            "That's why there's a microphone.",
            "It seems to me that you're taking advantage of the fact that the nearest neighbor algorithm can do essentially learning from positive examples only.",
            "So if you have your set one and you're set to.",
            "A single instance in set one can be a positive example of a unique class and percent two you can map it to that single instance.",
            "A single positive example.",
            "So in general you can instead of using a nearest neighbor algorithm, you can use any algorithm that can learn from a single positive example without negative examples so.",
            "I think there's more general generalization of your approach is replacing nearest neighbor with any algorithm returns from a single positive examples.",
            "Yes, exactly the paper.",
            "You can see that we have proposed how we can generate this mapping, so this is I started snapping mostly for the sake of.",
            "Simplicity for explanation.",
            "So independent we have explained how we can generalize it and then we have defined for this one have defined it as a function and then this function can be defined in a way that as you like and then we define it improve, obviously.",
            "But it's not just park assignment.",
            "For some cases status.",
            "Just in general we don't have limitation definition of this mapping function, but for the case studies that we I have explained, nearest neighbor nearest neighbor mapping works and according to our experiments.",
            "So for all of the unsupervised learning problems that so far we have considered and we don't have model mismatches, nearest neighbor mapping works.",
            "Or do we have problem?",
            "Thanks very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So very calm everybody to this attack.",
                    "label": 0
                },
                {
                    "sent": "I'm Morteza, Haggerty, Allegany and I want to present a joint talk with a joint work with Margot Frank and Walking Woman from each rig.",
                    "label": 0
                },
                {
                    "sent": "I will talk about principle for model orders collection.",
                    "label": 0
                },
                {
                    "sent": "We call it the minimum transfer cost principle.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I I started describing on introducing this principle and then I will explain how we can apply this principle in different application including.",
                    "label": 0
                },
                {
                    "sent": "Translator SVD for denoising matrices and finding the number of clustering in different clustering problems.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Assume that we have set up an objects with corresponding measurement measurement given by case.",
                    "label": 0
                },
                {
                    "sent": "We consider two instance scenario, which means we assume that we have two datasets or one or two with corresponding measure measurements.",
                    "label": 0
                },
                {
                    "sent": "EXPAND An extrude from from the same source.",
                    "label": 0
                },
                {
                    "sent": "Then in this settings, the model is characterized by a cost function and the parameters RSX&K is the set of measurement and is a solution.",
                    "label": 0
                },
                {
                    "sent": "For example, in the case of Chinese clustering, the solution is the assignment valuables plus the centroids.",
                    "label": 0
                },
                {
                    "sent": "And K is the number of clusters.",
                    "label": 0
                },
                {
                    "sent": "In general, K is the model order for unsupervised problem.",
                    "label": 0
                },
                {
                    "sent": "The fundamental question in learning, particularly in supervised learning, is about the up to about the optimal number of clusters, or more generally, about the appropriate model order.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To answer this fundamental question, we consider cross validation or generalization error in this setting, which means good selection of model order based on the first data set should give us good solutions.",
                    "label": 0
                },
                {
                    "sent": "Also, in the second data set.",
                    "label": 0
                },
                {
                    "sent": "And of course, the goodness of a solution is qualified by a cost function.",
                    "label": 0
                },
                {
                    "sent": "So this means that we should be able to translate a solution from one data set to the second data set and then investigate the quality of this solution.",
                    "label": 0
                },
                {
                    "sent": "So the new question here is that how we can transfer a solution from one data set to another data set.",
                    "label": 0
                },
                {
                    "sent": "I think in supervised setting up articularly in classification we have labels for test data set and this means that then this question is straightforward and trivial because we can use the labels for test data attempts and then we can compute prediction are organizational.",
                    "label": 0
                },
                {
                    "sent": "In the case of super unsupervised learning, we don't have any labels for data and then it is not obvious how we can do this transformation.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the sake of simplicity of explanation, I assume that the cost function is factorial.",
                    "label": 0
                },
                {
                    "sent": "I will explain later on how we can generalize the results to non factorial cost function.",
                    "label": 0
                },
                {
                    "sent": "This means that the cost function can be written down in this form here.",
                    "label": 0
                },
                {
                    "sent": "Which is sum of partial cost for all objects.",
                    "label": 0
                },
                {
                    "sent": "In this way we define an object wise mapping between the object wise mapping between objects of second data set and the first data set.",
                    "label": 0
                },
                {
                    "sent": "More accurately, we map.",
                    "label": 0
                },
                {
                    "sent": "Each object from the second data set and given the set of two measurements through an object from the first data set.",
                    "label": 0
                },
                {
                    "sent": "In fact, this mapping function or side function Maps is for each object from the second data set, finds its nearest neighbor from the first data set.",
                    "label": 0
                },
                {
                    "sent": "Now we can use this mapping function and then calculate new cost.",
                    "label": 0
                },
                {
                    "sent": "Caltrans called transfer costs.",
                    "label": 0
                },
                {
                    "sent": "Which is computed in this thing for each object from the second data set using this indicator function.",
                    "label": 0
                },
                {
                    "sent": "Here we find its nearest neighbor in the first data set.",
                    "label": 0
                },
                {
                    "sent": "And then we consider the solution which corresponds to the objects that we have found in the first data set and the athlete dissolution through the objects that will happen in the second data set and calculate the cost.",
                    "label": 0
                },
                {
                    "sent": "And then we sum over all objects in the second data set and take the average.",
                    "label": 0
                },
                {
                    "sent": "And in this way we can compute an estimator for.",
                    "label": 0
                },
                {
                    "sent": "In this case, we can find an estimator for generaliza.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Metal.",
                    "label": 0
                },
                {
                    "sent": "Normally we propose to use the minimum transfer cost principle or empty.",
                    "label": 1
                },
                {
                    "sent": "See this principle suggest to use model order for which the transfer costs are minimal.",
                    "label": 0
                },
                {
                    "sent": "This means that for different.",
                    "label": 0
                },
                {
                    "sent": "For example, in a clustering problem for different number of clusters, we can compute this transfer costs and choose the number for which the corresponding transfer cost is.",
                    "label": 0
                },
                {
                    "sent": "The lowest.",
                    "label": 0
                },
                {
                    "sent": "It follows the fee is that if you have two simple model then this means that this model will not will not be able to explain both X1 and X2.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if you have two complicated model then this means that it will be able to explain its politics one but fails to explain it's too because of different noise realizations in explain annex too.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now as I start explaining how we can apply this principle in different unsupervised setting setting problems, the first problem is denoising matrices via truncated SVD.",
                    "label": 1
                },
                {
                    "sent": "Assume that we have this metrics.",
                    "label": 0
                },
                {
                    "sent": "And the rules are objects and the columns of features and we want to do.",
                    "label": 0
                },
                {
                    "sent": "Is it the method which is used in that in the literature?",
                    "label": 0
                },
                {
                    "sent": "Is that to do singular value decomposition and then choose the first K component and then we construct a matrix.",
                    "label": 0
                },
                {
                    "sent": "This method is called Lola low rank approximation.",
                    "label": 0
                },
                {
                    "sent": "The important and critical question here is that.",
                    "label": 0
                },
                {
                    "sent": "How many components or how many racks?",
                    "label": 0
                },
                {
                    "sent": "We want to choose.",
                    "label": 0
                },
                {
                    "sent": "Or if we consider the spectrum of.",
                    "label": 0
                },
                {
                    "sent": "Singular values there we bound to the question is that where we want to cut off this spectrum?",
                    "label": 0
                },
                {
                    "sent": "So we propose to use MTC.",
                    "label": 0
                },
                {
                    "sent": "The minimum transfer cost principle to answer this question.",
                    "label": 0
                },
                {
                    "sent": "We use nearest neighbor mapping objects around the second data set to the first data set and we calculate the transfer cost in this way.",
                    "label": 0
                },
                {
                    "sent": "As you see here we map, we transfer the second data set to the first data set and then apply the solution that we already have and we have inferred from the first data set.",
                    "label": 0
                },
                {
                    "sent": "It is like this.",
                    "label": 0
                },
                {
                    "sent": "We have first data set, an second data set.",
                    "label": 0
                },
                {
                    "sent": "We map this to the second data set to the first data set an.",
                    "label": 0
                },
                {
                    "sent": "Assign the solution that we have for the first data set.",
                    "label": 0
                },
                {
                    "sent": "We assign it to the second data set and we calculate, discussed and the experiments show that.",
                    "label": 0
                },
                {
                    "sent": "This principle finds the correct number, correct model order, correct number of ranks, which is 5.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have applied this principle to real world datasets.",
                    "label": 0
                },
                {
                    "sent": "And application comes from denoising access access control matrix is that they are binary matrices that we have users and roles and the entries are noisy and we want to do.",
                    "label": 0
                },
                {
                    "sent": "Is this bundling active?",
                    "label": 0
                },
                {
                    "sent": "So we I can use SVD 2 truncated SVD to.",
                    "label": 1
                },
                {
                    "sent": "To do this task.",
                    "label": 0
                },
                {
                    "sent": "And here you see the results for four different real world datasets and this Red Square shows the optimal rank and this yellow bond.",
                    "label": 0
                },
                {
                    "sent": "The lowest price shows the rank that is selected by MPC and these are the other competitive principles in the literature.",
                    "label": 0
                },
                {
                    "sent": "And as you can observe from this plot.",
                    "label": 0
                },
                {
                    "sent": "The MTC principle.",
                    "label": 0
                },
                {
                    "sent": "Is more consistent than other principles in the literature.",
                    "label": 0
                },
                {
                    "sent": "With the optimal rank.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have also applied this principle to different clustering models and then we have shown that how dispensable is able to find the correct number of clusters in different for different clustering algorithms and methods?",
                    "label": 0
                },
                {
                    "sent": "For example, here we consider an important graph partitioning function or clustering problem called correlation clustering.",
                    "label": 1
                },
                {
                    "sent": "We assume that we have set of objects and we have set up a device.",
                    "label": 0
                },
                {
                    "sent": "Similarities which are either plus one or minus one.",
                    "label": 0
                },
                {
                    "sent": "In fact, this cost function.",
                    "label": 0
                },
                {
                    "sent": "This model is frequently used in analyzing social networks or other kinds of networks, for particular solution for a particular clustering and given set of measurements, then the cost function is defined in this way, as you see, which is in fact the number of disagreement, which means the number of positive edges that are inside clusters here plus number of.",
                    "label": 0
                },
                {
                    "sent": "Sorry, which is the number of negative edges which are inside clusters plus number of positive edges that are between clusters.",
                    "label": 0
                },
                {
                    "sent": "Because the goal is to maximize the currency.",
                    "label": 0
                },
                {
                    "sent": "And then so we have this model and we assume that we have two datasets, two instances from the from the same source.",
                    "label": 0
                },
                {
                    "sent": "And we want to analyze this.",
                    "label": 0
                },
                {
                    "sent": "Principle, so we consider the objects that we have in the second data set for each object from the second data set.",
                    "label": 0
                },
                {
                    "sent": "The calculated distance that we calculate the distance between these objects and each of the clusters that we have infant insert from the first data set.",
                    "label": 0
                },
                {
                    "sent": "So we have set of clusters that you have inferred from the first data set for each object from the second data set, we calculate this distance using this metric, which is constantly discussed function and then choose the cluster with minimum distance and assign its index as cluster label for this object.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I had to do experiments.",
                    "label": 0
                },
                {
                    "sent": "We generate two datasets with three clusters and we apply different noise models.",
                    "label": 0
                },
                {
                    "sent": "And here you see the results.",
                    "label": 0
                },
                {
                    "sent": "So for different number of clusters we calculated the transfer costs as you see here.",
                    "label": 1
                },
                {
                    "sent": "This principle is able to find the correct number of clusters which where the noise rate is zero point.",
                    "label": 0
                },
                {
                    "sent": "8.",
                    "label": 0
                },
                {
                    "sent": "We have compared results with instability index, which is another principle in spirit of cross validation, but its application is limited.",
                    "label": 0
                },
                {
                    "sent": "You can see here that the results are consistent.",
                    "label": 0
                },
                {
                    "sent": "And the other cases case study is when the noise level is zero 95.",
                    "label": 0
                },
                {
                    "sent": "Under this noise level then there is almost no structure in data, which means that we prefer to have only one cluster as we see here, this principle MTC is able to report one cluster as a profile number of clusters, while instability propose two clusters.",
                    "label": 0
                },
                {
                    "sent": "The reason is that instability index is not defined for the case when the number of clusters is bunk.",
                    "label": 0
                },
                {
                    "sent": "In the paper you can see other case studies with other noise models and noise realizations that this MTC principle works.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have uploaded also dispensable to mixture of Gaussians and we have showed how this principle can be used to infer the correct number of clusters.",
                    "label": 0
                },
                {
                    "sent": "Now we consider a case where we have model mismatch.",
                    "label": 0
                },
                {
                    "sent": "Assume that we generate two datasets using mixture of Gaussians.",
                    "label": 1
                },
                {
                    "sent": "But instead of using EM algorithm to infer the parameters we use K means to find the clusters.",
                    "label": 1
                },
                {
                    "sent": "So and then we find the number of clusters with minimal transfer costs.",
                    "label": 1
                },
                {
                    "sent": "He had his motive here.",
                    "label": 0
                },
                {
                    "sent": "We have model mismatch because in K means there is no variance.",
                    "label": 0
                },
                {
                    "sent": "So we only estimated Centrals and in fact the problem then is converted to vector quantization.",
                    "label": 0
                },
                {
                    "sent": "You know that in vector quantization we prefer the number of clusters, or in better words, the number of cells to be at the level of granularity of data.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. And here you see the experimental studies for this case.",
                    "label": 0
                },
                {
                    "sent": "For the case we have homogeneous clusters.",
                    "label": 0
                },
                {
                    "sent": "This means that the assume that clusters are generated from the same source, but it different means the variance developments of the classes are identical.",
                    "label": 0
                },
                {
                    "sent": "If you upload this empty principle with nearest neighbor, as you can see here, by increasing the number of clusters.",
                    "label": 0
                },
                {
                    "sent": "By increasing the number of clusters, transfer transfer costs reduce and as I said, the reason is that K means is more vector quantization problem rather than clustering, solution is more vector quantization solution than clustering solution.",
                    "label": 0
                },
                {
                    "sent": "By the way, to sub and to overcome this model mismatch, we propose to use self mapping or probabilistic mapping.",
                    "label": 0
                },
                {
                    "sent": "So for assigning each object from the second data set through the objects from the first data set, we define a gift distribution and this keeps distribution is controlled by a temperature without parameter.",
                    "label": 0
                },
                {
                    "sent": "And then we tune this beta parameter according to the variance of whole data set.",
                    "label": 0
                },
                {
                    "sent": "And then we do this probabilistic mapping and calculate transfer costs for different number of clusters.",
                    "label": 0
                },
                {
                    "sent": "And as you see here from this blue curve, then you see that this works then.",
                    "label": 0
                },
                {
                    "sent": "Soft mapping or probabilistic mapping is able to find the true number of clusters, which is 3 and we have also considered the generated mapping.",
                    "label": 1
                },
                {
                    "sent": "Generated mapping means that we map the objects from the second data set to the first data data set based on the value based on the order that they have generated in artificial data.",
                    "label": 0
                },
                {
                    "sent": "We have this mapping, but in real world data we don't have this mapping.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally we consider a more complicated case for this model mismatch study.",
                    "label": 0
                },
                {
                    "sent": "And here you see that we have clusters but with different scales.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And now the question is not how many clusters we have.",
                    "label": 0
                },
                {
                    "sent": "Again, if the upload MTC with nearest neighbor mapping, you see that because of vector quantization, nature of this algorithm it decreases until the level of ground with your data.",
                    "label": 0
                },
                {
                    "sent": "And then you see that generated mapping which is applicable only for synthetic data, finds three clusters.",
                    "label": 0
                },
                {
                    "sent": "And if you use a soft mapping or probabilistic mapping, it prefers two clusters in step three cluster.",
                    "label": 0
                },
                {
                    "sent": "The reason is that.",
                    "label": 0
                },
                {
                    "sent": "Then we define this.",
                    "label": 0
                },
                {
                    "sent": "The soft mapping or probabilistic mapping.",
                    "label": 1
                },
                {
                    "sent": "Then we have a global parameter which is temperature in Gibbs distribute distribution.",
                    "label": 0
                },
                {
                    "sent": "And then we tune this global parameter according to the variance of data.",
                    "label": 0
                },
                {
                    "sent": "So we have some kind of global variants.",
                    "label": 0
                },
                {
                    "sent": "But if if you have clusters with different scales with different variances, then it fails to capture this probability of clusters because we have only one parameter that can be that we can tune for this global soft mapping while in clusters at cluster level we have different finances for each cluster because of this inconsistency we are not able to capture.",
                    "label": 0
                },
                {
                    "sent": "The properties of each cluster.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I started the talk with introducing.",
                    "label": 0
                },
                {
                    "sent": "MTC minimum transfer costs, which is applicable for model order selection in different applications.",
                    "label": 1
                },
                {
                    "sent": "We don't see any limitation for uploading this impossible, so we think that we can apply this for any unsupervised problem.",
                    "label": 0
                },
                {
                    "sent": "An interpreter we have tried to cover different unsupervised problems so.",
                    "label": 1
                },
                {
                    "sent": "You can see the application of this principle in Gaussian mixture models, different clustering models.",
                    "label": 0
                },
                {
                    "sent": "Graph Parching models are just correlation, clustering or truncated truncated SVD for denoising images or boolean matrices or for Boolean matrix factorization and then for the case that we have model mismatch, we propose to use task mapping, probabilistic mapping and.",
                    "label": 1
                },
                {
                    "sent": "Chemistry different data centers.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Definition of this transfer cost you.",
                    "label": 0
                },
                {
                    "sent": "You make use of a nearest neighbor mapping in fact.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, my question.",
                    "label": 0
                },
                {
                    "sent": "My question is whether it would not be perhaps more reasonable to solve really an assignment problem.",
                    "label": 0
                },
                {
                    "sent": "Cause if you do it like this then the mapping is not unique, so potentially you may map several points from the 1st.",
                    "label": 0
                },
                {
                    "sent": "Solution to the second one to the same point of the 2nd.",
                    "label": 0
                },
                {
                    "sent": "The second one, also, it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not an assignment in a sense.",
                    "label": 0
                },
                {
                    "sent": "You mean it is better to have one to one assignment?",
                    "label": 0
                },
                {
                    "sent": "Yes, but I think it is not true because based on the way that we split the data into train and test, we might have some patterns more.",
                    "label": 0
                },
                {
                    "sent": "Some pattern is stronger in one data set and other so it is better to have.",
                    "label": 0
                },
                {
                    "sent": "It is better to provide possibility of assigning different several objects to one object.",
                    "label": 0
                },
                {
                    "sent": "Question in the back.",
                    "label": 0
                },
                {
                    "sent": "You need your own Mike.",
                    "label": 0
                },
                {
                    "sent": "That's why there's a microphone.",
                    "label": 0
                },
                {
                    "sent": "It seems to me that you're taking advantage of the fact that the nearest neighbor algorithm can do essentially learning from positive examples only.",
                    "label": 0
                },
                {
                    "sent": "So if you have your set one and you're set to.",
                    "label": 0
                },
                {
                    "sent": "A single instance in set one can be a positive example of a unique class and percent two you can map it to that single instance.",
                    "label": 0
                },
                {
                    "sent": "A single positive example.",
                    "label": 0
                },
                {
                    "sent": "So in general you can instead of using a nearest neighbor algorithm, you can use any algorithm that can learn from a single positive example without negative examples so.",
                    "label": 0
                },
                {
                    "sent": "I think there's more general generalization of your approach is replacing nearest neighbor with any algorithm returns from a single positive examples.",
                    "label": 0
                },
                {
                    "sent": "Yes, exactly the paper.",
                    "label": 0
                },
                {
                    "sent": "You can see that we have proposed how we can generate this mapping, so this is I started snapping mostly for the sake of.",
                    "label": 0
                },
                {
                    "sent": "Simplicity for explanation.",
                    "label": 0
                },
                {
                    "sent": "So independent we have explained how we can generalize it and then we have defined for this one have defined it as a function and then this function can be defined in a way that as you like and then we define it improve, obviously.",
                    "label": 0
                },
                {
                    "sent": "But it's not just park assignment.",
                    "label": 0
                },
                {
                    "sent": "For some cases status.",
                    "label": 0
                },
                {
                    "sent": "Just in general we don't have limitation definition of this mapping function, but for the case studies that we I have explained, nearest neighbor nearest neighbor mapping works and according to our experiments.",
                    "label": 0
                },
                {
                    "sent": "So for all of the unsupervised learning problems that so far we have considered and we don't have model mismatches, nearest neighbor mapping works.",
                    "label": 0
                },
                {
                    "sent": "Or do we have problem?",
                    "label": 0
                },
                {
                    "sent": "Thanks very much.",
                    "label": 0
                }
            ]
        }
    }
}