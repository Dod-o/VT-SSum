{
    "id": "gnmlwb2zs5ncv6udpt5wjwck2i5ishrw",
    "title": "Learning Bayesian Networks",
    "info": {
        "author": [
            "Richard E. Neapolitan, Northeastern Illinois University"
        ],
        "published": "Aug. 12, 2007",
        "recorded": "August 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/kdd07_neapolitan_lbn/",
    "segmentation": [
        [
            "Side and so maybe I probably be out there myself if I hadn't committed to giving this talk.",
            "He told me you told me that it's always like this here.",
            "They have most of you heard of Dan Kahneman.",
            "He did all the studies with famous diverse keyon, indicating that people don't reason normatively.",
            "He won the Nobel Prize in 2002 for Prospect theory.",
            "Anyway, I heard him give a talk few years ago, and the title of the talk.",
            "Are people really happy you're in California because of the weather, and now they see the weather here.",
            "I think it might be true.",
            "This is great weather.",
            "The talk was.",
            "Was very similar to the stuff he did on whether people reason rationally wanted to know if.",
            "If people's report of happiness was the consistent with their actual experience of happiness, and of course he found that wasn't the case, for instance.",
            "His research showed that divorced women tended to actually be happier than married women, even though they reported they were not as happy.",
            "So you guys could come to hear about condoms research.",
            "Obviously I'm stalling because I hate giving power point presentations.",
            "This is only my second one.",
            "First, one bombed miserable, even though I had a lot of animation and voice and everything.",
            "It's just I don't like the medium."
        ],
        [
            "See how it goes.",
            "Here is the talk.",
            "It's called statistical causality, and that's me, and that's my website.",
            "I'm going to be talking about notion of causality, and it's the notion that's developed in these texts and other places too.",
            "I just, you know, wrote down some places that I knew about.",
            "And it concerns variables influencing other variables.",
            "For instance, the smoking caused lung cancer.",
            "So what do we mean by variables influencing other variables?",
            "You have some population.",
            "In this case people, and there's a random variable in the population smoking.",
            "There's another random variable, lung cancer.",
            "The more the people tend to smoke, does that indicate the more they get?",
            "Lung cancer alright, so there's the value of 1 variable have a probabilistic effect on the value of another?",
            "Alright, that's that's the kind of causality.",
            "So the probability of lung cancer given that somebody.",
            "Smokes when you manipulate them to smoke greater than the probability that they do not.",
            "It does not concern token causality, which has to do with one time events where you have no population.",
            "A classic example is that the goal for running into my golf ball cause it to go in the hole and that we don't have any population here.",
            "It's one golfing and you know, like balls going this way go for runs into it and it goes in the hole then I'm."
        ],
        [
            "Right, but what is that?",
            "Is that a causal event?",
            "It's called token causality, and that's not what I'm discussing.",
            "I'm discussing the first type.",
            "Alright, here's what here's what I was talking about a minute ago about what kind of causality this is, and it formalizes it.",
            "It's a common way to at least learn causality, even if we don't define it this way of manipulation experiment, drug manufacturers do this all the time you take.",
            "A set of people you put half of them in one group and half in the other.",
            "That's the manipulation.",
            "In other words, the probability of being manipulated to be in one group is .5.",
            "The probability of being manipulated to be in the other group is .5.",
            "So you've got these people broken up into two groups.",
            "Everybody in Group one, you make smoke the probability of smoking giving you in Group one is 1.",
            "Everybody here knows this notation conditional probability.",
            "It's the probability of this event given that this one takes this value alright, and probably smoking not smoking, that's what the two stands for in this example.",
            "Given your group on is 0, so everyone in Group One smokes everyone in Group Two was not smoke.",
            "Now.",
            "If smoking causes lung cancer Group One would have a higher incidence of lung cancer than Group 2, and the more that's true, the greater the extent to which Group One has an incidence of lung cancer.",
            "The more we believe smoking causes lung cancer.",
            "So that's how we classically learn causation.",
            "And that's how drug companies do."
        ],
        [
            "Do it all the time.",
            "They want to see if a drug is a causative effect on some cure, and they do a manipulation experiment.",
            "I know it here.",
            "We don't really want to manipulate people and make them smoke.",
            "I mean, there's there's certain kinds of experiments you really don't want to do.",
            "I mean, especially in this country, we're trying to eliminate smoking, almost drugs.",
            "You can at least know annoy you, can't smoke anywhere starting January 1st.",
            "Virtually nowhere.",
            "Alright, so can we learn something about causal influences from passive data?",
            "Some people have other words for this.",
            "I call it passive data, it means."
        ],
        [
            "Data you just mind the data that you don't purposely create in any way.",
            "Now let's look at the smoking example again.",
            "From passive data, we've learned that smoking and lung cancer are correlated, right?",
            "And that's this arrow here or this line here means correlation.",
            "Now that could be due to smoking causing lung cancer, right?",
            "Certainly smoking causes lung cancer like I just said they would be correlated."
        ],
        [
            "So from this passive data, do I want to conclude that smoking causes lung cancer well?",
            "As smoking and lung cancer are correlated, it could be the reverse.",
            "People who get lung cancer could tend to pick up smoking, you know, because of the domain.",
            "That seems silly, right?",
            "About if this was just X&Y, would it seems so silly?",
            "I do know of 1 case X is actually a friend of mine, a woman who.",
            "Had lung cancer and quit smoking, but then she found out she was terminal and she said I may as well go out smoking and so in her case that she really had no advanced lung cancer.",
            "She started smoking.",
            "So in that case it can actually cause it that this is more of a token event almost though."
        ],
        [
            "But the point is that this just said X&Y from the correlation alone.",
            "Smoking can cause lung cancer, lung cancer, plus smoking we don't know.",
            "And the other common explanation is they could have a hidden common cause.",
            "Other the understanding of why this would correlate smoking and lung cancer is essential to understanding this.",
            "Talk that if if two events have a hidden common cause, they tend to be correlated.",
            "Why is that?",
            "Because if you smoke, it makes it more probable you have whatever this causes, which makes it more probable.",
            "You would also have lung cancer, so they're like they're correlated through this through this chain.",
            "The explanation would be this, perhaps some genetic defects and mutations, right?",
            "That would make you crave nicotine and also make you get lung cancer.",
            "I actually think at one time the.",
            "The cigarette manufacturers were arguing this point.",
            "I remember seeing that somewhere, but again, if this was just X&Y."
        ],
        [
            "Read explanations as good as the others.",
            "They all would make smoking and lung cancer correlated.",
            "So it seems like you can't learn causal influences from correlation from passive data.",
            "But the problem here is that we only have data on two variables.",
            "All right, well research in the 90s have shown that we can learn something about causal influences.",
            "If we have data on at least four variables, that might seem odd.",
            "Why would having data on other variables that other than smoking and lung cancer enable you to conclude that smoking causes lung cancer?"
        ],
        [
            "And that is actually the purpose of this talk.",
            "All right?",
            "Well why that is the case?",
            "Why?",
            "If you have more data, you can learn something.",
            "At first I need to define a causal graph.",
            "In general, when I have something written like this, I'm not going to say it.",
            "But like I said, I don't really like PowerPoint presentations and there's no point in me saying what you can read or even necessary leaving it up here long enough for you to read it.",
            "What I want to do is go over examples more and you can come back to these definitions later and.",
            "And look at them.",
            "So in general I'm not going to be reading these things.",
            "Here's here's what we mean by a direct cause.",
            "This is a study in rats done by luck at all in 1995.",
            "They manipulated testosterone levels.",
            "And found that there had a causal effect on DHT levels dehydro testosterone.",
            "They also found when they manipulated testosterone levels, they found that it had a causal effect on erectile function, so testosterone causes DHT levels and they found it also causes erectile function.",
            "They manipulated DHT itself.",
            "Alright, while holding testosterone fixed and found that it had an effect on erectile function, so there's an arrow here.",
            "Now, why didn't I draw an arrow from T to E?",
            "Why is that arrow missing, or because when they held DHT fixed that at a given level, if they if they held it low, it didn't matter whether testosterone was lower high.",
            "You had this level of erectile function was the same and when they fixed it high the same thing.",
            "It didn't matter whether the testosterone levels the erectile function levels were the same.",
            "Alright, so T is not a direct cause of E. That's why did natural an edge here by a direct cause.",
            "We mean there's no variable amongst your observed variables that mediates the causal effect.",
            "Now what if DHT wasn't one of our observed variables?",
            "Well, then there would be an arrow directly here, so whether something is the direct cause or not is dependent upon what variables you actually observing.",
            "I mean, you can argue philosophically that there's always some intermediate variables, and things are just.",
            "You know, unfolding in some certain way and we only as humans articulate certain variables that we observe.",
            "Alright, so that's what we mean by that."
        ],
        [
            "Direct cause and a causal graph is a graph containing.",
            "Variables and edges that are direct causes.",
            "Now, here's another thing.",
            "I hate to just say it right because he's saying it isn't going to.",
            "By the way, how much is the curiosity?",
            "How many people know the causal Markov assumption?",
            "And I want to get a feel for my audience.",
            "So the majority of you are not really familiar with causal networks or Bayesian networks, right?",
            "You're not right.",
            "So I've been to me there are like.",
            "Well, a causal network is a special kind of Bayesian network.",
            "It's one where the arcs represent causal influences.",
            "Cowsill is just something physical network.",
            "Yeah Beijing that were just represents conditional independence ease and you don't necessarily give them causal meaning.",
            "But then a certain kind of Beijing network is a causal network.",
            "In other words, it's a subset of all Bayesian networks where the edges do represent causes, but.",
            "Hunt people who know Bayesian networks work.",
            "She also know color networks.",
            "It seems that most people don't know either in this audience, so I better this is important to get this causal Markov assumption straight.",
            "And again, I'm not going to read it.",
            "What I'm going to do is show it by examples.",
            "Alright, let's go down to the bottom things.",
            "It says the probability distribution satisfies the Markov condition.",
            "If the probability of each variable is independent of its non descendants conditional on its parents.",
            "And then if we assume that the causal graph containing the variables satisfies that assumption, we make the causal Markov assumption.",
            "Now what I want to do is show some simple examples, causal little causal networks to show why.",
            "First of all, by going through this example."
        ],
        [
            "Give you intuition as to why it's reasonable to make this assumption, and second of all.",
            "Hopefully it'll make you understand what the assumption is.",
            "In these examples I use a capital letter to denote both of binary variable and one and it's one of its values.",
            "For simplicity, let's look at this simple example.",
            "Colds cause sneezing and they cause runny noses.",
            "Alright, so I and sneezing does not cause a runny nose and runny nose does not cause sneezing.",
            "So this is the causal graph causal DAG for these variables are also my only observed variables.",
            "Now the probability of sneezing.",
            "This is where I'm using S docile stand for a value.",
            "It means that person is sneezing, the probably of sneezing.",
            "Given you have a runny nose is greater than the probability of sneezing, that's based upon the argument I was giving before.",
            "If you have a runny nose, makes it more likely you have a cold, which makes it more likely have another symptom of of the coal.",
            "Alright, so they are not independent this notation here.",
            "It's an at symbol means not independent S&R, so this notation I'll be using.",
            "But but if I condition on a cold.",
            "In other words, I give this.",
            "I know the value of this variable.",
            "I know for this particular individual that she or he has a cold.",
            "All right, then there's a fixed probability of the person sneezing.",
            "Maybe it's 70% of people with colds.",
            "Sneeze.",
            "There's a fixed probability of the person has a runny nose, maybe that's 80%.",
            "These this value no longer makes this one more probable.",
            "The probability of sneezing.",
            "This means conditional on two values, practices published sneezing.",
            "Given you have a cold right, this is probably a sneezing, given you have a runny nose and a cold.",
            "And I'm saying that our intuition tells us they should be equal.",
            "Because the only thing that made them connected probabilistically was because runny nose made a cold more probable, but it can't do that anymore.",
            "'cause we know the person has a cold.",
            "So finding out I have a cold is useless information spreads.",
            "Probably sneezing because you already have this probability of what's like .7 there sneezing.",
            "So my argument is that sneezing and runny noses are independent, conditional and cold.",
            "Here is the notation, sneezing and runny nose dependent conditional on cold.",
            "And that the causal Markov assumption is that a node is independent of its non descendants conditional on its parents and more people are showing up.",
            "People are taking.",
            "Long lunch, and that's exactly what this says.",
            "Sneezing would be independent of its non descendant.",
            "Your descendants are all the all the ones you're pointing to hear, right?",
            "He's pointing to nobody, so sneezing is independent of running nose conditional on its parent cold and that's what the causal Markov assumption says.",
            "And so I'm illustrating with a simple example that it's a reasonable assumption.",
            "Went for a common cause.",
            "I forgot you guys ask questions at the end or keep trying to say they have any questions before I go on or but how do these talks code I give the whole talk and then questions.",
            "Nobody knows, right?",
            "It's up to me.",
            "Well, if you have a question, feel free to interrupt me.",
            "Alright, it's like.",
            "Well, because it's the same mark off like a Markov chain.",
            "It's the no forgetting right?",
            "It's forgetting me not know.",
            "Forgetting it means once this guy renders this guy, you forgot this guys value.",
            "Once you know this guy's value.",
            "I use the word guides.",
            "It's kind of like.",
            "And away called variables guys.",
            "But you see that why Markov is used because of the fact that this value is forgotten once this value is known.",
            "So if somebody with Markov chain.",
            "It's not similar, but it's the same notion.",
            "Yeah.",
            "Before this one, you said that this one.",
            "Details or number sentence, but actually it is dependent on the Castle.",
            "It's independent of its non descendants, conditional on its parents.",
            "By its non descendants, I mean here's a node.",
            "I mean This is why I say I don't like power point.",
            "I'd like to go to Blackboard and draw this.",
            "There's a node, and here's other nodes.",
            "Those are all its descendants and ascendants are everybody else.",
            "Your parents are actually your non descendants.",
            "Those both course are independent of your parents conditional on your parents.",
            "You know parents, often descendants, are part of what's called my complaint.",
            "Well, you're in your independent.",
            "Well, the reason you need to know them in the Markov blanket, because here's this.",
            "Node hears this node status later and they're both pointing to another node.",
            "If you give this Noda value, it renders these two dependent.",
            "That's why in the Markov blanket, you need those parents, but you're still if you just condition on the parents up here, you're independent of these of these parents of your children.",
            "If I can go draw on the blackboard here I can see I can't do that.",
            "So.",
            "If you're right about that baby in the Markov blanket, but that's not the same.",
            "The market blank is the set of all nodes that render a node independent of every other node in the network, right?",
            "And you need.",
            "Your children, and then you need your children's other parents.",
            "I'll get to that later.",
            "Actually, why knowledge of the child renders renders the two nodes independent."
        ],
        [
            "Actually, I'm coming to that later.",
            "This is the example I was actually made up during my during my second divorce.",
            "Alright, so it's.",
            "Cheating spouse would cause the spouse to dine with a stranger alright, which in turn would cause the spouse to be seen dining with a stranger.",
            "So this would be the causal graph amongst this, this is the causal chain.",
            "Right, the probability of cheating given that they're seeing is bigger than the probability of cheating.",
            "If I came in here and I told you that I had just seen your spouse dining with this good looking guy or good looking woman, you would suspect that they were cheating, right?",
            "Probably cheating goes up so they're not independent events.",
            "But if the dining event was already known to you, you had just before coming to this talk, seen it yourself.",
            "Then the fact that I reported to you is meaningless.",
            "Once you know this yourself, my report doesn't make it any more probable.",
            "The fact that I've seen it also is in material.",
            "So once you instantiate an intermediate variable, it renders these two independent, which again is the causal Markov assumption.",
            "As is independent of its NAND ascendancy conditional on its parent, D. So C&S are independent given D. And so that's a causal chain."
        ],
        [
            "These two are.",
            "Common cause and a causal chain are the ones that are easier to understand.",
            "This one is a little bit tricky.",
            "This is an old example made up by you to Pearl at UCLA.",
            "People that you didn't know how many people know him or somebody else did not.",
            "Alright, so the audience?",
            "He's probably the biggest name in this field of Bayesian network, so I'm just trying to get a feel for how familiar with Bayesian networks.",
            "Anyway.",
            "He was even UCLA where they have tremors all the time, right?",
            "He's noticed that that earthquakes make his burglar alarm go off, and of course hopefully a burglar is going to do that too.",
            "So we draw causal.",
            "Arc, you're also now we're not talking about 66 on the Richter scale, where there would be massive looting in an earthquake, so there's no causal link between burglars and earthquakes.",
            "My house is burglarized, is not going to cause an earthquake, and if there's a minor tremor, it's not going to make a burglar appear right.",
            "So these two events are independent.",
            "So the probability of B given Y equals the probability of Y, they're independent.",
            "Which is in fact the causal Markov assumption.",
            "B is independent of its non descendant E given its parents.",
            "If you have no parents, your parents are the empty set and that's just global independence, so there's nothing to condition on here.",
            "Memory for always wrote like C&D independent CNS independent given D. Well, there's nothing to condition at because these nodes have no parents.",
            "Alright, so that's.",
            "If two causes have a single effect, they are independent, and that then the causal Markov assumption says that they should be right.",
            "However.",
            "If your alarm goes off.",
            "All right, they're actually ordinarily rendered dependent.",
            "And this is what you were bringing up before.",
            "Once I know the value of this node, these become dependent.",
            "Once I know the alarm went off, there's probably burglarized finding out there's an earthquake lowers that probability.",
            "Now.",
            "Why should that be?",
            "I know when I've explained this to students, sometimes they say, well, how can the alarm going out to create a causal relationship between burglars and earthquakes?",
            "And it doesn't create a causal relationship that creates a statistical relationship probabilistic relationship.",
            "The way Perl originally told tells the example is like this, you have your your burglar alarm set up to go off in your office.",
            "It's about I think Mr Watson alright, so he's sitting.",
            "He's sitting in his office and his alarm goes off.",
            "Well, it says well, it's a good chance I've been burglarized so we got some this car and starts riding home on his way home.",
            "Here is on the radio that there's been an earthquake.",
            "This is all the earthquake makes my alarm go off.",
            "That explains away the alarm and therefore it is a good chance I haven't been burglarized.",
            "That psychologists call this discounting E discounts be.",
            "Now it's not.",
            "It doesn't create a causal relationship.",
            "If you're a frequentist, the guys only pay for you.",
            "Actually guys, people know what I mean about by frequentists.",
            "It's a classical statistician who believes in the relative frequency approach to probabilities, not abbasian.",
            "Right, so if you hear frequent is the best way to.",
            "Think about this is that.",
            "Of all those times, your alarm went off, will go off.",
            "The times that also include earthquakes will have less burglaries than the ones that do not include earthquakes.",
            "So it's a statistical relationship.",
            "When you instantiate the alarm, and if you think about it.",
            "Like I say from a perspective of that that example I gave you and think how you would react as a human like this, Mr Watson that you would discount the alarm."
        ],
        [
            "And once you knew that.",
            "At the earthquake happen this count the burglar I mean.",
            "But those are three classical examples.",
            "Guess that made him want to leave.",
            "Oh, just getting a better seat that makes you feel better.",
            "Here's a bigger example made out made up originally by Greg Cooper.",
            "He's.",
            "PC and computer science, then MD at the bio.",
            "Medical Informatics Department at University of Pittsburgh.",
            "So he does research you applying Bayesian networks in the medical domain.",
            "Here's an example.",
            "He made up an.",
            "I think these numbers were actually obtained from some data about the causal relationship between these five variables that smoking can cause bronchitis.",
            "Smoking can also cause lung cancer.",
            "Both of these conditions can cause fatigue and lung cancer can cause a chest X Ray to be positive.",
            "I've also shown the numbers here.",
            "That's how Bayesian networks are represented, yeah?",
            "Cooper at COPER persons Gregory.",
            "And it's in the Bio Medical Informatics program at the University of Pittsburgh.",
            "I have references at the end of this talk, and I believe there's a yeah, there's at least one paper 'cause that I reference.",
            "Alright, so.",
            "This is how Bayesian network is ordinarily represented with the prior probability of roots and the conditional probability of each node given values of its parents.",
            "Right, so the probability of B given H is .25.",
            "That means if you smoke, probably getting bronchitis is .25.",
            "If you don't smoke, it's only .05, which is reasonable, right?",
            "So smoking causes bronchitis.",
            "This should be bigger now since these lung cancer examples numbers are lot smaller than you would think, but I'm not quite sure when this means it means that weather in life you'll get lung cancer.",
            "I never look at this example that closer, whether it means 10 years after smoking, it says, Yep, that's one thing you have to do whenever you deal with statistics and Bayesian networks.",
            "Where you have to know what your variables actually represent.",
            "What is whole smoking mean doesn't mean smoking 2 packs a day for 10 years.",
            "So just saying smoking by itself is not really enough and that's all I'm saying here.",
            "For a simple example.",
            "Alright, then this is probably a fatigue given you have both these.",
            "Conditions it's the highest the poor guys got.",
            "Both bronchitis and lung cancer is more probable to be fatigued and the guy who's only got one or the other.",
            "Alright, so that's how the network is represented.",
            "My point here is actually to show something else.",
            "That the probability of bronchitis given lung cancer is bigger than the probability of bronchitis.",
            "Alright, once you have lung cancer, that's the argument I was making before right?",
            "Makes it more likely you'll smoke, which makes it more likely you'll have bronchitis.",
            "But once I instantiate the smoking, they become equal, so that's the same example I had before once I instantiate.",
            "The common cause that renders them independent.",
            "Now, even more than that, the probably bronchitis given positive chest X Ray is bigger than the probability of bronchitis.",
            "I was just a couple weeks ago.",
            "I was giving this talk.",
            "To my colleagues, one of whom is a needy position and she didn't.",
            "She told me doctors never really realized that an interactive she knows up.",
            "They don't realize that.",
            "A chest X Ray could be indicative of bronchitis.",
            "If a bronchitis can't cause a chest X Ray.",
            "They haven't been taught to reason like that in medical school, but the reason it is is because it makes lung cancer more probable now that it's more probably of lung cancer, it's more likely you'll smoke.",
            "You were smoker, which makes it more likely you'll have bronchitis.",
            "To see through this causal chain, here, these two are probabilistically dependent.",
            "However.",
            "Once I instantiate HI know the person smokes, they're rendered.",
            "Independent.",
            "That break the chain right here B is independent of LNX given its parent H. And that's the notation that B isn't.",
            "Try using this thing.",
            "To the dollar speakers at this talking is this thing is I've never used before.",
            "Alright, so that's a B is independent of LNX given H. B is independent of its non descendants, which arrellin X given its parent H. Notice is not independent of us.",
            "After that's decent, and it wouldn't be just 'cause I know the person smokes, you know."
        ],
        [
            "Fatigue still makes bronchitis more probable.",
            "Here's I'm switching to this thing is having to bend over to experimental evidence for the Markov condition.",
            "That same study right there study showed that he is independent of T given D. So there are experiments."
        ],
        [
            "It's based upon reasonable assumptions and experiments."
        ],
        [
            "We're out that that that it holds.",
            "Now, what are the exceptions to the causal Markov assumption?",
            "This is the most damaging one or the one that screws it up.",
            "The most of it that way hidden common causes.",
            "What if I only have 3 variables in the network running nose cold and sneezing, right?",
            "And what if there was some other cause of these two conditions?",
            "S would not be independent of our given C, because as still makes H more likely, which makes are more likely.",
            "Actually, there is another cause of I'm using H to denote hidden, but hayfever causes these two so if I don't articulate hay fever amongst my set of variables that cause a Markov.",
            "Assumption is screwed up.",
            "So if this was the case, SNR would not be independent.",
            "Given see, what's curious about this is a lot of researchers.",
            "Like to make the causal Markov assumption in practice.",
            "And ignore the fact that could be hidden common causes, and I don't think I can think of a domain in which it really makes sense.",
            "So what's the whole point of this talk?",
            "Well, in this first part of the talk I'm going, I'm going to assume there can be no hidden common causes, because that's the easy way to do things.",
            "And the second part, I'll relax that assumption, and that's when it makes this one.",
            "This theory to me has more value.",
            "Once you relax it."
        ],
        [
            "Alright, so that's the worst thing is that you have to assume no hidden common causes, and I'm not sure there's many domains you can really do that.",
            "Another thing is, causal feedback assumes a DAG, so you can't have things going in both directions.",
            "You know somebody.",
            "Studies certainly make him get good grades.",
            "And actually experience with my girl, my daughter who's in college.",
            "Now that you know which is getting good grades she start."
        ],
        [
            "Studying harder 'cause you know the reward.",
            "And it snowballed so you can't have that kind of situation going on.",
            "Selection bias.",
            "This is actually probably the hardest to understand.",
            "Finasteride is a medication that that.",
            "Merck pharmaceutical company Merck Manufacturers and and they originally used it for men who had BPH, but actually from passive data.",
            "They found that those guys were regrowing here and they started are using it as a medication for hair loss.",
            "Now, what if finasteride actually caused hypertension and this same colleague of mine is an MD told me that the reverse is true that finasteride actually lowers your blood pressure.",
            "But for my example you know just let me assume that right that it does make your blood pressure higher and what apprehension about hair loss also made people get high blood pressure guys losing his hair and gets upset about it needs is a blood pressure goes up again.",
            "I'm just making that up.",
            "Just 'cause I have a comprehensive example involving these things and I want to tie it all together.",
            "Alright, so assume that is the causal relationships among those variables, and suppose we obtained data an only FML.",
            "Now the words.",
            "We're only looking.",
            "We're not looking at hypertension.",
            "We're only looking at finasteride and hair loss.",
            "But somehow we.",
            "This is some kind of convenience sample and everyone in our sample suffers from hypertension.",
            "We go to some hospital and we're going toward where we're treating people for hypertension, and we get we get data on those people.",
            "So in other words, for everybody in our population this variable is, instantiate it too.",
            "Yes, person has hypertension.",
            "Well, if that was the case.",
            "Finasteride with discount hair loss.",
            "Just like I said before for.",
            "If we find out an individual uses finasteride, it makes it explains away the hypertension, making it less likely they'll lose their hair.",
            "So the people who use Fenesta ride would have less hair loss.",
            "So if selection bias is present, then I sample it can screw up the.",
            "You know the causal Markov assumption.",
            "That is not that common to happen, and that's not as nearly obviously as problematic as the hidden common cause thing.",
            "But it is something you have to be careful, love.",
            "This is just the last part.",
            "They are not independent in our observed distribution, although they are in the."
        ],
        [
            "Pendant amongst all people, they're not independent, and the probability distribution that we observe.",
            "The 4th one is is kind of a funny one in this.",
            "In this domain, there's always a population.",
            "My examples of the population has been humans, but if the population happens to be units of time from 1990 on, we just take each day alright.",
            "If we looked at that, let's look at the bottom 1 first.",
            "The Dow Jones average would be correlated with my hairline.",
            "'cause all during the 90s, the Dow Jones average went up and my hairline is going up at the same time yet, but nobody would ever think that the Dow Jones average had a causal effect on my hairline or vice versa.",
            "So the causal relationship between these two variables is there is none, but yet they were correlated.",
            "In the last few weeks, my hairline has not gone back down so that kind of indicates the causal relationship is not there actually."
        ],
        [
            "And I was up again that was down again on Friday, right?",
            "It's going like this now.",
            "Perhaps the condition that is most violated is that there can be no hidden common causes.",
            "Come back to this.",
            "Like I said, I don't."
        ],
        [
            "Assumption isn't all that reasonable an, but it's easier to develop a theory if we make it so that I'm going to start out making it.",
            "Yeah, so I need to go back.",
            "What's the difference between proposal feedback and discussion for relation honey honey problem works well if there's causal feedback, they would be correlated, right?",
            "But you couldn't apply this theory because this theory requires that it be a DAG.",
            "Those causation only goes in One Direction, so one is causation, one is correlation and a two different concepts.",
            "I think I better keep track of the time I realize.",
            "It's 238 already.",
            "This is going not going as quickly as I thought.",
            "Now here's something different.",
            "There is a conditional independency among these variables that is not entailed by the Markov condition.",
            "This is kind of a comprehensive example involving these variables fenesta ride.",
            "As I told you before, lowers DHT levels.",
            "That's actually how it.",
            "It cures baldness because DHT is the male hormone that makes your hair fall out.",
            "So if you lower your DHT levels.",
            "Actually, a lot of studies show that you do that around the age of 20.",
            "You won't lose your hair, not for sure, but again, it's very likely you will not now, as the study in log in at all showed DHT levels, though low, cause low DHT levels cause erectile dysfunction.",
            "So given this causal chain, you would think the use of finasteride would cause erectile dysfunction.",
            "So in Merck started.",
            "Offering this as a medication for baldness, they feared the side effect.",
            "Got a phone?",
            "My school, you'll be kicked out of the room for that.",
            "They actually my phones on two sides get kicked out to tickle.",
            "So what's going on here?",
            "Because who would want to take the medication then, right?",
            "If this happened well?",
            "Actually, in a in a very large controlled study.",
            "It was essentially found that ENF are independent.",
            "There's some very small evidence that they were slightly correlated.",
            "Now.",
            "Why would why would these two be independent when there's this causal chain?",
            "Well, that can happen.",
            "A causal and how it can happen is in this example.",
            "I think finasteride lowers your DHT levels, but it's not capable of lowering it below a certain level and all you need is that minimal level for erectile dysfunction.",
            "So let's say it can't lower it below 20 and 20 is all you need.",
            "So in other words it lowers it enough that you keep your hair.",
            "But that's it's not capable of lowering it so much that you have this problem.",
            "A similar example is typing ability.",
            "You take people and as people this is age.",
            "As people get older they get more experience, but their manual dexterity goes down South.",
            "HS has a causal relationship on manual dexterity, an on typing ability, an experience, I mean, and those two variables have an effect.",
            "Then your typing ability.",
            "So it's again I wish to Blackboard course last example top my head so you got this variable causing too like this and those two crossing another one at these two are independent because those two causes offset each other.",
            "The increased manual decrease in manual dexterity is offset by the increased experience and studies show.",
            "Once a person reaches a certain level of typing proficiency, they keep it all through their lives or until they become really old.",
            "So it's another case."
        ],
        [
            "Square where?",
            "There is not an effect that goes that that goes through a causal chain.",
            "Well, this kind of situation is not acceptable to learning causes.",
            "In order to learn causes, we can't have that situation.",
            "The causal faithfulness assumption assumes the observed distribution satisfies the Markov condition.",
            "And all conditional Independencies are entailed by the market condition.",
            "That's called the causal faithfulness assumption.",
            "In other words, it assumes that by looking at the data, you can know every conditional independency that's present in the distribution.",
            "We go back here.",
            "In other words, I would have been able to look at the causal DAG and know that ENF are independent conditional on D and I would have to know there are no other in dependencies.",
            "That's faithfulness is called faithfulness, called perfect perfection, because the perfect map, because everything you know about the probability distribution, not the numerical values besides Independencies, go can be read off the DAG.",
            "Alright, so that."
        ],
        [
            "Is the assumption we're going to start out making?",
            "We're going to assume there are not strange things.",
            "Going on and what are the exceptions to the causal faithfulness assumptions, will do all the exceptions to the Markov assumption.",
            "As all those ones I said before, plus you can't have these unusual causal relationships.",
            "So another problem with the theory is how can you ever be sure this unusual stuff isn't happening?",
            "I'll come back to that later again.",
            "This is statistics and statistics."
        ],
        [
            "Doesn't tell you something for sure.",
            "We can't know for sure that a causes B can just help us.",
            "So every model requires assumptions and assumptions always cause problems.",
            "But for now, let's let's learn causal influences, making their causal faithfulness assumption.",
            "So I'm going to assume that I'm assuming there's a causal dag out there."
        ],
        [
            "Attaining the observed variables and the probability distribution that I observe is faithful to it.",
            "And what can I learn if that's the case?",
            "Now first of all in what follows, I'm going to assume we have a large amount of data on the variables of interest.",
            "And we learned the conditional in dependencies from these data.",
            "There's two ways to actually learn.",
            "Causal networks are Bayesian networks in general, one is by learning the conditional Independencies first from the data, and then based on the independencies, learn the causal DAG.",
            "That's called the constraint based method, and the other way is to just score the DAG using the data.",
            "You don't learn in dependencies.",
            "If there's some way of creating a score and based programs like probably the data given the DAG is 1 simple score.",
            "The first way the constraint based method is much more intuitive, right?",
            "That's why that's the one I given an overview talk like this 'cause it's my."
        ],
        [
            "Easier for you.",
            "Get an intuition for why you can learn causes from data, whereas the scoring technique doesn't give you any intuition whatsoever.",
            "What do we mean exactly by this?",
            "From these data, we would learn that Y&X, probably why one given X 1X by y = 1 given X equal 2.",
            "See when X is 1.",
            "I'll go here.",
            "When X is 1.",
            "Why is 1/2 the time when X is 2?",
            "Why is 1/2 the time?",
            "I only showed eight data items ivyside want more data items than that, but I would learn that.",
            "In other words, I would learn that X&Y are independent.",
            "So the first thing you do is you take all the data and learn your conditional independencies."
        ],
        [
            "And then from the conditional independence ease, you learn the causal DAG.",
            "What's doing, I pressed the wrong thing.",
            "How much data do we need?",
            "Now in what files I'm going to assume that we know the Independencies right and, but the methods only as good as as the independence ease, and how much data do we need to rely abli learn anything I'll come back."
        ],
        [
            "This alright?",
            "But I'm going again.",
            "Assume for now that we learned the conditional independence ease for certain.",
            "I also get an example here.",
            "Suppose.",
            "V = X Y that means I settled observed variables or X&Y, and we learned their independent.",
            "Alright, so we're starting out with this knowledge that X&Y are independent.",
            "We can't have the causal dagenais or be we couldn't tell if we're making the causal faithfulness assumption X could not cause A and why I mean why could that cause X?",
            "Because if I apply the Markov condition for this DAG, I don't get that independency.",
            "I would have to get the why is independent of Axon for this tag?",
            "Why is independent of its non descendants conditional on X?",
            "So this DAG does not say why in X or independent neither does this one.",
            "Alright, so there's an independency that is not.",
            "Shown by the DAG which screws up faithfulness.",
            "So we must have the causal bag and see.",
            "That's kind of a no brainer, right?",
            "And then, if you have two variables and you find their independent, you assume they don't need another one causes each other and it doesn't even have to come to this talk to figure that out, right?",
            "But that's I'm starting out with the simplest example, right?",
            "Alright, suppose this is our setup, conditional independencies, and we have no independency.",
            "So in other words, they are dependent.",
            "So."
        ],
        [
            "When I say the set of conditional independencies is the empty set, I mean their dependent.",
            "We can't have the causal Dagenais.",
            "Because if I apply the Markov condition to that tag, it says X is independent of Y, right?",
            "And that independency is not observed?",
            "So if this were the causal DAG, then.",
            "Causal Markov assumption would not hold, and we're assuming it does hold.",
            "So we must have the causal Dragon B or in see that X causes Y or Y causes X.",
            "Now you may ask why?",
            "Why couldn't we have a hidden common cause?",
            "'cause I argued before hitting common cause would correlate them.",
            "Remember, right now I'm assuming that you don't have hidden common causes.",
            "So if I make that assumption which I can make if I want to write, then of course I can't conclude that there's a hidden Cam in Costco.",
            "They assume that there is no such thing.",
            "Alright, so that's another easy."
        ],
        [
            "Two, you have two variables.",
            "You find that there, not, that they are correlated.",
            "One causes the other.",
            "We don't know which one.",
            "All right, suppose we have three variables.",
            "Now, I'm going to slowly get things that are a little more interesting, and we know that X&Y are independent.",
            "So the only independent sees is that X&Y are independent.",
            "There can be no edge between X&Y owing to the reason I just gave an example one.",
            "If there were an edge from X&Y, the causal markup assumption would not say they are independent, right, because?",
            "But I gave an example one, so there can't be an edge here.",
            "There must be an edge between X&Z&Y&Z ohlinger.",
            "The reason given an example to once there is no edge between X&Y.",
            "If there's no edge between X&Z, then the Markov assumption would say X&Z are independent, and that's not one of our observed in dependencies.",
            "So the Markov assumption would be violated.",
            "So I can conclude that.",
            "We have to have these links.",
            "X is linked to ZZ is linked to Y.",
            "Pressing this thing instead of this thing.",
            "Alright, we cannot have the causal DAG and B or in C or D. I can't have any of these causal decks 'cause they all say.",
            "They all entail X&Y, are independent, given Z.",
            "Right, look at this one.",
            "It's why has to be independent of its non descendant X conditional and its parent ZX has to be independent of its non descendant Y conditionalize parents ZXSB independent of its non descendant.",
            "Why conditional on its parents?",
            "See all three of these tags say that and that conditional independency is not present.",
            "So.",
            "Markov assumption is not satisfied.",
            "There is even more here.",
            "The Markov condition does not entail for those tags.",
            "The Markov condition does not say X&Y is independent, so there's an independency which the Markov condition does not entail.",
            "Which violates the other half of the faithfulness part that you've got to be able to read off all the in dependencies that are there.",
            "So for all three of these tags have a conditional independency.",
            "I'm not observing all right and they don't have the one I am observing.",
            "So twice things get messed up.",
            "So we can conclude the only direction these arrows can have is this way.",
            "X&Y, both kozee.",
            "Yeah.",
            "Does he mean?",
            "A function that outputs dealer one or does it mean an event which is being used equals these are just random variables and they don't.",
            "They could be multinomial.",
            "They don't have to be binary, so they could be discreet, but it could be continuous.",
            "Also, there's also structural equation modeling.",
            "You can have visas.",
            "Newest variables.",
            "Let's post that Boolean variable.",
            "An IV's equals 0.",
            "X&Y are independent.",
            "But as equals one then X imply idependent.",
            "Well then they would still be.",
            "In the.",
            "When this when I say X&Y are independent conditional NZ and ask to be independent conditional on any value of Z.",
            "So if they are in.",
            "Independent conditional on one value and not the other.",
            "Then they're not independent.",
            "Conditional NZ, What you're saying is that bad condition on CS first value?",
            "Probably, if X Givens equals one and y = 1 equals probably of X given.",
            "Givens equals one y = 0, right?",
            "Customers with.",
            "Laugh with equals 0 = 1 and say this is the first one which makes.",
            "FY.",
            "Weather for sequels.",
            "No, you don't need that because these are just random variables, right?",
            "And then the theory says they have to be independent conditional on every value, and if they're not independent, conditional on every value, then there.",
            "You don't call it a conditional independency.",
            "I guess the way I've been stating these examples, I haven't made that clear.",
            "I've always just conditioned on one value right in those examples.",
            "So in other words.",
            "If sneezing and running nose.",
            "Are independent.",
            "Have to be independent given that the person has a cold and they also have to be independent.",
            "Given the person does not have a cold.",
            "We're assuming both hold.",
            "If one does not hold, then we don't call it a conditional independency.",
            "Is that your question?",
            "I need the blackboard again.",
            "Alright, so this would be the causal bag.",
            "Now absolutely happened here.",
            "I didn't mean to do that.",
            "Sorry I'm not good at PowerPoint.",
            "I again I meant to press this when I press that one that time.",
            "Like Gerald Ford, the Lyndon Johnson, so he can't walk and chew gum simultaneously.",
            "I can't.",
            "Get me on this thing."
        ],
        [
            "Alright, so we have to have X&Y causing, see that's the only thing we can conclude.",
            "If I can go on from here.",
            "Alright, suppose we have three variables, again, an now, X&Y are independent.",
            "Given ZI won't be labor this, but we end up with these links.",
            "Again, it's very similar to the arguments I already gave that there has to be an edge between X&Z and it cannot be one between X&Y.",
            "So we must have links in a like I just said we can't have the causal bag and B, which is when I just deduced before.",
            "The Markov condition applied to that tag and tails that X&Y are independent, right?",
            "And then in dependencies not observed.",
            "So the causal Markov assumption would not be satisfied.",
            "Furthermore, the Markov condition does not entail the conditional independency that I do observe.",
            "So the faithfulness part isn't there either.",
            "It's called an IMAP by the way, and this is not an IMAP at all.",
            "It's gotten independency that I'm not observing and doesn't have one.",
            "I am observing.",
            "It can't be with the faithfulness assumption.",
            "So we must have the causal day.",
            "I can see, or indeed or any.",
            "Now you can't distinguish them.",
            "These dogs are called Markov equivalent because they all three have the exact same conditional independencies, that Y is independent of X conditional NZ, so there's no way you could distinguish them.",
            "So making the faithfulness assumption with this information, you can't really know any causes, but you can know."
        ],
        [
            "They go this way this way or like this.",
            "Now here's a theorem which I'm just going to state and hopefully have the intuition for now.",
            "If the faithfulness condition is satisfied, then there's an edge between two variables if and only if they're not conditionally independent given any set of variables.",
            "In other words, either there's an edge between X&Y, or there is some set of variables that renders them independent.",
            "It could be the empty set.",
            "And that.",
            "Intuitively, that makes sense, right?",
            "If either X&Y have no edge?",
            "They are either there or are my trying to say either there's an edge."
        ],
        [
            "Between them, or they're independent, or there's some variables that render them independent.",
            "That's what this is really saying.",
            "Maybe the example make it easier to see.",
            "Suppose we observe four variables now, and these are conditional independencies.",
            "X&Y are independent.",
            "But W is independent of both of them, conditional on Z.",
            "This notation means W is independent of X.",
            "Conditional NZ WS independent of Y.",
            "Conditional NZ and WS Independent of X&Y taking values.",
            "Simultaneously conditional NZ.",
            "Alright, so let's say we observe that.",
            "Due to the previous theorem, the links must be those in a.",
            "Let me show you what I'm talking about here I I was saying that the Korean theorem there's got to be an edge between 2:00.",
            "Variables if and only if there's no variables that render them independent, so there's an edge between X&Z because you don't see any variable blocking the relationship between them.",
            "There's no X between X&Y because they're independent.",
            "Right here, independent conditional on the empty set.",
            "There's no edge between X&W because X is independent of W conditional on ZZ blocks.",
            "Through relationships, that's what the theorem is saying.",
            "You have an edge if and only if there's no other variable that blocks the causal relationship between them.",
            "And then Z&W have have have no variables blocking the class or relationship between them.",
            "So from these conditional independencies and that theorem I can conclude.",
            "These links.",
            "We must have the arrow directions and B because X&Y are independent.",
            "This is similar to the example I had before.",
            "If I made these arrows go this way, go this way, or both go up, they would all say X&Y are independent given Z, right, and that's not what it says it says.",
            "They're independent.",
            "It's similar to the example we had before where I directed where three variables and I directed the edges this way.",
            "Now, this is what this is where the theory becomes fun.",
            "Therefore we have to have the arrow directions in C because we do not have WX independent.",
            "See if I took this arrow and and made it go this way.",
            "Then the markup assumption would say X&W are independent.",
            "It would not say that X&W are independent given Z.",
            "Same thing for why?",
            "And the observed independency is not that X&W are independent, it's that they are independent given Z.",
            "So once these two edges are directed this way, this one's gotta go that way.",
            "And that says the correct independency.",
            "It says W is independent of X given its parent Z, which is what this says W is independent of X given Z.",
            "So once I learn these directions, I can learn another direction and think about this applied along linked list of variables Now with similar independencies.",
            "I could go all the way down to Dag.",
            "Learning causation, so if you have a."
        ],
        [
            "A lot of variables you can.",
            "You can learn a lot from.",
            "You start at the beginning and just go down.",
            "The dev learning causes.",
            "Actually, I'm on time, if you give me just one more minute, I'll finish what I want to do before the break.",
            "How much data do we need?",
            "In the limit with probability one, we will learn the correct tag that sefarim originally proven by.",
            "Howton in 1988 for curved exponential family of.",
            "Models and a guy named Geiger proved that Bayesian networks are such a family, so we will know will learn the correct tag in the limit.",
            "But we don't have an infinite amount of data.",
            "In 2006, is that you a 2006 they obtained bounds on the number of records needed to be confident we will not learn a particular wrong tag?",
            "Well, that's all.",
            "That's an interesting result.",
            "Mathematically, it's not really very useful.",
            "It assumes we know the correct bag.",
            "We know it's wrong bag.",
            "How many data items do we need to have a high probability?",
            "We won't learn that bag?",
            "Well, that really doesn't help you too much, because in order to know how many data items to know, you need not to learn a wrong dad, then you need to take all possible combinations and take the maximum and super exponential number of tags.",
            "So although it's an interesting result, it's not really useful for knowing how much data we need.",
            "As I say, as far as I know, because I you know you always have to say as far as you know, right?",
            "Because somebody."
        ],
        [
            "That's something you don't know about.",
            "There are no bounds and number of records needed to be confident we're not wearing any wrong tag.",
            "So to learn how much data we need, we need studies and there haven't been that many studies.",
            "I just sent the one is giving this talk in an email out to the UI Listserver and seems like there hasn't been too much more done recently.",
            "This group in 1997 showed that it was looking at connected graphs that showed that it learned the.",
            "There are two nodes that learned the correct tags in as few as ten data items, and as you increase number of datums, it stayed with the correct tag in their examples.",
            "With three they needed 200.",
            "With four they use different ones and then it was somewhere between 1000 and 5005 thousand 2000.",
            "Why is this number bigger than this?",
            "The one that required 5000 had an undirected cycle and somehow that must be harder to learn.",
            "So.",
            "This gives you some feel for how many data items you need.",
            "You got four or five.",
            "Variables and it seems like from the study you need a few 1000.",
            "Stronger."
        ],
        [
            "Of course are easier to learn if we if we have a deterministic relationship.",
            "It's easier to learn that if we have a very weak dependency.",
            "There's there are some conflicting empirical results.",
            "Cooper and herskovits.",
            "This topic is 1992 correctly learned.",
            "A 37 node not this is Cooper by the way.",
            "This is you were asking about him.",
            "You know the relative his are you actually look a little like him like like his younger brothers.",
            "Maybe it's a long lost brother.",
            "That's why you want to know.",
            "Correctly learn a 37 known network from 3008 items which were generated using the network and how they started with the network.",
            "Generated 3000 data items and it correctly.",
            "I think you'll learn everything said one edge correctly.",
            "That's looks good, right?",
            "But Myself and I did study with the psychologist colleague of mine.",
            "We obtained very goofy results when we tried learning an 8 node network and we had 9648 items.",
            "We weren't doing a simulation.",
            "We didn't start out with the network, generate data if we wanted it back.",
            "We were really trying to learn something.",
            "He was trying to learn what variables had an influence on an racial harassment in the military.",
            "And.",
            "What we learned was that whether individual held the military responsible for a racial incident has a causal effect on the individual's race.",
            "In other words, let's say I'm not happy with my current race.",
            "I could join the military, have a racial incident, hold the military responsible, and possibly change my race.",
            "Now, that obviously that's goofy, right and.",
            "And if I didn't know the variables though, right?",
            "If I didn't know that these variables represented, I would say quite a lot of data and other people with a lot of data.",
            "Learn learn 3000 items and I've got 9000.",
            "So I would conclude that X causes Y.",
            "But I can't conclude that because it's it goes against anything sensible.",
            "So.",
            "I'm going to end the first half of the talk here, but I want to leave you with the idea that this is just statistics and my brother will come back to this example in the second half and explain why I think this happened.",
            "It happened over example retail it.",
            "This is just statistics and it looks like it can help guide our beliefs, but can't.",
            "It's like magical P value, right?",
            "It's for P values greater than .05.",
            "Some people believe it for sure, but that's just.",
            "An arbitrary cut off point.",
            "All it can do is guide your beliefs.",
            "If it's .051, you still have some reasonable belief that it's true, so it's very similar to that that nothing is definite.",
            "Alright, after the break I'll relax this assumption of no hidden common causes.",
            "Like I said I would do."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Side and so maybe I probably be out there myself if I hadn't committed to giving this talk.",
                    "label": 0
                },
                {
                    "sent": "He told me you told me that it's always like this here.",
                    "label": 0
                },
                {
                    "sent": "They have most of you heard of Dan Kahneman.",
                    "label": 0
                },
                {
                    "sent": "He did all the studies with famous diverse keyon, indicating that people don't reason normatively.",
                    "label": 0
                },
                {
                    "sent": "He won the Nobel Prize in 2002 for Prospect theory.",
                    "label": 0
                },
                {
                    "sent": "Anyway, I heard him give a talk few years ago, and the title of the talk.",
                    "label": 0
                },
                {
                    "sent": "Are people really happy you're in California because of the weather, and now they see the weather here.",
                    "label": 0
                },
                {
                    "sent": "I think it might be true.",
                    "label": 0
                },
                {
                    "sent": "This is great weather.",
                    "label": 0
                },
                {
                    "sent": "The talk was.",
                    "label": 0
                },
                {
                    "sent": "Was very similar to the stuff he did on whether people reason rationally wanted to know if.",
                    "label": 0
                },
                {
                    "sent": "If people's report of happiness was the consistent with their actual experience of happiness, and of course he found that wasn't the case, for instance.",
                    "label": 0
                },
                {
                    "sent": "His research showed that divorced women tended to actually be happier than married women, even though they reported they were not as happy.",
                    "label": 0
                },
                {
                    "sent": "So you guys could come to hear about condoms research.",
                    "label": 0
                },
                {
                    "sent": "Obviously I'm stalling because I hate giving power point presentations.",
                    "label": 0
                },
                {
                    "sent": "This is only my second one.",
                    "label": 0
                },
                {
                    "sent": "First, one bombed miserable, even though I had a lot of animation and voice and everything.",
                    "label": 0
                },
                {
                    "sent": "It's just I don't like the medium.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See how it goes.",
                    "label": 0
                },
                {
                    "sent": "Here is the talk.",
                    "label": 0
                },
                {
                    "sent": "It's called statistical causality, and that's me, and that's my website.",
                    "label": 0
                },
                {
                    "sent": "I'm going to be talking about notion of causality, and it's the notion that's developed in these texts and other places too.",
                    "label": 0
                },
                {
                    "sent": "I just, you know, wrote down some places that I knew about.",
                    "label": 0
                },
                {
                    "sent": "And it concerns variables influencing other variables.",
                    "label": 1
                },
                {
                    "sent": "For instance, the smoking caused lung cancer.",
                    "label": 0
                },
                {
                    "sent": "So what do we mean by variables influencing other variables?",
                    "label": 0
                },
                {
                    "sent": "You have some population.",
                    "label": 0
                },
                {
                    "sent": "In this case people, and there's a random variable in the population smoking.",
                    "label": 0
                },
                {
                    "sent": "There's another random variable, lung cancer.",
                    "label": 0
                },
                {
                    "sent": "The more the people tend to smoke, does that indicate the more they get?",
                    "label": 0
                },
                {
                    "sent": "Lung cancer alright, so there's the value of 1 variable have a probabilistic effect on the value of another?",
                    "label": 0
                },
                {
                    "sent": "Alright, that's that's the kind of causality.",
                    "label": 0
                },
                {
                    "sent": "So the probability of lung cancer given that somebody.",
                    "label": 0
                },
                {
                    "sent": "Smokes when you manipulate them to smoke greater than the probability that they do not.",
                    "label": 1
                },
                {
                    "sent": "It does not concern token causality, which has to do with one time events where you have no population.",
                    "label": 0
                },
                {
                    "sent": "A classic example is that the goal for running into my golf ball cause it to go in the hole and that we don't have any population here.",
                    "label": 1
                },
                {
                    "sent": "It's one golfing and you know, like balls going this way go for runs into it and it goes in the hole then I'm.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, but what is that?",
                    "label": 0
                },
                {
                    "sent": "Is that a causal event?",
                    "label": 0
                },
                {
                    "sent": "It's called token causality, and that's not what I'm discussing.",
                    "label": 0
                },
                {
                    "sent": "I'm discussing the first type.",
                    "label": 0
                },
                {
                    "sent": "Alright, here's what here's what I was talking about a minute ago about what kind of causality this is, and it formalizes it.",
                    "label": 0
                },
                {
                    "sent": "It's a common way to at least learn causality, even if we don't define it this way of manipulation experiment, drug manufacturers do this all the time you take.",
                    "label": 1
                },
                {
                    "sent": "A set of people you put half of them in one group and half in the other.",
                    "label": 0
                },
                {
                    "sent": "That's the manipulation.",
                    "label": 0
                },
                {
                    "sent": "In other words, the probability of being manipulated to be in one group is .5.",
                    "label": 0
                },
                {
                    "sent": "The probability of being manipulated to be in the other group is .5.",
                    "label": 0
                },
                {
                    "sent": "So you've got these people broken up into two groups.",
                    "label": 0
                },
                {
                    "sent": "Everybody in Group one, you make smoke the probability of smoking giving you in Group one is 1.",
                    "label": 0
                },
                {
                    "sent": "Everybody here knows this notation conditional probability.",
                    "label": 0
                },
                {
                    "sent": "It's the probability of this event given that this one takes this value alright, and probably smoking not smoking, that's what the two stands for in this example.",
                    "label": 0
                },
                {
                    "sent": "Given your group on is 0, so everyone in Group One smokes everyone in Group Two was not smoke.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "If smoking causes lung cancer Group One would have a higher incidence of lung cancer than Group 2, and the more that's true, the greater the extent to which Group One has an incidence of lung cancer.",
                    "label": 1
                },
                {
                    "sent": "The more we believe smoking causes lung cancer.",
                    "label": 0
                },
                {
                    "sent": "So that's how we classically learn causation.",
                    "label": 0
                },
                {
                    "sent": "And that's how drug companies do.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do it all the time.",
                    "label": 0
                },
                {
                    "sent": "They want to see if a drug is a causative effect on some cure, and they do a manipulation experiment.",
                    "label": 0
                },
                {
                    "sent": "I know it here.",
                    "label": 0
                },
                {
                    "sent": "We don't really want to manipulate people and make them smoke.",
                    "label": 1
                },
                {
                    "sent": "I mean, there's there's certain kinds of experiments you really don't want to do.",
                    "label": 0
                },
                {
                    "sent": "I mean, especially in this country, we're trying to eliminate smoking, almost drugs.",
                    "label": 0
                },
                {
                    "sent": "You can at least know annoy you, can't smoke anywhere starting January 1st.",
                    "label": 0
                },
                {
                    "sent": "Virtually nowhere.",
                    "label": 0
                },
                {
                    "sent": "Alright, so can we learn something about causal influences from passive data?",
                    "label": 1
                },
                {
                    "sent": "Some people have other words for this.",
                    "label": 0
                },
                {
                    "sent": "I call it passive data, it means.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Data you just mind the data that you don't purposely create in any way.",
                    "label": 0
                },
                {
                    "sent": "Now let's look at the smoking example again.",
                    "label": 0
                },
                {
                    "sent": "From passive data, we've learned that smoking and lung cancer are correlated, right?",
                    "label": 1
                },
                {
                    "sent": "And that's this arrow here or this line here means correlation.",
                    "label": 0
                },
                {
                    "sent": "Now that could be due to smoking causing lung cancer, right?",
                    "label": 1
                },
                {
                    "sent": "Certainly smoking causes lung cancer like I just said they would be correlated.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So from this passive data, do I want to conclude that smoking causes lung cancer well?",
                    "label": 1
                },
                {
                    "sent": "As smoking and lung cancer are correlated, it could be the reverse.",
                    "label": 1
                },
                {
                    "sent": "People who get lung cancer could tend to pick up smoking, you know, because of the domain.",
                    "label": 0
                },
                {
                    "sent": "That seems silly, right?",
                    "label": 0
                },
                {
                    "sent": "About if this was just X&Y, would it seems so silly?",
                    "label": 0
                },
                {
                    "sent": "I do know of 1 case X is actually a friend of mine, a woman who.",
                    "label": 0
                },
                {
                    "sent": "Had lung cancer and quit smoking, but then she found out she was terminal and she said I may as well go out smoking and so in her case that she really had no advanced lung cancer.",
                    "label": 0
                },
                {
                    "sent": "She started smoking.",
                    "label": 0
                },
                {
                    "sent": "So in that case it can actually cause it that this is more of a token event almost though.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But the point is that this just said X&Y from the correlation alone.",
                    "label": 0
                },
                {
                    "sent": "Smoking can cause lung cancer, lung cancer, plus smoking we don't know.",
                    "label": 1
                },
                {
                    "sent": "And the other common explanation is they could have a hidden common cause.",
                    "label": 0
                },
                {
                    "sent": "Other the understanding of why this would correlate smoking and lung cancer is essential to understanding this.",
                    "label": 0
                },
                {
                    "sent": "Talk that if if two events have a hidden common cause, they tend to be correlated.",
                    "label": 0
                },
                {
                    "sent": "Why is that?",
                    "label": 0
                },
                {
                    "sent": "Because if you smoke, it makes it more probable you have whatever this causes, which makes it more probable.",
                    "label": 0
                },
                {
                    "sent": "You would also have lung cancer, so they're like they're correlated through this through this chain.",
                    "label": 0
                },
                {
                    "sent": "The explanation would be this, perhaps some genetic defects and mutations, right?",
                    "label": 0
                },
                {
                    "sent": "That would make you crave nicotine and also make you get lung cancer.",
                    "label": 0
                },
                {
                    "sent": "I actually think at one time the.",
                    "label": 0
                },
                {
                    "sent": "The cigarette manufacturers were arguing this point.",
                    "label": 0
                },
                {
                    "sent": "I remember seeing that somewhere, but again, if this was just X&Y.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Read explanations as good as the others.",
                    "label": 0
                },
                {
                    "sent": "They all would make smoking and lung cancer correlated.",
                    "label": 0
                },
                {
                    "sent": "So it seems like you can't learn causal influences from correlation from passive data.",
                    "label": 0
                },
                {
                    "sent": "But the problem here is that we only have data on two variables.",
                    "label": 1
                },
                {
                    "sent": "All right, well research in the 90s have shown that we can learn something about causal influences.",
                    "label": 0
                },
                {
                    "sent": "If we have data on at least four variables, that might seem odd.",
                    "label": 1
                },
                {
                    "sent": "Why would having data on other variables that other than smoking and lung cancer enable you to conclude that smoking causes lung cancer?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that is actually the purpose of this talk.",
                    "label": 0
                },
                {
                    "sent": "All right?",
                    "label": 0
                },
                {
                    "sent": "Well why that is the case?",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "If you have more data, you can learn something.",
                    "label": 0
                },
                {
                    "sent": "At first I need to define a causal graph.",
                    "label": 1
                },
                {
                    "sent": "In general, when I have something written like this, I'm not going to say it.",
                    "label": 0
                },
                {
                    "sent": "But like I said, I don't really like PowerPoint presentations and there's no point in me saying what you can read or even necessary leaving it up here long enough for you to read it.",
                    "label": 0
                },
                {
                    "sent": "What I want to do is go over examples more and you can come back to these definitions later and.",
                    "label": 0
                },
                {
                    "sent": "And look at them.",
                    "label": 0
                },
                {
                    "sent": "So in general I'm not going to be reading these things.",
                    "label": 0
                },
                {
                    "sent": "Here's here's what we mean by a direct cause.",
                    "label": 0
                },
                {
                    "sent": "This is a study in rats done by luck at all in 1995.",
                    "label": 1
                },
                {
                    "sent": "They manipulated testosterone levels.",
                    "label": 0
                },
                {
                    "sent": "And found that there had a causal effect on DHT levels dehydro testosterone.",
                    "label": 0
                },
                {
                    "sent": "They also found when they manipulated testosterone levels, they found that it had a causal effect on erectile function, so testosterone causes DHT levels and they found it also causes erectile function.",
                    "label": 0
                },
                {
                    "sent": "They manipulated DHT itself.",
                    "label": 0
                },
                {
                    "sent": "Alright, while holding testosterone fixed and found that it had an effect on erectile function, so there's an arrow here.",
                    "label": 0
                },
                {
                    "sent": "Now, why didn't I draw an arrow from T to E?",
                    "label": 0
                },
                {
                    "sent": "Why is that arrow missing, or because when they held DHT fixed that at a given level, if they if they held it low, it didn't matter whether testosterone was lower high.",
                    "label": 0
                },
                {
                    "sent": "You had this level of erectile function was the same and when they fixed it high the same thing.",
                    "label": 0
                },
                {
                    "sent": "It didn't matter whether the testosterone levels the erectile function levels were the same.",
                    "label": 0
                },
                {
                    "sent": "Alright, so T is not a direct cause of E. That's why did natural an edge here by a direct cause.",
                    "label": 1
                },
                {
                    "sent": "We mean there's no variable amongst your observed variables that mediates the causal effect.",
                    "label": 0
                },
                {
                    "sent": "Now what if DHT wasn't one of our observed variables?",
                    "label": 0
                },
                {
                    "sent": "Well, then there would be an arrow directly here, so whether something is the direct cause or not is dependent upon what variables you actually observing.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can argue philosophically that there's always some intermediate variables, and things are just.",
                    "label": 0
                },
                {
                    "sent": "You know, unfolding in some certain way and we only as humans articulate certain variables that we observe.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's what we mean by that.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Direct cause and a causal graph is a graph containing.",
                    "label": 0
                },
                {
                    "sent": "Variables and edges that are direct causes.",
                    "label": 0
                },
                {
                    "sent": "Now, here's another thing.",
                    "label": 0
                },
                {
                    "sent": "I hate to just say it right because he's saying it isn't going to.",
                    "label": 0
                },
                {
                    "sent": "By the way, how much is the curiosity?",
                    "label": 0
                },
                {
                    "sent": "How many people know the causal Markov assumption?",
                    "label": 0
                },
                {
                    "sent": "And I want to get a feel for my audience.",
                    "label": 0
                },
                {
                    "sent": "So the majority of you are not really familiar with causal networks or Bayesian networks, right?",
                    "label": 0
                },
                {
                    "sent": "You're not right.",
                    "label": 0
                },
                {
                    "sent": "So I've been to me there are like.",
                    "label": 0
                },
                {
                    "sent": "Well, a causal network is a special kind of Bayesian network.",
                    "label": 0
                },
                {
                    "sent": "It's one where the arcs represent causal influences.",
                    "label": 0
                },
                {
                    "sent": "Cowsill is just something physical network.",
                    "label": 0
                },
                {
                    "sent": "Yeah Beijing that were just represents conditional independence ease and you don't necessarily give them causal meaning.",
                    "label": 0
                },
                {
                    "sent": "But then a certain kind of Beijing network is a causal network.",
                    "label": 0
                },
                {
                    "sent": "In other words, it's a subset of all Bayesian networks where the edges do represent causes, but.",
                    "label": 0
                },
                {
                    "sent": "Hunt people who know Bayesian networks work.",
                    "label": 0
                },
                {
                    "sent": "She also know color networks.",
                    "label": 0
                },
                {
                    "sent": "It seems that most people don't know either in this audience, so I better this is important to get this causal Markov assumption straight.",
                    "label": 0
                },
                {
                    "sent": "And again, I'm not going to read it.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to do is show it by examples.",
                    "label": 0
                },
                {
                    "sent": "Alright, let's go down to the bottom things.",
                    "label": 0
                },
                {
                    "sent": "It says the probability distribution satisfies the Markov condition.",
                    "label": 1
                },
                {
                    "sent": "If the probability of each variable is independent of its non descendants conditional on its parents.",
                    "label": 1
                },
                {
                    "sent": "And then if we assume that the causal graph containing the variables satisfies that assumption, we make the causal Markov assumption.",
                    "label": 0
                },
                {
                    "sent": "Now what I want to do is show some simple examples, causal little causal networks to show why.",
                    "label": 0
                },
                {
                    "sent": "First of all, by going through this example.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Give you intuition as to why it's reasonable to make this assumption, and second of all.",
                    "label": 0
                },
                {
                    "sent": "Hopefully it'll make you understand what the assumption is.",
                    "label": 0
                },
                {
                    "sent": "In these examples I use a capital letter to denote both of binary variable and one and it's one of its values.",
                    "label": 1
                },
                {
                    "sent": "For simplicity, let's look at this simple example.",
                    "label": 0
                },
                {
                    "sent": "Colds cause sneezing and they cause runny noses.",
                    "label": 0
                },
                {
                    "sent": "Alright, so I and sneezing does not cause a runny nose and runny nose does not cause sneezing.",
                    "label": 0
                },
                {
                    "sent": "So this is the causal graph causal DAG for these variables are also my only observed variables.",
                    "label": 0
                },
                {
                    "sent": "Now the probability of sneezing.",
                    "label": 0
                },
                {
                    "sent": "This is where I'm using S docile stand for a value.",
                    "label": 0
                },
                {
                    "sent": "It means that person is sneezing, the probably of sneezing.",
                    "label": 0
                },
                {
                    "sent": "Given you have a runny nose is greater than the probability of sneezing, that's based upon the argument I was giving before.",
                    "label": 0
                },
                {
                    "sent": "If you have a runny nose, makes it more likely you have a cold, which makes it more likely have another symptom of of the coal.",
                    "label": 0
                },
                {
                    "sent": "Alright, so they are not independent this notation here.",
                    "label": 0
                },
                {
                    "sent": "It's an at symbol means not independent S&R, so this notation I'll be using.",
                    "label": 0
                },
                {
                    "sent": "But but if I condition on a cold.",
                    "label": 0
                },
                {
                    "sent": "In other words, I give this.",
                    "label": 0
                },
                {
                    "sent": "I know the value of this variable.",
                    "label": 0
                },
                {
                    "sent": "I know for this particular individual that she or he has a cold.",
                    "label": 0
                },
                {
                    "sent": "All right, then there's a fixed probability of the person sneezing.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's 70% of people with colds.",
                    "label": 0
                },
                {
                    "sent": "Sneeze.",
                    "label": 0
                },
                {
                    "sent": "There's a fixed probability of the person has a runny nose, maybe that's 80%.",
                    "label": 0
                },
                {
                    "sent": "These this value no longer makes this one more probable.",
                    "label": 0
                },
                {
                    "sent": "The probability of sneezing.",
                    "label": 0
                },
                {
                    "sent": "This means conditional on two values, practices published sneezing.",
                    "label": 0
                },
                {
                    "sent": "Given you have a cold right, this is probably a sneezing, given you have a runny nose and a cold.",
                    "label": 0
                },
                {
                    "sent": "And I'm saying that our intuition tells us they should be equal.",
                    "label": 0
                },
                {
                    "sent": "Because the only thing that made them connected probabilistically was because runny nose made a cold more probable, but it can't do that anymore.",
                    "label": 0
                },
                {
                    "sent": "'cause we know the person has a cold.",
                    "label": 0
                },
                {
                    "sent": "So finding out I have a cold is useless information spreads.",
                    "label": 0
                },
                {
                    "sent": "Probably sneezing because you already have this probability of what's like .7 there sneezing.",
                    "label": 0
                },
                {
                    "sent": "So my argument is that sneezing and runny noses are independent, conditional and cold.",
                    "label": 0
                },
                {
                    "sent": "Here is the notation, sneezing and runny nose dependent conditional on cold.",
                    "label": 0
                },
                {
                    "sent": "And that the causal Markov assumption is that a node is independent of its non descendants conditional on its parents and more people are showing up.",
                    "label": 0
                },
                {
                    "sent": "People are taking.",
                    "label": 0
                },
                {
                    "sent": "Long lunch, and that's exactly what this says.",
                    "label": 0
                },
                {
                    "sent": "Sneezing would be independent of its non descendant.",
                    "label": 0
                },
                {
                    "sent": "Your descendants are all the all the ones you're pointing to hear, right?",
                    "label": 0
                },
                {
                    "sent": "He's pointing to nobody, so sneezing is independent of running nose conditional on its parent cold and that's what the causal Markov assumption says.",
                    "label": 0
                },
                {
                    "sent": "And so I'm illustrating with a simple example that it's a reasonable assumption.",
                    "label": 0
                },
                {
                    "sent": "Went for a common cause.",
                    "label": 0
                },
                {
                    "sent": "I forgot you guys ask questions at the end or keep trying to say they have any questions before I go on or but how do these talks code I give the whole talk and then questions.",
                    "label": 0
                },
                {
                    "sent": "Nobody knows, right?",
                    "label": 0
                },
                {
                    "sent": "It's up to me.",
                    "label": 0
                },
                {
                    "sent": "Well, if you have a question, feel free to interrupt me.",
                    "label": 0
                },
                {
                    "sent": "Alright, it's like.",
                    "label": 0
                },
                {
                    "sent": "Well, because it's the same mark off like a Markov chain.",
                    "label": 0
                },
                {
                    "sent": "It's the no forgetting right?",
                    "label": 0
                },
                {
                    "sent": "It's forgetting me not know.",
                    "label": 0
                },
                {
                    "sent": "Forgetting it means once this guy renders this guy, you forgot this guys value.",
                    "label": 0
                },
                {
                    "sent": "Once you know this guy's value.",
                    "label": 0
                },
                {
                    "sent": "I use the word guides.",
                    "label": 0
                },
                {
                    "sent": "It's kind of like.",
                    "label": 0
                },
                {
                    "sent": "And away called variables guys.",
                    "label": 0
                },
                {
                    "sent": "But you see that why Markov is used because of the fact that this value is forgotten once this value is known.",
                    "label": 0
                },
                {
                    "sent": "So if somebody with Markov chain.",
                    "label": 0
                },
                {
                    "sent": "It's not similar, but it's the same notion.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Before this one, you said that this one.",
                    "label": 0
                },
                {
                    "sent": "Details or number sentence, but actually it is dependent on the Castle.",
                    "label": 0
                },
                {
                    "sent": "It's independent of its non descendants, conditional on its parents.",
                    "label": 0
                },
                {
                    "sent": "By its non descendants, I mean here's a node.",
                    "label": 0
                },
                {
                    "sent": "I mean This is why I say I don't like power point.",
                    "label": 0
                },
                {
                    "sent": "I'd like to go to Blackboard and draw this.",
                    "label": 0
                },
                {
                    "sent": "There's a node, and here's other nodes.",
                    "label": 0
                },
                {
                    "sent": "Those are all its descendants and ascendants are everybody else.",
                    "label": 0
                },
                {
                    "sent": "Your parents are actually your non descendants.",
                    "label": 0
                },
                {
                    "sent": "Those both course are independent of your parents conditional on your parents.",
                    "label": 0
                },
                {
                    "sent": "You know parents, often descendants, are part of what's called my complaint.",
                    "label": 0
                },
                {
                    "sent": "Well, you're in your independent.",
                    "label": 0
                },
                {
                    "sent": "Well, the reason you need to know them in the Markov blanket, because here's this.",
                    "label": 0
                },
                {
                    "sent": "Node hears this node status later and they're both pointing to another node.",
                    "label": 0
                },
                {
                    "sent": "If you give this Noda value, it renders these two dependent.",
                    "label": 0
                },
                {
                    "sent": "That's why in the Markov blanket, you need those parents, but you're still if you just condition on the parents up here, you're independent of these of these parents of your children.",
                    "label": 0
                },
                {
                    "sent": "If I can go draw on the blackboard here I can see I can't do that.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If you're right about that baby in the Markov blanket, but that's not the same.",
                    "label": 0
                },
                {
                    "sent": "The market blank is the set of all nodes that render a node independent of every other node in the network, right?",
                    "label": 0
                },
                {
                    "sent": "And you need.",
                    "label": 0
                },
                {
                    "sent": "Your children, and then you need your children's other parents.",
                    "label": 0
                },
                {
                    "sent": "I'll get to that later.",
                    "label": 0
                },
                {
                    "sent": "Actually, why knowledge of the child renders renders the two nodes independent.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, I'm coming to that later.",
                    "label": 0
                },
                {
                    "sent": "This is the example I was actually made up during my during my second divorce.",
                    "label": 0
                },
                {
                    "sent": "Alright, so it's.",
                    "label": 0
                },
                {
                    "sent": "Cheating spouse would cause the spouse to dine with a stranger alright, which in turn would cause the spouse to be seen dining with a stranger.",
                    "label": 1
                },
                {
                    "sent": "So this would be the causal graph amongst this, this is the causal chain.",
                    "label": 0
                },
                {
                    "sent": "Right, the probability of cheating given that they're seeing is bigger than the probability of cheating.",
                    "label": 0
                },
                {
                    "sent": "If I came in here and I told you that I had just seen your spouse dining with this good looking guy or good looking woman, you would suspect that they were cheating, right?",
                    "label": 0
                },
                {
                    "sent": "Probably cheating goes up so they're not independent events.",
                    "label": 0
                },
                {
                    "sent": "But if the dining event was already known to you, you had just before coming to this talk, seen it yourself.",
                    "label": 0
                },
                {
                    "sent": "Then the fact that I reported to you is meaningless.",
                    "label": 0
                },
                {
                    "sent": "Once you know this yourself, my report doesn't make it any more probable.",
                    "label": 0
                },
                {
                    "sent": "The fact that I've seen it also is in material.",
                    "label": 0
                },
                {
                    "sent": "So once you instantiate an intermediate variable, it renders these two independent, which again is the causal Markov assumption.",
                    "label": 0
                },
                {
                    "sent": "As is independent of its NAND ascendancy conditional on its parent, D. So C&S are independent given D. And so that's a causal chain.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These two are.",
                    "label": 0
                },
                {
                    "sent": "Common cause and a causal chain are the ones that are easier to understand.",
                    "label": 0
                },
                {
                    "sent": "This one is a little bit tricky.",
                    "label": 0
                },
                {
                    "sent": "This is an old example made up by you to Pearl at UCLA.",
                    "label": 0
                },
                {
                    "sent": "People that you didn't know how many people know him or somebody else did not.",
                    "label": 0
                },
                {
                    "sent": "Alright, so the audience?",
                    "label": 0
                },
                {
                    "sent": "He's probably the biggest name in this field of Bayesian network, so I'm just trying to get a feel for how familiar with Bayesian networks.",
                    "label": 0
                },
                {
                    "sent": "Anyway.",
                    "label": 0
                },
                {
                    "sent": "He was even UCLA where they have tremors all the time, right?",
                    "label": 0
                },
                {
                    "sent": "He's noticed that that earthquakes make his burglar alarm go off, and of course hopefully a burglar is going to do that too.",
                    "label": 0
                },
                {
                    "sent": "So we draw causal.",
                    "label": 0
                },
                {
                    "sent": "Arc, you're also now we're not talking about 66 on the Richter scale, where there would be massive looting in an earthquake, so there's no causal link between burglars and earthquakes.",
                    "label": 0
                },
                {
                    "sent": "My house is burglarized, is not going to cause an earthquake, and if there's a minor tremor, it's not going to make a burglar appear right.",
                    "label": 0
                },
                {
                    "sent": "So these two events are independent.",
                    "label": 0
                },
                {
                    "sent": "So the probability of B given Y equals the probability of Y, they're independent.",
                    "label": 0
                },
                {
                    "sent": "Which is in fact the causal Markov assumption.",
                    "label": 0
                },
                {
                    "sent": "B is independent of its non descendant E given its parents.",
                    "label": 0
                },
                {
                    "sent": "If you have no parents, your parents are the empty set and that's just global independence, so there's nothing to condition on here.",
                    "label": 0
                },
                {
                    "sent": "Memory for always wrote like C&D independent CNS independent given D. Well, there's nothing to condition at because these nodes have no parents.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's.",
                    "label": 0
                },
                {
                    "sent": "If two causes have a single effect, they are independent, and that then the causal Markov assumption says that they should be right.",
                    "label": 0
                },
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "If your alarm goes off.",
                    "label": 0
                },
                {
                    "sent": "All right, they're actually ordinarily rendered dependent.",
                    "label": 0
                },
                {
                    "sent": "And this is what you were bringing up before.",
                    "label": 0
                },
                {
                    "sent": "Once I know the value of this node, these become dependent.",
                    "label": 0
                },
                {
                    "sent": "Once I know the alarm went off, there's probably burglarized finding out there's an earthquake lowers that probability.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Why should that be?",
                    "label": 0
                },
                {
                    "sent": "I know when I've explained this to students, sometimes they say, well, how can the alarm going out to create a causal relationship between burglars and earthquakes?",
                    "label": 0
                },
                {
                    "sent": "And it doesn't create a causal relationship that creates a statistical relationship probabilistic relationship.",
                    "label": 0
                },
                {
                    "sent": "The way Perl originally told tells the example is like this, you have your your burglar alarm set up to go off in your office.",
                    "label": 0
                },
                {
                    "sent": "It's about I think Mr Watson alright, so he's sitting.",
                    "label": 0
                },
                {
                    "sent": "He's sitting in his office and his alarm goes off.",
                    "label": 0
                },
                {
                    "sent": "Well, it says well, it's a good chance I've been burglarized so we got some this car and starts riding home on his way home.",
                    "label": 0
                },
                {
                    "sent": "Here is on the radio that there's been an earthquake.",
                    "label": 0
                },
                {
                    "sent": "This is all the earthquake makes my alarm go off.",
                    "label": 0
                },
                {
                    "sent": "That explains away the alarm and therefore it is a good chance I haven't been burglarized.",
                    "label": 0
                },
                {
                    "sent": "That psychologists call this discounting E discounts be.",
                    "label": 1
                },
                {
                    "sent": "Now it's not.",
                    "label": 0
                },
                {
                    "sent": "It doesn't create a causal relationship.",
                    "label": 0
                },
                {
                    "sent": "If you're a frequentist, the guys only pay for you.",
                    "label": 0
                },
                {
                    "sent": "Actually guys, people know what I mean about by frequentists.",
                    "label": 0
                },
                {
                    "sent": "It's a classical statistician who believes in the relative frequency approach to probabilities, not abbasian.",
                    "label": 0
                },
                {
                    "sent": "Right, so if you hear frequent is the best way to.",
                    "label": 0
                },
                {
                    "sent": "Think about this is that.",
                    "label": 0
                },
                {
                    "sent": "Of all those times, your alarm went off, will go off.",
                    "label": 0
                },
                {
                    "sent": "The times that also include earthquakes will have less burglaries than the ones that do not include earthquakes.",
                    "label": 0
                },
                {
                    "sent": "So it's a statistical relationship.",
                    "label": 0
                },
                {
                    "sent": "When you instantiate the alarm, and if you think about it.",
                    "label": 0
                },
                {
                    "sent": "Like I say from a perspective of that that example I gave you and think how you would react as a human like this, Mr Watson that you would discount the alarm.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And once you knew that.",
                    "label": 0
                },
                {
                    "sent": "At the earthquake happen this count the burglar I mean.",
                    "label": 0
                },
                {
                    "sent": "But those are three classical examples.",
                    "label": 0
                },
                {
                    "sent": "Guess that made him want to leave.",
                    "label": 0
                },
                {
                    "sent": "Oh, just getting a better seat that makes you feel better.",
                    "label": 0
                },
                {
                    "sent": "Here's a bigger example made out made up originally by Greg Cooper.",
                    "label": 0
                },
                {
                    "sent": "He's.",
                    "label": 0
                },
                {
                    "sent": "PC and computer science, then MD at the bio.",
                    "label": 0
                },
                {
                    "sent": "Medical Informatics Department at University of Pittsburgh.",
                    "label": 0
                },
                {
                    "sent": "So he does research you applying Bayesian networks in the medical domain.",
                    "label": 0
                },
                {
                    "sent": "Here's an example.",
                    "label": 0
                },
                {
                    "sent": "He made up an.",
                    "label": 0
                },
                {
                    "sent": "I think these numbers were actually obtained from some data about the causal relationship between these five variables that smoking can cause bronchitis.",
                    "label": 0
                },
                {
                    "sent": "Smoking can also cause lung cancer.",
                    "label": 0
                },
                {
                    "sent": "Both of these conditions can cause fatigue and lung cancer can cause a chest X Ray to be positive.",
                    "label": 0
                },
                {
                    "sent": "I've also shown the numbers here.",
                    "label": 0
                },
                {
                    "sent": "That's how Bayesian networks are represented, yeah?",
                    "label": 0
                },
                {
                    "sent": "Cooper at COPER persons Gregory.",
                    "label": 0
                },
                {
                    "sent": "And it's in the Bio Medical Informatics program at the University of Pittsburgh.",
                    "label": 0
                },
                {
                    "sent": "I have references at the end of this talk, and I believe there's a yeah, there's at least one paper 'cause that I reference.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "This is how Bayesian network is ordinarily represented with the prior probability of roots and the conditional probability of each node given values of its parents.",
                    "label": 0
                },
                {
                    "sent": "Right, so the probability of B given H is .25.",
                    "label": 0
                },
                {
                    "sent": "That means if you smoke, probably getting bronchitis is .25.",
                    "label": 0
                },
                {
                    "sent": "If you don't smoke, it's only .05, which is reasonable, right?",
                    "label": 0
                },
                {
                    "sent": "So smoking causes bronchitis.",
                    "label": 0
                },
                {
                    "sent": "This should be bigger now since these lung cancer examples numbers are lot smaller than you would think, but I'm not quite sure when this means it means that weather in life you'll get lung cancer.",
                    "label": 0
                },
                {
                    "sent": "I never look at this example that closer, whether it means 10 years after smoking, it says, Yep, that's one thing you have to do whenever you deal with statistics and Bayesian networks.",
                    "label": 0
                },
                {
                    "sent": "Where you have to know what your variables actually represent.",
                    "label": 0
                },
                {
                    "sent": "What is whole smoking mean doesn't mean smoking 2 packs a day for 10 years.",
                    "label": 0
                },
                {
                    "sent": "So just saying smoking by itself is not really enough and that's all I'm saying here.",
                    "label": 0
                },
                {
                    "sent": "For a simple example.",
                    "label": 0
                },
                {
                    "sent": "Alright, then this is probably a fatigue given you have both these.",
                    "label": 0
                },
                {
                    "sent": "Conditions it's the highest the poor guys got.",
                    "label": 0
                },
                {
                    "sent": "Both bronchitis and lung cancer is more probable to be fatigued and the guy who's only got one or the other.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's how the network is represented.",
                    "label": 0
                },
                {
                    "sent": "My point here is actually to show something else.",
                    "label": 0
                },
                {
                    "sent": "That the probability of bronchitis given lung cancer is bigger than the probability of bronchitis.",
                    "label": 0
                },
                {
                    "sent": "Alright, once you have lung cancer, that's the argument I was making before right?",
                    "label": 0
                },
                {
                    "sent": "Makes it more likely you'll smoke, which makes it more likely you'll have bronchitis.",
                    "label": 0
                },
                {
                    "sent": "But once I instantiate the smoking, they become equal, so that's the same example I had before once I instantiate.",
                    "label": 0
                },
                {
                    "sent": "The common cause that renders them independent.",
                    "label": 0
                },
                {
                    "sent": "Now, even more than that, the probably bronchitis given positive chest X Ray is bigger than the probability of bronchitis.",
                    "label": 0
                },
                {
                    "sent": "I was just a couple weeks ago.",
                    "label": 0
                },
                {
                    "sent": "I was giving this talk.",
                    "label": 0
                },
                {
                    "sent": "To my colleagues, one of whom is a needy position and she didn't.",
                    "label": 0
                },
                {
                    "sent": "She told me doctors never really realized that an interactive she knows up.",
                    "label": 0
                },
                {
                    "sent": "They don't realize that.",
                    "label": 0
                },
                {
                    "sent": "A chest X Ray could be indicative of bronchitis.",
                    "label": 0
                },
                {
                    "sent": "If a bronchitis can't cause a chest X Ray.",
                    "label": 0
                },
                {
                    "sent": "They haven't been taught to reason like that in medical school, but the reason it is is because it makes lung cancer more probable now that it's more probably of lung cancer, it's more likely you'll smoke.",
                    "label": 0
                },
                {
                    "sent": "You were smoker, which makes it more likely you'll have bronchitis.",
                    "label": 0
                },
                {
                    "sent": "To see through this causal chain, here, these two are probabilistically dependent.",
                    "label": 0
                },
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "Once I instantiate HI know the person smokes, they're rendered.",
                    "label": 0
                },
                {
                    "sent": "Independent.",
                    "label": 0
                },
                {
                    "sent": "That break the chain right here B is independent of LNX given its parent H. And that's the notation that B isn't.",
                    "label": 0
                },
                {
                    "sent": "Try using this thing.",
                    "label": 0
                },
                {
                    "sent": "To the dollar speakers at this talking is this thing is I've never used before.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's a B is independent of LNX given H. B is independent of its non descendants, which arrellin X given its parent H. Notice is not independent of us.",
                    "label": 0
                },
                {
                    "sent": "After that's decent, and it wouldn't be just 'cause I know the person smokes, you know.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fatigue still makes bronchitis more probable.",
                    "label": 0
                },
                {
                    "sent": "Here's I'm switching to this thing is having to bend over to experimental evidence for the Markov condition.",
                    "label": 1
                },
                {
                    "sent": "That same study right there study showed that he is independent of T given D. So there are experiments.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's based upon reasonable assumptions and experiments.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're out that that that it holds.",
                    "label": 0
                },
                {
                    "sent": "Now, what are the exceptions to the causal Markov assumption?",
                    "label": 0
                },
                {
                    "sent": "This is the most damaging one or the one that screws it up.",
                    "label": 0
                },
                {
                    "sent": "The most of it that way hidden common causes.",
                    "label": 1
                },
                {
                    "sent": "What if I only have 3 variables in the network running nose cold and sneezing, right?",
                    "label": 0
                },
                {
                    "sent": "And what if there was some other cause of these two conditions?",
                    "label": 0
                },
                {
                    "sent": "S would not be independent of our given C, because as still makes H more likely, which makes are more likely.",
                    "label": 0
                },
                {
                    "sent": "Actually, there is another cause of I'm using H to denote hidden, but hayfever causes these two so if I don't articulate hay fever amongst my set of variables that cause a Markov.",
                    "label": 0
                },
                {
                    "sent": "Assumption is screwed up.",
                    "label": 0
                },
                {
                    "sent": "So if this was the case, SNR would not be independent.",
                    "label": 0
                },
                {
                    "sent": "Given see, what's curious about this is a lot of researchers.",
                    "label": 0
                },
                {
                    "sent": "Like to make the causal Markov assumption in practice.",
                    "label": 0
                },
                {
                    "sent": "And ignore the fact that could be hidden common causes, and I don't think I can think of a domain in which it really makes sense.",
                    "label": 0
                },
                {
                    "sent": "So what's the whole point of this talk?",
                    "label": 0
                },
                {
                    "sent": "Well, in this first part of the talk I'm going, I'm going to assume there can be no hidden common causes, because that's the easy way to do things.",
                    "label": 0
                },
                {
                    "sent": "And the second part, I'll relax that assumption, and that's when it makes this one.",
                    "label": 0
                },
                {
                    "sent": "This theory to me has more value.",
                    "label": 0
                },
                {
                    "sent": "Once you relax it.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so that's the worst thing is that you have to assume no hidden common causes, and I'm not sure there's many domains you can really do that.",
                    "label": 0
                },
                {
                    "sent": "Another thing is, causal feedback assumes a DAG, so you can't have things going in both directions.",
                    "label": 0
                },
                {
                    "sent": "You know somebody.",
                    "label": 0
                },
                {
                    "sent": "Studies certainly make him get good grades.",
                    "label": 1
                },
                {
                    "sent": "And actually experience with my girl, my daughter who's in college.",
                    "label": 0
                },
                {
                    "sent": "Now that you know which is getting good grades she start.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Studying harder 'cause you know the reward.",
                    "label": 0
                },
                {
                    "sent": "And it snowballed so you can't have that kind of situation going on.",
                    "label": 0
                },
                {
                    "sent": "Selection bias.",
                    "label": 0
                },
                {
                    "sent": "This is actually probably the hardest to understand.",
                    "label": 0
                },
                {
                    "sent": "Finasteride is a medication that that.",
                    "label": 0
                },
                {
                    "sent": "Merck pharmaceutical company Merck Manufacturers and and they originally used it for men who had BPH, but actually from passive data.",
                    "label": 0
                },
                {
                    "sent": "They found that those guys were regrowing here and they started are using it as a medication for hair loss.",
                    "label": 0
                },
                {
                    "sent": "Now, what if finasteride actually caused hypertension and this same colleague of mine is an MD told me that the reverse is true that finasteride actually lowers your blood pressure.",
                    "label": 0
                },
                {
                    "sent": "But for my example you know just let me assume that right that it does make your blood pressure higher and what apprehension about hair loss also made people get high blood pressure guys losing his hair and gets upset about it needs is a blood pressure goes up again.",
                    "label": 0
                },
                {
                    "sent": "I'm just making that up.",
                    "label": 0
                },
                {
                    "sent": "Just 'cause I have a comprehensive example involving these things and I want to tie it all together.",
                    "label": 0
                },
                {
                    "sent": "Alright, so assume that is the causal relationships among those variables, and suppose we obtained data an only FML.",
                    "label": 0
                },
                {
                    "sent": "Now the words.",
                    "label": 0
                },
                {
                    "sent": "We're only looking.",
                    "label": 0
                },
                {
                    "sent": "We're not looking at hypertension.",
                    "label": 0
                },
                {
                    "sent": "We're only looking at finasteride and hair loss.",
                    "label": 0
                },
                {
                    "sent": "But somehow we.",
                    "label": 0
                },
                {
                    "sent": "This is some kind of convenience sample and everyone in our sample suffers from hypertension.",
                    "label": 1
                },
                {
                    "sent": "We go to some hospital and we're going toward where we're treating people for hypertension, and we get we get data on those people.",
                    "label": 0
                },
                {
                    "sent": "So in other words, for everybody in our population this variable is, instantiate it too.",
                    "label": 0
                },
                {
                    "sent": "Yes, person has hypertension.",
                    "label": 0
                },
                {
                    "sent": "Well, if that was the case.",
                    "label": 1
                },
                {
                    "sent": "Finasteride with discount hair loss.",
                    "label": 0
                },
                {
                    "sent": "Just like I said before for.",
                    "label": 0
                },
                {
                    "sent": "If we find out an individual uses finasteride, it makes it explains away the hypertension, making it less likely they'll lose their hair.",
                    "label": 0
                },
                {
                    "sent": "So the people who use Fenesta ride would have less hair loss.",
                    "label": 0
                },
                {
                    "sent": "So if selection bias is present, then I sample it can screw up the.",
                    "label": 0
                },
                {
                    "sent": "You know the causal Markov assumption.",
                    "label": 0
                },
                {
                    "sent": "That is not that common to happen, and that's not as nearly obviously as problematic as the hidden common cause thing.",
                    "label": 0
                },
                {
                    "sent": "But it is something you have to be careful, love.",
                    "label": 0
                },
                {
                    "sent": "This is just the last part.",
                    "label": 0
                },
                {
                    "sent": "They are not independent in our observed distribution, although they are in the.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pendant amongst all people, they're not independent, and the probability distribution that we observe.",
                    "label": 0
                },
                {
                    "sent": "The 4th one is is kind of a funny one in this.",
                    "label": 0
                },
                {
                    "sent": "In this domain, there's always a population.",
                    "label": 0
                },
                {
                    "sent": "My examples of the population has been humans, but if the population happens to be units of time from 1990 on, we just take each day alright.",
                    "label": 0
                },
                {
                    "sent": "If we looked at that, let's look at the bottom 1 first.",
                    "label": 0
                },
                {
                    "sent": "The Dow Jones average would be correlated with my hairline.",
                    "label": 0
                },
                {
                    "sent": "'cause all during the 90s, the Dow Jones average went up and my hairline is going up at the same time yet, but nobody would ever think that the Dow Jones average had a causal effect on my hairline or vice versa.",
                    "label": 1
                },
                {
                    "sent": "So the causal relationship between these two variables is there is none, but yet they were correlated.",
                    "label": 0
                },
                {
                    "sent": "In the last few weeks, my hairline has not gone back down so that kind of indicates the causal relationship is not there actually.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I was up again that was down again on Friday, right?",
                    "label": 0
                },
                {
                    "sent": "It's going like this now.",
                    "label": 0
                },
                {
                    "sent": "Perhaps the condition that is most violated is that there can be no hidden common causes.",
                    "label": 1
                },
                {
                    "sent": "Come back to this.",
                    "label": 0
                },
                {
                    "sent": "Like I said, I don't.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Assumption isn't all that reasonable an, but it's easier to develop a theory if we make it so that I'm going to start out making it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I need to go back.",
                    "label": 0
                },
                {
                    "sent": "What's the difference between proposal feedback and discussion for relation honey honey problem works well if there's causal feedback, they would be correlated, right?",
                    "label": 0
                },
                {
                    "sent": "But you couldn't apply this theory because this theory requires that it be a DAG.",
                    "label": 0
                },
                {
                    "sent": "Those causation only goes in One Direction, so one is causation, one is correlation and a two different concepts.",
                    "label": 0
                },
                {
                    "sent": "I think I better keep track of the time I realize.",
                    "label": 0
                },
                {
                    "sent": "It's 238 already.",
                    "label": 0
                },
                {
                    "sent": "This is going not going as quickly as I thought.",
                    "label": 0
                },
                {
                    "sent": "Now here's something different.",
                    "label": 0
                },
                {
                    "sent": "There is a conditional independency among these variables that is not entailed by the Markov condition.",
                    "label": 1
                },
                {
                    "sent": "This is kind of a comprehensive example involving these variables fenesta ride.",
                    "label": 0
                },
                {
                    "sent": "As I told you before, lowers DHT levels.",
                    "label": 0
                },
                {
                    "sent": "That's actually how it.",
                    "label": 0
                },
                {
                    "sent": "It cures baldness because DHT is the male hormone that makes your hair fall out.",
                    "label": 0
                },
                {
                    "sent": "So if you lower your DHT levels.",
                    "label": 0
                },
                {
                    "sent": "Actually, a lot of studies show that you do that around the age of 20.",
                    "label": 0
                },
                {
                    "sent": "You won't lose your hair, not for sure, but again, it's very likely you will not now, as the study in log in at all showed DHT levels, though low, cause low DHT levels cause erectile dysfunction.",
                    "label": 0
                },
                {
                    "sent": "So given this causal chain, you would think the use of finasteride would cause erectile dysfunction.",
                    "label": 0
                },
                {
                    "sent": "So in Merck started.",
                    "label": 0
                },
                {
                    "sent": "Offering this as a medication for baldness, they feared the side effect.",
                    "label": 0
                },
                {
                    "sent": "Got a phone?",
                    "label": 0
                },
                {
                    "sent": "My school, you'll be kicked out of the room for that.",
                    "label": 0
                },
                {
                    "sent": "They actually my phones on two sides get kicked out to tickle.",
                    "label": 0
                },
                {
                    "sent": "So what's going on here?",
                    "label": 0
                },
                {
                    "sent": "Because who would want to take the medication then, right?",
                    "label": 0
                },
                {
                    "sent": "If this happened well?",
                    "label": 0
                },
                {
                    "sent": "Actually, in a in a very large controlled study.",
                    "label": 0
                },
                {
                    "sent": "It was essentially found that ENF are independent.",
                    "label": 0
                },
                {
                    "sent": "There's some very small evidence that they were slightly correlated.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Why would why would these two be independent when there's this causal chain?",
                    "label": 0
                },
                {
                    "sent": "Well, that can happen.",
                    "label": 0
                },
                {
                    "sent": "A causal and how it can happen is in this example.",
                    "label": 0
                },
                {
                    "sent": "I think finasteride lowers your DHT levels, but it's not capable of lowering it below a certain level and all you need is that minimal level for erectile dysfunction.",
                    "label": 0
                },
                {
                    "sent": "So let's say it can't lower it below 20 and 20 is all you need.",
                    "label": 0
                },
                {
                    "sent": "So in other words it lowers it enough that you keep your hair.",
                    "label": 0
                },
                {
                    "sent": "But that's it's not capable of lowering it so much that you have this problem.",
                    "label": 0
                },
                {
                    "sent": "A similar example is typing ability.",
                    "label": 0
                },
                {
                    "sent": "You take people and as people this is age.",
                    "label": 0
                },
                {
                    "sent": "As people get older they get more experience, but their manual dexterity goes down South.",
                    "label": 0
                },
                {
                    "sent": "HS has a causal relationship on manual dexterity, an on typing ability, an experience, I mean, and those two variables have an effect.",
                    "label": 0
                },
                {
                    "sent": "Then your typing ability.",
                    "label": 0
                },
                {
                    "sent": "So it's again I wish to Blackboard course last example top my head so you got this variable causing too like this and those two crossing another one at these two are independent because those two causes offset each other.",
                    "label": 0
                },
                {
                    "sent": "The increased manual decrease in manual dexterity is offset by the increased experience and studies show.",
                    "label": 0
                },
                {
                    "sent": "Once a person reaches a certain level of typing proficiency, they keep it all through their lives or until they become really old.",
                    "label": 0
                },
                {
                    "sent": "So it's another case.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Square where?",
                    "label": 0
                },
                {
                    "sent": "There is not an effect that goes that that goes through a causal chain.",
                    "label": 0
                },
                {
                    "sent": "Well, this kind of situation is not acceptable to learning causes.",
                    "label": 0
                },
                {
                    "sent": "In order to learn causes, we can't have that situation.",
                    "label": 0
                },
                {
                    "sent": "The causal faithfulness assumption assumes the observed distribution satisfies the Markov condition.",
                    "label": 1
                },
                {
                    "sent": "And all conditional Independencies are entailed by the market condition.",
                    "label": 0
                },
                {
                    "sent": "That's called the causal faithfulness assumption.",
                    "label": 0
                },
                {
                    "sent": "In other words, it assumes that by looking at the data, you can know every conditional independency that's present in the distribution.",
                    "label": 0
                },
                {
                    "sent": "We go back here.",
                    "label": 0
                },
                {
                    "sent": "In other words, I would have been able to look at the causal DAG and know that ENF are independent conditional on D and I would have to know there are no other in dependencies.",
                    "label": 0
                },
                {
                    "sent": "That's faithfulness is called faithfulness, called perfect perfection, because the perfect map, because everything you know about the probability distribution, not the numerical values besides Independencies, go can be read off the DAG.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is the assumption we're going to start out making?",
                    "label": 0
                },
                {
                    "sent": "We're going to assume there are not strange things.",
                    "label": 0
                },
                {
                    "sent": "Going on and what are the exceptions to the causal faithfulness assumptions, will do all the exceptions to the Markov assumption.",
                    "label": 1
                },
                {
                    "sent": "As all those ones I said before, plus you can't have these unusual causal relationships.",
                    "label": 0
                },
                {
                    "sent": "So another problem with the theory is how can you ever be sure this unusual stuff isn't happening?",
                    "label": 0
                },
                {
                    "sent": "I'll come back to that later again.",
                    "label": 0
                },
                {
                    "sent": "This is statistics and statistics.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Doesn't tell you something for sure.",
                    "label": 0
                },
                {
                    "sent": "We can't know for sure that a causes B can just help us.",
                    "label": 0
                },
                {
                    "sent": "So every model requires assumptions and assumptions always cause problems.",
                    "label": 0
                },
                {
                    "sent": "But for now, let's let's learn causal influences, making their causal faithfulness assumption.",
                    "label": 1
                },
                {
                    "sent": "So I'm going to assume that I'm assuming there's a causal dag out there.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Attaining the observed variables and the probability distribution that I observe is faithful to it.",
                    "label": 0
                },
                {
                    "sent": "And what can I learn if that's the case?",
                    "label": 0
                },
                {
                    "sent": "Now first of all in what follows, I'm going to assume we have a large amount of data on the variables of interest.",
                    "label": 1
                },
                {
                    "sent": "And we learned the conditional in dependencies from these data.",
                    "label": 0
                },
                {
                    "sent": "There's two ways to actually learn.",
                    "label": 0
                },
                {
                    "sent": "Causal networks are Bayesian networks in general, one is by learning the conditional Independencies first from the data, and then based on the independencies, learn the causal DAG.",
                    "label": 0
                },
                {
                    "sent": "That's called the constraint based method, and the other way is to just score the DAG using the data.",
                    "label": 0
                },
                {
                    "sent": "You don't learn in dependencies.",
                    "label": 0
                },
                {
                    "sent": "If there's some way of creating a score and based programs like probably the data given the DAG is 1 simple score.",
                    "label": 0
                },
                {
                    "sent": "The first way the constraint based method is much more intuitive, right?",
                    "label": 0
                },
                {
                    "sent": "That's why that's the one I given an overview talk like this 'cause it's my.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Easier for you.",
                    "label": 0
                },
                {
                    "sent": "Get an intuition for why you can learn causes from data, whereas the scoring technique doesn't give you any intuition whatsoever.",
                    "label": 0
                },
                {
                    "sent": "What do we mean exactly by this?",
                    "label": 0
                },
                {
                    "sent": "From these data, we would learn that Y&X, probably why one given X 1X by y = 1 given X equal 2.",
                    "label": 1
                },
                {
                    "sent": "See when X is 1.",
                    "label": 0
                },
                {
                    "sent": "I'll go here.",
                    "label": 0
                },
                {
                    "sent": "When X is 1.",
                    "label": 0
                },
                {
                    "sent": "Why is 1/2 the time when X is 2?",
                    "label": 0
                },
                {
                    "sent": "Why is 1/2 the time?",
                    "label": 0
                },
                {
                    "sent": "I only showed eight data items ivyside want more data items than that, but I would learn that.",
                    "label": 0
                },
                {
                    "sent": "In other words, I would learn that X&Y are independent.",
                    "label": 0
                },
                {
                    "sent": "So the first thing you do is you take all the data and learn your conditional independencies.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then from the conditional independence ease, you learn the causal DAG.",
                    "label": 0
                },
                {
                    "sent": "What's doing, I pressed the wrong thing.",
                    "label": 0
                },
                {
                    "sent": "How much data do we need?",
                    "label": 1
                },
                {
                    "sent": "Now in what files I'm going to assume that we know the Independencies right and, but the methods only as good as as the independence ease, and how much data do we need to rely abli learn anything I'll come back.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This alright?",
                    "label": 0
                },
                {
                    "sent": "But I'm going again.",
                    "label": 0
                },
                {
                    "sent": "Assume for now that we learned the conditional independence ease for certain.",
                    "label": 0
                },
                {
                    "sent": "I also get an example here.",
                    "label": 0
                },
                {
                    "sent": "Suppose.",
                    "label": 0
                },
                {
                    "sent": "V = X Y that means I settled observed variables or X&Y, and we learned their independent.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we're starting out with this knowledge that X&Y are independent.",
                    "label": 0
                },
                {
                    "sent": "We can't have the causal dagenais or be we couldn't tell if we're making the causal faithfulness assumption X could not cause A and why I mean why could that cause X?",
                    "label": 0
                },
                {
                    "sent": "Because if I apply the Markov condition for this DAG, I don't get that independency.",
                    "label": 0
                },
                {
                    "sent": "I would have to get the why is independent of Axon for this tag?",
                    "label": 0
                },
                {
                    "sent": "Why is independent of its non descendants conditional on X?",
                    "label": 0
                },
                {
                    "sent": "So this DAG does not say why in X or independent neither does this one.",
                    "label": 0
                },
                {
                    "sent": "Alright, so there's an independency that is not.",
                    "label": 0
                },
                {
                    "sent": "Shown by the DAG which screws up faithfulness.",
                    "label": 0
                },
                {
                    "sent": "So we must have the causal bag and see.",
                    "label": 1
                },
                {
                    "sent": "That's kind of a no brainer, right?",
                    "label": 0
                },
                {
                    "sent": "And then, if you have two variables and you find their independent, you assume they don't need another one causes each other and it doesn't even have to come to this talk to figure that out, right?",
                    "label": 0
                },
                {
                    "sent": "But that's I'm starting out with the simplest example, right?",
                    "label": 0
                },
                {
                    "sent": "Alright, suppose this is our setup, conditional independencies, and we have no independency.",
                    "label": 0
                },
                {
                    "sent": "So in other words, they are dependent.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "When I say the set of conditional independencies is the empty set, I mean their dependent.",
                    "label": 1
                },
                {
                    "sent": "We can't have the causal Dagenais.",
                    "label": 1
                },
                {
                    "sent": "Because if I apply the Markov condition to that tag, it says X is independent of Y, right?",
                    "label": 0
                },
                {
                    "sent": "And that independency is not observed?",
                    "label": 0
                },
                {
                    "sent": "So if this were the causal DAG, then.",
                    "label": 0
                },
                {
                    "sent": "Causal Markov assumption would not hold, and we're assuming it does hold.",
                    "label": 0
                },
                {
                    "sent": "So we must have the causal Dragon B or in see that X causes Y or Y causes X.",
                    "label": 1
                },
                {
                    "sent": "Now you may ask why?",
                    "label": 0
                },
                {
                    "sent": "Why couldn't we have a hidden common cause?",
                    "label": 0
                },
                {
                    "sent": "'cause I argued before hitting common cause would correlate them.",
                    "label": 0
                },
                {
                    "sent": "Remember, right now I'm assuming that you don't have hidden common causes.",
                    "label": 0
                },
                {
                    "sent": "So if I make that assumption which I can make if I want to write, then of course I can't conclude that there's a hidden Cam in Costco.",
                    "label": 0
                },
                {
                    "sent": "They assume that there is no such thing.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's another easy.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two, you have two variables.",
                    "label": 0
                },
                {
                    "sent": "You find that there, not, that they are correlated.",
                    "label": 0
                },
                {
                    "sent": "One causes the other.",
                    "label": 0
                },
                {
                    "sent": "We don't know which one.",
                    "label": 0
                },
                {
                    "sent": "All right, suppose we have three variables.",
                    "label": 0
                },
                {
                    "sent": "Now, I'm going to slowly get things that are a little more interesting, and we know that X&Y are independent.",
                    "label": 0
                },
                {
                    "sent": "So the only independent sees is that X&Y are independent.",
                    "label": 0
                },
                {
                    "sent": "There can be no edge between X&Y owing to the reason I just gave an example one.",
                    "label": 1
                },
                {
                    "sent": "If there were an edge from X&Y, the causal markup assumption would not say they are independent, right, because?",
                    "label": 0
                },
                {
                    "sent": "But I gave an example one, so there can't be an edge here.",
                    "label": 1
                },
                {
                    "sent": "There must be an edge between X&Z&Y&Z ohlinger.",
                    "label": 0
                },
                {
                    "sent": "The reason given an example to once there is no edge between X&Y.",
                    "label": 0
                },
                {
                    "sent": "If there's no edge between X&Z, then the Markov assumption would say X&Z are independent, and that's not one of our observed in dependencies.",
                    "label": 0
                },
                {
                    "sent": "So the Markov assumption would be violated.",
                    "label": 0
                },
                {
                    "sent": "So I can conclude that.",
                    "label": 0
                },
                {
                    "sent": "We have to have these links.",
                    "label": 0
                },
                {
                    "sent": "X is linked to ZZ is linked to Y.",
                    "label": 0
                },
                {
                    "sent": "Pressing this thing instead of this thing.",
                    "label": 0
                },
                {
                    "sent": "Alright, we cannot have the causal DAG and B or in C or D. I can't have any of these causal decks 'cause they all say.",
                    "label": 1
                },
                {
                    "sent": "They all entail X&Y, are independent, given Z.",
                    "label": 0
                },
                {
                    "sent": "Right, look at this one.",
                    "label": 0
                },
                {
                    "sent": "It's why has to be independent of its non descendant X conditional and its parent ZX has to be independent of its non descendant Y conditionalize parents ZXSB independent of its non descendant.",
                    "label": 1
                },
                {
                    "sent": "Why conditional on its parents?",
                    "label": 0
                },
                {
                    "sent": "See all three of these tags say that and that conditional independency is not present.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Markov assumption is not satisfied.",
                    "label": 1
                },
                {
                    "sent": "There is even more here.",
                    "label": 0
                },
                {
                    "sent": "The Markov condition does not entail for those tags.",
                    "label": 0
                },
                {
                    "sent": "The Markov condition does not say X&Y is independent, so there's an independency which the Markov condition does not entail.",
                    "label": 0
                },
                {
                    "sent": "Which violates the other half of the faithfulness part that you've got to be able to read off all the in dependencies that are there.",
                    "label": 0
                },
                {
                    "sent": "So for all three of these tags have a conditional independency.",
                    "label": 0
                },
                {
                    "sent": "I'm not observing all right and they don't have the one I am observing.",
                    "label": 0
                },
                {
                    "sent": "So twice things get messed up.",
                    "label": 0
                },
                {
                    "sent": "So we can conclude the only direction these arrows can have is this way.",
                    "label": 0
                },
                {
                    "sent": "X&Y, both kozee.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Does he mean?",
                    "label": 0
                },
                {
                    "sent": "A function that outputs dealer one or does it mean an event which is being used equals these are just random variables and they don't.",
                    "label": 0
                },
                {
                    "sent": "They could be multinomial.",
                    "label": 0
                },
                {
                    "sent": "They don't have to be binary, so they could be discreet, but it could be continuous.",
                    "label": 0
                },
                {
                    "sent": "Also, there's also structural equation modeling.",
                    "label": 0
                },
                {
                    "sent": "You can have visas.",
                    "label": 0
                },
                {
                    "sent": "Newest variables.",
                    "label": 0
                },
                {
                    "sent": "Let's post that Boolean variable.",
                    "label": 0
                },
                {
                    "sent": "An IV's equals 0.",
                    "label": 0
                },
                {
                    "sent": "X&Y are independent.",
                    "label": 0
                },
                {
                    "sent": "But as equals one then X imply idependent.",
                    "label": 0
                },
                {
                    "sent": "Well then they would still be.",
                    "label": 0
                },
                {
                    "sent": "In the.",
                    "label": 0
                },
                {
                    "sent": "When this when I say X&Y are independent conditional NZ and ask to be independent conditional on any value of Z.",
                    "label": 0
                },
                {
                    "sent": "So if they are in.",
                    "label": 0
                },
                {
                    "sent": "Independent conditional on one value and not the other.",
                    "label": 0
                },
                {
                    "sent": "Then they're not independent.",
                    "label": 0
                },
                {
                    "sent": "Conditional NZ, What you're saying is that bad condition on CS first value?",
                    "label": 0
                },
                {
                    "sent": "Probably, if X Givens equals one and y = 1 equals probably of X given.",
                    "label": 0
                },
                {
                    "sent": "Givens equals one y = 0, right?",
                    "label": 0
                },
                {
                    "sent": "Customers with.",
                    "label": 0
                },
                {
                    "sent": "Laugh with equals 0 = 1 and say this is the first one which makes.",
                    "label": 0
                },
                {
                    "sent": "FY.",
                    "label": 0
                },
                {
                    "sent": "Weather for sequels.",
                    "label": 0
                },
                {
                    "sent": "No, you don't need that because these are just random variables, right?",
                    "label": 0
                },
                {
                    "sent": "And then the theory says they have to be independent conditional on every value, and if they're not independent, conditional on every value, then there.",
                    "label": 0
                },
                {
                    "sent": "You don't call it a conditional independency.",
                    "label": 0
                },
                {
                    "sent": "I guess the way I've been stating these examples, I haven't made that clear.",
                    "label": 0
                },
                {
                    "sent": "I've always just conditioned on one value right in those examples.",
                    "label": 0
                },
                {
                    "sent": "So in other words.",
                    "label": 0
                },
                {
                    "sent": "If sneezing and running nose.",
                    "label": 0
                },
                {
                    "sent": "Are independent.",
                    "label": 0
                },
                {
                    "sent": "Have to be independent given that the person has a cold and they also have to be independent.",
                    "label": 0
                },
                {
                    "sent": "Given the person does not have a cold.",
                    "label": 0
                },
                {
                    "sent": "We're assuming both hold.",
                    "label": 0
                },
                {
                    "sent": "If one does not hold, then we don't call it a conditional independency.",
                    "label": 0
                },
                {
                    "sent": "Is that your question?",
                    "label": 0
                },
                {
                    "sent": "I need the blackboard again.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this would be the causal bag.",
                    "label": 0
                },
                {
                    "sent": "Now absolutely happened here.",
                    "label": 0
                },
                {
                    "sent": "I didn't mean to do that.",
                    "label": 0
                },
                {
                    "sent": "Sorry I'm not good at PowerPoint.",
                    "label": 0
                },
                {
                    "sent": "I again I meant to press this when I press that one that time.",
                    "label": 0
                },
                {
                    "sent": "Like Gerald Ford, the Lyndon Johnson, so he can't walk and chew gum simultaneously.",
                    "label": 0
                },
                {
                    "sent": "I can't.",
                    "label": 0
                },
                {
                    "sent": "Get me on this thing.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so we have to have X&Y causing, see that's the only thing we can conclude.",
                    "label": 0
                },
                {
                    "sent": "If I can go on from here.",
                    "label": 0
                },
                {
                    "sent": "Alright, suppose we have three variables, again, an now, X&Y are independent.",
                    "label": 0
                },
                {
                    "sent": "Given ZI won't be labor this, but we end up with these links.",
                    "label": 0
                },
                {
                    "sent": "Again, it's very similar to the arguments I already gave that there has to be an edge between X&Z and it cannot be one between X&Y.",
                    "label": 0
                },
                {
                    "sent": "So we must have links in a like I just said we can't have the causal bag and B, which is when I just deduced before.",
                    "label": 1
                },
                {
                    "sent": "The Markov condition applied to that tag and tails that X&Y are independent, right?",
                    "label": 0
                },
                {
                    "sent": "And then in dependencies not observed.",
                    "label": 0
                },
                {
                    "sent": "So the causal Markov assumption would not be satisfied.",
                    "label": 1
                },
                {
                    "sent": "Furthermore, the Markov condition does not entail the conditional independency that I do observe.",
                    "label": 0
                },
                {
                    "sent": "So the faithfulness part isn't there either.",
                    "label": 0
                },
                {
                    "sent": "It's called an IMAP by the way, and this is not an IMAP at all.",
                    "label": 0
                },
                {
                    "sent": "It's gotten independency that I'm not observing and doesn't have one.",
                    "label": 0
                },
                {
                    "sent": "I am observing.",
                    "label": 1
                },
                {
                    "sent": "It can't be with the faithfulness assumption.",
                    "label": 0
                },
                {
                    "sent": "So we must have the causal day.",
                    "label": 0
                },
                {
                    "sent": "I can see, or indeed or any.",
                    "label": 0
                },
                {
                    "sent": "Now you can't distinguish them.",
                    "label": 0
                },
                {
                    "sent": "These dogs are called Markov equivalent because they all three have the exact same conditional independencies, that Y is independent of X conditional NZ, so there's no way you could distinguish them.",
                    "label": 0
                },
                {
                    "sent": "So making the faithfulness assumption with this information, you can't really know any causes, but you can know.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They go this way this way or like this.",
                    "label": 0
                },
                {
                    "sent": "Now here's a theorem which I'm just going to state and hopefully have the intuition for now.",
                    "label": 0
                },
                {
                    "sent": "If the faithfulness condition is satisfied, then there's an edge between two variables if and only if they're not conditionally independent given any set of variables.",
                    "label": 1
                },
                {
                    "sent": "In other words, either there's an edge between X&Y, or there is some set of variables that renders them independent.",
                    "label": 0
                },
                {
                    "sent": "It could be the empty set.",
                    "label": 0
                },
                {
                    "sent": "And that.",
                    "label": 0
                },
                {
                    "sent": "Intuitively, that makes sense, right?",
                    "label": 0
                },
                {
                    "sent": "If either X&Y have no edge?",
                    "label": 0
                },
                {
                    "sent": "They are either there or are my trying to say either there's an edge.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Between them, or they're independent, or there's some variables that render them independent.",
                    "label": 0
                },
                {
                    "sent": "That's what this is really saying.",
                    "label": 0
                },
                {
                    "sent": "Maybe the example make it easier to see.",
                    "label": 0
                },
                {
                    "sent": "Suppose we observe four variables now, and these are conditional independencies.",
                    "label": 0
                },
                {
                    "sent": "X&Y are independent.",
                    "label": 0
                },
                {
                    "sent": "But W is independent of both of them, conditional on Z.",
                    "label": 0
                },
                {
                    "sent": "This notation means W is independent of X.",
                    "label": 0
                },
                {
                    "sent": "Conditional NZ WS independent of Y.",
                    "label": 0
                },
                {
                    "sent": "Conditional NZ and WS Independent of X&Y taking values.",
                    "label": 0
                },
                {
                    "sent": "Simultaneously conditional NZ.",
                    "label": 0
                },
                {
                    "sent": "Alright, so let's say we observe that.",
                    "label": 0
                },
                {
                    "sent": "Due to the previous theorem, the links must be those in a.",
                    "label": 1
                },
                {
                    "sent": "Let me show you what I'm talking about here I I was saying that the Korean theorem there's got to be an edge between 2:00.",
                    "label": 0
                },
                {
                    "sent": "Variables if and only if there's no variables that render them independent, so there's an edge between X&Z because you don't see any variable blocking the relationship between them.",
                    "label": 0
                },
                {
                    "sent": "There's no X between X&Y because they're independent.",
                    "label": 0
                },
                {
                    "sent": "Right here, independent conditional on the empty set.",
                    "label": 0
                },
                {
                    "sent": "There's no edge between X&W because X is independent of W conditional on ZZ blocks.",
                    "label": 0
                },
                {
                    "sent": "Through relationships, that's what the theorem is saying.",
                    "label": 0
                },
                {
                    "sent": "You have an edge if and only if there's no other variable that blocks the causal relationship between them.",
                    "label": 0
                },
                {
                    "sent": "And then Z&W have have have no variables blocking the class or relationship between them.",
                    "label": 0
                },
                {
                    "sent": "So from these conditional independencies and that theorem I can conclude.",
                    "label": 0
                },
                {
                    "sent": "These links.",
                    "label": 1
                },
                {
                    "sent": "We must have the arrow directions and B because X&Y are independent.",
                    "label": 0
                },
                {
                    "sent": "This is similar to the example I had before.",
                    "label": 0
                },
                {
                    "sent": "If I made these arrows go this way, go this way, or both go up, they would all say X&Y are independent given Z, right, and that's not what it says it says.",
                    "label": 0
                },
                {
                    "sent": "They're independent.",
                    "label": 0
                },
                {
                    "sent": "It's similar to the example we had before where I directed where three variables and I directed the edges this way.",
                    "label": 0
                },
                {
                    "sent": "Now, this is what this is where the theory becomes fun.",
                    "label": 1
                },
                {
                    "sent": "Therefore we have to have the arrow directions in C because we do not have WX independent.",
                    "label": 0
                },
                {
                    "sent": "See if I took this arrow and and made it go this way.",
                    "label": 0
                },
                {
                    "sent": "Then the markup assumption would say X&W are independent.",
                    "label": 0
                },
                {
                    "sent": "It would not say that X&W are independent given Z.",
                    "label": 0
                },
                {
                    "sent": "Same thing for why?",
                    "label": 0
                },
                {
                    "sent": "And the observed independency is not that X&W are independent, it's that they are independent given Z.",
                    "label": 0
                },
                {
                    "sent": "So once these two edges are directed this way, this one's gotta go that way.",
                    "label": 0
                },
                {
                    "sent": "And that says the correct independency.",
                    "label": 0
                },
                {
                    "sent": "It says W is independent of X given its parent Z, which is what this says W is independent of X given Z.",
                    "label": 0
                },
                {
                    "sent": "So once I learn these directions, I can learn another direction and think about this applied along linked list of variables Now with similar independencies.",
                    "label": 0
                },
                {
                    "sent": "I could go all the way down to Dag.",
                    "label": 0
                },
                {
                    "sent": "Learning causation, so if you have a.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A lot of variables you can.",
                    "label": 0
                },
                {
                    "sent": "You can learn a lot from.",
                    "label": 0
                },
                {
                    "sent": "You start at the beginning and just go down.",
                    "label": 0
                },
                {
                    "sent": "The dev learning causes.",
                    "label": 0
                },
                {
                    "sent": "Actually, I'm on time, if you give me just one more minute, I'll finish what I want to do before the break.",
                    "label": 0
                },
                {
                    "sent": "How much data do we need?",
                    "label": 1
                },
                {
                    "sent": "In the limit with probability one, we will learn the correct tag that sefarim originally proven by.",
                    "label": 1
                },
                {
                    "sent": "Howton in 1988 for curved exponential family of.",
                    "label": 0
                },
                {
                    "sent": "Models and a guy named Geiger proved that Bayesian networks are such a family, so we will know will learn the correct tag in the limit.",
                    "label": 0
                },
                {
                    "sent": "But we don't have an infinite amount of data.",
                    "label": 0
                },
                {
                    "sent": "In 2006, is that you a 2006 they obtained bounds on the number of records needed to be confident we will not learn a particular wrong tag?",
                    "label": 1
                },
                {
                    "sent": "Well, that's all.",
                    "label": 0
                },
                {
                    "sent": "That's an interesting result.",
                    "label": 0
                },
                {
                    "sent": "Mathematically, it's not really very useful.",
                    "label": 0
                },
                {
                    "sent": "It assumes we know the correct bag.",
                    "label": 0
                },
                {
                    "sent": "We know it's wrong bag.",
                    "label": 0
                },
                {
                    "sent": "How many data items do we need to have a high probability?",
                    "label": 0
                },
                {
                    "sent": "We won't learn that bag?",
                    "label": 0
                },
                {
                    "sent": "Well, that really doesn't help you too much, because in order to know how many data items to know, you need not to learn a wrong dad, then you need to take all possible combinations and take the maximum and super exponential number of tags.",
                    "label": 0
                },
                {
                    "sent": "So although it's an interesting result, it's not really useful for knowing how much data we need.",
                    "label": 0
                },
                {
                    "sent": "As I say, as far as I know, because I you know you always have to say as far as you know, right?",
                    "label": 0
                },
                {
                    "sent": "Because somebody.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's something you don't know about.",
                    "label": 0
                },
                {
                    "sent": "There are no bounds and number of records needed to be confident we're not wearing any wrong tag.",
                    "label": 1
                },
                {
                    "sent": "So to learn how much data we need, we need studies and there haven't been that many studies.",
                    "label": 0
                },
                {
                    "sent": "I just sent the one is giving this talk in an email out to the UI Listserver and seems like there hasn't been too much more done recently.",
                    "label": 0
                },
                {
                    "sent": "This group in 1997 showed that it was looking at connected graphs that showed that it learned the.",
                    "label": 0
                },
                {
                    "sent": "There are two nodes that learned the correct tags in as few as ten data items, and as you increase number of datums, it stayed with the correct tag in their examples.",
                    "label": 0
                },
                {
                    "sent": "With three they needed 200.",
                    "label": 0
                },
                {
                    "sent": "With four they use different ones and then it was somewhere between 1000 and 5005 thousand 2000.",
                    "label": 0
                },
                {
                    "sent": "Why is this number bigger than this?",
                    "label": 0
                },
                {
                    "sent": "The one that required 5000 had an undirected cycle and somehow that must be harder to learn.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "This gives you some feel for how many data items you need.",
                    "label": 0
                },
                {
                    "sent": "You got four or five.",
                    "label": 0
                },
                {
                    "sent": "Variables and it seems like from the study you need a few 1000.",
                    "label": 0
                },
                {
                    "sent": "Stronger.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of course are easier to learn if we if we have a deterministic relationship.",
                    "label": 0
                },
                {
                    "sent": "It's easier to learn that if we have a very weak dependency.",
                    "label": 0
                },
                {
                    "sent": "There's there are some conflicting empirical results.",
                    "label": 1
                },
                {
                    "sent": "Cooper and herskovits.",
                    "label": 0
                },
                {
                    "sent": "This topic is 1992 correctly learned.",
                    "label": 1
                },
                {
                    "sent": "A 37 node not this is Cooper by the way.",
                    "label": 0
                },
                {
                    "sent": "This is you were asking about him.",
                    "label": 0
                },
                {
                    "sent": "You know the relative his are you actually look a little like him like like his younger brothers.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's a long lost brother.",
                    "label": 1
                },
                {
                    "sent": "That's why you want to know.",
                    "label": 0
                },
                {
                    "sent": "Correctly learn a 37 known network from 3008 items which were generated using the network and how they started with the network.",
                    "label": 1
                },
                {
                    "sent": "Generated 3000 data items and it correctly.",
                    "label": 0
                },
                {
                    "sent": "I think you'll learn everything said one edge correctly.",
                    "label": 0
                },
                {
                    "sent": "That's looks good, right?",
                    "label": 1
                },
                {
                    "sent": "But Myself and I did study with the psychologist colleague of mine.",
                    "label": 1
                },
                {
                    "sent": "We obtained very goofy results when we tried learning an 8 node network and we had 9648 items.",
                    "label": 0
                },
                {
                    "sent": "We weren't doing a simulation.",
                    "label": 0
                },
                {
                    "sent": "We didn't start out with the network, generate data if we wanted it back.",
                    "label": 0
                },
                {
                    "sent": "We were really trying to learn something.",
                    "label": 0
                },
                {
                    "sent": "He was trying to learn what variables had an influence on an racial harassment in the military.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "What we learned was that whether individual held the military responsible for a racial incident has a causal effect on the individual's race.",
                    "label": 1
                },
                {
                    "sent": "In other words, let's say I'm not happy with my current race.",
                    "label": 0
                },
                {
                    "sent": "I could join the military, have a racial incident, hold the military responsible, and possibly change my race.",
                    "label": 0
                },
                {
                    "sent": "Now, that obviously that's goofy, right and.",
                    "label": 0
                },
                {
                    "sent": "And if I didn't know the variables though, right?",
                    "label": 0
                },
                {
                    "sent": "If I didn't know that these variables represented, I would say quite a lot of data and other people with a lot of data.",
                    "label": 0
                },
                {
                    "sent": "Learn learn 3000 items and I've got 9000.",
                    "label": 0
                },
                {
                    "sent": "So I would conclude that X causes Y.",
                    "label": 0
                },
                {
                    "sent": "But I can't conclude that because it's it goes against anything sensible.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I'm going to end the first half of the talk here, but I want to leave you with the idea that this is just statistics and my brother will come back to this example in the second half and explain why I think this happened.",
                    "label": 0
                },
                {
                    "sent": "It happened over example retail it.",
                    "label": 0
                },
                {
                    "sent": "This is just statistics and it looks like it can help guide our beliefs, but can't.",
                    "label": 0
                },
                {
                    "sent": "It's like magical P value, right?",
                    "label": 0
                },
                {
                    "sent": "It's for P values greater than .05.",
                    "label": 0
                },
                {
                    "sent": "Some people believe it for sure, but that's just.",
                    "label": 0
                },
                {
                    "sent": "An arbitrary cut off point.",
                    "label": 0
                },
                {
                    "sent": "All it can do is guide your beliefs.",
                    "label": 0
                },
                {
                    "sent": "If it's .051, you still have some reasonable belief that it's true, so it's very similar to that that nothing is definite.",
                    "label": 0
                },
                {
                    "sent": "Alright, after the break I'll relax this assumption of no hidden common causes.",
                    "label": 0
                },
                {
                    "sent": "Like I said I would do.",
                    "label": 0
                }
            ]
        }
    }
}