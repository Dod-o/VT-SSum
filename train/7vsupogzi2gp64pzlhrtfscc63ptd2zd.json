{
    "id": "7vsupogzi2gp64pzlhrtfscc63ptd2zd",
    "title": "Theory of Optimal Learning Machines",
    "info": {
        "author": [
            "Matteo Marsili, ICTP - The Abdus Salam International Centre for Theoretical Physics"
        ],
        "published": "May 15, 2019",
        "recorded": "May 2019",
        "category": [
            "Top->Science",
            "Top->Technology",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/kolokviji_marsili_optimal_learning_machines/",
    "segmentation": [
        [
            "And So what I want to discuss today, it's a subject that I've been interested in over the last few years, and this is a list of the people who have been involved in parts of what I'm going to tell you, and they most of them were, say students or postdocs interest, and then they move to other places.",
            "And.",
            "So.",
            "Just to give you an idea of what."
        ],
        [
            "Come from so this is our section in ICT and is a section that we call Quantitive life Sciences.",
            "And essentially we are all in one way or another theoretical physicist and our idea is to study living systems and intelligent systems with the same mindset of.",
            "Physicist, so hopefully quantitative manner, but focusing on.",
            "Mostly mostly on conceptual issues rather than particular applications.",
            "OK, so."
        ],
        [
            "So did.",
            "Why are?",
            "This learning machines important so there are of course important becausw.",
            "Of machine learning of deep neural networks and.",
            "Artificial intelligence.",
            "Which is a broad field, but they're also interesting because essentially learning machines are a build.",
            "An essential building block of life.",
            "Every this is not my point.",
            "This is appointed has been made by several people and this is from particular reference.",
            "But essentially, if you think about all systems that build life, what they?",
            "These are systems that intermediate between the inner function of an Organism or cell or something, and an environment which is highly valuable and the interaction between this system and environment.",
            "Must be such that it provides.",
            "And efficient representation of the states of the environment to the system OK. And so I think it is important to study and to understand the particular properties of these type of systems.",
            "Even beyond the.",
            "Machine learning.",
            "OK."
        ],
        [
            "So.",
            "Of course this is not something that.",
            "I'm starting.",
            "I mean there is a long tradition of studying information processing systems.",
            "And but most of what I found in the literature is based on the definition of efficient representations.",
            "That is based on input output relations.",
            "That is to say.",
            "The.",
            "The way in which these learning machines work is to say the system cares are particular about the particular variable.",
            "And essentially efficient representation.",
            "Is there a way to compress the information that is there in the environment about this variable?",
            "OK.",
            "So, um.",
            "No, the question is that.",
            "In many cases, so you first have to define what is the input, what is the information you care about in order to understand how the machine works.",
            "All you have to always discussed.",
            "I mean in this way of thinking you have always to think about this learning machine.",
            "In a way which is dependent on the context independent of the subject or which particular data is being analyzed or for which particular purpose OK?",
            "Instead, what I am going to argue is that you can look at this problem from a very generic point of view.",
            "Looking at learning machines as machines that try to extract.",
            "Maximally informative model of the.",
            "Model that generates the states of the environment.",
            "OK, so it's a compressed representation of how the environment evolves OK.",
            "So so key point and I'll discuss this in more detail, but the key point is that then if you look at things in this way.",
            "Then you can discuss properties of machine learning machines independently of the data or of the problem that these machines are meant to solve.",
            "OK, so."
        ],
        [
            "So this is the main result.",
            "So if you want just the couple so.",
            "What I will show is essentially that this opt.",
            "If you look at this optimal learning machine in this way.",
            "Then you find out that the optimal learning machine must have a very specific.",
            "Energy density distribution of energy densities OK, and in particular it should be exponential, at least in the in the range in which it operates.",
            "Then this means that if you look at a particular data, if you sample the states of this learning machine, then what you find is that the distribution of frequencies of states.",
            "So based power loss, which is what is called as being called statistical criticality.",
            "So this suggests that you find this broad distribution 'cause you're looking at efficient representations.",
            "And consequence of this is that now you can use these.",
            "Principles here in order to extract as a way of inferring what are the relevant variables.",
            "In high dimensional data, OK?",
            "OK, so the plan is the following, so I will first try to."
        ],
        [
            "Make the first point and in order to do this I will start to from very basics to remind you how does noise looks like.",
            "And then once you understand how noise look like, our inform in formation less data look like or informal.",
            "Does the generates?",
            "No information at all.",
            "Looks like you can understand how does a process that generates a rich information looks like OK. And, um.",
            "And then I will show a house samples in it.",
            "From this process look like and I will try to compare the properties of this optimal learning machines.",
            "We do the usual.",
            "Description of physical systems that is based on statistical mechanics.",
            "Ensure that the service file.",
            "Quite different principles OK?",
            "OK, finally I will give you a couple of examples of how to use these ideas to address open problems in machine learning and also to.",
            "Identify relevant variables in high."
        ],
        [
            "Dimensional data OK. OK, please interrupt me at anytime if you have questions so.",
            "So let me start by discussing what is noise.",
            "So imagine that you draw a vector high dimensional vector.",
            "So this D is very large.",
            "Over a valuables.",
            "So a sequence of variables just independently from some distribution.",
            "OK, imagine from zero one OK. Then essentially you will have this points in a very high dimensional space and they will be all over the place OK.",
            "There is very little you can say about them.",
            "However, there is a particular coordinator.",
            "On which these points will all align OK, and this particular coordinate is minus the log of the probability density from which you're drawing the points.",
            "This is Shannon theorem.",
            "OK, it tells you that now if you draw these points.",
            "From this distribution in this way, then what you will find?",
            "Is it on this axis?",
            "If you measure where the log of the probability of the points that you draw from this distribution go, they will all lie on the same line.",
            "We all attend the same value and this value is just the entropy OK?"
        ],
        [
            "So this is the law of large numbers, so this is also called the asymptotic."
        ],
        [
            "The partition property it tells you that almost surely the points that you are going to look at.",
            "When you draw things at random from a certain distribution, have the same probability which is E to the minus the entropy of these points of the probability and that the number and becausw.",
            "This is true.",
            "Then the number of typical points is inversely proportional to the probability is E to the entropy.",
            "OK, so this does not mean that you don't have.",
            "You cannot have points.",
            "Which have a very different value of log of the probability, but it's just that the probability that you find is points when these very large will be.",
            "Extremely small.",
            "OK.",
            "So if you want just.",
            "A simple example of this.",
            "Imagine just a sequence of spins, so very high demand bed, large magnetic system, so many spins.",
            "OK, with a given magnetic field.",
            "OK, so with probability one the magnetization will be independent.",
            "It will be the same.",
            "For all samples, for all configurations that you see, OK, this is what we call self averaging property OK, and is the basis of statistical mechanics indeed."
        ],
        [
            "This does not hold all, only four independent variables, but they All Souls for.",
            "Weakly interacting random variable which had essentially.",
            "All the variables that we deal with in statistical mechanics OK?",
            "OK.",
            "So."
        ],
        [
            "Now imagine that I want to.",
            "Make a summary of these points and I want to group these points into points which are somewhat similar.",
            "And so I figured out the particular criterion for saying that two points are similar or they are not similar.",
            "I define a certain distance and I put a threshold something like this.",
            "And so.",
            "And depending on this threshold, my clusters will be larger or smaller, so let's.",
            "So this means that so these points here.",
            "Will be points that are essentially.",
            "Old classes together and I can label this cluster by a variable as, so this will be my summary of this.",
            "Points.",
            "And so that I can.",
            "Think of the process of generating these points as the problem of generating these valuable S. Then the problem of generating the points given S OK now.",
            "What I want to ask is what type of?",
            "Cluster structure will I observe.",
            "If I look at random data.",
            "So.",
            "The boy."
        ],
        [
            "Is that if I look at random data, a situation like this one where there is one cluster of this size and one cluster which is much bigger than this?",
            "Will essentially never occur.",
            "Why?",
            "Because essentially these are random points and in the end there is no difference between these points.",
            "OK, so the fact that I'm putting some points in one class and some points in another cluster is just arbitrary depends on the way in which I'm defining my distance OK. And the number of ways if you look at how the in how many ways you can classify?",
            "These points where the average class size of is over given size.",
            "Then you will find out that this is dominated by.",
            "Class structure where all the clusters are essentially of the same size.",
            "This is just because of entropy.",
            "OK, so essentially."
        ],
        [
            "What you find out is.",
            "That if this data is really noise, then the.",
            "Any reasonable summary and most likely summary of this point will be one where essentially all these classes, all these points belong to classes of the same size, which means essentially the probability of each of these labels here will be essentially the same OK. And yes, in Tatica group partition proper."
        ],
        [
            "C tells you if you workout a little bit details that the number of these clusters must be inversely proportional.",
            "To the probability of each of these clusters.",
            "OK, this is exactly as in Tajik partition property.",
            "OK, so this is how noise.",
            "Looks like.",
            "OK. No.",
            "This means that if you look at what is the distribution of this valuable E, which is minus the log of the probability of this?",
            "A variables S here.",
            "Then you will find that it concentrates OK and this is the same result that we find in statistical mechanics.",
            "So the distribution of energies concentrates.",
            "In the Canonical example, and This is why you say the Canonical in somebody is the same as microcanonical in some OK.",
            "So this is how noise look like.",
            "Structureless data would look like.",
            "Now how does?"
        ],
        [
            "Instead, data with rich structure.",
            "We look like or generating process that generates data that we have.",
            "Well, at each structure look like well."
        ],
        [
            "You must have.",
            "A broad distribution of these energy levels.",
            "OK, so the distribution of energy level must be broad because essentially there is no way.",
            "I mean, if these points belong to a small cluster in these points belong to a large cluster, then they must be different becausw.",
            "Of strong statistical reasons OK. OK, so this means that these relation, which is just the syntactic equipartition property.",
            "Should hold on a very broad on a broad range of energy scales, or that the energy does not concentrate.",
            "OK, so this is my main point."
        ],
        [
            "OK, so if you want to see it pictorially so these all apply to the set of typical points in this space of values of X and what I'm discussing is about.",
            "How can you represent this typical set of values of access superpos?"
        ],
        [
            "Ocean of typical sets.",
            "Of points that are generated from a conditional distribution of X given S given the labels OK, and essentially you have different, say typical sets and this representation.",
            "Is one that a social distinguishes?",
            "It does not distinguish this point that belongs to the same.",
            "Blob here.",
            "By distinguishes point that have a different label South OK. And what?",
            "The result just told you about Tails is that the distribution of the sizes of this blob must be broad if the structure if the data is rich structure.",
            "And if the representation is sufficient, OK."
        ],
        [
            "OK, so more generally, you can generalize this picture by in the following way.",
            "So imagine that now you can abstract from the data from these what you are trying to represent and think whatever you are trying to represent.",
            "Every you cannot attach to any state of your representation.",
            "An energy variable which is just the coding cost is the number of bits that you need to spend to describe an outcome in this state.",
            "Then the.",
            "The average coding cost will be given by the average of these energy over the distribution process, which is just the entropy.",
            "OK. Now this is a measure of the resolution.",
            "Of how many?",
            "How much details?",
            "How many bits are you going to use?",
            "To describe the data OK, you can have a larger resolution or smaller resolution, OK?",
            "Now this just tells you how many bits you.",
            "Available OK, now the question is how do you use them in the most efficient way?",
            "And in order to use it in the most efficient way, what you have to do is to have a distribution of energy level, which is as broad as possible.",
            "OK, so in other words, you want that the the.",
            "Um?",
            "You want the number.",
            "Of energy levels that you cannot, or the number of states that you cannot distinguish because they have the same energy.",
            "If you want the degeneracy of energy level, this should be as small as possible.",
            "OK, because this is a measure of your noise, OK?",
            "So.",
            "So if this is the measure of your noise, then the your optimal learning machines should be machines for which the distribution of energy levels is such that the noise is as small as possible given a certain resolution.",
            "OK, so you solve this problem is just two line calculation.",
            "And the solution of this is exponential energy densities OK. Or if you want.",
            "The log of these generaci is what you could call our entropy Boltzmann entropy, so the Boltzmann entropy should be linear with respect to the energy.",
            "And you know that if the second derivative of the of the entropy with respect to the energy is the inverse of the specific heat.",
            "So this already tells you that.",
            "These linearity implies a sort of criticality OK, but I'll get back to this."
        ],
        [
            "OK, so if you look at what is the relation between the resolution, which is the average energy in this analogy?",
            "And the noise which is this Boltzmann entropy, which is essentially this.",
            "Then what you find is is is a convex or concave convex relation OK?",
            "And this is, uh, this is.",
            "A little bit.",
            "It all with what you find in statistical mechanics instead, is the mechanics.",
            "Usually this curve will be the other way around.",
            "OK will be concave.",
            "OK, so the entropy usually is a concave function of the energy OK.",
            "But now let's see what is the meaning of this of this.",
            "Of this cover, so this tells you how much noise, how many bits?",
            "So if you have, uh, these say 8 bits.",
            "At your disposal to describe your data set.",
            "Then.",
            "This tells you that at most five of them will be noise.",
            "The remaining three will tell you something about the generating process, OK?",
            "And now you see that as you change your resolution as you compress your representation.",
            "You can squeeze out the noise OK, but there is a part here."
        ],
        [
            "Where and this slope of this curve is precisely the LaGrange multiplier of the problem that we discussed in the previous slide.",
            "So when this slope here is.",
            "Wendy's LaGrange multiplier is positive.",
            "It means that when you decrease in this direction by 1 bit.",
            "Then on the Y axis you reduce by 1 plus new bits.",
            "The level of noise.",
            "So when new is positive.",
            "Then you are really so this efficient.",
            "This optimal learning machine are just eliminating noise.",
            "When Mu is negative, you start to eliminate also.",
            "Elements I mean orbits that tell you something on the generative process.",
            "OK, so this point here when new is equal to 0 and when you have exactly linear with coefficient one relation between the entropy and the energy is a very special point that characterizes optimal D optimal tradeoff between resolution and noise, OK?"
        ],
        [
            "No.",
            "Let me tell you how this.",
            "All this thing translates when you look at the sample.",
            "OK, so now we don't look inside the machine and look at this energy levels.",
            "But imagine that we just have a sample of data points we.",
            "We feed them on this system and what we observe are the states of the machine.",
            "That results from that, OK?",
            "Now let me cut a somewhat Long story short."
        ],
        [
            "Decision you can do the same analysis also on the basis of a single sample.",
            "And a basis of a single sample.",
            "You can say that the op, the total number of bits that you need to represent these each point of the sample will be given by the entropy of the empirical distribution.",
            "This K is just the number of times that you sell.",
            "Observe a particular outcome.",
            "So this is the total number of bits that you need to use to store your sample.",
            "One point of of the sample on your laptop.",
            "How many of these beats?",
            "Are just noise and how many of these bits tell you something on the generative process or are informative?",
            "Well especially, you can think."
        ],
        [
            "In the same way as we did.",
            "And essentially what you find out is that you can split this information content in one part, which is just noise.",
            "So all so the the entropy of the states.",
            "Which are which are observed, the same number of time this?",
            "Must be noise.",
            "This cannot be distinguished from noise.",
            "OK, whereas what it what?",
            "It remains.",
            "It's an upper bound to the number of useful bits.",
            "OK.",
            "So this is exactly this."
        ],
        [
            "So, so in this sense you can think of this entropy here.",
            "As a as a measure of resolution, and this entropy, here is a measure of intrinsic.",
            "Or useful information or what we call relevance."
        ],
        [
            "Say.",
            "And but you can also discuss the relation to this with the Bayesian model selection and.",
            "I'll be happy to discuss this.",
            "Offline"
        ],
        [
            "But OK, but let me tell you that one particular point of this is that now you can look at any data you like, and you can think.",
            "Let's imagine that this data is the output output of an optimal learning machine.",
            "So how can I tell?",
            "Whether this data is the output of an optimal learning machine or how can I quantify how many?",
            "Useful bits are there in this data.",
            "So what you can do is just you take your sample.",
            "You compute the frequency, which is the number of times you see a particular state.",
            "You compute the degeneracy, which is the number of states that uck times, and then you compute the resolution, resolution and the relevance, and you can plot these two things as a function of the resolution.",
            "OK, for example, this is an example.",
            "In data clustering you can essentially.",
            "Change the number of clusters.",
            "And essentially go from high resolution to low resolution."
        ],
        [
            "And given a particular cluster method, you can get different curves OK, and here what you want.",
            "You would understand is that there are methods to do this data clustering, for which this curve is higher up.",
            "So it means that extract more information on the generative process.",
            "OK, again, you can describe this tradeoff between resolution and relevance in each of these curves will have a different tradeoff.",
            "OK. OK, so."
        ],
        [
            "Uh.",
            "On this basis you can also describe what are maximally informative samples, whether samples that.",
            "Contain as much information as possible on the generative process.",
            "OK, and these are those that essentially satisfy these simple.",
            "Maximization process so that they maximize the entropy of the frequency at a given resolution.",
            "OK, now it's easy to."
        ],
        [
            "Solve this problem again.",
            "What you find is that there is a curve in this diagram of these HK versus HLS.",
            "Where are these maximum is obtained?",
            "And if you look at what the samples look like on this particular.",
            "When this Maxim is achieved, they all have power law distributions.",
            "OK.",
            "So essentially this tells you that you can take a sample.",
            "Think of this is coming from as being an efficient representation of higher dimensional data set, and you can tell whether this is an efficient representation or not by looking at the frequency distribution.",
            "And."
        ],
        [
            "Again, there is an optimal point in this curve, which is when the slope is equal to 1.",
            "Which is essentially when the tradeoff between resolution or relevance or noise and signal is at the optimal level at this particular point corresponds to zip flow, which is.",
            "When the number of states with that you serve K times goes down as K to the minus 2."
        ],
        [
            "OK, so there is a much simpler way to see that what I told you about the energy levels corresponds to what I told you on the frequency, because essentially the frequency in the end.",
            "So the energies are just minus the log of the probabilities, so you just do simple math and you see exponential distribution.",
            "Energy levels corresponds to power law distribution.",
            "There should be a K here.",
            "Sorry in frequencies."
        ],
        [
            "OK, now let me tell you how does.",
            "If these ideally optimal machines are learning machines, have these.",
            "Satisfy this maximum entropy.",
            "This is maximum relevance principle, minimum noise principle.",
            "How do they differ from systems that instead satisfy the?",
            "Statistical mechanics principle, which is essentially maximum entropy at a given energy.",
            "OK, so this is statistical mechanics as we know you will give the Hamiltonian when you give the Hamiltonian, you essentially give the density of states.",
            "You can count how many states are there, whether given energy OK. And then the problem is that the same account is to find the distribution over configurations over states that maximizes the entropy at a given energy OK, and is a result of this, you get an exponential distribution.",
            "And also you get equivalence of in sample in the sense that the Boltzmann entropy and Gibbs entropy are typical, essentially the same.",
            "And you get that the relation between this entropy and this entropy is essentially a concave relation is a result of this.",
            "You get criticality.",
            "So having broad distributions of frequency of energy as the specific, it is always finite.",
            "It does not diverge generally OK, or it diverges only at very specific point."
        ],
        [
            "So let me compare this to what happens to what I just told you about learning machines.",
            "So as I told you, learn optimal learning machine are machines such that if you define the energy levels as minus the log of the probability.",
            "Which is the coding cost, which is the natural cost in the information processing system?",
            "Then the problem is that of finding the energy level.",
            "So if you want the Hamiltonian.",
            "The tests a minimal degeneracy or minier average dissent, degeneracy at a fixed resolution.",
            "And now the resolution is equal to the average energy, and this is essentially the measure of the noise, OK?",
            "So this is what maximizes this entropy of the energy, which is what we call a resolution.",
            "As a result, you get a convex relation between the noise and the energy, which is quite different from this one.",
            "OK, and also get this exponential distribution.",
            "Which is consistent with having a critical system, typically having a critical system with broad distributions OK.",
            "So how?"
        ],
        [
            "What time do I have?",
            "So.",
            "10 minutes OK, so let me be a little bit more specific on how these optimal learning machines differ from physical system.",
            "OK, in order to do so.",
            "You can consider a very general system where essentially the.",
            "You have a system which is defined by a certain number of variable.",
            "Let's say spin variables and of them.",
            "And this system is in a hit button of a number of other variables.",
            "Let's say M and these are also spin variables OK.",
            "So you can think now the behavior of this system.",
            "You can think that it's a system that tries to maximize a certain function, and this function as a part that depends just on the system and the part that depends on the system and on the environment OK. And the so this general situation applies if you think a little bit about.",
            "Uh, about many systems that.",
            "We can think of OK, like say an open system in physics system in its environment or say for example a protein domain in a cell.",
            "And then what this product domain ties to maximize its fitness as function, which will depend in some way on the it's the sequence of amino acid which is the South and what whatever else is there?",
            "In the cellular environment.",
            "And also you can think this this applies to a lot of systems that we care about.",
            "OK, but in order to get a very general description, So what you need to find out is that what you need to specify is only how you generate these two objects.",
            "Here how you generate these to things here.",
            "And.",
            "Essentially what we do here is to assume that.",
            "The state, I mean this this.",
            "This part of this function here is drawn at random from stretched exponential distribution.",
            "And also these these both.",
            "These two things are drawn from these exponential from the stretched exponential distribution.",
            "So what you have here is an exponent gamma that you can tune and you can go from exponential, an exponential distribution, which is what would be an optimal learning machines for what they told you to do.",
            "To a physical system, which would typically have a Gaussian distribution of energy levels.",
            "OK."
        ],
        [
            "So this is what you find.",
            "So in brief, what you have is that.",
            "As you very this the strength, I mean when you have this energy density which is like stretched exponential when gamma is equal to 1 when you are at this particular point.",
            "You get systems that have an internal state.",
            "That is, that is.",
            "Is a statistic which is independent.",
            "Of how big is the environment?",
            "OK, this is the same thing that you have in optimal learning machine, so think about it.",
            "So if you have a set of pictures.",
            "Of animals.",
            "And a deep neural network that classifieds these pictures in cats, dogs, chimpanzees etc etc.",
            "So you would like that the classification is the same irrespective of whether this of the resolution of the picture.",
            "As long as the resolution is enough.",
            "OK, so if it is, say, one mega.",
            "About one MB per picture, or if it is 10 megabytes per picture, you would like the the the classification to be the same.",
            "OK, so among systems with these phase diagrams, those with gamma equal to 1 are the ones the only ones that have this property.",
            "OK."
        ],
        [
            "OK, so in particular what you find is they also have these.",
            "I mean this point."
        ],
        [
            "Where you get zip flow.",
            "This way you get exponential distribution and also you are at the phase transition.",
            "This precisely correspond to zip flow.",
            "And his ascension."
        ],
        [
            "What some people have been?",
            "Discussing on the basis of samples, though, measured from.",
            "Devil tissues, but I'll not go too much into detail, but the important thing is that.",
            "You can find a physical or if you want a specific thing to measure which is for example the specific it of.",
            "The specific it and this will tell you something about the efficiency of your representation.",
            "OK, so how does this work?"
        ],
        [
            "Practice.",
            "So can we test this theory?",
            "This set of ideas?"
        ],
        [
            "Well, first of all, if you look at a lot of data around you, you find power loss and now you can think that in particular in systems.",
            "That are supposed to be efficient representations of something you really find some power loss.",
            "So for example, language is the primary example, so languages.",
            "Is an efficient for the president always meant to be an efficient representation of?",
            "Over concepts.",
            "Very high dimensional stuff and you find it.",
            "Zip flows so that the frequency of how many times you find words.",
            "Follows this this particular behavior, immune system immune system, so these are like the antibody binding sites in the zebrafish, and you look at the abundance, and this is the immune system is essentially.",
            "The Organism representation of the environment of.",
            "Say.",
            "Bugs that are out there OK and you also find these zip flow.",
            "And this is neurons firing in the retina.",
            "So also you find this."
        ],
        [
            "But you can look outside artificial systems, so in deep neural networks and.",
            "So deep neural networks are these machines where you have the data and then you have several layers and you have couplings between the layers and you are just this couplings in such a way as to learn representations of of your data.",
            "And so that at the end, when you have learned this machine is able to generate.",
            "New data that are indistinguishable from the real ones OK?",
            "And so this is, say, So what you would expect.",
            "Is that if you learn?",
            "Data from these these machines, then different layers, would learn different representations at different resolutions and."
        ],
        [
            "What you would expect is that this representation should be efficient.",
            "And essentially what you find is that yes, they are efficient in the sense that this is examples of deep learner network with 10 layers.",
            "And on these MNIST data set, which is a little bit benchmark for these kind of things.",
            "And what you find is that the frequency of states with which observed states.",
            "In the different layers follows a power law and this curve.",
            "Of the of these, relevance is a function of.",
            "The resolution is very close to the maximal attainable relevance, and this is not true if you.",
            "If you're.",
            "Do look at other representation like what you're getting in clustering or if you look at other.",
            "If you look at the random data or if you look at the neural network."
        ],
        [
            "Before learning OK.",
            "So this is a property.",
            "That depends both on the fact that the data is nontrivial, and on the fact that the machine is close to optimal OK. Another important thing is that the.",
            "The point where.",
            "The layer on which distribution is closest to zip flow is also the one that generalizes best.",
            "OK.",
            "So this is a very recent result with the mass student."
        ],
        [
            "From column A superior and this tells you shows you what happens in just one layer of these machines.",
            "Do it in learning.",
            "OK, so this is the distributional energy levels as a function of.",
            "This is a machine where there are just 30 neurons, 30 spins.",
            "And this is the distribution of energy levels.",
            "Also, these distributional energy levels before you Start learning.",
            "And this is the distribution after three steps of learning, and this is the distribution of energy level after.",
            "60 steps of learning.",
            "So you see that what these machines do is actually to get a very broad distribution of energy levels in such a way that all this on the relevant range where the data is.",
            "You really get a linear.",
            "Say an exponential distribution.",
            "Of energy levels OK. OK, so the other efficient."
        ],
        [
            "The other systems that are suggested that are meant to optimally encode data such as minimum description length and normalized maximum likelihood.",
            "For these systems, you can exactly show.",
            "That this type of behavior.",
            "Actually occurs so that they are close to being efficient, and you can also show mathematically that the.",
            "The seat exactly at a critical point.",
            "OK, the last two minutes one minute."
        ],
        [
            "Or whatever I want to spend trying to tell you that another line over this is that we are pushing is to use these ideas in order to identify relevant variables in high dimensional data.",
            "Sold."
        ],
        [
            "This is 1 application of this so.",
            "So.",
            "So imagine that you do.",
            "I mean, there's this.",
            "Experiments when one can record the brain activity of subjects typically.",
            "Animals, rats or monkeys.",
            "In the particular region of the brain.",
            "During a particular task OK, and this is this.",
            "This allows you to understand how does.",
            "The brain codes or represents things.",
            "How does the brain works OK?",
            "And so this is particular data that we used in the that has been produced in the most slab on spatial navigation.",
            "So there is a particular region in the brain called the medial entorhinal cortex.",
            "Where which is supposed to be.",
            "Them.",
            "Which essentially generates space representation, at least in rats.",
            "The decisions that are there are neurons in these.",
            "Nutrients in this particular region.",
            "That generate this very nice example pattern, so the so when if you put a rat in a particular box.",
            "And you let him wander around.",
            "So these neurons will be active only when the rat.",
            "Passes through one of the nodes of the exact lattice.",
            "So this was quite remarkable discovery.",
            "These neurons are called grid cells, and it's part of the reason why the Motors were awarded the Nobel Prize in 2014.",
            "OK, so but the question is how do you find out?",
            "I mean to start with just records a sequence of zeros and ones.",
            "How do you find how do you go from here to here?",
            "Because in what you record there are both neurons that behave like this and neurons that behave like this.",
            "And maybe neurons that are completely unrelated with spatial navigation.",
            "They're doing something else.",
            "OK, so how do you find out what are the neurons that are relevant?",
            "And also in some cases you may recall from region A you don't know what is the particular.",
            "Correlate.",
            "That the the that region is is coding for OK.",
            "So you don't have, so you don't have an idea of.",
            "Even what do correlate what is the output of?",
            "What is the output of this signal?",
            "OK, so the idea we had is just on the basis if."
        ],
        [
            "I told you is true on the basis of.",
            "Just the data, just the sequence.",
            "You can figure out what neuron are relevant and which neurons are not relevant.",
            "OK, and way to apply these ideas.",
            "Door."
        ],
        [
            "Of this particular example, is the following is one way you may come up with a better one, but the way we found out is the following.",
            "So imagine that you take a window of time DT.",
            "You split your time series in a chunk of CDT.",
            "And then every neurons will be a sequence of zeros and ones.",
            "OK, you count the number of spikes.",
            "In each interval, each interval is a state.",
            "And the number of spikes is just the number of times that you get a spike in in that interval.",
            "So is your frequency OK?",
            "So then you can slide the window.",
            "You can get many states.",
            "You can measure both these entropy and this entropy.",
            "OK, now as you change the the.",
            "Time window.",
            "These two things will vary.",
            "I will draw curve OK like."
        ],
        [
            "This one.",
            "OK, so this is when essentially you are at very high resolution, so your DT is very small.",
            "So in every time being you either have one spike or 0.",
            "And this is somebody high low resolution.",
            "Well, essentially just one spike.",
            "One big OK. And what you see is that for each new day you can draw a curve and you can see that there are neurons for which this curve is higher than for others.",
            "And So what we say is that, let's say according to what I told you, well, this neuron should be more relevant than these noodle, and indeed if you go and look at the firing pattern, then this green neuron is really coding for some space dependence, and these other one is not.",
            "OK.",
            "So, but what you can do is also to compute the area under this curve and assign just to each neuron number which is the relevance what we call multiscale relevance.",
            "And then correlate this number with the."
        ],
        [
            "Say the mutual information of the filing activity and other important correlate.",
            "OK, So what you see here is that here there is this multiscale relevance.",
            "I told you about on the X axis and the Y axis there is the spatial information, the mutual information with the position of the filing patent with the position of the data.",
            "And what you see is that neurons that have low relevance.",
            "They do not contain any formation about space or about the direction of movement.",
            "Well, it's only noodles that have a high relevance that contains some information space and directional movement, and this is true for a very large number of experiments.",
            "All the experiments we could, we could look at them so in some sense this idea allows you to tell apart what are neurons that are.",
            "Coding for efficient representation water neurons that are not.",
            "And also these neurons that we identify."
        ],
        [
            "They are able to predict or to.",
            "The code.",
            "The position.",
            "As well as those neural which are maximally informative about the position.",
            "OK, the only thing is that in order to find out what are the most relevant neurons according to our measure, you don't need to know the space.",
            "You don't need to know that what correlates, they are the space coloring OK?",
            "OK, so I think."
        ],
        [
            "I already took too much time so.",
            "There is also another application that we did in trying to identify relevant positions in proteins, but that will just close with the.",
            "A couple of remarks."
        ],
        [
            "That I think are relevant.",
            "So there are many challenges in statistical learning so.",
            "The machine learning deep learning is something that has been exploding, but we don't really understand how it works.",
            "There are a lot of fundamental questions to be.",
            "To be addressed.",
            "OK so we don't understand why these machines are so efficient.",
            "We don't understand.",
            "So we observe that."
        ],
        [
            "These machines are very large statistical models.",
            "We apparently random couplings, but their energy landscape, which is not the one of glasses, so there are no local minima.",
            "So and especially you reach this efficient representation without energy budgets, so this is not well understood.",
            "Also another question is not well understood is why is it that these machines really need a lot of samples to learn.",
            "Something what is child would just need to look at three cats.",
            "And it would understand that the 4th one is a cut.",
            "Adam.",
            "And there are other questions, so the point I want to make is that every time you try to ask to answer one of these questions.",
            "It's very hard to get rid of the particular data that you're looking at or the particular architecture that you're looking at.",
            "OK, because all these questions have to do with the particular data set or a particular example.",
            "OK, so in some say what I tried to explain to you is that there is a way of addressing this question that is independent.",
            "Of the data, independent of the architecture of the model, I think this is a very interesting.",
            "Uh, direction.",
            "OK, so this is the summary of what I tried to tell."
        ],
        [
            "But I think it was a lot of information, so I'll just leave it there.",
            "And maybe if the time for questions then will go for that.",
            "Thank you very much.",
            "Questions.",
            "Thank you very much for very interesting talking and very difficult to follow, but can I ask you one quick question first, if these neural networks that you mention really obey Zipf's law?",
            "I mean getting on test that in the in the sense that you you mentioned and the second thing is that many of the biological systems which you also mentioned obey Zipf's law, right?",
            "In some variables that we can measure, can we invert the problem now and say if you observe zips log Kenny say which kind of partitioning between relevant and irrelevant information which mechanism?",
            "They really apply.",
            "Yeah so.",
            "OK, so the.",
            "Let me go back to this, and in any K in any example that we looked at.",
            "We found this specific.",
            "This behavior that essentially efficient representation in deep learning or less it up.",
            "Also machines or convolution.",
            "I mean there is a paper here that we published in J. Staten.",
            "And the.",
            "In the additional supplementary information there are lot of different architectures that we study unsupervised supervised learning.",
            "We always find these features.",
            "No no no yes yes yes.",
            "So the.",
            "So.",
            "So the idea is that essentially.",
            "And what this shows is that this is really.",
            "What learning is about learning is about, say, getting your energy distribution.",
            "As wide as possible, OK?",
            "Anne.",
            "Now the.",
            "Do.",
            "As a team member, the second part of the question.",
            "In biological systems you you know the Zips law exists and can be measured.",
            "Give me can we go back and ask and find out how this systems partition relevant from irrelevant effort yes, OK, so yes, that's the important point so.",
            "The way I. I would rephrase what you say or.",
            "This is issue is that if you look at all these data.",
            "As being the output of an optimal learning machine.",
            "Then the fact that they obeyed zip flow.",
            "It's.",
            "Natural OK it's.",
            "So the other, so there are two things here.",
            "So one thing is that.",
            "These efficient representations are generally.",
            "Not the type of representation that.",
            "Um, people look at it.",
            "It says that when you do data clustering.",
            "For example, you want to have five 610 clusters, OK?",
            "So you want to be in this in this diagram here.",
            "You want to be really on this side, where essentially your classes are very large.",
            "When you have a lot of statistics to classify all the.",
            "So what I'm talking about instead is the situation on this side where the number of clusters where you are in the undersampling, bridging your number of clusters is very high and the clusters are small.",
            "OK, so and what I'm saying is that up to a certain point here, so this part is universal.",
            "In the sense that as long as you compress, if you just eliminate noise, you are always going to.",
            "Lie on this line, whereas these other parts is not.",
            "It depends on what you care about, OK?",
            "So the other issue is.",
            "All this is relevant to the fact that we are trying to look at representation is a maximum informative on the generative process.",
            "So the whole idea here is that.",
            "When I look at this system.",
            "The this.",
            "Learning machine.",
            "Is not trying to learn.",
            "What is useful for the system is trying to learn just the generative compressed representation of the generative model of the states of the environment, OK?",
            "And that contains all the information about anything you could be interested in, OK?",
            "But as I told you all this is, this is it can also be very say.",
            "Um?",
            "Say non compressed representation.",
            "OK so.",
            "But we can talk maybe.",
            "Hi, thanks for the seminar.",
            "So I have two questions.",
            "One is that so do you.",
            "Don't make any assumption on the generative process in the sense that there are no parameters, right?",
            "Yes, so you don't make any assumption.",
            "The generative process, only you assume that the generative process must be.",
            "Must contain structure.",
            "OK, so for example, if you if this is not true.",
            "So for example if you take these, I'm nice data set which is just a handwritten digits digitalized and you are a shuffle every pixel.",
            "You just have noise.",
            "Then this doesn't work OK, because the.",
            "The so the condition for having this exponential distribution is that the machine should be optimal, but also the data should be non trivial OK. And then I mean another remark is that this computer is static.",
            "OK, so you don't say anything about the evolution towards this efficiency.",
            "And for instance, what happens?",
            "I don't know when the environment suppose you have very efficient representation of the environment and environment changes.",
            "So you should change your representation towards optimality.",
            "Can you make something like?",
            "I don't know a linear response theory.",
            "So this is the only thing that I said about the dynamics of learning how you get to learning.",
            "But there is another very interesting problem and this is.",
            "So which is this observation that?",
            "It is hard to unlearn, so imagine that this is awesome psychologies or psychology.",
            "Imagine that we do an experiment and.",
            "You are supposed to learn from, say, some outcomes.",
            "And so imagine that you have.",
            "Very typical are typical string of outcomes where essentially one very rare outcome comes out very often in the first round.",
            "Then you will draw conclusions.",
            "That even if the number of say.",
            "Discomfort material evidence is large.",
            "It will be very hard to reverse.",
            "OK, so we tend to.",
            "Learning machine, say once you learn something.",
            "It's very hard to unlearn, OK?",
            "And these are.",
            "Must be related.",
            "To the way in which the States, the space of.",
            "These parameter space gets disconnected.",
            "OK, so if you have a connected space of.",
            "App links if you want, then you can move from one representation to the other, but if it is disconnected with high energy barriers then that's very hard to go from one to the other.",
            "So this is.",
            "My, uh, I mean you can address all this kind of things.",
            "On the basis of.",
            "We are studying this kind of things on the basis of this insight.",
            "Are there more questions?",
            "I have a very naive one, so you mentioned this experiments on rats on grid cells.",
            "The most experiments and related experiments are there experiments on humans, especially kids.",
            "Navigation so these are expected.",
            "Well, the open discount of.",
            "The subjects and the implant.",
            "This.",
            "There are some experiments on this, but these are done on for example, on patients to try to recover some disabilities.",
            "So for example.",
            "Especially in the motor cortex, there are examples.",
            "There are experiments done in this way for, say, implants, artificial arts and controlling regaining control of artificial arts and things like this.",
            "But, uh, but of course humans.",
            "You cannot do experiments like this ones, so yeah.",
            "OK, so Professor Marcia will be here today and tomorrow.",
            "So if anybody wants to talk to him, just let me know.",
            "Let's thank him again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And So what I want to discuss today, it's a subject that I've been interested in over the last few years, and this is a list of the people who have been involved in parts of what I'm going to tell you, and they most of them were, say students or postdocs interest, and then they move to other places.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Just to give you an idea of what.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Come from so this is our section in ICT and is a section that we call Quantitive life Sciences.",
                    "label": 0
                },
                {
                    "sent": "And essentially we are all in one way or another theoretical physicist and our idea is to study living systems and intelligent systems with the same mindset of.",
                    "label": 0
                },
                {
                    "sent": "Physicist, so hopefully quantitative manner, but focusing on.",
                    "label": 0
                },
                {
                    "sent": "Mostly mostly on conceptual issues rather than particular applications.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So did.",
                    "label": 0
                },
                {
                    "sent": "Why are?",
                    "label": 0
                },
                {
                    "sent": "This learning machines important so there are of course important becausw.",
                    "label": 0
                },
                {
                    "sent": "Of machine learning of deep neural networks and.",
                    "label": 0
                },
                {
                    "sent": "Artificial intelligence.",
                    "label": 0
                },
                {
                    "sent": "Which is a broad field, but they're also interesting because essentially learning machines are a build.",
                    "label": 0
                },
                {
                    "sent": "An essential building block of life.",
                    "label": 0
                },
                {
                    "sent": "Every this is not my point.",
                    "label": 0
                },
                {
                    "sent": "This is appointed has been made by several people and this is from particular reference.",
                    "label": 0
                },
                {
                    "sent": "But essentially, if you think about all systems that build life, what they?",
                    "label": 0
                },
                {
                    "sent": "These are systems that intermediate between the inner function of an Organism or cell or something, and an environment which is highly valuable and the interaction between this system and environment.",
                    "label": 0
                },
                {
                    "sent": "Must be such that it provides.",
                    "label": 0
                },
                {
                    "sent": "And efficient representation of the states of the environment to the system OK. And so I think it is important to study and to understand the particular properties of these type of systems.",
                    "label": 0
                },
                {
                    "sent": "Even beyond the.",
                    "label": 0
                },
                {
                    "sent": "Machine learning.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Of course this is not something that.",
                    "label": 0
                },
                {
                    "sent": "I'm starting.",
                    "label": 0
                },
                {
                    "sent": "I mean there is a long tradition of studying information processing systems.",
                    "label": 0
                },
                {
                    "sent": "And but most of what I found in the literature is based on the definition of efficient representations.",
                    "label": 0
                },
                {
                    "sent": "That is based on input output relations.",
                    "label": 1
                },
                {
                    "sent": "That is to say.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The way in which these learning machines work is to say the system cares are particular about the particular variable.",
                    "label": 0
                },
                {
                    "sent": "And essentially efficient representation.",
                    "label": 0
                },
                {
                    "sent": "Is there a way to compress the information that is there in the environment about this variable?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "No, the question is that.",
                    "label": 0
                },
                {
                    "sent": "In many cases, so you first have to define what is the input, what is the information you care about in order to understand how the machine works.",
                    "label": 0
                },
                {
                    "sent": "All you have to always discussed.",
                    "label": 0
                },
                {
                    "sent": "I mean in this way of thinking you have always to think about this learning machine.",
                    "label": 0
                },
                {
                    "sent": "In a way which is dependent on the context independent of the subject or which particular data is being analyzed or for which particular purpose OK?",
                    "label": 0
                },
                {
                    "sent": "Instead, what I am going to argue is that you can look at this problem from a very generic point of view.",
                    "label": 0
                },
                {
                    "sent": "Looking at learning machines as machines that try to extract.",
                    "label": 0
                },
                {
                    "sent": "Maximally informative model of the.",
                    "label": 1
                },
                {
                    "sent": "Model that generates the states of the environment.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a compressed representation of how the environment evolves OK.",
                    "label": 0
                },
                {
                    "sent": "So so key point and I'll discuss this in more detail, but the key point is that then if you look at things in this way.",
                    "label": 0
                },
                {
                    "sent": "Then you can discuss properties of machine learning machines independently of the data or of the problem that these machines are meant to solve.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the main result.",
                    "label": 0
                },
                {
                    "sent": "So if you want just the couple so.",
                    "label": 0
                },
                {
                    "sent": "What I will show is essentially that this opt.",
                    "label": 0
                },
                {
                    "sent": "If you look at this optimal learning machine in this way.",
                    "label": 1
                },
                {
                    "sent": "Then you find out that the optimal learning machine must have a very specific.",
                    "label": 0
                },
                {
                    "sent": "Energy density distribution of energy densities OK, and in particular it should be exponential, at least in the in the range in which it operates.",
                    "label": 1
                },
                {
                    "sent": "Then this means that if you look at a particular data, if you sample the states of this learning machine, then what you find is that the distribution of frequencies of states.",
                    "label": 0
                },
                {
                    "sent": "So based power loss, which is what is called as being called statistical criticality.",
                    "label": 0
                },
                {
                    "sent": "So this suggests that you find this broad distribution 'cause you're looking at efficient representations.",
                    "label": 0
                },
                {
                    "sent": "And consequence of this is that now you can use these.",
                    "label": 0
                },
                {
                    "sent": "Principles here in order to extract as a way of inferring what are the relevant variables.",
                    "label": 1
                },
                {
                    "sent": "In high dimensional data, OK?",
                    "label": 0
                },
                {
                    "sent": "OK, so the plan is the following, so I will first try to.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Make the first point and in order to do this I will start to from very basics to remind you how does noise looks like.",
                    "label": 0
                },
                {
                    "sent": "And then once you understand how noise look like, our inform in formation less data look like or informal.",
                    "label": 1
                },
                {
                    "sent": "Does the generates?",
                    "label": 0
                },
                {
                    "sent": "No information at all.",
                    "label": 0
                },
                {
                    "sent": "Looks like you can understand how does a process that generates a rich information looks like OK. And, um.",
                    "label": 0
                },
                {
                    "sent": "And then I will show a house samples in it.",
                    "label": 0
                },
                {
                    "sent": "From this process look like and I will try to compare the properties of this optimal learning machines.",
                    "label": 1
                },
                {
                    "sent": "We do the usual.",
                    "label": 0
                },
                {
                    "sent": "Description of physical systems that is based on statistical mechanics.",
                    "label": 0
                },
                {
                    "sent": "Ensure that the service file.",
                    "label": 0
                },
                {
                    "sent": "Quite different principles OK?",
                    "label": 0
                },
                {
                    "sent": "OK, finally I will give you a couple of examples of how to use these ideas to address open problems in machine learning and also to.",
                    "label": 1
                },
                {
                    "sent": "Identify relevant variables in high.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dimensional data OK. OK, please interrupt me at anytime if you have questions so.",
                    "label": 0
                },
                {
                    "sent": "So let me start by discussing what is noise.",
                    "label": 1
                },
                {
                    "sent": "So imagine that you draw a vector high dimensional vector.",
                    "label": 0
                },
                {
                    "sent": "So this D is very large.",
                    "label": 0
                },
                {
                    "sent": "Over a valuables.",
                    "label": 0
                },
                {
                    "sent": "So a sequence of variables just independently from some distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, imagine from zero one OK. Then essentially you will have this points in a very high dimensional space and they will be all over the place OK.",
                    "label": 0
                },
                {
                    "sent": "There is very little you can say about them.",
                    "label": 0
                },
                {
                    "sent": "However, there is a particular coordinator.",
                    "label": 0
                },
                {
                    "sent": "On which these points will all align OK, and this particular coordinate is minus the log of the probability density from which you're drawing the points.",
                    "label": 0
                },
                {
                    "sent": "This is Shannon theorem.",
                    "label": 0
                },
                {
                    "sent": "OK, it tells you that now if you draw these points.",
                    "label": 0
                },
                {
                    "sent": "From this distribution in this way, then what you will find?",
                    "label": 0
                },
                {
                    "sent": "Is it on this axis?",
                    "label": 0
                },
                {
                    "sent": "If you measure where the log of the probability of the points that you draw from this distribution go, they will all lie on the same line.",
                    "label": 0
                },
                {
                    "sent": "We all attend the same value and this value is just the entropy OK?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the law of large numbers, so this is also called the asymptotic.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The partition property it tells you that almost surely the points that you are going to look at.",
                    "label": 0
                },
                {
                    "sent": "When you draw things at random from a certain distribution, have the same probability which is E to the minus the entropy of these points of the probability and that the number and becausw.",
                    "label": 0
                },
                {
                    "sent": "This is true.",
                    "label": 0
                },
                {
                    "sent": "Then the number of typical points is inversely proportional to the probability is E to the entropy.",
                    "label": 1
                },
                {
                    "sent": "OK, so this does not mean that you don't have.",
                    "label": 0
                },
                {
                    "sent": "You cannot have points.",
                    "label": 0
                },
                {
                    "sent": "Which have a very different value of log of the probability, but it's just that the probability that you find is points when these very large will be.",
                    "label": 0
                },
                {
                    "sent": "Extremely small.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So if you want just.",
                    "label": 0
                },
                {
                    "sent": "A simple example of this.",
                    "label": 0
                },
                {
                    "sent": "Imagine just a sequence of spins, so very high demand bed, large magnetic system, so many spins.",
                    "label": 0
                },
                {
                    "sent": "OK, with a given magnetic field.",
                    "label": 0
                },
                {
                    "sent": "OK, so with probability one the magnetization will be independent.",
                    "label": 0
                },
                {
                    "sent": "It will be the same.",
                    "label": 0
                },
                {
                    "sent": "For all samples, for all configurations that you see, OK, this is what we call self averaging property OK, and is the basis of statistical mechanics indeed.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This does not hold all, only four independent variables, but they All Souls for.",
                    "label": 0
                },
                {
                    "sent": "Weakly interacting random variable which had essentially.",
                    "label": 1
                },
                {
                    "sent": "All the variables that we deal with in statistical mechanics OK?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now imagine that I want to.",
                    "label": 0
                },
                {
                    "sent": "Make a summary of these points and I want to group these points into points which are somewhat similar.",
                    "label": 0
                },
                {
                    "sent": "And so I figured out the particular criterion for saying that two points are similar or they are not similar.",
                    "label": 0
                },
                {
                    "sent": "I define a certain distance and I put a threshold something like this.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "And depending on this threshold, my clusters will be larger or smaller, so let's.",
                    "label": 0
                },
                {
                    "sent": "So this means that so these points here.",
                    "label": 0
                },
                {
                    "sent": "Will be points that are essentially.",
                    "label": 0
                },
                {
                    "sent": "Old classes together and I can label this cluster by a variable as, so this will be my summary of this.",
                    "label": 0
                },
                {
                    "sent": "Points.",
                    "label": 0
                },
                {
                    "sent": "And so that I can.",
                    "label": 0
                },
                {
                    "sent": "Think of the process of generating these points as the problem of generating these valuable S. Then the problem of generating the points given S OK now.",
                    "label": 0
                },
                {
                    "sent": "What I want to ask is what type of?",
                    "label": 0
                },
                {
                    "sent": "Cluster structure will I observe.",
                    "label": 0
                },
                {
                    "sent": "If I look at random data.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The boy.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that if I look at random data, a situation like this one where there is one cluster of this size and one cluster which is much bigger than this?",
                    "label": 0
                },
                {
                    "sent": "Will essentially never occur.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because essentially these are random points and in the end there is no difference between these points.",
                    "label": 0
                },
                {
                    "sent": "OK, so the fact that I'm putting some points in one class and some points in another cluster is just arbitrary depends on the way in which I'm defining my distance OK. And the number of ways if you look at how the in how many ways you can classify?",
                    "label": 0
                },
                {
                    "sent": "These points where the average class size of is over given size.",
                    "label": 0
                },
                {
                    "sent": "Then you will find out that this is dominated by.",
                    "label": 0
                },
                {
                    "sent": "Class structure where all the clusters are essentially of the same size.",
                    "label": 0
                },
                {
                    "sent": "This is just because of entropy.",
                    "label": 0
                },
                {
                    "sent": "OK, so essentially.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What you find out is.",
                    "label": 0
                },
                {
                    "sent": "That if this data is really noise, then the.",
                    "label": 0
                },
                {
                    "sent": "Any reasonable summary and most likely summary of this point will be one where essentially all these classes, all these points belong to classes of the same size, which means essentially the probability of each of these labels here will be essentially the same OK. And yes, in Tatica group partition proper.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "C tells you if you workout a little bit details that the number of these clusters must be inversely proportional.",
                    "label": 0
                },
                {
                    "sent": "To the probability of each of these clusters.",
                    "label": 0
                },
                {
                    "sent": "OK, this is exactly as in Tajik partition property.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is how noise.",
                    "label": 0
                },
                {
                    "sent": "Looks like.",
                    "label": 0
                },
                {
                    "sent": "OK. No.",
                    "label": 0
                },
                {
                    "sent": "This means that if you look at what is the distribution of this valuable E, which is minus the log of the probability of this?",
                    "label": 0
                },
                {
                    "sent": "A variables S here.",
                    "label": 0
                },
                {
                    "sent": "Then you will find that it concentrates OK and this is the same result that we find in statistical mechanics.",
                    "label": 0
                },
                {
                    "sent": "So the distribution of energies concentrates.",
                    "label": 0
                },
                {
                    "sent": "In the Canonical example, and This is why you say the Canonical in somebody is the same as microcanonical in some OK.",
                    "label": 0
                },
                {
                    "sent": "So this is how noise look like.",
                    "label": 0
                },
                {
                    "sent": "Structureless data would look like.",
                    "label": 0
                },
                {
                    "sent": "Now how does?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Instead, data with rich structure.",
                    "label": 0
                },
                {
                    "sent": "We look like or generating process that generates data that we have.",
                    "label": 0
                },
                {
                    "sent": "Well, at each structure look like well.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You must have.",
                    "label": 0
                },
                {
                    "sent": "A broad distribution of these energy levels.",
                    "label": 0
                },
                {
                    "sent": "OK, so the distribution of energy level must be broad because essentially there is no way.",
                    "label": 0
                },
                {
                    "sent": "I mean, if these points belong to a small cluster in these points belong to a large cluster, then they must be different becausw.",
                    "label": 0
                },
                {
                    "sent": "Of strong statistical reasons OK. OK, so this means that these relation, which is just the syntactic equipartition property.",
                    "label": 0
                },
                {
                    "sent": "Should hold on a very broad on a broad range of energy scales, or that the energy does not concentrate.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is my main point.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so if you want to see it pictorially so these all apply to the set of typical points in this space of values of X and what I'm discussing is about.",
                    "label": 0
                },
                {
                    "sent": "How can you represent this typical set of values of access superpos?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ocean of typical sets.",
                    "label": 0
                },
                {
                    "sent": "Of points that are generated from a conditional distribution of X given S given the labels OK, and essentially you have different, say typical sets and this representation.",
                    "label": 0
                },
                {
                    "sent": "Is one that a social distinguishes?",
                    "label": 0
                },
                {
                    "sent": "It does not distinguish this point that belongs to the same.",
                    "label": 0
                },
                {
                    "sent": "Blob here.",
                    "label": 0
                },
                {
                    "sent": "By distinguishes point that have a different label South OK. And what?",
                    "label": 0
                },
                {
                    "sent": "The result just told you about Tails is that the distribution of the sizes of this blob must be broad if the structure if the data is rich structure.",
                    "label": 0
                },
                {
                    "sent": "And if the representation is sufficient, OK.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so more generally, you can generalize this picture by in the following way.",
                    "label": 0
                },
                {
                    "sent": "So imagine that now you can abstract from the data from these what you are trying to represent and think whatever you are trying to represent.",
                    "label": 0
                },
                {
                    "sent": "Every you cannot attach to any state of your representation.",
                    "label": 0
                },
                {
                    "sent": "An energy variable which is just the coding cost is the number of bits that you need to spend to describe an outcome in this state.",
                    "label": 0
                },
                {
                    "sent": "Then the.",
                    "label": 0
                },
                {
                    "sent": "The average coding cost will be given by the average of these energy over the distribution process, which is just the entropy.",
                    "label": 1
                },
                {
                    "sent": "OK. Now this is a measure of the resolution.",
                    "label": 0
                },
                {
                    "sent": "Of how many?",
                    "label": 0
                },
                {
                    "sent": "How much details?",
                    "label": 0
                },
                {
                    "sent": "How many bits are you going to use?",
                    "label": 0
                },
                {
                    "sent": "To describe the data OK, you can have a larger resolution or smaller resolution, OK?",
                    "label": 0
                },
                {
                    "sent": "Now this just tells you how many bits you.",
                    "label": 0
                },
                {
                    "sent": "Available OK, now the question is how do you use them in the most efficient way?",
                    "label": 0
                },
                {
                    "sent": "And in order to use it in the most efficient way, what you have to do is to have a distribution of energy level, which is as broad as possible.",
                    "label": 0
                },
                {
                    "sent": "OK, so in other words, you want that the the.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You want the number.",
                    "label": 0
                },
                {
                    "sent": "Of energy levels that you cannot, or the number of states that you cannot distinguish because they have the same energy.",
                    "label": 1
                },
                {
                    "sent": "If you want the degeneracy of energy level, this should be as small as possible.",
                    "label": 1
                },
                {
                    "sent": "OK, because this is a measure of your noise, OK?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So if this is the measure of your noise, then the your optimal learning machines should be machines for which the distribution of energy levels is such that the noise is as small as possible given a certain resolution.",
                    "label": 1
                },
                {
                    "sent": "OK, so you solve this problem is just two line calculation.",
                    "label": 0
                },
                {
                    "sent": "And the solution of this is exponential energy densities OK. Or if you want.",
                    "label": 0
                },
                {
                    "sent": "The log of these generaci is what you could call our entropy Boltzmann entropy, so the Boltzmann entropy should be linear with respect to the energy.",
                    "label": 0
                },
                {
                    "sent": "And you know that if the second derivative of the of the entropy with respect to the energy is the inverse of the specific heat.",
                    "label": 0
                },
                {
                    "sent": "So this already tells you that.",
                    "label": 0
                },
                {
                    "sent": "These linearity implies a sort of criticality OK, but I'll get back to this.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so if you look at what is the relation between the resolution, which is the average energy in this analogy?",
                    "label": 1
                },
                {
                    "sent": "And the noise which is this Boltzmann entropy, which is essentially this.",
                    "label": 1
                },
                {
                    "sent": "Then what you find is is is a convex or concave convex relation OK?",
                    "label": 0
                },
                {
                    "sent": "And this is, uh, this is.",
                    "label": 0
                },
                {
                    "sent": "A little bit.",
                    "label": 0
                },
                {
                    "sent": "It all with what you find in statistical mechanics instead, is the mechanics.",
                    "label": 0
                },
                {
                    "sent": "Usually this curve will be the other way around.",
                    "label": 0
                },
                {
                    "sent": "OK will be concave.",
                    "label": 0
                },
                {
                    "sent": "OK, so the entropy usually is a concave function of the energy OK.",
                    "label": 0
                },
                {
                    "sent": "But now let's see what is the meaning of this of this.",
                    "label": 0
                },
                {
                    "sent": "Of this cover, so this tells you how much noise, how many bits?",
                    "label": 0
                },
                {
                    "sent": "So if you have, uh, these say 8 bits.",
                    "label": 0
                },
                {
                    "sent": "At your disposal to describe your data set.",
                    "label": 0
                },
                {
                    "sent": "Then.",
                    "label": 0
                },
                {
                    "sent": "This tells you that at most five of them will be noise.",
                    "label": 0
                },
                {
                    "sent": "The remaining three will tell you something about the generating process, OK?",
                    "label": 0
                },
                {
                    "sent": "And now you see that as you change your resolution as you compress your representation.",
                    "label": 0
                },
                {
                    "sent": "You can squeeze out the noise OK, but there is a part here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where and this slope of this curve is precisely the LaGrange multiplier of the problem that we discussed in the previous slide.",
                    "label": 0
                },
                {
                    "sent": "So when this slope here is.",
                    "label": 0
                },
                {
                    "sent": "Wendy's LaGrange multiplier is positive.",
                    "label": 0
                },
                {
                    "sent": "It means that when you decrease in this direction by 1 bit.",
                    "label": 0
                },
                {
                    "sent": "Then on the Y axis you reduce by 1 plus new bits.",
                    "label": 0
                },
                {
                    "sent": "The level of noise.",
                    "label": 0
                },
                {
                    "sent": "So when new is positive.",
                    "label": 0
                },
                {
                    "sent": "Then you are really so this efficient.",
                    "label": 0
                },
                {
                    "sent": "This optimal learning machine are just eliminating noise.",
                    "label": 0
                },
                {
                    "sent": "When Mu is negative, you start to eliminate also.",
                    "label": 0
                },
                {
                    "sent": "Elements I mean orbits that tell you something on the generative process.",
                    "label": 0
                },
                {
                    "sent": "OK, so this point here when new is equal to 0 and when you have exactly linear with coefficient one relation between the entropy and the energy is a very special point that characterizes optimal D optimal tradeoff between resolution and noise, OK?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Let me tell you how this.",
                    "label": 0
                },
                {
                    "sent": "All this thing translates when you look at the sample.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we don't look inside the machine and look at this energy levels.",
                    "label": 0
                },
                {
                    "sent": "But imagine that we just have a sample of data points we.",
                    "label": 0
                },
                {
                    "sent": "We feed them on this system and what we observe are the states of the machine.",
                    "label": 0
                },
                {
                    "sent": "That results from that, OK?",
                    "label": 0
                },
                {
                    "sent": "Now let me cut a somewhat Long story short.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Decision you can do the same analysis also on the basis of a single sample.",
                    "label": 0
                },
                {
                    "sent": "And a basis of a single sample.",
                    "label": 0
                },
                {
                    "sent": "You can say that the op, the total number of bits that you need to represent these each point of the sample will be given by the entropy of the empirical distribution.",
                    "label": 0
                },
                {
                    "sent": "This K is just the number of times that you sell.",
                    "label": 0
                },
                {
                    "sent": "Observe a particular outcome.",
                    "label": 0
                },
                {
                    "sent": "So this is the total number of bits that you need to use to store your sample.",
                    "label": 0
                },
                {
                    "sent": "One point of of the sample on your laptop.",
                    "label": 0
                },
                {
                    "sent": "How many of these beats?",
                    "label": 1
                },
                {
                    "sent": "Are just noise and how many of these bits tell you something on the generative process or are informative?",
                    "label": 1
                },
                {
                    "sent": "Well especially, you can think.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the same way as we did.",
                    "label": 0
                },
                {
                    "sent": "And essentially what you find out is that you can split this information content in one part, which is just noise.",
                    "label": 0
                },
                {
                    "sent": "So all so the the entropy of the states.",
                    "label": 0
                },
                {
                    "sent": "Which are which are observed, the same number of time this?",
                    "label": 0
                },
                {
                    "sent": "Must be noise.",
                    "label": 0
                },
                {
                    "sent": "This cannot be distinguished from noise.",
                    "label": 0
                },
                {
                    "sent": "OK, whereas what it what?",
                    "label": 0
                },
                {
                    "sent": "It remains.",
                    "label": 0
                },
                {
                    "sent": "It's an upper bound to the number of useful bits.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is exactly this.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so in this sense you can think of this entropy here.",
                    "label": 0
                },
                {
                    "sent": "As a as a measure of resolution, and this entropy, here is a measure of intrinsic.",
                    "label": 0
                },
                {
                    "sent": "Or useful information or what we call relevance.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Say.",
                    "label": 0
                },
                {
                    "sent": "And but you can also discuss the relation to this with the Bayesian model selection and.",
                    "label": 0
                },
                {
                    "sent": "I'll be happy to discuss this.",
                    "label": 0
                },
                {
                    "sent": "Offline",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But OK, but let me tell you that one particular point of this is that now you can look at any data you like, and you can think.",
                    "label": 0
                },
                {
                    "sent": "Let's imagine that this data is the output output of an optimal learning machine.",
                    "label": 0
                },
                {
                    "sent": "So how can I tell?",
                    "label": 0
                },
                {
                    "sent": "Whether this data is the output of an optimal learning machine or how can I quantify how many?",
                    "label": 0
                },
                {
                    "sent": "Useful bits are there in this data.",
                    "label": 0
                },
                {
                    "sent": "So what you can do is just you take your sample.",
                    "label": 0
                },
                {
                    "sent": "You compute the frequency, which is the number of times you see a particular state.",
                    "label": 0
                },
                {
                    "sent": "You compute the degeneracy, which is the number of states that uck times, and then you compute the resolution, resolution and the relevance, and you can plot these two things as a function of the resolution.",
                    "label": 1
                },
                {
                    "sent": "OK, for example, this is an example.",
                    "label": 0
                },
                {
                    "sent": "In data clustering you can essentially.",
                    "label": 0
                },
                {
                    "sent": "Change the number of clusters.",
                    "label": 0
                },
                {
                    "sent": "And essentially go from high resolution to low resolution.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And given a particular cluster method, you can get different curves OK, and here what you want.",
                    "label": 0
                },
                {
                    "sent": "You would understand is that there are methods to do this data clustering, for which this curve is higher up.",
                    "label": 0
                },
                {
                    "sent": "So it means that extract more information on the generative process.",
                    "label": 0
                },
                {
                    "sent": "OK, again, you can describe this tradeoff between resolution and relevance in each of these curves will have a different tradeoff.",
                    "label": 0
                },
                {
                    "sent": "OK. OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "On this basis you can also describe what are maximally informative samples, whether samples that.",
                    "label": 1
                },
                {
                    "sent": "Contain as much information as possible on the generative process.",
                    "label": 0
                },
                {
                    "sent": "OK, and these are those that essentially satisfy these simple.",
                    "label": 0
                },
                {
                    "sent": "Maximization process so that they maximize the entropy of the frequency at a given resolution.",
                    "label": 0
                },
                {
                    "sent": "OK, now it's easy to.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Solve this problem again.",
                    "label": 0
                },
                {
                    "sent": "What you find is that there is a curve in this diagram of these HK versus HLS.",
                    "label": 0
                },
                {
                    "sent": "Where are these maximum is obtained?",
                    "label": 0
                },
                {
                    "sent": "And if you look at what the samples look like on this particular.",
                    "label": 0
                },
                {
                    "sent": "When this Maxim is achieved, they all have power law distributions.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So essentially this tells you that you can take a sample.",
                    "label": 0
                },
                {
                    "sent": "Think of this is coming from as being an efficient representation of higher dimensional data set, and you can tell whether this is an efficient representation or not by looking at the frequency distribution.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, there is an optimal point in this curve, which is when the slope is equal to 1.",
                    "label": 0
                },
                {
                    "sent": "Which is essentially when the tradeoff between resolution or relevance or noise and signal is at the optimal level at this particular point corresponds to zip flow, which is.",
                    "label": 0
                },
                {
                    "sent": "When the number of states with that you serve K times goes down as K to the minus 2.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so there is a much simpler way to see that what I told you about the energy levels corresponds to what I told you on the frequency, because essentially the frequency in the end.",
                    "label": 0
                },
                {
                    "sent": "So the energies are just minus the log of the probabilities, so you just do simple math and you see exponential distribution.",
                    "label": 0
                },
                {
                    "sent": "Energy levels corresponds to power law distribution.",
                    "label": 0
                },
                {
                    "sent": "There should be a K here.",
                    "label": 0
                },
                {
                    "sent": "Sorry in frequencies.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now let me tell you how does.",
                    "label": 1
                },
                {
                    "sent": "If these ideally optimal machines are learning machines, have these.",
                    "label": 0
                },
                {
                    "sent": "Satisfy this maximum entropy.",
                    "label": 0
                },
                {
                    "sent": "This is maximum relevance principle, minimum noise principle.",
                    "label": 0
                },
                {
                    "sent": "How do they differ from systems that instead satisfy the?",
                    "label": 0
                },
                {
                    "sent": "Statistical mechanics principle, which is essentially maximum entropy at a given energy.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is statistical mechanics as we know you will give the Hamiltonian when you give the Hamiltonian, you essentially give the density of states.",
                    "label": 0
                },
                {
                    "sent": "You can count how many states are there, whether given energy OK. And then the problem is that the same account is to find the distribution over configurations over states that maximizes the entropy at a given energy OK, and is a result of this, you get an exponential distribution.",
                    "label": 0
                },
                {
                    "sent": "And also you get equivalence of in sample in the sense that the Boltzmann entropy and Gibbs entropy are typical, essentially the same.",
                    "label": 0
                },
                {
                    "sent": "And you get that the relation between this entropy and this entropy is essentially a concave relation is a result of this.",
                    "label": 0
                },
                {
                    "sent": "You get criticality.",
                    "label": 1
                },
                {
                    "sent": "So having broad distributions of frequency of energy as the specific, it is always finite.",
                    "label": 0
                },
                {
                    "sent": "It does not diverge generally OK, or it diverges only at very specific point.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me compare this to what happens to what I just told you about learning machines.",
                    "label": 0
                },
                {
                    "sent": "So as I told you, learn optimal learning machine are machines such that if you define the energy levels as minus the log of the probability.",
                    "label": 1
                },
                {
                    "sent": "Which is the coding cost, which is the natural cost in the information processing system?",
                    "label": 0
                },
                {
                    "sent": "Then the problem is that of finding the energy level.",
                    "label": 1
                },
                {
                    "sent": "So if you want the Hamiltonian.",
                    "label": 0
                },
                {
                    "sent": "The tests a minimal degeneracy or minier average dissent, degeneracy at a fixed resolution.",
                    "label": 1
                },
                {
                    "sent": "And now the resolution is equal to the average energy, and this is essentially the measure of the noise, OK?",
                    "label": 0
                },
                {
                    "sent": "So this is what maximizes this entropy of the energy, which is what we call a resolution.",
                    "label": 0
                },
                {
                    "sent": "As a result, you get a convex relation between the noise and the energy, which is quite different from this one.",
                    "label": 0
                },
                {
                    "sent": "OK, and also get this exponential distribution.",
                    "label": 0
                },
                {
                    "sent": "Which is consistent with having a critical system, typically having a critical system with broad distributions OK.",
                    "label": 0
                },
                {
                    "sent": "So how?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What time do I have?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "10 minutes OK, so let me be a little bit more specific on how these optimal learning machines differ from physical system.",
                    "label": 0
                },
                {
                    "sent": "OK, in order to do so.",
                    "label": 0
                },
                {
                    "sent": "You can consider a very general system where essentially the.",
                    "label": 0
                },
                {
                    "sent": "You have a system which is defined by a certain number of variable.",
                    "label": 0
                },
                {
                    "sent": "Let's say spin variables and of them.",
                    "label": 0
                },
                {
                    "sent": "And this system is in a hit button of a number of other variables.",
                    "label": 0
                },
                {
                    "sent": "Let's say M and these are also spin variables OK.",
                    "label": 0
                },
                {
                    "sent": "So you can think now the behavior of this system.",
                    "label": 0
                },
                {
                    "sent": "You can think that it's a system that tries to maximize a certain function, and this function as a part that depends just on the system and the part that depends on the system and on the environment OK. And the so this general situation applies if you think a little bit about.",
                    "label": 0
                },
                {
                    "sent": "Uh, about many systems that.",
                    "label": 0
                },
                {
                    "sent": "We can think of OK, like say an open system in physics system in its environment or say for example a protein domain in a cell.",
                    "label": 1
                },
                {
                    "sent": "And then what this product domain ties to maximize its fitness as function, which will depend in some way on the it's the sequence of amino acid which is the South and what whatever else is there?",
                    "label": 0
                },
                {
                    "sent": "In the cellular environment.",
                    "label": 0
                },
                {
                    "sent": "And also you can think this this applies to a lot of systems that we care about.",
                    "label": 0
                },
                {
                    "sent": "OK, but in order to get a very general description, So what you need to find out is that what you need to specify is only how you generate these two objects.",
                    "label": 0
                },
                {
                    "sent": "Here how you generate these to things here.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Essentially what we do here is to assume that.",
                    "label": 0
                },
                {
                    "sent": "The state, I mean this this.",
                    "label": 0
                },
                {
                    "sent": "This part of this function here is drawn at random from stretched exponential distribution.",
                    "label": 0
                },
                {
                    "sent": "And also these these both.",
                    "label": 0
                },
                {
                    "sent": "These two things are drawn from these exponential from the stretched exponential distribution.",
                    "label": 0
                },
                {
                    "sent": "So what you have here is an exponent gamma that you can tune and you can go from exponential, an exponential distribution, which is what would be an optimal learning machines for what they told you to do.",
                    "label": 1
                },
                {
                    "sent": "To a physical system, which would typically have a Gaussian distribution of energy levels.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is what you find.",
                    "label": 0
                },
                {
                    "sent": "So in brief, what you have is that.",
                    "label": 0
                },
                {
                    "sent": "As you very this the strength, I mean when you have this energy density which is like stretched exponential when gamma is equal to 1 when you are at this particular point.",
                    "label": 0
                },
                {
                    "sent": "You get systems that have an internal state.",
                    "label": 0
                },
                {
                    "sent": "That is, that is.",
                    "label": 0
                },
                {
                    "sent": "Is a statistic which is independent.",
                    "label": 0
                },
                {
                    "sent": "Of how big is the environment?",
                    "label": 0
                },
                {
                    "sent": "OK, this is the same thing that you have in optimal learning machine, so think about it.",
                    "label": 0
                },
                {
                    "sent": "So if you have a set of pictures.",
                    "label": 0
                },
                {
                    "sent": "Of animals.",
                    "label": 0
                },
                {
                    "sent": "And a deep neural network that classifieds these pictures in cats, dogs, chimpanzees etc etc.",
                    "label": 0
                },
                {
                    "sent": "So you would like that the classification is the same irrespective of whether this of the resolution of the picture.",
                    "label": 0
                },
                {
                    "sent": "As long as the resolution is enough.",
                    "label": 0
                },
                {
                    "sent": "OK, so if it is, say, one mega.",
                    "label": 0
                },
                {
                    "sent": "About one MB per picture, or if it is 10 megabytes per picture, you would like the the the classification to be the same.",
                    "label": 0
                },
                {
                    "sent": "OK, so among systems with these phase diagrams, those with gamma equal to 1 are the ones the only ones that have this property.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so in particular what you find is they also have these.",
                    "label": 0
                },
                {
                    "sent": "I mean this point.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where you get zip flow.",
                    "label": 0
                },
                {
                    "sent": "This way you get exponential distribution and also you are at the phase transition.",
                    "label": 0
                },
                {
                    "sent": "This precisely correspond to zip flow.",
                    "label": 0
                },
                {
                    "sent": "And his ascension.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What some people have been?",
                    "label": 0
                },
                {
                    "sent": "Discussing on the basis of samples, though, measured from.",
                    "label": 0
                },
                {
                    "sent": "Devil tissues, but I'll not go too much into detail, but the important thing is that.",
                    "label": 0
                },
                {
                    "sent": "You can find a physical or if you want a specific thing to measure which is for example the specific it of.",
                    "label": 0
                },
                {
                    "sent": "The specific it and this will tell you something about the efficiency of your representation.",
                    "label": 0
                },
                {
                    "sent": "OK, so how does this work?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Practice.",
                    "label": 0
                },
                {
                    "sent": "So can we test this theory?",
                    "label": 0
                },
                {
                    "sent": "This set of ideas?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, first of all, if you look at a lot of data around you, you find power loss and now you can think that in particular in systems.",
                    "label": 0
                },
                {
                    "sent": "That are supposed to be efficient representations of something you really find some power loss.",
                    "label": 1
                },
                {
                    "sent": "So for example, language is the primary example, so languages.",
                    "label": 0
                },
                {
                    "sent": "Is an efficient for the president always meant to be an efficient representation of?",
                    "label": 0
                },
                {
                    "sent": "Over concepts.",
                    "label": 0
                },
                {
                    "sent": "Very high dimensional stuff and you find it.",
                    "label": 0
                },
                {
                    "sent": "Zip flows so that the frequency of how many times you find words.",
                    "label": 1
                },
                {
                    "sent": "Follows this this particular behavior, immune system immune system, so these are like the antibody binding sites in the zebrafish, and you look at the abundance, and this is the immune system is essentially.",
                    "label": 1
                },
                {
                    "sent": "The Organism representation of the environment of.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                },
                {
                    "sent": "Bugs that are out there OK and you also find these zip flow.",
                    "label": 0
                },
                {
                    "sent": "And this is neurons firing in the retina.",
                    "label": 0
                },
                {
                    "sent": "So also you find this.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But you can look outside artificial systems, so in deep neural networks and.",
                    "label": 0
                },
                {
                    "sent": "So deep neural networks are these machines where you have the data and then you have several layers and you have couplings between the layers and you are just this couplings in such a way as to learn representations of of your data.",
                    "label": 0
                },
                {
                    "sent": "And so that at the end, when you have learned this machine is able to generate.",
                    "label": 0
                },
                {
                    "sent": "New data that are indistinguishable from the real ones OK?",
                    "label": 0
                },
                {
                    "sent": "And so this is, say, So what you would expect.",
                    "label": 0
                },
                {
                    "sent": "Is that if you learn?",
                    "label": 0
                },
                {
                    "sent": "Data from these these machines, then different layers, would learn different representations at different resolutions and.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What you would expect is that this representation should be efficient.",
                    "label": 0
                },
                {
                    "sent": "And essentially what you find is that yes, they are efficient in the sense that this is examples of deep learner network with 10 layers.",
                    "label": 0
                },
                {
                    "sent": "And on these MNIST data set, which is a little bit benchmark for these kind of things.",
                    "label": 0
                },
                {
                    "sent": "And what you find is that the frequency of states with which observed states.",
                    "label": 0
                },
                {
                    "sent": "In the different layers follows a power law and this curve.",
                    "label": 0
                },
                {
                    "sent": "Of the of these, relevance is a function of.",
                    "label": 0
                },
                {
                    "sent": "The resolution is very close to the maximal attainable relevance, and this is not true if you.",
                    "label": 0
                },
                {
                    "sent": "If you're.",
                    "label": 0
                },
                {
                    "sent": "Do look at other representation like what you're getting in clustering or if you look at other.",
                    "label": 0
                },
                {
                    "sent": "If you look at the random data or if you look at the neural network.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before learning OK.",
                    "label": 0
                },
                {
                    "sent": "So this is a property.",
                    "label": 0
                },
                {
                    "sent": "That depends both on the fact that the data is nontrivial, and on the fact that the machine is close to optimal OK. Another important thing is that the.",
                    "label": 0
                },
                {
                    "sent": "The point where.",
                    "label": 0
                },
                {
                    "sent": "The layer on which distribution is closest to zip flow is also the one that generalizes best.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is a very recent result with the mass student.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From column A superior and this tells you shows you what happens in just one layer of these machines.",
                    "label": 0
                },
                {
                    "sent": "Do it in learning.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the distributional energy levels as a function of.",
                    "label": 0
                },
                {
                    "sent": "This is a machine where there are just 30 neurons, 30 spins.",
                    "label": 0
                },
                {
                    "sent": "And this is the distribution of energy levels.",
                    "label": 0
                },
                {
                    "sent": "Also, these distributional energy levels before you Start learning.",
                    "label": 0
                },
                {
                    "sent": "And this is the distribution after three steps of learning, and this is the distribution of energy level after.",
                    "label": 0
                },
                {
                    "sent": "60 steps of learning.",
                    "label": 0
                },
                {
                    "sent": "So you see that what these machines do is actually to get a very broad distribution of energy levels in such a way that all this on the relevant range where the data is.",
                    "label": 0
                },
                {
                    "sent": "You really get a linear.",
                    "label": 0
                },
                {
                    "sent": "Say an exponential distribution.",
                    "label": 0
                },
                {
                    "sent": "Of energy levels OK. OK, so the other efficient.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other systems that are suggested that are meant to optimally encode data such as minimum description length and normalized maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "For these systems, you can exactly show.",
                    "label": 0
                },
                {
                    "sent": "That this type of behavior.",
                    "label": 0
                },
                {
                    "sent": "Actually occurs so that they are close to being efficient, and you can also show mathematically that the.",
                    "label": 0
                },
                {
                    "sent": "The seat exactly at a critical point.",
                    "label": 0
                },
                {
                    "sent": "OK, the last two minutes one minute.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or whatever I want to spend trying to tell you that another line over this is that we are pushing is to use these ideas in order to identify relevant variables in high dimensional data.",
                    "label": 0
                },
                {
                    "sent": "Sold.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is 1 application of this so.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So imagine that you do.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's this.",
                    "label": 0
                },
                {
                    "sent": "Experiments when one can record the brain activity of subjects typically.",
                    "label": 0
                },
                {
                    "sent": "Animals, rats or monkeys.",
                    "label": 0
                },
                {
                    "sent": "In the particular region of the brain.",
                    "label": 1
                },
                {
                    "sent": "During a particular task OK, and this is this.",
                    "label": 0
                },
                {
                    "sent": "This allows you to understand how does.",
                    "label": 0
                },
                {
                    "sent": "The brain codes or represents things.",
                    "label": 0
                },
                {
                    "sent": "How does the brain works OK?",
                    "label": 0
                },
                {
                    "sent": "And so this is particular data that we used in the that has been produced in the most slab on spatial navigation.",
                    "label": 0
                },
                {
                    "sent": "So there is a particular region in the brain called the medial entorhinal cortex.",
                    "label": 0
                },
                {
                    "sent": "Where which is supposed to be.",
                    "label": 0
                },
                {
                    "sent": "Them.",
                    "label": 0
                },
                {
                    "sent": "Which essentially generates space representation, at least in rats.",
                    "label": 0
                },
                {
                    "sent": "The decisions that are there are neurons in these.",
                    "label": 0
                },
                {
                    "sent": "Nutrients in this particular region.",
                    "label": 0
                },
                {
                    "sent": "That generate this very nice example pattern, so the so when if you put a rat in a particular box.",
                    "label": 0
                },
                {
                    "sent": "And you let him wander around.",
                    "label": 0
                },
                {
                    "sent": "So these neurons will be active only when the rat.",
                    "label": 0
                },
                {
                    "sent": "Passes through one of the nodes of the exact lattice.",
                    "label": 0
                },
                {
                    "sent": "So this was quite remarkable discovery.",
                    "label": 0
                },
                {
                    "sent": "These neurons are called grid cells, and it's part of the reason why the Motors were awarded the Nobel Prize in 2014.",
                    "label": 0
                },
                {
                    "sent": "OK, so but the question is how do you find out?",
                    "label": 0
                },
                {
                    "sent": "I mean to start with just records a sequence of zeros and ones.",
                    "label": 0
                },
                {
                    "sent": "How do you find how do you go from here to here?",
                    "label": 0
                },
                {
                    "sent": "Because in what you record there are both neurons that behave like this and neurons that behave like this.",
                    "label": 0
                },
                {
                    "sent": "And maybe neurons that are completely unrelated with spatial navigation.",
                    "label": 0
                },
                {
                    "sent": "They're doing something else.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do you find out what are the neurons that are relevant?",
                    "label": 0
                },
                {
                    "sent": "And also in some cases you may recall from region A you don't know what is the particular.",
                    "label": 0
                },
                {
                    "sent": "Correlate.",
                    "label": 0
                },
                {
                    "sent": "That the the that region is is coding for OK.",
                    "label": 0
                },
                {
                    "sent": "So you don't have, so you don't have an idea of.",
                    "label": 0
                },
                {
                    "sent": "Even what do correlate what is the output of?",
                    "label": 0
                },
                {
                    "sent": "What is the output of this signal?",
                    "label": 0
                },
                {
                    "sent": "OK, so the idea we had is just on the basis if.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I told you is true on the basis of.",
                    "label": 0
                },
                {
                    "sent": "Just the data, just the sequence.",
                    "label": 0
                },
                {
                    "sent": "You can figure out what neuron are relevant and which neurons are not relevant.",
                    "label": 0
                },
                {
                    "sent": "OK, and way to apply these ideas.",
                    "label": 0
                },
                {
                    "sent": "Door.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of this particular example, is the following is one way you may come up with a better one, but the way we found out is the following.",
                    "label": 0
                },
                {
                    "sent": "So imagine that you take a window of time DT.",
                    "label": 0
                },
                {
                    "sent": "You split your time series in a chunk of CDT.",
                    "label": 0
                },
                {
                    "sent": "And then every neurons will be a sequence of zeros and ones.",
                    "label": 0
                },
                {
                    "sent": "OK, you count the number of spikes.",
                    "label": 0
                },
                {
                    "sent": "In each interval, each interval is a state.",
                    "label": 0
                },
                {
                    "sent": "And the number of spikes is just the number of times that you get a spike in in that interval.",
                    "label": 0
                },
                {
                    "sent": "So is your frequency OK?",
                    "label": 0
                },
                {
                    "sent": "So then you can slide the window.",
                    "label": 0
                },
                {
                    "sent": "You can get many states.",
                    "label": 0
                },
                {
                    "sent": "You can measure both these entropy and this entropy.",
                    "label": 0
                },
                {
                    "sent": "OK, now as you change the the.",
                    "label": 0
                },
                {
                    "sent": "Time window.",
                    "label": 0
                },
                {
                    "sent": "These two things will vary.",
                    "label": 0
                },
                {
                    "sent": "I will draw curve OK like.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is when essentially you are at very high resolution, so your DT is very small.",
                    "label": 0
                },
                {
                    "sent": "So in every time being you either have one spike or 0.",
                    "label": 0
                },
                {
                    "sent": "And this is somebody high low resolution.",
                    "label": 0
                },
                {
                    "sent": "Well, essentially just one spike.",
                    "label": 0
                },
                {
                    "sent": "One big OK. And what you see is that for each new day you can draw a curve and you can see that there are neurons for which this curve is higher than for others.",
                    "label": 0
                },
                {
                    "sent": "And So what we say is that, let's say according to what I told you, well, this neuron should be more relevant than these noodle, and indeed if you go and look at the firing pattern, then this green neuron is really coding for some space dependence, and these other one is not.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So, but what you can do is also to compute the area under this curve and assign just to each neuron number which is the relevance what we call multiscale relevance.",
                    "label": 0
                },
                {
                    "sent": "And then correlate this number with the.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Say the mutual information of the filing activity and other important correlate.",
                    "label": 0
                },
                {
                    "sent": "OK, So what you see here is that here there is this multiscale relevance.",
                    "label": 0
                },
                {
                    "sent": "I told you about on the X axis and the Y axis there is the spatial information, the mutual information with the position of the filing patent with the position of the data.",
                    "label": 0
                },
                {
                    "sent": "And what you see is that neurons that have low relevance.",
                    "label": 0
                },
                {
                    "sent": "They do not contain any formation about space or about the direction of movement.",
                    "label": 0
                },
                {
                    "sent": "Well, it's only noodles that have a high relevance that contains some information space and directional movement, and this is true for a very large number of experiments.",
                    "label": 0
                },
                {
                    "sent": "All the experiments we could, we could look at them so in some sense this idea allows you to tell apart what are neurons that are.",
                    "label": 0
                },
                {
                    "sent": "Coding for efficient representation water neurons that are not.",
                    "label": 0
                },
                {
                    "sent": "And also these neurons that we identify.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They are able to predict or to.",
                    "label": 0
                },
                {
                    "sent": "The code.",
                    "label": 0
                },
                {
                    "sent": "The position.",
                    "label": 0
                },
                {
                    "sent": "As well as those neural which are maximally informative about the position.",
                    "label": 0
                },
                {
                    "sent": "OK, the only thing is that in order to find out what are the most relevant neurons according to our measure, you don't need to know the space.",
                    "label": 0
                },
                {
                    "sent": "You don't need to know that what correlates, they are the space coloring OK?",
                    "label": 0
                },
                {
                    "sent": "OK, so I think.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I already took too much time so.",
                    "label": 0
                },
                {
                    "sent": "There is also another application that we did in trying to identify relevant positions in proteins, but that will just close with the.",
                    "label": 0
                },
                {
                    "sent": "A couple of remarks.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That I think are relevant.",
                    "label": 0
                },
                {
                    "sent": "So there are many challenges in statistical learning so.",
                    "label": 1
                },
                {
                    "sent": "The machine learning deep learning is something that has been exploding, but we don't really understand how it works.",
                    "label": 1
                },
                {
                    "sent": "There are a lot of fundamental questions to be.",
                    "label": 1
                },
                {
                    "sent": "To be addressed.",
                    "label": 0
                },
                {
                    "sent": "OK so we don't understand why these machines are so efficient.",
                    "label": 0
                },
                {
                    "sent": "We don't understand.",
                    "label": 0
                },
                {
                    "sent": "So we observe that.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These machines are very large statistical models.",
                    "label": 0
                },
                {
                    "sent": "We apparently random couplings, but their energy landscape, which is not the one of glasses, so there are no local minima.",
                    "label": 0
                },
                {
                    "sent": "So and especially you reach this efficient representation without energy budgets, so this is not well understood.",
                    "label": 0
                },
                {
                    "sent": "Also another question is not well understood is why is it that these machines really need a lot of samples to learn.",
                    "label": 1
                },
                {
                    "sent": "Something what is child would just need to look at three cats.",
                    "label": 0
                },
                {
                    "sent": "And it would understand that the 4th one is a cut.",
                    "label": 0
                },
                {
                    "sent": "Adam.",
                    "label": 0
                },
                {
                    "sent": "And there are other questions, so the point I want to make is that every time you try to ask to answer one of these questions.",
                    "label": 0
                },
                {
                    "sent": "It's very hard to get rid of the particular data that you're looking at or the particular architecture that you're looking at.",
                    "label": 0
                },
                {
                    "sent": "OK, because all these questions have to do with the particular data set or a particular example.",
                    "label": 0
                },
                {
                    "sent": "OK, so in some say what I tried to explain to you is that there is a way of addressing this question that is independent.",
                    "label": 0
                },
                {
                    "sent": "Of the data, independent of the architecture of the model, I think this is a very interesting.",
                    "label": 1
                },
                {
                    "sent": "Uh, direction.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the summary of what I tried to tell.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But I think it was a lot of information, so I'll just leave it there.",
                    "label": 0
                },
                {
                    "sent": "And maybe if the time for questions then will go for that.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for very interesting talking and very difficult to follow, but can I ask you one quick question first, if these neural networks that you mention really obey Zipf's law?",
                    "label": 0
                },
                {
                    "sent": "I mean getting on test that in the in the sense that you you mentioned and the second thing is that many of the biological systems which you also mentioned obey Zipf's law, right?",
                    "label": 1
                },
                {
                    "sent": "In some variables that we can measure, can we invert the problem now and say if you observe zips log Kenny say which kind of partitioning between relevant and irrelevant information which mechanism?",
                    "label": 0
                },
                {
                    "sent": "They really apply.",
                    "label": 0
                },
                {
                    "sent": "Yeah so.",
                    "label": 0
                },
                {
                    "sent": "OK, so the.",
                    "label": 0
                },
                {
                    "sent": "Let me go back to this, and in any K in any example that we looked at.",
                    "label": 0
                },
                {
                    "sent": "We found this specific.",
                    "label": 0
                },
                {
                    "sent": "This behavior that essentially efficient representation in deep learning or less it up.",
                    "label": 0
                },
                {
                    "sent": "Also machines or convolution.",
                    "label": 0
                },
                {
                    "sent": "I mean there is a paper here that we published in J. Staten.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "In the additional supplementary information there are lot of different architectures that we study unsupervised supervised learning.",
                    "label": 0
                },
                {
                    "sent": "We always find these features.",
                    "label": 0
                },
                {
                    "sent": "No no no yes yes yes.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that essentially.",
                    "label": 0
                },
                {
                    "sent": "And what this shows is that this is really.",
                    "label": 0
                },
                {
                    "sent": "What learning is about learning is about, say, getting your energy distribution.",
                    "label": 0
                },
                {
                    "sent": "As wide as possible, OK?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Now the.",
                    "label": 0
                },
                {
                    "sent": "Do.",
                    "label": 0
                },
                {
                    "sent": "As a team member, the second part of the question.",
                    "label": 0
                },
                {
                    "sent": "In biological systems you you know the Zips law exists and can be measured.",
                    "label": 0
                },
                {
                    "sent": "Give me can we go back and ask and find out how this systems partition relevant from irrelevant effort yes, OK, so yes, that's the important point so.",
                    "label": 0
                },
                {
                    "sent": "The way I. I would rephrase what you say or.",
                    "label": 0
                },
                {
                    "sent": "This is issue is that if you look at all these data.",
                    "label": 0
                },
                {
                    "sent": "As being the output of an optimal learning machine.",
                    "label": 0
                },
                {
                    "sent": "Then the fact that they obeyed zip flow.",
                    "label": 0
                },
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "Natural OK it's.",
                    "label": 0
                },
                {
                    "sent": "So the other, so there are two things here.",
                    "label": 0
                },
                {
                    "sent": "So one thing is that.",
                    "label": 0
                },
                {
                    "sent": "These efficient representations are generally.",
                    "label": 0
                },
                {
                    "sent": "Not the type of representation that.",
                    "label": 0
                },
                {
                    "sent": "Um, people look at it.",
                    "label": 0
                },
                {
                    "sent": "It says that when you do data clustering.",
                    "label": 0
                },
                {
                    "sent": "For example, you want to have five 610 clusters, OK?",
                    "label": 0
                },
                {
                    "sent": "So you want to be in this in this diagram here.",
                    "label": 0
                },
                {
                    "sent": "You want to be really on this side, where essentially your classes are very large.",
                    "label": 0
                },
                {
                    "sent": "When you have a lot of statistics to classify all the.",
                    "label": 0
                },
                {
                    "sent": "So what I'm talking about instead is the situation on this side where the number of clusters where you are in the undersampling, bridging your number of clusters is very high and the clusters are small.",
                    "label": 0
                },
                {
                    "sent": "OK, so and what I'm saying is that up to a certain point here, so this part is universal.",
                    "label": 0
                },
                {
                    "sent": "In the sense that as long as you compress, if you just eliminate noise, you are always going to.",
                    "label": 0
                },
                {
                    "sent": "Lie on this line, whereas these other parts is not.",
                    "label": 0
                },
                {
                    "sent": "It depends on what you care about, OK?",
                    "label": 0
                },
                {
                    "sent": "So the other issue is.",
                    "label": 0
                },
                {
                    "sent": "All this is relevant to the fact that we are trying to look at representation is a maximum informative on the generative process.",
                    "label": 1
                },
                {
                    "sent": "So the whole idea here is that.",
                    "label": 0
                },
                {
                    "sent": "When I look at this system.",
                    "label": 0
                },
                {
                    "sent": "The this.",
                    "label": 0
                },
                {
                    "sent": "Learning machine.",
                    "label": 0
                },
                {
                    "sent": "Is not trying to learn.",
                    "label": 0
                },
                {
                    "sent": "What is useful for the system is trying to learn just the generative compressed representation of the generative model of the states of the environment, OK?",
                    "label": 0
                },
                {
                    "sent": "And that contains all the information about anything you could be interested in, OK?",
                    "label": 0
                },
                {
                    "sent": "But as I told you all this is, this is it can also be very say.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Say non compressed representation.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "But we can talk maybe.",
                    "label": 0
                },
                {
                    "sent": "Hi, thanks for the seminar.",
                    "label": 0
                },
                {
                    "sent": "So I have two questions.",
                    "label": 0
                },
                {
                    "sent": "One is that so do you.",
                    "label": 0
                },
                {
                    "sent": "Don't make any assumption on the generative process in the sense that there are no parameters, right?",
                    "label": 0
                },
                {
                    "sent": "Yes, so you don't make any assumption.",
                    "label": 0
                },
                {
                    "sent": "The generative process, only you assume that the generative process must be.",
                    "label": 0
                },
                {
                    "sent": "Must contain structure.",
                    "label": 0
                },
                {
                    "sent": "OK, so for example, if you if this is not true.",
                    "label": 0
                },
                {
                    "sent": "So for example if you take these, I'm nice data set which is just a handwritten digits digitalized and you are a shuffle every pixel.",
                    "label": 0
                },
                {
                    "sent": "You just have noise.",
                    "label": 0
                },
                {
                    "sent": "Then this doesn't work OK, because the.",
                    "label": 0
                },
                {
                    "sent": "The so the condition for having this exponential distribution is that the machine should be optimal, but also the data should be non trivial OK. And then I mean another remark is that this computer is static.",
                    "label": 0
                },
                {
                    "sent": "OK, so you don't say anything about the evolution towards this efficiency.",
                    "label": 0
                },
                {
                    "sent": "And for instance, what happens?",
                    "label": 0
                },
                {
                    "sent": "I don't know when the environment suppose you have very efficient representation of the environment and environment changes.",
                    "label": 0
                },
                {
                    "sent": "So you should change your representation towards optimality.",
                    "label": 0
                },
                {
                    "sent": "Can you make something like?",
                    "label": 0
                },
                {
                    "sent": "I don't know a linear response theory.",
                    "label": 0
                },
                {
                    "sent": "So this is the only thing that I said about the dynamics of learning how you get to learning.",
                    "label": 0
                },
                {
                    "sent": "But there is another very interesting problem and this is.",
                    "label": 0
                },
                {
                    "sent": "So which is this observation that?",
                    "label": 0
                },
                {
                    "sent": "It is hard to unlearn, so imagine that this is awesome psychologies or psychology.",
                    "label": 0
                },
                {
                    "sent": "Imagine that we do an experiment and.",
                    "label": 0
                },
                {
                    "sent": "You are supposed to learn from, say, some outcomes.",
                    "label": 0
                },
                {
                    "sent": "And so imagine that you have.",
                    "label": 0
                },
                {
                    "sent": "Very typical are typical string of outcomes where essentially one very rare outcome comes out very often in the first round.",
                    "label": 0
                },
                {
                    "sent": "Then you will draw conclusions.",
                    "label": 0
                },
                {
                    "sent": "That even if the number of say.",
                    "label": 0
                },
                {
                    "sent": "Discomfort material evidence is large.",
                    "label": 0
                },
                {
                    "sent": "It will be very hard to reverse.",
                    "label": 0
                },
                {
                    "sent": "OK, so we tend to.",
                    "label": 0
                },
                {
                    "sent": "Learning machine, say once you learn something.",
                    "label": 0
                },
                {
                    "sent": "It's very hard to unlearn, OK?",
                    "label": 0
                },
                {
                    "sent": "And these are.",
                    "label": 0
                },
                {
                    "sent": "Must be related.",
                    "label": 0
                },
                {
                    "sent": "To the way in which the States, the space of.",
                    "label": 0
                },
                {
                    "sent": "These parameter space gets disconnected.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you have a connected space of.",
                    "label": 0
                },
                {
                    "sent": "App links if you want, then you can move from one representation to the other, but if it is disconnected with high energy barriers then that's very hard to go from one to the other.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "My, uh, I mean you can address all this kind of things.",
                    "label": 0
                },
                {
                    "sent": "On the basis of.",
                    "label": 0
                },
                {
                    "sent": "We are studying this kind of things on the basis of this insight.",
                    "label": 0
                },
                {
                    "sent": "Are there more questions?",
                    "label": 0
                },
                {
                    "sent": "I have a very naive one, so you mentioned this experiments on rats on grid cells.",
                    "label": 0
                },
                {
                    "sent": "The most experiments and related experiments are there experiments on humans, especially kids.",
                    "label": 0
                },
                {
                    "sent": "Navigation so these are expected.",
                    "label": 0
                },
                {
                    "sent": "Well, the open discount of.",
                    "label": 0
                },
                {
                    "sent": "The subjects and the implant.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "There are some experiments on this, but these are done on for example, on patients to try to recover some disabilities.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "Especially in the motor cortex, there are examples.",
                    "label": 0
                },
                {
                    "sent": "There are experiments done in this way for, say, implants, artificial arts and controlling regaining control of artificial arts and things like this.",
                    "label": 0
                },
                {
                    "sent": "But, uh, but of course humans.",
                    "label": 0
                },
                {
                    "sent": "You cannot do experiments like this ones, so yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, so Professor Marcia will be here today and tomorrow.",
                    "label": 0
                },
                {
                    "sent": "So if anybody wants to talk to him, just let me know.",
                    "label": 0
                },
                {
                    "sent": "Let's thank him again.",
                    "label": 0
                }
            ]
        }
    }
}