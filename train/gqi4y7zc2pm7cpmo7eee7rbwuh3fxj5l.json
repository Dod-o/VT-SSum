{
    "id": "gqi4y7zc2pm7cpmo7eee7rbwuh3fxj5l",
    "title": "KE4IR: Knowledge Extraction for Information Retrieval",
    "info": {
        "author": [
            "Marco Rospocher, Bruno Kessler Foundation"
        ],
        "published": "July 28, 2016",
        "recorded": "June 2016",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2016_rospocher_information_retrieval/",
    "segmentation": [
        [
            "OK, so good morning everybody.",
            "My name is Marcos poker.",
            "I'm are such scientist at from the cinema Casler FBC in Trento, Italy.",
            "And today I will present your work quoted with some colleagues at FBC about Keefer about exploiting knowledge extraction techniques for information retrieval."
        ],
        [
            "So indeed, the main purpose of this talk is to convince you that the performances of the well known document retrieval tasks, which basically consist in retrieving the most relevant documents in a collection for a given user query, can be significantly improved.",
            "Applying state of the art knowledge extraction techniques."
        ],
        [
            "So here's the outline of the talk.",
            "I start by formulating the problem and the motivation behind the work.",
            "Then I present key for our knowledge, extraction power, the information retrieval approach, and then I commend the results and of the evaluation we conducted to assess the performances and the benefits of Kiefer.",
            "So."
        ],
        [
            "Document Retrieval is a well known information retrieval tasks where there's a document collection, and for any given user query, like astronomers, influenced by Gauss, you have to find all the relevant documents in the collection and you want to sort them from the most relevant to the least relevant one."
        ],
        [
            "This task has been extensively studied in the literature.",
            "Typically, traditional information retrieval system, what they do, they compare the terms in the query and the terms in the documents.",
            "In some cases these terms are expanded to include also synonyms, related terms or even ontology concepts taken from our domain ontology.",
            "These traditional information retrieval systems tend to suffer or some shortcomings.",
            "First of all, relevant documents may not contain necessarily all the terms of the query.",
            "So if we think to the previous example we shown the astronomers influenced by Gauss query, a document might be about a very famous astronomers influenced by Gauss, but a strong number might not mention that all in the document.",
            "Similarly, document not particularly relevant might be ranked higher than relevant documents just because they contain all the three terms.",
            "But potentially in a totally unrelated way, like if I have a document about an astronomer born century before Gauss, but influenced by someone else like Leonardo, but containing the three terms.",
            "Over my query."
        ],
        [
            "The approach that we proposed, which is called Kiefer, which stands for knowledge extraction for information retrieval, complements the textural term typically used by traditional information retrieval system with semantic terms extracted by applying knowledge extraction techniques on the query and on the document text.",
            "So, given the query of our running example, this consistent augmenting the textual term, which typically are stemmed version of the word used in the in the documents.",
            "With semantic terms coming by, applying knowledge extraction techniques and reaching this knowledge extracted with three post coming from relevant linked open data source background knowledge information such as the UI of entities mentioned in the in the text type implicitly or explicitly mentioned in the text, semantic frames describing events or energy relation in the text, temporal information and so on, and so forth."
        ],
        [
            "As said, these semantic terms can be extracted by applying knowledge extraction techniques which basically identifies mentions.",
            "That is things snippet of text denoting something of interest, which could be an entity and events or relation from each mention, a set of semantic terms can be extracted.",
            "So if for example we have a named entity, by disambiguating it we can retrieve the UI and then exploiting the linked open data properties attached to that.",
            "You are I.",
            "We can obtain also type or even temporal information.",
            "Similarly, semantic terms might be derived from multiple mentioned within the same documents and you have to take that inform that thing into consideration.",
            "We are when you are computing the relevance of a semantic terms for a given document."
        ],
        [
            "So let's have a look more in details about the different typology of semantic terms.",
            "We are considering our approach what we call the semantic layers.",
            "The first layer is the UI layer, and it basically deals with the named entities mentioned in the text, and disambiguated with respect to relevant background knowledge resources such as DB pedia.",
            "At these terms are typically extracted using NLP tools for named entity recognition and classifications, entity linking, possibly supported by Coreference or solution.",
            "In our example, it means basically to add the term corresponding to the UI of the pedia DVP entity corresponding to Gauss."
        ],
        [
            "The second layer is the type player, and it deals with the ontology concept implicitly or explicitly mentioned in the text.",
            "So explicitly like in the case of common nouns, such as astronomers that can be disambiguated against war, not using word sense disambiguation techniques, and then mapped to relevant types in ontologies like Yahoo, for example.",
            "Or implicitly, like in the case of Gauss of named entities in general and in the example in the case of Gauss, where we can exploit the linking and then the types associated to that disambiguated entity in the in the linked open data cloud.",
            "And here again, we can, for example, exploit the types coming from the YAGO taxonomy.",
            "Of course, multiple types can be attached to an entities, and even you can use the supertype in the taxonomy of Jago.",
            "Two, you can import that super those super types, and in fact we do use them in the in our approach."
        ],
        [
            "The third layer is the frame layer, and this with the extraction of star shaped structure representing events or energy relations like influenced in our in this example that might have a certain frame type like for instance subjective influence from frame base.",
            "And play with participants one or more like a Gauss's astronomer, which plays a specific semantic role in the context of that frame.",
            "Semantic frames which can be extracted using NLP tools for semantic role labeling and then disambiguated against ontological resources available such as frame base, provides additional information that might help in matching the query and the documents more precisely.",
            "So the problem now is how do we map this Starship structure too?",
            "Semantic terms that it is what we are considering.",
            "Different approaches can be applied and in our current version of the work what we do is that we build couples formed by the frame type and the participant in the in the in the semantic frames.",
            "So in this case for example we have the couples with the subjective influence type from frame base and the pedia UI or Gauss.",
            "And we are restricting for the current version to couples where the participant is actually a named entity.",
            "That we were able to disambiguate."
        ],
        [
            "The 4th and final layer is the time layer and consist of temporal values.",
            "These temporal values can be implicitly mentioned in the text.",
            "We are some property associated to disambiguate are named entities that may occur in the text, like in the case of Gauss from DB Pedia.",
            "We can extract, for example, temporal information regarding to that entity, like the birth date or they might be explicitly mentioned in the text.",
            "Like if in our.",
            "In time expression, basically like if in our example we had acting century in front of astronomer.",
            "In this latter case this information can be extracted via tool for temporal expression recognition and normalization an and we represent the information coming from these terms in different granularities.",
            "So to be able to match both precise and let's say more fuzzy comparison between temporal values.",
            "So in this case for example we.",
            "Can derive information of different granularities from centuries down.",
            "Even today's if this information is available."
        ],
        [
            "Also, just recap, what we do is that we compliment the textural term that typically are extracted by are exploited by information retrieval systems.",
            "You see, for example, the standard version of astronomer influenced and Gauss with the semantic terms which are extracted by analyzing the queries with state of the art, knowledge extraction techniques and you opt in terms like DP, yoga house or century 17 or some semantic frames.",
            "So as you can immediately grasp, perform the from the table.",
            "We're enlarging the the terms considered for the matching quite a lot because we are moving from 3 terms in this particular example to a total of 47."
        ],
        [
            "So now how do we compare the queries and the documents understand which documents are relevant for a given query?",
            "So what we do is that we exploit an adaptation of the well known vector space model where basically documents are query and are seen as vector of terms and to compute the similarity you basically compute this color product between the two vectors and the similarity tells you if a document is relevant.",
            "If the value is greater than zero.",
            "And of course you can use.",
            "The value that you obtained by ranking the documents for a given query.",
            "These vectors in our specific case are basically composed by combining the information by concatenating the information coming from different layer, including all the information that both the text and information and the semantic information extracted."
        ],
        [
            "And more precisely, we are using three ingredients for computing them.",
            "The term frequency, which accounts for the frequency of the term in the text, the inverse document frequency, which accounts for the frequency of the term in the Word document and await, which is used to balance basically the impact of the textual and the semantic content extracted.",
            "That is, for each semantic layer, for each layer, even the text for one we can decide how much data layer contributes to.",
            "This seems like computing the similarity between the query and the document."
        ],
        [
            "So if we take our example, what we do is that we have the term frequency.",
            "We multiply it by the inverse document frequency, we multiply again it by the weight information that I mentioned, and I will comment a little bit more later on, and then we obtained the query that is used and for the for computing the similarity."
        ],
        [
            "So these terms for quiz and documents are practically computed using the pipeline shown here in the in the slide.",
            "So on the top part we're using the standard techniques for tokenization.",
            "Upward filtering and stemming.",
            "We're actually using Apache Lucene for this kind of processing on the top part, and we're complementing it with the lower part where the semantic analysis performed, so there is a first.",
            "We apply a tool for knowledge extraction that performs all the task I previously mentioned.",
            "We translate basically the text into a knowledge graph.",
            "Then we reached it using available linked open data sources such as DB pedia, Yagor frame base, and then we query this graph to obtain the semantic terms that are relevant.",
            "For our for our work, for the."
        ],
        [
            "Searching for the knowledge extraction part, we're using Pikes, Pikes is a state of the art knowledge extraction tool that basically transform a piece of text into an RDF knowledge graph centered around the notion of semantic frames.",
            "It works in two phases.",
            "In the first phase, called the linguistic feature extraction, it basically applies a number of tasks are number of tools for NLP processing for named entity recognition and normalization, temperation temporary suppression, recognition, normalization, coreference resolution, semantic role labeling versus disambiguation.",
            "To obtain a graph of mention that is a graph of snippets of text to which linguistic annotation are attached coming from this.",
            "Watching this is performed and then in the second phase we're distilling this mention graph into the final knowledge graph, which conveys in a concise and compact way the knowledge contained in the original text.",
            "And this second part is performed using some sparkle rules like approach by basically reinterpreting the information that was extracted by the linguistic features."
        ],
        [
            "Extraction.",
            "So besides performing quite well according to the evaluation that we conducted, parks is the only tool available to the best of our knowledge that exposed the semantic frames extracted from text according to frame base, which is our recent ontologies released, I think last year it was presented this year last year at the museum.",
            "The parks adopt A very modular architecture in which you can basically use different tools for the same, even for the same task.",
            "In fact, in the current version of the tool, we are using different semantic role labeling for doing the semantic role labeling, part maiden Semaphore and we are combining and complementing the information coming from this annotation, and actually, this combination helps improving the performance is in the extraction.",
            "All the output that Pikes produces exposing RDF, including the intermediate mention graph, and actually we use those for name graph for tracing the mansion from which each piece of knowledge was extracted from the text.",
            "And it works quite well also in terms of scalability in the sense that in the current implementation is able to process 7700 thousand tokens per per hour."
        ],
        [
            "So for more details on Pikes Code evaluation results and demos, you can go to the bikes website which is shown in this slide at Pikes Dot FBC Dot U.",
            "So apparently also packs website is quite effective.",
            "Some of our competitors are carbon copied.",
            "Our HTML for the tool but anyway."
        ],
        [
            "On the website you can also play with the online demo which provides some graphical way to navigate the knowledge extracted from the text as well away too."
        ],
        [
            "Navigate the linguistic annotation that were produced."
        ],
        [
            "And you can also see all the triples if you are interested.",
            "Actually quotes that are extracted from the text."
        ],
        [
            "So back to the keeper and revaluation of Kiefer.",
            "We applied key funds on a recently released a document collection that was built from the Vista Blog.",
            "It consists of 331 documents and 35 queries.",
            "Together with the relevance judgment, which are were manually validated by by human raters, actually these judgments are organized.",
            "Score from our our scores from one to five, where one means that the document is totally relevant for a query.",
            "An five that is regular relevant.",
            "One of the peculiarity of this document collection is that queries are quite diverse in nature, so you have keyword like queries like Romanticism.",
            "But you have also queried that requires two more semantic analysis to be properly served to be interpreted them like aviation pioneers publications or the query that we showed before the astronomers influenced by Gauss query."
        ],
        [
            "We compare the relevant documents returned by Kiefer, which with two baseline the Google Custom Search API and basically the version of Kiefer stripped off the whole semantic part.",
            "So considering only the textual part, which is basically assimilable to the Apache Lucene processing that you can get.",
            "Besides precision AT-15 in 10, we compute the standard metrics for information retrieval.",
            "Mean average precision map, and normalized discounted cumulative gain.",
            "N DCG.",
            "Both Amber Maps accounts for whether the documents relevant documents are returned by the query independently of the relevance score.",
            "That is for map document is relevant for a query or not relevant while and ECG takes also into account, the order in which these documents are returned and the relevance score of the documents return."
        ],
        [
            "So I previously mentioned that in our approach we can balance the the contribution of the textual part and the semantic part for devaluation.",
            "We actually took a quite neutral position, so we wait that extra in the semantic content equally 0.5 and which means that each semantic layer was actually accordingly waited in the in the processing.",
            "So all of the four layers are weighted equally.",
            "So how does Kiefer performs?",
            "So here we have the we have the results, so the first things that you can see is that there is a huge difference in performance is against the Google Custom Search API.",
            "This, in some sense shouldn't surprise too much because our interpretation is that Google is heavily meant.",
            "Large scale web scale web information retrieval, so it's in a situation where you have many documents returned for a query, so it's more, let's say in our opinion is more tuna toward precision, while in our context of devaluation also record is important in mean returning, there are a lot of relevant documents.",
            "But if you compare against the textual baseline, what you can see is that the the semantic information helps in performing consistently better than the textual baseline.",
            "Actually, the results that we get are statistically significant.",
            "So we can conclude that in fact, knowledge extraction techniques can helps improving the performance of the document retrieval task."
        ],
        [
            "So we also perform an analysis considering different combination of the layers, so enabling and disabling some of the layers in our approach to see if there are layers that are more effective.",
            "Another one in the performances and here you can see that the best one is when you consider all the four layer.",
            "So time your I frame and time you can also see that you are.",
            "I typically if you look at the map is always there when you have the best scoring values.",
            "What I want to remark it.",
            "Is that any combination that use the semantic information is better than the textual baseline in our experiment?"
        ],
        [
            "So we also conducted analyzed query by query to understand more in details what happened in analyzing them.",
            "And there's all these tests in the paper, but if you want to the general outcome or that type and time typing you are I are more frequently available in the query when you analyze a query, but they are they impact on the results is not always positive.",
            "So there are cases where you get penalized.",
            "He, under contrary, when framing timer available, this always results in an improvement of the performances.",
            "So if there is enough structure in the in the query, the performance is maybe quite a lot improved.",
            "We also close to look at some examples to see what happened, especially when there are big differences with respect to the textual baseline.",
            "So if you take an Apollo Russian campaign query, the results are quite good.",
            "Becausw Napoleon was correctly linked to.",
            "So it sent it in DB pedia and type it type information was used positively years.",
            "On the contrary, modern age English literature does not perform very well because we have several mentions in documents like English society or English Medic Alert that for some reason were linked to English literature."
        ],
        [
            "So the last content slide I promise to stop is the is the analysis of the balancing between the textual and the semantic content.",
            "So I present mentioned this.",
            "So this curve the blue line is the text or baseline and the red line is basically the changing of the map value when balancing differently the textual in the semantic part O means only textual information is used and new semantic information on the other end only semantic information.",
            "You know text on information.",
            "So for the evaluation we were at 0.5, so we took the neutral position, but the August map value can actually be achieved at zero point 0.65, meaning that if you wait to double the semantic content with respect to the text or content for this particular data collection, the performance are very good.",
            "Above 90 Interestingly, above 0.92 at the performance go very bad.",
            "So if I refresh Brian May the The thing is that probably if you use too much semantic information, this is a performance killer.",
            "So and we haven't did too much on this particular aspect, but we believe that the reason could be that when you are relying too much on the semantic information extracted by the knowledge processing, you are also affected by all the errors and.",
            "Performances of the Knowledge story are using.",
            "So all the."
        ],
        [
            "Material devaluation, the datasets, everything the codes for the running devaluation is available on the website that you have the euro either.",
            "So very."
        ],
        [
            "Quickly conclusion, exploiting the knowledge extraction techniques can actually improve the performances of information retrieval.",
            "The value of Maps and ECG that we obtained.",
            "Currently allow us to think about deploying this in real world situation, at least for small to medium size document collection.",
            "We are working right now on trying the work on larger document collection.",
            "We are currently processing the track WT10G which is a 1.6 million document collection and we want to see the performance is also on this larger corpus.",
            "One other thing that we notice is that maybe the performances can be improved quite a lot if you tune a little bit more.",
            "Your knowledge, extraction pattern, precision that rather than recall and finally we want to play a little bit with domain annotations.",
            "So trying to use the approach in some domains using some domain resources which has an impact on the processing because we are currently using.",
            "For example, entity linkers that are tide to DB pedia.",
            "Here we might need something a little bit more on that.",
            "So that's it.",
            "Thanks for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so good morning everybody.",
                    "label": 0
                },
                {
                    "sent": "My name is Marcos poker.",
                    "label": 0
                },
                {
                    "sent": "I'm are such scientist at from the cinema Casler FBC in Trento, Italy.",
                    "label": 0
                },
                {
                    "sent": "And today I will present your work quoted with some colleagues at FBC about Keefer about exploiting knowledge extraction techniques for information retrieval.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So indeed, the main purpose of this talk is to convince you that the performances of the well known document retrieval tasks, which basically consist in retrieving the most relevant documents in a collection for a given user query, can be significantly improved.",
                    "label": 0
                },
                {
                    "sent": "Applying state of the art knowledge extraction techniques.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the outline of the talk.",
                    "label": 0
                },
                {
                    "sent": "I start by formulating the problem and the motivation behind the work.",
                    "label": 0
                },
                {
                    "sent": "Then I present key for our knowledge, extraction power, the information retrieval approach, and then I commend the results and of the evaluation we conducted to assess the performances and the benefits of Kiefer.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Document Retrieval is a well known information retrieval tasks where there's a document collection, and for any given user query, like astronomers, influenced by Gauss, you have to find all the relevant documents in the collection and you want to sort them from the most relevant to the least relevant one.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This task has been extensively studied in the literature.",
                    "label": 0
                },
                {
                    "sent": "Typically, traditional information retrieval system, what they do, they compare the terms in the query and the terms in the documents.",
                    "label": 0
                },
                {
                    "sent": "In some cases these terms are expanded to include also synonyms, related terms or even ontology concepts taken from our domain ontology.",
                    "label": 1
                },
                {
                    "sent": "These traditional information retrieval systems tend to suffer or some shortcomings.",
                    "label": 0
                },
                {
                    "sent": "First of all, relevant documents may not contain necessarily all the terms of the query.",
                    "label": 1
                },
                {
                    "sent": "So if we think to the previous example we shown the astronomers influenced by Gauss query, a document might be about a very famous astronomers influenced by Gauss, but a strong number might not mention that all in the document.",
                    "label": 0
                },
                {
                    "sent": "Similarly, document not particularly relevant might be ranked higher than relevant documents just because they contain all the three terms.",
                    "label": 0
                },
                {
                    "sent": "But potentially in a totally unrelated way, like if I have a document about an astronomer born century before Gauss, but influenced by someone else like Leonardo, but containing the three terms.",
                    "label": 0
                },
                {
                    "sent": "Over my query.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The approach that we proposed, which is called Kiefer, which stands for knowledge extraction for information retrieval, complements the textural term typically used by traditional information retrieval system with semantic terms extracted by applying knowledge extraction techniques on the query and on the document text.",
                    "label": 1
                },
                {
                    "sent": "So, given the query of our running example, this consistent augmenting the textual term, which typically are stemmed version of the word used in the in the documents.",
                    "label": 0
                },
                {
                    "sent": "With semantic terms coming by, applying knowledge extraction techniques and reaching this knowledge extracted with three post coming from relevant linked open data source background knowledge information such as the UI of entities mentioned in the in the text type implicitly or explicitly mentioned in the text, semantic frames describing events or energy relation in the text, temporal information and so on, and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As said, these semantic terms can be extracted by applying knowledge extraction techniques which basically identifies mentions.",
                    "label": 0
                },
                {
                    "sent": "That is things snippet of text denoting something of interest, which could be an entity and events or relation from each mention, a set of semantic terms can be extracted.",
                    "label": 1
                },
                {
                    "sent": "So if for example we have a named entity, by disambiguating it we can retrieve the UI and then exploiting the linked open data properties attached to that.",
                    "label": 0
                },
                {
                    "sent": "You are I.",
                    "label": 0
                },
                {
                    "sent": "We can obtain also type or even temporal information.",
                    "label": 0
                },
                {
                    "sent": "Similarly, semantic terms might be derived from multiple mentioned within the same documents and you have to take that inform that thing into consideration.",
                    "label": 1
                },
                {
                    "sent": "We are when you are computing the relevance of a semantic terms for a given document.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's have a look more in details about the different typology of semantic terms.",
                    "label": 0
                },
                {
                    "sent": "We are considering our approach what we call the semantic layers.",
                    "label": 1
                },
                {
                    "sent": "The first layer is the UI layer, and it basically deals with the named entities mentioned in the text, and disambiguated with respect to relevant background knowledge resources such as DB pedia.",
                    "label": 0
                },
                {
                    "sent": "At these terms are typically extracted using NLP tools for named entity recognition and classifications, entity linking, possibly supported by Coreference or solution.",
                    "label": 0
                },
                {
                    "sent": "In our example, it means basically to add the term corresponding to the UI of the pedia DVP entity corresponding to Gauss.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second layer is the type player, and it deals with the ontology concept implicitly or explicitly mentioned in the text.",
                    "label": 0
                },
                {
                    "sent": "So explicitly like in the case of common nouns, such as astronomers that can be disambiguated against war, not using word sense disambiguation techniques, and then mapped to relevant types in ontologies like Yahoo, for example.",
                    "label": 0
                },
                {
                    "sent": "Or implicitly, like in the case of Gauss of named entities in general and in the example in the case of Gauss, where we can exploit the linking and then the types associated to that disambiguated entity in the in the linked open data cloud.",
                    "label": 0
                },
                {
                    "sent": "And here again, we can, for example, exploit the types coming from the YAGO taxonomy.",
                    "label": 0
                },
                {
                    "sent": "Of course, multiple types can be attached to an entities, and even you can use the supertype in the taxonomy of Jago.",
                    "label": 0
                },
                {
                    "sent": "Two, you can import that super those super types, and in fact we do use them in the in our approach.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The third layer is the frame layer, and this with the extraction of star shaped structure representing events or energy relations like influenced in our in this example that might have a certain frame type like for instance subjective influence from frame base.",
                    "label": 0
                },
                {
                    "sent": "And play with participants one or more like a Gauss's astronomer, which plays a specific semantic role in the context of that frame.",
                    "label": 0
                },
                {
                    "sent": "Semantic frames which can be extracted using NLP tools for semantic role labeling and then disambiguated against ontological resources available such as frame base, provides additional information that might help in matching the query and the documents more precisely.",
                    "label": 0
                },
                {
                    "sent": "So the problem now is how do we map this Starship structure too?",
                    "label": 0
                },
                {
                    "sent": "Semantic terms that it is what we are considering.",
                    "label": 0
                },
                {
                    "sent": "Different approaches can be applied and in our current version of the work what we do is that we build couples formed by the frame type and the participant in the in the in the semantic frames.",
                    "label": 0
                },
                {
                    "sent": "So in this case for example we have the couples with the subjective influence type from frame base and the pedia UI or Gauss.",
                    "label": 0
                },
                {
                    "sent": "And we are restricting for the current version to couples where the participant is actually a named entity.",
                    "label": 0
                },
                {
                    "sent": "That we were able to disambiguate.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The 4th and final layer is the time layer and consist of temporal values.",
                    "label": 0
                },
                {
                    "sent": "These temporal values can be implicitly mentioned in the text.",
                    "label": 0
                },
                {
                    "sent": "We are some property associated to disambiguate are named entities that may occur in the text, like in the case of Gauss from DB Pedia.",
                    "label": 0
                },
                {
                    "sent": "We can extract, for example, temporal information regarding to that entity, like the birth date or they might be explicitly mentioned in the text.",
                    "label": 0
                },
                {
                    "sent": "Like if in our.",
                    "label": 0
                },
                {
                    "sent": "In time expression, basically like if in our example we had acting century in front of astronomer.",
                    "label": 0
                },
                {
                    "sent": "In this latter case this information can be extracted via tool for temporal expression recognition and normalization an and we represent the information coming from these terms in different granularities.",
                    "label": 0
                },
                {
                    "sent": "So to be able to match both precise and let's say more fuzzy comparison between temporal values.",
                    "label": 0
                },
                {
                    "sent": "So in this case for example we.",
                    "label": 0
                },
                {
                    "sent": "Can derive information of different granularities from centuries down.",
                    "label": 0
                },
                {
                    "sent": "Even today's if this information is available.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, just recap, what we do is that we compliment the textural term that typically are extracted by are exploited by information retrieval systems.",
                    "label": 0
                },
                {
                    "sent": "You see, for example, the standard version of astronomer influenced and Gauss with the semantic terms which are extracted by analyzing the queries with state of the art, knowledge extraction techniques and you opt in terms like DP, yoga house or century 17 or some semantic frames.",
                    "label": 0
                },
                {
                    "sent": "So as you can immediately grasp, perform the from the table.",
                    "label": 0
                },
                {
                    "sent": "We're enlarging the the terms considered for the matching quite a lot because we are moving from 3 terms in this particular example to a total of 47.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now how do we compare the queries and the documents understand which documents are relevant for a given query?",
                    "label": 1
                },
                {
                    "sent": "So what we do is that we exploit an adaptation of the well known vector space model where basically documents are query and are seen as vector of terms and to compute the similarity you basically compute this color product between the two vectors and the similarity tells you if a document is relevant.",
                    "label": 1
                },
                {
                    "sent": "If the value is greater than zero.",
                    "label": 0
                },
                {
                    "sent": "And of course you can use.",
                    "label": 0
                },
                {
                    "sent": "The value that you obtained by ranking the documents for a given query.",
                    "label": 0
                },
                {
                    "sent": "These vectors in our specific case are basically composed by combining the information by concatenating the information coming from different layer, including all the information that both the text and information and the semantic information extracted.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And more precisely, we are using three ingredients for computing them.",
                    "label": 1
                },
                {
                    "sent": "The term frequency, which accounts for the frequency of the term in the text, the inverse document frequency, which accounts for the frequency of the term in the Word document and await, which is used to balance basically the impact of the textual and the semantic content extracted.",
                    "label": 1
                },
                {
                    "sent": "That is, for each semantic layer, for each layer, even the text for one we can decide how much data layer contributes to.",
                    "label": 0
                },
                {
                    "sent": "This seems like computing the similarity between the query and the document.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we take our example, what we do is that we have the term frequency.",
                    "label": 0
                },
                {
                    "sent": "We multiply it by the inverse document frequency, we multiply again it by the weight information that I mentioned, and I will comment a little bit more later on, and then we obtained the query that is used and for the for computing the similarity.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these terms for quiz and documents are practically computed using the pipeline shown here in the in the slide.",
                    "label": 0
                },
                {
                    "sent": "So on the top part we're using the standard techniques for tokenization.",
                    "label": 0
                },
                {
                    "sent": "Upward filtering and stemming.",
                    "label": 0
                },
                {
                    "sent": "We're actually using Apache Lucene for this kind of processing on the top part, and we're complementing it with the lower part where the semantic analysis performed, so there is a first.",
                    "label": 0
                },
                {
                    "sent": "We apply a tool for knowledge extraction that performs all the task I previously mentioned.",
                    "label": 1
                },
                {
                    "sent": "We translate basically the text into a knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "Then we reached it using available linked open data sources such as DB pedia, Yagor frame base, and then we query this graph to obtain the semantic terms that are relevant.",
                    "label": 0
                },
                {
                    "sent": "For our for our work, for the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Searching for the knowledge extraction part, we're using Pikes, Pikes is a state of the art knowledge extraction tool that basically transform a piece of text into an RDF knowledge graph centered around the notion of semantic frames.",
                    "label": 0
                },
                {
                    "sent": "It works in two phases.",
                    "label": 0
                },
                {
                    "sent": "In the first phase, called the linguistic feature extraction, it basically applies a number of tasks are number of tools for NLP processing for named entity recognition and normalization, temperation temporary suppression, recognition, normalization, coreference resolution, semantic role labeling versus disambiguation.",
                    "label": 1
                },
                {
                    "sent": "To obtain a graph of mention that is a graph of snippets of text to which linguistic annotation are attached coming from this.",
                    "label": 0
                },
                {
                    "sent": "Watching this is performed and then in the second phase we're distilling this mention graph into the final knowledge graph, which conveys in a concise and compact way the knowledge contained in the original text.",
                    "label": 0
                },
                {
                    "sent": "And this second part is performed using some sparkle rules like approach by basically reinterpreting the information that was extracted by the linguistic features.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Extraction.",
                    "label": 0
                },
                {
                    "sent": "So besides performing quite well according to the evaluation that we conducted, parks is the only tool available to the best of our knowledge that exposed the semantic frames extracted from text according to frame base, which is our recent ontologies released, I think last year it was presented this year last year at the museum.",
                    "label": 0
                },
                {
                    "sent": "The parks adopt A very modular architecture in which you can basically use different tools for the same, even for the same task.",
                    "label": 0
                },
                {
                    "sent": "In fact, in the current version of the tool, we are using different semantic role labeling for doing the semantic role labeling, part maiden Semaphore and we are combining and complementing the information coming from this annotation, and actually, this combination helps improving the performance is in the extraction.",
                    "label": 0
                },
                {
                    "sent": "All the output that Pikes produces exposing RDF, including the intermediate mention graph, and actually we use those for name graph for tracing the mansion from which each piece of knowledge was extracted from the text.",
                    "label": 0
                },
                {
                    "sent": "And it works quite well also in terms of scalability in the sense that in the current implementation is able to process 7700 thousand tokens per per hour.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for more details on Pikes Code evaluation results and demos, you can go to the bikes website which is shown in this slide at Pikes Dot FBC Dot U.",
                    "label": 0
                },
                {
                    "sent": "So apparently also packs website is quite effective.",
                    "label": 0
                },
                {
                    "sent": "Some of our competitors are carbon copied.",
                    "label": 0
                },
                {
                    "sent": "Our HTML for the tool but anyway.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the website you can also play with the online demo which provides some graphical way to navigate the knowledge extracted from the text as well away too.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Navigate the linguistic annotation that were produced.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can also see all the triples if you are interested.",
                    "label": 0
                },
                {
                    "sent": "Actually quotes that are extracted from the text.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So back to the keeper and revaluation of Kiefer.",
                    "label": 0
                },
                {
                    "sent": "We applied key funds on a recently released a document collection that was built from the Vista Blog.",
                    "label": 0
                },
                {
                    "sent": "It consists of 331 documents and 35 queries.",
                    "label": 1
                },
                {
                    "sent": "Together with the relevance judgment, which are were manually validated by by human raters, actually these judgments are organized.",
                    "label": 0
                },
                {
                    "sent": "Score from our our scores from one to five, where one means that the document is totally relevant for a query.",
                    "label": 0
                },
                {
                    "sent": "An five that is regular relevant.",
                    "label": 0
                },
                {
                    "sent": "One of the peculiarity of this document collection is that queries are quite diverse in nature, so you have keyword like queries like Romanticism.",
                    "label": 0
                },
                {
                    "sent": "But you have also queried that requires two more semantic analysis to be properly served to be interpreted them like aviation pioneers publications or the query that we showed before the astronomers influenced by Gauss query.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We compare the relevant documents returned by Kiefer, which with two baseline the Google Custom Search API and basically the version of Kiefer stripped off the whole semantic part.",
                    "label": 1
                },
                {
                    "sent": "So considering only the textual part, which is basically assimilable to the Apache Lucene processing that you can get.",
                    "label": 0
                },
                {
                    "sent": "Besides precision AT-15 in 10, we compute the standard metrics for information retrieval.",
                    "label": 0
                },
                {
                    "sent": "Mean average precision map, and normalized discounted cumulative gain.",
                    "label": 0
                },
                {
                    "sent": "N DCG.",
                    "label": 0
                },
                {
                    "sent": "Both Amber Maps accounts for whether the documents relevant documents are returned by the query independently of the relevance score.",
                    "label": 0
                },
                {
                    "sent": "That is for map document is relevant for a query or not relevant while and ECG takes also into account, the order in which these documents are returned and the relevance score of the documents return.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I previously mentioned that in our approach we can balance the the contribution of the textual part and the semantic part for devaluation.",
                    "label": 0
                },
                {
                    "sent": "We actually took a quite neutral position, so we wait that extra in the semantic content equally 0.5 and which means that each semantic layer was actually accordingly waited in the in the processing.",
                    "label": 0
                },
                {
                    "sent": "So all of the four layers are weighted equally.",
                    "label": 0
                },
                {
                    "sent": "So how does Kiefer performs?",
                    "label": 0
                },
                {
                    "sent": "So here we have the we have the results, so the first things that you can see is that there is a huge difference in performance is against the Google Custom Search API.",
                    "label": 0
                },
                {
                    "sent": "This, in some sense shouldn't surprise too much because our interpretation is that Google is heavily meant.",
                    "label": 0
                },
                {
                    "sent": "Large scale web scale web information retrieval, so it's in a situation where you have many documents returned for a query, so it's more, let's say in our opinion is more tuna toward precision, while in our context of devaluation also record is important in mean returning, there are a lot of relevant documents.",
                    "label": 0
                },
                {
                    "sent": "But if you compare against the textual baseline, what you can see is that the the semantic information helps in performing consistently better than the textual baseline.",
                    "label": 0
                },
                {
                    "sent": "Actually, the results that we get are statistically significant.",
                    "label": 0
                },
                {
                    "sent": "So we can conclude that in fact, knowledge extraction techniques can helps improving the performance of the document retrieval task.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we also perform an analysis considering different combination of the layers, so enabling and disabling some of the layers in our approach to see if there are layers that are more effective.",
                    "label": 0
                },
                {
                    "sent": "Another one in the performances and here you can see that the best one is when you consider all the four layer.",
                    "label": 0
                },
                {
                    "sent": "So time your I frame and time you can also see that you are.",
                    "label": 0
                },
                {
                    "sent": "I typically if you look at the map is always there when you have the best scoring values.",
                    "label": 0
                },
                {
                    "sent": "What I want to remark it.",
                    "label": 0
                },
                {
                    "sent": "Is that any combination that use the semantic information is better than the textual baseline in our experiment?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we also conducted analyzed query by query to understand more in details what happened in analyzing them.",
                    "label": 0
                },
                {
                    "sent": "And there's all these tests in the paper, but if you want to the general outcome or that type and time typing you are I are more frequently available in the query when you analyze a query, but they are they impact on the results is not always positive.",
                    "label": 0
                },
                {
                    "sent": "So there are cases where you get penalized.",
                    "label": 0
                },
                {
                    "sent": "He, under contrary, when framing timer available, this always results in an improvement of the performances.",
                    "label": 0
                },
                {
                    "sent": "So if there is enough structure in the in the query, the performance is maybe quite a lot improved.",
                    "label": 0
                },
                {
                    "sent": "We also close to look at some examples to see what happened, especially when there are big differences with respect to the textual baseline.",
                    "label": 0
                },
                {
                    "sent": "So if you take an Apollo Russian campaign query, the results are quite good.",
                    "label": 0
                },
                {
                    "sent": "Becausw Napoleon was correctly linked to.",
                    "label": 0
                },
                {
                    "sent": "So it sent it in DB pedia and type it type information was used positively years.",
                    "label": 0
                },
                {
                    "sent": "On the contrary, modern age English literature does not perform very well because we have several mentions in documents like English society or English Medic Alert that for some reason were linked to English literature.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the last content slide I promise to stop is the is the analysis of the balancing between the textual and the semantic content.",
                    "label": 0
                },
                {
                    "sent": "So I present mentioned this.",
                    "label": 0
                },
                {
                    "sent": "So this curve the blue line is the text or baseline and the red line is basically the changing of the map value when balancing differently the textual in the semantic part O means only textual information is used and new semantic information on the other end only semantic information.",
                    "label": 0
                },
                {
                    "sent": "You know text on information.",
                    "label": 0
                },
                {
                    "sent": "So for the evaluation we were at 0.5, so we took the neutral position, but the August map value can actually be achieved at zero point 0.65, meaning that if you wait to double the semantic content with respect to the text or content for this particular data collection, the performance are very good.",
                    "label": 0
                },
                {
                    "sent": "Above 90 Interestingly, above 0.92 at the performance go very bad.",
                    "label": 0
                },
                {
                    "sent": "So if I refresh Brian May the The thing is that probably if you use too much semantic information, this is a performance killer.",
                    "label": 0
                },
                {
                    "sent": "So and we haven't did too much on this particular aspect, but we believe that the reason could be that when you are relying too much on the semantic information extracted by the knowledge processing, you are also affected by all the errors and.",
                    "label": 0
                },
                {
                    "sent": "Performances of the Knowledge story are using.",
                    "label": 0
                },
                {
                    "sent": "So all the.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Material devaluation, the datasets, everything the codes for the running devaluation is available on the website that you have the euro either.",
                    "label": 0
                },
                {
                    "sent": "So very.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Quickly conclusion, exploiting the knowledge extraction techniques can actually improve the performances of information retrieval.",
                    "label": 1
                },
                {
                    "sent": "The value of Maps and ECG that we obtained.",
                    "label": 0
                },
                {
                    "sent": "Currently allow us to think about deploying this in real world situation, at least for small to medium size document collection.",
                    "label": 1
                },
                {
                    "sent": "We are working right now on trying the work on larger document collection.",
                    "label": 0
                },
                {
                    "sent": "We are currently processing the track WT10G which is a 1.6 million document collection and we want to see the performance is also on this larger corpus.",
                    "label": 0
                },
                {
                    "sent": "One other thing that we notice is that maybe the performances can be improved quite a lot if you tune a little bit more.",
                    "label": 0
                },
                {
                    "sent": "Your knowledge, extraction pattern, precision that rather than recall and finally we want to play a little bit with domain annotations.",
                    "label": 0
                },
                {
                    "sent": "So trying to use the approach in some domains using some domain resources which has an impact on the processing because we are currently using.",
                    "label": 0
                },
                {
                    "sent": "For example, entity linkers that are tide to DB pedia.",
                    "label": 0
                },
                {
                    "sent": "Here we might need something a little bit more on that.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "Thanks for your attention.",
                    "label": 0
                }
            ]
        }
    }
}