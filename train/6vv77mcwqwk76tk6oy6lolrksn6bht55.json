{
    "id": "6vv77mcwqwk76tk6oy6lolrksn6bht55",
    "title": "A Convex Method for Locating Regions of Interest with Multi-Instance Learning",
    "info": {
        "author": [
            "Yu-Feng Li, LAMDA Group, Department of Computer Science and Technology, Nanjing University"
        ],
        "published": "Oct. 20, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Instance-based Learning"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd09_li_cmlrimil/",
    "segmentation": [
        [
            "So the next presentation will be given by family.",
            "02 and it's about the complex methods for locating regions of interest will be exactly.",
            "Thank you, good afternoon everyone, and if only this is a joint work with James called I will turn and do our job.",
            "The title of this presentation, it is convex mixels for local interest regions of interest with multiple Insta."
        ],
        [
            "Learning.",
            "First of all, let's briefly introduced multiple instance learning.",
            "Multiple interest earning is first proposed by the data rich in their AI Journal and multiple instance learning ends to multiple instances is quite different from traditional supervised learning.",
            "It tends to learn from the training set consists of bags where each batch contains multiple, many instances.",
            "In traditional multiple instance learning, assumption about is positive if it contains at least one positive.",
            "Instance otherwise it is a negative ad.",
            "So we may see the labels of training base are known, but the labels of the instance in the best unknown.",
            "So.",
            "However, in a multiple instance learning, identify the positive instance in the positive bias is a very important problems for multiple instances, the name 'cause it's very helpful to understanding the relationship between the label and input patterns.",
            "Besides, it also has some interesting."
        ],
        [
            "Applications for example, in reverent feedbacks of CBI are usually user is only interested in some regions of the image is recalled regions of interest our I.",
            "For example, there are several images of some set.",
            "Usually the user is only interested in this one, and this one and this one so identified this really regions of interesting is maybe maybe understanding the user more quickly.",
            "So.",
            "In fact, besides.",
            "Locating our eyes can could be users in the other area, such as the image screaming.",
            "For example in medical or literature applications, which requires to a fast scheming for a large amount of images.",
            "To detect the suspects area of the image.",
            "So if the desire is very desirable, if we can detect some regions of the image is if we can successfully detected regions of interest, and when the suspect images was was showing to the examiner so."
        ],
        [
            "The problems in this presentation is that how to develop an efficient and theoretical supported methods for locating our eyes.",
            "This goes through this presentation."
        ],
        [
            "Here is the outline of this presentation.",
            "I will first give some into brief introduction and then propose our methods and experimental results.",
            "Finally, I can."
        ],
        [
            "Curtis work so multiple instances, and as I mentioned before, is originally by former researcher research on a John activity prediction by the editor rich in their air Journal.",
            "Here each jumps some small molecule is working by the building to the target area.",
            "For each model create qualify which is qualified to make the jump.",
            "One of these shaved could tightly bound to the target area.",
            "So.",
            "But the American medical may have many alternative shapes, so the difficulty is that the biochemistry can only know the weather or medical is qualified or not.",
            "But do not know which shape corresponding to the qualification."
        ],
        [
            "So the idea in their paper is very simple.",
            "He expanded each shaped by the vector feature vector.",
            "I mean an instance, then amount OK becomes a bag of instance instance, so a bad is positive if it contains at least one positive instance.",
            "Otherwise the bad is negative.",
            "So the chemists Imagenes today only know the labels of the training base, but they do not know the instance of the labels in the training base."
        ],
        [
            "So this is the multiple instances learning.",
            "Currently there are various applications of multiple instances for image analysis, such as the image calibration, image retrieval and face detection, and computer aided medical.",
            "Well knows now that was."
        ],
        [
            "As for locating the Allies, there are also some related works.",
            "The first one is the diversity density and its variance.",
            "These methods can effectively located our eyes, but it may cause huge time complexity and overall overall optimization problem is non convex.",
            "So you may suffer from some local solutions.",
            "The other one is.",
            "OK, an hour methods proposed by Joe in the AIG HK 05 paper is very variation of sedition KMS, as proposed by one and Asuka in there SMLO 2000 paper.",
            "This method is very, very efficient, but they are wholly based on the heuristic search.",
            "The third type of methods is SVM basis in my source.",
            "Currently they're not.",
            "There are very few SVM methods.",
            "Focus on locating our eyes except my SVN.",
            "And my screen is efficient and effective to located hours, but the overall transition problem is still nonconvex, so it may still suffer some local solution.",
            "Our versus many focus on the SVM based methods, so let me briefly introduce the MI."
        ],
        [
            "Sweden.",
            "And my SVN is first is proposed by the injury in their NIPS paper the idea of MSV is very simple.",
            "This large modern principle, so.",
            "Suppose we have two positives.",
            "Anna two negative X.",
            "Each circle means the unlabeled instance.",
            "We do not know.",
            "So the more my SVN is trying to find.",
            "Finally, find the optimal have plans for the positive and negative such that the key instance for for the positive and negatives are.",
            "The margin of between then are maximized.",
            "Finally, the maximum prediction, the maximum or the most confident prediction of the positives are referred to the key instance or the our eyes.",
            "It's very simple idea for the Ms multiple instance I SVN.",
            "So let."
        ],
        [
            "Describe these problems more formula formally.",
            "So suppose we are given a set of training bags, be I iy up to the BNY and we're HBI is a bad.",
            "It contains multiple instance and then.",
            "And why is the label?",
            "As opposed to decision function, is a linear model.",
            "So the goal here is to learn the FF minimized structure.",
            "Risk functions such like this.",
            "Here the Omega is strictly monotonic increasing function which is always also refers as regularization term.",
            "The L here is a loss function.",
            "And the see here is the regulation parameter.",
            "So here there there has a maximum maximum operator.",
            "Here the main idea here is to separate the key instance.",
            "To separate the key instance in the positive and negative with large margin.",
            "So here so that becomes Max Max operator here."
        ],
        [
            "So if we consider the margin turn for the for the Omega and square hinge loss, then the ordinal optimization problem it becomes following.",
            "Here the C is a slight variables.",
            "So this however is a non convex problems becausw of the Max operator.",
            "Which may get stuck in local solution, so the main contribution of this work is.",
            "We propose a convex relaxation problems to solve such an nonconvex problem."
        ],
        [
            "So let me introduce our."
        ],
        [
            "Proposed makes us the first one.",
            "It is called an instance labeled key instance VM.",
            "By introducing some indicator variables D an XIJ, we can reformulate the original M ISBN's following here the Max operator for the positive band is represented by the this form and Max operator by the negative taxes as presented by illuminating all the other instance in the negative X as each one as a constraint in the optimization problem.",
            "So here the D it is is integral.",
            "It belongs to zero or one and the summary of the DJ in the bad is equal to 1.",
            "So and and a Lambda is a slight variable balanced side variables between the positive and negative X.",
            "So you may see that this kind of it can be proved that this kind of instance based key SVN is equivalent to the SMI SVN, but further know that constraints in this formulations maybe maybe large becausw illuminates all the instance in the next band.",
            "Random samples is very large.",
            "Then the optimization constraints may be very huge."
        ],
        [
            "So we propose another back level key instance, SVN, that is, we simply represent the negative X by the mean of the instances like this.",
            "The effects of this presentation has been demonstrated by the Ganter and the SML O2 paper and stream funding their picketed paper, so this trick has been successfully used in Murrell.",
            "Multiple instances learning.",
            "So in order to solve our proposed instance, labor KSV and an level KSV, and we consider a moji."
        ],
        [
            "Narrow formulation.",
            "It can involve the original key instance, Caspian and level KSVN as special cases.",
            "As a special case is when we define a different and different feature match for this formulation.",
            "So.",
            "In our paper, we asked to solve this optimization problem instead.",
            "OK."
        ],
        [
            "Before going through the mathematical details of proposed, we first need to give some intuition view of all the main motivation of approaches or manova solution is very simple.",
            "So if we given a set of data without knowing the labels to training and SVN.",
            "This is quite difficult.",
            "But if we did notice some some kind of labels, then training and SVN could be quite efficient.",
            "So this is a very very simple observation and our our strategy is also quite simple.",
            "So when first of all we do not know the we given a set of unlabelled instance then we.",
            "Simply give some initial labels to train SVN.",
            "And then the next step we try to generate the next most of information information labels according to by the current solution.",
            "Such like this.",
            "And then we learn different weights for these two kinds of label assignment.",
            "And then finally we interpret this sentence and solve another SVN and then you find the next most vital information, information label and intuitive procedures into convergence.",
            "So the idea is quite simple here.",
            "And further, note that each label assignments in the SVN dual function we corresponding to a kind of Labor kernel.",
            "So learning ways with different label assignments reduced to the multiple kernel learning which is convex and efficient in general."
        ],
        [
            "So let me go, let me discuss some mathematical details.",
            "So if it's considered a dual function of the original SVM problems.",
            "And then we hear the variables is described as following.",
            "And then.",
            "We consider the minimax relaxation.",
            "By simply interchanging the min Max problems.",
            "Is this worth noting that these two formulation is not exactly the same, it's just a convex relaxation, so this formulation becomes a convex.",
            "By simply illuminate all the possible D as a constraint here.",
            "Here each constraint is a common constraint which is convex, so the overall optimization overpopulation is convex.",
            "But further induced dual variables for this based optimization problem, it can become following.",
            "So if we know that each KDT becomes as a kernel, then the whole optimization problem is exactly the same as multiple kerning.",
            "So you can see that we just learn to trust, need to learn the mu, which is the weight for different kernels.",
            "However, it is now possible to."
        ],
        [
            "I actually solved multiple kernel learning problems cause there are too expensive.",
            "The meaning that the reason is that there is potential number of base kernels because there is potential number of the possible label assignments for the labels.",
            "So in this paper in our paper we refer the employee or cutting plane algorithm to solve our optimization problem.",
            "I'm sorry.",
            "Will happen.",
            "Sorry.",
            "So for the MCL.",
            "Sorry.",
            "OK, the first initial first initial DI mean the labels as to some initial data label assignment and then we initially looking sexy by the D0 and then we run the MCL to find the Alpha and the objective objective value and then you find the next validates DI mean the informatic labels by concurrent solutions and then update the Scorpion set by putting.",
            "By adding the define the D into the original working set, and then we repeat this.",
            "Repeat this procedure until convergence.",
            "So for the MCL we used adapted simple anchor methods proposed by Spark in the Gmail paper.",
            "And for finding the most valid, the most problem the most difficult problems is how to find the valid D. In fact."
        ],
        [
            "To find the most valid, I mean the label assignment we need to solve the current sort this problem.",
            "However, this problem is a concave QP problem which could not be solved efficiently.",
            "So.",
            "As we further mentioned that the cutting plane algorithm only need to add a constraint or valid constraints at each iteration.",
            "So in our paper we propose a simple and efficient methods for finding a good approximation for the most valid D. The idea is is is also very simple.",
            "Here we first rewritten the form as following by the definition of the map.",
            "And then we we, we approximate this formulation by the infinite norm.",
            "This infinite pronoun can be this infinite can be can be solved by multiple linear problems, which is only need to buy sorting.",
            "Need to sort in the.",
            "It only only can be solved.",
            "It can be solved by the sorting.",
            "Now it's OK.",
            "So."
        ],
        [
            "So let's go to the experimental results."
        ],
        [
            "In our experiments, we consider two kinds of tasks.",
            "The first one is a CBI image data set and the second one is benchmark data set.",
            "Here are some statistical in the CBI."
        ],
        [
            "That says we have to find categories and each category contains 100 images and there are some average hours in per images.",
            "The image size is 106 by 106 and the feature representations by using the SSP and methods.",
            "Finally, we use the success ratio to evaluate the performance is separate is the ratio of the number of successes divided by the number total number of relevant images."
        ],
        [
            "So here are the results we we used one wrist rest to deal with the multi task multi class problem and then we used 15 data through train and the rest of them as the testing data.",
            "For.",
            "For training and testing, 1.5 datas are relevant images and the other one are irrelevant images.",
            "We complete this this setup for 30 runs and report the average average results.",
            "Here is the results as we may see our proposed instance based Cwmbran levels CSB and achieves.",
            "Almost the best performance in all the SVM based methods.",
            "Also competitive original DDR NDND methods."
        ],
        [
            "Here is some examples.",
            "The last two ones are proposed methods."
        ],
        [
            "Finally, we also consider that the different the different number of the confidence confidence specs here, The xx is the number of the confident backs and Y axis is the success rate.",
            "As we can see the instance based KSV and is consistently better than all the other stuff based methods."
        ],
        [
            "So we also consider the CPU time for all the purpose methods, as we may see that instance based care SVN.",
            "It might be a little bit little bit time consuming, but our base back K SVN is.",
            "Is very efficient, so we first considered the performance per time cause here.",
            "The performances is calculated by the one device to the rank.",
            "And then we can see that our back level care as we achieved the highest performance amount, all the SPN time axles so.",
            "You may see that that's identical.",
            "Can our sources achieve very high performance potential costs cause?",
            "Because the methods require efficient, but the performance is not is not very good."
        ],
        [
            "So we also considered the benchmark data set.",
            "We used 10 for cost validation.",
            "Here are the results.",
            "You're going to see that our performance, the performance of our CSB is competitive or the other set of our methods."
        ],
        [
            "Finally, let me conclude our words.",
            "The main contribution in this paper is is the developer convex methods for locating our eyes with the help of multiple instances.",
            "And as we may note, images there there.",
            "As we know, the images that do not always have one our eyes in.",
            "Is only one regions of images in interest of interest in the images, so it may be have multiple or our groups in the images.",
            "So in the next step we will try to consider to locating the multiple hours in images or the outside groups in the images.",
            "So that's all for my.",
            "Presentation thank you."
        ],
        [
            "Haha.",
            "This.",
            "Or you just remember.",
            "Yes, the iteration is it.",
            "The iteration convergence number at the problem is this is indeed is a problems in our methods 'cause we have analysis.",
            "We have very many literatures about this, about the convergence ratio.",
            "But there are things because the problem is reformulates AZLP problem, so the convergence ratio is not well study in optimization community.",
            "So in all of our impact ICS we find that the iteration number maybe do not.",
            "Do not exist then 50.",
            "Maybe it's OK. OK.",
            "Question.",
            "The big question still so in your evaluation that are in fact still ways in which you can evaluate the multi instance.",
            "Lower one is how well it predicts the exact regions of interest and the other is how well it predicts the bags as a whole right?",
            "Yeah, and you have shown an evaluation on both levels, so must qualities you look at the bag as a whole.",
            "OK, so do you know if there are results about the correlation between these two measures?",
            "Is it the case of quantum methods?",
            "Works well.",
            "For predicting the bag label, it also works well for predicting regions of interest, yeah?",
            "Sorry.",
            "Actually we have compared both settings.",
            "The first setting is to just locating the our eyes here right?"
        ],
        [
            "Here's the I the success ratio definition is to.",
            "The is considered the both sides.",
            "The first sign is the ratio of the success the Allies detected.",
            "I mean the number of the hour I detect and the second side is the total number.",
            "So relevant features and images, so we need to predict the images rather is relevant or not, and then we calculate the number of our eyes index relevant images so they are considered both sides in this accessories here.",
            "OK, thank you.",
            "So far pretty quickly.",
            "Yeah yeah yeah, actually we have do some very simple very small data to evaluate the realization and original global optimal solution.",
            "You can see that it has some gap between the convex relaxation and global solution.",
            "But the but the gap is not too big, but I'm not sure whether the gap can be measured.",
            "Currently I do not know how to how to color, how to measure the gaps here so but we did find that there D had gaps between the commercialization and global solution.",
            "But they're not exactly the same.",
            "How much?",
            "Yes, I see but.",
            "I know and actually I also consider this problem, but.",
            "It might be a little bit quite difficult because the commercialization.",
            "Anne for some conditions.",
            "For example, when the global solution is added at the advertis of the of the space, then the realization May becomes the same as the global solution.",
            "But we do not know the weather global solution is on the vertex of the feature space or the physical space so.",
            "So I'm not sure whether I can export this, sorry.",
            "I think it's about time to move on.",
            "So thanks once again, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the next presentation will be given by family.",
                    "label": 0
                },
                {
                    "sent": "02 and it's about the complex methods for locating regions of interest will be exactly.",
                    "label": 1
                },
                {
                    "sent": "Thank you, good afternoon everyone, and if only this is a joint work with James called I will turn and do our job.",
                    "label": 0
                },
                {
                    "sent": "The title of this presentation, it is convex mixels for local interest regions of interest with multiple Insta.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learning.",
                    "label": 0
                },
                {
                    "sent": "First of all, let's briefly introduced multiple instance learning.",
                    "label": 0
                },
                {
                    "sent": "Multiple interest earning is first proposed by the data rich in their AI Journal and multiple instance learning ends to multiple instances is quite different from traditional supervised learning.",
                    "label": 0
                },
                {
                    "sent": "It tends to learn from the training set consists of bags where each batch contains multiple, many instances.",
                    "label": 0
                },
                {
                    "sent": "In traditional multiple instance learning, assumption about is positive if it contains at least one positive.",
                    "label": 0
                },
                {
                    "sent": "Instance otherwise it is a negative ad.",
                    "label": 0
                },
                {
                    "sent": "So we may see the labels of training base are known, but the labels of the instance in the best unknown.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "However, in a multiple instance learning, identify the positive instance in the positive bias is a very important problems for multiple instances, the name 'cause it's very helpful to understanding the relationship between the label and input patterns.",
                    "label": 0
                },
                {
                    "sent": "Besides, it also has some interesting.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Applications for example, in reverent feedbacks of CBI are usually user is only interested in some regions of the image is recalled regions of interest our I.",
                    "label": 1
                },
                {
                    "sent": "For example, there are several images of some set.",
                    "label": 0
                },
                {
                    "sent": "Usually the user is only interested in this one, and this one and this one so identified this really regions of interesting is maybe maybe understanding the user more quickly.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In fact, besides.",
                    "label": 1
                },
                {
                    "sent": "Locating our eyes can could be users in the other area, such as the image screaming.",
                    "label": 0
                },
                {
                    "sent": "For example in medical or literature applications, which requires to a fast scheming for a large amount of images.",
                    "label": 0
                },
                {
                    "sent": "To detect the suspects area of the image.",
                    "label": 0
                },
                {
                    "sent": "So if the desire is very desirable, if we can detect some regions of the image is if we can successfully detected regions of interest, and when the suspect images was was showing to the examiner so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problems in this presentation is that how to develop an efficient and theoretical supported methods for locating our eyes.",
                    "label": 0
                },
                {
                    "sent": "This goes through this presentation.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is the outline of this presentation.",
                    "label": 0
                },
                {
                    "sent": "I will first give some into brief introduction and then propose our methods and experimental results.",
                    "label": 1
                },
                {
                    "sent": "Finally, I can.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Curtis work so multiple instances, and as I mentioned before, is originally by former researcher research on a John activity prediction by the editor rich in their air Journal.",
                    "label": 0
                },
                {
                    "sent": "Here each jumps some small molecule is working by the building to the target area.",
                    "label": 1
                },
                {
                    "sent": "For each model create qualify which is qualified to make the jump.",
                    "label": 1
                },
                {
                    "sent": "One of these shaved could tightly bound to the target area.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But the American medical may have many alternative shapes, so the difficulty is that the biochemistry can only know the weather or medical is qualified or not.",
                    "label": 1
                },
                {
                    "sent": "But do not know which shape corresponding to the qualification.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the idea in their paper is very simple.",
                    "label": 0
                },
                {
                    "sent": "He expanded each shaped by the vector feature vector.",
                    "label": 0
                },
                {
                    "sent": "I mean an instance, then amount OK becomes a bag of instance instance, so a bad is positive if it contains at least one positive instance.",
                    "label": 1
                },
                {
                    "sent": "Otherwise the bad is negative.",
                    "label": 1
                },
                {
                    "sent": "So the chemists Imagenes today only know the labels of the training base, but they do not know the instance of the labels in the training base.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the multiple instances learning.",
                    "label": 0
                },
                {
                    "sent": "Currently there are various applications of multiple instances for image analysis, such as the image calibration, image retrieval and face detection, and computer aided medical.",
                    "label": 1
                },
                {
                    "sent": "Well knows now that was.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As for locating the Allies, there are also some related works.",
                    "label": 1
                },
                {
                    "sent": "The first one is the diversity density and its variance.",
                    "label": 0
                },
                {
                    "sent": "These methods can effectively located our eyes, but it may cause huge time complexity and overall overall optimization problem is non convex.",
                    "label": 0
                },
                {
                    "sent": "So you may suffer from some local solutions.",
                    "label": 0
                },
                {
                    "sent": "The other one is.",
                    "label": 1
                },
                {
                    "sent": "OK, an hour methods proposed by Joe in the AIG HK 05 paper is very variation of sedition KMS, as proposed by one and Asuka in there SMLO 2000 paper.",
                    "label": 0
                },
                {
                    "sent": "This method is very, very efficient, but they are wholly based on the heuristic search.",
                    "label": 1
                },
                {
                    "sent": "The third type of methods is SVM basis in my source.",
                    "label": 0
                },
                {
                    "sent": "Currently they're not.",
                    "label": 0
                },
                {
                    "sent": "There are very few SVM methods.",
                    "label": 0
                },
                {
                    "sent": "Focus on locating our eyes except my SVN.",
                    "label": 0
                },
                {
                    "sent": "And my screen is efficient and effective to located hours, but the overall transition problem is still nonconvex, so it may still suffer some local solution.",
                    "label": 1
                },
                {
                    "sent": "Our versus many focus on the SVM based methods, so let me briefly introduce the MI.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sweden.",
                    "label": 0
                },
                {
                    "sent": "And my SVN is first is proposed by the injury in their NIPS paper the idea of MSV is very simple.",
                    "label": 0
                },
                {
                    "sent": "This large modern principle, so.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have two positives.",
                    "label": 0
                },
                {
                    "sent": "Anna two negative X.",
                    "label": 0
                },
                {
                    "sent": "Each circle means the unlabeled instance.",
                    "label": 0
                },
                {
                    "sent": "We do not know.",
                    "label": 0
                },
                {
                    "sent": "So the more my SVN is trying to find.",
                    "label": 0
                },
                {
                    "sent": "Finally, find the optimal have plans for the positive and negative such that the key instance for for the positive and negatives are.",
                    "label": 0
                },
                {
                    "sent": "The margin of between then are maximized.",
                    "label": 0
                },
                {
                    "sent": "Finally, the maximum prediction, the maximum or the most confident prediction of the positives are referred to the key instance or the our eyes.",
                    "label": 0
                },
                {
                    "sent": "It's very simple idea for the Ms multiple instance I SVN.",
                    "label": 0
                },
                {
                    "sent": "So let.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Describe these problems more formula formally.",
                    "label": 0
                },
                {
                    "sent": "So suppose we are given a set of training bags, be I iy up to the BNY and we're HBI is a bad.",
                    "label": 1
                },
                {
                    "sent": "It contains multiple instance and then.",
                    "label": 0
                },
                {
                    "sent": "And why is the label?",
                    "label": 0
                },
                {
                    "sent": "As opposed to decision function, is a linear model.",
                    "label": 1
                },
                {
                    "sent": "So the goal here is to learn the FF minimized structure.",
                    "label": 0
                },
                {
                    "sent": "Risk functions such like this.",
                    "label": 0
                },
                {
                    "sent": "Here the Omega is strictly monotonic increasing function which is always also refers as regularization term.",
                    "label": 1
                },
                {
                    "sent": "The L here is a loss function.",
                    "label": 0
                },
                {
                    "sent": "And the see here is the regulation parameter.",
                    "label": 0
                },
                {
                    "sent": "So here there there has a maximum maximum operator.",
                    "label": 0
                },
                {
                    "sent": "Here the main idea here is to separate the key instance.",
                    "label": 0
                },
                {
                    "sent": "To separate the key instance in the positive and negative with large margin.",
                    "label": 0
                },
                {
                    "sent": "So here so that becomes Max Max operator here.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we consider the margin turn for the for the Omega and square hinge loss, then the ordinal optimization problem it becomes following.",
                    "label": 0
                },
                {
                    "sent": "Here the C is a slight variables.",
                    "label": 0
                },
                {
                    "sent": "So this however is a non convex problems becausw of the Max operator.",
                    "label": 1
                },
                {
                    "sent": "Which may get stuck in local solution, so the main contribution of this work is.",
                    "label": 0
                },
                {
                    "sent": "We propose a convex relaxation problems to solve such an nonconvex problem.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me introduce our.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Proposed makes us the first one.",
                    "label": 0
                },
                {
                    "sent": "It is called an instance labeled key instance VM.",
                    "label": 1
                },
                {
                    "sent": "By introducing some indicator variables D an XIJ, we can reformulate the original M ISBN's following here the Max operator for the positive band is represented by the this form and Max operator by the negative taxes as presented by illuminating all the other instance in the negative X as each one as a constraint in the optimization problem.",
                    "label": 0
                },
                {
                    "sent": "So here the D it is is integral.",
                    "label": 0
                },
                {
                    "sent": "It belongs to zero or one and the summary of the DJ in the bad is equal to 1.",
                    "label": 0
                },
                {
                    "sent": "So and and a Lambda is a slight variable balanced side variables between the positive and negative X.",
                    "label": 1
                },
                {
                    "sent": "So you may see that this kind of it can be proved that this kind of instance based key SVN is equivalent to the SMI SVN, but further know that constraints in this formulations maybe maybe large becausw illuminates all the instance in the next band.",
                    "label": 0
                },
                {
                    "sent": "Random samples is very large.",
                    "label": 0
                },
                {
                    "sent": "Then the optimization constraints may be very huge.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we propose another back level key instance, SVN, that is, we simply represent the negative X by the mean of the instances like this.",
                    "label": 1
                },
                {
                    "sent": "The effects of this presentation has been demonstrated by the Ganter and the SML O2 paper and stream funding their picketed paper, so this trick has been successfully used in Murrell.",
                    "label": 0
                },
                {
                    "sent": "Multiple instances learning.",
                    "label": 0
                },
                {
                    "sent": "So in order to solve our proposed instance, labor KSV and an level KSV, and we consider a moji.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Narrow formulation.",
                    "label": 0
                },
                {
                    "sent": "It can involve the original key instance, Caspian and level KSVN as special cases.",
                    "label": 1
                },
                {
                    "sent": "As a special case is when we define a different and different feature match for this formulation.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In our paper, we asked to solve this optimization problem instead.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Before going through the mathematical details of proposed, we first need to give some intuition view of all the main motivation of approaches or manova solution is very simple.",
                    "label": 0
                },
                {
                    "sent": "So if we given a set of data without knowing the labels to training and SVN.",
                    "label": 0
                },
                {
                    "sent": "This is quite difficult.",
                    "label": 0
                },
                {
                    "sent": "But if we did notice some some kind of labels, then training and SVN could be quite efficient.",
                    "label": 0
                },
                {
                    "sent": "So this is a very very simple observation and our our strategy is also quite simple.",
                    "label": 0
                },
                {
                    "sent": "So when first of all we do not know the we given a set of unlabelled instance then we.",
                    "label": 0
                },
                {
                    "sent": "Simply give some initial labels to train SVN.",
                    "label": 0
                },
                {
                    "sent": "And then the next step we try to generate the next most of information information labels according to by the current solution.",
                    "label": 0
                },
                {
                    "sent": "Such like this.",
                    "label": 0
                },
                {
                    "sent": "And then we learn different weights for these two kinds of label assignment.",
                    "label": 1
                },
                {
                    "sent": "And then finally we interpret this sentence and solve another SVN and then you find the next most vital information, information label and intuitive procedures into convergence.",
                    "label": 0
                },
                {
                    "sent": "So the idea is quite simple here.",
                    "label": 0
                },
                {
                    "sent": "And further, note that each label assignments in the SVN dual function we corresponding to a kind of Labor kernel.",
                    "label": 1
                },
                {
                    "sent": "So learning ways with different label assignments reduced to the multiple kernel learning which is convex and efficient in general.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me go, let me discuss some mathematical details.",
                    "label": 0
                },
                {
                    "sent": "So if it's considered a dual function of the original SVM problems.",
                    "label": 0
                },
                {
                    "sent": "And then we hear the variables is described as following.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "We consider the minimax relaxation.",
                    "label": 1
                },
                {
                    "sent": "By simply interchanging the min Max problems.",
                    "label": 0
                },
                {
                    "sent": "Is this worth noting that these two formulation is not exactly the same, it's just a convex relaxation, so this formulation becomes a convex.",
                    "label": 0
                },
                {
                    "sent": "By simply illuminate all the possible D as a constraint here.",
                    "label": 0
                },
                {
                    "sent": "Here each constraint is a common constraint which is convex, so the overall optimization overpopulation is convex.",
                    "label": 0
                },
                {
                    "sent": "But further induced dual variables for this based optimization problem, it can become following.",
                    "label": 0
                },
                {
                    "sent": "So if we know that each KDT becomes as a kernel, then the whole optimization problem is exactly the same as multiple kerning.",
                    "label": 0
                },
                {
                    "sent": "So you can see that we just learn to trust, need to learn the mu, which is the weight for different kernels.",
                    "label": 0
                },
                {
                    "sent": "However, it is now possible to.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I actually solved multiple kernel learning problems cause there are too expensive.",
                    "label": 1
                },
                {
                    "sent": "The meaning that the reason is that there is potential number of base kernels because there is potential number of the possible label assignments for the labels.",
                    "label": 1
                },
                {
                    "sent": "So in this paper in our paper we refer the employee or cutting plane algorithm to solve our optimization problem.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Will happen.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "So for the MCL.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "OK, the first initial first initial DI mean the labels as to some initial data label assignment and then we initially looking sexy by the D0 and then we run the MCL to find the Alpha and the objective objective value and then you find the next validates DI mean the informatic labels by concurrent solutions and then update the Scorpion set by putting.",
                    "label": 0
                },
                {
                    "sent": "By adding the define the D into the original working set, and then we repeat this.",
                    "label": 0
                },
                {
                    "sent": "Repeat this procedure until convergence.",
                    "label": 0
                },
                {
                    "sent": "So for the MCL we used adapted simple anchor methods proposed by Spark in the Gmail paper.",
                    "label": 0
                },
                {
                    "sent": "And for finding the most valid, the most problem the most difficult problems is how to find the valid D. In fact.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To find the most valid, I mean the label assignment we need to solve the current sort this problem.",
                    "label": 1
                },
                {
                    "sent": "However, this problem is a concave QP problem which could not be solved efficiently.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "As we further mentioned that the cutting plane algorithm only need to add a constraint or valid constraints at each iteration.",
                    "label": 0
                },
                {
                    "sent": "So in our paper we propose a simple and efficient methods for finding a good approximation for the most valid D. The idea is is is also very simple.",
                    "label": 1
                },
                {
                    "sent": "Here we first rewritten the form as following by the definition of the map.",
                    "label": 0
                },
                {
                    "sent": "And then we we, we approximate this formulation by the infinite norm.",
                    "label": 1
                },
                {
                    "sent": "This infinite pronoun can be this infinite can be can be solved by multiple linear problems, which is only need to buy sorting.",
                    "label": 0
                },
                {
                    "sent": "Need to sort in the.",
                    "label": 0
                },
                {
                    "sent": "It only only can be solved.",
                    "label": 0
                },
                {
                    "sent": "It can be solved by the sorting.",
                    "label": 0
                },
                {
                    "sent": "Now it's OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's go to the experimental results.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In our experiments, we consider two kinds of tasks.",
                    "label": 1
                },
                {
                    "sent": "The first one is a CBI image data set and the second one is benchmark data set.",
                    "label": 0
                },
                {
                    "sent": "Here are some statistical in the CBI.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That says we have to find categories and each category contains 100 images and there are some average hours in per images.",
                    "label": 0
                },
                {
                    "sent": "The image size is 106 by 106 and the feature representations by using the SSP and methods.",
                    "label": 0
                },
                {
                    "sent": "Finally, we use the success ratio to evaluate the performance is separate is the ratio of the number of successes divided by the number total number of relevant images.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are the results we we used one wrist rest to deal with the multi task multi class problem and then we used 15 data through train and the rest of them as the testing data.",
                    "label": 0
                },
                {
                    "sent": "For.",
                    "label": 0
                },
                {
                    "sent": "For training and testing, 1.5 datas are relevant images and the other one are irrelevant images.",
                    "label": 1
                },
                {
                    "sent": "We complete this this setup for 30 runs and report the average average results.",
                    "label": 1
                },
                {
                    "sent": "Here is the results as we may see our proposed instance based Cwmbran levels CSB and achieves.",
                    "label": 0
                },
                {
                    "sent": "Almost the best performance in all the SVM based methods.",
                    "label": 0
                },
                {
                    "sent": "Also competitive original DDR NDND methods.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is some examples.",
                    "label": 0
                },
                {
                    "sent": "The last two ones are proposed methods.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, we also consider that the different the different number of the confidence confidence specs here, The xx is the number of the confident backs and Y axis is the success rate.",
                    "label": 0
                },
                {
                    "sent": "As we can see the instance based KSV and is consistently better than all the other stuff based methods.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we also consider the CPU time for all the purpose methods, as we may see that instance based care SVN.",
                    "label": 0
                },
                {
                    "sent": "It might be a little bit little bit time consuming, but our base back K SVN is.",
                    "label": 0
                },
                {
                    "sent": "Is very efficient, so we first considered the performance per time cause here.",
                    "label": 1
                },
                {
                    "sent": "The performances is calculated by the one device to the rank.",
                    "label": 0
                },
                {
                    "sent": "And then we can see that our back level care as we achieved the highest performance amount, all the SPN time axles so.",
                    "label": 0
                },
                {
                    "sent": "You may see that that's identical.",
                    "label": 0
                },
                {
                    "sent": "Can our sources achieve very high performance potential costs cause?",
                    "label": 0
                },
                {
                    "sent": "Because the methods require efficient, but the performance is not is not very good.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we also considered the benchmark data set.",
                    "label": 0
                },
                {
                    "sent": "We used 10 for cost validation.",
                    "label": 0
                },
                {
                    "sent": "Here are the results.",
                    "label": 0
                },
                {
                    "sent": "You're going to see that our performance, the performance of our CSB is competitive or the other set of our methods.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, let me conclude our words.",
                    "label": 0
                },
                {
                    "sent": "The main contribution in this paper is is the developer convex methods for locating our eyes with the help of multiple instances.",
                    "label": 1
                },
                {
                    "sent": "And as we may note, images there there.",
                    "label": 0
                },
                {
                    "sent": "As we know, the images that do not always have one our eyes in.",
                    "label": 0
                },
                {
                    "sent": "Is only one regions of images in interest of interest in the images, so it may be have multiple or our groups in the images.",
                    "label": 0
                },
                {
                    "sent": "So in the next step we will try to consider to locating the multiple hours in images or the outside groups in the images.",
                    "label": 0
                },
                {
                    "sent": "So that's all for my.",
                    "label": 0
                },
                {
                    "sent": "Presentation thank you.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Haha.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Or you just remember.",
                    "label": 0
                },
                {
                    "sent": "Yes, the iteration is it.",
                    "label": 0
                },
                {
                    "sent": "The iteration convergence number at the problem is this is indeed is a problems in our methods 'cause we have analysis.",
                    "label": 0
                },
                {
                    "sent": "We have very many literatures about this, about the convergence ratio.",
                    "label": 0
                },
                {
                    "sent": "But there are things because the problem is reformulates AZLP problem, so the convergence ratio is not well study in optimization community.",
                    "label": 0
                },
                {
                    "sent": "So in all of our impact ICS we find that the iteration number maybe do not.",
                    "label": 0
                },
                {
                    "sent": "Do not exist then 50.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's OK. OK.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "The big question still so in your evaluation that are in fact still ways in which you can evaluate the multi instance.",
                    "label": 0
                },
                {
                    "sent": "Lower one is how well it predicts the exact regions of interest and the other is how well it predicts the bags as a whole right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, and you have shown an evaluation on both levels, so must qualities you look at the bag as a whole.",
                    "label": 0
                },
                {
                    "sent": "OK, so do you know if there are results about the correlation between these two measures?",
                    "label": 0
                },
                {
                    "sent": "Is it the case of quantum methods?",
                    "label": 0
                },
                {
                    "sent": "Works well.",
                    "label": 0
                },
                {
                    "sent": "For predicting the bag label, it also works well for predicting regions of interest, yeah?",
                    "label": 1
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Actually we have compared both settings.",
                    "label": 0
                },
                {
                    "sent": "The first setting is to just locating the our eyes here right?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's the I the success ratio definition is to.",
                    "label": 0
                },
                {
                    "sent": "The is considered the both sides.",
                    "label": 0
                },
                {
                    "sent": "The first sign is the ratio of the success the Allies detected.",
                    "label": 1
                },
                {
                    "sent": "I mean the number of the hour I detect and the second side is the total number.",
                    "label": 1
                },
                {
                    "sent": "So relevant features and images, so we need to predict the images rather is relevant or not, and then we calculate the number of our eyes index relevant images so they are considered both sides in this accessories here.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "So far pretty quickly.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah yeah, actually we have do some very simple very small data to evaluate the realization and original global optimal solution.",
                    "label": 0
                },
                {
                    "sent": "You can see that it has some gap between the convex relaxation and global solution.",
                    "label": 0
                },
                {
                    "sent": "But the but the gap is not too big, but I'm not sure whether the gap can be measured.",
                    "label": 0
                },
                {
                    "sent": "Currently I do not know how to how to color, how to measure the gaps here so but we did find that there D had gaps between the commercialization and global solution.",
                    "label": 0
                },
                {
                    "sent": "But they're not exactly the same.",
                    "label": 0
                },
                {
                    "sent": "How much?",
                    "label": 0
                },
                {
                    "sent": "Yes, I see but.",
                    "label": 0
                },
                {
                    "sent": "I know and actually I also consider this problem, but.",
                    "label": 0
                },
                {
                    "sent": "It might be a little bit quite difficult because the commercialization.",
                    "label": 0
                },
                {
                    "sent": "Anne for some conditions.",
                    "label": 0
                },
                {
                    "sent": "For example, when the global solution is added at the advertis of the of the space, then the realization May becomes the same as the global solution.",
                    "label": 0
                },
                {
                    "sent": "But we do not know the weather global solution is on the vertex of the feature space or the physical space so.",
                    "label": 0
                },
                {
                    "sent": "So I'm not sure whether I can export this, sorry.",
                    "label": 0
                },
                {
                    "sent": "I think it's about time to move on.",
                    "label": 0
                },
                {
                    "sent": "So thanks once again, thank you.",
                    "label": 0
                }
            ]
        }
    }
}