{
    "id": "nenlphfgmbd2u2kegqtucxhirctzffzi",
    "title": "Finding Representative Nodes in Probabilistic Graphs",
    "info": {
        "author": [
            "Laura Langohr, University of Helsinki"
        ],
        "published": "Oct. 20, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Network Analysis"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd09_langohr_frnpg/",
    "segmentation": [
        [
            "So I'll tell you today how we find representative nodes and probabilistic graphs."
        ],
        [
            "First, I will give you a short introduction, then show you how to measure similarities and probabilistic graphs.",
            "After that it will be possible to show how to cluster and find representatives and graphs.",
            "And afterwards I show you some experiments and results."
        ],
        [
            "So the motivation is to abstract a large set of nodes.",
            "So if you have a set of nodes, for example, biological noise could be hundreds of genes, which some biologists got from first experiments, and you want to select a smaller set of nodes out of them which represent the big sad.",
            "Which of course shouldn't be too similar be cause then you go just into One Direction and miss something else.",
            "What has been in the big set of nodes?",
            "So you want to remove latency and to find groups of nodes and then select representative of those groups where you could go further into study of them."
        ],
        [
            "Um, we apply that on the bio Minecraft.",
            "We heard about it today or several times, so the biomass graph is a big biological graph which integrates 12 biological databases into a single large graph and has over 1 million edges and almost 10,000,000 edges.",
            "So the nodes, as we had already genes proteins could be here like funnel types, pathways, scientific articles.",
            "And the edges are connections between those.",
            "So gene codes for protein, protein effects and disease and the disease is mentioned in an article.",
            "And this graph is probabilistic one, but I'm coming to the edge weights little bit."
        ],
        [
            "Later.",
            "So one slide, two related work.",
            "There's been done a lot for using clustering to find representatives.",
            "For example, to approximate clustering, so you first find the representatives and then just cluster those and then assign the other objects to them.",
            "Or reduce the number of that opposing databases as has been also in that conference.",
            "Something about that.",
            "But they don't use graph structure.",
            "And then again representatives are selected in graphs, for example to reduce the receivers which sends feedback.",
            "But they again don't use clustering.",
            "And then of course, there's a lot of things done for searching for special node I have here only three examples, like viral marketing or page rank or search for special type of nodes, but they don't use for they don't search for representative, so we are not aware of anything where representatives are found using clustering and graphs."
        ],
        [
            "So here again, well, little more detail what we're doing.",
            "So, given a set of nodes.",
            "We first calculate the power similarities between all of these nodes.",
            "And afterwards we have the similarities.",
            "We can just cluster those nodes.",
            "We do this with came its antiviral clustering and afterwards we output for each cluster one representative.",
            "Which is then one node."
        ],
        [
            "So I first show you how to.",
            "The similarities are calculated.",
            "So as I said, we have a graph where the edges have weights and we.",
            "See the weights as probabilities that the edge exists.",
            "So given that graph and the edge weights.",
            "Then a path, of course consists of different edges along the path, and then we can say the probability of the path is the product of the probability of the edges along the path, which is then.",
            "Shows how strongly the.",
            "Nodes are connected via the different paths and then you can define the probability of the best path, which is basically just the well the path between the two nodes, which is the maximum.",
            "So for example, if you go for A and F in that little example there you have to pass between those two and the best path would be that one which have the higher probability.",
            "Um?",
            "So once we know how to measure similarities and graphs, if you have now the set of nodes.",
            "We can just extract from the big big Bioman graph at subgraph, connecting all the nodes we're interested in and then calculate the power similarities for all pairs.",
            "Once we have the similarities weekend on cluster.",
            "So as a side one method we're going we used is came it came.",
            "It's is very similar to K means, which I'm sure."
        ],
        [
            "All of you know, but the difference is that K means using mean as a cluster center.",
            "However, if you have a graph, well, how to calculate that mean and committees again uses an object as cluster center, so in this case the memory does a node.",
            "So first if you have the similarities calculated then we just can choose K nodes randomly as first nodes cluster afterwards all the other nodes to the newest one.",
            "Whereas if a node has similarities to all.",
            "Matter is 0.",
            "Then we considered an outlier and don't cluster to any matter at all.",
            "Afterwards, for each cluster we calculate a new Medicaid and the last two steps are repeated until the matter is converges or.",
            "And.",
            "The number set of the number of iteration is too high, but usually K means and K methods converge quite quickly, so as an."
        ],
        [
            "Little example here.",
            "In this example my jeans were clustered.",
            "These nine genes were obtained from 3 classes.",
            "We know there were related to phenotype and then we used committees to cluster them.",
            "In this example, there's only one gene that is the one that in the middle with the number 1627 which were clustered wrongly.",
            "So we have the ellipsoid on the right side, which one closer than the rectangles in the middle?",
            "Down area which is the second one in the.",
            "Diamonds on the left.",
            "Our average represent the classes we obtained.",
            "We have some edges and some middle nodes between them, and the dashed lines are passes where there is more than one node between them.",
            "So only one edge, only one node over clustered wrongly.",
            "But if you consider the representatives which were selected, which are the ones with the double line, they were obtained from those three classes.",
            "The second."
        ],
        [
            "Clustering we used by actual clustering where first you consider all the nodes as a cluster on its own and then merge the clusters which have the.",
            "High similarity we use average language together and then repeat the second step until only K clusters remain and then again we go like came into it's we select for each cluster one maybe.",
            "As representative."
        ],
        [
            "So let me show you some experiments we did.",
            "The test data we used, published by Kula, and I'll last year they did something slightly different, but the test data we could use, so they selected 110 diseases and for each disease.",
            "They collected three 241 genes which are related to that disease.",
            "And those.",
            "Disease gene families we could use as classes we would know before and then select the genes and cluster them."
        ],
        [
            "On the biography, as shown before.",
            "So we had cameras we had to actual clustering and Additionally we also combined them to random selection of representatives.",
            "We did 100 test runs for each and four K3 and K10."
        ],
        [
            "Then we had four measures to measure the results.",
            "2 measures for measures.",
            "The representativeness of the representatives."
        ],
        [
            "Obtained.",
            "The first one is just the average similarity of objects to the closest representative.",
            "So basically we go over all objects and sum up over the objects X and the method of this, which is the closest representative and calculate the average overtime.",
            "The second one.",
            "As a fraction of now."
        ],
        [
            "Representative classes, whereas we basically count the number of original classes when no representative were selected out.",
            "And then we have two measures for."
        ],
        [
            "Measuring the underlying clustering.",
            "The first one."
        ],
        [
            "Measures the average compactness of clusters, so we go over all class or classes and then overall pair of nodes in the clusters and find the minimum similarity.",
            "And second one is wrongly assigned objects that we basically count the objects that were."
        ],
        [
            "Formally assigned, so figure out which cluster represents which original classes on.",
            "Count the number of objects where if only assigned.",
            "So as I said, we had hundred test runs with K3K10.",
            "Those four measures I go over the results now measure by measure.",
            "So far the average similar."
        ],
        [
            "To the nearest representative we have on the.",
            "Left side came edits against the hierarchical clustering and on the upper side we have Casey down.",
            "We have K10 so if you see you look at the comparison but cameras into actual clustering you see that.",
            "Commits is better than vertical.",
            "What is again, what is no big surprise because comedy is kind of optimize this measure.",
            "But if you can see still he article against random selection of the representatives who I think was clearly outperforming the random selection.",
            "For the second measure, measure the fraction of non."
        ],
        [
            "Preventative clusters so this average values so committee's anti radical for both K3 and K10 outperformed the random for bigger K10.",
            "A little bit better than the camera's approach.",
            "And for the average."
        ],
        [
            "Apartment of clusters.",
            "Here the logical again against committees is on the left side and up there's case we and honest K10 and on the right side we have random against came into this time came it is against radical.",
            "You clearly see that we actually is performing a little bit better, but again that is also no big surprise 'cause the racial approach optimizes this measure.",
            "And but committed still outperforms the random selection."
        ],
        [
            "Representatives.",
            "And the only assigned objects here again accommodates antibiotic clustering are better than the random selection of representatives for K3.",
            "Four K10.",
            "The committees is not doing anymore as well as well as good as the hierarchical clustering.",
            "So."
        ],
        [
            "I conclude with.",
            "The slide we had the probabilistic graph I showed you how to identify representatives which commits antiviral clustering.",
            "Both methods are promising approaches to identify representatives, but the article method seems to be more robust.",
            "Thank you.",
            "Christian.",
            "For sale"
        ],
        [
            "Directly refers to.",
            "Another question.",
            "Are there other questions?",
            "OK, other similarity measures between knows no.",
            "Of course, that's different stuff.",
            "Possible white.",
            "You don't have to consider only one path to measure the similarity between two nodes.",
            "We can use something where you consider all paths between those two notes.",
            "Now we just stick to the simplest one here.",
            "So my comment is kind of related so.",
            "We did something similar in what we did.",
            "We were running playground from each and every node, so that in the end we got the feature vector for each node.",
            "And the DOT product between the feature vector became the similarity between the notes and when you cluster those you can also compute temporaries and stuff like that.",
            "So when you have feature vectors then you have some more freedom or the next steps OK?",
            "So.",
            "Well, you seem to have here as I can kind of discrepancy between your objective and questioned algorithm that you want me to say.",
            "Not my objective is to get.",
            "Measures are presented this, but then I got this one.",
            "This matter with algorithm or around the clustering which I don't know what they're doing and just compare empirically if it happened to be good or not, and I would say that can you come up with the precise objective function of the damed with algorithm is optimal.",
            "Come up with an algorithm that we explicitly directly try to optimize your measures of representative rather than just you know.",
            "Quickly measure picking a random algorithm and checking on data.",
            "Well was I lucky in the magical.",
            "Yeah, so the well, what is the definition of really representative, right or?",
            "Yes.",
            "We saw him at this measure.",
            "Take an algorithm.",
            "I'll be Charlie like they make it, or I can say, I believe that they measured everything is very good algorithm, so maybe I can formulate what measure of representativeness this algorithm is really off.",
            "You know, like the K means algorithm is really.",
            "You can prove it eventually optimize reclaiming function.",
            "There's a mismatch between the gold and the others in the preview.",
            "Will be the easiest called, but there's no signal definition for being represented.",
            "Yeah, that's why we give here two different measures.",
            "One is this ring out close.",
            "The nodes are.",
            "On average, they represented, so that's one major wanted out before the other one we did was using a background noise.",
            "Since we have classification problem, we could also see OK. All the original classes.",
            "So.",
            "We want to bring up this problem.",
            "We don't want to propose single measure as we measure.",
            "Even the measure you can try to design the algorithm that will optimize this year, and I think this is at the algorithm that optimizes business and whether even a measure maybe come up in December.",
            "Oh, if you have an algorithm like hey maybe just to believe it is really good job, maybe figure out which measure because.",
            "OK, more questions.",
            "That seems to be the case then.",
            "Thank you again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll tell you today how we find representative nodes and probabilistic graphs.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, I will give you a short introduction, then show you how to measure similarities and probabilistic graphs.",
                    "label": 0
                },
                {
                    "sent": "After that it will be possible to show how to cluster and find representatives and graphs.",
                    "label": 0
                },
                {
                    "sent": "And afterwards I show you some experiments and results.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the motivation is to abstract a large set of nodes.",
                    "label": 1
                },
                {
                    "sent": "So if you have a set of nodes, for example, biological noise could be hundreds of genes, which some biologists got from first experiments, and you want to select a smaller set of nodes out of them which represent the big sad.",
                    "label": 0
                },
                {
                    "sent": "Which of course shouldn't be too similar be cause then you go just into One Direction and miss something else.",
                    "label": 0
                },
                {
                    "sent": "What has been in the big set of nodes?",
                    "label": 0
                },
                {
                    "sent": "So you want to remove latency and to find groups of nodes and then select representative of those groups where you could go further into study of them.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, we apply that on the bio Minecraft.",
                    "label": 0
                },
                {
                    "sent": "We heard about it today or several times, so the biomass graph is a big biological graph which integrates 12 biological databases into a single large graph and has over 1 million edges and almost 10,000,000 edges.",
                    "label": 1
                },
                {
                    "sent": "So the nodes, as we had already genes proteins could be here like funnel types, pathways, scientific articles.",
                    "label": 0
                },
                {
                    "sent": "And the edges are connections between those.",
                    "label": 0
                },
                {
                    "sent": "So gene codes for protein, protein effects and disease and the disease is mentioned in an article.",
                    "label": 0
                },
                {
                    "sent": "And this graph is probabilistic one, but I'm coming to the edge weights little bit.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Later.",
                    "label": 0
                },
                {
                    "sent": "So one slide, two related work.",
                    "label": 1
                },
                {
                    "sent": "There's been done a lot for using clustering to find representatives.",
                    "label": 1
                },
                {
                    "sent": "For example, to approximate clustering, so you first find the representatives and then just cluster those and then assign the other objects to them.",
                    "label": 1
                },
                {
                    "sent": "Or reduce the number of that opposing databases as has been also in that conference.",
                    "label": 1
                },
                {
                    "sent": "Something about that.",
                    "label": 0
                },
                {
                    "sent": "But they don't use graph structure.",
                    "label": 0
                },
                {
                    "sent": "And then again representatives are selected in graphs, for example to reduce the receivers which sends feedback.",
                    "label": 0
                },
                {
                    "sent": "But they again don't use clustering.",
                    "label": 0
                },
                {
                    "sent": "And then of course, there's a lot of things done for searching for special node I have here only three examples, like viral marketing or page rank or search for special type of nodes, but they don't use for they don't search for representative, so we are not aware of anything where representatives are found using clustering and graphs.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here again, well, little more detail what we're doing.",
                    "label": 0
                },
                {
                    "sent": "So, given a set of nodes.",
                    "label": 1
                },
                {
                    "sent": "We first calculate the power similarities between all of these nodes.",
                    "label": 0
                },
                {
                    "sent": "And afterwards we have the similarities.",
                    "label": 0
                },
                {
                    "sent": "We can just cluster those nodes.",
                    "label": 1
                },
                {
                    "sent": "We do this with came its antiviral clustering and afterwards we output for each cluster one representative.",
                    "label": 0
                },
                {
                    "sent": "Which is then one node.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I first show you how to.",
                    "label": 0
                },
                {
                    "sent": "The similarities are calculated.",
                    "label": 0
                },
                {
                    "sent": "So as I said, we have a graph where the edges have weights and we.",
                    "label": 0
                },
                {
                    "sent": "See the weights as probabilities that the edge exists.",
                    "label": 0
                },
                {
                    "sent": "So given that graph and the edge weights.",
                    "label": 1
                },
                {
                    "sent": "Then a path, of course consists of different edges along the path, and then we can say the probability of the path is the product of the probability of the edges along the path, which is then.",
                    "label": 1
                },
                {
                    "sent": "Shows how strongly the.",
                    "label": 0
                },
                {
                    "sent": "Nodes are connected via the different paths and then you can define the probability of the best path, which is basically just the well the path between the two nodes, which is the maximum.",
                    "label": 1
                },
                {
                    "sent": "So for example, if you go for A and F in that little example there you have to pass between those two and the best path would be that one which have the higher probability.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So once we know how to measure similarities and graphs, if you have now the set of nodes.",
                    "label": 0
                },
                {
                    "sent": "We can just extract from the big big Bioman graph at subgraph, connecting all the nodes we're interested in and then calculate the power similarities for all pairs.",
                    "label": 0
                },
                {
                    "sent": "Once we have the similarities weekend on cluster.",
                    "label": 0
                },
                {
                    "sent": "So as a side one method we're going we used is came it came.",
                    "label": 0
                },
                {
                    "sent": "It's is very similar to K means, which I'm sure.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All of you know, but the difference is that K means using mean as a cluster center.",
                    "label": 0
                },
                {
                    "sent": "However, if you have a graph, well, how to calculate that mean and committees again uses an object as cluster center, so in this case the memory does a node.",
                    "label": 0
                },
                {
                    "sent": "So first if you have the similarities calculated then we just can choose K nodes randomly as first nodes cluster afterwards all the other nodes to the newest one.",
                    "label": 1
                },
                {
                    "sent": "Whereas if a node has similarities to all.",
                    "label": 0
                },
                {
                    "sent": "Matter is 0.",
                    "label": 0
                },
                {
                    "sent": "Then we considered an outlier and don't cluster to any matter at all.",
                    "label": 1
                },
                {
                    "sent": "Afterwards, for each cluster we calculate a new Medicaid and the last two steps are repeated until the matter is converges or.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The number set of the number of iteration is too high, but usually K means and K methods converge quite quickly, so as an.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Little example here.",
                    "label": 0
                },
                {
                    "sent": "In this example my jeans were clustered.",
                    "label": 0
                },
                {
                    "sent": "These nine genes were obtained from 3 classes.",
                    "label": 0
                },
                {
                    "sent": "We know there were related to phenotype and then we used committees to cluster them.",
                    "label": 0
                },
                {
                    "sent": "In this example, there's only one gene that is the one that in the middle with the number 1627 which were clustered wrongly.",
                    "label": 0
                },
                {
                    "sent": "So we have the ellipsoid on the right side, which one closer than the rectangles in the middle?",
                    "label": 0
                },
                {
                    "sent": "Down area which is the second one in the.",
                    "label": 0
                },
                {
                    "sent": "Diamonds on the left.",
                    "label": 0
                },
                {
                    "sent": "Our average represent the classes we obtained.",
                    "label": 0
                },
                {
                    "sent": "We have some edges and some middle nodes between them, and the dashed lines are passes where there is more than one node between them.",
                    "label": 0
                },
                {
                    "sent": "So only one edge, only one node over clustered wrongly.",
                    "label": 0
                },
                {
                    "sent": "But if you consider the representatives which were selected, which are the ones with the double line, they were obtained from those three classes.",
                    "label": 0
                },
                {
                    "sent": "The second.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Clustering we used by actual clustering where first you consider all the nodes as a cluster on its own and then merge the clusters which have the.",
                    "label": 0
                },
                {
                    "sent": "High similarity we use average language together and then repeat the second step until only K clusters remain and then again we go like came into it's we select for each cluster one maybe.",
                    "label": 1
                },
                {
                    "sent": "As representative.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me show you some experiments we did.",
                    "label": 0
                },
                {
                    "sent": "The test data we used, published by Kula, and I'll last year they did something slightly different, but the test data we could use, so they selected 110 diseases and for each disease.",
                    "label": 1
                },
                {
                    "sent": "They collected three 241 genes which are related to that disease.",
                    "label": 0
                },
                {
                    "sent": "And those.",
                    "label": 0
                },
                {
                    "sent": "Disease gene families we could use as classes we would know before and then select the genes and cluster them.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the biography, as shown before.",
                    "label": 0
                },
                {
                    "sent": "So we had cameras we had to actual clustering and Additionally we also combined them to random selection of representatives.",
                    "label": 1
                },
                {
                    "sent": "We did 100 test runs for each and four K3 and K10.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we had four measures to measure the results.",
                    "label": 0
                },
                {
                    "sent": "2 measures for measures.",
                    "label": 0
                },
                {
                    "sent": "The representativeness of the representatives.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Obtained.",
                    "label": 0
                },
                {
                    "sent": "The first one is just the average similarity of objects to the closest representative.",
                    "label": 1
                },
                {
                    "sent": "So basically we go over all objects and sum up over the objects X and the method of this, which is the closest representative and calculate the average overtime.",
                    "label": 0
                },
                {
                    "sent": "The second one.",
                    "label": 0
                },
                {
                    "sent": "As a fraction of now.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Representative classes, whereas we basically count the number of original classes when no representative were selected out.",
                    "label": 0
                },
                {
                    "sent": "And then we have two measures for.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Measuring the underlying clustering.",
                    "label": 0
                },
                {
                    "sent": "The first one.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Measures the average compactness of clusters, so we go over all class or classes and then overall pair of nodes in the clusters and find the minimum similarity.",
                    "label": 0
                },
                {
                    "sent": "And second one is wrongly assigned objects that we basically count the objects that were.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Formally assigned, so figure out which cluster represents which original classes on.",
                    "label": 0
                },
                {
                    "sent": "Count the number of objects where if only assigned.",
                    "label": 0
                },
                {
                    "sent": "So as I said, we had hundred test runs with K3K10.",
                    "label": 0
                },
                {
                    "sent": "Those four measures I go over the results now measure by measure.",
                    "label": 0
                },
                {
                    "sent": "So far the average similar.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To the nearest representative we have on the.",
                    "label": 0
                },
                {
                    "sent": "Left side came edits against the hierarchical clustering and on the upper side we have Casey down.",
                    "label": 0
                },
                {
                    "sent": "We have K10 so if you see you look at the comparison but cameras into actual clustering you see that.",
                    "label": 0
                },
                {
                    "sent": "Commits is better than vertical.",
                    "label": 0
                },
                {
                    "sent": "What is again, what is no big surprise because comedy is kind of optimize this measure.",
                    "label": 0
                },
                {
                    "sent": "But if you can see still he article against random selection of the representatives who I think was clearly outperforming the random selection.",
                    "label": 0
                },
                {
                    "sent": "For the second measure, measure the fraction of non.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Preventative clusters so this average values so committee's anti radical for both K3 and K10 outperformed the random for bigger K10.",
                    "label": 0
                },
                {
                    "sent": "A little bit better than the camera's approach.",
                    "label": 0
                },
                {
                    "sent": "And for the average.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Apartment of clusters.",
                    "label": 0
                },
                {
                    "sent": "Here the logical again against committees is on the left side and up there's case we and honest K10 and on the right side we have random against came into this time came it is against radical.",
                    "label": 0
                },
                {
                    "sent": "You clearly see that we actually is performing a little bit better, but again that is also no big surprise 'cause the racial approach optimizes this measure.",
                    "label": 0
                },
                {
                    "sent": "And but committed still outperforms the random selection.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Representatives.",
                    "label": 0
                },
                {
                    "sent": "And the only assigned objects here again accommodates antibiotic clustering are better than the random selection of representatives for K3.",
                    "label": 0
                },
                {
                    "sent": "Four K10.",
                    "label": 0
                },
                {
                    "sent": "The committees is not doing anymore as well as well as good as the hierarchical clustering.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I conclude with.",
                    "label": 0
                },
                {
                    "sent": "The slide we had the probabilistic graph I showed you how to identify representatives which commits antiviral clustering.",
                    "label": 0
                },
                {
                    "sent": "Both methods are promising approaches to identify representatives, but the article method seems to be more robust.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Christian.",
                    "label": 0
                },
                {
                    "sent": "For sale",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Directly refers to.",
                    "label": 0
                },
                {
                    "sent": "Another question.",
                    "label": 0
                },
                {
                    "sent": "Are there other questions?",
                    "label": 0
                },
                {
                    "sent": "OK, other similarity measures between knows no.",
                    "label": 0
                },
                {
                    "sent": "Of course, that's different stuff.",
                    "label": 0
                },
                {
                    "sent": "Possible white.",
                    "label": 0
                },
                {
                    "sent": "You don't have to consider only one path to measure the similarity between two nodes.",
                    "label": 0
                },
                {
                    "sent": "We can use something where you consider all paths between those two notes.",
                    "label": 0
                },
                {
                    "sent": "Now we just stick to the simplest one here.",
                    "label": 0
                },
                {
                    "sent": "So my comment is kind of related so.",
                    "label": 0
                },
                {
                    "sent": "We did something similar in what we did.",
                    "label": 0
                },
                {
                    "sent": "We were running playground from each and every node, so that in the end we got the feature vector for each node.",
                    "label": 0
                },
                {
                    "sent": "And the DOT product between the feature vector became the similarity between the notes and when you cluster those you can also compute temporaries and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "So when you have feature vectors then you have some more freedom or the next steps OK?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Well, you seem to have here as I can kind of discrepancy between your objective and questioned algorithm that you want me to say.",
                    "label": 0
                },
                {
                    "sent": "Not my objective is to get.",
                    "label": 0
                },
                {
                    "sent": "Measures are presented this, but then I got this one.",
                    "label": 0
                },
                {
                    "sent": "This matter with algorithm or around the clustering which I don't know what they're doing and just compare empirically if it happened to be good or not, and I would say that can you come up with the precise objective function of the damed with algorithm is optimal.",
                    "label": 0
                },
                {
                    "sent": "Come up with an algorithm that we explicitly directly try to optimize your measures of representative rather than just you know.",
                    "label": 0
                },
                {
                    "sent": "Quickly measure picking a random algorithm and checking on data.",
                    "label": 0
                },
                {
                    "sent": "Well was I lucky in the magical.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the well, what is the definition of really representative, right or?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "We saw him at this measure.",
                    "label": 0
                },
                {
                    "sent": "Take an algorithm.",
                    "label": 0
                },
                {
                    "sent": "I'll be Charlie like they make it, or I can say, I believe that they measured everything is very good algorithm, so maybe I can formulate what measure of representativeness this algorithm is really off.",
                    "label": 0
                },
                {
                    "sent": "You know, like the K means algorithm is really.",
                    "label": 0
                },
                {
                    "sent": "You can prove it eventually optimize reclaiming function.",
                    "label": 0
                },
                {
                    "sent": "There's a mismatch between the gold and the others in the preview.",
                    "label": 0
                },
                {
                    "sent": "Will be the easiest called, but there's no signal definition for being represented.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's why we give here two different measures.",
                    "label": 0
                },
                {
                    "sent": "One is this ring out close.",
                    "label": 0
                },
                {
                    "sent": "The nodes are.",
                    "label": 0
                },
                {
                    "sent": "On average, they represented, so that's one major wanted out before the other one we did was using a background noise.",
                    "label": 0
                },
                {
                    "sent": "Since we have classification problem, we could also see OK. All the original classes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We want to bring up this problem.",
                    "label": 0
                },
                {
                    "sent": "We don't want to propose single measure as we measure.",
                    "label": 0
                },
                {
                    "sent": "Even the measure you can try to design the algorithm that will optimize this year, and I think this is at the algorithm that optimizes business and whether even a measure maybe come up in December.",
                    "label": 0
                },
                {
                    "sent": "Oh, if you have an algorithm like hey maybe just to believe it is really good job, maybe figure out which measure because.",
                    "label": 0
                },
                {
                    "sent": "OK, more questions.",
                    "label": 0
                },
                {
                    "sent": "That seems to be the case then.",
                    "label": 0
                },
                {
                    "sent": "Thank you again.",
                    "label": 0
                }
            ]
        }
    }
}