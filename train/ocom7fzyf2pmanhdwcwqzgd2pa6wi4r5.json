{
    "id": "ocom7fzyf2pmanhdwcwqzgd2pa6wi4r5",
    "title": "Global and Efficient Self-Similarity for Object Classification and Detection",
    "info": {
        "author": [
            "Thomas Deselaers, Department of Information Technology and Electrical Engineering, ETH Zurich"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Object Recognition"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_deselaers_gess/",
    "segmentation": [
        [
            "Hello and welcome to this talk.",
            "My name is Thomas de Los and this is joint work with Victoria Ferrari."
        ],
        [
            "Let's first talk about conventional image descriptors.",
            "They measure direct image properties such as gradients or colors."
        ],
        [
            "And typically follow the assumption that there is a direct visual property shared among images showing objects of the same class.",
            "However, Schechtman and Irani observed in their CPR 7 paper that this assumption does not always hold, as can be seen from the images here at the bottom.",
            "Well, all of them so hard they do not share a direct visual property such as colors or textures.",
            "Not even enter intention and continuity.",
            "What makes these images similar is that local intensity patterns are repeated within the image in a similar geometric layout.",
            "The spirit of self similarity is that images are similar.",
            "If the wave patterns repeat within them is similar and not because they have similar colors or textures.",
            "Such similarity is an indirect property which generalizes better than conventional descriptors and can be used even when these fail."
        ],
        [
            "The local steps Rescripted proposed the shape and Ronnie is computed as follows for certain interest point, they take a small Patch around it and compute the correlation surface with its immediate surrounding.",
            "Then the computer lock color histogram over this.",
            "This is repeated for a lot of interest points.",
            "This work stood a lot of interest and many people started actively using it quite quickly."
        ],
        [
            "Typical applications of local Cemetery descriptors include object recognition, image retrieval and action recognition.",
            "For example, Schechtman Irani use it in their original work within an ensemble matching method.",
            "Boyment uses it within its nearest neighbor approach in CPR 8 and several people use it as yet another feature in multi kernel learning schemes or in other combinations.",
            "Here, typically a bag of visual words, descriptors computed from local self similarities.",
            "Interestingly, in all of these works, self similarity is considered locally, whereas we believe it should be considered globally to capture."
        ],
        [
            "Long range similarities within an image.",
            "In this slide you can see in the top original images with the market Patch and in the bottom and overlay of a global correlation surface with the entire image.",
            "Although the images are not similar at all in their colors and textures, the correlation surface is are very similar here apart from the left hand, side, left and boundary of the logo results in a similar correlation surface.",
            "Analogously, at the right hand side."
        ],
        [
            "Here's an example for Swans.",
            "Apart from this, one body is similar to the entire body and the Patch from the small neck is similar to the entire neck."
        ],
        [
            "Let's formalize what is global self similarity, really?",
            "For an image we compute the self similarity between all pairs of pixels.",
            "P&P prime.",
            "Which gives the correlation surface for every pixel peep.",
            "This will repeat for every pair of pixels.",
            "Let's do one more.",
            "And then we end up with a four dimensional steps energy tensor.",
            "SI for an image.",
            "Note also that the small correlation surfaces that were used within the local self similarity are fully included here."
        ],
        [
            "The global self similarity tensor is very expensive to compute onto store.",
            "To compute it, we have to compare every pixel with every other pixel.",
            "Every comparison takes W square operations leading to H ^2 W, ^2 W squared operations, which for typical image of size 500 by 300 takes about 20 hours.",
            "The memory requirement is also quadratic in the image size, and here is about 80 gigabytes.",
            "Therefore, our aim is to reduce both computation time and memory requirement."
        ],
        [
            "So far I hope I convinced you that self similarity should be considered globally and that it is infeasible to compute directly.",
            "Further, I showed how we formalize it.",
            "In the remainder I will describe how to reduce the computational complexity of the global self similarity tensor.",
            "Then we'll talk about one of the two descriptors that we propose to format self similarity such that it can be used in standard machine learning classifiers.",
            "I will further show our self similarity can be used for object detection and it showed experimentally that global self similarity outperforms local self similarity and that self similarity descriptors are complementary to conventional descriptors, making them ideally suited for combinations."
        ],
        [
            "We want to find an efficient approximation to the global self similarity tensor.",
            "Therefore we quantize all the patches in the image.",
            "According to code book theater.",
            "Then we define the two patches are similar if they are assigned to the same prototype.",
            "This is certainly valid because similarity is transitive.",
            "If both patches are similar to certain prototype, they must also be similar to each other.",
            "So a Patch is assigned to a prototype.",
            "And then we know that it is similar to all the other pictures that were assigned to the same prototype.",
            "You see, the positions of these patches highlit.",
            "This pitch was assigned to the same prototype, resulting in the same assignment.",
            "Here, dispatch and dispatch were assigned to two different prototypes.",
            "Using this technique, reduce the runtime to be linear in the image size, resulting in a speedup factor.",
            "Also linear in the image size.",
            "For typical image, this corresponds to a 750 fold speedup."
        ],
        [
            "Now let's go one step further and assume the two pixels are only similar if they are assigned to the same prototype.",
            "This makes the correlation surface is binary and disjunct.",
            "Now correlation surface for a pixel is the binary image where all pixels which were assigned to the same prototype are on.",
            "This further allows us to store the entire self similarity information in a single prototype assignment map MI where we store the assigned prototype for every pixel only.",
            "On the right here we visualize the prototype assignment map where pixels are colored according to their prototypes.",
            "They were assigned to their four pixels marked in the same color, were assigned to the same prototype.",
            "We can easily obtain a binary correlation surface for every pixel.",
            "Thus this is a compact representation of the 4D self similarity tensor.",
            "The memory requirements are reduced from quadratic to linear in the image size.",
            "To obtain the prototype assignment map, we have to choose a codebook theater.",
            "There are several options and options, but since we are interested in self similarity."
        ],
        [
            "We can use image specific Patch product code books which can be much smaller than conventional code.",
            "Books that are typically used for bag of words representations.",
            "In fact, contrary to those where it is typically required that the different visual words have the same meaning across images.",
            "Here we use a codebook specific to the individual images.",
            "This also matches the spirit of self similarity.",
            "Best we're only interested where structures repeat within an individual image rather than finding the same appearance across other images.",
            "He will see the code book for each of the four images.",
            "And you can clearly see that they are well suited for their respective images.",
            "This code books out.",
            "And using K means on randomly sampled patches from these images.",
            "And once we have these codebooks we can compute the prototype assignment Maps using only one convolution per code word, while image specific code books are most interesting and require less entries for a good image representation, we evaluate other more generic code books and their para meters in the paper."
        ],
        [
            "So far I've been talking about the global self similarity tensor and how to compute it for an image.",
            "However, as presented so far it is not suited to be used.",
            "It's not suited to be used in most classifiers since the tensor size depends on the image size and it is too large to work with efficiently.",
            "Therefore I will now describe how to format a compact fixed size descriptor that can be used within standard machine learning classifiers easily.",
            "In this paper we present two descriptors, Bank of correlation Surface is an self similarity, hypercubes.",
            "Why a bit of correlation surfaces are inspired from bag of words approach is here I will talk about self similarity hypercubes."
        ],
        [
            "To obtain a self similarity hypercube, we put a D 1 * D Two grid here 4 by 4 under the prototype assignment map.",
            "Then for every pair of cells, janjay prime in this grid, we count how many of the pixels within the cells were assigned to the same prototype.",
            "Another interpretation to this is to sum over the 4D sub part of the self similarity tensor corresponding to the cells.",
            "This we do for all pairs of cells, resulting in a D 1 * D two times D 1 * D Two tensor where every entry measure measures the similarity of two cells in the image."
        ],
        [
            "To compute the self similarity hypercube for an H prime times W prime image window naively requires H prime squared times W prime square operations.",
            "Using this for sliding window detection is very expensive because there are many windows in an image now with."
        ],
        [
            "And how to do this more efficiently?",
            "For this we consider the interpretation that the self similarity hypercube entries contains sums over the 40 subparts of the self similarity tensor corresponding to image cells.",
            "To obtain these sums efficiently, we compute a 4D integral self similarity tensor analogously to integral images.",
            "From this integral self similarity tensor, we can then obtain the number of pixels which were assigned to the same prototype within two cells using just 16 vlookups.",
            "Therefore, it is possible to compute a self similarity hypercube for an arbitrary window using just 16 look ups per entry, which is fast, and in particular it does not depend on the window size.",
            "For typical step similarity hypercube with D1 and D2 equals 10, this requires 160,000 operations, which corresponds to a 5000 foot speed up for a typical image."
        ],
        [
            "We can go even further and use a branch and bound technique similar to the efficient stop windows search from Lampard at all.",
            "However, the derivation is a bit lengthy and therefore I will not present in this talk and refer you to Section 5.",
            "Two of our paper."
        ],
        [
            "Now let's go to the experimental evaluation.",
            "I will present two types of experiments.",
            "First classification second detection for object classification, we use objects cropped out of Pascal or seven according to the ground truth bounding boxes, resulting in about 10,000 objects from 20 classes, and the task is to classify all test images using a model trained on all training and validation images."
        ],
        [
            "Here we compare the classification performance of different descriptors according to the accuracy on this twenty class classification task.",
            "For comparison, we showed the results using a GIST descriptor which, among other conventional descriptors, performed best.",
            "Our global self similarity, hypercubes outperform back of local self similarity is substantially nearly by a factor of two when we combine the gist descriptor with any of the similarity descriptors.",
            "In both cases, the combination outperforms its component, which shows how they complement each other.",
            "Further, the gain using similarity hypercubes is again about twice that of local self similarities."
        ],
        [
            "For detection, we evaluate on the THC shape classes data set following the standard protocol is used in many papers.",
            "Since Ferrari, CVP or 7.",
            "It consists of 255 images in five classes and the aim is to detect all objects of these classes up to a bounding box.",
            "For detection, we train a linear SVM and apply a sliding window algorithm to be able to find multiple objects per image."
        ],
        [
            "You represent detection rate versus false positive per image plots for all five classes.",
            "The solid lines are obtained using submitted hypercubes, and the dashed lines are obtained using bag of local self similarities.",
            "The gap in performance is quite visible.",
            "This shows again estimated hypercubes outperform back of local self similarities and that it is possible to use global self similarity for detection, which is the main message of this experiment.",
            "As a side note.",
            "If we compare with other approaches on this data set, we outperform earlier approaches, but some recent approaches perform better from even better.",
            "Note that this is really a site issue, since the purpose here was not to outperform the state of the art, but to establish global self similarity as a useful feature."
        ],
        [
            "Now let's look at the run times for 200 by 200 image computing the global self similarity tensor directly takes about 1 1/2 hours.",
            "Using our method, it takes less than 1.5 minutes, including the computation of the image.",
            "Specific dictionaries.",
            "Then to compute the descriptors is really fast overall to compute the global self similarity tensor, we achieve a 70 fold speedup."
        ],
        [
            "For detection we need about 30 seconds per image for comparison.",
            "If we would want to compute the global self similarity tensor directly for 25,000 Windows in an image, we would be presenting these results only at CPR 2014.",
            "Our method achieves a speedup of about a million, which makes it possible to use global self similarity for detection."
        ],
        [
            "So now that I told you the runtimes, maybe I should go back to the title and change it to read global and feasible self similarity for object classification and detection."
        ],
        [
            "This concludes the talk.",
            "I hope I've convinced you that self similarity should be considered globally rather than locally because it clearly outperforms its local counterpart for both classification and detection.",
            "Further, we have shown that self similarity conveys information truly complementary to conventional descriptors.",
            "Represented methods that make the use of global self similarity feasable both in terms of memory and in terms of runtime.",
            "We also presented to descriptors based on global self similarity, of which I presented one in this talk and it showed how this can be used for detection.",
            "If you are interested in the other descriptor, you can visit us at our poster later today."
        ],
        [
            "Thank you for your attention.",
            "We have time for questions.",
            "Of course we have.",
            "Patient the question was if I could comment on invariants to scale and rotation so.",
            "We did not really evaluate the invariant with respect to rotation for scale.",
            "We can search across multiple scales in the detection and it works quite well actually in the in the detection phase we can basically extract the descriptor for an arbitrary window, no matter which aspect ratio in which size in always at the same time, and therefore we can search the scales and really very efficiently.",
            "So the scale is not the problem rotation we didn't evaluate.",
            "Not.",
            "Thank you so this global similarity.",
            "If it is a fundamental principle of images, so the application should be not unconstrained to classification of action.",
            "Should we have more broad application over this similarity principle, right?",
            "Excuse me, I didn't understand the question.",
            "Sorry.",
            "I mean if this global similarity is a fundamental principle of image representation, the application of this one should not only restrict to classification or object detection should have more broader application of this principle.",
            "Global similarity, right?",
            "Yes, I would expect that this would also work for other applications and already in this conference I've seen quite a few papers which do different things using local self similarities, and I would expect that the global similarity concept would also work in other applications then yes, secure.",
            "So you're advocating for global self similarity under the hand on the Pascal data set.",
            "You have to crop your images, you know to feed the object.",
            "So is it really global?",
            "Self similarity or object level self similarity?",
            "So we extract similarity on the entire image.",
            "For the case of classification, we did use objects which we cropped out of the of the Pascal 7 datasets because our original aim where we wanted to do with global self similarity is detection and therefore we wanted to have the classification task as close as possible to this.",
            "In fact, what the self similarity descriptor describes is the image that you give it to that you give to it, and in this case this certainly the object and we expect that basically we.",
            "Give a global representation of the self similarity within the object.",
            "So the question was if we use the back of local similarities for the local services to which we compare, or if we use an ensemble matching method, so we actually did use the bag of local self similarities using the same parameters that most of the papers that use it as a like like these papers that use it.",
            "Didn't.",
            "No.",
            "So we use the same parameters, for example used in Galar and Lampard.",
            "And I think Chatfield also uses the same parameters.",
            "So we use the bag of local self similarities here it's true.",
            "Excuse me impaired.",
            "So the question is that the correct comparison would be using the same method and innocence it is right?",
            "So we could also compare to the example to the ensemble, and in fact there are some, but since it it modeled the spatial relationships between the different local similarities probably also captures some global self similarity, but look well, captures the spatial relationships between different local self similarities.",
            "And in fact yeah, probably it would be.",
            "It could also be compared to this, yes?",
            "Let's thank our four speakers again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello and welcome to this talk.",
                    "label": 0
                },
                {
                    "sent": "My name is Thomas de Los and this is joint work with Victoria Ferrari.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's first talk about conventional image descriptors.",
                    "label": 0
                },
                {
                    "sent": "They measure direct image properties such as gradients or colors.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And typically follow the assumption that there is a direct visual property shared among images showing objects of the same class.",
                    "label": 1
                },
                {
                    "sent": "However, Schechtman and Irani observed in their CPR 7 paper that this assumption does not always hold, as can be seen from the images here at the bottom.",
                    "label": 0
                },
                {
                    "sent": "Well, all of them so hard they do not share a direct visual property such as colors or textures.",
                    "label": 0
                },
                {
                    "sent": "Not even enter intention and continuity.",
                    "label": 0
                },
                {
                    "sent": "What makes these images similar is that local intensity patterns are repeated within the image in a similar geometric layout.",
                    "label": 0
                },
                {
                    "sent": "The spirit of self similarity is that images are similar.",
                    "label": 0
                },
                {
                    "sent": "If the wave patterns repeat within them is similar and not because they have similar colors or textures.",
                    "label": 1
                },
                {
                    "sent": "Such similarity is an indirect property which generalizes better than conventional descriptors and can be used even when these fail.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The local steps Rescripted proposed the shape and Ronnie is computed as follows for certain interest point, they take a small Patch around it and compute the correlation surface with its immediate surrounding.",
                    "label": 0
                },
                {
                    "sent": "Then the computer lock color histogram over this.",
                    "label": 0
                },
                {
                    "sent": "This is repeated for a lot of interest points.",
                    "label": 0
                },
                {
                    "sent": "This work stood a lot of interest and many people started actively using it quite quickly.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Typical applications of local Cemetery descriptors include object recognition, image retrieval and action recognition.",
                    "label": 1
                },
                {
                    "sent": "For example, Schechtman Irani use it in their original work within an ensemble matching method.",
                    "label": 0
                },
                {
                    "sent": "Boyment uses it within its nearest neighbor approach in CPR 8 and several people use it as yet another feature in multi kernel learning schemes or in other combinations.",
                    "label": 1
                },
                {
                    "sent": "Here, typically a bag of visual words, descriptors computed from local self similarities.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, in all of these works, self similarity is considered locally, whereas we believe it should be considered globally to capture.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Long range similarities within an image.",
                    "label": 0
                },
                {
                    "sent": "In this slide you can see in the top original images with the market Patch and in the bottom and overlay of a global correlation surface with the entire image.",
                    "label": 0
                },
                {
                    "sent": "Although the images are not similar at all in their colors and textures, the correlation surface is are very similar here apart from the left hand, side, left and boundary of the logo results in a similar correlation surface.",
                    "label": 0
                },
                {
                    "sent": "Analogously, at the right hand side.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's an example for Swans.",
                    "label": 0
                },
                {
                    "sent": "Apart from this, one body is similar to the entire body and the Patch from the small neck is similar to the entire neck.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's formalize what is global self similarity, really?",
                    "label": 0
                },
                {
                    "sent": "For an image we compute the self similarity between all pairs of pixels.",
                    "label": 1
                },
                {
                    "sent": "P&P prime.",
                    "label": 0
                },
                {
                    "sent": "Which gives the correlation surface for every pixel peep.",
                    "label": 0
                },
                {
                    "sent": "This will repeat for every pair of pixels.",
                    "label": 0
                },
                {
                    "sent": "Let's do one more.",
                    "label": 0
                },
                {
                    "sent": "And then we end up with a four dimensional steps energy tensor.",
                    "label": 0
                },
                {
                    "sent": "SI for an image.",
                    "label": 0
                },
                {
                    "sent": "Note also that the small correlation surfaces that were used within the local self similarity are fully included here.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The global self similarity tensor is very expensive to compute onto store.",
                    "label": 0
                },
                {
                    "sent": "To compute it, we have to compare every pixel with every other pixel.",
                    "label": 0
                },
                {
                    "sent": "Every comparison takes W square operations leading to H ^2 W, ^2 W squared operations, which for typical image of size 500 by 300 takes about 20 hours.",
                    "label": 0
                },
                {
                    "sent": "The memory requirement is also quadratic in the image size, and here is about 80 gigabytes.",
                    "label": 0
                },
                {
                    "sent": "Therefore, our aim is to reduce both computation time and memory requirement.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So far I hope I convinced you that self similarity should be considered globally and that it is infeasible to compute directly.",
                    "label": 0
                },
                {
                    "sent": "Further, I showed how we formalize it.",
                    "label": 0
                },
                {
                    "sent": "In the remainder I will describe how to reduce the computational complexity of the global self similarity tensor.",
                    "label": 0
                },
                {
                    "sent": "Then we'll talk about one of the two descriptors that we propose to format self similarity such that it can be used in standard machine learning classifiers.",
                    "label": 0
                },
                {
                    "sent": "I will further show our self similarity can be used for object detection and it showed experimentally that global self similarity outperforms local self similarity and that self similarity descriptors are complementary to conventional descriptors, making them ideally suited for combinations.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We want to find an efficient approximation to the global self similarity tensor.",
                    "label": 1
                },
                {
                    "sent": "Therefore we quantize all the patches in the image.",
                    "label": 0
                },
                {
                    "sent": "According to code book theater.",
                    "label": 0
                },
                {
                    "sent": "Then we define the two patches are similar if they are assigned to the same prototype.",
                    "label": 1
                },
                {
                    "sent": "This is certainly valid because similarity is transitive.",
                    "label": 0
                },
                {
                    "sent": "If both patches are similar to certain prototype, they must also be similar to each other.",
                    "label": 0
                },
                {
                    "sent": "So a Patch is assigned to a prototype.",
                    "label": 0
                },
                {
                    "sent": "And then we know that it is similar to all the other pictures that were assigned to the same prototype.",
                    "label": 0
                },
                {
                    "sent": "You see, the positions of these patches highlit.",
                    "label": 0
                },
                {
                    "sent": "This pitch was assigned to the same prototype, resulting in the same assignment.",
                    "label": 0
                },
                {
                    "sent": "Here, dispatch and dispatch were assigned to two different prototypes.",
                    "label": 0
                },
                {
                    "sent": "Using this technique, reduce the runtime to be linear in the image size, resulting in a speedup factor.",
                    "label": 0
                },
                {
                    "sent": "Also linear in the image size.",
                    "label": 0
                },
                {
                    "sent": "For typical image, this corresponds to a 750 fold speedup.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let's go one step further and assume the two pixels are only similar if they are assigned to the same prototype.",
                    "label": 1
                },
                {
                    "sent": "This makes the correlation surface is binary and disjunct.",
                    "label": 0
                },
                {
                    "sent": "Now correlation surface for a pixel is the binary image where all pixels which were assigned to the same prototype are on.",
                    "label": 0
                },
                {
                    "sent": "This further allows us to store the entire self similarity information in a single prototype assignment map MI where we store the assigned prototype for every pixel only.",
                    "label": 0
                },
                {
                    "sent": "On the right here we visualize the prototype assignment map where pixels are colored according to their prototypes.",
                    "label": 0
                },
                {
                    "sent": "They were assigned to their four pixels marked in the same color, were assigned to the same prototype.",
                    "label": 0
                },
                {
                    "sent": "We can easily obtain a binary correlation surface for every pixel.",
                    "label": 0
                },
                {
                    "sent": "Thus this is a compact representation of the 4D self similarity tensor.",
                    "label": 0
                },
                {
                    "sent": "The memory requirements are reduced from quadratic to linear in the image size.",
                    "label": 0
                },
                {
                    "sent": "To obtain the prototype assignment map, we have to choose a codebook theater.",
                    "label": 0
                },
                {
                    "sent": "There are several options and options, but since we are interested in self similarity.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can use image specific Patch product code books which can be much smaller than conventional code.",
                    "label": 1
                },
                {
                    "sent": "Books that are typically used for bag of words representations.",
                    "label": 0
                },
                {
                    "sent": "In fact, contrary to those where it is typically required that the different visual words have the same meaning across images.",
                    "label": 0
                },
                {
                    "sent": "Here we use a codebook specific to the individual images.",
                    "label": 0
                },
                {
                    "sent": "This also matches the spirit of self similarity.",
                    "label": 0
                },
                {
                    "sent": "Best we're only interested where structures repeat within an individual image rather than finding the same appearance across other images.",
                    "label": 0
                },
                {
                    "sent": "He will see the code book for each of the four images.",
                    "label": 0
                },
                {
                    "sent": "And you can clearly see that they are well suited for their respective images.",
                    "label": 0
                },
                {
                    "sent": "This code books out.",
                    "label": 0
                },
                {
                    "sent": "And using K means on randomly sampled patches from these images.",
                    "label": 0
                },
                {
                    "sent": "And once we have these codebooks we can compute the prototype assignment Maps using only one convolution per code word, while image specific code books are most interesting and require less entries for a good image representation, we evaluate other more generic code books and their para meters in the paper.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So far I've been talking about the global self similarity tensor and how to compute it for an image.",
                    "label": 0
                },
                {
                    "sent": "However, as presented so far it is not suited to be used.",
                    "label": 0
                },
                {
                    "sent": "It's not suited to be used in most classifiers since the tensor size depends on the image size and it is too large to work with efficiently.",
                    "label": 0
                },
                {
                    "sent": "Therefore I will now describe how to format a compact fixed size descriptor that can be used within standard machine learning classifiers easily.",
                    "label": 1
                },
                {
                    "sent": "In this paper we present two descriptors, Bank of correlation Surface is an self similarity, hypercubes.",
                    "label": 1
                },
                {
                    "sent": "Why a bit of correlation surfaces are inspired from bag of words approach is here I will talk about self similarity hypercubes.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To obtain a self similarity hypercube, we put a D 1 * D Two grid here 4 by 4 under the prototype assignment map.",
                    "label": 0
                },
                {
                    "sent": "Then for every pair of cells, janjay prime in this grid, we count how many of the pixels within the cells were assigned to the same prototype.",
                    "label": 0
                },
                {
                    "sent": "Another interpretation to this is to sum over the 4D sub part of the self similarity tensor corresponding to the cells.",
                    "label": 0
                },
                {
                    "sent": "This we do for all pairs of cells, resulting in a D 1 * D two times D 1 * D Two tensor where every entry measure measures the similarity of two cells in the image.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To compute the self similarity hypercube for an H prime times W prime image window naively requires H prime squared times W prime square operations.",
                    "label": 0
                },
                {
                    "sent": "Using this for sliding window detection is very expensive because there are many windows in an image now with.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And how to do this more efficiently?",
                    "label": 0
                },
                {
                    "sent": "For this we consider the interpretation that the self similarity hypercube entries contains sums over the 40 subparts of the self similarity tensor corresponding to image cells.",
                    "label": 0
                },
                {
                    "sent": "To obtain these sums efficiently, we compute a 4D integral self similarity tensor analogously to integral images.",
                    "label": 0
                },
                {
                    "sent": "From this integral self similarity tensor, we can then obtain the number of pixels which were assigned to the same prototype within two cells using just 16 vlookups.",
                    "label": 0
                },
                {
                    "sent": "Therefore, it is possible to compute a self similarity hypercube for an arbitrary window using just 16 look ups per entry, which is fast, and in particular it does not depend on the window size.",
                    "label": 1
                },
                {
                    "sent": "For typical step similarity hypercube with D1 and D2 equals 10, this requires 160,000 operations, which corresponds to a 5000 foot speed up for a typical image.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can go even further and use a branch and bound technique similar to the efficient stop windows search from Lampard at all.",
                    "label": 0
                },
                {
                    "sent": "However, the derivation is a bit lengthy and therefore I will not present in this talk and refer you to Section 5.",
                    "label": 0
                },
                {
                    "sent": "Two of our paper.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let's go to the experimental evaluation.",
                    "label": 0
                },
                {
                    "sent": "I will present two types of experiments.",
                    "label": 0
                },
                {
                    "sent": "First classification second detection for object classification, we use objects cropped out of Pascal or seven according to the ground truth bounding boxes, resulting in about 10,000 objects from 20 classes, and the task is to classify all test images using a model trained on all training and validation images.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here we compare the classification performance of different descriptors according to the accuracy on this twenty class classification task.",
                    "label": 0
                },
                {
                    "sent": "For comparison, we showed the results using a GIST descriptor which, among other conventional descriptors, performed best.",
                    "label": 1
                },
                {
                    "sent": "Our global self similarity, hypercubes outperform back of local self similarity is substantially nearly by a factor of two when we combine the gist descriptor with any of the similarity descriptors.",
                    "label": 0
                },
                {
                    "sent": "In both cases, the combination outperforms its component, which shows how they complement each other.",
                    "label": 0
                },
                {
                    "sent": "Further, the gain using similarity hypercubes is again about twice that of local self similarities.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For detection, we evaluate on the THC shape classes data set following the standard protocol is used in many papers.",
                    "label": 1
                },
                {
                    "sent": "Since Ferrari, CVP or 7.",
                    "label": 0
                },
                {
                    "sent": "It consists of 255 images in five classes and the aim is to detect all objects of these classes up to a bounding box.",
                    "label": 1
                },
                {
                    "sent": "For detection, we train a linear SVM and apply a sliding window algorithm to be able to find multiple objects per image.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You represent detection rate versus false positive per image plots for all five classes.",
                    "label": 0
                },
                {
                    "sent": "The solid lines are obtained using submitted hypercubes, and the dashed lines are obtained using bag of local self similarities.",
                    "label": 0
                },
                {
                    "sent": "The gap in performance is quite visible.",
                    "label": 0
                },
                {
                    "sent": "This shows again estimated hypercubes outperform back of local self similarities and that it is possible to use global self similarity for detection, which is the main message of this experiment.",
                    "label": 1
                },
                {
                    "sent": "As a side note.",
                    "label": 0
                },
                {
                    "sent": "If we compare with other approaches on this data set, we outperform earlier approaches, but some recent approaches perform better from even better.",
                    "label": 0
                },
                {
                    "sent": "Note that this is really a site issue, since the purpose here was not to outperform the state of the art, but to establish global self similarity as a useful feature.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let's look at the run times for 200 by 200 image computing the global self similarity tensor directly takes about 1 1/2 hours.",
                    "label": 0
                },
                {
                    "sent": "Using our method, it takes less than 1.5 minutes, including the computation of the image.",
                    "label": 1
                },
                {
                    "sent": "Specific dictionaries.",
                    "label": 0
                },
                {
                    "sent": "Then to compute the descriptors is really fast overall to compute the global self similarity tensor, we achieve a 70 fold speedup.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For detection we need about 30 seconds per image for comparison.",
                    "label": 1
                },
                {
                    "sent": "If we would want to compute the global self similarity tensor directly for 25,000 Windows in an image, we would be presenting these results only at CPR 2014.",
                    "label": 0
                },
                {
                    "sent": "Our method achieves a speedup of about a million, which makes it possible to use global self similarity for detection.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now that I told you the runtimes, maybe I should go back to the title and change it to read global and feasible self similarity for object classification and detection.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This concludes the talk.",
                    "label": 0
                },
                {
                    "sent": "I hope I've convinced you that self similarity should be considered globally rather than locally because it clearly outperforms its local counterpart for both classification and detection.",
                    "label": 1
                },
                {
                    "sent": "Further, we have shown that self similarity conveys information truly complementary to conventional descriptors.",
                    "label": 1
                },
                {
                    "sent": "Represented methods that make the use of global self similarity feasable both in terms of memory and in terms of runtime.",
                    "label": 0
                },
                {
                    "sent": "We also presented to descriptors based on global self similarity, of which I presented one in this talk and it showed how this can be used for detection.",
                    "label": 0
                },
                {
                    "sent": "If you are interested in the other descriptor, you can visit us at our poster later today.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you for your attention.",
                    "label": 1
                },
                {
                    "sent": "We have time for questions.",
                    "label": 0
                },
                {
                    "sent": "Of course we have.",
                    "label": 0
                },
                {
                    "sent": "Patient the question was if I could comment on invariants to scale and rotation so.",
                    "label": 0
                },
                {
                    "sent": "We did not really evaluate the invariant with respect to rotation for scale.",
                    "label": 0
                },
                {
                    "sent": "We can search across multiple scales in the detection and it works quite well actually in the in the detection phase we can basically extract the descriptor for an arbitrary window, no matter which aspect ratio in which size in always at the same time, and therefore we can search the scales and really very efficiently.",
                    "label": 0
                },
                {
                    "sent": "So the scale is not the problem rotation we didn't evaluate.",
                    "label": 0
                },
                {
                    "sent": "Not.",
                    "label": 0
                },
                {
                    "sent": "Thank you so this global similarity.",
                    "label": 0
                },
                {
                    "sent": "If it is a fundamental principle of images, so the application should be not unconstrained to classification of action.",
                    "label": 0
                },
                {
                    "sent": "Should we have more broad application over this similarity principle, right?",
                    "label": 0
                },
                {
                    "sent": "Excuse me, I didn't understand the question.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "I mean if this global similarity is a fundamental principle of image representation, the application of this one should not only restrict to classification or object detection should have more broader application of this principle.",
                    "label": 0
                },
                {
                    "sent": "Global similarity, right?",
                    "label": 0
                },
                {
                    "sent": "Yes, I would expect that this would also work for other applications and already in this conference I've seen quite a few papers which do different things using local self similarities, and I would expect that the global similarity concept would also work in other applications then yes, secure.",
                    "label": 0
                },
                {
                    "sent": "So you're advocating for global self similarity under the hand on the Pascal data set.",
                    "label": 0
                },
                {
                    "sent": "You have to crop your images, you know to feed the object.",
                    "label": 0
                },
                {
                    "sent": "So is it really global?",
                    "label": 0
                },
                {
                    "sent": "Self similarity or object level self similarity?",
                    "label": 0
                },
                {
                    "sent": "So we extract similarity on the entire image.",
                    "label": 0
                },
                {
                    "sent": "For the case of classification, we did use objects which we cropped out of the of the Pascal 7 datasets because our original aim where we wanted to do with global self similarity is detection and therefore we wanted to have the classification task as close as possible to this.",
                    "label": 0
                },
                {
                    "sent": "In fact, what the self similarity descriptor describes is the image that you give it to that you give to it, and in this case this certainly the object and we expect that basically we.",
                    "label": 0
                },
                {
                    "sent": "Give a global representation of the self similarity within the object.",
                    "label": 0
                },
                {
                    "sent": "So the question was if we use the back of local similarities for the local services to which we compare, or if we use an ensemble matching method, so we actually did use the bag of local self similarities using the same parameters that most of the papers that use it as a like like these papers that use it.",
                    "label": 0
                },
                {
                    "sent": "Didn't.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "So we use the same parameters, for example used in Galar and Lampard.",
                    "label": 0
                },
                {
                    "sent": "And I think Chatfield also uses the same parameters.",
                    "label": 0
                },
                {
                    "sent": "So we use the bag of local self similarities here it's true.",
                    "label": 0
                },
                {
                    "sent": "Excuse me impaired.",
                    "label": 0
                },
                {
                    "sent": "So the question is that the correct comparison would be using the same method and innocence it is right?",
                    "label": 0
                },
                {
                    "sent": "So we could also compare to the example to the ensemble, and in fact there are some, but since it it modeled the spatial relationships between the different local similarities probably also captures some global self similarity, but look well, captures the spatial relationships between different local self similarities.",
                    "label": 0
                },
                {
                    "sent": "And in fact yeah, probably it would be.",
                    "label": 0
                },
                {
                    "sent": "It could also be compared to this, yes?",
                    "label": 0
                },
                {
                    "sent": "Let's thank our four speakers again.",
                    "label": 0
                }
            ]
        }
    }
}