{
    "id": "55vhgbmuposskw3mvpil7hgfgdw7wj64",
    "title": "Escaping From Saddle Points --- Online Stochastic Gradient for Tensor Decomposition",
    "info": {
        "author": [
            "Furong Huang, Department of Computer Science, University of California, Irvine"
        ],
        "published": "Aug. 20, 2015",
        "recorded": "July 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2015_huang_tensor_decomposition/",
    "segmentation": [
        [
            "So today I'm going to talk about us online stochastic gradient descent for tensor decomposition.",
            "This is a joint work with wrong from Microsoft Research.",
            "True achieve from UC Berkeley and Young from Cornell.",
            "So we'll talk about escaping from the saddle points today.",
            "Um?"
        ],
        [
            "So just an outline of what I'm going to talk about today.",
            "First, I'll give you some motivations why you know stochastic gradient descent and is interesting, and will give a summary of contribution.",
            "Will talk about SGD for nonconvex optimization in details, and then I'll give you an application for orthogonal tensor decomposition and show some experiment results and will conclude.",
            "So let's get started."
        ],
        [
            "So.",
            "I guess everyone in the audience is very familiar with stochastic gradient descent, so the stochastic gradient descent optimization problem tried to optimize the function FW where W is the support, W is in the dimensional D vector, and you wanted to minimize the function.",
            "Find the global minimum of the function.",
            "The function can be general, it can be convex or non convex, so the stochastic gradient descent is very simple.",
            "You first initialize from a random point W 0.",
            "And then, you know, iteratively you have this update.",
            "So you move your your stochastic gradient.",
            "Oracle would observe some SG WT based on the current point and then you move towards the opposite direction of SG, WT and eat are there is the learning on step sites.",
            "Are moving step sites, so for of course for stochastic gradient descent to work you have to assume some you know.",
            "Of course the expected value of SJW should be the gradient.",
            "And you don't also don't want the gradient to fluctuate too much.",
            "You want it to be bounded around the.",
            "You know the gradient.",
            "So a lot of people have been studying on this stochastic gradient descent for all convex function is well studied.",
            "However, in many of the applications recently we you know we look at non convex functions.",
            "For example in neural Nets the very popular back propagation is nothing but using the gradient descend or stochastic gradient descent on a non convex function, for example sigmoid, which is a very popular one.",
            "Also in, you know spectral methods well.",
            "You can do turn on matrix or tensor decompositions to find the model parameters and usually those decompositions are.",
            "Also you have to optimize over non convex function."
        ],
        [
            "The bad news is that you know, without any additional assumption, optimizing over non convex functions NP hard we can solve it.",
            "You know with yeah local up with so many local minimums on the long convex function you you is very hard to find the global minimum and also with so many saddle points is very hard to find the local minimum."
        ],
        [
            "So what is a saddle point?",
            "A saddle point is not a local minimum, but it has a gradient.",
            "You know the gradient of the saddle point is 0 is a stationary point.",
            "So for example, in the figure on your right hand side, you know the saddle point is an axe.",
            "You can see from in the direction of Axb.",
            "It is kind of a local minimum, but in the direction of CXD it is a local maximum.",
            "So the question is that.",
            "Is stochastic gradient descent the 1st order method effective in presence of saddle points?"
        ],
        [
            "So, given a nonconvex function with many saddle points, what kind of property will guarantee the you know stochastic gradient descent to converge to a local minimum?",
            "So this is the question we are going to."
        ],
        [
            "Answer of course I give you this answer is like strict saddle property, but we'll talk about that later on.",
            "So."
        ],
        [
            "Let's go to the details of using stochastic gradient descent for nonconvex optimization."
        ],
        [
            "Sorry, just the summary of contributions.",
            "We have identified a wide class of non convex function called St saddle function.",
            "This function includes you know functions with.",
            "Sorry this class includes functions with exponentially many local extremal.",
            "You know minimum, maximum and saddle points.",
            "We also proved that stochastic gradient descent converge to a local minimum in polynomial time under the strict settle.",
            "Property and we apply over SGD algorithm to learn the orthogonal tensor decomposition.",
            "We found the objective which satisfies the saddle St St, Saddle property and this is the first online first order algorithm with global convergence guarantee."
        ],
        [
            "So the quest."
        ],
        [
            "And here is what property will guarantee the local progress."
        ],
        [
            "You know, with this saddle points, we know that stationary points is the points where you know gradient of FW is zero and this includes local, minimal, local maximal and subtle points.",
            "However, we know that if we look at the Hessian so when there is a saddle point we know that has seen has both positive and negative eigenvalues, so."
        ],
        [
            "Here comes the definition of strict settle function.",
            "So we define the strict set of function as a twice differentiable FW which we call district saddle.",
            "If all the local minimal have, that's the.",
            "Has seen is positive definite.",
            "Annoys other stationary point.",
            "Satisfies that there is the minimal eigenvalue of the Hessian is smaller than 0."
        ],
        [
            "Meaning that there is a direction that you have a minus.",
            "You know have a negative eigenvalue.",
            "So here is just an example here you know if you look at the function C which is X ^2 -- Y square.",
            "You can see the three figures here.",
            "You know the first one is the local minimum, can see the.",
            "I don't know if you can see the dots here, so at this local at this local minimum W minus W star star is local minimum.",
            "The norm is bounded by Delta.",
            "You know that you know this is just to show you know a showcase of what the local minimum is and also the gradient here is zero and the.",
            "Halcyon is positive definite.",
            "So if you see the saddle point here, for example, in this one, it is the thought I draw here an you know that the minimum the minimum eigenvalue vector is smaller than some minus,, is a positive value, so it's a negative value for.",
            "For other points, we know that the.",
            "The gradient.",
            "The normal the gradient is greater than epsilon, so you cannot have 0.",
            "Gradient in other points.",
            "So with all these.",
            "In mind.",
            "Intuitively, we know that if we have these properties, the three properties I described here, then you know we can always use the housing information doing the 2nd order Taylor expansion of the function, and if we find that there is an eigen negative eigenvalue of the Hessian, we can always hope to find a direction that we can escape from the saddle point, right?",
            "So this is pretty intuitive and surprisingly we know we were going to prove that.",
            "The stochastic gradient descent can also escape from the saddle point efficiently using just the 1st order gradient information."
        ],
        [
            "So what is the intuition here?",
            "Why would STD work on a saddle point with you know this only first order information.",
            "So here we again look at the toy example the equals to X ^2 -- y ^2.",
            "So if you see here.",
            "For this thought, this is the saddle point.",
            "In this example, you know the SGD would have some.",
            "So if you have some, for example, you have some.",
            "Your SGD would move in all the directions around the saddle point.",
            "If for some small probability you happen to move around this direction, this Y direction, your STD movement would reinforce or boost the movement into that direction.",
            "Although if you have some.",
            "Probability of moving in this yx.",
            "Sorry X direction then you ask Judy would remain bounded in this saddle point you won't escape, so the idea is that OK?",
            "They so if this is another view of the same figure.",
            "Here you can see that if we do, if we have some noise which help us to go into the direction of Y then we will escape from the saddle point quickly.",
            "But if we.",
            "A very unlucky and stuck in this axe direction, then well stuck there.",
            "So was the."
        ],
        [
            "Intuition in mind, here is our modified as."
        ],
        [
            "The algorithm, So what is it?",
            "The noisy stochastic gradient descent algorithm is a very simple one, is just the minor modification of STD, meaning that at each step, which is sample annoys N, which is uniform from the which is uniformly from the unit sphere, and so the algorithm becomes that the next point would be the current point minus the step size times the SGW plus some noise.",
            "So why we do that is to make sure that there is some probability that you are going to go to all the directions around the saddle point."
        ],
        [
            "So of course we assume some nice properties on this function.",
            "For example smoothness of the gradient and Lipschitz of the Hessian.",
            "So gay."
        ],
        [
            "In all this.",
            "Let me introduce you."
        ],
        [
            "Main result, so the convergence theory.",
            "What is it?",
            "Is that under assumptions above the strict settle property we talked about for any data greater than zero, there always exist a threshold.",
            "Which is it a maximum and that as long as the step size is bounded by that atomic maximum we have WTT is the convergence time is our close to some local minima with.",
            "Probability at least one minus that, so is a high probability bound.",
            "So."
        ],
        [
            "Well, first ignore these complicated equations for now and talk about something here.",
            "So remember that we only talked about getting our close to some local minimum, but we haven't talked about the overall convergence.",
            "So in order to get overall convergence will have to, you know, sorry, in order to get one over root convergence rate, we can use the theorem first to find the point that is inside the strong convex region of local minimum.",
            "And then decrease the learning rate by 1 / T. So.",
            "So I just wanted to give you a brief idea about what the proof is so."
        ],
        [
            "For all the points when for all the non stationary points, when the gradient is large enough we can always prove we can prove that the expected function value is decreased by at least Omega order of Little Square.",
            "Italy is the step size and then at the saddle point when the gradient is small.",
            "Of course the saddle point, we know that gradient small and we have this non negative negative direction which is that.",
            "The smallest eigenvalue of the Hessian is smaller than minus, We can prove that the expected function value is decreased by order ITA.",
            "So was at most other one over each time.",
            "So.",
            "A combination of this.",
            "We know that the function the function expected function value would decrease by at least order ETA in at most order one over iterations, so there will be always a small, probably as long as there is a small probability of being order one square root, it'll close to a local minimum, so with all so I've talked about 1, two and three.",
            "So now we also assume that the function is bounded.",
            "Because of this business of the, you know, the hassian and the.",
            "Gradient, so with the function value bounded we can prove that in order one over each square steps with at least constant probability, we will WT will be square root E to close to a local minimum so."
        ],
        [
            "So now again we have another lemma which says that once WT is.",
            "Close enough to some local minimum W star with probability at least one over that over 2.",
            "You know W T + 1 would still be in this local minimum.",
            "You know it will be close to some order.",
            "Square root E to choose to the optimal point for all the eyes which is in the order of this so after so with all these 125 we can, we can argue that after order log one over there to airparks of you know order one square iterations that's from yeah, that's from here, right?",
            "We say that.",
            "In order one over other square steps will at least have some probability which is close to the local minimum.",
            "So the probability of success will be one over.",
            "This value is essentially one over data, so it's a high probability bound.",
            "So this completes the argument OK.",
            "So."
        ],
        [
            "I'll just briefly talk about the applications, so we now have the convergence theory.",
            "We just briefly talk about the applique."
        ],
        [
            "Mission for orthogonal tensor decomposition.",
            "So the motivation I guess you know I don't have to motivate too much, we can learn latent variable graphical models using tensor decomposition and the model parameters are learned through decomposition of higher order moments.",
            "So for example, a 4th order orthogonal tensor decomposition you you you can you have a tensor T which is the 4th order tensor.",
            "It can be decomposed into like the tensor product of AI's.",
            "From one 2D sent you have some constraints.",
            "For example, the normal AI is 1 and for any two vectors they are, so essentially a is also normal, right?",
            "So our goal is to, given the tensor T we wanted to recover a. I swear it is orthogonal.",
            "So."
        ],
        [
            "You know this problem is challenging because of the symmetry inherently is.",
            "Susceptible to subtle point issues and.",
            "Long as because we are asking to find the D different components AI any permutation with yellow valid solution and we also this kind of symmetry can create exponentially many local minima and saddle points.",
            "So what we do is like we identified a new objective function which satisfies the strict settle property we described before and we developed a first online algorithm for orthogonal tensor decomposition with convergence guarantee.",
            "So this is a key step towards making tensor decomposition algorithms scalable 'cause we don't have to look at the housing information.",
            "So what is the theorem here?",
            "So our new objective function is strict subtle Moreover.",
            "All is local minimal.",
            "Have the form you I = 2 K, a permutation of I permit permutation of a for some copy equals 2 great positive or minus one and permutation for any kind of permutation.",
            "Essentially we want we can flip the signs of the eigenvectors and also do the column permutation of the eigenvector matrix."
        ],
        [
            "So here are some mix."
        ],
        [
            "Elemental results, so we compared with the traditional Reconstruction Era objective with our new object.",
            "If I didn't have, you know, I didn't give you the exact form of the new objective is in our paper.",
            "I don't want to confuse you for now.",
            "So yeah, if you have more questions, you can ask me later on.",
            "So we compare this to objective and we show that our new object objective converge much better than the.",
            "Traditional Reconstruction Era."
        ],
        [
            "So we looked at the ICA setting performance with a mini batch of size 100 and we showed that when we're doing the constant learning rate, we can have some still have some errors here.",
            "But when we decrease the learning rate, using it to buy T, then we have that the convergence the reconstruction error will go to 0."
        ],
        [
            "So just to conclude, we identified the class or function called saddle strict settle property function and we show that stochastic gradient descent with minor modification can converge to a local minimum under strict set of property and we also developed a new online algorithm for tensor decomposition which is a non convex optimization problem.",
            "Yeah, that's it.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So today I'm going to talk about us online stochastic gradient descent for tensor decomposition.",
                    "label": 1
                },
                {
                    "sent": "This is a joint work with wrong from Microsoft Research.",
                    "label": 0
                },
                {
                    "sent": "True achieve from UC Berkeley and Young from Cornell.",
                    "label": 1
                },
                {
                    "sent": "So we'll talk about escaping from the saddle points today.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just an outline of what I'm going to talk about today.",
                    "label": 0
                },
                {
                    "sent": "First, I'll give you some motivations why you know stochastic gradient descent and is interesting, and will give a summary of contribution.",
                    "label": 1
                },
                {
                    "sent": "Will talk about SGD for nonconvex optimization in details, and then I'll give you an application for orthogonal tensor decomposition and show some experiment results and will conclude.",
                    "label": 1
                },
                {
                    "sent": "So let's get started.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I guess everyone in the audience is very familiar with stochastic gradient descent, so the stochastic gradient descent optimization problem tried to optimize the function FW where W is the support, W is in the dimensional D vector, and you wanted to minimize the function.",
                    "label": 0
                },
                {
                    "sent": "Find the global minimum of the function.",
                    "label": 0
                },
                {
                    "sent": "The function can be general, it can be convex or non convex, so the stochastic gradient descent is very simple.",
                    "label": 0
                },
                {
                    "sent": "You first initialize from a random point W 0.",
                    "label": 0
                },
                {
                    "sent": "And then, you know, iteratively you have this update.",
                    "label": 0
                },
                {
                    "sent": "So you move your your stochastic gradient.",
                    "label": 0
                },
                {
                    "sent": "Oracle would observe some SG WT based on the current point and then you move towards the opposite direction of SG, WT and eat are there is the learning on step sites.",
                    "label": 0
                },
                {
                    "sent": "Are moving step sites, so for of course for stochastic gradient descent to work you have to assume some you know.",
                    "label": 0
                },
                {
                    "sent": "Of course the expected value of SJW should be the gradient.",
                    "label": 0
                },
                {
                    "sent": "And you don't also don't want the gradient to fluctuate too much.",
                    "label": 0
                },
                {
                    "sent": "You want it to be bounded around the.",
                    "label": 0
                },
                {
                    "sent": "You know the gradient.",
                    "label": 0
                },
                {
                    "sent": "So a lot of people have been studying on this stochastic gradient descent for all convex function is well studied.",
                    "label": 1
                },
                {
                    "sent": "However, in many of the applications recently we you know we look at non convex functions.",
                    "label": 0
                },
                {
                    "sent": "For example in neural Nets the very popular back propagation is nothing but using the gradient descend or stochastic gradient descent on a non convex function, for example sigmoid, which is a very popular one.",
                    "label": 1
                },
                {
                    "sent": "Also in, you know spectral methods well.",
                    "label": 0
                },
                {
                    "sent": "You can do turn on matrix or tensor decompositions to find the model parameters and usually those decompositions are.",
                    "label": 0
                },
                {
                    "sent": "Also you have to optimize over non convex function.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The bad news is that you know, without any additional assumption, optimizing over non convex functions NP hard we can solve it.",
                    "label": 0
                },
                {
                    "sent": "You know with yeah local up with so many local minimums on the long convex function you you is very hard to find the global minimum and also with so many saddle points is very hard to find the local minimum.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is a saddle point?",
                    "label": 1
                },
                {
                    "sent": "A saddle point is not a local minimum, but it has a gradient.",
                    "label": 0
                },
                {
                    "sent": "You know the gradient of the saddle point is 0 is a stationary point.",
                    "label": 0
                },
                {
                    "sent": "So for example, in the figure on your right hand side, you know the saddle point is an axe.",
                    "label": 0
                },
                {
                    "sent": "You can see from in the direction of Axb.",
                    "label": 0
                },
                {
                    "sent": "It is kind of a local minimum, but in the direction of CXD it is a local maximum.",
                    "label": 0
                },
                {
                    "sent": "So the question is that.",
                    "label": 1
                },
                {
                    "sent": "Is stochastic gradient descent the 1st order method effective in presence of saddle points?",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, given a nonconvex function with many saddle points, what kind of property will guarantee the you know stochastic gradient descent to converge to a local minimum?",
                    "label": 0
                },
                {
                    "sent": "So this is the question we are going to.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Answer of course I give you this answer is like strict saddle property, but we'll talk about that later on.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's go to the details of using stochastic gradient descent for nonconvex optimization.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sorry, just the summary of contributions.",
                    "label": 0
                },
                {
                    "sent": "We have identified a wide class of non convex function called St saddle function.",
                    "label": 0
                },
                {
                    "sent": "This function includes you know functions with.",
                    "label": 0
                },
                {
                    "sent": "Sorry this class includes functions with exponentially many local extremal.",
                    "label": 1
                },
                {
                    "sent": "You know minimum, maximum and saddle points.",
                    "label": 1
                },
                {
                    "sent": "We also proved that stochastic gradient descent converge to a local minimum in polynomial time under the strict settle.",
                    "label": 1
                },
                {
                    "sent": "Property and we apply over SGD algorithm to learn the orthogonal tensor decomposition.",
                    "label": 0
                },
                {
                    "sent": "We found the objective which satisfies the saddle St St, Saddle property and this is the first online first order algorithm with global convergence guarantee.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the quest.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is what property will guarantee the local progress.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know, with this saddle points, we know that stationary points is the points where you know gradient of FW is zero and this includes local, minimal, local maximal and subtle points.",
                    "label": 0
                },
                {
                    "sent": "However, we know that if we look at the Hessian so when there is a saddle point we know that has seen has both positive and negative eigenvalues, so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here comes the definition of strict settle function.",
                    "label": 0
                },
                {
                    "sent": "So we define the strict set of function as a twice differentiable FW which we call district saddle.",
                    "label": 1
                },
                {
                    "sent": "If all the local minimal have, that's the.",
                    "label": 0
                },
                {
                    "sent": "Has seen is positive definite.",
                    "label": 0
                },
                {
                    "sent": "Annoys other stationary point.",
                    "label": 0
                },
                {
                    "sent": "Satisfies that there is the minimal eigenvalue of the Hessian is smaller than 0.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Meaning that there is a direction that you have a minus.",
                    "label": 0
                },
                {
                    "sent": "You know have a negative eigenvalue.",
                    "label": 0
                },
                {
                    "sent": "So here is just an example here you know if you look at the function C which is X ^2 -- Y square.",
                    "label": 0
                },
                {
                    "sent": "You can see the three figures here.",
                    "label": 0
                },
                {
                    "sent": "You know the first one is the local minimum, can see the.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you can see the dots here, so at this local at this local minimum W minus W star star is local minimum.",
                    "label": 0
                },
                {
                    "sent": "The norm is bounded by Delta.",
                    "label": 0
                },
                {
                    "sent": "You know that you know this is just to show you know a showcase of what the local minimum is and also the gradient here is zero and the.",
                    "label": 0
                },
                {
                    "sent": "Halcyon is positive definite.",
                    "label": 0
                },
                {
                    "sent": "So if you see the saddle point here, for example, in this one, it is the thought I draw here an you know that the minimum the minimum eigenvalue vector is smaller than some minus,, is a positive value, so it's a negative value for.",
                    "label": 0
                },
                {
                    "sent": "For other points, we know that the.",
                    "label": 0
                },
                {
                    "sent": "The gradient.",
                    "label": 0
                },
                {
                    "sent": "The normal the gradient is greater than epsilon, so you cannot have 0.",
                    "label": 0
                },
                {
                    "sent": "Gradient in other points.",
                    "label": 0
                },
                {
                    "sent": "So with all these.",
                    "label": 0
                },
                {
                    "sent": "In mind.",
                    "label": 0
                },
                {
                    "sent": "Intuitively, we know that if we have these properties, the three properties I described here, then you know we can always use the housing information doing the 2nd order Taylor expansion of the function, and if we find that there is an eigen negative eigenvalue of the Hessian, we can always hope to find a direction that we can escape from the saddle point, right?",
                    "label": 1
                },
                {
                    "sent": "So this is pretty intuitive and surprisingly we know we were going to prove that.",
                    "label": 0
                },
                {
                    "sent": "The stochastic gradient descent can also escape from the saddle point efficiently using just the 1st order gradient information.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is the intuition here?",
                    "label": 0
                },
                {
                    "sent": "Why would STD work on a saddle point with you know this only first order information.",
                    "label": 1
                },
                {
                    "sent": "So here we again look at the toy example the equals to X ^2 -- y ^2.",
                    "label": 0
                },
                {
                    "sent": "So if you see here.",
                    "label": 0
                },
                {
                    "sent": "For this thought, this is the saddle point.",
                    "label": 1
                },
                {
                    "sent": "In this example, you know the SGD would have some.",
                    "label": 0
                },
                {
                    "sent": "So if you have some, for example, you have some.",
                    "label": 0
                },
                {
                    "sent": "Your SGD would move in all the directions around the saddle point.",
                    "label": 0
                },
                {
                    "sent": "If for some small probability you happen to move around this direction, this Y direction, your STD movement would reinforce or boost the movement into that direction.",
                    "label": 0
                },
                {
                    "sent": "Although if you have some.",
                    "label": 0
                },
                {
                    "sent": "Probability of moving in this yx.",
                    "label": 0
                },
                {
                    "sent": "Sorry X direction then you ask Judy would remain bounded in this saddle point you won't escape, so the idea is that OK?",
                    "label": 1
                },
                {
                    "sent": "They so if this is another view of the same figure.",
                    "label": 0
                },
                {
                    "sent": "Here you can see that if we do, if we have some noise which help us to go into the direction of Y then we will escape from the saddle point quickly.",
                    "label": 0
                },
                {
                    "sent": "But if we.",
                    "label": 0
                },
                {
                    "sent": "A very unlucky and stuck in this axe direction, then well stuck there.",
                    "label": 0
                },
                {
                    "sent": "So was the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Intuition in mind, here is our modified as.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The algorithm, So what is it?",
                    "label": 0
                },
                {
                    "sent": "The noisy stochastic gradient descent algorithm is a very simple one, is just the minor modification of STD, meaning that at each step, which is sample annoys N, which is uniform from the which is uniformly from the unit sphere, and so the algorithm becomes that the next point would be the current point minus the step size times the SGW plus some noise.",
                    "label": 1
                },
                {
                    "sent": "So why we do that is to make sure that there is some probability that you are going to go to all the directions around the saddle point.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So of course we assume some nice properties on this function.",
                    "label": 0
                },
                {
                    "sent": "For example smoothness of the gradient and Lipschitz of the Hessian.",
                    "label": 0
                },
                {
                    "sent": "So gay.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In all this.",
                    "label": 0
                },
                {
                    "sent": "Let me introduce you.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Main result, so the convergence theory.",
                    "label": 0
                },
                {
                    "sent": "What is it?",
                    "label": 0
                },
                {
                    "sent": "Is that under assumptions above the strict settle property we talked about for any data greater than zero, there always exist a threshold.",
                    "label": 0
                },
                {
                    "sent": "Which is it a maximum and that as long as the step size is bounded by that atomic maximum we have WTT is the convergence time is our close to some local minima with.",
                    "label": 1
                },
                {
                    "sent": "Probability at least one minus that, so is a high probability bound.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, first ignore these complicated equations for now and talk about something here.",
                    "label": 0
                },
                {
                    "sent": "So remember that we only talked about getting our close to some local minimum, but we haven't talked about the overall convergence.",
                    "label": 0
                },
                {
                    "sent": "So in order to get overall convergence will have to, you know, sorry, in order to get one over root convergence rate, we can use the theorem first to find the point that is inside the strong convex region of local minimum.",
                    "label": 1
                },
                {
                    "sent": "And then decrease the learning rate by 1 / T. So.",
                    "label": 0
                },
                {
                    "sent": "So I just wanted to give you a brief idea about what the proof is so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For all the points when for all the non stationary points, when the gradient is large enough we can always prove we can prove that the expected function value is decreased by at least Omega order of Little Square.",
                    "label": 0
                },
                {
                    "sent": "Italy is the step size and then at the saddle point when the gradient is small.",
                    "label": 1
                },
                {
                    "sent": "Of course the saddle point, we know that gradient small and we have this non negative negative direction which is that.",
                    "label": 0
                },
                {
                    "sent": "The smallest eigenvalue of the Hessian is smaller than minus, We can prove that the expected function value is decreased by order ITA.",
                    "label": 0
                },
                {
                    "sent": "So was at most other one over each time.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "A combination of this.",
                    "label": 0
                },
                {
                    "sent": "We know that the function the function expected function value would decrease by at least order ETA in at most order one over iterations, so there will be always a small, probably as long as there is a small probability of being order one square root, it'll close to a local minimum, so with all so I've talked about 1, two and three.",
                    "label": 1
                },
                {
                    "sent": "So now we also assume that the function is bounded.",
                    "label": 0
                },
                {
                    "sent": "Because of this business of the, you know, the hassian and the.",
                    "label": 1
                },
                {
                    "sent": "Gradient, so with the function value bounded we can prove that in order one over each square steps with at least constant probability, we will WT will be square root E to close to a local minimum so.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now again we have another lemma which says that once WT is.",
                    "label": 0
                },
                {
                    "sent": "Close enough to some local minimum W star with probability at least one over that over 2.",
                    "label": 0
                },
                {
                    "sent": "You know W T + 1 would still be in this local minimum.",
                    "label": 0
                },
                {
                    "sent": "You know it will be close to some order.",
                    "label": 0
                },
                {
                    "sent": "Square root E to choose to the optimal point for all the eyes which is in the order of this so after so with all these 125 we can, we can argue that after order log one over there to airparks of you know order one square iterations that's from yeah, that's from here, right?",
                    "label": 0
                },
                {
                    "sent": "We say that.",
                    "label": 0
                },
                {
                    "sent": "In order one over other square steps will at least have some probability which is close to the local minimum.",
                    "label": 0
                },
                {
                    "sent": "So the probability of success will be one over.",
                    "label": 0
                },
                {
                    "sent": "This value is essentially one over data, so it's a high probability bound.",
                    "label": 0
                },
                {
                    "sent": "So this completes the argument OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll just briefly talk about the applications, so we now have the convergence theory.",
                    "label": 0
                },
                {
                    "sent": "We just briefly talk about the applique.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mission for orthogonal tensor decomposition.",
                    "label": 0
                },
                {
                    "sent": "So the motivation I guess you know I don't have to motivate too much, we can learn latent variable graphical models using tensor decomposition and the model parameters are learned through decomposition of higher order moments.",
                    "label": 1
                },
                {
                    "sent": "So for example, a 4th order orthogonal tensor decomposition you you you can you have a tensor T which is the 4th order tensor.",
                    "label": 0
                },
                {
                    "sent": "It can be decomposed into like the tensor product of AI's.",
                    "label": 0
                },
                {
                    "sent": "From one 2D sent you have some constraints.",
                    "label": 0
                },
                {
                    "sent": "For example, the normal AI is 1 and for any two vectors they are, so essentially a is also normal, right?",
                    "label": 0
                },
                {
                    "sent": "So our goal is to, given the tensor T we wanted to recover a. I swear it is orthogonal.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You know this problem is challenging because of the symmetry inherently is.",
                    "label": 0
                },
                {
                    "sent": "Susceptible to subtle point issues and.",
                    "label": 1
                },
                {
                    "sent": "Long as because we are asking to find the D different components AI any permutation with yellow valid solution and we also this kind of symmetry can create exponentially many local minima and saddle points.",
                    "label": 1
                },
                {
                    "sent": "So what we do is like we identified a new objective function which satisfies the strict settle property we described before and we developed a first online algorithm for orthogonal tensor decomposition with convergence guarantee.",
                    "label": 1
                },
                {
                    "sent": "So this is a key step towards making tensor decomposition algorithms scalable 'cause we don't have to look at the housing information.",
                    "label": 0
                },
                {
                    "sent": "So what is the theorem here?",
                    "label": 0
                },
                {
                    "sent": "So our new objective function is strict subtle Moreover.",
                    "label": 0
                },
                {
                    "sent": "All is local minimal.",
                    "label": 0
                },
                {
                    "sent": "Have the form you I = 2 K, a permutation of I permit permutation of a for some copy equals 2 great positive or minus one and permutation for any kind of permutation.",
                    "label": 0
                },
                {
                    "sent": "Essentially we want we can flip the signs of the eigenvectors and also do the column permutation of the eigenvector matrix.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some mix.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Elemental results, so we compared with the traditional Reconstruction Era objective with our new object.",
                    "label": 0
                },
                {
                    "sent": "If I didn't have, you know, I didn't give you the exact form of the new objective is in our paper.",
                    "label": 0
                },
                {
                    "sent": "I don't want to confuse you for now.",
                    "label": 0
                },
                {
                    "sent": "So yeah, if you have more questions, you can ask me later on.",
                    "label": 0
                },
                {
                    "sent": "So we compare this to objective and we show that our new object objective converge much better than the.",
                    "label": 0
                },
                {
                    "sent": "Traditional Reconstruction Era.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we looked at the ICA setting performance with a mini batch of size 100 and we showed that when we're doing the constant learning rate, we can have some still have some errors here.",
                    "label": 0
                },
                {
                    "sent": "But when we decrease the learning rate, using it to buy T, then we have that the convergence the reconstruction error will go to 0.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to conclude, we identified the class or function called saddle strict settle property function and we show that stochastic gradient descent with minor modification can converge to a local minimum under strict set of property and we also developed a new online algorithm for tensor decomposition which is a non convex optimization problem.",
                    "label": 1
                },
                {
                    "sent": "Yeah, that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}