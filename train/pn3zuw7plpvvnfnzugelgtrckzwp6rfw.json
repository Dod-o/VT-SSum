{
    "id": "pn3zuw7plpvvnfnzugelgtrckzwp6rfw",
    "title": "Information Complexity in Bandit Subset Selection",
    "info": {
        "author": [
            "Emilie Kaufmann, Telecom ParisTech"
        ],
        "published": "Aug. 9, 2013",
        "recorded": "June 2013",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/colt2013_kaufmann_information/",
    "segmentation": [
        [
            "Hi everyone, so in this joint work with Shivaram Caleana Krishnan from Yahoo.",
            "Labs Bangalore, we investigate the complexity of the problem of finding the M best arm in a bandit model."
        ],
        [
            "So the building model is quite similar as in previous talks.",
            "So here we study the stochastic bandit.",
            "So is simply a sets of K and no probability distribution here.",
            "Our distribution will be barely so.",
            "Forecasters interact with this set of distribution and you can draw and, um, according to its sampling strategy, in any observes unassociated reward which is drawn from the associated burn redistribution.",
            "So the mainstream goal in banded models is to learn which are means the best based on the observed samples.",
            "So the model is similar to."
        ],
        [
            "Previous to what we've seen previously, but the objective will not be so, so far.",
            "We've only consider regret minimization.",
            "That is, the forecaster went to learn which ARM is the best, while maximizing its rewards.",
            "You cannot make too many heroes during the process on one to minimize its regrets.",
            "So his sampling strategy has to be a tradeoff between exploration of the environment and exploitation of the current knowledge where."
        ],
        [
            "So we're going to focus on another setting, which is sometimes done.",
            "Pure exploration was a forecaster simply has to recommend the sets of best arms as quickly as possible.",
            "So using ask you simple as possible, but without suffering a loss.",
            "When you draw bad arms.",
            "So here the sampling strategy simply as to explore optimal is environment."
        ],
        [
            "So more precisely, the pure exploration program we consider in this work is done.",
            "Explore M. So there is a number M of arm.",
            "We want to find.",
            "So the setting is packed.",
            "So we fix some Delta, which is a confidence parameters and we also set some epsilon which is a tolerance parameters and define the set SM epsilon star to be the the N best arms up to some tolerance parameters."
        ],
        [
            "So our forecasters is going to choose at time T several arms that you want to observe.",
            "And yes, too.",
            "So after observing some samples, he decided to stop and to recommend a set of arms.",
            "So it stops after a total number of samples an and recommend the set S and his objective."
        ],
        [
            "Of course, is that with probability at least one minus Delta.",
            "The sets SC recommends is indeed including in the true best arms, and the sample complexity."
        ],
        [
            "As to be small, so was a challenge for Explorer.",
            "So far regret minimization.",
            "The problem is pretty much solved in the boundary setting because we know a lot lower bounds.",
            "Regret along with algorithm matching, his lowering lower bond, so the regrets up to diamond Divided by Logan is asymptotically lower bounded by this quantity, which depends on the problem and involves some information theoretic complexity.",
            "So the KL divergent.",
            "Between the distribution of the arms, but the picture is not as beautiful."
        ],
        [
            "04 Explorer, So what we would want for M bigger than one is for example and lower bound on the sample complexity of every algorithm which is correct with probability 1 minus Delta.",
            "And we would want this lower bound to involve some also information theoretic quantity.",
            "So sadly we don't give this lower bound in our work.",
            "But we present improved algorithm for which we have the first upper bound on the sample complexity involving KL divergent's."
        ],
        [
            "So contribution of the following.",
            "So first we review existing algorithm for Explorer and show that they broadly fail in two categories.",
            "So algorithm using uniform sampling and elimination versus algorithm using adaptive sampling and both make use of the confidence interval.",
            "So in the paper we compare these two approach and all."
        ],
        [
            "So sure that we gain by using good confidence interval based on callback like Bird divergance as it was also already done successfully in the regret minimization setting.",
            "And so for the algo."
        ],
        [
            "Then we consider we show that the upper bounds will feature some so information complexity, so KL divergent will appear through a County named churn of information."
        ],
        [
            "So I will just quickly explain what I mean by my algorithms.",
            "So the first is named Cal Racing and his base well.",
            "The algorithm maintain a set of remaining arms and that it runs the forecaster we sample all the remaining arms with the possibility to eliminate some arms.",
            "So for example, so the elimination will be based on confidence interval.",
            "So in this setting we're going to eliminate the empirical best arm because his lower confidence bound.",
            "Is bigger than the upper confidence bound of the M?",
            "Of the N -- M worst arms.",
            "But the idea is still to sample uniformly the arms, so I will give you more detail at."
        ],
        [
            "My poster of course, but just the conflicting you Ristic is name adaptive sampling, so we have to sample only a few armati trans and the will be carefully chosen to be those two critic alarms.",
            "So among the empirical best, arms were going to draw the one with lowest confidence bond among the worst empirical arms were going to draw the one with.",
            "Hyest overconfidence bomb.",
            "So this week."
        ],
        [
            "For a nice treat us and here is the bond.",
            "It involves channel information, but I have no more time to give you more details, so see you at my poster."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everyone, so in this joint work with Shivaram Caleana Krishnan from Yahoo.",
                    "label": 0
                },
                {
                    "sent": "Labs Bangalore, we investigate the complexity of the problem of finding the M best arm in a bandit model.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the building model is quite similar as in previous talks.",
                    "label": 0
                },
                {
                    "sent": "So here we study the stochastic bandit.",
                    "label": 1
                },
                {
                    "sent": "So is simply a sets of K and no probability distribution here.",
                    "label": 0
                },
                {
                    "sent": "Our distribution will be barely so.",
                    "label": 0
                },
                {
                    "sent": "Forecasters interact with this set of distribution and you can draw and, um, according to its sampling strategy, in any observes unassociated reward which is drawn from the associated burn redistribution.",
                    "label": 1
                },
                {
                    "sent": "So the mainstream goal in banded models is to learn which are means the best based on the observed samples.",
                    "label": 1
                },
                {
                    "sent": "So the model is similar to.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Previous to what we've seen previously, but the objective will not be so, so far.",
                    "label": 0
                },
                {
                    "sent": "We've only consider regret minimization.",
                    "label": 1
                },
                {
                    "sent": "That is, the forecaster went to learn which ARM is the best, while maximizing its rewards.",
                    "label": 1
                },
                {
                    "sent": "You cannot make too many heroes during the process on one to minimize its regrets.",
                    "label": 0
                },
                {
                    "sent": "So his sampling strategy has to be a tradeoff between exploration of the environment and exploitation of the current knowledge where.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we're going to focus on another setting, which is sometimes done.",
                    "label": 0
                },
                {
                    "sent": "Pure exploration was a forecaster simply has to recommend the sets of best arms as quickly as possible.",
                    "label": 1
                },
                {
                    "sent": "So using ask you simple as possible, but without suffering a loss.",
                    "label": 0
                },
                {
                    "sent": "When you draw bad arms.",
                    "label": 0
                },
                {
                    "sent": "So here the sampling strategy simply as to explore optimal is environment.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So more precisely, the pure exploration program we consider in this work is done.",
                    "label": 0
                },
                {
                    "sent": "Explore M. So there is a number M of arm.",
                    "label": 0
                },
                {
                    "sent": "We want to find.",
                    "label": 0
                },
                {
                    "sent": "So the setting is packed.",
                    "label": 0
                },
                {
                    "sent": "So we fix some Delta, which is a confidence parameters and we also set some epsilon which is a tolerance parameters and define the set SM epsilon star to be the the N best arms up to some tolerance parameters.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our forecasters is going to choose at time T several arms that you want to observe.",
                    "label": 1
                },
                {
                    "sent": "And yes, too.",
                    "label": 0
                },
                {
                    "sent": "So after observing some samples, he decided to stop and to recommend a set of arms.",
                    "label": 1
                },
                {
                    "sent": "So it stops after a total number of samples an and recommend the set S and his objective.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, is that with probability at least one minus Delta.",
                    "label": 0
                },
                {
                    "sent": "The sets SC recommends is indeed including in the true best arms, and the sample complexity.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As to be small, so was a challenge for Explorer.",
                    "label": 0
                },
                {
                    "sent": "So far regret minimization.",
                    "label": 0
                },
                {
                    "sent": "The problem is pretty much solved in the boundary setting because we know a lot lower bounds.",
                    "label": 1
                },
                {
                    "sent": "Regret along with algorithm matching, his lowering lower bond, so the regrets up to diamond Divided by Logan is asymptotically lower bounded by this quantity, which depends on the problem and involves some information theoretic complexity.",
                    "label": 0
                },
                {
                    "sent": "So the KL divergent.",
                    "label": 0
                },
                {
                    "sent": "Between the distribution of the arms, but the picture is not as beautiful.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "04 Explorer, So what we would want for M bigger than one is for example and lower bound on the sample complexity of every algorithm which is correct with probability 1 minus Delta.",
                    "label": 1
                },
                {
                    "sent": "And we would want this lower bound to involve some also information theoretic quantity.",
                    "label": 1
                },
                {
                    "sent": "So sadly we don't give this lower bound in our work.",
                    "label": 0
                },
                {
                    "sent": "But we present improved algorithm for which we have the first upper bound on the sample complexity involving KL divergent's.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So contribution of the following.",
                    "label": 0
                },
                {
                    "sent": "So first we review existing algorithm for Explorer and show that they broadly fail in two categories.",
                    "label": 1
                },
                {
                    "sent": "So algorithm using uniform sampling and elimination versus algorithm using adaptive sampling and both make use of the confidence interval.",
                    "label": 1
                },
                {
                    "sent": "So in the paper we compare these two approach and all.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So sure that we gain by using good confidence interval based on callback like Bird divergance as it was also already done successfully in the regret minimization setting.",
                    "label": 0
                },
                {
                    "sent": "And so for the algo.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we consider we show that the upper bounds will feature some so information complexity, so KL divergent will appear through a County named churn of information.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I will just quickly explain what I mean by my algorithms.",
                    "label": 0
                },
                {
                    "sent": "So the first is named Cal Racing and his base well.",
                    "label": 0
                },
                {
                    "sent": "The algorithm maintain a set of remaining arms and that it runs the forecaster we sample all the remaining arms with the possibility to eliminate some arms.",
                    "label": 0
                },
                {
                    "sent": "So for example, so the elimination will be based on confidence interval.",
                    "label": 0
                },
                {
                    "sent": "So in this setting we're going to eliminate the empirical best arm because his lower confidence bound.",
                    "label": 0
                },
                {
                    "sent": "Is bigger than the upper confidence bound of the M?",
                    "label": 0
                },
                {
                    "sent": "Of the N -- M worst arms.",
                    "label": 0
                },
                {
                    "sent": "But the idea is still to sample uniformly the arms, so I will give you more detail at.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My poster of course, but just the conflicting you Ristic is name adaptive sampling, so we have to sample only a few armati trans and the will be carefully chosen to be those two critic alarms.",
                    "label": 0
                },
                {
                    "sent": "So among the empirical best, arms were going to draw the one with lowest confidence bond among the worst empirical arms were going to draw the one with.",
                    "label": 0
                },
                {
                    "sent": "Hyest overconfidence bomb.",
                    "label": 0
                },
                {
                    "sent": "So this week.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For a nice treat us and here is the bond.",
                    "label": 0
                },
                {
                    "sent": "It involves channel information, but I have no more time to give you more details, so see you at my poster.",
                    "label": 0
                }
            ]
        }
    }
}