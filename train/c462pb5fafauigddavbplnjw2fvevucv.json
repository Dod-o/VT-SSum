{
    "id": "c462pb5fafauigddavbplnjw2fvevucv",
    "title": "Almost Linear-Time Algorithms for Adaptive Betweenness Centrality using Hypergraph Sketches",
    "info": {
        "author": [
            "Yuichi Yoshida, National Institute of Informatics"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_yoshida_hypergraph_sketches/",
    "segmentation": [
        [
            "OK, so I'm talking about linear time algorithm for adaptive between centrality."
        ],
        [
            "So let me introduce what centrality is for us.",
            "So centrality of about X means how important botics is.",
            "Of course, this is very abstract, but this is important notion in network science, and there are several definitions of centrality like degree of robotics or page rank.",
            "But here we focus on centrality is based on shortest path is so intuitively many if many shortest path path path is passed through the body extender vertex is important.",
            "So example includes coverage centrality between centrality and closeness.",
            "Variety, but in this talk we mainly I focused on coverage generated because of its simplicity.",
            "So."
        ],
        [
            "Let me define what coverage centrality is so so pair of what is St is covered by a vertex B if the shortest still show this path passes through the body XP.",
            "So then the cover centrality of the vertex V is how many fraction peers are covered by."
        ],
        [
            "So in this graph, so we want to measure the coverage entropy then.",
            "So if we choose this steeper then it contributes by say One North squared cause the shortest path between SNT pass through the body XP."
        ],
        [
            "But here for this player it doesn't count."
        ],
        [
            "The between centrality is just well generalization or variant of covered centrality.",
            "We only consider how much fraction, so as the shortest path path, product B.",
            "Instead of just 01 or nothing."
        ],
        [
            "So there are many applications of coverage, centrality or between centrality.",
            "So one famous thing is community detection.",
            "So given a graph like that, we want to choose K buses.",
            "And we want to make well, and we want to remove care about 6 and we want to find committees.",
            "So for this task.",
            "Terrorism is given humans algorithms.",
            "In this algorithm we choose the bottex of highest between centrality."
        ],
        [
            "And then remove the botics."
        ],
        [
            "OK, and then we and then we repeat the same."
        ],
        [
            "Thing K times.",
            "So it means that we compute the highest between saturated batiks in the resulting graph on the remove vertex and keep doing so K times."
        ],
        [
            "So in this, in this case case."
        ],
        [
            "Equal to two under, we get the three communities."
        ],
        [
            "So there are well other application, many other applications cover centrality or between centralities, so one is distance Oracle which means the constructing an index index for answering shortest paths between query pairs and another one is targeting immunization, which is a famous where which is very well studied problem in network science.",
            "But in these applications it is no good to computer cover centrality or between centrality in the original graph so.",
            "We don't want the computer between central cover centrality in the original graph and take the top K boxes in order to run the algorithm.",
            "Before I explained before.",
            "But instead we want to do the following.",
            "So we want to compute Cover Central between centrality adaptively.",
            "So what does it mean?",
            "So it means so for each step we take the batiks of highest coverage centrality of business centrality.",
            "In the current graph and then we no longer consider appears already covered by the selected Vertex.",
            "So this is important."
        ],
        [
            "OK, so this is called adaptive centrality, but but the program of this method is that all previous method takes a lot of time at least quadratic time.",
            "So in order to compute top K boxes based on adaptive coverage centrality, then we need KN squared M time where our case number of vertices we want to choose on then is the number of vertices and limits the number of edges so.",
            "This is very large and since this is so, we have approximate algorithm, but it also takes KNM time which is very large for business.",
            "Central idea.",
            "This description is a bit better but for approximate method we still need KM time and K can be for example one or so in the.",
            "In that case the time complexity is like quadratic.",
            "So this is very slow for huge graphs."
        ],
        [
            "So the contribution of this paper, our work is given, giving, giving a method that computes the ordering based on adaptive centrality in almost linear time.",
            "No matter what K is.",
            "So even if K is .1 or the running time is almost linear time, so that time complexity is for adaptive color centrality adopted between centrality and plus M Logan over if some squared.",
            "So far between standard, we have another parameter, but that's very that is very small in practice."
        ],
        [
            "So we also have theoretical guarantee the output is 1 -- 1 epsilon approximation where approximation to a search optimization problem I will, which I will describe later.",
            "And then by experiment which check the effectiveness of the method.",
            "So the coverage centrality and the centrality obtained by the product set by our method is close to the cover centralized between centrality of the exact method and sometimes.",
            "Our method is 1000 times faster than previous algorithms.",
            "OK."
        ],
        [
            "So let me rephrase the problem using well, different notion.",
            "So we want to define the coverage centrality.",
            "Oh, I will describe the algorithm for coverage central idea, because between centralized is a bit difficult, so the coverage central the I want to define coverage centrality over botics set.",
            "So the cover centrality robotics at South is the fraction of pears covered biologics in some vertex in South.",
            "And we want to.",
            "I want to define cover centrality or V condition on having chosen but except South by CV cap, X -- Y S. Then what we want to solve is as follows.",
            "We want to compute the following ordering.",
            "So for each step we take the.",
            "We take the vertex that maximizes the resulting coverage centrality.",
            "So they already chose V1 through Vin minus one over the chosen ones is and we put V. Another vertex V and then we what we want to do is maximizing the resulting coverage centrality.",
            "So this can be seen as a gradient method for maximizing the coverage centrality.",
            "Or computing the.",
            "The computing the vertex set of size K that has maximum coverage centroid.",
            "OK."
        ],
        [
            "So let me describe our method.",
            "So methods sketches the original graph by hyper graph.",
            "So instead of computing the cover centrality of vertex or buses, reconstruct the hypergraph H as follows.",
            "So M is a parameter such as Logan over epsilon squared, and then we sample appear for M times with sample appear.",
            "Or what is AST uniformly at random?",
            "Then we compute St shirts passes.",
            "So this path then what we do is adding the hyperedge consisting of buses in this shortest path is.",
            "Select this so these two 2 versus we selected spare buses and competition spots and other hyperedge containing the buses in the service part is of course the shortest path may not be unique, so in such case view at all the buses in the order source path between SMT.",
            "And we keep doing that.",
            "So this is the sketch hypergraph sketch of the original graph, so that construct the time complexity of constructing this hypergraph sketches well that's N + M times capital M, which is almost linear.",
            "This is simple.",
            "Because we are just computing the shortest path for only capital M times."
        ],
        [
            "So how can we compute the ordering based on adaptive covered centrality?",
            "This is actually very simple, we do.",
            "We do not have the computer covered centrality.",
            "We only have to take care of degrees in the hypergraph.",
            "So 4K times what we do is to take the vertex of maximum degree in the current graph where the current graph means that H minus already chosen versus.",
            "So in the in this hypergraph sketch the vertex of maximum degree is V1 in the figure.",
            "So what we do is just.",
            "Remove the hyper edges incident to the vertex V1 and then we take the vertex of maximum degree in the current graph that is free to hear and then remove the batiks.",
            "So.",
            "We have removed all the hyperedges so the remaining order is arbitrary.",
            "But this is what we do.",
            "So we only suffices keep 2 degrees in hyper graph.",
            "This is much, much easier task than computing coverage centralities.",
            "So actually we can make this algorithm possible in time in time or order of N + M capital M."
        ],
        [
            "So the correction is I don't want to go into the proof detail, but let's see the intuition behind the correctness behind proof, so the.",
            "Expected degree of vertex B in the hypergraph hypergraph sketch divided by divided by M. Is equal to the probability that the vertex.",
            "The degree of the Botics V increases by choosing a random pair.",
            "But this is actually exactly equal to the cover centrality of the product B.",
            "So it means that the cover centrality of E can be approximated by the degree of the politics in the high bar graph.",
            "So we can say actually the same thing for the cover centrality of the condition or having chosen but except S. So the coverage centrality of hard work we having success South can be approximated by.",
            "The degree in the in the hypergraphs remove the hypergraph edge minus is."
        ],
        [
            "So let me show you experimental results about method."
        ],
        [
            "So the first one is the accuracy of our method.",
            "So in the left figure is about covered centrality and the right figure is about between centrality and X axis is the number of buses chosen and vaccines covered.",
            "Central idea between centrality.",
            "So the blue lines means that the cover central idea between centralized is computed by the exact method.",
            "So M is the number of high bridge is in the high bar graph sketch.",
            "So if M gets larger than the accuracy gets gets better and then basically MFM is 4K or 16 K. The error is up to 1% so this is very accurate method."
        ],
        [
            "So the let's see the running time.",
            "So when K is 50, so this is for small graphs.",
            "So when K is 50, the exact method takes like 1000 seconds and sampling methods still takes approximate methods still takes 10 seconds, but our work only takes less than one SEC.",
            "So.",
            "The so our method is very fast even when K is equal to 50.",
            "But when K is N, method is much much faster than previous methods.",
            "Actually exact methods didn't finish in 12 hours and sampling methods takes like 3 hours.",
            "But methods only takes less than one SEC.",
            "The important thing here is that no matter what K is, the running time of our method.",
            "Does not does not change much."
        ],
        [
            "So this is runtime of competing very large computing model covered central idea for large graphs up to 10,000,000 edges.",
            "So for these graphs we only need 100 seconds.",
            "This is not so slow, but I think, well, I want to make it more faster, much faster, but this is."
        ],
        [
            "So the summary is that.",
            "We are giving which showed almost linear time algorithm for adaptive.",
            "It means, between centrality uncovered centrality.",
            "And I didn't explain but there is probable guarantee of 1 -- 1 Nova Epson approximation to the problem of maximizing the cover centrality of vertex set of size K. And we confirmed accuracy and efficiency by experiment.",
            "So since method does not depend on the running time of our method does not depend on the choice of K, so adaptive between centrality or cover centrality now available in applications involving large networks.",
            "So for future works I want to make it even faster.",
            "And maybe it's possible to apply to other centralizes like, say, like closeness centralizes?",
            "OK, that's it, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm talking about linear time algorithm for adaptive between centrality.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me introduce what centrality is for us.",
                    "label": 0
                },
                {
                    "sent": "So centrality of about X means how important botics is.",
                    "label": 1
                },
                {
                    "sent": "Of course, this is very abstract, but this is important notion in network science, and there are several definitions of centrality like degree of robotics or page rank.",
                    "label": 1
                },
                {
                    "sent": "But here we focus on centrality is based on shortest path is so intuitively many if many shortest path path path is passed through the body extender vertex is important.",
                    "label": 0
                },
                {
                    "sent": "So example includes coverage centrality between centrality and closeness.",
                    "label": 0
                },
                {
                    "sent": "Variety, but in this talk we mainly I focused on coverage generated because of its simplicity.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me define what coverage centrality is so so pair of what is St is covered by a vertex B if the shortest still show this path passes through the body XP.",
                    "label": 0
                },
                {
                    "sent": "So then the cover centrality of the vertex V is how many fraction peers are covered by.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this graph, so we want to measure the coverage entropy then.",
                    "label": 0
                },
                {
                    "sent": "So if we choose this steeper then it contributes by say One North squared cause the shortest path between SNT pass through the body XP.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But here for this player it doesn't count.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The between centrality is just well generalization or variant of covered centrality.",
                    "label": 0
                },
                {
                    "sent": "We only consider how much fraction, so as the shortest path path, product B.",
                    "label": 1
                },
                {
                    "sent": "Instead of just 01 or nothing.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are many applications of coverage, centrality or between centrality.",
                    "label": 0
                },
                {
                    "sent": "So one famous thing is community detection.",
                    "label": 1
                },
                {
                    "sent": "So given a graph like that, we want to choose K buses.",
                    "label": 0
                },
                {
                    "sent": "And we want to make well, and we want to remove care about 6 and we want to find committees.",
                    "label": 0
                },
                {
                    "sent": "So for this task.",
                    "label": 0
                },
                {
                    "sent": "Terrorism is given humans algorithms.",
                    "label": 0
                },
                {
                    "sent": "In this algorithm we choose the bottex of highest between centrality.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then remove the botics.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and then we and then we repeat the same.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing K times.",
                    "label": 0
                },
                {
                    "sent": "So it means that we compute the highest between saturated batiks in the resulting graph on the remove vertex and keep doing so K times.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this, in this case case.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Equal to two under, we get the three communities.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are well other application, many other applications cover centrality or between centralities, so one is distance Oracle which means the constructing an index index for answering shortest paths between query pairs and another one is targeting immunization, which is a famous where which is very well studied problem in network science.",
                    "label": 0
                },
                {
                    "sent": "But in these applications it is no good to computer cover centrality or between centrality in the original graph so.",
                    "label": 1
                },
                {
                    "sent": "We don't want the computer between central cover centrality in the original graph and take the top K boxes in order to run the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Before I explained before.",
                    "label": 0
                },
                {
                    "sent": "But instead we want to do the following.",
                    "label": 1
                },
                {
                    "sent": "So we want to compute Cover Central between centrality adaptively.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean?",
                    "label": 0
                },
                {
                    "sent": "So it means so for each step we take the batiks of highest coverage centrality of business centrality.",
                    "label": 1
                },
                {
                    "sent": "In the current graph and then we no longer consider appears already covered by the selected Vertex.",
                    "label": 0
                },
                {
                    "sent": "So this is important.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is called adaptive centrality, but but the program of this method is that all previous method takes a lot of time at least quadratic time.",
                    "label": 1
                },
                {
                    "sent": "So in order to compute top K boxes based on adaptive coverage centrality, then we need KN squared M time where our case number of vertices we want to choose on then is the number of vertices and limits the number of edges so.",
                    "label": 0
                },
                {
                    "sent": "This is very large and since this is so, we have approximate algorithm, but it also takes KNM time which is very large for business.",
                    "label": 0
                },
                {
                    "sent": "Central idea.",
                    "label": 0
                },
                {
                    "sent": "This description is a bit better but for approximate method we still need KM time and K can be for example one or so in the.",
                    "label": 0
                },
                {
                    "sent": "In that case the time complexity is like quadratic.",
                    "label": 0
                },
                {
                    "sent": "So this is very slow for huge graphs.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the contribution of this paper, our work is given, giving, giving a method that computes the ordering based on adaptive centrality in almost linear time.",
                    "label": 1
                },
                {
                    "sent": "No matter what K is.",
                    "label": 0
                },
                {
                    "sent": "So even if K is .1 or the running time is almost linear time, so that time complexity is for adaptive color centrality adopted between centrality and plus M Logan over if some squared.",
                    "label": 0
                },
                {
                    "sent": "So far between standard, we have another parameter, but that's very that is very small in practice.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we also have theoretical guarantee the output is 1 -- 1 epsilon approximation where approximation to a search optimization problem I will, which I will describe later.",
                    "label": 1
                },
                {
                    "sent": "And then by experiment which check the effectiveness of the method.",
                    "label": 0
                },
                {
                    "sent": "So the coverage centrality and the centrality obtained by the product set by our method is close to the cover centralized between centrality of the exact method and sometimes.",
                    "label": 1
                },
                {
                    "sent": "Our method is 1000 times faster than previous algorithms.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me rephrase the problem using well, different notion.",
                    "label": 1
                },
                {
                    "sent": "So we want to define the coverage centrality.",
                    "label": 0
                },
                {
                    "sent": "Oh, I will describe the algorithm for coverage central idea, because between centralized is a bit difficult, so the coverage central the I want to define coverage centrality over botics set.",
                    "label": 0
                },
                {
                    "sent": "So the cover centrality robotics at South is the fraction of pears covered biologics in some vertex in South.",
                    "label": 0
                },
                {
                    "sent": "And we want to.",
                    "label": 0
                },
                {
                    "sent": "I want to define cover centrality or V condition on having chosen but except South by CV cap, X -- Y S. Then what we want to solve is as follows.",
                    "label": 0
                },
                {
                    "sent": "We want to compute the following ordering.",
                    "label": 1
                },
                {
                    "sent": "So for each step we take the.",
                    "label": 0
                },
                {
                    "sent": "We take the vertex that maximizes the resulting coverage centrality.",
                    "label": 0
                },
                {
                    "sent": "So they already chose V1 through Vin minus one over the chosen ones is and we put V. Another vertex V and then we what we want to do is maximizing the resulting coverage centrality.",
                    "label": 1
                },
                {
                    "sent": "So this can be seen as a gradient method for maximizing the coverage centrality.",
                    "label": 0
                },
                {
                    "sent": "Or computing the.",
                    "label": 0
                },
                {
                    "sent": "The computing the vertex set of size K that has maximum coverage centroid.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me describe our method.",
                    "label": 0
                },
                {
                    "sent": "So methods sketches the original graph by hyper graph.",
                    "label": 0
                },
                {
                    "sent": "So instead of computing the cover centrality of vertex or buses, reconstruct the hypergraph H as follows.",
                    "label": 1
                },
                {
                    "sent": "So M is a parameter such as Logan over epsilon squared, and then we sample appear for M times with sample appear.",
                    "label": 0
                },
                {
                    "sent": "Or what is AST uniformly at random?",
                    "label": 0
                },
                {
                    "sent": "Then we compute St shirts passes.",
                    "label": 0
                },
                {
                    "sent": "So this path then what we do is adding the hyperedge consisting of buses in this shortest path is.",
                    "label": 0
                },
                {
                    "sent": "Select this so these two 2 versus we selected spare buses and competition spots and other hyperedge containing the buses in the service part is of course the shortest path may not be unique, so in such case view at all the buses in the order source path between SMT.",
                    "label": 0
                },
                {
                    "sent": "And we keep doing that.",
                    "label": 0
                },
                {
                    "sent": "So this is the sketch hypergraph sketch of the original graph, so that construct the time complexity of constructing this hypergraph sketches well that's N + M times capital M, which is almost linear.",
                    "label": 0
                },
                {
                    "sent": "This is simple.",
                    "label": 0
                },
                {
                    "sent": "Because we are just computing the shortest path for only capital M times.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how can we compute the ordering based on adaptive covered centrality?",
                    "label": 1
                },
                {
                    "sent": "This is actually very simple, we do.",
                    "label": 0
                },
                {
                    "sent": "We do not have the computer covered centrality.",
                    "label": 0
                },
                {
                    "sent": "We only have to take care of degrees in the hypergraph.",
                    "label": 0
                },
                {
                    "sent": "So 4K times what we do is to take the vertex of maximum degree in the current graph where the current graph means that H minus already chosen versus.",
                    "label": 0
                },
                {
                    "sent": "So in the in this hypergraph sketch the vertex of maximum degree is V1 in the figure.",
                    "label": 0
                },
                {
                    "sent": "So what we do is just.",
                    "label": 0
                },
                {
                    "sent": "Remove the hyper edges incident to the vertex V1 and then we take the vertex of maximum degree in the current graph that is free to hear and then remove the batiks.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We have removed all the hyperedges so the remaining order is arbitrary.",
                    "label": 0
                },
                {
                    "sent": "But this is what we do.",
                    "label": 0
                },
                {
                    "sent": "So we only suffices keep 2 degrees in hyper graph.",
                    "label": 1
                },
                {
                    "sent": "This is much, much easier task than computing coverage centralities.",
                    "label": 0
                },
                {
                    "sent": "So actually we can make this algorithm possible in time in time or order of N + M capital M.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the correction is I don't want to go into the proof detail, but let's see the intuition behind the correctness behind proof, so the.",
                    "label": 0
                },
                {
                    "sent": "Expected degree of vertex B in the hypergraph hypergraph sketch divided by divided by M. Is equal to the probability that the vertex.",
                    "label": 0
                },
                {
                    "sent": "The degree of the Botics V increases by choosing a random pair.",
                    "label": 0
                },
                {
                    "sent": "But this is actually exactly equal to the cover centrality of the product B.",
                    "label": 0
                },
                {
                    "sent": "So it means that the cover centrality of E can be approximated by the degree of the politics in the high bar graph.",
                    "label": 1
                },
                {
                    "sent": "So we can say actually the same thing for the cover centrality of the condition or having chosen but except S. So the coverage centrality of hard work we having success South can be approximated by.",
                    "label": 0
                },
                {
                    "sent": "The degree in the in the hypergraphs remove the hypergraph edge minus is.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me show you experimental results about method.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first one is the accuracy of our method.",
                    "label": 0
                },
                {
                    "sent": "So in the left figure is about covered centrality and the right figure is about between centrality and X axis is the number of buses chosen and vaccines covered.",
                    "label": 0
                },
                {
                    "sent": "Central idea between centrality.",
                    "label": 0
                },
                {
                    "sent": "So the blue lines means that the cover central idea between centralized is computed by the exact method.",
                    "label": 0
                },
                {
                    "sent": "So M is the number of high bridge is in the high bar graph sketch.",
                    "label": 0
                },
                {
                    "sent": "So if M gets larger than the accuracy gets gets better and then basically MFM is 4K or 16 K. The error is up to 1% so this is very accurate method.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the let's see the running time.",
                    "label": 0
                },
                {
                    "sent": "So when K is 50, so this is for small graphs.",
                    "label": 0
                },
                {
                    "sent": "So when K is 50, the exact method takes like 1000 seconds and sampling methods still takes approximate methods still takes 10 seconds, but our work only takes less than one SEC.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The so our method is very fast even when K is equal to 50.",
                    "label": 0
                },
                {
                    "sent": "But when K is N, method is much much faster than previous methods.",
                    "label": 0
                },
                {
                    "sent": "Actually exact methods didn't finish in 12 hours and sampling methods takes like 3 hours.",
                    "label": 1
                },
                {
                    "sent": "But methods only takes less than one SEC.",
                    "label": 1
                },
                {
                    "sent": "The important thing here is that no matter what K is, the running time of our method.",
                    "label": 0
                },
                {
                    "sent": "Does not does not change much.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is runtime of competing very large computing model covered central idea for large graphs up to 10,000,000 edges.",
                    "label": 0
                },
                {
                    "sent": "So for these graphs we only need 100 seconds.",
                    "label": 0
                },
                {
                    "sent": "This is not so slow, but I think, well, I want to make it more faster, much faster, but this is.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the summary is that.",
                    "label": 0
                },
                {
                    "sent": "We are giving which showed almost linear time algorithm for adaptive.",
                    "label": 1
                },
                {
                    "sent": "It means, between centrality uncovered centrality.",
                    "label": 0
                },
                {
                    "sent": "And I didn't explain but there is probable guarantee of 1 -- 1 Nova Epson approximation to the problem of maximizing the cover centrality of vertex set of size K. And we confirmed accuracy and efficiency by experiment.",
                    "label": 1
                },
                {
                    "sent": "So since method does not depend on the running time of our method does not depend on the choice of K, so adaptive between centrality or cover centrality now available in applications involving large networks.",
                    "label": 0
                },
                {
                    "sent": "So for future works I want to make it even faster.",
                    "label": 0
                },
                {
                    "sent": "And maybe it's possible to apply to other centralizes like, say, like closeness centralizes?",
                    "label": 0
                },
                {
                    "sent": "OK, that's it, thanks.",
                    "label": 0
                }
            ]
        }
    }
}