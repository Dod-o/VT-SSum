{
    "id": "mzfpp6g3ibcjfdh2cf4kb2dmiafmsksf",
    "title": "Opening up audiovisual archives for media professionals and researchers",
    "info": {
        "author": [
            "Tinne Tuytelaars, Faculty of Engineering, KU Leuven"
        ],
        "published": "Feb. 10, 2014",
        "recorded": "January 2014",
        "category": [
            "Top->Computer Science->Semantic Web->Annotation",
            "Top->Computer Science->Semantic Web->Applications",
            "Top->Computer Science->Software and Tools"
        ]
    },
    "url": "http://videolectures.net/wmpa2014_tuytelaars_audiovisual_archives/",
    "segmentation": [
        [
            "The idea of this talk is to introduce you to the access project.",
            "This is a project that started three years ago and still running for one more year and that has goal to open up audiovisual archives and up to now the last three years we actually focused on two types of end users that's made up media professionals as well as researchers, and so that's what I will be talking about, mostly today."
        ],
        [
            "Just a very short overview of this project.",
            "I'll start with this presentation.",
            "I'll start with the introduction of the access project, what it's really about.",
            "Then I'll focus on the audiovisual content analysis, which is the main backbone of the systems we develop.",
            "Now I must say that maybe I do not do honor to all the different aspects of the project.",
            "I decided to focus on the audiovisual content analysis because that's also what I'm myself most familiar with.",
            "So there's a lot of work also going on like studying users, getting user requirements, and all these things.",
            "I will only touch up on this.",
            "Because I'm not the expert in that field.",
            "Then I'll show 2 demo systems that we have developed that it's access Pro and access research.",
            "And I'll conclude with some lessons learned and focus on future work.",
            "I should also say at this point that.",
            "This is clearly joint efforts.",
            "I'm standing here presenting all this work, but it's work from a whole consortium.",
            "It's a.",
            "Great team that we're having.",
            "They're all very motivated, very dedicated, and it's thanks to them that I can show you.",
            "I can show you all these systems and all this work.",
            "But I'll want to start with a short commercial short story that kind of captures the main idea of the excess product."
        ],
        [
            "This is Tom.",
            "Tom works at an archive.",
            "And I hope you cannot.",
            "Is a TV journalist.",
            "It is a strange job.",
            "Yeah, research interview.",
            "It was us.",
            "We started a revolution cut.",
            "One thing Tom never liked about his job was the research in the archive.",
            "But why Tom's broadcaster has a wonderful huge treasure archive material.",
            "One could easily search with keywords.",
            "But then the relevant sequence had to be found and this kind of search was often quite hard.",
            "Tom had to scream and scream and scream some more.",
            "Until he finally found what he was looking for, you really cool, but those days are gone now thanks to access.",
            "Access enables Tom only to search for keywords, but directly for images excess can detect buildings, places and objects.",
            "At one glance, Tom finds the relevant sequences.",
            "No search, no fast forwarding.",
            "X is also searches for similar images.",
            "For example it can file records of a particular person or face in the archive.",
            "Based on previously found image, Tom could not believe it at first class, but thanks to speech recognition he can now search for spoken words.",
            "This revolution will bring down the president.",
            "Ever since Axis Tom enjoys researching the archive it has never before been so easy to find gems hidden in the archive.",
            "This way his contributions will be even better and now Tom is even happier with his dream job.",
            "Access creates a user interface for each of the targeted user groups, media professionals, researchers and educators and home users.",
            "The project is partially funded by the European Commission and the research is gone by.",
            "Get more info here.",
            "OK, so it's a commercial.",
            "It may be a bit too optimistic, but it kind of captures very nicely the spirits and the idea of the access project.",
            "If we look at."
        ],
        [
            "Current situation in common practice when people look at at archives then we see that there's a huge wealth of audiovisual data around, so we focus on video material that actually is.",
            "The same applies also to other types of audio visual data.",
            "There's enormous wealth of information around at public broadcasters, but also like.",
            "In companies and it's getting easier and easier to collect data and to start data, but then accessing this data is a problem.",
            "Knowing what's in your archive, that's really the key.",
            "Getting to the knowledge the semantics rather than just the raw data.",
            "And it turns out that there's actually quite a lot of data in this archives that is simply irretrievable.",
            "That cannot be found.",
            "For a number of reasons, on the one hand, there is a lot of ultimate irial that comes from the pre digital era that has not been.",
            "Annotated properly, so there's a huge effort going on.",
            "Digitising this information a lot has been digitized already, but then without the additional metadata.",
            "It's not really useful because you cannot really retrieve and find the relevant data there.",
            "Another problem with.",
            "The current situation is that the metadata that is available is provided by archivists and they do a wonderful job adding metadata for the data in their archive.",
            "But it's usually at the level of entire documents, so they say, OK, this is a documentary about.",
            "The Arabic spring.",
            "In Egypt, but they don't go to the final grade level.",
            "They don't go to the details of individual fragments.",
            "That might be fine if you just want to find a documentary and you just want to look at it.",
            "So if you are a passive user, but if you are more active user and you want to.",
            "Reuse that material you want to be creative with it and make a new compilation or whatever.",
            "Then typically you're not interested in the entire documentary you're interested in particular fragments like the fragmente where you have this demonstration on the tackling squared with different.",
            "Isn't this person or this event going on that level of detail is not available in the current meta data as provided?",
            "By the archivists.",
            "Also, the data provided by the archivists is.",
            "In a sense, biased.",
            "Because whatever user is interested in depends on the situation.",
            "Differently have different uses of material, like whether we are active or passive user, whether we want to reduce the data or just watch it is also depends from 1 user to another.",
            "Another example is researchers.",
            "Maybe you don't want to find a particular fragmente to reuse it, but you want to find the fragments or lots of fragments.",
            "To get some statistics and to see the trends overtime, like historians, might be interested in, I don't know how many women wear headscarves in Egypt.",
            "And they want to watch.",
            "Or they have a huge source of information there of audiovisual material from which they could extract this information.",
            "But that would mean that they would have to manually go through all this data they can retrieve.",
            "Based on the current meta meta data.",
            "Documentaries where they think they might be relevant, like on the Arabic Spring or something like that, but then within that documentary they have to manually browse like feedforward or browser keyframes and so on, and then check are there women.",
            "Do they wear a headscarf?",
            "Yes or no?",
            "It's very time consuming.",
            "It's not the way you want to actually do your research.",
            "What they would like to have it again, automated methods that can.",
            "Retrieve particular fragments at a very fine grained scale.",
            "And this not just for one fragment for a huge number of fragments, so it need really need to scale up so that they can get statistics from there, and they can actually do something with it.",
            "Also the.",
            "Metadata you're interested in might actually change overtime.",
            "Or change from 1 user to another.",
            "I notice that myself if I look at my personal photo collection or video collection.",
            "If I look at the recent years, I'm mostly interested in the extraordinary like special events, travels and so on.",
            "But if you go further back in time.",
            "Then actually it's not the special events that are most interesting, but it's the ordinary events like just oh look kind of clothes we were wearing at that time.",
            "Look at that car, look at just ordinary things, become much more important, but an annotator who would have nicely set like this is the birthday of this person at that location, and so on.",
            "Will not have annotated things like the clouds are the cars or anything like that because?",
            "It's so ordinary they think it's not important, but So what is important can shift overtime and also can shift from one place to another and so on.",
            "If I travel and I see the news in some other country, I'm not really interested in the specific news item, but again, more in the general setting and so on.",
            "So it's very difficult to manually provide metadata at the right level of granularity and to really deal with.",
            "All the different information needs that different types of users might have.",
            "And therefore we thought like for access it would be good to try and open up these archives and to add on top of the metadata provided by archivists, additional metadata that is extracted.",
            "In an automatic fashion like we automatically retrieve and annotate and so on the data so that users.",
            "Sorry, so that users can query the data and retrieve the data they are interested in."
        ],
        [
            "OK, so this is basically what I just."
        ],
        [
            "Set.",
            "So in a nutshell, while Texas has main goals like the mission statement of the Access project goes as follows, we want to develop new tools.",
            "Providing you an engaging ways to interact with audiovisual libraries.",
            "So this is an aspect that I didn't mention in the previous slide yet.",
            "Actually we also want to go beyond simple searching the archive.",
            "The basic idea when you think about opening up an archive is like you just.",
            "Have particular information needs you formulated in terms of search query and then the answer is retrieved from the archive.",
            "You get a ranked list back of the videos that are relevant for your search, but that's not the way people typically want to.",
            "Interact with the archive.",
            "The example of the researcher I just gave before is 1 example where people might want to get some statistics out of the archive.",
            "It's again some information needs, but it's not simply searching and getting a ranked list.",
            "They want to get extra information from their people.",
            "Might be interested in just browsing the archive, exploring the archive, or as we set in the project proposal, experiencing the archive because it's still.",
            "Unclear what this could all.",
            "On campus, there's so many different ways you can interact with an archive.",
            "So we want also in the access project try and go beyond the simple search.",
            "Um?"
        ],
        [
            "And we want to do so for a multitude of end users.",
            "There's already quite a few systems that are being developed focusing on media professionals.",
            "But the needs and the background knowledge of media professionals is very different from what you see when you talk with researchers or when you talk with home users and you cannot build just one system for all of them.",
            "You need to adapt the system towards the specific needs.",
            "For instance, home users often don't know what's in the archive media professionals.",
            "They probably are somewhat familiar with the system, although.",
            "It turns out that also media professionals often do not know what's in their archives.",
            "Um?",
            "And so we want to have different systems and look at different needs.",
            "So that really this wealth of information in the archive can be opened up to as many."
        ],
        [
            "Different users as possible.",
            "And to achieve that we want to build on state of the art content analysis techniques where we focus on computer vision.",
            "Analyzing the visual information in the videos.",
            "Audio analysis and speech recognition, but also multimodal aspects where we try to combine audio and video.",
            "Search and navigation where we focus on scalability.",
            "The methods we develop.",
            "Should not only be accurate, but also they should be applicable on a large scale like they don't need to.",
            "They should not use too much computational power.",
            "They should be scalable to thousands or ultimately millions of hours of video.",
            "Another aspect that we wanted to focus on is weakly supervised methods that is also when learning our methods, we want the system to learn from weekly weeks of provision.",
            "You can easily say OK, I trained a classifier for a particular concept, but if that means that you need to collect a lot of training materials for that particular concept that again it's very labor intensive and it's not very flexible.",
            "So instead we want to have methods that can.",
            "Learn from data that's already available from the Internet or some other source."
        ],
        [
            "In practice, we focus on different types of content because it turns out that the techniques you need to recognize, for instance, people is very different from what you need.",
            "For places, events, object categories.",
            "People in particular turn out to be very important for most users.",
            "If you look at what people search for, it's mostly people names.",
            "And only secondary places, events, categories.",
            "So we need to have different methods to cope with these different types of contents."
        ],
        [
            "And we follow a user centric approach.",
            "So we early on showed prototypes to end users interviewed, then got feedback from them.",
            "Do we do service?",
            "We showed them our systems, get feedback and so on.",
            "But as I said in the beginning, I will not focus too much on this.",
            "Cycle of getting input from users and iterating.",
            "It's a process that also runs over the different systems.",
            "So we had first system for the professional users.",
            "The feedback we got from that system.",
            "Was used to improve the system for the professionals, but also for.",
            "We need to account for building the system for the researchers and will be used for home users as well.",
            "And."
        ],
        [
            "It's just like how we go to our logo so it's users, technology and content.",
            "That's enough for the introduction."
        ],
        [
            "Let's move on to the core of this talk.",
            "How do we do it?",
            "What is the underlying audiovisual content analysis pipeline?",
            "How do we actually get the right interpretation from this video so that we can retrieve data from it and we can answer information needs?"
        ],
        [
            "This is the overall pipeline I'm not going to talk too much about this slide."
        ],
        [
            "Quickly just go over the first steps here to see how so you get the general flow of information.",
            "All the videos first gets collected.",
            "We extract the existing metadata because all the meta data that is available, it would be stupid not to use it, so we collect it.",
            "We make sure that at least the metadata that is available is searchable.",
            "We do a video normalization step where we change the different formats and so on.",
            "And then we have two parallel tracks, one that focuses on the audio.",
            "Where we do speech processing, so diarization, speech processing and so on and on the other hand, we look at the video.",
            "And with the video actually the first thing is how do you define a fragment?",
            "So you have a large video?",
            "You have to split it up in fragments.",
            "That's the unit that people can retrieve, and it's very difficult thing to define the right fragmente.",
            "So we actually took a very simple approach.",
            "Here we just run a shot detector and we select a couple of key frames for each shots, and most of the further processing.",
            "It's limited to this keyframes.",
            "Um?",
            "Except for.",
            "Two or three different components, where actually the temporal information is very important.",
            "So for the faces we do tracking also for the event detection.",
            "Of course you need to have the temporal information, but the rest is just focusing on the individual keyframes, and it turns out that actually selecting the good keyframes.",
            "This is quite important in that setting.",
            "And from there we then have a series of different components that analyze the keyframes.",
            "In the sense that they extract.",
            "Faces and do face recognition.",
            "They extract features that can be used later for object category recognition for place recognition and so on.",
            "And one of the key components.",
            "One of the key differentiators of our access system compared to.",
            "Previous systems is."
        ],
        [
            "That we actually.",
            "Focus on this on the fly.",
            "Paradigm so I should explain what we mean with that.",
            "We had a lot of discussion in the beginning of the project, like what is it should be that these are?",
            "What kind of objects should we be able to retrieve from the system?",
            "What kind of which people do we need to be recognized?",
            "And so on.",
            "And it turns out that it's very difficult to come up with such a list, because as I said before, different users may have different needs, different interests, things can change overtime.",
            "And so instead of having like a fixed dose, fixed list of concepts that we say, OK, this is the things that we annotate and that you can search for.",
            "We took a completely different approach and we.",
            "Kind of.",
            "Took something that for user looks very similar to just a Google search you just have.",
            "A box where you can type.",
            "Whatever text you want, say I want to search for motorbikes or I want to search for headscarves or.",
            "I want to search for Bill Clinton.",
            "I don't know, just type whatever you want in this box.",
            "And then.",
            "Based on that, we try to retrieve the relevant content.",
            "There's no fix this August.",
            "You can just type anything you want.",
            "So how does that work well?",
            "We want to search for before I go into the details.",
            "So the idea is here.",
            "We want to search for this.",
            "Object.",
            "And the visual data.",
            "So not just in the metadata, not just in the speech recognition, but in the visual content.",
            "But we don't have a model for motorbikes at first, So what we do is we start from this.",
            "Words that you typed in.",
            "In the system and we then go to commercial search engine like Google Images.",
            "But it could be anything, could be Bing or whatever.",
            "We retrieve a set of images from.",
            "This.",
            "Internet search engine and it turns out that the quality of this retrieved results is quite good.",
            "So that gives us a set of positive examples.",
            "Apart from that we have a pool of negative training data.",
            "So we have like a fixed set of maybe 1000 different images, very diverse, not on any particular topic.",
            "And based on this, we actually train a classifier.",
            "So we have an image encoder that extracts features from each of them, both positive and negative images, and then we'll train a visual model.",
            "I'll give more details in a minute.",
            "And based on that visual model, we can then go back to our archive.",
            "For all the images in the archive we have precomputed features.",
            "So features that we have become computed before hand and then we can match our model against these features to retrieve from the archive.",
            "The output.",
            "And so this is a very general scheme.",
            "What we call the on the fly learning of new models that we have applied both for.",
            "Object categories as well as faces as well as locations and logos.",
            "And it gives you a very flexible system, so you can just.",
            "Rick Reiff whatever you want.",
            "Also, it's language independent if you want to search in a different language.",
            "No problem.",
            "You still get well.",
            "You would get a different model, but you would get very similar.",
            "Results."
        ],
        [
            "OK, so.",
            "For instance, for the object categories, the example of.",
            "Motorbikes or cars or whatever.",
            "This is what we do.",
            "We use a relatively standard pipeline, so for an image we extract.",
            "Sift features that are densely sampled over the image.",
            "We have a few extra tricks there.",
            "We use the root sift which seems to work a bit better than standard SIFT.",
            "I'm not sure whether you're all familiar with the bag of words encoding, like representing images with visual words.",
            "Yes or no?",
            "No reaction.",
            "Well, so basically.",
            "Do you, do you know shift?",
            "Yes, OK, so you can basically represent so an individual SIFT feature is not very discriminative, and so you cannot really rely on individual sift features.",
            "Instead, you have to look at the distribution of the SIFT features over the image.",
            "You have to look at.",
            "All the sift features extracted from an image together an how they are distributed in Sift feature space.",
            "One way to do that is.",
            "Using a Gaussian mixture model.",
            "And basically.",
            "You can.",
            "Assign each sift feature to one of your mixture components.",
            "And so you can then get a feature vector that for each component in your Goshen mixture model, encodes how many of the features in the image fall within that component.",
            "And that can be extended.",
            "You can also add first order and 2nd order statistics of your Goshen mixture model so you can get a very.",
            "Discriminative feature representation for the image that's very robust that can.",
            "This so it means that if you change the viewpoint slightly, if you change the illumination slightly.",
            "You still have a very similar representation.",
            "This gives you a very high dimensional representation, especially if you add first and 2nd order information, which brings you to a Fisher vector representation, but you can add a compression stage where you learn a dimensionality reduction.",
            "And then you actually have a feature vector that you can just use for.",
            "Training a classifier like support vector machine or anything like that.",
            "So you extract this kind of features for all of your images in the database.",
            "Thanks to the compression.",
            "The size of these features keeps under control and since this is very powerful representation to start with and high dimensional.",
            "A simple linear classifier will actually suffice for separating the positive data from the negative data, and that means that.",
            "At retrieval time.",
            "It's actually.",
            "Quite feasible to just.",
            "Go over all the images in your database.",
            "For each image you just.",
            "Take the feature vector that you got.",
            "You multiply it with the feature vector from your classifier.",
            "It's just a vector product.",
            "And that tells you give you a score for whether the image contains the object yes or no.",
            "So it's linear in the size of the database, but since the constant is so small, it's just.",
            "A vector product, it still runs quite fast and we can actually have this on the fly.",
            "So while the user is waiting, in fact it turns out that retrieving the images from Google images and doing the feature computation takes more time than actually then running over the archive and retrieving the results from the archive."
        ],
        [
            "Here you see some results of this.",
            "Which will category search.",
            "Uh, so this is data set from the Netherlands Institute of Sound and Vision, which is also used for several of the track fit experiments, so it's about 400 hours of data that we used in this experiment.",
            "And so if you type forests, this is the kind of images you get.",
            "They're not all forests, but.",
            "They look like firsts at least.",
            "So there was no pre trained classifier.",
            "You just type first moment later you get this kind of results back.",
            "Another user might not be interested in the forests, but might be interested in architecture.",
            "So you type Gothic architecture and you get a different set of.",
            "Results.",
            "So this works both for scenes as well as objects, as long as the object is not too small.",
            "If you would search for bottles and you hope to find all the images where there's a bottle in the image, it may not give you the desired results because.",
            "The bottle images you find on Google probably have just the bottle in the center of the image, and that's not what you have in the archive.",
            "So as long as the quality of the Google images is good enough.",
            "And the.",
            "Query is something visual.",
            "Then it works quite quite well.",
            "Of course, if you type something like politics.",
            "Or an abstract term like Mark.",
            "It will not work because it needs to be something that you can visually recognize and retrieve."
        ],
        [
            "OK, so we applied the same scheme not only for objects but also for faces.",
            "So as I said in the beginning, people are very much interested in people.",
            "And so it turns out that actually you can do a very similar thing.",
            "Four people, so you have your text query where you just type the name of the person you want to find.",
            "Google images gives you a set of images.",
            "And so in Google images you can indicate that you want to have images with faces.",
            "And that helps to get rid of some of the clutter from all these images you detect the face, you extract the facial features and a descriptor of the face.",
            "You have some negative images of faces, so you can learn a linear classifier.",
            "And then giving you your archives.",
            "You can also have the facial features there.",
            "And so you can just take the vector product to get a ranking and you get results where you see that particular person in the archives.",
            "And so here supply to Hollywood movies, because then we know like particular actor should occur or not in a particular movie.",
            "And to get the.",
            "Say."
        ],
        [
            "This is more accurate.",
            "We do not extract them from a single keyframe, but we extract up.",
            "Sorry we extract tracks of faces like this.",
            "That is because face detection typically works very well when the face is frontal.",
            "When the person is looking towards the camera, but when the person is looking somewhere else.",
            "When you have a profile view, then Sir difficult to detect the face and so from a single keyframe it's sometimes very difficult to get an accurate detection, but if you.",
            "Take multiple frames.",
            "And the person happens to look inside the camera at some point, then from there you can track the face over longer.",
            "Time and you can get more information and more accurate.",
            "Data.",
            "So."
        ],
        [
            "We detect a face.",
            "We align the face and we crop the information outside the face and then again we have a very similar pipeline in the sense we extract, then SIFT features.",
            "We use Gaussian mixture models, feature vectors, dimensionality reduction and that gives us a compact face representation.",
            "So again, it's quite similar except for the first steps.",
            "How you extract the features and the focus on the faces.",
            "Also we found that whereas initially.",
            "We worked with facial landmarks like the corners of the eyes and the nose and so on.",
            "It turns out that just having a dense sampling also for faces.",
            "Works much better, and so describing everything is better than only describing these interests.",
            "Points and actually, if you look at the different publications, you see that a lot of effort in the project went into good feature representations.",
            "It's very important if you want to have good results and you want to use simple classifiers like just a linear classifier that you have a good feature representation that holds for faces that also holds for objects as well As for for events, and so good and robust representations is really key.",
            "Domain that we have been working on and making progress on."
        ],
        [
            "OK so here you see some results.",
            "If you type George Bush and you search in the same and ISV data set you get this results where again I guess.",
            "There's a few mistakes, I guess, but most of them are indeed George Bush.",
            "As you would expect.",
            "This technique works best for famous people for which you can really find very good results from Google Images.",
            "If the person is not very famous, it doesn't occur very often in the data set then.",
            "Alright, it doesn't occur very often on the Internet.",
            "Then the Google images results may be confusing and also the classifier you learn will be confusing, so it works better in for people that are kind of celebrities for other people, it might be better to use some alternative data, not search on Google, but maybe search on some dedicated websites for information so we didn't investigate that very much.",
            "But there might be other sources that you can add into the system, like external data that you have available.",
            "This can be relevant for a particular data source and the nice thing about this is that actually.",
            "The model we have is very general.",
            "We never really imposed that.",
            "All these images should be the same person we just set.",
            "We want to find.",
            "We train a classifier that separates.",
            "This set of images from a set of negative images.",
            "And that means that we can just as well apply it, not for a specific person, but for a category of persons.",
            "So, for instance, you can type spectacles.",
            "And you will find.",
            "Images in the database of different people, very spectacles.",
            "You can look for old people.",
            "People with beards, people with mustaches and so on, so.",
            "Again, you can just define the query as you want.",
            "It trains a model.",
            "It gives you the results."
        ],
        [
            "OK. Now it turns out that people in practice sometimes try to use this system not just for object categories, but more for specific objects like specific buildings or logos and stuff like that.",
            "So we said, OK, you can just type any query, but if you type query like Earth, it's a specific highly textured object.",
            "And instead of using this general technique that trains in general classifier, it turns out that or it's well known within the computer vision literature that for this kind of objects you better rely on feature matching approaches.",
            "You don't look at just the overall distribution of the features in the image, but you look at individual features and you try to match individual features between pairs of images.",
            "And then you can also check the geometric configuration between these features and you can see which ones correspond and whether they are consistent with one another.",
            "That's a framework that's typically used in a query by example setting where you show one example image, and then you ask the system to retrieve from the archive additional images of the same object.",
            "But you can just as well use the same.",
            "Idea in an on the fly setting where you retrieve images from Google.",
            "Then you extract descriptors.",
            "And then you just match them with the descriptors you have in your database, like using inverted file systems.",
            "Re rank the top retrieved results and you get results.",
            "Like this?"
        ],
        [
            "So the features that you have to use in this setting are somewhat different than what we had in the other applications.",
            "Downsampling is not a good idea here.",
            "You want to have.",
            "Specific features that can be matched accurately and that can cope also with viewpoint changes.",
            "So you use interest points for in this case, and we used affine invariant interest points so that you can really generalize a lot from a single example image."
        ],
        [
            "And then you can match between 2 images and find the consistent matches and you can really see if you have a lot of matches, then indeed it's probably the same objects and this is much more reliable than just the score of the classifier for this kind of images.",
            "Now the difference between applying this in a query by example setting and applying this in on the fly learning setting is that for the online on the fly learning, you don't just have a single example image that you have multiple example images.",
            "So we extend this idea to multi image.",
            "Multi query image retrieval.",
            "Very looked at different ways of combining multiple tray example images and ranks obtained from these multiple.",
            "Exam."
        ],
        [
            "Images so one way is to just pull the output of the results at the end.",
            "So you just use one training example.",
            "Hello at once and then at the end you merge the results.",
            "Another approach is to have an unsupervised pattern mining step here in between that learns a model.",
            "From with mid level more informative features at this stage and then retrieves the results and then it turns out that you don't need to do the spatial verification anymore."
        ],
        [
            "Again, some examples so you can search for instance for the Golden Gate Bridge.",
            "And you get this kind of results.",
            "You can search for particular brands like logos such as Red Bull and that gives you.",
            "This kind of results."
        ],
        [
            "The Eiffel Tower.",
            "Just do US Army Corps and engineers logo, whatever."
        ],
        [
            "It works quite well and usually it doesn't give the results or less noisy than what you get with the category detection.",
            "For the locals, there's a restriction.",
            "That's of course the logos should be sufficiently textured.",
            "An informative, like typical example is like the night global, which is just this.",
            "We are shape and if you would try and.",
            "Retrieve the night logo, then the results would be disappointing because you find this shape anywhere in the trees.",
            "In the clouds.",
            "But not necessarily on shoes."
        ],
        [
            "OK.",
            "So.",
            "Just recapitulating a bit, we have been talking about this on the fly, learned classifiers which are really a key component in the access systems.",
            "They allow a user to define.",
            "Just by himself, what he's interested in, what he wants to search for, and that is really great.",
            "We get feedback from users that this is really kind of making data much more accessible.",
            "They can search for whatever they want, especially also for less experienced users who may not be so familiar with these hours.",
            "Really like this kind of.",
            "Methods.",
            "On the other hand.",
            "Whenever we want to do something on the fly, we always have to make a compromise between.",
            "Speed on one hand and accuracy on the other hand.",
            "Like the user is actually waiting while we are.",
            "Building our model from the images we got from Google images and we don't want to use or to wait too long.",
            "The user can wait for a couple of seconds, but the user probably doesn't want to wait much longer and so that means that.",
            "Whenever we train our models.",
            "We have to give up some of the accuracy.",
            "In order to gain in speed, so we cannot use as many Google images as we want because the more images we want to retrieve for training our models.",
            "The longer it will take also the kind of features you extract, the kind of classifiers you use are kind of limited because you have to do the processing on the fly.",
            "And so.",
            "A recent insight that we got was that actually.",
            "You do not always have to do this again.",
            "On the fly.",
            "First of all, you can cash your results whenever a particular person has.",
            "Post certain query if another person later.",
            "Types the same words.",
            "We don't have to do the same thing over again.",
            "We can just retrieve the results that we cashed.",
            "And also for common queries queries that occur.",
            "Quite frequently, instead of just using this model that was trained in a hurry in and off on the fly setting.",
            "We could train better models offline.",
            "So where we just take more images?",
            "Or maybe we add like other sources that are more reliable than just Google images.",
            "It turns out that some types of users are even willing to put some effort in building these models, and so they are willing to give you relevance feedback to indicate what are the correct or wrong results, and so you can use that relevance feedback to improve your classifiers.",
            "And then if one user does this then you get a better classifier that can be reused by all the other users.",
            "So this is something that we are currently investigating more.",
            "So what we did is in first instance is to just train classifiers for different Imagenet categories.",
            "I'll show some examples later, and since they have cleaner training data, they will indeed give you better results.",
            "We are also planning to have pre trained models for.",
            "A lot of celebrities, people that are.",
            "Retrieved the query quite often.",
            "And that will give a much more.",
            "But much better impression of the retrieval results because the most frequent ones will give you the best results.",
            "They will be very fast, and so on.",
            "And in some sense.",
            "The philosophy here is to go into.",
            "Lifelong learning or external learning kind of mechanism where the system keeps upgrading and improving its models so.",
            "You start with a set of initial models, but as people use more queries, you can add more models and more and more of these have been pre trained so can be cashed and less has to be done on the fly.",
            "The problem there is that to make this happen and to experience to run experiments with this, you actually need to have a lot of users.",
            "And and it's a you have to set up really a big experiment.",
            "So at the moment we just have the Imagenet categories and then.",
            "Probably in the future also.",
            "And faces and we combine them with the on the fly stuff and by using relevance feedback we can know which ones are good and bad.",
            "So which ones to use?",
            "Which ones to ignore?"
        ],
        [
            "OK, I'm not sure how I'm doing time wise.",
            "Oh OK, another thing that we investigated quite a bit is event detection.",
            "So rather than just looking at keyframes objects since.",
            "Faces it might also be interesting to find videos of particular events like people shaking hands or a person answering a phone, and this is a recent topic that emerged in computer vision.",
            "And that especially partner India has been focusing on."
        ],
        [
            "So since this is also part of a track fit task nowadays there's training data for a couple of events available, so you have lots of training videos for a birthday party for operate and stuff like that, and so we can actually again learn pre trained classifiers for these events.",
            "It's not feasible to rule event detection in an on the fly setting because just retrieving videos from.",
            "YouTube or whatever.",
            "Downloading this and extracting features from this would be way too time consuming to have it in on the fly setting where the user is waiting.",
            "So you really need to have the temporal information for to make these things work.",
            "That means you need to have the video, and that means that processing times are much."
        ],
        [
            "More expensive.",
            "Again, a lot of effort went into getting the good representations.",
            "Good features that capture the essence of a particular event.",
            "So basically what we do is first some optical flow computation.",
            "But then we we estimated the global motion.",
            "And so you can focus on actually the foreground and model only trajectories on the foreground.",
            "That's the ones here in green, so these are.",
            "Features individual points on the.",
            "In a frame that are tracked overtime so they really follow the object, they are not fixed.",
            "But they follow the object and as such they capture both the motion as well as the appearance of.",
            "Yeah, in this case the human performing the action.",
            "So once you have this.",
            "Trajectory's that belongs to the foreground motion.",
            "You can again use.",
            "A descriptor for the whole video that looks at the distribution of these features.",
            "So Fisher vectors representation or something like that?"
        ],
        [
            "And apart from just the only fly search.",
            "We also have tools for similarity search, so query by example.",
            "So for scenes and objects, that's just the standard pipeline similar to the.",
            "Places on the fly system that I mentioned before, but we also have.",
            "Something for similarity?",
            "Search for specific four faces.",
            "So as I showed in the video, the commercial video at the very beginning, we can use a particular image of a face as a query and then retrieved from the database other images of.",
            "Faces that look very similar to this one.",
            "And in this setting you really want to find the same person.",
            "'cause that's what people are mostly interested in.",
            "So basically what we do is we extract features but.",
            "We don't just look at the overall distribution as such.",
            "We learn a metric that captures like what kind of variations are typical.",
            "Like four different images of the same person and what kind of variations are like, not typical for the same person.",
            "So that variations due to facial expressions or not as much damaging to the distance measure you use then features that are really characteristic for a particular person."
        ],
        [
            "OK, and so that brings us to the second part.",
            "I've explained most of the audiovisual content components we have in our systems.",
            "Based on that we built.",
            "Two different systems.",
            "So far, so one which we call Access Pro which focuses on media professionals.",
            "Which was developed?",
            "Like the first 2 years of the project and then another One X is research which we developed like just.",
            "Last year, which focuses on the researchers and so basically they built on the same components.",
            "On audiovisual content analysis.",
            "But the tools in access ratio research may be more advanced than the ones we had in access.",
            "Pro and especially also the interface is very different because as we said, professional users have different needs than researchers and so they may actually want different things in the interface.",
            "Want to interact with the database in a different?",
            "Wait?",
            "So the."
        ],
        [
            "What the?",
            "Access pro system.",
            "Looks like.",
            "And."
        ],
        [
            "This is what the excess risk research system looks like.",
            "So overall it's still looks.",
            "Maybe somewhat similar, but let me just say."
        ],
        [
            "Stress some of the things we think that are different between.",
            "Media professionals and researchers like researchers.",
            "Really, they're not so familiar with the content of the database, so they might actually want to.",
            "Rely more on browsing and linking just.",
            "Surfing the and going from one place to another and find what's in the data set.",
            "Also, researchers may be interested more in tagging and annotation.",
            "They want to add their own notes their own.",
            "Comments in on the data set.",
            "Because they're looking at the data from a particular perspective, and so they want to be able to add nodes and then search in these nodes and so on.",
            "They might actually be interested more in search trails.",
            "You don't have just a search query Anna result, But then you refine the results and you continue.",
            "You want to be able to reproduce the same result later on to go back in time to previous searches and so on.",
            "They want to be able to export meta data because they want to.",
            "Run some statistics analysis on it.",
            "They're probably more interested in customization and personalization, although.",
            "Some of the professional users also want to have that.",
            "They're more interested in collaboration, so it's usually it's often a joint effort where different people want to share nodes or you want to select some videos and then send them on to a friend.",
            "Our colleague researcher so that he can also look into them at his view and so on.",
            "They are interested in usage statistics, so which are the popular videos?",
            "Which are the interesting videos and so on?",
            "And they're more interested in these hours?",
            "And so this is kind of or some of the.",
            "Differences that we took into account when developing these systems.",
            "So instead of just going through my slides on these systems.",
            "Let me just switch.",
            "Let's see if I can show a short demo.",
            "So this is basically the.",
            "Access pro system.",
            "And so basically you have here on the left the search.",
            "Menu where you can do texture text search, visual search similarity search.",
            "You can apply filters on the meta data.",
            "You can also specify certain date range.",
            "So here I show the results on this.",
            "An ISV Pro data set which is actually 400 hours that are also commonly used for for track fit.",
            "So it's.",
            "Just broadcasts material from the Netherlands Institute of Sound and Vision.",
            "It's Dutch data, so if you do text search then it's best if you type your search queries in Dutch because the metadata is in Dutch.",
            "Spoken words are also mostly in Dutch, and so the default thing is to just search on metadata and spoken words.",
            "So if you would just have meta data.",
            "Then results are.",
            "OK, and that's what people are most familiar or like.",
            "The archive is our end user most familiar with.",
            "But you can actually improve the results by adding also the spoken words, for instance.",
            "If I type koening Beaudoin, which is like a.",
            "King of Belgium.",
            "Just a meta data search doesn't find too many relevant.",
            "Queries.",
            "But if I.",
            "Search for coding Baldwin in the spoken words.",
            "Then it turns out that there's actually.",
            "A couple of videos, like this one, this one where you indeed see.",
            "The King of all King of Belgium in the video material.",
            "And so for the Dutch archive.",
            "He was probably not important enough to be explicitly annotated, but for a Belgian user it might be interesting to see also that his present error.",
            "We can also have different types of views we can look at the results as thumbnails as I show here, which is mostly interested.",
            "Interesting if you are doing a visible search.",
            "But we also have compact view where you get some basic information about the length of the video, the title of the video, the date.",
            "And short description.",
            "Or you can have a detailed view way of a bit more information.",
            "For instance, you can also see what based on what this video was retrieved.",
            "So at this moment we only have the spoken words search active, so it's matched based on speech.",
            "But you can also have combinations of textual and visual search and then you can see.",
            "Walter actually caused this video to be retrieved, and it turns out that users really wanted feedback.",
            "They want to know why do I get this results?",
            "So you can do a preview, then you get to see.",
            "The video but you can also look at more detailed information.",
            "And then you get all the metadata that's available for that program.",
            "And then, like the spoken words, speech recognition.",
            "For particular segment that was retrieved here.",
            "So you could also say OK if I want to find.",
            "Calling Baldwin in the image.",
            "Maybe instead of just searching in the text, I can search for him.",
            "In the visual.",
            "Search books now we look for.",
            "Koning beaudoin for face of coding.",
            "Bowdoin in.",
            "This database turns out that it doesn't really work too well, but the problem is if you look at the training images.",
            "There's actually not many coding Baldwins here like this, ones are correct.",
            "But that's like always the same image.",
            "This one is correct, but it's like 2 limited to actually.",
            "Build a good model of that person.",
            "If, on the other hand.",
            "I take for instance Vulcan and then.",
            "Which was the.",
            "Prime Minister of the Netherlands at a time when this.",
            "The other set was collected.",
            "These are the training images that we collect from Google images.",
            "Again, they're not for perfect.",
            "The 1st two are wrong, but these here are all correct.",
            "And based on that.",
            "These are the images we retrieve and indeed you see that.",
            "They are all showing the prime.",
            "The ex Prime Minister of the Netherlands.",
            "And for some users, it's actually if you really want to find particular fragments.",
            "This is much more interesting to search for balcony like this and you can see where you have nice view of him or in the nice setting.",
            "Then when you just search for.",
            "The same person.",
            "In the metadata.",
            "Or spoken words.",
            "Then you get much more noisy data.",
            "Sometimes there is spoken and like I guess here it's a group photo is part of it.",
            "Here's present.",
            "But then you also have a lot of other.",
            "Material where maybe it's about Vulcan and or or someone taking an interview of Vulcan and but it may not be the actual.",
            "They may not be feasible.",
            "And so if you want to reduce if you want to.",
            "Actively use this data, then it might be more interesting to be able to do the visual search.",
            "We also have this similarity search.",
            "For instance, if it's OK, who is this person and I want to see if there's more.",
            "Examples of this person in the database you can drag it to the similarity search and you find.",
            "Examples of this particular person.",
            "And of course we can also do the category search.",
            "So.",
            "Let me just show the results for the first.",
            "Again, maybe now it's clear.",
            "So you can see lots of forests, but you can also use it for other categories.",
            "Like if I see.",
            "The.",
            "Thinking of a good example.",
            "With this let's just say car.",
            "Not sure whether it's.",
            "Working too well on these datasets, but.",
            "So you see, here he has to retrieve because he didn't have it online and so we have to wait a moment.",
            "Because during that time he goes back to Google images, retrieves images there, computes the model applied, applies it to the database.",
            "It's not instantaneous, but it's just a few seconds, so that's not really a problem.",
            "It's fast enough, and for most users it's acceptable, and you see that the results look again quite good.",
            "Um?",
            "OK, so.",
            "Let's switch to the research system.",
            "The research system as we said this is a bit more.",
            "Complex like here, you just had the basic search tools and that sits in the research system, gets first overview of recently viewed videos, your own research, recent queries so you can look back at what you searched before.",
            "The interesting thing is also that like you can click on a link here.",
            "So you can just go to a previous query again.",
            "And you get the results that you retrieved earlier, and so you have here an unique identifier of that particular search, so you can send.",
            "That's identifier to your colleague.",
            "He can also find the same information.",
            "You can just go back and forth through your search results.",
            "You can look at popular videos.",
            "You can have your own collection of videos.",
            "There's lots of things you can do.",
            "The search tool itself is much simpler, so it's just here on top single.",
            "Query box, but you can specify again whether you want to have a text search or visible search for these different type of components.",
            "And Additionally, we also have this automatic search.",
            "Which is still under development like.",
            "Where we automatically try to figure out whether what you're searching for, whether your query is a person, and then maybe you're more interested in two interfaces, or whether it's.",
            "An object and then you want to search based on categories or whether it's a place and so it tries to automatically find the relevant.",
            "Per component to apply to your search you can also do the similarity search.",
            "Using this we have advanced search where you can combine multiple queries.",
            "And so this is this demo here runs on data from Deutsche Welle, so it's in German.",
            "And it's only 40 hours actually.",
            "Most of our experiments recently we did on bigger datasets from an ISV which was almost 4000 hours of data, which is roughly half a year of continuous video broadcasting.",
            "But there's IPR issues with that data, and so we cannot show it and.",
            "Public audiences so you can search here.",
            "Like for instance bundle tool is a specific place.",
            "You can search for the results.",
            "You get.",
            "Different examples.",
            "Of that particular building.",
            "So you can add it to your collection.",
            "You can do a similarity search.",
            "You can also just get more detailed information about the.",
            "Video.",
            "Will that or understand my schedule?",
            "I'll just put off the audio and here you have more program information.",
            "For instance, researchers also want to have the possibility that you display all the keyframes belonging to the video that you have a virtual cutter so you can select the fragment that you're mostly interested in, instead of having the whole video, you can download the meta data.",
            "You can add it to collection.",
            "You can download the transcripts or subtitles.",
            "You can add.",
            "You can add your own nodes, two particular video and then for the browsing and linking we also have here like a possibility to look at related videos or related segments.",
            "Which at the moment or purely based on the metadata information.",
            "So that you can kind of browse and find other information that seems relevant.",
            "One more thing I wanted to show here is the difference between the on the fly search and the pre trained classifiers.",
            "So at this moment since the data is in German and the user testings were done by.",
            "Journalists at Deutsche Welle.",
            "Who are German?",
            "We translated the.",
            "Pre trained classifiers based on image net to German and that means that if you type a word in English.",
            "You will get.",
            "Like on the fly train results.",
            "You type it in German then it will use a pre trained classifier and so for instance if I type balloon and I search for category.",
            "He goes.",
            "To Google images retrieves images there.",
            "Extracts features for, then trains the model, then applies model to the archive.",
            "And you get this kind of result.",
            "So there's a couple of balloons here, but there's also other things that it gets confused with.",
            "If, on the other hand, we type balloon.",
            "Which is the German equivalent and then it goes much faster because it takes a pre trained classifier and you see that the results also look much better.",
            "There's still confusion with this virtual a logo, but you really retrieve quite a few of these.",
            "Balloons in the data sets.",
            "Same thing for instance, if you type Zeitung, which is newspaper.",
            "You get different.",
            "Newspapers and things that look similar and we notice that the pre trained classifiers if they are wrong.",
            "Often they're more like reasonable mistakes.",
            "They are things that maybe are not.",
            "Newspapers in this case, but at least things that look somewhat similar that people can understand that the system makes this mistake, and that's usually also something that people like.",
            "So yeah, so you can have.",
            "We also have the possibility here to either show the results at the level of individual segments or individual programs.",
            "You can sort them based on the date when they were published.",
            "The length of the video.",
            "You can see how relevant they are, how often they refute, how often they were liked.",
            "You can also filter the results based on metadata.",
            "There's some some keywords and named entities that kind of retrieved from the metadata.",
            "If you search for something he tries to.",
            "Find the relevant thing and then you can apply filters and get better results.",
            "So you could also combine different searches in by adding filters.",
            "OK, so if you want you can just contact me after the talk and you can try out a system yourself.",
            "Maybe more convincing than just me showing a few examples, but it actually works quite well.",
            "Uh.",
            "OK, So what time is it?",
            "I have to start work to wrap up."
        ],
        [
            "Very quickly, so this thing was evaluated at track fit, so we used a very similar.",
            "Interface for the instance search."
        ],
        [
            "We actually did on average in terms of mean average precision, but in terms of precision, we were better."
        ],
        [
            "So here you see the results where the blue ones are the axis."
        ],
        [
            "Wells"
        ],
        [
            "The reason why we didn't do so well in."
        ],
        [
            "Terms of recall is probably because our users didn't spend as much time like they got 15 minutes, but they on average used only half of their time and then they stopped.",
            "So they could probably have found additional results."
        ],
        [
            "We also took part in the media Event detection task with this multimedia event detection system.",
            "Are equal to best results."
        ],
        [
            "We also did something for multimedia event recounting where we try to explain why certain results was retrieved where you see timelines and you can see whether it's based on the audio or based on the visual content.",
            "What are the relevant fragments in the video that actually are relevant for particular event, category and so?"
        ],
        [
            "See then.",
            "Quickly.",
            "A few words on like what if we learned or just a few general comments that I thought would be interesting to share first?",
            "This idea of on the fly learning of models seems really to be a very powerful paradigm, and so I really would.",
            "Suggest everyone.",
            "Two to go in that direction or use it because it can really do a lot more than what you have with pre trained classifiers and so it really goes in the direction of lifelong learning and the system gets better and better overtime and that's really what's what you want.",
            "We also noticed that.",
            "Data is important.",
            "The more data the better.",
            "So we compared systems with different amounts of data.",
            "And actually, the bigger the data sets you're applying your method to, the better the results get the more convinced your users will be because.",
            "If you have a very small data set.",
            "You, there's only limited content available there, and there's a very good chance that something that person is searching for is just not present in the data sets.",
            "And then you just get.",
            "And the related results returns because we return the top ranked ones.",
            "But if the object is not there in the archive, then there's no way we can retrieve it.",
            "The bigger you make your data set.",
            "So going from $500 to 1002 thousand 3004 thousand, we see that gradually the top results really get much much better because.",
            "There's more.",
            "Option instances that are in the data set.",
            "There's a better chance that once you retrieve data to prove we really correct.",
            "When we did this experiment with 4000 hours of data, we notice that even for very weird queries you still get.",
            "Results out of the data set you can just.",
            "Use some of these image net classifiers where you think well this is like this has no chance, but let's just see what it gives you.",
            "Try snow scooter and there you go you find.",
            "A couple of snow scooters in your archive you type cargoship.",
            "You type whatever you want.",
            "The most weird things.",
            "Can you find them and people are really surprised.",
            "Oh yeah, you found it.",
            "So it really becomes very important to have a lot of data.",
            "And people like the system or if it's applied on a larger data set, it takes effort, but it's worth it.",
            "We also found that it's quite important to educate your users.",
            "Especially archivists are used to work with very clean data.",
            "They work with data that is provided by.",
            "Like archivists, that is always correct.",
            "That's very reliable.",
            "And now we propose them a system that can retrieve other information, but that's inherently noisy.",
            "You find sometimes the correct object, but sometimes there's also results retrieved that are incorrect.",
            "And at first it's very difficult for them to really understand this and to cope with this because they say, well, I don't trust this system.",
            "I don't want to use it because I don't trust it.",
            "Worse.",
            "If you understand what is going on, you can say, well, OK, I still have to verify whether it's correct, but at least I can find things that I couldn't find before.",
            "So that's important that you really show them and explain them what's what's going on.",
            "They also want to vary.",
            "To understand why you get a certain result which is not always possible to explain, you just train a classifier and.",
            "Sometimes it's overfitting, sometimes it's.",
            "Like the negative data are not representative enough.",
            "There's a lot of things that can go wrong, but you cannot explain all this to the end users.",
            "Also a good user interface is important.",
            "The first feedback you get when you show a system to the user is just about the user interface, like only this button should be there and why don't you have this and we should have.",
            "It's important that you showed the system with a good user interface and you put a lot of effort in having the interface done well.",
            "And finally, I guess.",
            "There's still a lot of room for improvement in terms of multimodal and spatial temporal processing.",
            "Initially when we started Project I thought OK for Access Pro we will start with keyframe based analysis but afterwards we will go beyond.",
            "Analysis of keyframes will really analyze the full videos because there's much more content individuals and individual keyframes.",
            "But in practice, it turns out that the computational efforts that you have if you want to process video or so much.",
            "Bigger than what you have if you just process individual keyframes then it's at this moment not really worth it.",
            "For instance, event detection uses video.",
            "There you cannot do without for the faces.",
            "We also use it, but it really means that the face tracking now.",
            "Takes a lot of resources and takes a lot of time.",
            "If you want to do the indexing.",
            "And worse.",
            "In an ideal setting, you think well, we want to do everything spatial, temporal, not only analyze the keyframes because then you lose a lot of information in between.",
            "In practice, it's not so easy to actually do that, and the same holds for the multimodal aspects.",
            "We thought initially well, we want to not just have audio on one side.",
            "Video on the other, you want to combine them and combine them, not just at the last stage when you combine different queries, But you want to combine them early on, because all you can provide context for object recognition in video and vice versa.",
            "Also, for people like.",
            "The speaker identification and face recognition can help each other, and so on, and we're working on these things, but it's.",
            "Not so easy to really apply it throughout the entire pipeline, and for all the different components we use multimodal aspects for the event detection.",
            "We are working on combination of speaker identification, face recognition.",
            "But it's not as easy as you would think at 1st, and so there's still a lot of things that can be done in that respect.",
            "OK, and I guess that was about my last slide.",
            "I still had a few slides on the excess home system that we're starting to look into, but I guess I'm running out of time for that one."
        ],
        [
            "The.",
            "So I'll finish with this one.",
            "Do you have any questions?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The idea of this talk is to introduce you to the access project.",
                    "label": 0
                },
                {
                    "sent": "This is a project that started three years ago and still running for one more year and that has goal to open up audiovisual archives and up to now the last three years we actually focused on two types of end users that's made up media professionals as well as researchers, and so that's what I will be talking about, mostly today.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just a very short overview of this project.",
                    "label": 0
                },
                {
                    "sent": "I'll start with this presentation.",
                    "label": 0
                },
                {
                    "sent": "I'll start with the introduction of the access project, what it's really about.",
                    "label": 0
                },
                {
                    "sent": "Then I'll focus on the audiovisual content analysis, which is the main backbone of the systems we develop.",
                    "label": 1
                },
                {
                    "sent": "Now I must say that maybe I do not do honor to all the different aspects of the project.",
                    "label": 0
                },
                {
                    "sent": "I decided to focus on the audiovisual content analysis because that's also what I'm myself most familiar with.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of work also going on like studying users, getting user requirements, and all these things.",
                    "label": 0
                },
                {
                    "sent": "I will only touch up on this.",
                    "label": 0
                },
                {
                    "sent": "Because I'm not the expert in that field.",
                    "label": 0
                },
                {
                    "sent": "Then I'll show 2 demo systems that we have developed that it's access Pro and access research.",
                    "label": 0
                },
                {
                    "sent": "And I'll conclude with some lessons learned and focus on future work.",
                    "label": 1
                },
                {
                    "sent": "I should also say at this point that.",
                    "label": 0
                },
                {
                    "sent": "This is clearly joint efforts.",
                    "label": 0
                },
                {
                    "sent": "I'm standing here presenting all this work, but it's work from a whole consortium.",
                    "label": 0
                },
                {
                    "sent": "It's a.",
                    "label": 0
                },
                {
                    "sent": "Great team that we're having.",
                    "label": 0
                },
                {
                    "sent": "They're all very motivated, very dedicated, and it's thanks to them that I can show you.",
                    "label": 0
                },
                {
                    "sent": "I can show you all these systems and all this work.",
                    "label": 0
                },
                {
                    "sent": "But I'll want to start with a short commercial short story that kind of captures the main idea of the excess product.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is Tom.",
                    "label": 0
                },
                {
                    "sent": "Tom works at an archive.",
                    "label": 0
                },
                {
                    "sent": "And I hope you cannot.",
                    "label": 0
                },
                {
                    "sent": "Is a TV journalist.",
                    "label": 0
                },
                {
                    "sent": "It is a strange job.",
                    "label": 0
                },
                {
                    "sent": "Yeah, research interview.",
                    "label": 0
                },
                {
                    "sent": "It was us.",
                    "label": 0
                },
                {
                    "sent": "We started a revolution cut.",
                    "label": 0
                },
                {
                    "sent": "One thing Tom never liked about his job was the research in the archive.",
                    "label": 0
                },
                {
                    "sent": "But why Tom's broadcaster has a wonderful huge treasure archive material.",
                    "label": 0
                },
                {
                    "sent": "One could easily search with keywords.",
                    "label": 0
                },
                {
                    "sent": "But then the relevant sequence had to be found and this kind of search was often quite hard.",
                    "label": 0
                },
                {
                    "sent": "Tom had to scream and scream and scream some more.",
                    "label": 0
                },
                {
                    "sent": "Until he finally found what he was looking for, you really cool, but those days are gone now thanks to access.",
                    "label": 0
                },
                {
                    "sent": "Access enables Tom only to search for keywords, but directly for images excess can detect buildings, places and objects.",
                    "label": 0
                },
                {
                    "sent": "At one glance, Tom finds the relevant sequences.",
                    "label": 0
                },
                {
                    "sent": "No search, no fast forwarding.",
                    "label": 0
                },
                {
                    "sent": "X is also searches for similar images.",
                    "label": 0
                },
                {
                    "sent": "For example it can file records of a particular person or face in the archive.",
                    "label": 0
                },
                {
                    "sent": "Based on previously found image, Tom could not believe it at first class, but thanks to speech recognition he can now search for spoken words.",
                    "label": 0
                },
                {
                    "sent": "This revolution will bring down the president.",
                    "label": 0
                },
                {
                    "sent": "Ever since Axis Tom enjoys researching the archive it has never before been so easy to find gems hidden in the archive.",
                    "label": 0
                },
                {
                    "sent": "This way his contributions will be even better and now Tom is even happier with his dream job.",
                    "label": 0
                },
                {
                    "sent": "Access creates a user interface for each of the targeted user groups, media professionals, researchers and educators and home users.",
                    "label": 0
                },
                {
                    "sent": "The project is partially funded by the European Commission and the research is gone by.",
                    "label": 0
                },
                {
                    "sent": "Get more info here.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a commercial.",
                    "label": 0
                },
                {
                    "sent": "It may be a bit too optimistic, but it kind of captures very nicely the spirits and the idea of the access project.",
                    "label": 0
                },
                {
                    "sent": "If we look at.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Current situation in common practice when people look at at archives then we see that there's a huge wealth of audiovisual data around, so we focus on video material that actually is.",
                    "label": 1
                },
                {
                    "sent": "The same applies also to other types of audio visual data.",
                    "label": 0
                },
                {
                    "sent": "There's enormous wealth of information around at public broadcasters, but also like.",
                    "label": 0
                },
                {
                    "sent": "In companies and it's getting easier and easier to collect data and to start data, but then accessing this data is a problem.",
                    "label": 0
                },
                {
                    "sent": "Knowing what's in your archive, that's really the key.",
                    "label": 0
                },
                {
                    "sent": "Getting to the knowledge the semantics rather than just the raw data.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that there's actually quite a lot of data in this archives that is simply irretrievable.",
                    "label": 0
                },
                {
                    "sent": "That cannot be found.",
                    "label": 0
                },
                {
                    "sent": "For a number of reasons, on the one hand, there is a lot of ultimate irial that comes from the pre digital era that has not been.",
                    "label": 0
                },
                {
                    "sent": "Annotated properly, so there's a huge effort going on.",
                    "label": 0
                },
                {
                    "sent": "Digitising this information a lot has been digitized already, but then without the additional metadata.",
                    "label": 0
                },
                {
                    "sent": "It's not really useful because you cannot really retrieve and find the relevant data there.",
                    "label": 0
                },
                {
                    "sent": "Another problem with.",
                    "label": 0
                },
                {
                    "sent": "The current situation is that the metadata that is available is provided by archivists and they do a wonderful job adding metadata for the data in their archive.",
                    "label": 0
                },
                {
                    "sent": "But it's usually at the level of entire documents, so they say, OK, this is a documentary about.",
                    "label": 0
                },
                {
                    "sent": "The Arabic spring.",
                    "label": 0
                },
                {
                    "sent": "In Egypt, but they don't go to the final grade level.",
                    "label": 0
                },
                {
                    "sent": "They don't go to the details of individual fragments.",
                    "label": 0
                },
                {
                    "sent": "That might be fine if you just want to find a documentary and you just want to look at it.",
                    "label": 0
                },
                {
                    "sent": "So if you are a passive user, but if you are more active user and you want to.",
                    "label": 0
                },
                {
                    "sent": "Reuse that material you want to be creative with it and make a new compilation or whatever.",
                    "label": 0
                },
                {
                    "sent": "Then typically you're not interested in the entire documentary you're interested in particular fragments like the fragmente where you have this demonstration on the tackling squared with different.",
                    "label": 0
                },
                {
                    "sent": "Isn't this person or this event going on that level of detail is not available in the current meta data as provided?",
                    "label": 0
                },
                {
                    "sent": "By the archivists.",
                    "label": 1
                },
                {
                    "sent": "Also, the data provided by the archivists is.",
                    "label": 0
                },
                {
                    "sent": "In a sense, biased.",
                    "label": 0
                },
                {
                    "sent": "Because whatever user is interested in depends on the situation.",
                    "label": 0
                },
                {
                    "sent": "Differently have different uses of material, like whether we are active or passive user, whether we want to reduce the data or just watch it is also depends from 1 user to another.",
                    "label": 0
                },
                {
                    "sent": "Another example is researchers.",
                    "label": 0
                },
                {
                    "sent": "Maybe you don't want to find a particular fragmente to reuse it, but you want to find the fragments or lots of fragments.",
                    "label": 0
                },
                {
                    "sent": "To get some statistics and to see the trends overtime, like historians, might be interested in, I don't know how many women wear headscarves in Egypt.",
                    "label": 0
                },
                {
                    "sent": "And they want to watch.",
                    "label": 0
                },
                {
                    "sent": "Or they have a huge source of information there of audiovisual material from which they could extract this information.",
                    "label": 1
                },
                {
                    "sent": "But that would mean that they would have to manually go through all this data they can retrieve.",
                    "label": 0
                },
                {
                    "sent": "Based on the current meta meta data.",
                    "label": 0
                },
                {
                    "sent": "Documentaries where they think they might be relevant, like on the Arabic Spring or something like that, but then within that documentary they have to manually browse like feedforward or browser keyframes and so on, and then check are there women.",
                    "label": 0
                },
                {
                    "sent": "Do they wear a headscarf?",
                    "label": 0
                },
                {
                    "sent": "Yes or no?",
                    "label": 0
                },
                {
                    "sent": "It's very time consuming.",
                    "label": 0
                },
                {
                    "sent": "It's not the way you want to actually do your research.",
                    "label": 0
                },
                {
                    "sent": "What they would like to have it again, automated methods that can.",
                    "label": 0
                },
                {
                    "sent": "Retrieve particular fragments at a very fine grained scale.",
                    "label": 0
                },
                {
                    "sent": "And this not just for one fragment for a huge number of fragments, so it need really need to scale up so that they can get statistics from there, and they can actually do something with it.",
                    "label": 0
                },
                {
                    "sent": "Also the.",
                    "label": 0
                },
                {
                    "sent": "Metadata you're interested in might actually change overtime.",
                    "label": 0
                },
                {
                    "sent": "Or change from 1 user to another.",
                    "label": 0
                },
                {
                    "sent": "I notice that myself if I look at my personal photo collection or video collection.",
                    "label": 0
                },
                {
                    "sent": "If I look at the recent years, I'm mostly interested in the extraordinary like special events, travels and so on.",
                    "label": 0
                },
                {
                    "sent": "But if you go further back in time.",
                    "label": 0
                },
                {
                    "sent": "Then actually it's not the special events that are most interesting, but it's the ordinary events like just oh look kind of clothes we were wearing at that time.",
                    "label": 0
                },
                {
                    "sent": "Look at that car, look at just ordinary things, become much more important, but an annotator who would have nicely set like this is the birthday of this person at that location, and so on.",
                    "label": 0
                },
                {
                    "sent": "Will not have annotated things like the clouds are the cars or anything like that because?",
                    "label": 0
                },
                {
                    "sent": "It's so ordinary they think it's not important, but So what is important can shift overtime and also can shift from one place to another and so on.",
                    "label": 0
                },
                {
                    "sent": "If I travel and I see the news in some other country, I'm not really interested in the specific news item, but again, more in the general setting and so on.",
                    "label": 0
                },
                {
                    "sent": "So it's very difficult to manually provide metadata at the right level of granularity and to really deal with.",
                    "label": 0
                },
                {
                    "sent": "All the different information needs that different types of users might have.",
                    "label": 0
                },
                {
                    "sent": "And therefore we thought like for access it would be good to try and open up these archives and to add on top of the metadata provided by archivists, additional metadata that is extracted.",
                    "label": 0
                },
                {
                    "sent": "In an automatic fashion like we automatically retrieve and annotate and so on the data so that users.",
                    "label": 0
                },
                {
                    "sent": "Sorry, so that users can query the data and retrieve the data they are interested in.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is basically what I just.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Set.",
                    "label": 0
                },
                {
                    "sent": "So in a nutshell, while Texas has main goals like the mission statement of the Access project goes as follows, we want to develop new tools.",
                    "label": 0
                },
                {
                    "sent": "Providing you an engaging ways to interact with audiovisual libraries.",
                    "label": 1
                },
                {
                    "sent": "So this is an aspect that I didn't mention in the previous slide yet.",
                    "label": 0
                },
                {
                    "sent": "Actually we also want to go beyond simple searching the archive.",
                    "label": 0
                },
                {
                    "sent": "The basic idea when you think about opening up an archive is like you just.",
                    "label": 0
                },
                {
                    "sent": "Have particular information needs you formulated in terms of search query and then the answer is retrieved from the archive.",
                    "label": 0
                },
                {
                    "sent": "You get a ranked list back of the videos that are relevant for your search, but that's not the way people typically want to.",
                    "label": 0
                },
                {
                    "sent": "Interact with the archive.",
                    "label": 0
                },
                {
                    "sent": "The example of the researcher I just gave before is 1 example where people might want to get some statistics out of the archive.",
                    "label": 0
                },
                {
                    "sent": "It's again some information needs, but it's not simply searching and getting a ranked list.",
                    "label": 0
                },
                {
                    "sent": "They want to get extra information from their people.",
                    "label": 0
                },
                {
                    "sent": "Might be interested in just browsing the archive, exploring the archive, or as we set in the project proposal, experiencing the archive because it's still.",
                    "label": 0
                },
                {
                    "sent": "Unclear what this could all.",
                    "label": 0
                },
                {
                    "sent": "On campus, there's so many different ways you can interact with an archive.",
                    "label": 0
                },
                {
                    "sent": "So we want also in the access project try and go beyond the simple search.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we want to do so for a multitude of end users.",
                    "label": 1
                },
                {
                    "sent": "There's already quite a few systems that are being developed focusing on media professionals.",
                    "label": 0
                },
                {
                    "sent": "But the needs and the background knowledge of media professionals is very different from what you see when you talk with researchers or when you talk with home users and you cannot build just one system for all of them.",
                    "label": 0
                },
                {
                    "sent": "You need to adapt the system towards the specific needs.",
                    "label": 1
                },
                {
                    "sent": "For instance, home users often don't know what's in the archive media professionals.",
                    "label": 0
                },
                {
                    "sent": "They probably are somewhat familiar with the system, although.",
                    "label": 0
                },
                {
                    "sent": "It turns out that also media professionals often do not know what's in their archives.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And so we want to have different systems and look at different needs.",
                    "label": 0
                },
                {
                    "sent": "So that really this wealth of information in the archive can be opened up to as many.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different users as possible.",
                    "label": 0
                },
                {
                    "sent": "And to achieve that we want to build on state of the art content analysis techniques where we focus on computer vision.",
                    "label": 0
                },
                {
                    "sent": "Analyzing the visual information in the videos.",
                    "label": 0
                },
                {
                    "sent": "Audio analysis and speech recognition, but also multimodal aspects where we try to combine audio and video.",
                    "label": 0
                },
                {
                    "sent": "Search and navigation where we focus on scalability.",
                    "label": 0
                },
                {
                    "sent": "The methods we develop.",
                    "label": 0
                },
                {
                    "sent": "Should not only be accurate, but also they should be applicable on a large scale like they don't need to.",
                    "label": 0
                },
                {
                    "sent": "They should not use too much computational power.",
                    "label": 0
                },
                {
                    "sent": "They should be scalable to thousands or ultimately millions of hours of video.",
                    "label": 0
                },
                {
                    "sent": "Another aspect that we wanted to focus on is weakly supervised methods that is also when learning our methods, we want the system to learn from weekly weeks of provision.",
                    "label": 0
                },
                {
                    "sent": "You can easily say OK, I trained a classifier for a particular concept, but if that means that you need to collect a lot of training materials for that particular concept that again it's very labor intensive and it's not very flexible.",
                    "label": 0
                },
                {
                    "sent": "So instead we want to have methods that can.",
                    "label": 0
                },
                {
                    "sent": "Learn from data that's already available from the Internet or some other source.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In practice, we focus on different types of content because it turns out that the techniques you need to recognize, for instance, people is very different from what you need.",
                    "label": 0
                },
                {
                    "sent": "For places, events, object categories.",
                    "label": 1
                },
                {
                    "sent": "People in particular turn out to be very important for most users.",
                    "label": 0
                },
                {
                    "sent": "If you look at what people search for, it's mostly people names.",
                    "label": 0
                },
                {
                    "sent": "And only secondary places, events, categories.",
                    "label": 0
                },
                {
                    "sent": "So we need to have different methods to cope with these different types of contents.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we follow a user centric approach.",
                    "label": 0
                },
                {
                    "sent": "So we early on showed prototypes to end users interviewed, then got feedback from them.",
                    "label": 0
                },
                {
                    "sent": "Do we do service?",
                    "label": 0
                },
                {
                    "sent": "We showed them our systems, get feedback and so on.",
                    "label": 0
                },
                {
                    "sent": "But as I said in the beginning, I will not focus too much on this.",
                    "label": 0
                },
                {
                    "sent": "Cycle of getting input from users and iterating.",
                    "label": 0
                },
                {
                    "sent": "It's a process that also runs over the different systems.",
                    "label": 0
                },
                {
                    "sent": "So we had first system for the professional users.",
                    "label": 0
                },
                {
                    "sent": "The feedback we got from that system.",
                    "label": 0
                },
                {
                    "sent": "Was used to improve the system for the professionals, but also for.",
                    "label": 0
                },
                {
                    "sent": "We need to account for building the system for the researchers and will be used for home users as well.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's just like how we go to our logo so it's users, technology and content.",
                    "label": 0
                },
                {
                    "sent": "That's enough for the introduction.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's move on to the core of this talk.",
                    "label": 0
                },
                {
                    "sent": "How do we do it?",
                    "label": 0
                },
                {
                    "sent": "What is the underlying audiovisual content analysis pipeline?",
                    "label": 1
                },
                {
                    "sent": "How do we actually get the right interpretation from this video so that we can retrieve data from it and we can answer information needs?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the overall pipeline I'm not going to talk too much about this slide.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quickly just go over the first steps here to see how so you get the general flow of information.",
                    "label": 0
                },
                {
                    "sent": "All the videos first gets collected.",
                    "label": 0
                },
                {
                    "sent": "We extract the existing metadata because all the meta data that is available, it would be stupid not to use it, so we collect it.",
                    "label": 0
                },
                {
                    "sent": "We make sure that at least the metadata that is available is searchable.",
                    "label": 0
                },
                {
                    "sent": "We do a video normalization step where we change the different formats and so on.",
                    "label": 0
                },
                {
                    "sent": "And then we have two parallel tracks, one that focuses on the audio.",
                    "label": 0
                },
                {
                    "sent": "Where we do speech processing, so diarization, speech processing and so on and on the other hand, we look at the video.",
                    "label": 0
                },
                {
                    "sent": "And with the video actually the first thing is how do you define a fragment?",
                    "label": 0
                },
                {
                    "sent": "So you have a large video?",
                    "label": 0
                },
                {
                    "sent": "You have to split it up in fragments.",
                    "label": 0
                },
                {
                    "sent": "That's the unit that people can retrieve, and it's very difficult thing to define the right fragmente.",
                    "label": 0
                },
                {
                    "sent": "So we actually took a very simple approach.",
                    "label": 0
                },
                {
                    "sent": "Here we just run a shot detector and we select a couple of key frames for each shots, and most of the further processing.",
                    "label": 0
                },
                {
                    "sent": "It's limited to this keyframes.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Except for.",
                    "label": 0
                },
                {
                    "sent": "Two or three different components, where actually the temporal information is very important.",
                    "label": 0
                },
                {
                    "sent": "So for the faces we do tracking also for the event detection.",
                    "label": 0
                },
                {
                    "sent": "Of course you need to have the temporal information, but the rest is just focusing on the individual keyframes, and it turns out that actually selecting the good keyframes.",
                    "label": 0
                },
                {
                    "sent": "This is quite important in that setting.",
                    "label": 0
                },
                {
                    "sent": "And from there we then have a series of different components that analyze the keyframes.",
                    "label": 0
                },
                {
                    "sent": "In the sense that they extract.",
                    "label": 0
                },
                {
                    "sent": "Faces and do face recognition.",
                    "label": 0
                },
                {
                    "sent": "They extract features that can be used later for object category recognition for place recognition and so on.",
                    "label": 0
                },
                {
                    "sent": "And one of the key components.",
                    "label": 0
                },
                {
                    "sent": "One of the key differentiators of our access system compared to.",
                    "label": 0
                },
                {
                    "sent": "Previous systems is.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we actually.",
                    "label": 0
                },
                {
                    "sent": "Focus on this on the fly.",
                    "label": 0
                },
                {
                    "sent": "Paradigm so I should explain what we mean with that.",
                    "label": 0
                },
                {
                    "sent": "We had a lot of discussion in the beginning of the project, like what is it should be that these are?",
                    "label": 0
                },
                {
                    "sent": "What kind of objects should we be able to retrieve from the system?",
                    "label": 0
                },
                {
                    "sent": "What kind of which people do we need to be recognized?",
                    "label": 1
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that it's very difficult to come up with such a list, because as I said before, different users may have different needs, different interests, things can change overtime.",
                    "label": 0
                },
                {
                    "sent": "And so instead of having like a fixed dose, fixed list of concepts that we say, OK, this is the things that we annotate and that you can search for.",
                    "label": 0
                },
                {
                    "sent": "We took a completely different approach and we.",
                    "label": 0
                },
                {
                    "sent": "Kind of.",
                    "label": 0
                },
                {
                    "sent": "Took something that for user looks very similar to just a Google search you just have.",
                    "label": 0
                },
                {
                    "sent": "A box where you can type.",
                    "label": 0
                },
                {
                    "sent": "Whatever text you want, say I want to search for motorbikes or I want to search for headscarves or.",
                    "label": 0
                },
                {
                    "sent": "I want to search for Bill Clinton.",
                    "label": 0
                },
                {
                    "sent": "I don't know, just type whatever you want in this box.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "Based on that, we try to retrieve the relevant content.",
                    "label": 0
                },
                {
                    "sent": "There's no fix this August.",
                    "label": 0
                },
                {
                    "sent": "You can just type anything you want.",
                    "label": 0
                },
                {
                    "sent": "So how does that work well?",
                    "label": 0
                },
                {
                    "sent": "We want to search for before I go into the details.",
                    "label": 0
                },
                {
                    "sent": "So the idea is here.",
                    "label": 0
                },
                {
                    "sent": "We want to search for this.",
                    "label": 0
                },
                {
                    "sent": "Object.",
                    "label": 0
                },
                {
                    "sent": "And the visual data.",
                    "label": 1
                },
                {
                    "sent": "So not just in the metadata, not just in the speech recognition, but in the visual content.",
                    "label": 0
                },
                {
                    "sent": "But we don't have a model for motorbikes at first, So what we do is we start from this.",
                    "label": 0
                },
                {
                    "sent": "Words that you typed in.",
                    "label": 0
                },
                {
                    "sent": "In the system and we then go to commercial search engine like Google Images.",
                    "label": 0
                },
                {
                    "sent": "But it could be anything, could be Bing or whatever.",
                    "label": 0
                },
                {
                    "sent": "We retrieve a set of images from.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Internet search engine and it turns out that the quality of this retrieved results is quite good.",
                    "label": 0
                },
                {
                    "sent": "So that gives us a set of positive examples.",
                    "label": 0
                },
                {
                    "sent": "Apart from that we have a pool of negative training data.",
                    "label": 0
                },
                {
                    "sent": "So we have like a fixed set of maybe 1000 different images, very diverse, not on any particular topic.",
                    "label": 0
                },
                {
                    "sent": "And based on this, we actually train a classifier.",
                    "label": 0
                },
                {
                    "sent": "So we have an image encoder that extracts features from each of them, both positive and negative images, and then we'll train a visual model.",
                    "label": 0
                },
                {
                    "sent": "I'll give more details in a minute.",
                    "label": 1
                },
                {
                    "sent": "And based on that visual model, we can then go back to our archive.",
                    "label": 1
                },
                {
                    "sent": "For all the images in the archive we have precomputed features.",
                    "label": 0
                },
                {
                    "sent": "So features that we have become computed before hand and then we can match our model against these features to retrieve from the archive.",
                    "label": 0
                },
                {
                    "sent": "The output.",
                    "label": 0
                },
                {
                    "sent": "And so this is a very general scheme.",
                    "label": 0
                },
                {
                    "sent": "What we call the on the fly learning of new models that we have applied both for.",
                    "label": 0
                },
                {
                    "sent": "Object categories as well as faces as well as locations and logos.",
                    "label": 0
                },
                {
                    "sent": "And it gives you a very flexible system, so you can just.",
                    "label": 0
                },
                {
                    "sent": "Rick Reiff whatever you want.",
                    "label": 0
                },
                {
                    "sent": "Also, it's language independent if you want to search in a different language.",
                    "label": 0
                },
                {
                    "sent": "No problem.",
                    "label": 0
                },
                {
                    "sent": "You still get well.",
                    "label": 0
                },
                {
                    "sent": "You would get a different model, but you would get very similar.",
                    "label": 0
                },
                {
                    "sent": "Results.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "For instance, for the object categories, the example of.",
                    "label": 0
                },
                {
                    "sent": "Motorbikes or cars or whatever.",
                    "label": 0
                },
                {
                    "sent": "This is what we do.",
                    "label": 0
                },
                {
                    "sent": "We use a relatively standard pipeline, so for an image we extract.",
                    "label": 0
                },
                {
                    "sent": "Sift features that are densely sampled over the image.",
                    "label": 0
                },
                {
                    "sent": "We have a few extra tricks there.",
                    "label": 0
                },
                {
                    "sent": "We use the root sift which seems to work a bit better than standard SIFT.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure whether you're all familiar with the bag of words encoding, like representing images with visual words.",
                    "label": 0
                },
                {
                    "sent": "Yes or no?",
                    "label": 0
                },
                {
                    "sent": "No reaction.",
                    "label": 0
                },
                {
                    "sent": "Well, so basically.",
                    "label": 0
                },
                {
                    "sent": "Do you, do you know shift?",
                    "label": 0
                },
                {
                    "sent": "Yes, OK, so you can basically represent so an individual SIFT feature is not very discriminative, and so you cannot really rely on individual sift features.",
                    "label": 0
                },
                {
                    "sent": "Instead, you have to look at the distribution of the SIFT features over the image.",
                    "label": 0
                },
                {
                    "sent": "You have to look at.",
                    "label": 0
                },
                {
                    "sent": "All the sift features extracted from an image together an how they are distributed in Sift feature space.",
                    "label": 0
                },
                {
                    "sent": "One way to do that is.",
                    "label": 0
                },
                {
                    "sent": "Using a Gaussian mixture model.",
                    "label": 0
                },
                {
                    "sent": "And basically.",
                    "label": 0
                },
                {
                    "sent": "You can.",
                    "label": 0
                },
                {
                    "sent": "Assign each sift feature to one of your mixture components.",
                    "label": 0
                },
                {
                    "sent": "And so you can then get a feature vector that for each component in your Goshen mixture model, encodes how many of the features in the image fall within that component.",
                    "label": 0
                },
                {
                    "sent": "And that can be extended.",
                    "label": 0
                },
                {
                    "sent": "You can also add first order and 2nd order statistics of your Goshen mixture model so you can get a very.",
                    "label": 0
                },
                {
                    "sent": "Discriminative feature representation for the image that's very robust that can.",
                    "label": 0
                },
                {
                    "sent": "This so it means that if you change the viewpoint slightly, if you change the illumination slightly.",
                    "label": 0
                },
                {
                    "sent": "You still have a very similar representation.",
                    "label": 0
                },
                {
                    "sent": "This gives you a very high dimensional representation, especially if you add first and 2nd order information, which brings you to a Fisher vector representation, but you can add a compression stage where you learn a dimensionality reduction.",
                    "label": 0
                },
                {
                    "sent": "And then you actually have a feature vector that you can just use for.",
                    "label": 0
                },
                {
                    "sent": "Training a classifier like support vector machine or anything like that.",
                    "label": 0
                },
                {
                    "sent": "So you extract this kind of features for all of your images in the database.",
                    "label": 0
                },
                {
                    "sent": "Thanks to the compression.",
                    "label": 0
                },
                {
                    "sent": "The size of these features keeps under control and since this is very powerful representation to start with and high dimensional.",
                    "label": 0
                },
                {
                    "sent": "A simple linear classifier will actually suffice for separating the positive data from the negative data, and that means that.",
                    "label": 0
                },
                {
                    "sent": "At retrieval time.",
                    "label": 0
                },
                {
                    "sent": "It's actually.",
                    "label": 0
                },
                {
                    "sent": "Quite feasible to just.",
                    "label": 0
                },
                {
                    "sent": "Go over all the images in your database.",
                    "label": 0
                },
                {
                    "sent": "For each image you just.",
                    "label": 0
                },
                {
                    "sent": "Take the feature vector that you got.",
                    "label": 0
                },
                {
                    "sent": "You multiply it with the feature vector from your classifier.",
                    "label": 0
                },
                {
                    "sent": "It's just a vector product.",
                    "label": 0
                },
                {
                    "sent": "And that tells you give you a score for whether the image contains the object yes or no.",
                    "label": 0
                },
                {
                    "sent": "So it's linear in the size of the database, but since the constant is so small, it's just.",
                    "label": 0
                },
                {
                    "sent": "A vector product, it still runs quite fast and we can actually have this on the fly.",
                    "label": 0
                },
                {
                    "sent": "So while the user is waiting, in fact it turns out that retrieving the images from Google images and doing the feature computation takes more time than actually then running over the archive and retrieving the results from the archive.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here you see some results of this.",
                    "label": 0
                },
                {
                    "sent": "Which will category search.",
                    "label": 0
                },
                {
                    "sent": "Uh, so this is data set from the Netherlands Institute of Sound and Vision, which is also used for several of the track fit experiments, so it's about 400 hours of data that we used in this experiment.",
                    "label": 0
                },
                {
                    "sent": "And so if you type forests, this is the kind of images you get.",
                    "label": 0
                },
                {
                    "sent": "They're not all forests, but.",
                    "label": 0
                },
                {
                    "sent": "They look like firsts at least.",
                    "label": 0
                },
                {
                    "sent": "So there was no pre trained classifier.",
                    "label": 0
                },
                {
                    "sent": "You just type first moment later you get this kind of results back.",
                    "label": 0
                },
                {
                    "sent": "Another user might not be interested in the forests, but might be interested in architecture.",
                    "label": 0
                },
                {
                    "sent": "So you type Gothic architecture and you get a different set of.",
                    "label": 1
                },
                {
                    "sent": "Results.",
                    "label": 0
                },
                {
                    "sent": "So this works both for scenes as well as objects, as long as the object is not too small.",
                    "label": 0
                },
                {
                    "sent": "If you would search for bottles and you hope to find all the images where there's a bottle in the image, it may not give you the desired results because.",
                    "label": 0
                },
                {
                    "sent": "The bottle images you find on Google probably have just the bottle in the center of the image, and that's not what you have in the archive.",
                    "label": 0
                },
                {
                    "sent": "So as long as the quality of the Google images is good enough.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "Query is something visual.",
                    "label": 0
                },
                {
                    "sent": "Then it works quite quite well.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you type something like politics.",
                    "label": 0
                },
                {
                    "sent": "Or an abstract term like Mark.",
                    "label": 0
                },
                {
                    "sent": "It will not work because it needs to be something that you can visually recognize and retrieve.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we applied the same scheme not only for objects but also for faces.",
                    "label": 0
                },
                {
                    "sent": "So as I said in the beginning, people are very much interested in people.",
                    "label": 0
                },
                {
                    "sent": "And so it turns out that actually you can do a very similar thing.",
                    "label": 0
                },
                {
                    "sent": "Four people, so you have your text query where you just type the name of the person you want to find.",
                    "label": 1
                },
                {
                    "sent": "Google images gives you a set of images.",
                    "label": 0
                },
                {
                    "sent": "And so in Google images you can indicate that you want to have images with faces.",
                    "label": 0
                },
                {
                    "sent": "And that helps to get rid of some of the clutter from all these images you detect the face, you extract the facial features and a descriptor of the face.",
                    "label": 0
                },
                {
                    "sent": "You have some negative images of faces, so you can learn a linear classifier.",
                    "label": 1
                },
                {
                    "sent": "And then giving you your archives.",
                    "label": 0
                },
                {
                    "sent": "You can also have the facial features there.",
                    "label": 1
                },
                {
                    "sent": "And so you can just take the vector product to get a ranking and you get results where you see that particular person in the archives.",
                    "label": 0
                },
                {
                    "sent": "And so here supply to Hollywood movies, because then we know like particular actor should occur or not in a particular movie.",
                    "label": 0
                },
                {
                    "sent": "And to get the.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is more accurate.",
                    "label": 0
                },
                {
                    "sent": "We do not extract them from a single keyframe, but we extract up.",
                    "label": 0
                },
                {
                    "sent": "Sorry we extract tracks of faces like this.",
                    "label": 0
                },
                {
                    "sent": "That is because face detection typically works very well when the face is frontal.",
                    "label": 0
                },
                {
                    "sent": "When the person is looking towards the camera, but when the person is looking somewhere else.",
                    "label": 0
                },
                {
                    "sent": "When you have a profile view, then Sir difficult to detect the face and so from a single keyframe it's sometimes very difficult to get an accurate detection, but if you.",
                    "label": 0
                },
                {
                    "sent": "Take multiple frames.",
                    "label": 0
                },
                {
                    "sent": "And the person happens to look inside the camera at some point, then from there you can track the face over longer.",
                    "label": 0
                },
                {
                    "sent": "Time and you can get more information and more accurate.",
                    "label": 0
                },
                {
                    "sent": "Data.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We detect a face.",
                    "label": 0
                },
                {
                    "sent": "We align the face and we crop the information outside the face and then again we have a very similar pipeline in the sense we extract, then SIFT features.",
                    "label": 0
                },
                {
                    "sent": "We use Gaussian mixture models, feature vectors, dimensionality reduction and that gives us a compact face representation.",
                    "label": 0
                },
                {
                    "sent": "So again, it's quite similar except for the first steps.",
                    "label": 0
                },
                {
                    "sent": "How you extract the features and the focus on the faces.",
                    "label": 0
                },
                {
                    "sent": "Also we found that whereas initially.",
                    "label": 0
                },
                {
                    "sent": "We worked with facial landmarks like the corners of the eyes and the nose and so on.",
                    "label": 0
                },
                {
                    "sent": "It turns out that just having a dense sampling also for faces.",
                    "label": 1
                },
                {
                    "sent": "Works much better, and so describing everything is better than only describing these interests.",
                    "label": 0
                },
                {
                    "sent": "Points and actually, if you look at the different publications, you see that a lot of effort in the project went into good feature representations.",
                    "label": 0
                },
                {
                    "sent": "It's very important if you want to have good results and you want to use simple classifiers like just a linear classifier that you have a good feature representation that holds for faces that also holds for objects as well As for for events, and so good and robust representations is really key.",
                    "label": 0
                },
                {
                    "sent": "Domain that we have been working on and making progress on.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so here you see some results.",
                    "label": 0
                },
                {
                    "sent": "If you type George Bush and you search in the same and ISV data set you get this results where again I guess.",
                    "label": 0
                },
                {
                    "sent": "There's a few mistakes, I guess, but most of them are indeed George Bush.",
                    "label": 1
                },
                {
                    "sent": "As you would expect.",
                    "label": 0
                },
                {
                    "sent": "This technique works best for famous people for which you can really find very good results from Google Images.",
                    "label": 0
                },
                {
                    "sent": "If the person is not very famous, it doesn't occur very often in the data set then.",
                    "label": 0
                },
                {
                    "sent": "Alright, it doesn't occur very often on the Internet.",
                    "label": 0
                },
                {
                    "sent": "Then the Google images results may be confusing and also the classifier you learn will be confusing, so it works better in for people that are kind of celebrities for other people, it might be better to use some alternative data, not search on Google, but maybe search on some dedicated websites for information so we didn't investigate that very much.",
                    "label": 0
                },
                {
                    "sent": "But there might be other sources that you can add into the system, like external data that you have available.",
                    "label": 0
                },
                {
                    "sent": "This can be relevant for a particular data source and the nice thing about this is that actually.",
                    "label": 0
                },
                {
                    "sent": "The model we have is very general.",
                    "label": 0
                },
                {
                    "sent": "We never really imposed that.",
                    "label": 0
                },
                {
                    "sent": "All these images should be the same person we just set.",
                    "label": 0
                },
                {
                    "sent": "We want to find.",
                    "label": 0
                },
                {
                    "sent": "We train a classifier that separates.",
                    "label": 0
                },
                {
                    "sent": "This set of images from a set of negative images.",
                    "label": 0
                },
                {
                    "sent": "And that means that we can just as well apply it, not for a specific person, but for a category of persons.",
                    "label": 0
                },
                {
                    "sent": "So, for instance, you can type spectacles.",
                    "label": 0
                },
                {
                    "sent": "And you will find.",
                    "label": 0
                },
                {
                    "sent": "Images in the database of different people, very spectacles.",
                    "label": 0
                },
                {
                    "sent": "You can look for old people.",
                    "label": 0
                },
                {
                    "sent": "People with beards, people with mustaches and so on, so.",
                    "label": 0
                },
                {
                    "sent": "Again, you can just define the query as you want.",
                    "label": 0
                },
                {
                    "sent": "It trains a model.",
                    "label": 0
                },
                {
                    "sent": "It gives you the results.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. Now it turns out that people in practice sometimes try to use this system not just for object categories, but more for specific objects like specific buildings or logos and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "So we said, OK, you can just type any query, but if you type query like Earth, it's a specific highly textured object.",
                    "label": 0
                },
                {
                    "sent": "And instead of using this general technique that trains in general classifier, it turns out that or it's well known within the computer vision literature that for this kind of objects you better rely on feature matching approaches.",
                    "label": 0
                },
                {
                    "sent": "You don't look at just the overall distribution of the features in the image, but you look at individual features and you try to match individual features between pairs of images.",
                    "label": 0
                },
                {
                    "sent": "And then you can also check the geometric configuration between these features and you can see which ones correspond and whether they are consistent with one another.",
                    "label": 1
                },
                {
                    "sent": "That's a framework that's typically used in a query by example setting where you show one example image, and then you ask the system to retrieve from the archive additional images of the same object.",
                    "label": 0
                },
                {
                    "sent": "But you can just as well use the same.",
                    "label": 1
                },
                {
                    "sent": "Idea in an on the fly setting where you retrieve images from Google.",
                    "label": 0
                },
                {
                    "sent": "Then you extract descriptors.",
                    "label": 0
                },
                {
                    "sent": "And then you just match them with the descriptors you have in your database, like using inverted file systems.",
                    "label": 0
                },
                {
                    "sent": "Re rank the top retrieved results and you get results.",
                    "label": 0
                },
                {
                    "sent": "Like this?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the features that you have to use in this setting are somewhat different than what we had in the other applications.",
                    "label": 0
                },
                {
                    "sent": "Downsampling is not a good idea here.",
                    "label": 0
                },
                {
                    "sent": "You want to have.",
                    "label": 0
                },
                {
                    "sent": "Specific features that can be matched accurately and that can cope also with viewpoint changes.",
                    "label": 0
                },
                {
                    "sent": "So you use interest points for in this case, and we used affine invariant interest points so that you can really generalize a lot from a single example image.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you can match between 2 images and find the consistent matches and you can really see if you have a lot of matches, then indeed it's probably the same objects and this is much more reliable than just the score of the classifier for this kind of images.",
                    "label": 0
                },
                {
                    "sent": "Now the difference between applying this in a query by example setting and applying this in on the fly learning setting is that for the online on the fly learning, you don't just have a single example image that you have multiple example images.",
                    "label": 0
                },
                {
                    "sent": "So we extend this idea to multi image.",
                    "label": 0
                },
                {
                    "sent": "Multi query image retrieval.",
                    "label": 0
                },
                {
                    "sent": "Very looked at different ways of combining multiple tray example images and ranks obtained from these multiple.",
                    "label": 0
                },
                {
                    "sent": "Exam.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Images so one way is to just pull the output of the results at the end.",
                    "label": 0
                },
                {
                    "sent": "So you just use one training example.",
                    "label": 0
                },
                {
                    "sent": "Hello at once and then at the end you merge the results.",
                    "label": 0
                },
                {
                    "sent": "Another approach is to have an unsupervised pattern mining step here in between that learns a model.",
                    "label": 1
                },
                {
                    "sent": "From with mid level more informative features at this stage and then retrieves the results and then it turns out that you don't need to do the spatial verification anymore.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again, some examples so you can search for instance for the Golden Gate Bridge.",
                    "label": 1
                },
                {
                    "sent": "And you get this kind of results.",
                    "label": 0
                },
                {
                    "sent": "You can search for particular brands like logos such as Red Bull and that gives you.",
                    "label": 0
                },
                {
                    "sent": "This kind of results.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Eiffel Tower.",
                    "label": 0
                },
                {
                    "sent": "Just do US Army Corps and engineers logo, whatever.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It works quite well and usually it doesn't give the results or less noisy than what you get with the category detection.",
                    "label": 0
                },
                {
                    "sent": "For the locals, there's a restriction.",
                    "label": 0
                },
                {
                    "sent": "That's of course the logos should be sufficiently textured.",
                    "label": 0
                },
                {
                    "sent": "An informative, like typical example is like the night global, which is just this.",
                    "label": 0
                },
                {
                    "sent": "We are shape and if you would try and.",
                    "label": 0
                },
                {
                    "sent": "Retrieve the night logo, then the results would be disappointing because you find this shape anywhere in the trees.",
                    "label": 0
                },
                {
                    "sent": "In the clouds.",
                    "label": 0
                },
                {
                    "sent": "But not necessarily on shoes.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Just recapitulating a bit, we have been talking about this on the fly, learned classifiers which are really a key component in the access systems.",
                    "label": 0
                },
                {
                    "sent": "They allow a user to define.",
                    "label": 0
                },
                {
                    "sent": "Just by himself, what he's interested in, what he wants to search for, and that is really great.",
                    "label": 0
                },
                {
                    "sent": "We get feedback from users that this is really kind of making data much more accessible.",
                    "label": 0
                },
                {
                    "sent": "They can search for whatever they want, especially also for less experienced users who may not be so familiar with these hours.",
                    "label": 0
                },
                {
                    "sent": "Really like this kind of.",
                    "label": 0
                },
                {
                    "sent": "Methods.",
                    "label": 0
                },
                {
                    "sent": "On the other hand.",
                    "label": 0
                },
                {
                    "sent": "Whenever we want to do something on the fly, we always have to make a compromise between.",
                    "label": 0
                },
                {
                    "sent": "Speed on one hand and accuracy on the other hand.",
                    "label": 1
                },
                {
                    "sent": "Like the user is actually waiting while we are.",
                    "label": 0
                },
                {
                    "sent": "Building our model from the images we got from Google images and we don't want to use or to wait too long.",
                    "label": 0
                },
                {
                    "sent": "The user can wait for a couple of seconds, but the user probably doesn't want to wait much longer and so that means that.",
                    "label": 0
                },
                {
                    "sent": "Whenever we train our models.",
                    "label": 0
                },
                {
                    "sent": "We have to give up some of the accuracy.",
                    "label": 0
                },
                {
                    "sent": "In order to gain in speed, so we cannot use as many Google images as we want because the more images we want to retrieve for training our models.",
                    "label": 0
                },
                {
                    "sent": "The longer it will take also the kind of features you extract, the kind of classifiers you use are kind of limited because you have to do the processing on the fly.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "A recent insight that we got was that actually.",
                    "label": 0
                },
                {
                    "sent": "You do not always have to do this again.",
                    "label": 0
                },
                {
                    "sent": "On the fly.",
                    "label": 0
                },
                {
                    "sent": "First of all, you can cash your results whenever a particular person has.",
                    "label": 0
                },
                {
                    "sent": "Post certain query if another person later.",
                    "label": 0
                },
                {
                    "sent": "Types the same words.",
                    "label": 0
                },
                {
                    "sent": "We don't have to do the same thing over again.",
                    "label": 0
                },
                {
                    "sent": "We can just retrieve the results that we cashed.",
                    "label": 0
                },
                {
                    "sent": "And also for common queries queries that occur.",
                    "label": 1
                },
                {
                    "sent": "Quite frequently, instead of just using this model that was trained in a hurry in and off on the fly setting.",
                    "label": 0
                },
                {
                    "sent": "We could train better models offline.",
                    "label": 0
                },
                {
                    "sent": "So where we just take more images?",
                    "label": 0
                },
                {
                    "sent": "Or maybe we add like other sources that are more reliable than just Google images.",
                    "label": 0
                },
                {
                    "sent": "It turns out that some types of users are even willing to put some effort in building these models, and so they are willing to give you relevance feedback to indicate what are the correct or wrong results, and so you can use that relevance feedback to improve your classifiers.",
                    "label": 0
                },
                {
                    "sent": "And then if one user does this then you get a better classifier that can be reused by all the other users.",
                    "label": 0
                },
                {
                    "sent": "So this is something that we are currently investigating more.",
                    "label": 0
                },
                {
                    "sent": "So what we did is in first instance is to just train classifiers for different Imagenet categories.",
                    "label": 0
                },
                {
                    "sent": "I'll show some examples later, and since they have cleaner training data, they will indeed give you better results.",
                    "label": 0
                },
                {
                    "sent": "We are also planning to have pre trained models for.",
                    "label": 0
                },
                {
                    "sent": "A lot of celebrities, people that are.",
                    "label": 0
                },
                {
                    "sent": "Retrieved the query quite often.",
                    "label": 0
                },
                {
                    "sent": "And that will give a much more.",
                    "label": 0
                },
                {
                    "sent": "But much better impression of the retrieval results because the most frequent ones will give you the best results.",
                    "label": 0
                },
                {
                    "sent": "They will be very fast, and so on.",
                    "label": 0
                },
                {
                    "sent": "And in some sense.",
                    "label": 0
                },
                {
                    "sent": "The philosophy here is to go into.",
                    "label": 0
                },
                {
                    "sent": "Lifelong learning or external learning kind of mechanism where the system keeps upgrading and improving its models so.",
                    "label": 0
                },
                {
                    "sent": "You start with a set of initial models, but as people use more queries, you can add more models and more and more of these have been pre trained so can be cashed and less has to be done on the fly.",
                    "label": 0
                },
                {
                    "sent": "The problem there is that to make this happen and to experience to run experiments with this, you actually need to have a lot of users.",
                    "label": 1
                },
                {
                    "sent": "And and it's a you have to set up really a big experiment.",
                    "label": 0
                },
                {
                    "sent": "So at the moment we just have the Imagenet categories and then.",
                    "label": 0
                },
                {
                    "sent": "Probably in the future also.",
                    "label": 0
                },
                {
                    "sent": "And faces and we combine them with the on the fly stuff and by using relevance feedback we can know which ones are good and bad.",
                    "label": 0
                },
                {
                    "sent": "So which ones to use?",
                    "label": 0
                },
                {
                    "sent": "Which ones to ignore?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I'm not sure how I'm doing time wise.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, another thing that we investigated quite a bit is event detection.",
                    "label": 0
                },
                {
                    "sent": "So rather than just looking at keyframes objects since.",
                    "label": 0
                },
                {
                    "sent": "Faces it might also be interesting to find videos of particular events like people shaking hands or a person answering a phone, and this is a recent topic that emerged in computer vision.",
                    "label": 0
                },
                {
                    "sent": "And that especially partner India has been focusing on.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So since this is also part of a track fit task nowadays there's training data for a couple of events available, so you have lots of training videos for a birthday party for operate and stuff like that, and so we can actually again learn pre trained classifiers for these events.",
                    "label": 0
                },
                {
                    "sent": "It's not feasible to rule event detection in an on the fly setting because just retrieving videos from.",
                    "label": 0
                },
                {
                    "sent": "YouTube or whatever.",
                    "label": 0
                },
                {
                    "sent": "Downloading this and extracting features from this would be way too time consuming to have it in on the fly setting where the user is waiting.",
                    "label": 0
                },
                {
                    "sent": "So you really need to have the temporal information for to make these things work.",
                    "label": 0
                },
                {
                    "sent": "That means you need to have the video, and that means that processing times are much.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More expensive.",
                    "label": 0
                },
                {
                    "sent": "Again, a lot of effort went into getting the good representations.",
                    "label": 0
                },
                {
                    "sent": "Good features that capture the essence of a particular event.",
                    "label": 0
                },
                {
                    "sent": "So basically what we do is first some optical flow computation.",
                    "label": 0
                },
                {
                    "sent": "But then we we estimated the global motion.",
                    "label": 0
                },
                {
                    "sent": "And so you can focus on actually the foreground and model only trajectories on the foreground.",
                    "label": 0
                },
                {
                    "sent": "That's the ones here in green, so these are.",
                    "label": 0
                },
                {
                    "sent": "Features individual points on the.",
                    "label": 0
                },
                {
                    "sent": "In a frame that are tracked overtime so they really follow the object, they are not fixed.",
                    "label": 0
                },
                {
                    "sent": "But they follow the object and as such they capture both the motion as well as the appearance of.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in this case the human performing the action.",
                    "label": 0
                },
                {
                    "sent": "So once you have this.",
                    "label": 0
                },
                {
                    "sent": "Trajectory's that belongs to the foreground motion.",
                    "label": 0
                },
                {
                    "sent": "You can again use.",
                    "label": 0
                },
                {
                    "sent": "A descriptor for the whole video that looks at the distribution of these features.",
                    "label": 0
                },
                {
                    "sent": "So Fisher vectors representation or something like that?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And apart from just the only fly search.",
                    "label": 0
                },
                {
                    "sent": "We also have tools for similarity search, so query by example.",
                    "label": 1
                },
                {
                    "sent": "So for scenes and objects, that's just the standard pipeline similar to the.",
                    "label": 0
                },
                {
                    "sent": "Places on the fly system that I mentioned before, but we also have.",
                    "label": 0
                },
                {
                    "sent": "Something for similarity?",
                    "label": 0
                },
                {
                    "sent": "Search for specific four faces.",
                    "label": 0
                },
                {
                    "sent": "So as I showed in the video, the commercial video at the very beginning, we can use a particular image of a face as a query and then retrieved from the database other images of.",
                    "label": 0
                },
                {
                    "sent": "Faces that look very similar to this one.",
                    "label": 0
                },
                {
                    "sent": "And in this setting you really want to find the same person.",
                    "label": 0
                },
                {
                    "sent": "'cause that's what people are mostly interested in.",
                    "label": 0
                },
                {
                    "sent": "So basically what we do is we extract features but.",
                    "label": 0
                },
                {
                    "sent": "We don't just look at the overall distribution as such.",
                    "label": 1
                },
                {
                    "sent": "We learn a metric that captures like what kind of variations are typical.",
                    "label": 0
                },
                {
                    "sent": "Like four different images of the same person and what kind of variations are like, not typical for the same person.",
                    "label": 0
                },
                {
                    "sent": "So that variations due to facial expressions or not as much damaging to the distance measure you use then features that are really characteristic for a particular person.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and so that brings us to the second part.",
                    "label": 0
                },
                {
                    "sent": "I've explained most of the audiovisual content components we have in our systems.",
                    "label": 1
                },
                {
                    "sent": "Based on that we built.",
                    "label": 0
                },
                {
                    "sent": "Two different systems.",
                    "label": 0
                },
                {
                    "sent": "So far, so one which we call Access Pro which focuses on media professionals.",
                    "label": 0
                },
                {
                    "sent": "Which was developed?",
                    "label": 0
                },
                {
                    "sent": "Like the first 2 years of the project and then another One X is research which we developed like just.",
                    "label": 0
                },
                {
                    "sent": "Last year, which focuses on the researchers and so basically they built on the same components.",
                    "label": 0
                },
                {
                    "sent": "On audiovisual content analysis.",
                    "label": 0
                },
                {
                    "sent": "But the tools in access ratio research may be more advanced than the ones we had in access.",
                    "label": 0
                },
                {
                    "sent": "Pro and especially also the interface is very different because as we said, professional users have different needs than researchers and so they may actually want different things in the interface.",
                    "label": 0
                },
                {
                    "sent": "Want to interact with the database in a different?",
                    "label": 0
                },
                {
                    "sent": "Wait?",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What the?",
                    "label": 0
                },
                {
                    "sent": "Access pro system.",
                    "label": 0
                },
                {
                    "sent": "Looks like.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is what the excess risk research system looks like.",
                    "label": 0
                },
                {
                    "sent": "So overall it's still looks.",
                    "label": 0
                },
                {
                    "sent": "Maybe somewhat similar, but let me just say.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stress some of the things we think that are different between.",
                    "label": 0
                },
                {
                    "sent": "Media professionals and researchers like researchers.",
                    "label": 0
                },
                {
                    "sent": "Really, they're not so familiar with the content of the database, so they might actually want to.",
                    "label": 0
                },
                {
                    "sent": "Rely more on browsing and linking just.",
                    "label": 1
                },
                {
                    "sent": "Surfing the and going from one place to another and find what's in the data set.",
                    "label": 1
                },
                {
                    "sent": "Also, researchers may be interested more in tagging and annotation.",
                    "label": 0
                },
                {
                    "sent": "They want to add their own notes their own.",
                    "label": 0
                },
                {
                    "sent": "Comments in on the data set.",
                    "label": 0
                },
                {
                    "sent": "Because they're looking at the data from a particular perspective, and so they want to be able to add nodes and then search in these nodes and so on.",
                    "label": 1
                },
                {
                    "sent": "They might actually be interested more in search trails.",
                    "label": 0
                },
                {
                    "sent": "You don't have just a search query Anna result, But then you refine the results and you continue.",
                    "label": 0
                },
                {
                    "sent": "You want to be able to reproduce the same result later on to go back in time to previous searches and so on.",
                    "label": 0
                },
                {
                    "sent": "They want to be able to export meta data because they want to.",
                    "label": 0
                },
                {
                    "sent": "Run some statistics analysis on it.",
                    "label": 0
                },
                {
                    "sent": "They're probably more interested in customization and personalization, although.",
                    "label": 0
                },
                {
                    "sent": "Some of the professional users also want to have that.",
                    "label": 0
                },
                {
                    "sent": "They're more interested in collaboration, so it's usually it's often a joint effort where different people want to share nodes or you want to select some videos and then send them on to a friend.",
                    "label": 0
                },
                {
                    "sent": "Our colleague researcher so that he can also look into them at his view and so on.",
                    "label": 0
                },
                {
                    "sent": "They are interested in usage statistics, so which are the popular videos?",
                    "label": 0
                },
                {
                    "sent": "Which are the interesting videos and so on?",
                    "label": 0
                },
                {
                    "sent": "And they're more interested in these hours?",
                    "label": 0
                },
                {
                    "sent": "And so this is kind of or some of the.",
                    "label": 0
                },
                {
                    "sent": "Differences that we took into account when developing these systems.",
                    "label": 0
                },
                {
                    "sent": "So instead of just going through my slides on these systems.",
                    "label": 0
                },
                {
                    "sent": "Let me just switch.",
                    "label": 0
                },
                {
                    "sent": "Let's see if I can show a short demo.",
                    "label": 0
                },
                {
                    "sent": "So this is basically the.",
                    "label": 0
                },
                {
                    "sent": "Access pro system.",
                    "label": 0
                },
                {
                    "sent": "And so basically you have here on the left the search.",
                    "label": 0
                },
                {
                    "sent": "Menu where you can do texture text search, visual search similarity search.",
                    "label": 0
                },
                {
                    "sent": "You can apply filters on the meta data.",
                    "label": 0
                },
                {
                    "sent": "You can also specify certain date range.",
                    "label": 0
                },
                {
                    "sent": "So here I show the results on this.",
                    "label": 0
                },
                {
                    "sent": "An ISV Pro data set which is actually 400 hours that are also commonly used for for track fit.",
                    "label": 0
                },
                {
                    "sent": "So it's.",
                    "label": 0
                },
                {
                    "sent": "Just broadcasts material from the Netherlands Institute of Sound and Vision.",
                    "label": 0
                },
                {
                    "sent": "It's Dutch data, so if you do text search then it's best if you type your search queries in Dutch because the metadata is in Dutch.",
                    "label": 0
                },
                {
                    "sent": "Spoken words are also mostly in Dutch, and so the default thing is to just search on metadata and spoken words.",
                    "label": 0
                },
                {
                    "sent": "So if you would just have meta data.",
                    "label": 0
                },
                {
                    "sent": "Then results are.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's what people are most familiar or like.",
                    "label": 0
                },
                {
                    "sent": "The archive is our end user most familiar with.",
                    "label": 0
                },
                {
                    "sent": "But you can actually improve the results by adding also the spoken words, for instance.",
                    "label": 0
                },
                {
                    "sent": "If I type koening Beaudoin, which is like a.",
                    "label": 0
                },
                {
                    "sent": "King of Belgium.",
                    "label": 0
                },
                {
                    "sent": "Just a meta data search doesn't find too many relevant.",
                    "label": 0
                },
                {
                    "sent": "Queries.",
                    "label": 0
                },
                {
                    "sent": "But if I.",
                    "label": 0
                },
                {
                    "sent": "Search for coding Baldwin in the spoken words.",
                    "label": 0
                },
                {
                    "sent": "Then it turns out that there's actually.",
                    "label": 0
                },
                {
                    "sent": "A couple of videos, like this one, this one where you indeed see.",
                    "label": 0
                },
                {
                    "sent": "The King of all King of Belgium in the video material.",
                    "label": 0
                },
                {
                    "sent": "And so for the Dutch archive.",
                    "label": 0
                },
                {
                    "sent": "He was probably not important enough to be explicitly annotated, but for a Belgian user it might be interesting to see also that his present error.",
                    "label": 0
                },
                {
                    "sent": "We can also have different types of views we can look at the results as thumbnails as I show here, which is mostly interested.",
                    "label": 0
                },
                {
                    "sent": "Interesting if you are doing a visible search.",
                    "label": 0
                },
                {
                    "sent": "But we also have compact view where you get some basic information about the length of the video, the title of the video, the date.",
                    "label": 0
                },
                {
                    "sent": "And short description.",
                    "label": 0
                },
                {
                    "sent": "Or you can have a detailed view way of a bit more information.",
                    "label": 0
                },
                {
                    "sent": "For instance, you can also see what based on what this video was retrieved.",
                    "label": 0
                },
                {
                    "sent": "So at this moment we only have the spoken words search active, so it's matched based on speech.",
                    "label": 0
                },
                {
                    "sent": "But you can also have combinations of textual and visual search and then you can see.",
                    "label": 0
                },
                {
                    "sent": "Walter actually caused this video to be retrieved, and it turns out that users really wanted feedback.",
                    "label": 0
                },
                {
                    "sent": "They want to know why do I get this results?",
                    "label": 0
                },
                {
                    "sent": "So you can do a preview, then you get to see.",
                    "label": 0
                },
                {
                    "sent": "The video but you can also look at more detailed information.",
                    "label": 0
                },
                {
                    "sent": "And then you get all the metadata that's available for that program.",
                    "label": 0
                },
                {
                    "sent": "And then, like the spoken words, speech recognition.",
                    "label": 0
                },
                {
                    "sent": "For particular segment that was retrieved here.",
                    "label": 0
                },
                {
                    "sent": "So you could also say OK if I want to find.",
                    "label": 0
                },
                {
                    "sent": "Calling Baldwin in the image.",
                    "label": 0
                },
                {
                    "sent": "Maybe instead of just searching in the text, I can search for him.",
                    "label": 0
                },
                {
                    "sent": "In the visual.",
                    "label": 0
                },
                {
                    "sent": "Search books now we look for.",
                    "label": 0
                },
                {
                    "sent": "Koning beaudoin for face of coding.",
                    "label": 0
                },
                {
                    "sent": "Bowdoin in.",
                    "label": 0
                },
                {
                    "sent": "This database turns out that it doesn't really work too well, but the problem is if you look at the training images.",
                    "label": 0
                },
                {
                    "sent": "There's actually not many coding Baldwins here like this, ones are correct.",
                    "label": 0
                },
                {
                    "sent": "But that's like always the same image.",
                    "label": 0
                },
                {
                    "sent": "This one is correct, but it's like 2 limited to actually.",
                    "label": 0
                },
                {
                    "sent": "Build a good model of that person.",
                    "label": 0
                },
                {
                    "sent": "If, on the other hand.",
                    "label": 0
                },
                {
                    "sent": "I take for instance Vulcan and then.",
                    "label": 0
                },
                {
                    "sent": "Which was the.",
                    "label": 0
                },
                {
                    "sent": "Prime Minister of the Netherlands at a time when this.",
                    "label": 0
                },
                {
                    "sent": "The other set was collected.",
                    "label": 0
                },
                {
                    "sent": "These are the training images that we collect from Google images.",
                    "label": 0
                },
                {
                    "sent": "Again, they're not for perfect.",
                    "label": 0
                },
                {
                    "sent": "The 1st two are wrong, but these here are all correct.",
                    "label": 0
                },
                {
                    "sent": "And based on that.",
                    "label": 0
                },
                {
                    "sent": "These are the images we retrieve and indeed you see that.",
                    "label": 0
                },
                {
                    "sent": "They are all showing the prime.",
                    "label": 0
                },
                {
                    "sent": "The ex Prime Minister of the Netherlands.",
                    "label": 0
                },
                {
                    "sent": "And for some users, it's actually if you really want to find particular fragments.",
                    "label": 0
                },
                {
                    "sent": "This is much more interesting to search for balcony like this and you can see where you have nice view of him or in the nice setting.",
                    "label": 0
                },
                {
                    "sent": "Then when you just search for.",
                    "label": 0
                },
                {
                    "sent": "The same person.",
                    "label": 0
                },
                {
                    "sent": "In the metadata.",
                    "label": 0
                },
                {
                    "sent": "Or spoken words.",
                    "label": 0
                },
                {
                    "sent": "Then you get much more noisy data.",
                    "label": 0
                },
                {
                    "sent": "Sometimes there is spoken and like I guess here it's a group photo is part of it.",
                    "label": 0
                },
                {
                    "sent": "Here's present.",
                    "label": 0
                },
                {
                    "sent": "But then you also have a lot of other.",
                    "label": 0
                },
                {
                    "sent": "Material where maybe it's about Vulcan and or or someone taking an interview of Vulcan and but it may not be the actual.",
                    "label": 0
                },
                {
                    "sent": "They may not be feasible.",
                    "label": 0
                },
                {
                    "sent": "And so if you want to reduce if you want to.",
                    "label": 0
                },
                {
                    "sent": "Actively use this data, then it might be more interesting to be able to do the visual search.",
                    "label": 0
                },
                {
                    "sent": "We also have this similarity search.",
                    "label": 0
                },
                {
                    "sent": "For instance, if it's OK, who is this person and I want to see if there's more.",
                    "label": 0
                },
                {
                    "sent": "Examples of this person in the database you can drag it to the similarity search and you find.",
                    "label": 0
                },
                {
                    "sent": "Examples of this particular person.",
                    "label": 0
                },
                {
                    "sent": "And of course we can also do the category search.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let me just show the results for the first.",
                    "label": 0
                },
                {
                    "sent": "Again, maybe now it's clear.",
                    "label": 0
                },
                {
                    "sent": "So you can see lots of forests, but you can also use it for other categories.",
                    "label": 0
                },
                {
                    "sent": "Like if I see.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Thinking of a good example.",
                    "label": 0
                },
                {
                    "sent": "With this let's just say car.",
                    "label": 0
                },
                {
                    "sent": "Not sure whether it's.",
                    "label": 0
                },
                {
                    "sent": "Working too well on these datasets, but.",
                    "label": 0
                },
                {
                    "sent": "So you see, here he has to retrieve because he didn't have it online and so we have to wait a moment.",
                    "label": 0
                },
                {
                    "sent": "Because during that time he goes back to Google images, retrieves images there, computes the model applied, applies it to the database.",
                    "label": 0
                },
                {
                    "sent": "It's not instantaneous, but it's just a few seconds, so that's not really a problem.",
                    "label": 0
                },
                {
                    "sent": "It's fast enough, and for most users it's acceptable, and you see that the results look again quite good.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Let's switch to the research system.",
                    "label": 0
                },
                {
                    "sent": "The research system as we said this is a bit more.",
                    "label": 0
                },
                {
                    "sent": "Complex like here, you just had the basic search tools and that sits in the research system, gets first overview of recently viewed videos, your own research, recent queries so you can look back at what you searched before.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing is also that like you can click on a link here.",
                    "label": 0
                },
                {
                    "sent": "So you can just go to a previous query again.",
                    "label": 0
                },
                {
                    "sent": "And you get the results that you retrieved earlier, and so you have here an unique identifier of that particular search, so you can send.",
                    "label": 0
                },
                {
                    "sent": "That's identifier to your colleague.",
                    "label": 0
                },
                {
                    "sent": "He can also find the same information.",
                    "label": 0
                },
                {
                    "sent": "You can just go back and forth through your search results.",
                    "label": 0
                },
                {
                    "sent": "You can look at popular videos.",
                    "label": 0
                },
                {
                    "sent": "You can have your own collection of videos.",
                    "label": 0
                },
                {
                    "sent": "There's lots of things you can do.",
                    "label": 0
                },
                {
                    "sent": "The search tool itself is much simpler, so it's just here on top single.",
                    "label": 0
                },
                {
                    "sent": "Query box, but you can specify again whether you want to have a text search or visible search for these different type of components.",
                    "label": 0
                },
                {
                    "sent": "And Additionally, we also have this automatic search.",
                    "label": 0
                },
                {
                    "sent": "Which is still under development like.",
                    "label": 0
                },
                {
                    "sent": "Where we automatically try to figure out whether what you're searching for, whether your query is a person, and then maybe you're more interested in two interfaces, or whether it's.",
                    "label": 0
                },
                {
                    "sent": "An object and then you want to search based on categories or whether it's a place and so it tries to automatically find the relevant.",
                    "label": 0
                },
                {
                    "sent": "Per component to apply to your search you can also do the similarity search.",
                    "label": 0
                },
                {
                    "sent": "Using this we have advanced search where you can combine multiple queries.",
                    "label": 0
                },
                {
                    "sent": "And so this is this demo here runs on data from Deutsche Welle, so it's in German.",
                    "label": 0
                },
                {
                    "sent": "And it's only 40 hours actually.",
                    "label": 0
                },
                {
                    "sent": "Most of our experiments recently we did on bigger datasets from an ISV which was almost 4000 hours of data, which is roughly half a year of continuous video broadcasting.",
                    "label": 0
                },
                {
                    "sent": "But there's IPR issues with that data, and so we cannot show it and.",
                    "label": 0
                },
                {
                    "sent": "Public audiences so you can search here.",
                    "label": 0
                },
                {
                    "sent": "Like for instance bundle tool is a specific place.",
                    "label": 0
                },
                {
                    "sent": "You can search for the results.",
                    "label": 0
                },
                {
                    "sent": "You get.",
                    "label": 0
                },
                {
                    "sent": "Different examples.",
                    "label": 0
                },
                {
                    "sent": "Of that particular building.",
                    "label": 0
                },
                {
                    "sent": "So you can add it to your collection.",
                    "label": 0
                },
                {
                    "sent": "You can do a similarity search.",
                    "label": 0
                },
                {
                    "sent": "You can also just get more detailed information about the.",
                    "label": 0
                },
                {
                    "sent": "Video.",
                    "label": 0
                },
                {
                    "sent": "Will that or understand my schedule?",
                    "label": 0
                },
                {
                    "sent": "I'll just put off the audio and here you have more program information.",
                    "label": 0
                },
                {
                    "sent": "For instance, researchers also want to have the possibility that you display all the keyframes belonging to the video that you have a virtual cutter so you can select the fragment that you're mostly interested in, instead of having the whole video, you can download the meta data.",
                    "label": 0
                },
                {
                    "sent": "You can add it to collection.",
                    "label": 0
                },
                {
                    "sent": "You can download the transcripts or subtitles.",
                    "label": 0
                },
                {
                    "sent": "You can add.",
                    "label": 0
                },
                {
                    "sent": "You can add your own nodes, two particular video and then for the browsing and linking we also have here like a possibility to look at related videos or related segments.",
                    "label": 0
                },
                {
                    "sent": "Which at the moment or purely based on the metadata information.",
                    "label": 0
                },
                {
                    "sent": "So that you can kind of browse and find other information that seems relevant.",
                    "label": 0
                },
                {
                    "sent": "One more thing I wanted to show here is the difference between the on the fly search and the pre trained classifiers.",
                    "label": 0
                },
                {
                    "sent": "So at this moment since the data is in German and the user testings were done by.",
                    "label": 0
                },
                {
                    "sent": "Journalists at Deutsche Welle.",
                    "label": 0
                },
                {
                    "sent": "Who are German?",
                    "label": 0
                },
                {
                    "sent": "We translated the.",
                    "label": 0
                },
                {
                    "sent": "Pre trained classifiers based on image net to German and that means that if you type a word in English.",
                    "label": 0
                },
                {
                    "sent": "You will get.",
                    "label": 0
                },
                {
                    "sent": "Like on the fly train results.",
                    "label": 0
                },
                {
                    "sent": "You type it in German then it will use a pre trained classifier and so for instance if I type balloon and I search for category.",
                    "label": 0
                },
                {
                    "sent": "He goes.",
                    "label": 0
                },
                {
                    "sent": "To Google images retrieves images there.",
                    "label": 0
                },
                {
                    "sent": "Extracts features for, then trains the model, then applies model to the archive.",
                    "label": 0
                },
                {
                    "sent": "And you get this kind of result.",
                    "label": 0
                },
                {
                    "sent": "So there's a couple of balloons here, but there's also other things that it gets confused with.",
                    "label": 0
                },
                {
                    "sent": "If, on the other hand, we type balloon.",
                    "label": 0
                },
                {
                    "sent": "Which is the German equivalent and then it goes much faster because it takes a pre trained classifier and you see that the results also look much better.",
                    "label": 0
                },
                {
                    "sent": "There's still confusion with this virtual a logo, but you really retrieve quite a few of these.",
                    "label": 0
                },
                {
                    "sent": "Balloons in the data sets.",
                    "label": 0
                },
                {
                    "sent": "Same thing for instance, if you type Zeitung, which is newspaper.",
                    "label": 0
                },
                {
                    "sent": "You get different.",
                    "label": 0
                },
                {
                    "sent": "Newspapers and things that look similar and we notice that the pre trained classifiers if they are wrong.",
                    "label": 0
                },
                {
                    "sent": "Often they're more like reasonable mistakes.",
                    "label": 0
                },
                {
                    "sent": "They are things that maybe are not.",
                    "label": 0
                },
                {
                    "sent": "Newspapers in this case, but at least things that look somewhat similar that people can understand that the system makes this mistake, and that's usually also something that people like.",
                    "label": 0
                },
                {
                    "sent": "So yeah, so you can have.",
                    "label": 0
                },
                {
                    "sent": "We also have the possibility here to either show the results at the level of individual segments or individual programs.",
                    "label": 0
                },
                {
                    "sent": "You can sort them based on the date when they were published.",
                    "label": 0
                },
                {
                    "sent": "The length of the video.",
                    "label": 0
                },
                {
                    "sent": "You can see how relevant they are, how often they refute, how often they were liked.",
                    "label": 0
                },
                {
                    "sent": "You can also filter the results based on metadata.",
                    "label": 0
                },
                {
                    "sent": "There's some some keywords and named entities that kind of retrieved from the metadata.",
                    "label": 0
                },
                {
                    "sent": "If you search for something he tries to.",
                    "label": 0
                },
                {
                    "sent": "Find the relevant thing and then you can apply filters and get better results.",
                    "label": 0
                },
                {
                    "sent": "So you could also combine different searches in by adding filters.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you want you can just contact me after the talk and you can try out a system yourself.",
                    "label": 0
                },
                {
                    "sent": "Maybe more convincing than just me showing a few examples, but it actually works quite well.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "OK, So what time is it?",
                    "label": 0
                },
                {
                    "sent": "I have to start work to wrap up.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very quickly, so this thing was evaluated at track fit, so we used a very similar.",
                    "label": 0
                },
                {
                    "sent": "Interface for the instance search.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We actually did on average in terms of mean average precision, but in terms of precision, we were better.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here you see the results where the blue ones are the axis.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wells",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The reason why we didn't do so well in.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Terms of recall is probably because our users didn't spend as much time like they got 15 minutes, but they on average used only half of their time and then they stopped.",
                    "label": 0
                },
                {
                    "sent": "So they could probably have found additional results.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also took part in the media Event detection task with this multimedia event detection system.",
                    "label": 0
                },
                {
                    "sent": "Are equal to best results.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also did something for multimedia event recounting where we try to explain why certain results was retrieved where you see timelines and you can see whether it's based on the audio or based on the visual content.",
                    "label": 0
                },
                {
                    "sent": "What are the relevant fragments in the video that actually are relevant for particular event, category and so?",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See then.",
                    "label": 0
                },
                {
                    "sent": "Quickly.",
                    "label": 0
                },
                {
                    "sent": "A few words on like what if we learned or just a few general comments that I thought would be interesting to share first?",
                    "label": 0
                },
                {
                    "sent": "This idea of on the fly learning of models seems really to be a very powerful paradigm, and so I really would.",
                    "label": 0
                },
                {
                    "sent": "Suggest everyone.",
                    "label": 0
                },
                {
                    "sent": "Two to go in that direction or use it because it can really do a lot more than what you have with pre trained classifiers and so it really goes in the direction of lifelong learning and the system gets better and better overtime and that's really what's what you want.",
                    "label": 0
                },
                {
                    "sent": "We also noticed that.",
                    "label": 0
                },
                {
                    "sent": "Data is important.",
                    "label": 0
                },
                {
                    "sent": "The more data the better.",
                    "label": 1
                },
                {
                    "sent": "So we compared systems with different amounts of data.",
                    "label": 0
                },
                {
                    "sent": "And actually, the bigger the data sets you're applying your method to, the better the results get the more convinced your users will be because.",
                    "label": 0
                },
                {
                    "sent": "If you have a very small data set.",
                    "label": 0
                },
                {
                    "sent": "You, there's only limited content available there, and there's a very good chance that something that person is searching for is just not present in the data sets.",
                    "label": 0
                },
                {
                    "sent": "And then you just get.",
                    "label": 0
                },
                {
                    "sent": "And the related results returns because we return the top ranked ones.",
                    "label": 0
                },
                {
                    "sent": "But if the object is not there in the archive, then there's no way we can retrieve it.",
                    "label": 0
                },
                {
                    "sent": "The bigger you make your data set.",
                    "label": 0
                },
                {
                    "sent": "So going from $500 to 1002 thousand 3004 thousand, we see that gradually the top results really get much much better because.",
                    "label": 0
                },
                {
                    "sent": "There's more.",
                    "label": 0
                },
                {
                    "sent": "Option instances that are in the data set.",
                    "label": 0
                },
                {
                    "sent": "There's a better chance that once you retrieve data to prove we really correct.",
                    "label": 0
                },
                {
                    "sent": "When we did this experiment with 4000 hours of data, we notice that even for very weird queries you still get.",
                    "label": 0
                },
                {
                    "sent": "Results out of the data set you can just.",
                    "label": 0
                },
                {
                    "sent": "Use some of these image net classifiers where you think well this is like this has no chance, but let's just see what it gives you.",
                    "label": 0
                },
                {
                    "sent": "Try snow scooter and there you go you find.",
                    "label": 0
                },
                {
                    "sent": "A couple of snow scooters in your archive you type cargoship.",
                    "label": 0
                },
                {
                    "sent": "You type whatever you want.",
                    "label": 0
                },
                {
                    "sent": "The most weird things.",
                    "label": 0
                },
                {
                    "sent": "Can you find them and people are really surprised.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, you found it.",
                    "label": 0
                },
                {
                    "sent": "So it really becomes very important to have a lot of data.",
                    "label": 0
                },
                {
                    "sent": "And people like the system or if it's applied on a larger data set, it takes effort, but it's worth it.",
                    "label": 0
                },
                {
                    "sent": "We also found that it's quite important to educate your users.",
                    "label": 1
                },
                {
                    "sent": "Especially archivists are used to work with very clean data.",
                    "label": 0
                },
                {
                    "sent": "They work with data that is provided by.",
                    "label": 0
                },
                {
                    "sent": "Like archivists, that is always correct.",
                    "label": 0
                },
                {
                    "sent": "That's very reliable.",
                    "label": 0
                },
                {
                    "sent": "And now we propose them a system that can retrieve other information, but that's inherently noisy.",
                    "label": 0
                },
                {
                    "sent": "You find sometimes the correct object, but sometimes there's also results retrieved that are incorrect.",
                    "label": 0
                },
                {
                    "sent": "And at first it's very difficult for them to really understand this and to cope with this because they say, well, I don't trust this system.",
                    "label": 0
                },
                {
                    "sent": "I don't want to use it because I don't trust it.",
                    "label": 0
                },
                {
                    "sent": "Worse.",
                    "label": 0
                },
                {
                    "sent": "If you understand what is going on, you can say, well, OK, I still have to verify whether it's correct, but at least I can find things that I couldn't find before.",
                    "label": 0
                },
                {
                    "sent": "So that's important that you really show them and explain them what's what's going on.",
                    "label": 0
                },
                {
                    "sent": "They also want to vary.",
                    "label": 0
                },
                {
                    "sent": "To understand why you get a certain result which is not always possible to explain, you just train a classifier and.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's overfitting, sometimes it's.",
                    "label": 0
                },
                {
                    "sent": "Like the negative data are not representative enough.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of things that can go wrong, but you cannot explain all this to the end users.",
                    "label": 0
                },
                {
                    "sent": "Also a good user interface is important.",
                    "label": 1
                },
                {
                    "sent": "The first feedback you get when you show a system to the user is just about the user interface, like only this button should be there and why don't you have this and we should have.",
                    "label": 0
                },
                {
                    "sent": "It's important that you showed the system with a good user interface and you put a lot of effort in having the interface done well.",
                    "label": 0
                },
                {
                    "sent": "And finally, I guess.",
                    "label": 0
                },
                {
                    "sent": "There's still a lot of room for improvement in terms of multimodal and spatial temporal processing.",
                    "label": 0
                },
                {
                    "sent": "Initially when we started Project I thought OK for Access Pro we will start with keyframe based analysis but afterwards we will go beyond.",
                    "label": 0
                },
                {
                    "sent": "Analysis of keyframes will really analyze the full videos because there's much more content individuals and individual keyframes.",
                    "label": 0
                },
                {
                    "sent": "But in practice, it turns out that the computational efforts that you have if you want to process video or so much.",
                    "label": 0
                },
                {
                    "sent": "Bigger than what you have if you just process individual keyframes then it's at this moment not really worth it.",
                    "label": 0
                },
                {
                    "sent": "For instance, event detection uses video.",
                    "label": 0
                },
                {
                    "sent": "There you cannot do without for the faces.",
                    "label": 0
                },
                {
                    "sent": "We also use it, but it really means that the face tracking now.",
                    "label": 0
                },
                {
                    "sent": "Takes a lot of resources and takes a lot of time.",
                    "label": 0
                },
                {
                    "sent": "If you want to do the indexing.",
                    "label": 0
                },
                {
                    "sent": "And worse.",
                    "label": 0
                },
                {
                    "sent": "In an ideal setting, you think well, we want to do everything spatial, temporal, not only analyze the keyframes because then you lose a lot of information in between.",
                    "label": 0
                },
                {
                    "sent": "In practice, it's not so easy to actually do that, and the same holds for the multimodal aspects.",
                    "label": 0
                },
                {
                    "sent": "We thought initially well, we want to not just have audio on one side.",
                    "label": 0
                },
                {
                    "sent": "Video on the other, you want to combine them and combine them, not just at the last stage when you combine different queries, But you want to combine them early on, because all you can provide context for object recognition in video and vice versa.",
                    "label": 0
                },
                {
                    "sent": "Also, for people like.",
                    "label": 0
                },
                {
                    "sent": "The speaker identification and face recognition can help each other, and so on, and we're working on these things, but it's.",
                    "label": 0
                },
                {
                    "sent": "Not so easy to really apply it throughout the entire pipeline, and for all the different components we use multimodal aspects for the event detection.",
                    "label": 0
                },
                {
                    "sent": "We are working on combination of speaker identification, face recognition.",
                    "label": 0
                },
                {
                    "sent": "But it's not as easy as you would think at 1st, and so there's still a lot of things that can be done in that respect.",
                    "label": 0
                },
                {
                    "sent": "OK, and I guess that was about my last slide.",
                    "label": 0
                },
                {
                    "sent": "I still had a few slides on the excess home system that we're starting to look into, but I guess I'm running out of time for that one.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "So I'll finish with this one.",
                    "label": 0
                },
                {
                    "sent": "Do you have any questions?",
                    "label": 0
                }
            ]
        }
    }
}