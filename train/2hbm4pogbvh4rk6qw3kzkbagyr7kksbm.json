{
    "id": "2hbm4pogbvh4rk6qw3kzkbagyr7kksbm",
    "title": "Using linguistic information as features for text categorization",
    "info": {
        "author": [
            "Arturo Montejo R\u00e1ez, University of Ja\u00e9n"
        ],
        "published": "Nov. 26, 2007",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Text Mining",
            "Top->Computer Science->Computational Linguistics"
        ]
    },
    "url": "http://videolectures.net/mmdss07_raez_uli/",
    "segmentation": [
        [
            "Today the last talk we are all.",
            "Target I can read that on your faces.",
            "So I will pass quickly on the matter that already Mark.",
            "Underlining, so I think that I can make this presentation shorter.",
            "My worker.",
            "Is million text categorization and I'm present here some results that are not impressive from the point of view of what we are using, but for from what we can really deduce from from our results.",
            "So I will start my presentation first answering questions.",
            "So the 1st."
        ],
        [
            "Where is high?"
        ],
        [
            "Everybody ask about about that, so I will just go briefly on that and use this opportunity to promote my province.",
            "We are in this all this pain and delphia.",
            "We have very nice landscapes.",
            "Of course we have thousands and thousands and millions of olive trees.",
            "And so the olive oil is good strong.",
            "Anne's plenty of castles and renaissance moments, so it's a very nice place to visit."
        ],
        [
            "You already know.",
            "OK, and now I'm going to stop here again.",
            "We are still on the on the on the front page.",
            "It's about my my group.",
            "We mainly do natural language processing.",
            "We are not machine learning experts.",
            "OK, so we apply those algorithms to our problems.",
            "We do text simulation, text mining in general, multilingual information retrieval, multimodal information retrieval.",
            "That means to retrieve information, no matter the format of the sous video photo text, but our concern mainly on using text to improve those multimodal systems.",
            "We worked on some question and answering.",
            "We have started the.",
            "One year ago, some work on dialogue systems and also we are working on text one in Tainment.",
            "If any of you is interested on any of this matter, he can approach me.",
            "OK, so this is the group I'm talking about.",
            "You can find more information in this URL about papers project."
        ],
        [
            "Topics reach topics, etc.",
            "OK, so.",
            "What I'm going to to explain here is the there is something wrong here.",
            "I lost the the transparency.",
            "OK. And I'm going to 1st make an introduction to classification problems, but we already have it before, so I will go faster on that.",
            "Or should we provide some examples of?",
            "Running a.",
            "Text classification systems real data.",
            "And why they are interesting with some of the applications?",
            "Because the cases are so high that I will just mention some of them.",
            "And I will focus on any specific multi label text classification problem.",
            "That is the one that we have to face in the other side of the Alps.",
            "I will give more details later.",
            "And we will then describe this architecture.",
            "This general detector that is more or less a consensus now in for creating a text characterization system.",
            "So you can use it as a receipt.",
            "To create a.",
            "Acceleration system able to face a big amounts of data.",
            "I will underline the problem of imbalance of data which we are facing all the time in this paradigm.",
            "And of course, how we tune the system for for that corpus OK, and you will say yes, but where is the talk about linguistic features?"
        ],
        [
            "Oh, that's the tricky thing.",
            "Yeah.",
            "OK, I will talk about using this linguistic information as feature is on is smaller brief experiment.",
            "We perform it on.",
            "We were supposed to get to obtain certain research according to the literature, and was repressing for us.",
            "Some of the results that we will discuss later.",
            "I will explain the back of the words and how can we integrate.",
            "And linguistic information in the vector space model.",
            "Straightforward way.",
            "Um, at that point I would like to make a reflection.",
            "Why using high level information?",
            "OK. OK, Ann.",
            "And then I will work.",
            "Sorry I will.",
            "I will pass over some past work done on the on the use of linguistic information as feature for text categorization.",
            "And then I will explain that experience that we cut it out on, which were the results, which I think that will take most of the final part of the presentation.",
            "Also compression some features."
        ],
        [
            "OK. You already know that we can.",
            "We can classify text classification problems in three main paradigms.",
            "The binary classifier, either we, we, we have a document and we want to either address or no answer to know if it belongs or not to accept in class, or if it belong to two different class that are mutually exclusive.",
            "We can also work in a multi class.",
            "We can also have a multiclass problem where we want to assign one label to a document among a given set of candidates.",
            "And we can also work on our multi label classifier, which is the most complex one.",
            "OK, and there is an interesting article about reducing all these problems to just live in other case which is quite intuitive.",
            "But here they explain it in a more formal way.",
            "OK, so this is just to give some notation, but."
        ],
        [
            "I think you already know about it.",
            "Examples being added case.",
            "If this email is spam or is not a spam, or as we so before.",
            "If this web page is maintained by terrorists or not OK, that will be a banner abinadi case and the advantage of with the case that the valuation.",
            "Doesn't have to travel with many possibilities about how do I operate and how?",
            "How do I evaluate and we will."
        ],
        [
            "We will see that later.",
            "This would be an example of a multi class classification problem where we have a paper or PDF paper or research paper and we want to label it within one and only one of the recent categories OK."
        ],
        [
            "And this is.",
            "And this is a real example of classification of.",
            "App Meta data extracted from from a database of high energy physics papers.",
            "This meta data contains, among other information, an abstract, and that's after this plaintext.",
            "So we can use that, and this will be the labels that were assigned by expert to that to that document.",
            "Below you have an example of vaccination made by by the system we built."
        ],
        [
            "OK, so.",
            "Which is their history of text classification systems?",
            "L in the in the in the.",
            "In the literature we can find dysbiosis system.",
            "In 1987 an they.",
            "The information about it is not very detailed.",
            "It's very well explaining how to to the to do the infer to know if a label belongs or not to the to the document, but mainly they take words from the title and works from the content.",
            "And they try to make a match at that match with a lot of realistic.",
            "So I mean, it was a really hard job.",
            "I mean they they they they they link it mostly manually all this and they got 61% recall but there is no other information about the evaluation of the system."
        ],
        [
            "One year later.",
            "We we know about this surface system.",
            "When was the first text classification system for automatic text classification system for physics?",
            "Anne.",
            "It was in production and it's performing also text mentation from the from the corpus of.",
            "Sorry for that from the content of the paper.",
            "And then using some probabilistic computation.",
            "Also very very complex, because formulas were adjusted manually in order to make the system work as better as possible, they were able to reach 75% precision and 68% of recall."
        ],
        [
            "Which is not very much, but it was a hard task.",
            "In 1994, we have one that is more in.",
            "Close, I mean it's closer to what we used to have today.",
            "Secure base it, but it had a knowledge base of 170,000 words and phrases and they were also manually introduces all these rules.",
            "OK, it was oriented not to reproduce automatically.",
            "Keyboards back to help indexers to find where which could be the keyword that were interesting for a certain publication OK. Hey Richard, 50% both in position and recall, which is not very much but we are talking about a multi level categorization problem with thousands of."
        ],
        [
            "Of possible categories.",
            "Here, I think that even this this this measurements are now incorrect because I think that this information is dates from seven years ago.",
            "OK so in DRC they are experts on in with the label text categorization 2.",
            "With the Euroblock multilingual so loose that is in more than 20 languages with more than 6000 classes and they use machine learning methods.",
            "And they they degree of multi ability of the of the documents are 5.6 classes per document.",
            "Another age.",
            "OK, we have something like from something like 12 classes in average in high energy."
        ],
        [
            "Physics.",
            "Finally we have this non index system which was for for medical."
        ],
        [
            "Labani OK.",
            "But what we can see is that we have pass it from.",
            "In this system, from touristical approaches hard coded stuff to more flexible solution.",
            "Thanks for the use of machine learning algorithm."
        ],
        [
            "OK.",
            "So why is people involving a time on working on text categorization systems?",
            "Why?",
            "It's interesting to work for for this.",
            "There are plenty of of application of this automatic automatically generated labels and we can group this application into two different categories.",
            "Not always categorizing direct manipulation.",
            "When the when the when the user of the system wants to manipulate directly the keyboards or also an automatic manipulation when we want a machine, another program, another algorithm to you to make profit from those outputs.",
            "OK, as lighting manipulation we can consider the set of keywords in a multi label rolling as such kind of summary of the content.",
            "So imagine after you are looking for a higher physics paper in a database and you get the title, but then you can get the keyboards.",
            "So in the same way we have these snippets for Google results, we can consider that we could consider those keyboards too.",
            "Get a better idea about the content of the paper without opening it and reading it, OK?",
            "Also for navigation I can use that from two young from one group of documents to another group of documents depending on the on the labels they share.",
            "For for classification, for query expansion we can apply this this keyboard to query Son and classify queries and provide this keyboard additional information in the query.",
            "We can perform cross lingual received because I can I can select a keyboard and then I can introduce that.",
            "Sorry I can introduce that label in a search engine and if that label is a real labeling the service in the controller vocabulary and this service is multilingual then I can recover the retrieve documents in different languages.",
            "I can do a concept worksheet that is similar to the navigation and of course I can also do a guided seat so I can get results.",
            "Maybe I can narrow my search to certain topics.",
            "I would automated manipulation of of keywords.",
            "I can see it by by subject feel.",
            "OK so I will just select a subject field back inside that field.",
            "There is certain keywords within I don't know.",
            "I don't see them, but the system will use it to get on to get more recall in the result.",
            "Also, we can perform we're dealing with document similarity, but I think it has been already explained using those keywords.",
            "OK as an extra space so it can be used as a Nexus between documents in different languages.",
            "Thanks to Doctor Multilinguality of the of the vessels.",
            "I can do also multilingual clustering based on that that the hours.",
            "But I could also populate the semantic web.",
            "If I know that certain web pages are talking about certain topics and I have a good classifier for them, I could add more information today to the semantic information of those pages and relate them so I can.",
            "I could eventually use that information to provide certain content to the semantic web in an automatic way.",
            "Also, I can populate the semantic grid.",
            "I don't know if you are familiar with this concept.",
            "Is the Web is a kind of distributed file system?",
            "The grid is a kind of distributed operating system using the whole power of the Internet.",
            "So the idea is that I can we can also.",
            "Find services that are already categorized ready to certain labels to set the controller labels.",
            "I don't know.",
            "I know that there is a service in one server to query about forecasting.",
            "Another is another service in one server to query about latest news in sports.",
            "OK and I could use that even to generate those labels and create the kind of network so I can relate different services.",
            "Also, we can use it for a recommendation systems.",
            "We don't see the keywords but we are asking for a book and we know that the book is ready to certain topics.",
            "So then I can propose more books about those topics.",
            "Of course we have seen we can generate the graphs."
        ],
        [
            "OK, this is a view of.",
            "The construction of one of the.",
            "Detectors that we find in the in the in the other side of the apps close to Geneva in Switzerland.",
            "Is held in Geneva.",
            "I'm sorry catching Sanofi in France an they have the big the biggest machine in the world so far is really amazing there.",
            "There are thousands and thousands of physicists working there and producing scientific publications.",
            "Scientifiques report cyantific information.",
            "OK, but not only that.",
            "Also serve is the laboratory for particle physics.",
            "Is collecting papers about particle physics so.",
            "Not only that, is a source of production, but is also one of the main story straight for this information.",
            "So far I'm so far few years ago they were some expressing in German level authority in DC.",
            "Who got the task of reading scientific papers?",
            "Day by day and select some keywords from from a predefined controlled vocabulary that basically shows OK.",
            "So you needed very skill people because they they must be experts on.",
            "On the matter means to really know, uh, what is this paper talking about?",
            "But they also must be expert in leavening because they have to know very well.",
            "This is solos.",
            "OK, so.",
            "The you need very qualified people for a very not very interesting task which is read and read and read and Silicon label OK.",
            "So that could be one of the reasons to to work for an automatic categorization system.",
            "Something like they did in NASA for adding from her helping indexers to make the task more easy."
        ],
        [
            "Easier, but I found a different reasons for really work on it.",
            "There was this.",
            "This is the office that was right close to the mine one.",
            "So then I decided that I had to do text classification because otherwise those people will die.",
            "I mean under the weight of tons of papers I mean.",
            "So."
        ],
        [
            "So that's really that's really an important reason, but OK, this is the real reason why this project was starting insert.",
            "We can see here the the number of documents that are arriving.",
            "Per week OK this they have been generally average, so every week we compute the number of documents and we have reached for the whole year.",
            "So from from the 80s to 2003 we can see that is an exponential growth very clear.",
            "I can imagine that 20 years ago.",
            "To have a group of four 5 experts to read the 100 papers.",
            "Distribute them, maybe you can have a 20 papers and you read it during the week.",
            "So then you can label them OK.",
            "But when you have a now is more almost 1000 papers per week.",
            "It's really expensive to do this.",
            "Do it in that."
        ],
        [
            "Waso that's why.",
            "Multilabel classification matters OK.",
            "So we prepared the corpus.",
            "We think different partitions because we expected to have a different classifiers depending on the on the subject that was covered by the papers.",
            "So we have one for theoretical high energy physics, one for experimental high energy physics and one for astrophysics OK.",
            "These are the sizes of these different splits.",
            "This different subcollections.",
            "The interesting thing is that we have their full text information.",
            "We have the content of the full paper.",
            "OK has been instructed from the PDF, but also we have meta data information.",
            "This this collection was generated by the original selection done by by James Vegan from the Library of CERN and this corpus is distill it.",
            "Great to use for you.",
            "You can download it from that URL.",
            "Is freely available."
        ],
        [
            "OK, so this corpus, having generated from the real PDF documents that researchers submit through their database and convert it using the tool, is called PDF to text and then forget because there are plenty of garbage within the database.",
            "Not all the documents are well stored there.",
            "OK, so there were some corruption and on some of the documents had to be a racist.",
            "So we cleaned the collection, but that's the interesting thing is that we have.",
            "Full text, I mean the real content of the document."
        ],
        [
            "And also we have they made their data that this did they record but worse in the database this record is following an XML format and is following the Open Architecture Initiative standard which is more or less related to the Dublin core meta data set.",
            "OK, so we have information about the author.",
            "We have information about the language it is threatening.",
            "We have the abstract here.",
            "The subject which is a predefined the category for the document.",
            "And we have the title separated the date of publication so.",
            "I believe that we can do plenty of things with the collection.",
            "OK, because we could just using the authors we can do text categorization if we work on on graphs for example.",
            "OK. Because I mean, I I.",
            "A scientist working in an area is mainly to stay in that area and produce receipt papers, and on those on the same subject, OK. All that information is available from that URL.",
            "OK, this is."
        ],
        [
            "OK, So what about building a text classification system?",
            "We know that we can use the back of the words we know we have that we can create vectors and then we can use so much learning.",
            "But which is the general architecture for that?",
            "OK, France already stated that Israel text.",
            "OK, fix you later.",
            "That is real text mining task OK, we can apply many different techniques.",
            "Sometimes when we are creating a text classification system, we don't know what to use because they are.",
            "You guys you are giving so different so many solutions that is difficult to to select one of them.",
            "OK so we spend the time playing with them.",
            "This architecture is is based on the experience of some recuperation about the current system that we are in 2000.",
            "This is done by Sebastiane and we can see that mainly we have.",
            "To prepare the data OK to generate our.",
            "To generate our samples and then we can do machine learning and to prepare the data.",
            "We have two main steps."
        ],
        [
            "The first one is the feature extraction we want to take the features OK. We want to wait then.",
            "So normally steps here are convert to plain text which is already done in this corpus.",
            "Remove punctuation because in the back of the work we don't care about process another paragraph neither of that.",
            "Then we perform some."
        ],
        [
            "Stopwords removal and then we wait a hour.",
            "Features our words OK. An it's it's very nice to to condense all the different violent violent that are on waiting functions.",
            "On this formula.",
            "There is always mostly always one local component.",
            "That awaits the word within the document.",
            "There is global component that wait, the worse within the collection.",
            "OK, and there is a normalization factor always OK in order to, for example, not depend on the size of the document."
        ],
        [
            "For the local await we used to choose this frequency normalized by the by the log."
        ],
        [
            "OK, but they don't.",
            "They're not getting full function for this global.",
            "This global wait we have there are plenty of formula.",
            "The two main ones are.",
            "Inverse document frequency.",
            "That is, I want to penalize those terms that are in many documents.",
            "OK, because there may be there are two general, so they are.",
            "They don't have real power for discriminate among them or I can use entropy."
        ],
        [
            "And formalizing this would be the typical causing normalization.",
            "OK, so we just divide by the by the."
        ],
        [
            "Normal of the vector.",
            "And then we have to filter our features because we have thousands and thousands of features.",
            "One of the splits in the epochs in the experimental subcollection.",
            "We have more than 150,000 features.",
            "So I mean we can work with them but but.",
            "Out of all of the interesting.",
            "Because if we can get rid of many of them and still maintain our accuracy, why maintain them and make the system slower OK?",
            "So we can filter by document frequency.",
            "This is a very simple approach is one of these very simple things that worked very well.",
            "OK, it's just that if I turn this into many documents, we select three so long, then we discard and we can get rid of.",
            "A big a big amount of terms.",
            "We can also filter because here we are talking about this classification.",
            "Also filter by class frequency.",
            "If using the document as an access to to know to how many terms sorta know to how many keywords to how many classes attend is related to.",
            "We can also filter on that basis OK. And then of course we can also use information gain to filter our features.",
            "We have applied that here."
        ],
        [
            "The feature transformation that means OK Vector space is nice, but I don't have to have those working as components of vectors.",
            "Maybe I can jump to another another space.",
            "We kind of code use Latin semantic indexing, which is basically in singular value decomposition.",
            "We can also apply some third clustering, so we work with clusters instead of of terms we have and apply anything of this because this is very expensive in terms of.",
            "Computing the timing."
        ],
        [
            "Then OK, we are in the in the pink part of the story.",
            "We are training our classifiers an are plenty of learning algorithms available.",
            "And after that, if I want to do multi label and what I get from a classifier, is classification status values so I have to add a rank it either through solving it or just considering the default for interpretation of the output.",
            "For example if we have SVM we know that positive values are."
        ],
        [
            "Values OK. Now we like to work a little bit about evaluation issues.",
            "We are used to accuracy, but this that's good for binary problems.",
            "But when we are working on on multiclass and multilabel text classification, it is important to really understand what means precision, what means recall?",
            "Why do you say the F measure on?",
            "How do we operate it?",
            "OK, so we will stop on that later.",
            "OK, so we have this a yes no answer from the expert and this just no answer from the system.",
            "We all know what is true positive and false positive and all that and more less.",
            "We know that how these measures are computed.",
            "So I just pass."
        ],
        [
            "This slide.",
            "I'm sorry we perform for personalization to not really rely on or depends on how we do we split the data, but now it's important to notice that most of the words I've read on text classification performance, performance.",
            "Any cracking of two to compute the final precision and recall OK?",
            "That is, we just compute through positive for positive for true negatives, and we apply our formulas OK.",
            "But there is also a macro bragging.",
            "OK, I want to know the precision and recall of a document.",
            "OK, so for this document, which is the precision I have reached, how of the keyboard I have proposed, which are good?",
            "How many of them are good for the keywords that I was supposed to get?",
            "How?",
            "How many of them?",
            "I really got OK so.",
            "This a selection of the evaluation strategy is very important in order to understand what is happening with the system.",
            "For example, for for my problem.",
            "We wanted to have keywords in the basis of each document.",
            "OK, so I don't average by class as is usually done.",
            "I averaged by document.",
            "OK. Gas too.",
            "Remark that.",
            "So we have to decide whether we want to to average per document or where we want to average per class, and that will depend on on the real.",
            "Scope of."
        ],
        [
            "Our overseas thing.",
            "OK, another another important issue here is the print of unbalanced data we got.",
            "We having this table there most the 10 most frequent classes in the.",
            "They received a source in the in this head corpus OK. And we can see that.",
            "We have more than 1500 different keywords but only just looking at the first thing.",
            "We can see how dramatically the number of available documents for those classes drops OK. For that we apply this a degree in order to have an idea of for comparing for example collection for studying how depending on the on this."
        ],
        [
            "Balance the system can derivate, so this is the the inner embarrassed degree degree.",
            "One means that there is no positive sample for that class.",
            "And we can see that.",
            "Just in for the.",
            "For the very few first classes, we are already very close to 1, so we we have very very few very few documents, positive samples to train our system for most of the classes in the in the corpus.",
            "And this is also a very important thing, because sometimes we work on collections that are very well prepared it and.",
            "But and that are so well prepared that they take care of not having this imbalance, material world is not like that, OK?",
            "We can see the graph or for the first thing."
        ],
        [
            "Classes.",
            "And this will be the the embarrassed degree of of the euroblock corpus US we had when we performed this experiment we had 21,000 documents and again we have this effect.",
            "OK, it's not so dramatic as we have for the help corpus, but there is also high embarrassed degree.",
            "So what we propose it forces."
        ],
        [
            "And As for this multi level problem, was the algorithm that this.",
            "A mixture of case I submit algorithm over other machine learning algorithms.",
            "OK, which is the adaptive selection of base classifier.",
            "It is that since we want to perform the classification fast, we're not going to apply several algorithms for each class we are going to buy just one algorithm.",
            "OK, one classifier, but we know that it's class may show a different behavior to different algorithms, so we're going to let the algorithm to wander through the different classes on the site, which with.",
            "Then he the class want to married with OK.",
            "So that's the idea we passed through there."
        ],
        [
            "System.",
            "Anne.",
            "This training documents OK this validation documents.",
            "So the algorithm itself needs for training and is split between real training example some validation samples.",
            "We pass a threshold will spread it later and we pass.",
            "The class is an asset of candidate binary classifiers.",
            "OK, we can plug it in whatever we want.",
            "Whenever they we get a binary answer.",
            "They said that the algorithm is going to take for each candidate for each class and we train it OK, and then it will evaluate it and if the performance of that learning algorithm on the on the validation subset is higher than Alpha, then we consider that the class has been trained with that algorithm.",
            "OK, if we are not reaching a minimum of quality, we just discard the algorithm, we just discard.",
            "The class because we know that with this imbalance problem there will be plenty of classes that we cannot train, so we just discard them.",
            "Why you don't use just one classifier?",
            "The best motherboard for all classes?",
            "Because because we notice that our experiments so that.",
            "Having a good classifier, what means having a good credit for all of them, you evaluate in the basis of each class and usually it's class will select a different classifier and not all your different machine learning algorithm.",
            "But you can even specify the same algorithm with different parameters sessions so.",
            "OK, but for the Guardian is like you have different candidates so and it work very well.",
            "I mean it worked better than Allah Boot for example.",
            "It's really."
        ],
        [
            "Fast.",
            "So that would be a graphical view of the process.",
            "We have the sample, we have the training samples and the validation samples.",
            "We have this classifier learning phase where all the candidates are trained.",
            "But then we filter them using just selecting the best one on the validation set an filtered it out.",
            "If it doesn't give a minimum of."
        ],
        [
            "Anything OK?",
            "So we perform it the plenty of experiments tuning the system.",
            "I mean he had in DRC.",
            "They also know what that means.",
            "Do to really find the best parameter session for that collection of documents, which classifier?",
            "Where boot if we can apply bigrams, which kind of filtering strategy was best, and all this stuff, and it's not that.",
            "Yep.",
            "Button.",
            "I don't fully understand what what you mean.",
            "I mean when you have to train a classifier.",
            "I mean I categorize are what you have is positive and negative samples, so you can of course apply some techniques like oversampling or things like that.",
            "But then you are introducing more noise to the system.",
            "You mean that discarding that that classifier is?",
            "You find that very good categorization.",
            "Yeah.",
            "Give me that a kind of of three so we can split the different samples depending of the answer of the best.",
            "I mean the more balanced categories or something like that.",
            "Yeah.",
            "Yeah, yeah.",
            "True, that's true.",
            "I mean.",
            "No, no, we just don't don't consider that possibility.",
            "I mean, but but you are right.",
            "I mean there is more information you can learn from from how it behaves with the rest of class, sure.",
            "I asked the same question.",
            "Sorry.",
            "OK, OK, it's OK."
        ],
        [
            "OK.",
            "So one of the experiment was to study the effect of this Alpha at reserve in this algorithm.",
            "But of course to use the Alpha, we have to decide in on basis of which measure we want to filter out.",
            "Categorizers OK, so this was done on the basis of the F measure and we can see that we have here is not very visible have here.",
            "The percentage of classes that we are covered by the final system.",
            "OK, so.",
            "Just moving in this direction we are.",
            "Forcing the classifiers to be better.",
            "I mean, forcing the address to to have a better answer, a better response.",
            "We can reduce dramatically the number of classes that we are able to treat, so so with a similar value with similar measurements of precision and recall, an F measure, we can already discard plenty of classes.",
            "Would you would you social problem and I agree.",
            "I mean because sometimes we are more interested on those classes that are not so frequent.",
            "I mean when I have to discriminate among two documents, rare classes are really crucial."
        ],
        [
            "OK, so here we have the effect of letting the system decided on a different set of approaches.",
            "We apply the Rocchio algorithm, the perceptron learning algorithm, with an even margins.",
            "They plow algorithm support vector machines all with simple.",
            "Activation that means they fold prioritization of of our software solution and then we try different parameterization as candidates but using the same algorithm.",
            "OK and the last one is the same except which incorporate all of this.",
            "So the algorithm is going to set all this wide range of possible candidates.",
            "Location is have is a linear classifier, is a very simple one.",
            "With a half.",
            "Yeah.",
            "Yes, try here.",
            "Binary classifiers.",
            "And as I said I don't.",
            "I don't care which is behind.",
            "I'm not really, not really, but I want to to see the effect of of letting having different approaches for for all the classes so the classes can try to find if if there is.",
            "One approach is better than for it, OK?",
            "So we can see that the best solution was the this mixed solution."
        ],
        [
            "OK, one of 1 interesting thing I should go faster is that for example is just using the abstract and then iterate information as additional feature.",
            "It worked almost as well as the whole.",
            "Document the whole full text document so you can have.",
            "You can have similar.",
            "Performance.",
            "Behavior and very similar performance.",
            "Yes, not taking into account the hole in the full text, which is also."
        ],
        [
            "I'm headed for speed up the system.",
            "And the classification times we did with our first prototype was on average it takes.",
            "A little bit more than one second to classify OK?",
            "In this hex hieroglyphic experimental corpus, with the average."
        ],
        [
            "Is 5.",
            "So.",
            "Some reflections so far is that we are classification system RB.",
            "We have to to deal with different steps.",
            "OK, many parameters has to be tuned.",
            "Also, what about the availability of our parameters?",
            "I mean are these this team going to maintain to keep the system under the same level of performance during the time when we are receiving more and more documents?",
            "And maybe they topics that are being treated there are different?",
            "Evolving an how dependent we on our training data, even if we do this tenfold cross validation or I mean how how good, how in which level we can really trust.",
            "Our final system.",
            "Another important thing is that we have to measure in terms in terms of the final goal.",
            "As I pointed out.",
            "I mean if my goal is to present documents with categories, then I have to measure document by document.",
            "OK, we have to do to get with Robin S and of course they input data is important.",
            "I think it's OK.",
            "So as the input data is important, can we find more features?",
            "More information that can reach my system?",
            "Because I mean the meta data trick working well, it's not the full text information, but it's very informative information.",
            "Can I take more information even if I take it from the text itself?"
        ],
        [
            "I pass over here.",
            "This is what we get when we use stopwords removal."
        ],
        [
            "Colonist aiming to produce the.",
            "AM.",
            "OK, to produce the final backwards.",
            "So what can we have?",
            "A semantic linguistic information?",
            "We can add the dilemma of a world.",
            "We can have multi word detection.",
            "We can even use anaphora resolution to replicate certain words.",
            "We can use the part of the speech we cool.",
            "We cool use dependency tree semantic roles named entity recognition metadata paraphrasing or why not.",
            "As we see poetry, I mean everything.",
            "That can add more information, OK?",
            "And I'm going to select just these two.",
            "This lemma, which is.",
            "It's not exactly that there is sort of a steaming process, but mostly."
        ],
        [
            "OK, and the part of speech they are work done on the on the subject.",
            "As has been pointed out before giving using warnet for clustering and using this the I don't know if you know where net is sort of all the words in the English language.",
            "OK, so the case that with this so I can know that the different meanings for Assistant Word and they are grouped into since it's so I mean words that are shared the same meaning.",
            "I don't.",
            "I mean, he bonhomie different kind of relationships.",
            "Um, there is 1 interesting paper on using part of his speech, nose and were senses for doing text."
        ],
        [
            "They work in I I.",
            "They're working on different corpus and there are different corpora.",
            "But today they found that it was worthless.",
            "I mean there were not big improvements.",
            "So.",
            "In principle, we should stop here and there is nothing to do with linguistic feature, but we still believe that maybe if we combine this linguistic feature in some."
        ],
        [
            "Way we can find something interesting.",
            "OK, so this is the office of all these providing English language feature.",
            "OK, sorry.",
            "Adding data from higher level of abstract, we reach our feature space with additional information.",
            "Whenever this data is related in some way.",
            "So if we can find something that can put more data into the system which is related to what we already have an add more information, why?"
        ],
        [
            "You see I mean, why not using it for example like for these points?",
            "What is happening from my point of view is that we are adding what we're really doing.",
            "We are adding even if we are using poetry, we are adding external knowledge.",
            "But this fit into the system OK.",
            "So we are creating features that in some way can add more information about what we already have using just the plain text.",
            "OK, even if we are using very high an abstract."
        ],
        [
            "Tattoos.",
            "So that's different.",
            "How to incorporate this abstract information using this certain vector space model in a dying way so you don't have to think too much about what is this all about?",
            "OK, we can add, modify, remove."
        ],
        [
            "Combine.",
            "OK, so the experiments that we perform it is using this Reuters collection very well known collection and this split.",
            "We use it the ticket software which is at the implementation of this additive solution of base classifier, but that is not of interest.",
            "We are more concerned of what we can get depending on the feature we put into the system and we apply three different algorithms, Perceptron algorithm, the logistic digestion, regulation and support.",
            ", she.",
            "So these are the different features we are going to consider.",
            "Just text.",
            "I think the worse as they are OK noise teaming, nothing else.",
            "This stem of each work we apply the Porter, a suffix stepping algorithm.",
            "The root of the word using ontology, which will tell me really the root of that word.",
            "We play apply gate for that entry target.",
            "Forget this information.",
            "We also create a new feature which is the combination of the steam and the part of the speech in for sample this way also.",
            "Black, they stick the part of the speed with the word and went off with the root an.",
            "This is not here we we did it, and this is, but it's not in the results, OK?",
            "I mean we have the result, but I didn't bring it with me so.",
            "And one last experiment where we just put all of it together is the world the roots team."
        ],
        [
            "And then part of the speech.",
            "OK, so these are the results using support vector machine macro bragging by document.",
            "OK so surprising we are getting better results with with the last with the last combination.",
            "Just putting all together the word steam, the part of the speech.",
            "OK so compared to the normal a steam.",
            "There is nothing that very.",
            "I mean there is few that can be compared.",
            "Maybe the route with is already very similar strategy?",
            "OK, but we can really improve, not.",
            "It's not very significant but but we can improve.",
            "In precision record and recall our system."
        ],
        [
            "Putting all together and we apply different algorithms, we can see that the results."
        ],
        [
            "Are more or less consistent.",
            "And this is using Macro Dragon by class.",
            "OK, so I've reached my class again.",
            "We can find."
        ],
        [
            "The same behavior.",
            "This is microblogging.",
            "OK, so it's nothing ready to document is not ready to class, is just counting the when I do."
        ],
        [
            "We do things right or wrong, OK?",
            "So this is a better view of the F measure for afternoon travel, again with the different algorithms altogether and the different services.",
            "And we can see that this they use of this last strategy can really improve certain algorithms, so so it depends on the underlying.",
            "It's good for the three of them, but for some of them is even better OK?",
            "So the effect of the feature depending of course in algorithm use it."
        ],
        [
            "An ipass yes here.",
            "So if we want it to select our best setup depending on if I'm interested in in the documents.",
            "Averaging of interested in the class of lagging or I'm interested in microblogging or I'm more interested in purchasing and recall we can see that mostly all the answer would be.",
            "Using that plan algorithm and this last combination, just putting the word extend the post."
        ],
        [
            "All of we know.",
            "OK, so we have to know what we want.",
            "We have to know if we are a size.",
            "Have I have repeated continually?",
            "If we are more focused on documents or on classes, OK?",
            "Anne.",
            "I find that perfect classification system showed too many degrees of freedom when you have all the whole system, you have to turn all these parameters.",
            "You have too many degrees so.",
            "To what extent we can really believe our results?",
            "Because maybe we could just change this and we have a cascade effect on and nothing works.",
            "Anyway, I think we this is already a pair here about to about what if the initial condition is different is assistant.",
            "Is this graph basis are going to work really?"
        ],
        [
            "So.",
            "We want to to study it and more corporate.",
            "Of course on using additional linguistic features because we think that still is worth using some linguistic features.",
            "So maybe features that are in a higher level.",
            "I don't know if we will reach this smart point, but we will try.",
            "Of course, study how we can combine these may be using information gain so we can study which is the information gain I get from this combination."
        ],
        [
            "On additional languages, so that's all questions.",
            "Thank you very much for your attention.",
            "Any questions?",
            "You go for the weekend then.",
            "To add linguistic features back, I don't know how these guys published, but then you have the impression that two things.",
            "Can we explain stuff is in which we view this paper was published?",
            "It was supposed to yesterday.",
            "What year was extremely.",
            "Which author was do you mean that the documents in which you were published the documents?",
            "Yeah.",
            "Your.",
            "Give you some.",
            "Yeah, it's true that experiment experiments with meta data.",
            "Yeah, yeah we we added us.",
            "As another feature, so we take all the all the fields that are in the in the record and we add them.",
            "Jennifer, I need to really improving.",
            "Sorry, no, not just the content, but we specialize.",
            "It is, for example, if I have a title and I have three working within, I will add something in the beginning of each word to really discriminate those words from the rest of the context or something like T_And then they were to know that they come from the from the title and the same with the dates and the outdoors.",
            "Yeah, I mean it's as almost as good as the full text thing, so.",
            "One question, how would you compare the affected?",
            "At some point you mentioned that.",
            "It was pretty good, so switched to abstract instead of the full text.",
            "Is the effect of switching comparing to the.",
            "Differences between the various algorithms and linguistic features.",
            "No, no, no no.",
            "What I have some here for about linguistic feature.",
            "Maybe I went too fast.",
            "Point is that we use it Reuters OK and then the this information.",
            "These results are not coming from.",
            "Writers are coming from the high Energy Physics Collection an here and we also you can see for example there that you have F + N. That means that we are putting together the whole content of the full text document plus the meta data information, the abstract title.",
            "So of course that's the best approach, but is also very very expensive.",
            "So.",
            "Yes, we have differences.",
            "You mean if to know in which comes with this, the confidence so.",
            "Getting rid of the text and then focusing on on abstract itself or the differences between various classifiers.",
            "I mean, what is the?",
            "No, they did not hear the classifier not important.",
            "I mean the the concert here was to know which it was the best choose not to really the classifier.",
            "Matthew.",
            "Now you see I expect your corpus to have a high ponderance noun phrases.",
            "I wonder if you retrain your party speech tagger and or if you feel confident in your ring on the corpus, it would've been off the shelf.",
            "I we didn't perform any refinement on the on those tools, we just use it up.",
            "They were available.",
            "You felt confident in the results when we look back attacks.",
            "There is also that it helps in some way.",
            "Of course, maybe if we have a better tool.",
            "We will get to maybe better results so so I'm not really confident on that.",
            "Thank you very much and thank you all for your.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Today the last talk we are all.",
                    "label": 0
                },
                {
                    "sent": "Target I can read that on your faces.",
                    "label": 0
                },
                {
                    "sent": "So I will pass quickly on the matter that already Mark.",
                    "label": 0
                },
                {
                    "sent": "Underlining, so I think that I can make this presentation shorter.",
                    "label": 0
                },
                {
                    "sent": "My worker.",
                    "label": 0
                },
                {
                    "sent": "Is million text categorization and I'm present here some results that are not impressive from the point of view of what we are using, but for from what we can really deduce from from our results.",
                    "label": 0
                },
                {
                    "sent": "So I will start my presentation first answering questions.",
                    "label": 0
                },
                {
                    "sent": "So the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where is high?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Everybody ask about about that, so I will just go briefly on that and use this opportunity to promote my province.",
                    "label": 0
                },
                {
                    "sent": "We are in this all this pain and delphia.",
                    "label": 0
                },
                {
                    "sent": "We have very nice landscapes.",
                    "label": 0
                },
                {
                    "sent": "Of course we have thousands and thousands and millions of olive trees.",
                    "label": 0
                },
                {
                    "sent": "And so the olive oil is good strong.",
                    "label": 0
                },
                {
                    "sent": "Anne's plenty of castles and renaissance moments, so it's a very nice place to visit.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You already know.",
                    "label": 0
                },
                {
                    "sent": "OK, and now I'm going to stop here again.",
                    "label": 0
                },
                {
                    "sent": "We are still on the on the on the front page.",
                    "label": 0
                },
                {
                    "sent": "It's about my my group.",
                    "label": 0
                },
                {
                    "sent": "We mainly do natural language processing.",
                    "label": 1
                },
                {
                    "sent": "We are not machine learning experts.",
                    "label": 0
                },
                {
                    "sent": "OK, so we apply those algorithms to our problems.",
                    "label": 1
                },
                {
                    "sent": "We do text simulation, text mining in general, multilingual information retrieval, multimodal information retrieval.",
                    "label": 0
                },
                {
                    "sent": "That means to retrieve information, no matter the format of the sous video photo text, but our concern mainly on using text to improve those multimodal systems.",
                    "label": 0
                },
                {
                    "sent": "We worked on some question and answering.",
                    "label": 1
                },
                {
                    "sent": "We have started the.",
                    "label": 0
                },
                {
                    "sent": "One year ago, some work on dialogue systems and also we are working on text one in Tainment.",
                    "label": 0
                },
                {
                    "sent": "If any of you is interested on any of this matter, he can approach me.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the group I'm talking about.",
                    "label": 0
                },
                {
                    "sent": "You can find more information in this URL about papers project.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Topics reach topics, etc.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to to explain here is the there is something wrong here.",
                    "label": 0
                },
                {
                    "sent": "I lost the the transparency.",
                    "label": 0
                },
                {
                    "sent": "OK. And I'm going to 1st make an introduction to classification problems, but we already have it before, so I will go faster on that.",
                    "label": 1
                },
                {
                    "sent": "Or should we provide some examples of?",
                    "label": 1
                },
                {
                    "sent": "Running a.",
                    "label": 0
                },
                {
                    "sent": "Text classification systems real data.",
                    "label": 0
                },
                {
                    "sent": "And why they are interesting with some of the applications?",
                    "label": 0
                },
                {
                    "sent": "Because the cases are so high that I will just mention some of them.",
                    "label": 0
                },
                {
                    "sent": "And I will focus on any specific multi label text classification problem.",
                    "label": 0
                },
                {
                    "sent": "That is the one that we have to face in the other side of the Alps.",
                    "label": 0
                },
                {
                    "sent": "I will give more details later.",
                    "label": 0
                },
                {
                    "sent": "And we will then describe this architecture.",
                    "label": 0
                },
                {
                    "sent": "This general detector that is more or less a consensus now in for creating a text characterization system.",
                    "label": 0
                },
                {
                    "sent": "So you can use it as a receipt.",
                    "label": 0
                },
                {
                    "sent": "To create a.",
                    "label": 0
                },
                {
                    "sent": "Acceleration system able to face a big amounts of data.",
                    "label": 0
                },
                {
                    "sent": "I will underline the problem of imbalance of data which we are facing all the time in this paradigm.",
                    "label": 1
                },
                {
                    "sent": "And of course, how we tune the system for for that corpus OK, and you will say yes, but where is the talk about linguistic features?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oh, that's the tricky thing.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, I will talk about using this linguistic information as feature is on is smaller brief experiment.",
                    "label": 0
                },
                {
                    "sent": "We perform it on.",
                    "label": 0
                },
                {
                    "sent": "We were supposed to get to obtain certain research according to the literature, and was repressing for us.",
                    "label": 0
                },
                {
                    "sent": "Some of the results that we will discuss later.",
                    "label": 0
                },
                {
                    "sent": "I will explain the back of the words and how can we integrate.",
                    "label": 0
                },
                {
                    "sent": "And linguistic information in the vector space model.",
                    "label": 0
                },
                {
                    "sent": "Straightforward way.",
                    "label": 0
                },
                {
                    "sent": "Um, at that point I would like to make a reflection.",
                    "label": 0
                },
                {
                    "sent": "Why using high level information?",
                    "label": 1
                },
                {
                    "sent": "OK. OK, Ann.",
                    "label": 0
                },
                {
                    "sent": "And then I will work.",
                    "label": 0
                },
                {
                    "sent": "Sorry I will.",
                    "label": 0
                },
                {
                    "sent": "I will pass over some past work done on the on the use of linguistic information as feature for text categorization.",
                    "label": 1
                },
                {
                    "sent": "And then I will explain that experience that we cut it out on, which were the results, which I think that will take most of the final part of the presentation.",
                    "label": 0
                },
                {
                    "sent": "Also compression some features.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. You already know that we can.",
                    "label": 0
                },
                {
                    "sent": "We can classify text classification problems in three main paradigms.",
                    "label": 0
                },
                {
                    "sent": "The binary classifier, either we, we, we have a document and we want to either address or no answer to know if it belongs or not to accept in class, or if it belong to two different class that are mutually exclusive.",
                    "label": 0
                },
                {
                    "sent": "We can also work in a multi class.",
                    "label": 0
                },
                {
                    "sent": "We can also have a multiclass problem where we want to assign one label to a document among a given set of candidates.",
                    "label": 0
                },
                {
                    "sent": "And we can also work on our multi label classifier, which is the most complex one.",
                    "label": 0
                },
                {
                    "sent": "OK, and there is an interesting article about reducing all these problems to just live in other case which is quite intuitive.",
                    "label": 0
                },
                {
                    "sent": "But here they explain it in a more formal way.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is just to give some notation, but.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think you already know about it.",
                    "label": 0
                },
                {
                    "sent": "Examples being added case.",
                    "label": 0
                },
                {
                    "sent": "If this email is spam or is not a spam, or as we so before.",
                    "label": 0
                },
                {
                    "sent": "If this web page is maintained by terrorists or not OK, that will be a banner abinadi case and the advantage of with the case that the valuation.",
                    "label": 0
                },
                {
                    "sent": "Doesn't have to travel with many possibilities about how do I operate and how?",
                    "label": 0
                },
                {
                    "sent": "How do I evaluate and we will.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will see that later.",
                    "label": 0
                },
                {
                    "sent": "This would be an example of a multi class classification problem where we have a paper or PDF paper or research paper and we want to label it within one and only one of the recent categories OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is.",
                    "label": 0
                },
                {
                    "sent": "And this is a real example of classification of.",
                    "label": 0
                },
                {
                    "sent": "App Meta data extracted from from a database of high energy physics papers.",
                    "label": 0
                },
                {
                    "sent": "This meta data contains, among other information, an abstract, and that's after this plaintext.",
                    "label": 0
                },
                {
                    "sent": "So we can use that, and this will be the labels that were assigned by expert to that to that document.",
                    "label": 0
                },
                {
                    "sent": "Below you have an example of vaccination made by by the system we built.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Which is their history of text classification systems?",
                    "label": 0
                },
                {
                    "sent": "L in the in the in the.",
                    "label": 0
                },
                {
                    "sent": "In the literature we can find dysbiosis system.",
                    "label": 0
                },
                {
                    "sent": "In 1987 an they.",
                    "label": 0
                },
                {
                    "sent": "The information about it is not very detailed.",
                    "label": 0
                },
                {
                    "sent": "It's very well explaining how to to the to do the infer to know if a label belongs or not to the to the document, but mainly they take words from the title and works from the content.",
                    "label": 0
                },
                {
                    "sent": "And they try to make a match at that match with a lot of realistic.",
                    "label": 0
                },
                {
                    "sent": "So I mean, it was a really hard job.",
                    "label": 0
                },
                {
                    "sent": "I mean they they they they they link it mostly manually all this and they got 61% recall but there is no other information about the evaluation of the system.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One year later.",
                    "label": 0
                },
                {
                    "sent": "We we know about this surface system.",
                    "label": 0
                },
                {
                    "sent": "When was the first text classification system for automatic text classification system for physics?",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 1
                },
                {
                    "sent": "It was in production and it's performing also text mentation from the from the corpus of.",
                    "label": 0
                },
                {
                    "sent": "Sorry for that from the content of the paper.",
                    "label": 1
                },
                {
                    "sent": "And then using some probabilistic computation.",
                    "label": 0
                },
                {
                    "sent": "Also very very complex, because formulas were adjusted manually in order to make the system work as better as possible, they were able to reach 75% precision and 68% of recall.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which is not very much, but it was a hard task.",
                    "label": 0
                },
                {
                    "sent": "In 1994, we have one that is more in.",
                    "label": 0
                },
                {
                    "sent": "Close, I mean it's closer to what we used to have today.",
                    "label": 0
                },
                {
                    "sent": "Secure base it, but it had a knowledge base of 170,000 words and phrases and they were also manually introduces all these rules.",
                    "label": 1
                },
                {
                    "sent": "OK, it was oriented not to reproduce automatically.",
                    "label": 0
                },
                {
                    "sent": "Keyboards back to help indexers to find where which could be the keyword that were interesting for a certain publication OK. Hey Richard, 50% both in position and recall, which is not very much but we are talking about a multi level categorization problem with thousands of.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of possible categories.",
                    "label": 0
                },
                {
                    "sent": "Here, I think that even this this this measurements are now incorrect because I think that this information is dates from seven years ago.",
                    "label": 0
                },
                {
                    "sent": "OK so in DRC they are experts on in with the label text categorization 2.",
                    "label": 0
                },
                {
                    "sent": "With the Euroblock multilingual so loose that is in more than 20 languages with more than 6000 classes and they use machine learning methods.",
                    "label": 1
                },
                {
                    "sent": "And they they degree of multi ability of the of the documents are 5.6 classes per document.",
                    "label": 0
                },
                {
                    "sent": "Another age.",
                    "label": 0
                },
                {
                    "sent": "OK, we have something like from something like 12 classes in average in high energy.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Physics.",
                    "label": 0
                },
                {
                    "sent": "Finally we have this non index system which was for for medical.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Labani OK.",
                    "label": 0
                },
                {
                    "sent": "But what we can see is that we have pass it from.",
                    "label": 0
                },
                {
                    "sent": "In this system, from touristical approaches hard coded stuff to more flexible solution.",
                    "label": 0
                },
                {
                    "sent": "Thanks for the use of machine learning algorithm.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So why is people involving a time on working on text categorization systems?",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "It's interesting to work for for this.",
                    "label": 0
                },
                {
                    "sent": "There are plenty of of application of this automatic automatically generated labels and we can group this application into two different categories.",
                    "label": 0
                },
                {
                    "sent": "Not always categorizing direct manipulation.",
                    "label": 1
                },
                {
                    "sent": "When the when the when the user of the system wants to manipulate directly the keyboards or also an automatic manipulation when we want a machine, another program, another algorithm to you to make profit from those outputs.",
                    "label": 0
                },
                {
                    "sent": "OK, as lighting manipulation we can consider the set of keywords in a multi label rolling as such kind of summary of the content.",
                    "label": 0
                },
                {
                    "sent": "So imagine after you are looking for a higher physics paper in a database and you get the title, but then you can get the keyboards.",
                    "label": 0
                },
                {
                    "sent": "So in the same way we have these snippets for Google results, we can consider that we could consider those keyboards too.",
                    "label": 0
                },
                {
                    "sent": "Get a better idea about the content of the paper without opening it and reading it, OK?",
                    "label": 0
                },
                {
                    "sent": "Also for navigation I can use that from two young from one group of documents to another group of documents depending on the on the labels they share.",
                    "label": 0
                },
                {
                    "sent": "For for classification, for query expansion we can apply this this keyboard to query Son and classify queries and provide this keyboard additional information in the query.",
                    "label": 0
                },
                {
                    "sent": "We can perform cross lingual received because I can I can select a keyboard and then I can introduce that.",
                    "label": 0
                },
                {
                    "sent": "Sorry I can introduce that label in a search engine and if that label is a real labeling the service in the controller vocabulary and this service is multilingual then I can recover the retrieve documents in different languages.",
                    "label": 0
                },
                {
                    "sent": "I can do a concept worksheet that is similar to the navigation and of course I can also do a guided seat so I can get results.",
                    "label": 0
                },
                {
                    "sent": "Maybe I can narrow my search to certain topics.",
                    "label": 1
                },
                {
                    "sent": "I would automated manipulation of of keywords.",
                    "label": 0
                },
                {
                    "sent": "I can see it by by subject feel.",
                    "label": 0
                },
                {
                    "sent": "OK so I will just select a subject field back inside that field.",
                    "label": 0
                },
                {
                    "sent": "There is certain keywords within I don't know.",
                    "label": 0
                },
                {
                    "sent": "I don't see them, but the system will use it to get on to get more recall in the result.",
                    "label": 0
                },
                {
                    "sent": "Also, we can perform we're dealing with document similarity, but I think it has been already explained using those keywords.",
                    "label": 1
                },
                {
                    "sent": "OK as an extra space so it can be used as a Nexus between documents in different languages.",
                    "label": 1
                },
                {
                    "sent": "Thanks to Doctor Multilinguality of the of the vessels.",
                    "label": 0
                },
                {
                    "sent": "I can do also multilingual clustering based on that that the hours.",
                    "label": 0
                },
                {
                    "sent": "But I could also populate the semantic web.",
                    "label": 0
                },
                {
                    "sent": "If I know that certain web pages are talking about certain topics and I have a good classifier for them, I could add more information today to the semantic information of those pages and relate them so I can.",
                    "label": 1
                },
                {
                    "sent": "I could eventually use that information to provide certain content to the semantic web in an automatic way.",
                    "label": 0
                },
                {
                    "sent": "Also, I can populate the semantic grid.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you are familiar with this concept.",
                    "label": 0
                },
                {
                    "sent": "Is the Web is a kind of distributed file system?",
                    "label": 0
                },
                {
                    "sent": "The grid is a kind of distributed operating system using the whole power of the Internet.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that I can we can also.",
                    "label": 0
                },
                {
                    "sent": "Find services that are already categorized ready to certain labels to set the controller labels.",
                    "label": 1
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "I know that there is a service in one server to query about forecasting.",
                    "label": 0
                },
                {
                    "sent": "Another is another service in one server to query about latest news in sports.",
                    "label": 0
                },
                {
                    "sent": "OK and I could use that even to generate those labels and create the kind of network so I can relate different services.",
                    "label": 0
                },
                {
                    "sent": "Also, we can use it for a recommendation systems.",
                    "label": 0
                },
                {
                    "sent": "We don't see the keywords but we are asking for a book and we know that the book is ready to certain topics.",
                    "label": 0
                },
                {
                    "sent": "So then I can propose more books about those topics.",
                    "label": 0
                },
                {
                    "sent": "Of course we have seen we can generate the graphs.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, this is a view of.",
                    "label": 0
                },
                {
                    "sent": "The construction of one of the.",
                    "label": 0
                },
                {
                    "sent": "Detectors that we find in the in the in the other side of the apps close to Geneva in Switzerland.",
                    "label": 0
                },
                {
                    "sent": "Is held in Geneva.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry catching Sanofi in France an they have the big the biggest machine in the world so far is really amazing there.",
                    "label": 0
                },
                {
                    "sent": "There are thousands and thousands of physicists working there and producing scientific publications.",
                    "label": 0
                },
                {
                    "sent": "Scientifiques report cyantific information.",
                    "label": 0
                },
                {
                    "sent": "OK, but not only that.",
                    "label": 0
                },
                {
                    "sent": "Also serve is the laboratory for particle physics.",
                    "label": 1
                },
                {
                    "sent": "Is collecting papers about particle physics so.",
                    "label": 0
                },
                {
                    "sent": "Not only that, is a source of production, but is also one of the main story straight for this information.",
                    "label": 0
                },
                {
                    "sent": "So far I'm so far few years ago they were some expressing in German level authority in DC.",
                    "label": 0
                },
                {
                    "sent": "Who got the task of reading scientific papers?",
                    "label": 0
                },
                {
                    "sent": "Day by day and select some keywords from from a predefined controlled vocabulary that basically shows OK.",
                    "label": 0
                },
                {
                    "sent": "So you needed very skill people because they they must be experts on.",
                    "label": 0
                },
                {
                    "sent": "On the matter means to really know, uh, what is this paper talking about?",
                    "label": 0
                },
                {
                    "sent": "But they also must be expert in leavening because they have to know very well.",
                    "label": 0
                },
                {
                    "sent": "This is solos.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "The you need very qualified people for a very not very interesting task which is read and read and read and Silicon label OK.",
                    "label": 0
                },
                {
                    "sent": "So that could be one of the reasons to to work for an automatic categorization system.",
                    "label": 0
                },
                {
                    "sent": "Something like they did in NASA for adding from her helping indexers to make the task more easy.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Easier, but I found a different reasons for really work on it.",
                    "label": 0
                },
                {
                    "sent": "There was this.",
                    "label": 0
                },
                {
                    "sent": "This is the office that was right close to the mine one.",
                    "label": 0
                },
                {
                    "sent": "So then I decided that I had to do text classification because otherwise those people will die.",
                    "label": 0
                },
                {
                    "sent": "I mean under the weight of tons of papers I mean.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's really that's really an important reason, but OK, this is the real reason why this project was starting insert.",
                    "label": 0
                },
                {
                    "sent": "We can see here the the number of documents that are arriving.",
                    "label": 0
                },
                {
                    "sent": "Per week OK this they have been generally average, so every week we compute the number of documents and we have reached for the whole year.",
                    "label": 0
                },
                {
                    "sent": "So from from the 80s to 2003 we can see that is an exponential growth very clear.",
                    "label": 0
                },
                {
                    "sent": "I can imagine that 20 years ago.",
                    "label": 0
                },
                {
                    "sent": "To have a group of four 5 experts to read the 100 papers.",
                    "label": 0
                },
                {
                    "sent": "Distribute them, maybe you can have a 20 papers and you read it during the week.",
                    "label": 0
                },
                {
                    "sent": "So then you can label them OK.",
                    "label": 0
                },
                {
                    "sent": "But when you have a now is more almost 1000 papers per week.",
                    "label": 1
                },
                {
                    "sent": "It's really expensive to do this.",
                    "label": 0
                },
                {
                    "sent": "Do it in that.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Waso that's why.",
                    "label": 0
                },
                {
                    "sent": "Multilabel classification matters OK.",
                    "label": 0
                },
                {
                    "sent": "So we prepared the corpus.",
                    "label": 0
                },
                {
                    "sent": "We think different partitions because we expected to have a different classifiers depending on the on the subject that was covered by the papers.",
                    "label": 0
                },
                {
                    "sent": "So we have one for theoretical high energy physics, one for experimental high energy physics and one for astrophysics OK.",
                    "label": 0
                },
                {
                    "sent": "These are the sizes of these different splits.",
                    "label": 0
                },
                {
                    "sent": "This different subcollections.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing is that we have their full text information.",
                    "label": 0
                },
                {
                    "sent": "We have the content of the full paper.",
                    "label": 0
                },
                {
                    "sent": "OK has been instructed from the PDF, but also we have meta data information.",
                    "label": 0
                },
                {
                    "sent": "This this collection was generated by the original selection done by by James Vegan from the Library of CERN and this corpus is distill it.",
                    "label": 1
                },
                {
                    "sent": "Great to use for you.",
                    "label": 1
                },
                {
                    "sent": "You can download it from that URL.",
                    "label": 0
                },
                {
                    "sent": "Is freely available.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this corpus, having generated from the real PDF documents that researchers submit through their database and convert it using the tool, is called PDF to text and then forget because there are plenty of garbage within the database.",
                    "label": 0
                },
                {
                    "sent": "Not all the documents are well stored there.",
                    "label": 0
                },
                {
                    "sent": "OK, so there were some corruption and on some of the documents had to be a racist.",
                    "label": 0
                },
                {
                    "sent": "So we cleaned the collection, but that's the interesting thing is that we have.",
                    "label": 0
                },
                {
                    "sent": "Full text, I mean the real content of the document.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also we have they made their data that this did they record but worse in the database this record is following an XML format and is following the Open Architecture Initiative standard which is more or less related to the Dublin core meta data set.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have information about the author.",
                    "label": 0
                },
                {
                    "sent": "We have information about the language it is threatening.",
                    "label": 0
                },
                {
                    "sent": "We have the abstract here.",
                    "label": 0
                },
                {
                    "sent": "The subject which is a predefined the category for the document.",
                    "label": 0
                },
                {
                    "sent": "And we have the title separated the date of publication so.",
                    "label": 0
                },
                {
                    "sent": "I believe that we can do plenty of things with the collection.",
                    "label": 0
                },
                {
                    "sent": "OK, because we could just using the authors we can do text categorization if we work on on graphs for example.",
                    "label": 0
                },
                {
                    "sent": "OK. Because I mean, I I.",
                    "label": 0
                },
                {
                    "sent": "A scientist working in an area is mainly to stay in that area and produce receipt papers, and on those on the same subject, OK. All that information is available from that URL.",
                    "label": 0
                },
                {
                    "sent": "OK, this is.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what about building a text classification system?",
                    "label": 1
                },
                {
                    "sent": "We know that we can use the back of the words we know we have that we can create vectors and then we can use so much learning.",
                    "label": 0
                },
                {
                    "sent": "But which is the general architecture for that?",
                    "label": 0
                },
                {
                    "sent": "OK, France already stated that Israel text.",
                    "label": 0
                },
                {
                    "sent": "OK, fix you later.",
                    "label": 0
                },
                {
                    "sent": "That is real text mining task OK, we can apply many different techniques.",
                    "label": 1
                },
                {
                    "sent": "Sometimes when we are creating a text classification system, we don't know what to use because they are.",
                    "label": 0
                },
                {
                    "sent": "You guys you are giving so different so many solutions that is difficult to to select one of them.",
                    "label": 0
                },
                {
                    "sent": "OK so we spend the time playing with them.",
                    "label": 0
                },
                {
                    "sent": "This architecture is is based on the experience of some recuperation about the current system that we are in 2000.",
                    "label": 0
                },
                {
                    "sent": "This is done by Sebastiane and we can see that mainly we have.",
                    "label": 0
                },
                {
                    "sent": "To prepare the data OK to generate our.",
                    "label": 0
                },
                {
                    "sent": "To generate our samples and then we can do machine learning and to prepare the data.",
                    "label": 0
                },
                {
                    "sent": "We have two main steps.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first one is the feature extraction we want to take the features OK. We want to wait then.",
                    "label": 0
                },
                {
                    "sent": "So normally steps here are convert to plain text which is already done in this corpus.",
                    "label": 1
                },
                {
                    "sent": "Remove punctuation because in the back of the work we don't care about process another paragraph neither of that.",
                    "label": 0
                },
                {
                    "sent": "Then we perform some.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stopwords removal and then we wait a hour.",
                    "label": 0
                },
                {
                    "sent": "Features our words OK. An it's it's very nice to to condense all the different violent violent that are on waiting functions.",
                    "label": 0
                },
                {
                    "sent": "On this formula.",
                    "label": 0
                },
                {
                    "sent": "There is always mostly always one local component.",
                    "label": 0
                },
                {
                    "sent": "That awaits the word within the document.",
                    "label": 0
                },
                {
                    "sent": "There is global component that wait, the worse within the collection.",
                    "label": 0
                },
                {
                    "sent": "OK, and there is a normalization factor always OK in order to, for example, not depend on the size of the document.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the local await we used to choose this frequency normalized by the by the log.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, but they don't.",
                    "label": 0
                },
                {
                    "sent": "They're not getting full function for this global.",
                    "label": 0
                },
                {
                    "sent": "This global wait we have there are plenty of formula.",
                    "label": 0
                },
                {
                    "sent": "The two main ones are.",
                    "label": 0
                },
                {
                    "sent": "Inverse document frequency.",
                    "label": 0
                },
                {
                    "sent": "That is, I want to penalize those terms that are in many documents.",
                    "label": 0
                },
                {
                    "sent": "OK, because there may be there are two general, so they are.",
                    "label": 0
                },
                {
                    "sent": "They don't have real power for discriminate among them or I can use entropy.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And formalizing this would be the typical causing normalization.",
                    "label": 0
                },
                {
                    "sent": "OK, so we just divide by the by the.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Normal of the vector.",
                    "label": 0
                },
                {
                    "sent": "And then we have to filter our features because we have thousands and thousands of features.",
                    "label": 0
                },
                {
                    "sent": "One of the splits in the epochs in the experimental subcollection.",
                    "label": 0
                },
                {
                    "sent": "We have more than 150,000 features.",
                    "label": 0
                },
                {
                    "sent": "So I mean we can work with them but but.",
                    "label": 0
                },
                {
                    "sent": "Out of all of the interesting.",
                    "label": 0
                },
                {
                    "sent": "Because if we can get rid of many of them and still maintain our accuracy, why maintain them and make the system slower OK?",
                    "label": 0
                },
                {
                    "sent": "So we can filter by document frequency.",
                    "label": 1
                },
                {
                    "sent": "This is a very simple approach is one of these very simple things that worked very well.",
                    "label": 0
                },
                {
                    "sent": "OK, it's just that if I turn this into many documents, we select three so long, then we discard and we can get rid of.",
                    "label": 0
                },
                {
                    "sent": "A big a big amount of terms.",
                    "label": 0
                },
                {
                    "sent": "We can also filter because here we are talking about this classification.",
                    "label": 0
                },
                {
                    "sent": "Also filter by class frequency.",
                    "label": 1
                },
                {
                    "sent": "If using the document as an access to to know to how many terms sorta know to how many keywords to how many classes attend is related to.",
                    "label": 0
                },
                {
                    "sent": "We can also filter on that basis OK. And then of course we can also use information gain to filter our features.",
                    "label": 0
                },
                {
                    "sent": "We have applied that here.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The feature transformation that means OK Vector space is nice, but I don't have to have those working as components of vectors.",
                    "label": 0
                },
                {
                    "sent": "Maybe I can jump to another another space.",
                    "label": 0
                },
                {
                    "sent": "We kind of code use Latin semantic indexing, which is basically in singular value decomposition.",
                    "label": 0
                },
                {
                    "sent": "We can also apply some third clustering, so we work with clusters instead of of terms we have and apply anything of this because this is very expensive in terms of.",
                    "label": 0
                },
                {
                    "sent": "Computing the timing.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then OK, we are in the in the pink part of the story.",
                    "label": 0
                },
                {
                    "sent": "We are training our classifiers an are plenty of learning algorithms available.",
                    "label": 1
                },
                {
                    "sent": "And after that, if I want to do multi label and what I get from a classifier, is classification status values so I have to add a rank it either through solving it or just considering the default for interpretation of the output.",
                    "label": 0
                },
                {
                    "sent": "For example if we have SVM we know that positive values are.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Values OK. Now we like to work a little bit about evaluation issues.",
                    "label": 0
                },
                {
                    "sent": "We are used to accuracy, but this that's good for binary problems.",
                    "label": 0
                },
                {
                    "sent": "But when we are working on on multiclass and multilabel text classification, it is important to really understand what means precision, what means recall?",
                    "label": 0
                },
                {
                    "sent": "Why do you say the F measure on?",
                    "label": 0
                },
                {
                    "sent": "How do we operate it?",
                    "label": 0
                },
                {
                    "sent": "OK, so we will stop on that later.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have this a yes no answer from the expert and this just no answer from the system.",
                    "label": 0
                },
                {
                    "sent": "We all know what is true positive and false positive and all that and more less.",
                    "label": 0
                },
                {
                    "sent": "We know that how these measures are computed.",
                    "label": 0
                },
                {
                    "sent": "So I just pass.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This slide.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry we perform for personalization to not really rely on or depends on how we do we split the data, but now it's important to notice that most of the words I've read on text classification performance, performance.",
                    "label": 0
                },
                {
                    "sent": "Any cracking of two to compute the final precision and recall OK?",
                    "label": 0
                },
                {
                    "sent": "That is, we just compute through positive for positive for true negatives, and we apply our formulas OK.",
                    "label": 0
                },
                {
                    "sent": "But there is also a macro bragging.",
                    "label": 0
                },
                {
                    "sent": "OK, I want to know the precision and recall of a document.",
                    "label": 0
                },
                {
                    "sent": "OK, so for this document, which is the precision I have reached, how of the keyboard I have proposed, which are good?",
                    "label": 0
                },
                {
                    "sent": "How many of them are good for the keywords that I was supposed to get?",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "How many of them?",
                    "label": 0
                },
                {
                    "sent": "I really got OK so.",
                    "label": 0
                },
                {
                    "sent": "This a selection of the evaluation strategy is very important in order to understand what is happening with the system.",
                    "label": 0
                },
                {
                    "sent": "For example, for for my problem.",
                    "label": 0
                },
                {
                    "sent": "We wanted to have keywords in the basis of each document.",
                    "label": 0
                },
                {
                    "sent": "OK, so I don't average by class as is usually done.",
                    "label": 0
                },
                {
                    "sent": "I averaged by document.",
                    "label": 0
                },
                {
                    "sent": "OK. Gas too.",
                    "label": 0
                },
                {
                    "sent": "Remark that.",
                    "label": 0
                },
                {
                    "sent": "So we have to decide whether we want to to average per document or where we want to average per class, and that will depend on on the real.",
                    "label": 0
                },
                {
                    "sent": "Scope of.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our overseas thing.",
                    "label": 0
                },
                {
                    "sent": "OK, another another important issue here is the print of unbalanced data we got.",
                    "label": 1
                },
                {
                    "sent": "We having this table there most the 10 most frequent classes in the.",
                    "label": 0
                },
                {
                    "sent": "They received a source in the in this head corpus OK. And we can see that.",
                    "label": 0
                },
                {
                    "sent": "We have more than 1500 different keywords but only just looking at the first thing.",
                    "label": 0
                },
                {
                    "sent": "We can see how dramatically the number of available documents for those classes drops OK. For that we apply this a degree in order to have an idea of for comparing for example collection for studying how depending on the on this.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Balance the system can derivate, so this is the the inner embarrassed degree degree.",
                    "label": 0
                },
                {
                    "sent": "One means that there is no positive sample for that class.",
                    "label": 0
                },
                {
                    "sent": "And we can see that.",
                    "label": 0
                },
                {
                    "sent": "Just in for the.",
                    "label": 0
                },
                {
                    "sent": "For the very few first classes, we are already very close to 1, so we we have very very few very few documents, positive samples to train our system for most of the classes in the in the corpus.",
                    "label": 0
                },
                {
                    "sent": "And this is also a very important thing, because sometimes we work on collections that are very well prepared it and.",
                    "label": 0
                },
                {
                    "sent": "But and that are so well prepared that they take care of not having this imbalance, material world is not like that, OK?",
                    "label": 0
                },
                {
                    "sent": "We can see the graph or for the first thing.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Classes.",
                    "label": 0
                },
                {
                    "sent": "And this will be the the embarrassed degree of of the euroblock corpus US we had when we performed this experiment we had 21,000 documents and again we have this effect.",
                    "label": 0
                },
                {
                    "sent": "OK, it's not so dramatic as we have for the help corpus, but there is also high embarrassed degree.",
                    "label": 0
                },
                {
                    "sent": "So what we propose it forces.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And As for this multi level problem, was the algorithm that this.",
                    "label": 0
                },
                {
                    "sent": "A mixture of case I submit algorithm over other machine learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "OK, which is the adaptive selection of base classifier.",
                    "label": 0
                },
                {
                    "sent": "It is that since we want to perform the classification fast, we're not going to apply several algorithms for each class we are going to buy just one algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, one classifier, but we know that it's class may show a different behavior to different algorithms, so we're going to let the algorithm to wander through the different classes on the site, which with.",
                    "label": 0
                },
                {
                    "sent": "Then he the class want to married with OK.",
                    "label": 0
                },
                {
                    "sent": "So that's the idea we passed through there.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "System.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "This training documents OK this validation documents.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm itself needs for training and is split between real training example some validation samples.",
                    "label": 0
                },
                {
                    "sent": "We pass a threshold will spread it later and we pass.",
                    "label": 0
                },
                {
                    "sent": "The class is an asset of candidate binary classifiers.",
                    "label": 0
                },
                {
                    "sent": "OK, we can plug it in whatever we want.",
                    "label": 0
                },
                {
                    "sent": "Whenever they we get a binary answer.",
                    "label": 0
                },
                {
                    "sent": "They said that the algorithm is going to take for each candidate for each class and we train it OK, and then it will evaluate it and if the performance of that learning algorithm on the on the validation subset is higher than Alpha, then we consider that the class has been trained with that algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, if we are not reaching a minimum of quality, we just discard the algorithm, we just discard.",
                    "label": 0
                },
                {
                    "sent": "The class because we know that with this imbalance problem there will be plenty of classes that we cannot train, so we just discard them.",
                    "label": 0
                },
                {
                    "sent": "Why you don't use just one classifier?",
                    "label": 0
                },
                {
                    "sent": "The best motherboard for all classes?",
                    "label": 0
                },
                {
                    "sent": "Because because we notice that our experiments so that.",
                    "label": 0
                },
                {
                    "sent": "Having a good classifier, what means having a good credit for all of them, you evaluate in the basis of each class and usually it's class will select a different classifier and not all your different machine learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "But you can even specify the same algorithm with different parameters sessions so.",
                    "label": 0
                },
                {
                    "sent": "OK, but for the Guardian is like you have different candidates so and it work very well.",
                    "label": 0
                },
                {
                    "sent": "I mean it worked better than Allah Boot for example.",
                    "label": 0
                },
                {
                    "sent": "It's really.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fast.",
                    "label": 0
                },
                {
                    "sent": "So that would be a graphical view of the process.",
                    "label": 0
                },
                {
                    "sent": "We have the sample, we have the training samples and the validation samples.",
                    "label": 0
                },
                {
                    "sent": "We have this classifier learning phase where all the candidates are trained.",
                    "label": 0
                },
                {
                    "sent": "But then we filter them using just selecting the best one on the validation set an filtered it out.",
                    "label": 0
                },
                {
                    "sent": "If it doesn't give a minimum of.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anything OK?",
                    "label": 0
                },
                {
                    "sent": "So we perform it the plenty of experiments tuning the system.",
                    "label": 0
                },
                {
                    "sent": "I mean he had in DRC.",
                    "label": 0
                },
                {
                    "sent": "They also know what that means.",
                    "label": 0
                },
                {
                    "sent": "Do to really find the best parameter session for that collection of documents, which classifier?",
                    "label": 0
                },
                {
                    "sent": "Where boot if we can apply bigrams, which kind of filtering strategy was best, and all this stuff, and it's not that.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Button.",
                    "label": 0
                },
                {
                    "sent": "I don't fully understand what what you mean.",
                    "label": 0
                },
                {
                    "sent": "I mean when you have to train a classifier.",
                    "label": 0
                },
                {
                    "sent": "I mean I categorize are what you have is positive and negative samples, so you can of course apply some techniques like oversampling or things like that.",
                    "label": 0
                },
                {
                    "sent": "But then you are introducing more noise to the system.",
                    "label": 0
                },
                {
                    "sent": "You mean that discarding that that classifier is?",
                    "label": 0
                },
                {
                    "sent": "You find that very good categorization.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Give me that a kind of of three so we can split the different samples depending of the answer of the best.",
                    "label": 0
                },
                {
                    "sent": "I mean the more balanced categories or something like that.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "True, that's true.",
                    "label": 0
                },
                {
                    "sent": "I mean.",
                    "label": 0
                },
                {
                    "sent": "No, no, we just don't don't consider that possibility.",
                    "label": 0
                },
                {
                    "sent": "I mean, but but you are right.",
                    "label": 0
                },
                {
                    "sent": "I mean there is more information you can learn from from how it behaves with the rest of class, sure.",
                    "label": 0
                },
                {
                    "sent": "I asked the same question.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, it's OK.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So one of the experiment was to study the effect of this Alpha at reserve in this algorithm.",
                    "label": 1
                },
                {
                    "sent": "But of course to use the Alpha, we have to decide in on basis of which measure we want to filter out.",
                    "label": 0
                },
                {
                    "sent": "Categorizers OK, so this was done on the basis of the F measure and we can see that we have here is not very visible have here.",
                    "label": 0
                },
                {
                    "sent": "The percentage of classes that we are covered by the final system.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Just moving in this direction we are.",
                    "label": 0
                },
                {
                    "sent": "Forcing the classifiers to be better.",
                    "label": 0
                },
                {
                    "sent": "I mean, forcing the address to to have a better answer, a better response.",
                    "label": 0
                },
                {
                    "sent": "We can reduce dramatically the number of classes that we are able to treat, so so with a similar value with similar measurements of precision and recall, an F measure, we can already discard plenty of classes.",
                    "label": 0
                },
                {
                    "sent": "Would you would you social problem and I agree.",
                    "label": 0
                },
                {
                    "sent": "I mean because sometimes we are more interested on those classes that are not so frequent.",
                    "label": 0
                },
                {
                    "sent": "I mean when I have to discriminate among two documents, rare classes are really crucial.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here we have the effect of letting the system decided on a different set of approaches.",
                    "label": 1
                },
                {
                    "sent": "We apply the Rocchio algorithm, the perceptron learning algorithm, with an even margins.",
                    "label": 0
                },
                {
                    "sent": "They plow algorithm support vector machines all with simple.",
                    "label": 0
                },
                {
                    "sent": "Activation that means they fold prioritization of of our software solution and then we try different parameterization as candidates but using the same algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK and the last one is the same except which incorporate all of this.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm is going to set all this wide range of possible candidates.",
                    "label": 0
                },
                {
                    "sent": "Location is have is a linear classifier, is a very simple one.",
                    "label": 0
                },
                {
                    "sent": "With a half.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yes, try here.",
                    "label": 0
                },
                {
                    "sent": "Binary classifiers.",
                    "label": 0
                },
                {
                    "sent": "And as I said I don't.",
                    "label": 0
                },
                {
                    "sent": "I don't care which is behind.",
                    "label": 0
                },
                {
                    "sent": "I'm not really, not really, but I want to to see the effect of of letting having different approaches for for all the classes so the classes can try to find if if there is.",
                    "label": 0
                },
                {
                    "sent": "One approach is better than for it, OK?",
                    "label": 0
                },
                {
                    "sent": "So we can see that the best solution was the this mixed solution.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, one of 1 interesting thing I should go faster is that for example is just using the abstract and then iterate information as additional feature.",
                    "label": 0
                },
                {
                    "sent": "It worked almost as well as the whole.",
                    "label": 0
                },
                {
                    "sent": "Document the whole full text document so you can have.",
                    "label": 0
                },
                {
                    "sent": "You can have similar.",
                    "label": 0
                },
                {
                    "sent": "Performance.",
                    "label": 0
                },
                {
                    "sent": "Behavior and very similar performance.",
                    "label": 0
                },
                {
                    "sent": "Yes, not taking into account the hole in the full text, which is also.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm headed for speed up the system.",
                    "label": 0
                },
                {
                    "sent": "And the classification times we did with our first prototype was on average it takes.",
                    "label": 1
                },
                {
                    "sent": "A little bit more than one second to classify OK?",
                    "label": 0
                },
                {
                    "sent": "In this hex hieroglyphic experimental corpus, with the average.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is 5.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Some reflections so far is that we are classification system RB.",
                    "label": 0
                },
                {
                    "sent": "We have to to deal with different steps.",
                    "label": 0
                },
                {
                    "sent": "OK, many parameters has to be tuned.",
                    "label": 1
                },
                {
                    "sent": "Also, what about the availability of our parameters?",
                    "label": 0
                },
                {
                    "sent": "I mean are these this team going to maintain to keep the system under the same level of performance during the time when we are receiving more and more documents?",
                    "label": 0
                },
                {
                    "sent": "And maybe they topics that are being treated there are different?",
                    "label": 0
                },
                {
                    "sent": "Evolving an how dependent we on our training data, even if we do this tenfold cross validation or I mean how how good, how in which level we can really trust.",
                    "label": 0
                },
                {
                    "sent": "Our final system.",
                    "label": 0
                },
                {
                    "sent": "Another important thing is that we have to measure in terms in terms of the final goal.",
                    "label": 1
                },
                {
                    "sent": "As I pointed out.",
                    "label": 0
                },
                {
                    "sent": "I mean if my goal is to present documents with categories, then I have to measure document by document.",
                    "label": 0
                },
                {
                    "sent": "OK, we have to do to get with Robin S and of course they input data is important.",
                    "label": 0
                },
                {
                    "sent": "I think it's OK.",
                    "label": 1
                },
                {
                    "sent": "So as the input data is important, can we find more features?",
                    "label": 0
                },
                {
                    "sent": "More information that can reach my system?",
                    "label": 0
                },
                {
                    "sent": "Because I mean the meta data trick working well, it's not the full text information, but it's very informative information.",
                    "label": 0
                },
                {
                    "sent": "Can I take more information even if I take it from the text itself?",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I pass over here.",
                    "label": 0
                },
                {
                    "sent": "This is what we get when we use stopwords removal.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Colonist aiming to produce the.",
                    "label": 0
                },
                {
                    "sent": "AM.",
                    "label": 0
                },
                {
                    "sent": "OK, to produce the final backwards.",
                    "label": 0
                },
                {
                    "sent": "So what can we have?",
                    "label": 1
                },
                {
                    "sent": "A semantic linguistic information?",
                    "label": 0
                },
                {
                    "sent": "We can add the dilemma of a world.",
                    "label": 0
                },
                {
                    "sent": "We can have multi word detection.",
                    "label": 1
                },
                {
                    "sent": "We can even use anaphora resolution to replicate certain words.",
                    "label": 0
                },
                {
                    "sent": "We can use the part of the speech we cool.",
                    "label": 0
                },
                {
                    "sent": "We cool use dependency tree semantic roles named entity recognition metadata paraphrasing or why not.",
                    "label": 1
                },
                {
                    "sent": "As we see poetry, I mean everything.",
                    "label": 0
                },
                {
                    "sent": "That can add more information, OK?",
                    "label": 0
                },
                {
                    "sent": "And I'm going to select just these two.",
                    "label": 0
                },
                {
                    "sent": "This lemma, which is.",
                    "label": 0
                },
                {
                    "sent": "It's not exactly that there is sort of a steaming process, but mostly.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and the part of speech they are work done on the on the subject.",
                    "label": 0
                },
                {
                    "sent": "As has been pointed out before giving using warnet for clustering and using this the I don't know if you know where net is sort of all the words in the English language.",
                    "label": 0
                },
                {
                    "sent": "OK, so the case that with this so I can know that the different meanings for Assistant Word and they are grouped into since it's so I mean words that are shared the same meaning.",
                    "label": 0
                },
                {
                    "sent": "I don't.",
                    "label": 0
                },
                {
                    "sent": "I mean, he bonhomie different kind of relationships.",
                    "label": 0
                },
                {
                    "sent": "Um, there is 1 interesting paper on using part of his speech, nose and were senses for doing text.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They work in I I.",
                    "label": 0
                },
                {
                    "sent": "They're working on different corpus and there are different corpora.",
                    "label": 0
                },
                {
                    "sent": "But today they found that it was worthless.",
                    "label": 0
                },
                {
                    "sent": "I mean there were not big improvements.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In principle, we should stop here and there is nothing to do with linguistic feature, but we still believe that maybe if we combine this linguistic feature in some.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Way we can find something interesting.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the office of all these providing English language feature.",
                    "label": 0
                },
                {
                    "sent": "OK, sorry.",
                    "label": 0
                },
                {
                    "sent": "Adding data from higher level of abstract, we reach our feature space with additional information.",
                    "label": 1
                },
                {
                    "sent": "Whenever this data is related in some way.",
                    "label": 0
                },
                {
                    "sent": "So if we can find something that can put more data into the system which is related to what we already have an add more information, why?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You see I mean, why not using it for example like for these points?",
                    "label": 0
                },
                {
                    "sent": "What is happening from my point of view is that we are adding what we're really doing.",
                    "label": 0
                },
                {
                    "sent": "We are adding even if we are using poetry, we are adding external knowledge.",
                    "label": 0
                },
                {
                    "sent": "But this fit into the system OK.",
                    "label": 0
                },
                {
                    "sent": "So we are creating features that in some way can add more information about what we already have using just the plain text.",
                    "label": 0
                },
                {
                    "sent": "OK, even if we are using very high an abstract.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Tattoos.",
                    "label": 0
                },
                {
                    "sent": "So that's different.",
                    "label": 0
                },
                {
                    "sent": "How to incorporate this abstract information using this certain vector space model in a dying way so you don't have to think too much about what is this all about?",
                    "label": 1
                },
                {
                    "sent": "OK, we can add, modify, remove.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Combine.",
                    "label": 0
                },
                {
                    "sent": "OK, so the experiments that we perform it is using this Reuters collection very well known collection and this split.",
                    "label": 0
                },
                {
                    "sent": "We use it the ticket software which is at the implementation of this additive solution of base classifier, but that is not of interest.",
                    "label": 0
                },
                {
                    "sent": "We are more concerned of what we can get depending on the feature we put into the system and we apply three different algorithms, Perceptron algorithm, the logistic digestion, regulation and support.",
                    "label": 0
                },
                {
                    "sent": ", she.",
                    "label": 0
                },
                {
                    "sent": "So these are the different features we are going to consider.",
                    "label": 0
                },
                {
                    "sent": "Just text.",
                    "label": 0
                },
                {
                    "sent": "I think the worse as they are OK noise teaming, nothing else.",
                    "label": 0
                },
                {
                    "sent": "This stem of each work we apply the Porter, a suffix stepping algorithm.",
                    "label": 0
                },
                {
                    "sent": "The root of the word using ontology, which will tell me really the root of that word.",
                    "label": 0
                },
                {
                    "sent": "We play apply gate for that entry target.",
                    "label": 0
                },
                {
                    "sent": "Forget this information.",
                    "label": 0
                },
                {
                    "sent": "We also create a new feature which is the combination of the steam and the part of the speech in for sample this way also.",
                    "label": 0
                },
                {
                    "sent": "Black, they stick the part of the speed with the word and went off with the root an.",
                    "label": 0
                },
                {
                    "sent": "This is not here we we did it, and this is, but it's not in the results, OK?",
                    "label": 0
                },
                {
                    "sent": "I mean we have the result, but I didn't bring it with me so.",
                    "label": 0
                },
                {
                    "sent": "And one last experiment where we just put all of it together is the world the roots team.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then part of the speech.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are the results using support vector machine macro bragging by document.",
                    "label": 0
                },
                {
                    "sent": "OK so surprising we are getting better results with with the last with the last combination.",
                    "label": 0
                },
                {
                    "sent": "Just putting all together the word steam, the part of the speech.",
                    "label": 0
                },
                {
                    "sent": "OK so compared to the normal a steam.",
                    "label": 0
                },
                {
                    "sent": "There is nothing that very.",
                    "label": 0
                },
                {
                    "sent": "I mean there is few that can be compared.",
                    "label": 0
                },
                {
                    "sent": "Maybe the route with is already very similar strategy?",
                    "label": 0
                },
                {
                    "sent": "OK, but we can really improve, not.",
                    "label": 0
                },
                {
                    "sent": "It's not very significant but but we can improve.",
                    "label": 0
                },
                {
                    "sent": "In precision record and recall our system.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Putting all together and we apply different algorithms, we can see that the results.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are more or less consistent.",
                    "label": 0
                },
                {
                    "sent": "And this is using Macro Dragon by class.",
                    "label": 0
                },
                {
                    "sent": "OK, so I've reached my class again.",
                    "label": 0
                },
                {
                    "sent": "We can find.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same behavior.",
                    "label": 0
                },
                {
                    "sent": "This is microblogging.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's nothing ready to document is not ready to class, is just counting the when I do.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We do things right or wrong, OK?",
                    "label": 0
                },
                {
                    "sent": "So this is a better view of the F measure for afternoon travel, again with the different algorithms altogether and the different services.",
                    "label": 0
                },
                {
                    "sent": "And we can see that this they use of this last strategy can really improve certain algorithms, so so it depends on the underlying.",
                    "label": 1
                },
                {
                    "sent": "It's good for the three of them, but for some of them is even better OK?",
                    "label": 0
                },
                {
                    "sent": "So the effect of the feature depending of course in algorithm use it.",
                    "label": 1
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An ipass yes here.",
                    "label": 0
                },
                {
                    "sent": "So if we want it to select our best setup depending on if I'm interested in in the documents.",
                    "label": 0
                },
                {
                    "sent": "Averaging of interested in the class of lagging or I'm interested in microblogging or I'm more interested in purchasing and recall we can see that mostly all the answer would be.",
                    "label": 0
                },
                {
                    "sent": "Using that plan algorithm and this last combination, just putting the word extend the post.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All of we know.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have to know what we want.",
                    "label": 1
                },
                {
                    "sent": "We have to know if we are a size.",
                    "label": 0
                },
                {
                    "sent": "Have I have repeated continually?",
                    "label": 0
                },
                {
                    "sent": "If we are more focused on documents or on classes, OK?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 1
                },
                {
                    "sent": "I find that perfect classification system showed too many degrees of freedom when you have all the whole system, you have to turn all these parameters.",
                    "label": 0
                },
                {
                    "sent": "You have too many degrees so.",
                    "label": 0
                },
                {
                    "sent": "To what extent we can really believe our results?",
                    "label": 0
                },
                {
                    "sent": "Because maybe we could just change this and we have a cascade effect on and nothing works.",
                    "label": 0
                },
                {
                    "sent": "Anyway, I think we this is already a pair here about to about what if the initial condition is different is assistant.",
                    "label": 0
                },
                {
                    "sent": "Is this graph basis are going to work really?",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We want to to study it and more corporate.",
                    "label": 0
                },
                {
                    "sent": "Of course on using additional linguistic features because we think that still is worth using some linguistic features.",
                    "label": 1
                },
                {
                    "sent": "So maybe features that are in a higher level.",
                    "label": 0
                },
                {
                    "sent": "I don't know if we will reach this smart point, but we will try.",
                    "label": 0
                },
                {
                    "sent": "Of course, study how we can combine these may be using information gain so we can study which is the information gain I get from this combination.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On additional languages, so that's all questions.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 1
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "You go for the weekend then.",
                    "label": 0
                },
                {
                    "sent": "To add linguistic features back, I don't know how these guys published, but then you have the impression that two things.",
                    "label": 0
                },
                {
                    "sent": "Can we explain stuff is in which we view this paper was published?",
                    "label": 0
                },
                {
                    "sent": "It was supposed to yesterday.",
                    "label": 0
                },
                {
                    "sent": "What year was extremely.",
                    "label": 0
                },
                {
                    "sent": "Which author was do you mean that the documents in which you were published the documents?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Your.",
                    "label": 0
                },
                {
                    "sent": "Give you some.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's true that experiment experiments with meta data.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah we we added us.",
                    "label": 0
                },
                {
                    "sent": "As another feature, so we take all the all the fields that are in the in the record and we add them.",
                    "label": 0
                },
                {
                    "sent": "Jennifer, I need to really improving.",
                    "label": 0
                },
                {
                    "sent": "Sorry, no, not just the content, but we specialize.",
                    "label": 0
                },
                {
                    "sent": "It is, for example, if I have a title and I have three working within, I will add something in the beginning of each word to really discriminate those words from the rest of the context or something like T_And then they were to know that they come from the from the title and the same with the dates and the outdoors.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean it's as almost as good as the full text thing, so.",
                    "label": 0
                },
                {
                    "sent": "One question, how would you compare the affected?",
                    "label": 0
                },
                {
                    "sent": "At some point you mentioned that.",
                    "label": 0
                },
                {
                    "sent": "It was pretty good, so switched to abstract instead of the full text.",
                    "label": 0
                },
                {
                    "sent": "Is the effect of switching comparing to the.",
                    "label": 0
                },
                {
                    "sent": "Differences between the various algorithms and linguistic features.",
                    "label": 0
                },
                {
                    "sent": "No, no, no no.",
                    "label": 0
                },
                {
                    "sent": "What I have some here for about linguistic feature.",
                    "label": 0
                },
                {
                    "sent": "Maybe I went too fast.",
                    "label": 0
                },
                {
                    "sent": "Point is that we use it Reuters OK and then the this information.",
                    "label": 0
                },
                {
                    "sent": "These results are not coming from.",
                    "label": 0
                },
                {
                    "sent": "Writers are coming from the high Energy Physics Collection an here and we also you can see for example there that you have F + N. That means that we are putting together the whole content of the full text document plus the meta data information, the abstract title.",
                    "label": 0
                },
                {
                    "sent": "So of course that's the best approach, but is also very very expensive.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yes, we have differences.",
                    "label": 0
                },
                {
                    "sent": "You mean if to know in which comes with this, the confidence so.",
                    "label": 0
                },
                {
                    "sent": "Getting rid of the text and then focusing on on abstract itself or the differences between various classifiers.",
                    "label": 0
                },
                {
                    "sent": "I mean, what is the?",
                    "label": 0
                },
                {
                    "sent": "No, they did not hear the classifier not important.",
                    "label": 0
                },
                {
                    "sent": "I mean the the concert here was to know which it was the best choose not to really the classifier.",
                    "label": 0
                },
                {
                    "sent": "Matthew.",
                    "label": 0
                },
                {
                    "sent": "Now you see I expect your corpus to have a high ponderance noun phrases.",
                    "label": 0
                },
                {
                    "sent": "I wonder if you retrain your party speech tagger and or if you feel confident in your ring on the corpus, it would've been off the shelf.",
                    "label": 0
                },
                {
                    "sent": "I we didn't perform any refinement on the on those tools, we just use it up.",
                    "label": 0
                },
                {
                    "sent": "They were available.",
                    "label": 0
                },
                {
                    "sent": "You felt confident in the results when we look back attacks.",
                    "label": 0
                },
                {
                    "sent": "There is also that it helps in some way.",
                    "label": 0
                },
                {
                    "sent": "Of course, maybe if we have a better tool.",
                    "label": 0
                },
                {
                    "sent": "We will get to maybe better results so so I'm not really confident on that.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much and thank you all for your.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}