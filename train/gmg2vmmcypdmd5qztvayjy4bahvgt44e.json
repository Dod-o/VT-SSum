{
    "id": "gmg2vmmcypdmd5qztvayjy4bahvgt44e",
    "title": "Graph Sample and Hold: A Framework for Big-Graph Analytics",
    "info": {
        "author": [
            "Nesreen K. Ahmed, Department of Computer Science, Purdue University"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Knowledge Extraction",
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/kdd2014_ahmed_big_graph_analytics/",
    "segmentation": [
        [
            "I'm just reading from Purdue University computer science Department and this paper is a joint work with negative field.",
            "Jennifer Neville and Ramona Kompella."
        ],
        [
            "So graphs provide a very rich data representation for various types of networks like social networks, web graphs, and the Internet, and so graph analytics comes at the heart and the foundation of studying all these types of complex networks, however."
        ],
        [
            "Studying complex networks, analyzing them is a very challenging task, an computational intensive, and that's due to their massive size and also due to the fact that many of these networks are actually dynamically streaming overtime.",
            "And so do to these challenges."
        ],
        [
            "We usually need to collect a sample, which is basically a subset of nodes or edges from which we can study the properties of these graphs."
        ],
        [
            "So the main motivation of this paper is that if we have a large graph, this actually are presented as a stream of edges.",
            "So how to efficiently sample from this graph with while limiting the memory space in order to calculate different unbiased estimates of various graph properties so for."
        ],
        [
            "Sample if we have such an edge stream then we can select a subset of the edges that appear in this."
        ],
        [
            "The man from which we can estimate certain graph properties like the number of edges, number of edges and number of triangles, and those three out of the main or the particular focus that we have in this paper, the."
        ],
        [
            "Two are actually particularly important because you can compute the global clustering coefficient, which is very representative of the rate of transitivity in the graph."
        ],
        [
            "So how this is actually related has been handled in the related work.",
            "So let's focus first on the sampling part.",
            "So random sampling is a widely used tool for big data and big graph analytics, and probably some of you have attended the tutorial yesterday which covered in detail the problem of how to use sampling to solve many of these problems, and so one such method that actually suggested to use uniform random sampling which is very simple idea where you.",
            "You could just do some graph sparsification with a probability that's uniform, so one single probability that can be used.",
            "However, it has been shown that this method has certain problems, so one of them is that the chains of sampling a sub graph like a triangle is usually very low because we sample and that's due to the fact that we sample independent edges.",
            "So in fact we have that graph where we sample independent edges, but the goal at the end is to actually capture higher liver patterns like triangles.",
            "And so the probability would be very low to actually sample that triangle, and so also the estimates that can be driven from these samples usually suffer from a high variance, so other methods have been proposed to solve this sort of problem, and one of them is instead of doing edge sampling, is to actually sample wedges and so the idea is that instead of sampling the edges, we use these sample vertices and for each vertex the sample certain wedges which basically incident edges to this.",
            "Vertex and so.",
            "Then after that the output the estimate of the closed wedges or the triangles, however these methods."
        ],
        [
            "In general, suffer from a certain limitation which basically that they assume that the whole graph can fit into memory, which is somehow a limitation for many of the massive graphs that we actually see today.",
            "So."
        ],
        [
            "One simple solution to solve the problem.",
            "If the graph can't fit in memory, then to use actually stream sampling.",
            "So which means that if you have that edge stream, you can just sequentially sample from the edges without storing the full graph into the memory.",
            "However, even stream sampling suffer some limitations in the literature.",
            "For example, some work assume that there is a specific order of this stream, which means that neighbors of a vertex could arrive altogether like groups together in the stream.",
            "Other assumptions like that we can do multiple passes over the stream.",
            "So these sorts of assumptions are somehow a bit unrealistic for certain graphs that we see today, and so recently there has been a lot of focus on single pass algorithms that would just take one pass over the stream and also does not assume any sort of order over the stream.",
            "So one very well known example of these kinds of methods was a paper that was presented in KDD last year which proposed the idea of a streaming triangles.",
            "Which is very similar actually to the idea of which sampling that I described, and instead of actually doing the which sampling on a graph that fits into memory, it actually does the which sample on in a single Passover the edges stream, and so this method has been shown to perform in practice.",
            "However, even."
        ],
        [
            "And all these types of methods they suffer from a particular problem, which is that most of these sampling designs are particularly designed to sample specific graph properties like triangles or wedges.",
            "And so if you would like to actually generalize beyond triangles, like for example like cycles or four nodes or anything like that, then usually these methods are totally on applicable because they are designed to actually sample certain types of graph properties."
        ],
        [
            "And so driven by these ideas we try to propose a new framework which is called graph sample and hold, and so this framework basically runs over the stream sequentially in."
        ],
        [
            "In a single pass and does not assume any certain order over the stream.",
            "So for each edge we flip a coin with a certain probability and then the probability."
        ],
        [
            "T of selecting the edge would be basically conditional on the stored state or the sample that we have collected so far from the stream.",
            "So if the edges to."
        ],
        [
            "Totally independent of the sample.",
            "Then it will be sampled with some probability P and if the edges actually there's some dependency to the sample that."
        ],
        [
            "We have collected so far it will be sampled with another probability Q.",
            "So the whole idea of this framework is to decompose the sampling process into two functions that you can tune later on based on what kind of graph properties that you are actually interested in.",
            "So one can think that the sampling function or the first function, the sample is basically trying to explore new graph regions that haven't been visited before in the sample and the holding function is trying to explore graph regions that have been.",
            "Actually visited before in the sample."
        ],
        [
            "And so then the question, why do we need to hold?",
            "What if what happens if we just use sampling so?"
        ],
        [
            "In that case, if we make the two functions the same like both the sampling and the holding function would be the same, that means that we will use only one single probability to select the edges, and that would reduce this framework to the uniform random sampling.",
            "And as we have just discussed in the last few minutes, that random sampling in general suffer from a number of limitations."
        ],
        [
            "So the framework actually decomposes into two different steps.",
            "The first step is to is to select the sample.",
            "The second step is to around some unbiased estimators over the sample in order to come up with the unbiased estimates."
        ],
        [
            "So let's try to focus on the sample."
        ],
        [
            "1st, so how can we define the dependencies between the edge and the sample?",
            "So if we start with an empty sample, then we always try to ask the question that whether the edge is actually adjacent to the sample or not.",
            "Which means that one of the nodes that are incident to this edge has been appearing in the sample or not."
        ],
        [
            "So if the answer if the answer is no, then we use the sampling function with probability P. If the answer is yes, then we will use the holding function."
        ],
        [
            "So then we."
        ],
        [
            "Flip a coin with this probability.",
            "If had we update the sample."
        ],
        [
            "Which means we just add the edge and the probability to the same."
        ],
        [
            "Then what if we would like to favor the sample itself to a certain property, like triangles for example?",
            "Then we can actually define multiple dependencies here in the holding function where if the edge is actually closing a triangle, then we sample it with probability one for example, and if the edge is just forming a wedge, then we sample it with probability Q."
        ],
        [
            "So coming to the."
        ],
        [
            "Estimation part we use the Harvest Thomson statistical estimation frame."
        ],
        [
            "And so the idea is that every edge would be attached to the sampling probability that was used to select the edge into the sample, and then we define the selection estimator to be just basically a weight which is inversely proportional to the probability that was used to include the sample.",
            "Include the edge into the sample and then."
        ],
        [
            "And generalize this selection estimator by saying that we have an indicator variable that would equal to 1 if the edge is actually in the sample or not, and then divided by the probability."
        ],
        [
            "So as an example, if the edge hasn't been sampling hasn't been added to the sample, then that means that the estimate would be equals to 0 if the edge was sampled with probability P, then the estimator would be 1 / P, and again, if there was sampled with probability Q would be 1 / Q."
        ],
        [
            "And so this idea is so the selection estimator would be unbiased in the sense that the expected value over a number of trials would be equal to 1."
        ],
        [
            "And so we can use this selection estimator in order to to define actually the estimate of the edge account, which would basically be the summation over the selection estimators of all the edges that appeared in the sample."
        ],
        [
            "So now if we have done this actually for just edges, which is the simplest case?",
            "In general, how can we generalize this to a subset of edges?"
        ],
        [
            "Like triangles or wedges.",
            "So if we assume that we have a subset of edges like J, then the estimator of the subset would be basically the product over the estimators of each edge in the subset, and that's also unbiased according to."
        ],
        [
            "What we said before and then.",
            "So as an example, the estimator over sample triangle would be basically the product over the estimators of all the three edges that appear in the triangle."
        ],
        [
            "So we use this to provide the estimate of the triangle counts, and we also use a similar idea to provide the estimate of the wedge accounts, which would basically be the summation over the estimators of all the triangles that appear in the sample, or the summation of estimators of all the wedges that appear in the sample.",
            "So after we define all these estimators, we"
        ],
        [
            "Also compute the harvest Thompson unbiased variance estimator.",
            "However, I'm not going to have any time to talk about this, so please come to the poster if you are interested in detail.",
            "This unbiased variance variance estimator.",
            "We use it later to compute the confidence bounds."
        ],
        [
            "Our experiments, we have done experiments on different types of graphs from social, Facebook, graphs and web graphs and."
        ],
        [
            "Here so this is 1 example of 1 sample that is actually less than 40,000 edges for the six graphs.",
            "So the first column they represent the actual value.",
            "The second column represents the estimated value and the third column that represented the relative error, which basically the estimated minus the actual divided by the actual and so as we can see for all."
        ],
        [
            "Graphs and all the properties.",
            "The relative error is actually less than 1% for only 40,000 edges of the graph."
        ],
        [
            "We also study.",
            "The convergence properties of this method and so the red line represented the actual and the blue diamonds represent the ratio between the estimated and the actual, so as long as we are close to the red line, that means that the estimate is the estimate is has a good quality and we also compute the confidence bounds.",
            "So the green circles represent the upper and lower confidence bounds.",
            "So as we can see when we vary the sample size by changing the parameters.",
            "The samples converge to to be more tighter bounds around the actual value, and that also is the case for both edge triangle and wedge and global clustering coefficient."
        ],
        [
            "We also compared to the previous work, which is a stream triangles from KDD last year, and so as we can see for the three web graphs, there are is between 7 to 12% and our error is between OH point 2 to oh point 6%.",
            "For almost the same sample size."
        ],
        [
            "Which achieves almost like 92 to 96% improvement.",
            "One more thing to note here is that the streaming triangles method is actually designed for sampling only triangles, and our approach is more generic for to be tuned for different properties."
        ],
        [
            "Finally, in conclusion so.",
            "A sample is representative if the graph properties of interest can be estimated with a known degree over curacy, so the issue is that there is no such like perfect sample that would matter.",
            "All kinds of properties of the population.",
            "This is usually hard to collect in graphs, specifically in graphs.",
            "So instead of collecting this sort of a perfect sample, we can actually define our target is that we would like to estimate these certain properties and try to bias the sample.",
            "To estimate those those sets of properties and in that sense, the sample would be representative of these graph properties.",
            "So we propose this generic framework that has the two functions sampling and hold, which is sort of a flexible way to decompose the sampling process, and this framework is efficient and runs in a single pass streaming and also tries to select the representative sample according to what graph properties of interest that we are.",
            "Interested in, we tried this approach on a number of properties of the graph going from the simplest, which is the number of edges to the hardest, which is the transitivity and the number of triangles and our relative error over the set of experiments that we have performed showed that it's usually it's like generally less than 1% error for a sample size of 40,000 edges."
        ],
        [
            "And so since the graph sample and hold is a very generic framework, so it actually admits the generalizations, so our future work is to actually extend this work to adaptively changing the parameters P&Q according to the stream itself and two in order to maintain a fixed size stored state and also to extend this work to other things like graphics and induced subgraphs.",
            "Which means that instead of like thinking only about triangles like looking.",
            "On for the bigger picture, like what are like, how can we estimate the set of graph let's or induced subgraphs that are greater than three nodes from the stream?",
            "This piece"
        ],
        [
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm just reading from Purdue University computer science Department and this paper is a joint work with negative field.",
                    "label": 0
                },
                {
                    "sent": "Jennifer Neville and Ramona Kompella.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So graphs provide a very rich data representation for various types of networks like social networks, web graphs, and the Internet, and so graph analytics comes at the heart and the foundation of studying all these types of complex networks, however.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Studying complex networks, analyzing them is a very challenging task, an computational intensive, and that's due to their massive size and also due to the fact that many of these networks are actually dynamically streaming overtime.",
                    "label": 0
                },
                {
                    "sent": "And so do to these challenges.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We usually need to collect a sample, which is basically a subset of nodes or edges from which we can study the properties of these graphs.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the main motivation of this paper is that if we have a large graph, this actually are presented as a stream of edges.",
                    "label": 0
                },
                {
                    "sent": "So how to efficiently sample from this graph with while limiting the memory space in order to calculate different unbiased estimates of various graph properties so for.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sample if we have such an edge stream then we can select a subset of the edges that appear in this.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The man from which we can estimate certain graph properties like the number of edges, number of edges and number of triangles, and those three out of the main or the particular focus that we have in this paper, the.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two are actually particularly important because you can compute the global clustering coefficient, which is very representative of the rate of transitivity in the graph.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how this is actually related has been handled in the related work.",
                    "label": 0
                },
                {
                    "sent": "So let's focus first on the sampling part.",
                    "label": 0
                },
                {
                    "sent": "So random sampling is a widely used tool for big data and big graph analytics, and probably some of you have attended the tutorial yesterday which covered in detail the problem of how to use sampling to solve many of these problems, and so one such method that actually suggested to use uniform random sampling which is very simple idea where you.",
                    "label": 0
                },
                {
                    "sent": "You could just do some graph sparsification with a probability that's uniform, so one single probability that can be used.",
                    "label": 1
                },
                {
                    "sent": "However, it has been shown that this method has certain problems, so one of them is that the chains of sampling a sub graph like a triangle is usually very low because we sample and that's due to the fact that we sample independent edges.",
                    "label": 0
                },
                {
                    "sent": "So in fact we have that graph where we sample independent edges, but the goal at the end is to actually capture higher liver patterns like triangles.",
                    "label": 0
                },
                {
                    "sent": "And so the probability would be very low to actually sample that triangle, and so also the estimates that can be driven from these samples usually suffer from a high variance, so other methods have been proposed to solve this sort of problem, and one of them is instead of doing edge sampling, is to actually sample wedges and so the idea is that instead of sampling the edges, we use these sample vertices and for each vertex the sample certain wedges which basically incident edges to this.",
                    "label": 0
                },
                {
                    "sent": "Vertex and so.",
                    "label": 0
                },
                {
                    "sent": "Then after that the output the estimate of the closed wedges or the triangles, however these methods.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In general, suffer from a certain limitation which basically that they assume that the whole graph can fit into memory, which is somehow a limitation for many of the massive graphs that we actually see today.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One simple solution to solve the problem.",
                    "label": 0
                },
                {
                    "sent": "If the graph can't fit in memory, then to use actually stream sampling.",
                    "label": 0
                },
                {
                    "sent": "So which means that if you have that edge stream, you can just sequentially sample from the edges without storing the full graph into the memory.",
                    "label": 0
                },
                {
                    "sent": "However, even stream sampling suffer some limitations in the literature.",
                    "label": 0
                },
                {
                    "sent": "For example, some work assume that there is a specific order of this stream, which means that neighbors of a vertex could arrive altogether like groups together in the stream.",
                    "label": 1
                },
                {
                    "sent": "Other assumptions like that we can do multiple passes over the stream.",
                    "label": 0
                },
                {
                    "sent": "So these sorts of assumptions are somehow a bit unrealistic for certain graphs that we see today, and so recently there has been a lot of focus on single pass algorithms that would just take one pass over the stream and also does not assume any sort of order over the stream.",
                    "label": 0
                },
                {
                    "sent": "So one very well known example of these kinds of methods was a paper that was presented in KDD last year which proposed the idea of a streaming triangles.",
                    "label": 0
                },
                {
                    "sent": "Which is very similar actually to the idea of which sampling that I described, and instead of actually doing the which sampling on a graph that fits into memory, it actually does the which sample on in a single Passover the edges stream, and so this method has been shown to perform in practice.",
                    "label": 0
                },
                {
                    "sent": "However, even.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And all these types of methods they suffer from a particular problem, which is that most of these sampling designs are particularly designed to sample specific graph properties like triangles or wedges.",
                    "label": 0
                },
                {
                    "sent": "And so if you would like to actually generalize beyond triangles, like for example like cycles or four nodes or anything like that, then usually these methods are totally on applicable because they are designed to actually sample certain types of graph properties.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so driven by these ideas we try to propose a new framework which is called graph sample and hold, and so this framework basically runs over the stream sequentially in.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a single pass and does not assume any certain order over the stream.",
                    "label": 0
                },
                {
                    "sent": "So for each edge we flip a coin with a certain probability and then the probability.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "T of selecting the edge would be basically conditional on the stored state or the sample that we have collected so far from the stream.",
                    "label": 0
                },
                {
                    "sent": "So if the edges to.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Totally independent of the sample.",
                    "label": 0
                },
                {
                    "sent": "Then it will be sampled with some probability P and if the edges actually there's some dependency to the sample that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have collected so far it will be sampled with another probability Q.",
                    "label": 0
                },
                {
                    "sent": "So the whole idea of this framework is to decompose the sampling process into two functions that you can tune later on based on what kind of graph properties that you are actually interested in.",
                    "label": 0
                },
                {
                    "sent": "So one can think that the sampling function or the first function, the sample is basically trying to explore new graph regions that haven't been visited before in the sample and the holding function is trying to explore graph regions that have been.",
                    "label": 0
                },
                {
                    "sent": "Actually visited before in the sample.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so then the question, why do we need to hold?",
                    "label": 0
                },
                {
                    "sent": "What if what happens if we just use sampling so?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In that case, if we make the two functions the same like both the sampling and the holding function would be the same, that means that we will use only one single probability to select the edges, and that would reduce this framework to the uniform random sampling.",
                    "label": 0
                },
                {
                    "sent": "And as we have just discussed in the last few minutes, that random sampling in general suffer from a number of limitations.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the framework actually decomposes into two different steps.",
                    "label": 0
                },
                {
                    "sent": "The first step is to is to select the sample.",
                    "label": 0
                },
                {
                    "sent": "The second step is to around some unbiased estimators over the sample in order to come up with the unbiased estimates.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's try to focus on the sample.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1st, so how can we define the dependencies between the edge and the sample?",
                    "label": 0
                },
                {
                    "sent": "So if we start with an empty sample, then we always try to ask the question that whether the edge is actually adjacent to the sample or not.",
                    "label": 0
                },
                {
                    "sent": "Which means that one of the nodes that are incident to this edge has been appearing in the sample or not.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if the answer if the answer is no, then we use the sampling function with probability P. If the answer is yes, then we will use the holding function.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then we.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Flip a coin with this probability.",
                    "label": 0
                },
                {
                    "sent": "If had we update the sample.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which means we just add the edge and the probability to the same.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then what if we would like to favor the sample itself to a certain property, like triangles for example?",
                    "label": 0
                },
                {
                    "sent": "Then we can actually define multiple dependencies here in the holding function where if the edge is actually closing a triangle, then we sample it with probability one for example, and if the edge is just forming a wedge, then we sample it with probability Q.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So coming to the.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Estimation part we use the Harvest Thomson statistical estimation frame.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the idea is that every edge would be attached to the sampling probability that was used to select the edge into the sample, and then we define the selection estimator to be just basically a weight which is inversely proportional to the probability that was used to include the sample.",
                    "label": 0
                },
                {
                    "sent": "Include the edge into the sample and then.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And generalize this selection estimator by saying that we have an indicator variable that would equal to 1 if the edge is actually in the sample or not, and then divided by the probability.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as an example, if the edge hasn't been sampling hasn't been added to the sample, then that means that the estimate would be equals to 0 if the edge was sampled with probability P, then the estimator would be 1 / P, and again, if there was sampled with probability Q would be 1 / Q.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so this idea is so the selection estimator would be unbiased in the sense that the expected value over a number of trials would be equal to 1.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we can use this selection estimator in order to to define actually the estimate of the edge account, which would basically be the summation over the selection estimators of all the edges that appeared in the sample.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now if we have done this actually for just edges, which is the simplest case?",
                    "label": 0
                },
                {
                    "sent": "In general, how can we generalize this to a subset of edges?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like triangles or wedges.",
                    "label": 0
                },
                {
                    "sent": "So if we assume that we have a subset of edges like J, then the estimator of the subset would be basically the product over the estimators of each edge in the subset, and that's also unbiased according to.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we said before and then.",
                    "label": 0
                },
                {
                    "sent": "So as an example, the estimator over sample triangle would be basically the product over the estimators of all the three edges that appear in the triangle.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we use this to provide the estimate of the triangle counts, and we also use a similar idea to provide the estimate of the wedge accounts, which would basically be the summation over the estimators of all the triangles that appear in the sample, or the summation of estimators of all the wedges that appear in the sample.",
                    "label": 0
                },
                {
                    "sent": "So after we define all these estimators, we",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also compute the harvest Thompson unbiased variance estimator.",
                    "label": 0
                },
                {
                    "sent": "However, I'm not going to have any time to talk about this, so please come to the poster if you are interested in detail.",
                    "label": 0
                },
                {
                    "sent": "This unbiased variance variance estimator.",
                    "label": 0
                },
                {
                    "sent": "We use it later to compute the confidence bounds.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our experiments, we have done experiments on different types of graphs from social, Facebook, graphs and web graphs and.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here so this is 1 example of 1 sample that is actually less than 40,000 edges for the six graphs.",
                    "label": 0
                },
                {
                    "sent": "So the first column they represent the actual value.",
                    "label": 0
                },
                {
                    "sent": "The second column represents the estimated value and the third column that represented the relative error, which basically the estimated minus the actual divided by the actual and so as we can see for all.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graphs and all the properties.",
                    "label": 0
                },
                {
                    "sent": "The relative error is actually less than 1% for only 40,000 edges of the graph.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also study.",
                    "label": 0
                },
                {
                    "sent": "The convergence properties of this method and so the red line represented the actual and the blue diamonds represent the ratio between the estimated and the actual, so as long as we are close to the red line, that means that the estimate is the estimate is has a good quality and we also compute the confidence bounds.",
                    "label": 0
                },
                {
                    "sent": "So the green circles represent the upper and lower confidence bounds.",
                    "label": 0
                },
                {
                    "sent": "So as we can see when we vary the sample size by changing the parameters.",
                    "label": 0
                },
                {
                    "sent": "The samples converge to to be more tighter bounds around the actual value, and that also is the case for both edge triangle and wedge and global clustering coefficient.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also compared to the previous work, which is a stream triangles from KDD last year, and so as we can see for the three web graphs, there are is between 7 to 12% and our error is between OH point 2 to oh point 6%.",
                    "label": 0
                },
                {
                    "sent": "For almost the same sample size.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which achieves almost like 92 to 96% improvement.",
                    "label": 0
                },
                {
                    "sent": "One more thing to note here is that the streaming triangles method is actually designed for sampling only triangles, and our approach is more generic for to be tuned for different properties.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, in conclusion so.",
                    "label": 0
                },
                {
                    "sent": "A sample is representative if the graph properties of interest can be estimated with a known degree over curacy, so the issue is that there is no such like perfect sample that would matter.",
                    "label": 0
                },
                {
                    "sent": "All kinds of properties of the population.",
                    "label": 0
                },
                {
                    "sent": "This is usually hard to collect in graphs, specifically in graphs.",
                    "label": 0
                },
                {
                    "sent": "So instead of collecting this sort of a perfect sample, we can actually define our target is that we would like to estimate these certain properties and try to bias the sample.",
                    "label": 0
                },
                {
                    "sent": "To estimate those those sets of properties and in that sense, the sample would be representative of these graph properties.",
                    "label": 0
                },
                {
                    "sent": "So we propose this generic framework that has the two functions sampling and hold, which is sort of a flexible way to decompose the sampling process, and this framework is efficient and runs in a single pass streaming and also tries to select the representative sample according to what graph properties of interest that we are.",
                    "label": 0
                },
                {
                    "sent": "Interested in, we tried this approach on a number of properties of the graph going from the simplest, which is the number of edges to the hardest, which is the transitivity and the number of triangles and our relative error over the set of experiments that we have performed showed that it's usually it's like generally less than 1% error for a sample size of 40,000 edges.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so since the graph sample and hold is a very generic framework, so it actually admits the generalizations, so our future work is to actually extend this work to adaptively changing the parameters P&Q according to the stream itself and two in order to maintain a fixed size stored state and also to extend this work to other things like graphics and induced subgraphs.",
                    "label": 1
                },
                {
                    "sent": "Which means that instead of like thinking only about triangles like looking.",
                    "label": 0
                },
                {
                    "sent": "On for the bigger picture, like what are like, how can we estimate the set of graph let's or induced subgraphs that are greater than three nodes from the stream?",
                    "label": 0
                },
                {
                    "sent": "This piece",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}