{
    "id": "v7akcwiwbkxup72yylzgbri5w2pkt7tc",
    "title": "From Injective Hilbert Space Embeddings to Deconvolution",
    "info": {
        "author": [
            "Bernhard Sch\u00f6lkopf, Max Planck Institute for Biological Cybernetics, Max Planck Institute"
        ],
        "published": "Jan. 12, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Computational Photography"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2010_schoelkopf_ihs/",
    "segmentation": [
        [
            "I'm going to talk about something that I have been thinking about already for a few years, but I never got around to doing something with it.",
            "So actually I wanted to work it out more before I present it.",
            "But let's see, let's see, what do you make of it today?",
            "Is it loud enough?",
            "So."
        ],
        [
            "And I should say this is joint work with a number of people that are here and the number of people that are."
        ],
        [
            "Not here, so payment already gave the definition of positive definite kernel just to remind you it's a for me it's a symmetric function.",
            "Some people don't include this, so it's a symmetric function which whatever points you plug into it will give you a positive definite matrix and positive definite.",
            "I include the case where it can be 0.",
            "Stricter case is in this community.",
            "Here.",
            "I know other people quite differently, called the strictly positive definite case.",
            "So if you think of it as semi definite indefinite here is called definition strictly definite, so strictly positive definite case is the case where this sum only get 0 if all the coefficients are zero.",
            "Assuming the points XI are pairwise testing.",
            "So if the points are repeated then the sum can be 0 anyway.",
            "So the nice thing about positive definite kernels is one can show there's a characterization of positive definite count in terms of a representation in a dot product space.",
            "The characterization says that opposing kernel is positive definite if and only if.",
            "Is that a big box?",
            "Yeah.",
            "Q So kernel is positive definite if and only if there exists a mapping file into some dot product space such that the kernel computes the dot product in that space in this space which has."
        ],
        [
            "Have been mentioned that payment is a reproducing kernel Hilbert space and this is an example of a kernel.",
            "If you take the dot product Canonical dot product between 2 dimensional vectors, X&X prime raised to the power of D. And you just work it out.",
            "You can collect the terms into the X terms here.",
            "The ex prime terms here.",
            "This becomes a big sum over N to the power of the coefficients and this thing here back here.",
            "You can just think of as a dot product after some nonlinear mapping fire and the mapping file you can read off it computes all possible products in the input qualities or input pixels.",
            "If you think of these as images.",
            "So that's one example of a kernel that Maps into a."
        ],
        [
            "Hilbert space of dimension into the power of D and more generally, it can also happen.",
            "You can map into infinite dimensional spaces in the general construction.",
            "Of the mapping is as follows.",
            "We take a point in the input domain.",
            "We map it into a function that we get by substituting the point into the kernel function and considering it as a function of the second argument.",
            "So for instance, if it's a Gaussian kernel.",
            "Find X would be mapped into a Gaussian centered on X.",
            "The point X prime would be mapped into Gaussian center.",
            "The next prime and then we have to define a dot product in that space, so that's a space of Hilbert space of functions, or so far it's just a vector space of functions.",
            "We define the dot product which satisfies this property here, so the DOT product between these two kernel functions is itself computed as the value of the kernel function evaluated in X&X prime.",
            "And when control this is a dot product and one more property that I will need later on is the fact that the kernel represents point evaluation.",
            "So if you take the dot product between the kernel in some arbitrary function.",
            "You recover the value of the function at that point, so this is a non unusual Hilbert space values of functions."
        ],
        [
            "Individual points are well defined.",
            "And I will very soon get to image processing.",
            "Don't worry, so it's I'm not going to give you standard kernel talk here.",
            "This is an example that led to this link to image processing from the first chapter of our book where I was thinking about what's the most trivial kernel algorithm that could give as a as an introduction in this trivial algorithm, it is a pattern recognition algorithm.",
            "You have two sets of points, the pluses, the circles you compute the means of this set and of this set of the positive class and negative class in the reproducing kernel space.",
            "So you map them into the space using this prescription from before.",
            "Compute the mean and then given a new point, you just check whether it's closer to this mean or closer to this mean.",
            "So you map this new point also into the reproducing kernel space, compute the distance and you get a classifier that looks like this and it's 1000 Windows Plug-in classic file, so it computes a Windows estimates of the density of the positive class, the negative class and uses that for classification.",
            "Now you can ask yourself what happens if this vector is 0.",
            "Then of course it doesn't work.",
            "So for instance, if you directly did this in the input space, this trivial classifier and your two classes had the same mean, you will be stuffed.",
            "So."
        ],
        [
            "This is actually a starting point for an interesting question.",
            "Question is, how much information does this mapping mule?"
        ],
        [
            "So we think of it as a mapping mapping that takes a set of points and Maps it into the.",
            "Mean of those points."
        ],
        [
            "In the dark ages.",
            "So how much information does this mapping contain?",
            "Not in the linear case where we don't do any mapping to the future space, or we just use a different trivial kernel that just contains the information about the mean.",
            "That's clear.",
            "Now if we use a polynomial kernel of this form, it's if you think about it for a minute, it's easy to see that the mapping actually computes all empirical moments up to order the so it computes mean covariance structure and so on.",
            "Depending on how big it is.",
            "And somewhat surprisingly, or maybe not if we look at it in this sequence, is that if the kernel is sufficiently nonlinear, sufficiently rich in some sense, and insufficiently, which in this case means it's strictly positive definite, then it turns out that.",
            "Is a bit misleading.",
            "I should have rewritten this.",
            "It turns out that the mapping does not lose any information, so it contains information about the whole data set X, so you can reconstruct the whole data set from that one point in the Hilbert space.",
            "So the mean if you compute the mean in this rich space, then it actually remembers each point that contributed to it.",
            "And this can be generalized to probability measurements and I will show you."
        ],
        [
            "Briefly, but."
        ],
        [
            "First I want to maybe briefly proof.",
            "That's in the case of strictly positive definite kernels we do."
        ],
        [
            "Lose any information.",
            "So what we're going to do?",
            "Because it's such a short proof?",
            "Cooper slightly more general proposition in the statement is that if the kernel is strictly positive definite, and we assume that in the sets of X&Y, there are no repeated points.",
            "And the proof is going to say if I can write a linear combination of the points in the set X which equals a linear combination of the points in the set Y.",
            "And this linear equations are the same.",
            "Then the points have to be the same if you consider the special case that these alphas are just.",
            "So this is just the mean of this point.",
            "X mean of the points.",
            "Why then we have the statement from before in the proof is as follows.",
            "So by contradiction we first we assume there is a point in the set X which does not appear in the set Y.",
            "So let's subtract this sum from the left hand side and then we make it a sum over distinct points.",
            "So it's possible that some points why appear in the set X.",
            "So we're going to remove those.",
            "And then we will get something like this and the set is now the union of these.",
            "Points X&Y of course.",
            "By doing this, some of the coefficients might have magically magically become zero, because they might appear in both sets, but it is important to know that at least one of the coefficients did not become zero.",
            "So.",
            "So let's say this is the one.",
            "This is the number one, because we assume that number one is not in the set.",
            "Why so?",
            "The coefficient of X one is still there and it's still non 0.",
            "So we assume that all coefficients are non 0.",
            "Otherwise it's sort of trivial to add additional points.",
            "So we now have this equation here and we know that at least gamma one is not zero.",
            "We take now that we take the dot product with the same thing again.",
            "At the DOT product in the Hilbert space, we use this identity so the kernel represents point evaluation.",
            "Also when applied to another kernel then we get this quantity here and we know that this is true even though at least one of the gammas is non zero and that exactly means that K is not strictly positive definite.",
            "So."
        ],
        [
            "Hope this didn't take too much time.",
            "So we know that this mean mapping that takes a set of points Maps it into the representative space is invertible or injective, and we can give the same mapping.",
            "So we're going through this mapping will later on play the role of an imaging mapping.",
            "So now we will do the same.",
            "So far we can do image Ng four sets of Delta Peaks if you want.",
            "It's not so interesting.",
            "We want to do imaging with real images.",
            "So let's think of our images as parental probability measures.",
            "So what we're going to do is we'll define this mapping that takes a probability measure and Maps it into.",
            "The expectation with respect to that measure of the feature mapping or of the kernel functions.",
            "So in the sense for each input point, each input point gets mapped into a function.",
            "But then they get weighted in the feature space according to how likely they are under this probability measure.",
            "So this again is 1 function in the reproducing kernel Hilbert space.",
            "If we have certain conditions satisfied for the kernel, then this function.",
            "Actually this expectation exists.",
            "And one thing to point out at this point is.",
            "And if you think of this, this is an integral over the kernel, and if there's a density over the density or over the measure.",
            "If you think of this integral, then of course if the kernel is a shift invariant one which is not untypical, then this is the convolution of the density.",
            "If there is a density in the kernel.",
            "So before I showed you that we have injectivity.",
            "Question of course is do we still have injectivity in this very rich case?",
            "Is it still the case that this one point in the vector space contains all?"
        ],
        [
            "Patient about the measure that you put in.",
            "And maybe somewhat surprisingly, this is still the case.",
            "The original statement that we proved sometime ago was for the case where the kernels are universal in the sense of shame, but so that's an approximation property of the Hilbert spaces tends in the set of continuous functions.",
            "This is something standard came up with for proving consistency of support vector machines, but actually it's true for a slightly larger class of kernels which we have later called characteristic kernels."
        ],
        [
            "So.",
            "2 examples of that kernel Maps, so one is from statistics.",
            "This is the so called moment generating function of a random variable with Dist distribution P. So in this case you take a kernel.",
            "This is actually known to be a universal kernel, just exponent of the product.",
            "Then take the expectation this thing is well known in statistics because from this you can reconstruct if it exists, you can reconstruct all moments of the distribution of a random variable.",
            "Here's the example from optics.",
            "So we consider a setup where we are imaging through an aperture.",
            "This is I is the indicator function of the aperture.",
            "Now, of course, if we have a point source over here and we image it through this aperture, we all know that we get this sync function back here.",
            "If we have an extended source of incoherent light, what we're going to get is back here.",
            "The convolution of the sync function with the distribution of our extended source.",
            "And this is all in the setting of found hover diffraction sort of the infinite distance limit where things workout so simply and then so the intensity image will be convolution of P and the four year transform squared of this because we're looking at the intensity before you transform squared of this aperture function.",
            "So this is what we're going to get.",
            "And of course if you remember what I showed you before about the kernel mapping, if we choose our kernel to be this thing.",
            "Or we can do this the convolution of the indicator function with itself.",
            "That's a so called B spline kernel.",
            "The simplest baseline kernel.",
            "It is shift invariant.",
            "It's also positive definite.",
            "That's due to a famous theorem from functional analysis to Bochner theorem, which says that for your transforms of non negative measures are positive definite kernels.",
            "So this is this is a triangle function.",
            "This convolution of this indicator function of the aperture with itself, it's just a little pyramid, so that's positive or non negative.",
            "So if we set this to be our kernel, it's supposed to different kernel and.",
            "This mapping from the input image to what we get here is exactly this kernel mean mapping.",
            "So now it's it's interesting to have this link because we can think about what this kind of mapping has been used in kernel methods in different domains.",
            "For instance, in two sample testing, independence testing and we have studied a number of properties.",
            "So for instance, if we look at 2 sample testing where we have two samples of points, we want to decide are they from the same distribution or from different distributions and there it's it's very important to know whether the mapping is invertible, otherwise we lose information and we're not going to get a statistical tests.",
            "So we looked in the past.",
            "We have looked a lot into questions of invertibility of this mapping and.",
            "So now the ideas can be reused this for imaging to say something interesting about the imaging process and the main message of the talk will be first of all consistent with what people believe in optics imaging process.",
            "In such a setup with the finite aperture is not invertible in general.",
            "But maybe somewhat surprising, it becomes invertible if we restrict the class of distributions that with that we put in.",
            "So I've been discussing this with."
        ],
        [
            "Some physicists into optics and I'm getting mixed messages as to whether it's surprising and not.",
            "The usual reaction is first they tell me that's impossible, and then when I explained it some point they say.",
            "Well actually, maybe maybe it's trivial, so it's I wonder whether it's something in between.",
            "Let's see, so it would be.",
            "I would be very interested in your feedback because I'm sure there are people in the audience.",
            "We know a lot more about optics than I do, so my optics knowledge is from physics degree 20 years ago.",
            "So let's look at it a little bit more in detail.",
            "So we, in the simplest case, if we assume the identity is all everything that I said so far, works for Borel probability measures.",
            "But if the densities exist against Colonel Shift invariant, we assume also all free transform exists, then I can give you some intuition for what makes it non invertible.",
            "So the mapping the mean mapping to be invertible means.",
            "That if we map a distribution P or identity P now into this kernel space and we do the same for Q and we get the same point in our space, then it has to be the case that P is equal to Q.",
            "So that means invertibility.",
            "Now let's write this out here.",
            "So here we have the convolution of CNP here.",
            "OK in Q.",
            "And we want that this identity implies P equal to Q.",
            "Now we can rewrite this.",
            "We can take the Fourier transform to get this equation here with the closure L identity which tells us.",
            "First of all, if the Fourier transform of the kernel has full support, then we can just divide by this thing.",
            "And then invert the Fourier.",
            "Transform so if the.",
            "If they had the Fourier transform of K has full support and this I did.",
            "This implication is certainly true.",
            "So then we can invert the thing.",
            "Now, unfortunately or Fortunately, otherwise people wouldn't believe me.",
            "The Fourier transform will not have full support in the kernel that I showed you in the last slide, because it will.",
            "It's just this triangular function, so if the aperture is finite, I convolve the aperture itself.",
            "I don't get full support unless the aperture is infinitely large, in which case of course it becomes invertible, so this is consistent with what we know so far.",
            "Now, maybe somewhat more surprising is if we take a continuous kernel function with compact support, then the shorts Paley Wiener theorem, it's four year transform will have full support the whole real line.",
            "So that means if we were able to build an aperture which is not just from an indicator function, but somehow which leads to a continuous K with compact support, then maybe it would be invertible and.",
            "So that's the first message.",
            "Second messages.",
            "Now suppose we want to stick with this kind of aperture, which is what we usually do with just an opening.",
            "Is it maybe possible to somehow restrict the class of images that we put in such that things become invertible after all?"
        ],
        [
            "And the answer is yes.",
            "The condition that we need in this case is actually a fairly reasonable condition, so that for the kernel we only need the condition that.",
            "The.",
            "For you transform of the kernel has a nonempty the support of the Fourier transform of the kernel has nonempty interior, so it at least contains an open set, so it's in our case, this means the aperture is not zero.",
            "It's a finite aperture.",
            "Ender so in this case.",
            "Of course, the mapping is not invertible in general, but it turns out as a consequence of a theorem that we proved in a different context.",
            "The mapping becomes invertible for all distributions that have compact support.",
            "So if we restrict ourselves images that have compact support and if we know that beforehand, then from a mathematical point of view things should be invertible.",
            "So that's.",
            "So the reason why people initially usually say it's impossible is viscous because of these upper characterizations, or.",
            "Well, I think maybe we can just discuss that afterwards, so.",
            "Yeah.",
            "So if we if we translate this back just to summarize again, the font for diffraction aperture imaging process is not invertible for the class of all light sources, but it is if we restrict the class, for instance, to compact support and maybe even more trivial cases.",
            "Suppose you restrict the class you suppose you knew there's only two Delta peaks in your image.",
            "Then of course I think basically you could always invert it, because you can just.",
            "You just look whether the sync functions are so that's this statement is basically a generalization of that."
        ],
        [
            "Now, if it's invertible and now I'm going to shift gears.",
            "So this was the mathematical part of the talk.",
            "Now the rest of the talk will just be a images and maybe a few videos when you just cut me off whenever I should finish.",
            "How much time is there like 10 minutes?",
            "Now suppose it is invertible.",
            "How do we do it?",
            "That's a process, of course.",
            "The problem of deconvolution, so I'm going to show you some examples of the kind of work we do in deconvolution in my lap, and this is mostly work of Steven who are here in the audience.",
            "So it's because this would I showed you so far was mathematics and with statements about when is it invertible and when it is not.",
            "But it doesn't say anything so far about how to invert it."
        ],
        [
            "OK, you know all about deconvolution so this is an example of a non trivial point spread function.",
            "This is the point spread function that the Hubble Space Telescope's camera ahead at the beginning before they did corrections, so this is."
        ],
        [
            "Pretty nontrivial one, and one interesting one problem that we start with in typical, maybe two or three years ago was this problem of ground based astronomy.",
            "So the problem where the light travel you have some light front that comes in.",
            "You assume that is out in space.",
            "It's planar, but then it passes through several layers of turbulence and the wavefronts gets get perturbed and then you get nontrivial point spread functions that actually change very fast.",
            "At the same time scale as these things.",
            "It's turbulences."
        ],
        [
            "Change.",
            "And the problem that we looked at was multiframe deconvolution.",
            "So the basic idea was that we assume out there in space there is an image which is stationary and we observe the image through turbulence.",
            "There's a convolution, we observe something like this.",
            "And S at time progresses.",
            "This thing continuously changes.",
            "But we know that this thing doesn't change, so does that give us information to recover all these point spread functions and to recover the true image."
        ],
        [
            "And of course the answer is yes.",
            "We rephrase this as an optimized as an online learning problem, so we have these obvious batch optimization problem which we can solve in an online fashion by alternating between optimizing for F and optimizing for X and."
        ],
        [
            "So let me just show you some images.",
            "So here the first image.",
            "We set the.",
            "We set the hypothetical true image to be equal to the observed image and then we get the second image computer point spread function.",
            "Update the hypothetical true image and keep going and you can see that this keeps getting sharper after 10 steps.",
            "It's already pretty good."
        ],
        [
            "He steps 30 steps.",
            "So this was also applied to images of extended objects, so this is a thing.",
            "Is the Copernicus crater on the moon likely you correct me if I'm wrong?",
            "This is an example sequence of observed frames.",
            "This was, I think the sequence was longer.",
            "This is the visually best frame from the sequence.",
            "This is using a method called registax, which tries to pick good good images and averages them and sharpens them.",
            "This is a more sophisticated method used in astronomy, Knox, Thompson, deconvolution.",
            "This is our method online band deconvolution.",
            "This is if we also put in some super resolution so I should say."
        ],
        [
            "This model, once one has a nice image."
        ],
        [
            "Formation model like this one can also put in other things.",
            "For instance, we can put in other linear operations in here and we can."
        ],
        [
            "Put in the downsampling operation and try to recover a true image."
        ],
        [
            "Is higher resolution than what we observe?",
            "In this case we get an image like that and then we had his later compared it also to some.",
            "Imagery from the Lunar Orbiter and verified that."
        ],
        [
            "This structure is actually real, so this is another example of."
        ],
        [
            "Synthetic"
        ],
        [
            "Wait, this is a synthetic.",
            "Case."
        ],
        [
            "Let's skip this one.",
            "We also can put in not just the downsampling operation, but we can also put in a clipping operation, so it's sometimes the case that a sensor eclipse image intensity, especially for stars which are point sources.",
            "And that's also a relatively simple operation which we can add to the generative model and then try to reconstruct the full dynamic range image, because in a sense, if you have a point source which is which is smeared out, then of course in the sides which are the sensor is not saturated, you have information about how high the peak in the middle should be, even though it exceeded the dynamic dynamic range of the sensor.",
            "And that worked also quite well.",
            "So here we have an observed from.",
            "You see these typical bloated styles that you get in astronomical imaging where a large areas it might be saturated and then we can do with saturation correction.",
            "Get a higher than mid range.",
            "We can even combine it with super resolution."
        ],
        [
            "So here's an extension to space to the space variant case, but."
        ],
        [
            "Still a multi frame setup so we have input is a video, so this is the raw sequence taken from the roof of our building through the exhaust of an air conditioning system.",
            "And here you can see the reconstruction, which already after relatively few images.",
            "So this is a blind reconstruction is almost as good or maybe as good as the ground truth.",
            "Here's another application from biomedical imaging magnetic resonance imaging.",
            "This is the heart of a mouse and this is a slice through the mouse and you see the heart beating.",
            "But you also see some movement artifacts here.",
            "If we apply it in this case.",
            "Of course now the assumption that the true images stationary is not quite true, but you see it managed to make it stationary and to make it relatively sharp and OK, I guess you can still see a little bit at the heart is trying to move.",
            "But we were quite surprised with this with these results, and so where our collaborators there are.",
            "Physicists, so I'm going to skip this."
        ],
        [
            "One because this was presented at the main conference and end with a few images, few teasers for a project which we have done more recently which is now under review.",
            "And this is in the area of lens error correction.",
            "So if we have the nonstationary case where the point spread function is allowed to vary over the image.",
            "Then of course we can also apply this with some modifications to the case.",
            "Where we want to remove optical aberrations from imaging systems of both monochromatic and chromatic operations.",
            "We basically we said we measure a set of point spread functions characterizing a lens and then try to recover correct image by doing non blind deconvolution.",
            "And here we have an image, so I think this is the original image.",
            "This was taken with a Canon 50 millimeter lens, fully open aperture 1.4."
        ],
        [
            "This is the correction that we get if you apply a package called DX.",
            "Oh, which is something that professional photographers do.",
            "So Dxo has a set of combinations of cameras and lenses that days of pre tested so built into the system and if you select the right combination it will try to do the optimal correction for this combination.",
            "In next I'm going to show you."
        ],
        [
            "Our correction, which is this one.",
            "So maybe at this resolution we don't see."
        ],
        [
            "It's a well, but I think I have a magnified view, so this is the original image so you can see, even though this is a reasonably good lens, it has a pretty bad image quality."
        ],
        [
            "In the corners this is the Dxo correction which also gets brighter because the lens has."
        ],
        [
            "Wrong vignetting, this is our correction, so I think you can probably see that it's better than Dxo, or at least visually it seems sharper."
        ],
        [
            "See more of the structure that would here we have."
        ],
        [
            "Detail.",
            "You know, very last thing, so me and Steven and Christian, who was also involved in this.",
            "They actually did something that I thought wouldn't work.",
            "They built their own lens just with one piece of glass.",
            "So this is a really, really crappy lens and also measured that lens and try to just try to see how the system method breaks.",
            "People tell us, usually in image processing and photography or late vision conferences you have to show where your method breaks, so we try to be good reason scientists even though we machine learning people.",
            "So we did it with this lens and."
        ],
        [
            "This lens of course makes really really crappy images, so this is an image taken.",
            "You see out here is very blurry, and when they then did the correction and show me the results, I really couldn't believe it."
        ],
        [
            "Because they really look quite impressive.",
            "So maybe."
        ],
        [
            "Show you again."
        ],
        [
            "The original."
        ],
        [
            "And I think it's clear that if you do a non stationary."
        ],
        [
            "Conclusion I don't have the point spread functions here, but they are very very much of the image if you try to do this with stationary deconvolution, you're stuffed.",
            "So I think I'm going to skip this.",
            "This was an application in cryo EM electron microscopy imaging.",
            "And get to the conclusions.",
            "So I think one aspect of kernel methods that we haven't used so much in machine learning, but maybe we should be using Morris.",
            "That the kernel is just a Green's function, so it's the point response of a system, and I think optics is a beautiful example where we can exploit this analogy.",
            "And that's what I've done in this talk.",
            "So I've showed you a kernel representation.",
            "Off the imaging process.",
            "Which exploits this analogy?",
            "I showed you some conditions on the invertibility of the imaging process, and maybe the main point is that if we have prior knowledge about the source distribution, then we can actually get imaging processes that are invertible even if the aperture is only finitely large.",
            "And show you some examples of deconvolution.",
            "Thank you very much.",
            "So we have time for questions.",
            "Yes, question about the online deconvolution.",
            "It seems that the process would be sensitive to the order in which you process the frames.",
            "So it depends which, so the method doesn't use too much.",
            "We have different versions of this method, but vanilla method does not depend on it too much.",
            "I think we have some results that I don't have here in the slides, but in principle of course one could even argue if when if the video camera is fast enough then subsequent blur kernels should not be independent of each other.",
            "And once we actually use this information, so right now we're not using this match, we implicitly using it.",
            "A little bit, but not much so.",
            "In principle, yes it should.",
            "So the.",
            "And we have enough time to optimize the blocker.",
            "Observations in the broken.",
            "This kind of over determined since it was much larger than the broken.",
            "So maybe it speed things up if you have a good initialization from the previous time step, but the result is very similar no matter way so.",
            "Yes, so in Prometric radio astronomy conclusions are big.",
            "Thing that they have to do?",
            "Have you done any work on applying that we have not done anything with radio astronomers?",
            "Actually, it would be very interesting we have.",
            "We are in contact with novel light astronomers.",
            "And where I think is also an important topic, because the adaptive optics we usually you need, either you needn't star which is nearby and which almost never exists.",
            "A bright enough stars such that image very fast.",
            "Or you need an artificial GuideStar and which also has some problems so so these things are easier in infrared, but it doesn't work everywhere, so I think I think, well, we certainly hope that this can be useful for astronomy, and we've shown it to some astronomers and they like that stuff in.",
            "But Radioastronomy, I think that would also be cool here.",
            "New.",
            "Simple examples, sources with compact support for which using process.",
            "Well, I think if the support is compact it must be invertible always.",
            "Facebook.",
            "On compact supports images.",
            "Oh well, for not for apertures because basically what this is saying is, no matter how small the apertures if you are imaging through an aperture you're not losing information provided you know that support is compact.",
            "Now if it's a different kind of imaging process, minor trivial example would be if the kernel is 0, so the temperature is closed, but that's of course mathematically this would come out.",
            "At.",
            "I think.",
            "If one were able to build apertures that are not just indicator functions.",
            "Then I think.",
            "What if one constructs a kernel which has a discrete spectrum?",
            "Something like this that should work.",
            "So that should be a case which is not invertible.",
            "Yeah.",
            "It will feel OK, which is your there supposed to be positive, right?",
            "So when you pick this career path from the zeros?",
            "Thanks for your transfer.",
            "It is so certainly if you if you take the aperture then you will have zeros, yeah?",
            "Exactly the zeros.",
            "I'm assuming restrict well.",
            "The nice thing is, if you the distributions have compact supports, you will be invertible.",
            "Yes, because they cannot, yeah.",
            "But it also says that if your distribution if you cannot.",
            "No.",
            "What was the value of three transformer of density at where the where the kernel vanished?",
            "We have plans for America if the kernel.",
            "Very small.",
            "Those locations are also highly so that's that's an important image.",
            "Now if we wanted to use this somehow in practice, maybe two.",
            "Yeah so.",
            "Then the numerical aspects might be relevant as well now.",
            "So then maybe so, I'm not sure yet whether this is just a mathematical statement or whether.",
            "That sort of shows the importance of using multiple frames is when you have multiple frames where point spread function moves the zeroes that you're talking about actually don't occur in the same spot in each rank, so you get information from across different friends, and you can then recover.",
            "That's right.",
            "Yeah, so for practical practice this makes a difference in.",
            "I don't know whether that's true but mean you right?",
            "I guess that's the current really destroys frequency content that those frequencies are going right, but not quite knowledge about your image.",
            "Yeah, then you.",
            "Then you can do something about it, like for example an interest.",
            "You want to have all the frequencies to be in phase and by that you kind of can recover the frequencies that are destroyed.",
            "And maybe I think.",
            "Exactly, yeah, so that was the motivation.",
            "Also in this other domain.",
            "So we start looking at these problems for two sample testing and at the time I was thinking if we have prior knowledge there must be something we could do.",
            "I was surprised that the prior knowledge that one needs to have is so generic in week so that already with this very basic prior knowledge only you have compact support.",
            "You can do so much so that still possible to me somehow.",
            "OK, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to talk about something that I have been thinking about already for a few years, but I never got around to doing something with it.",
                    "label": 0
                },
                {
                    "sent": "So actually I wanted to work it out more before I present it.",
                    "label": 0
                },
                {
                    "sent": "But let's see, let's see, what do you make of it today?",
                    "label": 0
                },
                {
                    "sent": "Is it loud enough?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I should say this is joint work with a number of people that are here and the number of people that are.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not here, so payment already gave the definition of positive definite kernel just to remind you it's a for me it's a symmetric function.",
                    "label": 0
                },
                {
                    "sent": "Some people don't include this, so it's a symmetric function which whatever points you plug into it will give you a positive definite matrix and positive definite.",
                    "label": 0
                },
                {
                    "sent": "I include the case where it can be 0.",
                    "label": 0
                },
                {
                    "sent": "Stricter case is in this community.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "I know other people quite differently, called the strictly positive definite case.",
                    "label": 0
                },
                {
                    "sent": "So if you think of it as semi definite indefinite here is called definition strictly definite, so strictly positive definite case is the case where this sum only get 0 if all the coefficients are zero.",
                    "label": 0
                },
                {
                    "sent": "Assuming the points XI are pairwise testing.",
                    "label": 0
                },
                {
                    "sent": "So if the points are repeated then the sum can be 0 anyway.",
                    "label": 0
                },
                {
                    "sent": "So the nice thing about positive definite kernels is one can show there's a characterization of positive definite count in terms of a representation in a dot product space.",
                    "label": 1
                },
                {
                    "sent": "The characterization says that opposing kernel is positive definite if and only if.",
                    "label": 0
                },
                {
                    "sent": "Is that a big box?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Q So kernel is positive definite if and only if there exists a mapping file into some dot product space such that the kernel computes the dot product in that space in this space which has.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have been mentioned that payment is a reproducing kernel Hilbert space and this is an example of a kernel.",
                    "label": 0
                },
                {
                    "sent": "If you take the dot product Canonical dot product between 2 dimensional vectors, X&X prime raised to the power of D. And you just work it out.",
                    "label": 0
                },
                {
                    "sent": "You can collect the terms into the X terms here.",
                    "label": 0
                },
                {
                    "sent": "The ex prime terms here.",
                    "label": 0
                },
                {
                    "sent": "This becomes a big sum over N to the power of the coefficients and this thing here back here.",
                    "label": 0
                },
                {
                    "sent": "You can just think of as a dot product after some nonlinear mapping fire and the mapping file you can read off it computes all possible products in the input qualities or input pixels.",
                    "label": 0
                },
                {
                    "sent": "If you think of these as images.",
                    "label": 0
                },
                {
                    "sent": "So that's one example of a kernel that Maps into a.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hilbert space of dimension into the power of D and more generally, it can also happen.",
                    "label": 1
                },
                {
                    "sent": "You can map into infinite dimensional spaces in the general construction.",
                    "label": 0
                },
                {
                    "sent": "Of the mapping is as follows.",
                    "label": 0
                },
                {
                    "sent": "We take a point in the input domain.",
                    "label": 0
                },
                {
                    "sent": "We map it into a function that we get by substituting the point into the kernel function and considering it as a function of the second argument.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if it's a Gaussian kernel.",
                    "label": 0
                },
                {
                    "sent": "Find X would be mapped into a Gaussian centered on X.",
                    "label": 0
                },
                {
                    "sent": "The point X prime would be mapped into Gaussian center.",
                    "label": 0
                },
                {
                    "sent": "The next prime and then we have to define a dot product in that space, so that's a space of Hilbert space of functions, or so far it's just a vector space of functions.",
                    "label": 0
                },
                {
                    "sent": "We define the dot product which satisfies this property here, so the DOT product between these two kernel functions is itself computed as the value of the kernel function evaluated in X&X prime.",
                    "label": 0
                },
                {
                    "sent": "And when control this is a dot product and one more property that I will need later on is the fact that the kernel represents point evaluation.",
                    "label": 0
                },
                {
                    "sent": "So if you take the dot product between the kernel in some arbitrary function.",
                    "label": 0
                },
                {
                    "sent": "You recover the value of the function at that point, so this is a non unusual Hilbert space values of functions.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Individual points are well defined.",
                    "label": 0
                },
                {
                    "sent": "And I will very soon get to image processing.",
                    "label": 0
                },
                {
                    "sent": "Don't worry, so it's I'm not going to give you standard kernel talk here.",
                    "label": 0
                },
                {
                    "sent": "This is an example that led to this link to image processing from the first chapter of our book where I was thinking about what's the most trivial kernel algorithm that could give as a as an introduction in this trivial algorithm, it is a pattern recognition algorithm.",
                    "label": 1
                },
                {
                    "sent": "You have two sets of points, the pluses, the circles you compute the means of this set and of this set of the positive class and negative class in the reproducing kernel space.",
                    "label": 0
                },
                {
                    "sent": "So you map them into the space using this prescription from before.",
                    "label": 0
                },
                {
                    "sent": "Compute the mean and then given a new point, you just check whether it's closer to this mean or closer to this mean.",
                    "label": 0
                },
                {
                    "sent": "So you map this new point also into the reproducing kernel space, compute the distance and you get a classifier that looks like this and it's 1000 Windows Plug-in classic file, so it computes a Windows estimates of the density of the positive class, the negative class and uses that for classification.",
                    "label": 0
                },
                {
                    "sent": "Now you can ask yourself what happens if this vector is 0.",
                    "label": 0
                },
                {
                    "sent": "Then of course it doesn't work.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if you directly did this in the input space, this trivial classifier and your two classes had the same mean, you will be stuffed.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is actually a starting point for an interesting question.",
                    "label": 0
                },
                {
                    "sent": "Question is, how much information does this mapping mule?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we think of it as a mapping mapping that takes a set of points and Maps it into the.",
                    "label": 0
                },
                {
                    "sent": "Mean of those points.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the dark ages.",
                    "label": 0
                },
                {
                    "sent": "So how much information does this mapping contain?",
                    "label": 0
                },
                {
                    "sent": "Not in the linear case where we don't do any mapping to the future space, or we just use a different trivial kernel that just contains the information about the mean.",
                    "label": 0
                },
                {
                    "sent": "That's clear.",
                    "label": 0
                },
                {
                    "sent": "Now if we use a polynomial kernel of this form, it's if you think about it for a minute, it's easy to see that the mapping actually computes all empirical moments up to order the so it computes mean covariance structure and so on.",
                    "label": 0
                },
                {
                    "sent": "Depending on how big it is.",
                    "label": 0
                },
                {
                    "sent": "And somewhat surprisingly, or maybe not if we look at it in this sequence, is that if the kernel is sufficiently nonlinear, sufficiently rich in some sense, and insufficiently, which in this case means it's strictly positive definite, then it turns out that.",
                    "label": 0
                },
                {
                    "sent": "Is a bit misleading.",
                    "label": 0
                },
                {
                    "sent": "I should have rewritten this.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the mapping does not lose any information, so it contains information about the whole data set X, so you can reconstruct the whole data set from that one point in the Hilbert space.",
                    "label": 0
                },
                {
                    "sent": "So the mean if you compute the mean in this rich space, then it actually remembers each point that contributed to it.",
                    "label": 0
                },
                {
                    "sent": "And this can be generalized to probability measurements and I will show you.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Briefly, but.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First I want to maybe briefly proof.",
                    "label": 0
                },
                {
                    "sent": "That's in the case of strictly positive definite kernels we do.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lose any information.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do?",
                    "label": 0
                },
                {
                    "sent": "Because it's such a short proof?",
                    "label": 0
                },
                {
                    "sent": "Cooper slightly more general proposition in the statement is that if the kernel is strictly positive definite, and we assume that in the sets of X&Y, there are no repeated points.",
                    "label": 0
                },
                {
                    "sent": "And the proof is going to say if I can write a linear combination of the points in the set X which equals a linear combination of the points in the set Y.",
                    "label": 0
                },
                {
                    "sent": "And this linear equations are the same.",
                    "label": 0
                },
                {
                    "sent": "Then the points have to be the same if you consider the special case that these alphas are just.",
                    "label": 0
                },
                {
                    "sent": "So this is just the mean of this point.",
                    "label": 0
                },
                {
                    "sent": "X mean of the points.",
                    "label": 0
                },
                {
                    "sent": "Why then we have the statement from before in the proof is as follows.",
                    "label": 0
                },
                {
                    "sent": "So by contradiction we first we assume there is a point in the set X which does not appear in the set Y.",
                    "label": 0
                },
                {
                    "sent": "So let's subtract this sum from the left hand side and then we make it a sum over distinct points.",
                    "label": 0
                },
                {
                    "sent": "So it's possible that some points why appear in the set X.",
                    "label": 0
                },
                {
                    "sent": "So we're going to remove those.",
                    "label": 0
                },
                {
                    "sent": "And then we will get something like this and the set is now the union of these.",
                    "label": 0
                },
                {
                    "sent": "Points X&Y of course.",
                    "label": 0
                },
                {
                    "sent": "By doing this, some of the coefficients might have magically magically become zero, because they might appear in both sets, but it is important to know that at least one of the coefficients did not become zero.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So let's say this is the one.",
                    "label": 0
                },
                {
                    "sent": "This is the number one, because we assume that number one is not in the set.",
                    "label": 0
                },
                {
                    "sent": "Why so?",
                    "label": 0
                },
                {
                    "sent": "The coefficient of X one is still there and it's still non 0.",
                    "label": 0
                },
                {
                    "sent": "So we assume that all coefficients are non 0.",
                    "label": 0
                },
                {
                    "sent": "Otherwise it's sort of trivial to add additional points.",
                    "label": 0
                },
                {
                    "sent": "So we now have this equation here and we know that at least gamma one is not zero.",
                    "label": 0
                },
                {
                    "sent": "We take now that we take the dot product with the same thing again.",
                    "label": 0
                },
                {
                    "sent": "At the DOT product in the Hilbert space, we use this identity so the kernel represents point evaluation.",
                    "label": 0
                },
                {
                    "sent": "Also when applied to another kernel then we get this quantity here and we know that this is true even though at least one of the gammas is non zero and that exactly means that K is not strictly positive definite.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hope this didn't take too much time.",
                    "label": 0
                },
                {
                    "sent": "So we know that this mean mapping that takes a set of points Maps it into the representative space is invertible or injective, and we can give the same mapping.",
                    "label": 0
                },
                {
                    "sent": "So we're going through this mapping will later on play the role of an imaging mapping.",
                    "label": 0
                },
                {
                    "sent": "So now we will do the same.",
                    "label": 0
                },
                {
                    "sent": "So far we can do image Ng four sets of Delta Peaks if you want.",
                    "label": 0
                },
                {
                    "sent": "It's not so interesting.",
                    "label": 0
                },
                {
                    "sent": "We want to do imaging with real images.",
                    "label": 0
                },
                {
                    "sent": "So let's think of our images as parental probability measures.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do is we'll define this mapping that takes a probability measure and Maps it into.",
                    "label": 0
                },
                {
                    "sent": "The expectation with respect to that measure of the feature mapping or of the kernel functions.",
                    "label": 0
                },
                {
                    "sent": "So in the sense for each input point, each input point gets mapped into a function.",
                    "label": 0
                },
                {
                    "sent": "But then they get weighted in the feature space according to how likely they are under this probability measure.",
                    "label": 0
                },
                {
                    "sent": "So this again is 1 function in the reproducing kernel Hilbert space.",
                    "label": 0
                },
                {
                    "sent": "If we have certain conditions satisfied for the kernel, then this function.",
                    "label": 0
                },
                {
                    "sent": "Actually this expectation exists.",
                    "label": 0
                },
                {
                    "sent": "And one thing to point out at this point is.",
                    "label": 0
                },
                {
                    "sent": "And if you think of this, this is an integral over the kernel, and if there's a density over the density or over the measure.",
                    "label": 0
                },
                {
                    "sent": "If you think of this integral, then of course if the kernel is a shift invariant one which is not untypical, then this is the convolution of the density.",
                    "label": 0
                },
                {
                    "sent": "If there is a density in the kernel.",
                    "label": 0
                },
                {
                    "sent": "So before I showed you that we have injectivity.",
                    "label": 0
                },
                {
                    "sent": "Question of course is do we still have injectivity in this very rich case?",
                    "label": 0
                },
                {
                    "sent": "Is it still the case that this one point in the vector space contains all?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Patient about the measure that you put in.",
                    "label": 0
                },
                {
                    "sent": "And maybe somewhat surprisingly, this is still the case.",
                    "label": 0
                },
                {
                    "sent": "The original statement that we proved sometime ago was for the case where the kernels are universal in the sense of shame, but so that's an approximation property of the Hilbert spaces tends in the set of continuous functions.",
                    "label": 0
                },
                {
                    "sent": "This is something standard came up with for proving consistency of support vector machines, but actually it's true for a slightly larger class of kernels which we have later called characteristic kernels.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "2 examples of that kernel Maps, so one is from statistics.",
                    "label": 0
                },
                {
                    "sent": "This is the so called moment generating function of a random variable with Dist distribution P. So in this case you take a kernel.",
                    "label": 1
                },
                {
                    "sent": "This is actually known to be a universal kernel, just exponent of the product.",
                    "label": 0
                },
                {
                    "sent": "Then take the expectation this thing is well known in statistics because from this you can reconstruct if it exists, you can reconstruct all moments of the distribution of a random variable.",
                    "label": 0
                },
                {
                    "sent": "Here's the example from optics.",
                    "label": 1
                },
                {
                    "sent": "So we consider a setup where we are imaging through an aperture.",
                    "label": 1
                },
                {
                    "sent": "This is I is the indicator function of the aperture.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, if we have a point source over here and we image it through this aperture, we all know that we get this sync function back here.",
                    "label": 0
                },
                {
                    "sent": "If we have an extended source of incoherent light, what we're going to get is back here.",
                    "label": 0
                },
                {
                    "sent": "The convolution of the sync function with the distribution of our extended source.",
                    "label": 0
                },
                {
                    "sent": "And this is all in the setting of found hover diffraction sort of the infinite distance limit where things workout so simply and then so the intensity image will be convolution of P and the four year transform squared of this because we're looking at the intensity before you transform squared of this aperture function.",
                    "label": 0
                },
                {
                    "sent": "So this is what we're going to get.",
                    "label": 0
                },
                {
                    "sent": "And of course if you remember what I showed you before about the kernel mapping, if we choose our kernel to be this thing.",
                    "label": 0
                },
                {
                    "sent": "Or we can do this the convolution of the indicator function with itself.",
                    "label": 0
                },
                {
                    "sent": "That's a so called B spline kernel.",
                    "label": 0
                },
                {
                    "sent": "The simplest baseline kernel.",
                    "label": 1
                },
                {
                    "sent": "It is shift invariant.",
                    "label": 0
                },
                {
                    "sent": "It's also positive definite.",
                    "label": 0
                },
                {
                    "sent": "That's due to a famous theorem from functional analysis to Bochner theorem, which says that for your transforms of non negative measures are positive definite kernels.",
                    "label": 0
                },
                {
                    "sent": "So this is this is a triangle function.",
                    "label": 0
                },
                {
                    "sent": "This convolution of this indicator function of the aperture with itself, it's just a little pyramid, so that's positive or non negative.",
                    "label": 0
                },
                {
                    "sent": "So if we set this to be our kernel, it's supposed to different kernel and.",
                    "label": 0
                },
                {
                    "sent": "This mapping from the input image to what we get here is exactly this kernel mean mapping.",
                    "label": 0
                },
                {
                    "sent": "So now it's it's interesting to have this link because we can think about what this kind of mapping has been used in kernel methods in different domains.",
                    "label": 0
                },
                {
                    "sent": "For instance, in two sample testing, independence testing and we have studied a number of properties.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if we look at 2 sample testing where we have two samples of points, we want to decide are they from the same distribution or from different distributions and there it's it's very important to know whether the mapping is invertible, otherwise we lose information and we're not going to get a statistical tests.",
                    "label": 0
                },
                {
                    "sent": "So we looked in the past.",
                    "label": 1
                },
                {
                    "sent": "We have looked a lot into questions of invertibility of this mapping and.",
                    "label": 0
                },
                {
                    "sent": "So now the ideas can be reused this for imaging to say something interesting about the imaging process and the main message of the talk will be first of all consistent with what people believe in optics imaging process.",
                    "label": 0
                },
                {
                    "sent": "In such a setup with the finite aperture is not invertible in general.",
                    "label": 1
                },
                {
                    "sent": "But maybe somewhat surprising, it becomes invertible if we restrict the class of distributions that with that we put in.",
                    "label": 0
                },
                {
                    "sent": "So I've been discussing this with.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some physicists into optics and I'm getting mixed messages as to whether it's surprising and not.",
                    "label": 0
                },
                {
                    "sent": "The usual reaction is first they tell me that's impossible, and then when I explained it some point they say.",
                    "label": 0
                },
                {
                    "sent": "Well actually, maybe maybe it's trivial, so it's I wonder whether it's something in between.",
                    "label": 0
                },
                {
                    "sent": "Let's see, so it would be.",
                    "label": 0
                },
                {
                    "sent": "I would be very interested in your feedback because I'm sure there are people in the audience.",
                    "label": 0
                },
                {
                    "sent": "We know a lot more about optics than I do, so my optics knowledge is from physics degree 20 years ago.",
                    "label": 0
                },
                {
                    "sent": "So let's look at it a little bit more in detail.",
                    "label": 0
                },
                {
                    "sent": "So we, in the simplest case, if we assume the identity is all everything that I said so far, works for Borel probability measures.",
                    "label": 0
                },
                {
                    "sent": "But if the densities exist against Colonel Shift invariant, we assume also all free transform exists, then I can give you some intuition for what makes it non invertible.",
                    "label": 0
                },
                {
                    "sent": "So the mapping the mean mapping to be invertible means.",
                    "label": 0
                },
                {
                    "sent": "That if we map a distribution P or identity P now into this kernel space and we do the same for Q and we get the same point in our space, then it has to be the case that P is equal to Q.",
                    "label": 0
                },
                {
                    "sent": "So that means invertibility.",
                    "label": 0
                },
                {
                    "sent": "Now let's write this out here.",
                    "label": 0
                },
                {
                    "sent": "So here we have the convolution of CNP here.",
                    "label": 0
                },
                {
                    "sent": "OK in Q.",
                    "label": 0
                },
                {
                    "sent": "And we want that this identity implies P equal to Q.",
                    "label": 0
                },
                {
                    "sent": "Now we can rewrite this.",
                    "label": 0
                },
                {
                    "sent": "We can take the Fourier transform to get this equation here with the closure L identity which tells us.",
                    "label": 0
                },
                {
                    "sent": "First of all, if the Fourier transform of the kernel has full support, then we can just divide by this thing.",
                    "label": 0
                },
                {
                    "sent": "And then invert the Fourier.",
                    "label": 0
                },
                {
                    "sent": "Transform so if the.",
                    "label": 0
                },
                {
                    "sent": "If they had the Fourier transform of K has full support and this I did.",
                    "label": 0
                },
                {
                    "sent": "This implication is certainly true.",
                    "label": 0
                },
                {
                    "sent": "So then we can invert the thing.",
                    "label": 0
                },
                {
                    "sent": "Now, unfortunately or Fortunately, otherwise people wouldn't believe me.",
                    "label": 0
                },
                {
                    "sent": "The Fourier transform will not have full support in the kernel that I showed you in the last slide, because it will.",
                    "label": 0
                },
                {
                    "sent": "It's just this triangular function, so if the aperture is finite, I convolve the aperture itself.",
                    "label": 0
                },
                {
                    "sent": "I don't get full support unless the aperture is infinitely large, in which case of course it becomes invertible, so this is consistent with what we know so far.",
                    "label": 0
                },
                {
                    "sent": "Now, maybe somewhat more surprising is if we take a continuous kernel function with compact support, then the shorts Paley Wiener theorem, it's four year transform will have full support the whole real line.",
                    "label": 0
                },
                {
                    "sent": "So that means if we were able to build an aperture which is not just from an indicator function, but somehow which leads to a continuous K with compact support, then maybe it would be invertible and.",
                    "label": 1
                },
                {
                    "sent": "So that's the first message.",
                    "label": 0
                },
                {
                    "sent": "Second messages.",
                    "label": 0
                },
                {
                    "sent": "Now suppose we want to stick with this kind of aperture, which is what we usually do with just an opening.",
                    "label": 0
                },
                {
                    "sent": "Is it maybe possible to somehow restrict the class of images that we put in such that things become invertible after all?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the answer is yes.",
                    "label": 0
                },
                {
                    "sent": "The condition that we need in this case is actually a fairly reasonable condition, so that for the kernel we only need the condition that.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "For you transform of the kernel has a nonempty the support of the Fourier transform of the kernel has nonempty interior, so it at least contains an open set, so it's in our case, this means the aperture is not zero.",
                    "label": 0
                },
                {
                    "sent": "It's a finite aperture.",
                    "label": 0
                },
                {
                    "sent": "Ender so in this case.",
                    "label": 0
                },
                {
                    "sent": "Of course, the mapping is not invertible in general, but it turns out as a consequence of a theorem that we proved in a different context.",
                    "label": 0
                },
                {
                    "sent": "The mapping becomes invertible for all distributions that have compact support.",
                    "label": 1
                },
                {
                    "sent": "So if we restrict ourselves images that have compact support and if we know that beforehand, then from a mathematical point of view things should be invertible.",
                    "label": 0
                },
                {
                    "sent": "So that's.",
                    "label": 0
                },
                {
                    "sent": "So the reason why people initially usually say it's impossible is viscous because of these upper characterizations, or.",
                    "label": 0
                },
                {
                    "sent": "Well, I think maybe we can just discuss that afterwards, so.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So if we if we translate this back just to summarize again, the font for diffraction aperture imaging process is not invertible for the class of all light sources, but it is if we restrict the class, for instance, to compact support and maybe even more trivial cases.",
                    "label": 1
                },
                {
                    "sent": "Suppose you restrict the class you suppose you knew there's only two Delta peaks in your image.",
                    "label": 0
                },
                {
                    "sent": "Then of course I think basically you could always invert it, because you can just.",
                    "label": 0
                },
                {
                    "sent": "You just look whether the sync functions are so that's this statement is basically a generalization of that.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, if it's invertible and now I'm going to shift gears.",
                    "label": 0
                },
                {
                    "sent": "So this was the mathematical part of the talk.",
                    "label": 0
                },
                {
                    "sent": "Now the rest of the talk will just be a images and maybe a few videos when you just cut me off whenever I should finish.",
                    "label": 0
                },
                {
                    "sent": "How much time is there like 10 minutes?",
                    "label": 0
                },
                {
                    "sent": "Now suppose it is invertible.",
                    "label": 1
                },
                {
                    "sent": "How do we do it?",
                    "label": 0
                },
                {
                    "sent": "That's a process, of course.",
                    "label": 0
                },
                {
                    "sent": "The problem of deconvolution, so I'm going to show you some examples of the kind of work we do in deconvolution in my lap, and this is mostly work of Steven who are here in the audience.",
                    "label": 0
                },
                {
                    "sent": "So it's because this would I showed you so far was mathematics and with statements about when is it invertible and when it is not.",
                    "label": 0
                },
                {
                    "sent": "But it doesn't say anything so far about how to invert it.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, you know all about deconvolution so this is an example of a non trivial point spread function.",
                    "label": 0
                },
                {
                    "sent": "This is the point spread function that the Hubble Space Telescope's camera ahead at the beginning before they did corrections, so this is.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pretty nontrivial one, and one interesting one problem that we start with in typical, maybe two or three years ago was this problem of ground based astronomy.",
                    "label": 0
                },
                {
                    "sent": "So the problem where the light travel you have some light front that comes in.",
                    "label": 0
                },
                {
                    "sent": "You assume that is out in space.",
                    "label": 0
                },
                {
                    "sent": "It's planar, but then it passes through several layers of turbulence and the wavefronts gets get perturbed and then you get nontrivial point spread functions that actually change very fast.",
                    "label": 0
                },
                {
                    "sent": "At the same time scale as these things.",
                    "label": 0
                },
                {
                    "sent": "It's turbulences.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Change.",
                    "label": 0
                },
                {
                    "sent": "And the problem that we looked at was multiframe deconvolution.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea was that we assume out there in space there is an image which is stationary and we observe the image through turbulence.",
                    "label": 0
                },
                {
                    "sent": "There's a convolution, we observe something like this.",
                    "label": 0
                },
                {
                    "sent": "And S at time progresses.",
                    "label": 0
                },
                {
                    "sent": "This thing continuously changes.",
                    "label": 0
                },
                {
                    "sent": "But we know that this thing doesn't change, so does that give us information to recover all these point spread functions and to recover the true image.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of course the answer is yes.",
                    "label": 0
                },
                {
                    "sent": "We rephrase this as an optimized as an online learning problem, so we have these obvious batch optimization problem which we can solve in an online fashion by alternating between optimizing for F and optimizing for X and.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me just show you some images.",
                    "label": 0
                },
                {
                    "sent": "So here the first image.",
                    "label": 0
                },
                {
                    "sent": "We set the.",
                    "label": 0
                },
                {
                    "sent": "We set the hypothetical true image to be equal to the observed image and then we get the second image computer point spread function.",
                    "label": 0
                },
                {
                    "sent": "Update the hypothetical true image and keep going and you can see that this keeps getting sharper after 10 steps.",
                    "label": 0
                },
                {
                    "sent": "It's already pretty good.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He steps 30 steps.",
                    "label": 0
                },
                {
                    "sent": "So this was also applied to images of extended objects, so this is a thing.",
                    "label": 0
                },
                {
                    "sent": "Is the Copernicus crater on the moon likely you correct me if I'm wrong?",
                    "label": 0
                },
                {
                    "sent": "This is an example sequence of observed frames.",
                    "label": 0
                },
                {
                    "sent": "This was, I think the sequence was longer.",
                    "label": 0
                },
                {
                    "sent": "This is the visually best frame from the sequence.",
                    "label": 0
                },
                {
                    "sent": "This is using a method called registax, which tries to pick good good images and averages them and sharpens them.",
                    "label": 0
                },
                {
                    "sent": "This is a more sophisticated method used in astronomy, Knox, Thompson, deconvolution.",
                    "label": 0
                },
                {
                    "sent": "This is our method online band deconvolution.",
                    "label": 0
                },
                {
                    "sent": "This is if we also put in some super resolution so I should say.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This model, once one has a nice image.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Formation model like this one can also put in other things.",
                    "label": 0
                },
                {
                    "sent": "For instance, we can put in other linear operations in here and we can.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Put in the downsampling operation and try to recover a true image.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is higher resolution than what we observe?",
                    "label": 0
                },
                {
                    "sent": "In this case we get an image like that and then we had his later compared it also to some.",
                    "label": 0
                },
                {
                    "sent": "Imagery from the Lunar Orbiter and verified that.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This structure is actually real, so this is another example of.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Synthetic",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wait, this is a synthetic.",
                    "label": 0
                },
                {
                    "sent": "Case.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's skip this one.",
                    "label": 0
                },
                {
                    "sent": "We also can put in not just the downsampling operation, but we can also put in a clipping operation, so it's sometimes the case that a sensor eclipse image intensity, especially for stars which are point sources.",
                    "label": 0
                },
                {
                    "sent": "And that's also a relatively simple operation which we can add to the generative model and then try to reconstruct the full dynamic range image, because in a sense, if you have a point source which is which is smeared out, then of course in the sides which are the sensor is not saturated, you have information about how high the peak in the middle should be, even though it exceeded the dynamic dynamic range of the sensor.",
                    "label": 0
                },
                {
                    "sent": "And that worked also quite well.",
                    "label": 0
                },
                {
                    "sent": "So here we have an observed from.",
                    "label": 0
                },
                {
                    "sent": "You see these typical bloated styles that you get in astronomical imaging where a large areas it might be saturated and then we can do with saturation correction.",
                    "label": 1
                },
                {
                    "sent": "Get a higher than mid range.",
                    "label": 0
                },
                {
                    "sent": "We can even combine it with super resolution.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's an extension to space to the space variant case, but.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Still a multi frame setup so we have input is a video, so this is the raw sequence taken from the roof of our building through the exhaust of an air conditioning system.",
                    "label": 0
                },
                {
                    "sent": "And here you can see the reconstruction, which already after relatively few images.",
                    "label": 0
                },
                {
                    "sent": "So this is a blind reconstruction is almost as good or maybe as good as the ground truth.",
                    "label": 0
                },
                {
                    "sent": "Here's another application from biomedical imaging magnetic resonance imaging.",
                    "label": 0
                },
                {
                    "sent": "This is the heart of a mouse and this is a slice through the mouse and you see the heart beating.",
                    "label": 0
                },
                {
                    "sent": "But you also see some movement artifacts here.",
                    "label": 0
                },
                {
                    "sent": "If we apply it in this case.",
                    "label": 0
                },
                {
                    "sent": "Of course now the assumption that the true images stationary is not quite true, but you see it managed to make it stationary and to make it relatively sharp and OK, I guess you can still see a little bit at the heart is trying to move.",
                    "label": 0
                },
                {
                    "sent": "But we were quite surprised with this with these results, and so where our collaborators there are.",
                    "label": 0
                },
                {
                    "sent": "Physicists, so I'm going to skip this.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One because this was presented at the main conference and end with a few images, few teasers for a project which we have done more recently which is now under review.",
                    "label": 0
                },
                {
                    "sent": "And this is in the area of lens error correction.",
                    "label": 0
                },
                {
                    "sent": "So if we have the nonstationary case where the point spread function is allowed to vary over the image.",
                    "label": 0
                },
                {
                    "sent": "Then of course we can also apply this with some modifications to the case.",
                    "label": 0
                },
                {
                    "sent": "Where we want to remove optical aberrations from imaging systems of both monochromatic and chromatic operations.",
                    "label": 0
                },
                {
                    "sent": "We basically we said we measure a set of point spread functions characterizing a lens and then try to recover correct image by doing non blind deconvolution.",
                    "label": 0
                },
                {
                    "sent": "And here we have an image, so I think this is the original image.",
                    "label": 0
                },
                {
                    "sent": "This was taken with a Canon 50 millimeter lens, fully open aperture 1.4.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the correction that we get if you apply a package called DX.",
                    "label": 0
                },
                {
                    "sent": "Oh, which is something that professional photographers do.",
                    "label": 0
                },
                {
                    "sent": "So Dxo has a set of combinations of cameras and lenses that days of pre tested so built into the system and if you select the right combination it will try to do the optimal correction for this combination.",
                    "label": 0
                },
                {
                    "sent": "In next I'm going to show you.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our correction, which is this one.",
                    "label": 0
                },
                {
                    "sent": "So maybe at this resolution we don't see.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a well, but I think I have a magnified view, so this is the original image so you can see, even though this is a reasonably good lens, it has a pretty bad image quality.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the corners this is the Dxo correction which also gets brighter because the lens has.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wrong vignetting, this is our correction, so I think you can probably see that it's better than Dxo, or at least visually it seems sharper.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See more of the structure that would here we have.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Detail.",
                    "label": 0
                },
                {
                    "sent": "You know, very last thing, so me and Steven and Christian, who was also involved in this.",
                    "label": 0
                },
                {
                    "sent": "They actually did something that I thought wouldn't work.",
                    "label": 0
                },
                {
                    "sent": "They built their own lens just with one piece of glass.",
                    "label": 0
                },
                {
                    "sent": "So this is a really, really crappy lens and also measured that lens and try to just try to see how the system method breaks.",
                    "label": 0
                },
                {
                    "sent": "People tell us, usually in image processing and photography or late vision conferences you have to show where your method breaks, so we try to be good reason scientists even though we machine learning people.",
                    "label": 0
                },
                {
                    "sent": "So we did it with this lens and.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This lens of course makes really really crappy images, so this is an image taken.",
                    "label": 0
                },
                {
                    "sent": "You see out here is very blurry, and when they then did the correction and show me the results, I really couldn't believe it.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because they really look quite impressive.",
                    "label": 0
                },
                {
                    "sent": "So maybe.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Show you again.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The original.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I think it's clear that if you do a non stationary.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Conclusion I don't have the point spread functions here, but they are very very much of the image if you try to do this with stationary deconvolution, you're stuffed.",
                    "label": 0
                },
                {
                    "sent": "So I think I'm going to skip this.",
                    "label": 0
                },
                {
                    "sent": "This was an application in cryo EM electron microscopy imaging.",
                    "label": 0
                },
                {
                    "sent": "And get to the conclusions.",
                    "label": 0
                },
                {
                    "sent": "So I think one aspect of kernel methods that we haven't used so much in machine learning, but maybe we should be using Morris.",
                    "label": 0
                },
                {
                    "sent": "That the kernel is just a Green's function, so it's the point response of a system, and I think optics is a beautiful example where we can exploit this analogy.",
                    "label": 0
                },
                {
                    "sent": "And that's what I've done in this talk.",
                    "label": 0
                },
                {
                    "sent": "So I've showed you a kernel representation.",
                    "label": 0
                },
                {
                    "sent": "Off the imaging process.",
                    "label": 0
                },
                {
                    "sent": "Which exploits this analogy?",
                    "label": 0
                },
                {
                    "sent": "I showed you some conditions on the invertibility of the imaging process, and maybe the main point is that if we have prior knowledge about the source distribution, then we can actually get imaging processes that are invertible even if the aperture is only finitely large.",
                    "label": 0
                },
                {
                    "sent": "And show you some examples of deconvolution.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "So we have time for questions.",
                    "label": 0
                },
                {
                    "sent": "Yes, question about the online deconvolution.",
                    "label": 0
                },
                {
                    "sent": "It seems that the process would be sensitive to the order in which you process the frames.",
                    "label": 0
                },
                {
                    "sent": "So it depends which, so the method doesn't use too much.",
                    "label": 0
                },
                {
                    "sent": "We have different versions of this method, but vanilla method does not depend on it too much.",
                    "label": 0
                },
                {
                    "sent": "I think we have some results that I don't have here in the slides, but in principle of course one could even argue if when if the video camera is fast enough then subsequent blur kernels should not be independent of each other.",
                    "label": 0
                },
                {
                    "sent": "And once we actually use this information, so right now we're not using this match, we implicitly using it.",
                    "label": 0
                },
                {
                    "sent": "A little bit, but not much so.",
                    "label": 0
                },
                {
                    "sent": "In principle, yes it should.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "And we have enough time to optimize the blocker.",
                    "label": 0
                },
                {
                    "sent": "Observations in the broken.",
                    "label": 0
                },
                {
                    "sent": "This kind of over determined since it was much larger than the broken.",
                    "label": 0
                },
                {
                    "sent": "So maybe it speed things up if you have a good initialization from the previous time step, but the result is very similar no matter way so.",
                    "label": 0
                },
                {
                    "sent": "Yes, so in Prometric radio astronomy conclusions are big.",
                    "label": 0
                },
                {
                    "sent": "Thing that they have to do?",
                    "label": 0
                },
                {
                    "sent": "Have you done any work on applying that we have not done anything with radio astronomers?",
                    "label": 0
                },
                {
                    "sent": "Actually, it would be very interesting we have.",
                    "label": 0
                },
                {
                    "sent": "We are in contact with novel light astronomers.",
                    "label": 0
                },
                {
                    "sent": "And where I think is also an important topic, because the adaptive optics we usually you need, either you needn't star which is nearby and which almost never exists.",
                    "label": 0
                },
                {
                    "sent": "A bright enough stars such that image very fast.",
                    "label": 0
                },
                {
                    "sent": "Or you need an artificial GuideStar and which also has some problems so so these things are easier in infrared, but it doesn't work everywhere, so I think I think, well, we certainly hope that this can be useful for astronomy, and we've shown it to some astronomers and they like that stuff in.",
                    "label": 0
                },
                {
                    "sent": "But Radioastronomy, I think that would also be cool here.",
                    "label": 0
                },
                {
                    "sent": "New.",
                    "label": 0
                },
                {
                    "sent": "Simple examples, sources with compact support for which using process.",
                    "label": 0
                },
                {
                    "sent": "Well, I think if the support is compact it must be invertible always.",
                    "label": 0
                },
                {
                    "sent": "Facebook.",
                    "label": 0
                },
                {
                    "sent": "On compact supports images.",
                    "label": 0
                },
                {
                    "sent": "Oh well, for not for apertures because basically what this is saying is, no matter how small the apertures if you are imaging through an aperture you're not losing information provided you know that support is compact.",
                    "label": 0
                },
                {
                    "sent": "Now if it's a different kind of imaging process, minor trivial example would be if the kernel is 0, so the temperature is closed, but that's of course mathematically this would come out.",
                    "label": 0
                },
                {
                    "sent": "At.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "If one were able to build apertures that are not just indicator functions.",
                    "label": 0
                },
                {
                    "sent": "Then I think.",
                    "label": 0
                },
                {
                    "sent": "What if one constructs a kernel which has a discrete spectrum?",
                    "label": 0
                },
                {
                    "sent": "Something like this that should work.",
                    "label": 0
                },
                {
                    "sent": "So that should be a case which is not invertible.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "It will feel OK, which is your there supposed to be positive, right?",
                    "label": 0
                },
                {
                    "sent": "So when you pick this career path from the zeros?",
                    "label": 0
                },
                {
                    "sent": "Thanks for your transfer.",
                    "label": 0
                },
                {
                    "sent": "It is so certainly if you if you take the aperture then you will have zeros, yeah?",
                    "label": 0
                },
                {
                    "sent": "Exactly the zeros.",
                    "label": 0
                },
                {
                    "sent": "I'm assuming restrict well.",
                    "label": 0
                },
                {
                    "sent": "The nice thing is, if you the distributions have compact supports, you will be invertible.",
                    "label": 0
                },
                {
                    "sent": "Yes, because they cannot, yeah.",
                    "label": 0
                },
                {
                    "sent": "But it also says that if your distribution if you cannot.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "What was the value of three transformer of density at where the where the kernel vanished?",
                    "label": 0
                },
                {
                    "sent": "We have plans for America if the kernel.",
                    "label": 0
                },
                {
                    "sent": "Very small.",
                    "label": 0
                },
                {
                    "sent": "Those locations are also highly so that's that's an important image.",
                    "label": 0
                },
                {
                    "sent": "Now if we wanted to use this somehow in practice, maybe two.",
                    "label": 0
                },
                {
                    "sent": "Yeah so.",
                    "label": 0
                },
                {
                    "sent": "Then the numerical aspects might be relevant as well now.",
                    "label": 0
                },
                {
                    "sent": "So then maybe so, I'm not sure yet whether this is just a mathematical statement or whether.",
                    "label": 0
                },
                {
                    "sent": "That sort of shows the importance of using multiple frames is when you have multiple frames where point spread function moves the zeroes that you're talking about actually don't occur in the same spot in each rank, so you get information from across different friends, and you can then recover.",
                    "label": 0
                },
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so for practical practice this makes a difference in.",
                    "label": 0
                },
                {
                    "sent": "I don't know whether that's true but mean you right?",
                    "label": 0
                },
                {
                    "sent": "I guess that's the current really destroys frequency content that those frequencies are going right, but not quite knowledge about your image.",
                    "label": 0
                },
                {
                    "sent": "Yeah, then you.",
                    "label": 0
                },
                {
                    "sent": "Then you can do something about it, like for example an interest.",
                    "label": 0
                },
                {
                    "sent": "You want to have all the frequencies to be in phase and by that you kind of can recover the frequencies that are destroyed.",
                    "label": 0
                },
                {
                    "sent": "And maybe I think.",
                    "label": 0
                },
                {
                    "sent": "Exactly, yeah, so that was the motivation.",
                    "label": 0
                },
                {
                    "sent": "Also in this other domain.",
                    "label": 0
                },
                {
                    "sent": "So we start looking at these problems for two sample testing and at the time I was thinking if we have prior knowledge there must be something we could do.",
                    "label": 0
                },
                {
                    "sent": "I was surprised that the prior knowledge that one needs to have is so generic in week so that already with this very basic prior knowledge only you have compact support.",
                    "label": 0
                },
                {
                    "sent": "You can do so much so that still possible to me somehow.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}