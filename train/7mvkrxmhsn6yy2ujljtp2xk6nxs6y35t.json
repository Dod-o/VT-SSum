{
    "id": "7mvkrxmhsn6yy2ujljtp2xk6nxs6y35t",
    "title": "Non-Euclidean Dissimilarities: Causes and Informativeness",
    "info": {
        "author": [
            "Marco Loog, Pattern Recognition Laboratory, Delft University of Technology (TU Delft)"
        ],
        "published": "Sept. 13, 2010",
        "recorded": "August 2010",
        "category": [
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/ssspr2010_loog_ned/",
    "segmentation": [
        [
            "So it doesn't really matter that much what the picture actually shows.",
            "I just took one nice picture from collection of photographs I made.",
            "And if you look at typical images like this and it doesn't really matter whether it's image or whether you see it in real life.",
            "If people observe a scene like this, you might actually wonder things like very basic things like so.",
            "Can you give me what the distance is between this little girl?",
            "Whatever she wants to do with the Matchbox and the actual Matchbox?",
            "Well, I hope that you more or less all agree with me that probably the distance between this Matchbox and the girl.",
            "Is 0 girls holding the matchbox?",
            "Another distance that we might be interested in is what's the distance between the girl and the ground while she's standing on the floor.",
            "So I guess we can all agree here that the distance between the girl and the floor is 0.",
            "Now, what is the distance between the matchbox and the floor?",
            "While it seems to be.",
            "Someone higher up.",
            "I don't know how tall this girl is.",
            "But at least it's clearly non 0.",
            "And I guess with many scenes that you can see around you, you have the same kind of configuration.",
            "People are with their elbows on the table, so the people might have a distance 0 to the table.",
            "There's a water bottle on the table.",
            "The water bottle is has a distance of 0 to the table.",
            "But the distance between this person and the water bottle might be larger than 0.",
            "Thing that you should note from this.",
            "Is that it's a typically used kind of distance measure between objects.",
            "But it's actually heavily non Euclidean.",
            "In fact, it's even more metric in this case because it clearly violates the triangular inequality.",
            "Oh, that's not.",
            "OK."
        ],
        [
            "So this talk is going to be about non Euclidean dissimilarity's causes an informal informativeness."
        ],
        [
            "Bob down should actually be giving this talk, but while I will not dwell on the reasons for us absence, allies, Korth Ring it, and it's going to be as presented by me, marchelo.",
            "So I'm part of Bob's Group, or maybe slowly on Bob is going to be part of my group.",
            "But OK, there's discussion about this.",
            "We both found out University of Technology in the Netherlands, an ally.",
            "She is at the Mansion universe, Manchester University at the UK.",
            "So they wrote the paper.",
            "I try to make more or less old slides myself so you can partly complain to me partly."
        ],
        [
            "I have to complain to Bob, probably.",
            "Of course there's no need for me to point out that I'm the so called Messenger.",
            "OK, I'll drill a bit more on on indeed just to also show you some further images.",
            "Indeed, you see it everywhere.",
            "Distance from the windows from take any window in this wall.",
            "The distance from this window from every window to the wall is 0.",
            "The distance between the windows is typically non zero.",
            "We here again would describe this and we use distance that is known."
        ],
        [
            "Lydian again nonmetric even.",
            "Distance from the backpack to the Walker is 0. the Walker is on this snowfield and the distance is zero.",
            "However, the backpack has a positive distance to the snowfield with dealing with a non metric this similarity measure.",
            "Another thing also in street."
        ],
        [
            "Change scenes this applies.",
            "There's a black Berry on a bench.",
            "There's a woman sitting on the bench.",
            "Both have zero distance to the bench.",
            "The black Berry and woman are on a positive distance, so there's no motricity here.",
            "Or maybe the black Berry is huge and touching.",
            "The woman that I.",
            "Think it's only a small one.",
            "Maybe a bit."
        ],
        [
            "Overkill, but to demonstrate you that it also works in more abstract settings.",
            "These two sculptures they have a distance from each other while they're both have a distance of 0 to their pedestal.",
            "And finally, yet another work of art somewhere in New York."
        ],
        [
            "So this frame.",
            "As a distance of 0 to the wall, a distance of 0 to the floor, and actually in this case there's no kind of metric violation becausw, we could claim that the distance between the floor and the wall is actually also zero.",
            "But this seems a bit strange.",
            "I mean we have three objects.",
            "They all have distance zero to each other.",
            "Typically, if we would be in the typical feature space that we we treat, our pattern recognition problems in, we would actually decide that these three objects that they're basically the same object, which is clearly not the case here."
        ],
        [
            "So what I'm actually going to talk about?",
            "Well, first I'll give a brief overview or slight introduction to dissimilarity based pattern recognition.",
            "I'll discuss a bit about dissimilarity space, embedding of the similarities, or distance matrices I briefly touch upon pseudo Euclidean spaces."
        ],
        [
            "And then I actually come to the two major points, let's say or two messages.",
            "The causes of non Euclidean A's.",
            "And how informative these similarities actually are, and I'll end with some conclusions if time permits.",
            "So let's consider the typical pattern recognition system.",
            "We have some sensors by mid by means we which."
        ],
        [
            "By which means we sense some object.",
            "We need to somehow represent.",
            "By means of what the output of these sounds, we need to represent this object, typically in a future space, and from that we can do a classification, generalization, etc.",
            "So the point is about mainly about this middle block here.",
            "The representation bond, so indeed mostly probably everybody here is familiar with feature based better recognition.",
            "You represent an object or you try to represent an object as a feature you extract from images, particular features, texture, features, whatever.",
            "You try to represent it.",
            "By means of features, sometimes you try to relax this a bit.",
            "Do this kind of bag of words, representations you multiple instance learning, but still even in these typically you assume that you have, from the subcomponents you have from vector vectorial kind of representation.",
            "The alternative that, well, maybe in other areas of science there may be more use with the Alternative Institute, or at least when it comes to this statistical pattern recognition people from the structural side.",
            "They are more more used to the alternative of pairwise similarities.",
            "This can be so bad this analysis mainly basically means we don't represent an object by feature vector, but we describe an object by how it relates to all other objects in our training sets.",
            "Typically this is expert constructed and some people so Edelman in his book actually considers this pairwise dissimilarity based approach to be in a way more fundamental than feature based approach.",
            "Well, I wouldn't say the archetypical classifier to use in the dissimilarity based."
        ],
        [
            "Approaches, for example, if their expert defined these similarities.",
            "The way you go about doing classification with this in the typical way is that you actually do a nearest neighbor kind of classification.",
            "So the simple idea is.",
            "This is my matrix of Dissimilarity's, so here are seven objects.",
            "Set out like this and this and I can calculate all their dis similarities.",
            "Now the new object comes in that I would like to classify.",
            "The nearest neighbor rule basically says well, I consider only the dissimilarity from this object two or objects in my training set.",
            "So basically I only consider this vector of dis similarities.",
            "And I check which of these disparities is the smallest Ann.",
            "I assign my new incoming objects to either the red class or the blue class depending on where the smallest dissimilarity can be found."
        ],
        [
            "But of course, in a way, this is a waste of.",
            "Of resources, waste of data.",
            "The point is that.",
            "That might actually be much more in this dissimilarity matrix matrix.",
            "We did nearest neighbor only based on this on this vector, but we might actually be able to learn something from all the dissimilarity's in the training set.",
            "And we can generally ask the question, how can we actually build more general classifiers than nearest neighbor rule?",
            "OK, that's the key.",
            "Nearest neighborhood, but we would like to take it a bit further than that.",
            "Although in a way we try to get rid of.",
            "I'll get rid of that.",
            "We try to do something else then feature based approach is still one typical thing.",
            "Maybe to do is to see whether we can employ.",
            "General better recognition tools that are based on vector vectorial representation.",
            "Whether we can still use them for the similarities.",
            "So in this case, are two possible approaches, or at least two possible approaches."
        ],
        [
            "One is called.",
            "Refer to us in this similarity space.",
            "The simple idea is that basically I can consider every rule.",
            "That belongs to a particular object, so this is all the similarities to all other seven object."
        ],
        [
            "Object number one.",
            "OK, it also has a distance to itself and I just interpret them as being features.",
            "Another possibility is so basically I can for example choose let's say the 1st three dissimilarity's and based on this part I can then build a 3 dimensional feature space in which I can do my general better recognition tricks.",
            "Do you say then called prototypes?",
            "So you decide to which objects you would calculate your dissimilarity and build a feature space.",
            "On the other possibility is to do an embedding, an embedding embedding basically means that I tried to take a Euclidean space and I tried to put my in this case seven points in this Euclidean space, such that if I calculate Euclidean distances between these points.",
            "That they actually match exactly with the dissimilarity's that are initially defined.",
            "And then you say OK, now I have data now have vectorial data that actually matches exactly with the dissimilarity's now and now in this vector space I can just build my classifier.",
            "Well, one of the typical examples of embedding is."
        ],
        [
            "Classical scaling or well, of course.",
            "The relationships, the PCA etc.",
            "And indeed it does simple things like.",
            "We have here we can calculate distances between.",
            "Cities they don't necessarily have to fulfill in to start with that they are in the Euclidean space.",
            "Can in this case calculate my 13 by 13 distance matrix, and I can try to see whether I can embed them by means of a classical scaling or whatever.",
            "And if I display the first 2 dimensions, you get something like this out, so they should to certain important to certain extent match the actual distances that you find here."
        ],
        [
            "Does, however, a major problem in this, and that's the point that many popular dissimilarity measures they are actually not Euclidean.",
            "And this actually means that you cannot embed them properly in Euclidean space.",
            "This means that if you only want to stick to Euclidean space, there will be some sort of discrepancy between the distances you find in your Euclidean space and the similarities that you have that you received, or that you constructed yourself.",
            "Of course, we all know things like an hour, one distance or a Hausdorff distance for shapes, album distance in histograms often used, or things like distances based on Fisher, where you try to measure the distance between one or more classes to a more classics.",
            "Sometimes these distances are even non metric or the dissimilarity's are non metric.",
            "One of the well known examples of its from clustering.",
            "If you use something like single linkage it will it were very often violated the triangular inequality.",
            "In some sense, all the pictures are showed they are all in some sense they are all examples of single single linkage.",
            "Where you clearly can see that the distance between 2A and B is 02, B&C is zero.",
            "An agency has a positive value.",
            "Just as a reminder.",
            "This is a kind of four point configuration where which is Euclidean.",
            "This is possible to embed this in the Euclidean space.",
            "Here this distance is between C&D and so become too short to actually properly bambata many Euclidean space.",
            "So it's still metric.",
            "And here where four points where even the triangular inequality's have been via."
        ],
        [
            "Related, so it's not a metric even.",
            "OK, so to some extent round, cancel resort to classical scaling."
        ],
        [
            "And this is by means of.",
            "If you allow pseudo Euclidean embedding.",
            "Nope."
        ],
        [
            "Sketch this or Euclidean embedding basically means I have medicine, the similarities and I would like this to be fulfilled.",
            "I have points XI and XJ, for which if I calculate the square distances to square the similarity saying if you however extend your space by, let's call it a negative space while you actually.",
            "Add to the distances in such a way so you have one space in which you just calculate positive the distance in a normal way.",
            "Normal Euclidean where you have another space where you do the normal Euclidean kind of calculations, but you actually allow the distances to be subtracted from each other, so this relates to indefinite kernels and crying space."
        ],
        [
            "This and things like that.",
            "But the point is, the point is that.",
            "Many people have considered this to be an artifact of their data or whatever, and basically what they try to do in an embedding.",
            "This is where you find negative eigenvector eigenvalues in your money, which is what they tried, but they simply say in the embedding as well.",
            "Well, forget about this term.",
            "Let's throw out all embedding directions that have the negative eigenvalue and will proceed with this part.",
            "Well, just to mention about this, this work comes partly from the same bat project, which is a rather large European project where someone to organize here and so on are also involved in, and this focus on the study of non metric and indefinite non metric data and indefinite kernels etc."
        ],
        [
            "The questions that the Dell Group asked and some of the other members in the in the consortium as well.",
            "So why do they actually?"
        ],
        [
            "Or why do we get actually non Euclidean data an II?",
            "Are they actually in senchal?",
            "Are they informative in some sort of way?",
            "Well, now to other things.",
            "Can we build classifiers for them?",
            "We already discussed this in other work and can we transform them into Euclidean representations?",
            "Yes we can, but that often comes at the loss of performance.",
            "So."
        ],
        [
            "But I hear would like to say some things about which is the actual topic of the main topic of the papers.",
            "Why do they occur an are they essential or are they informative?",
            "I guess he's just some examples of how you get actually to non well non Euclidean is first of all we have things like computational noise.",
            "OK this is something that just happens.",
            "I mean this is not.",
            "Anyway, it's not an intrinsic kind of event of the data.",
            "So even if you do a little experiment like this and Matlab.",
            "Maybe if you do it in Mathematica it will give you no problems.",
            "If you can do the exact calculations but in Matlab.",
            "Purely due to the noise in the representation of numbers, if I do 50 random points in 20 dimensions, calculate the distance matrix.",
            "And then I would expect.",
            "29 zero eigenvalues.",
            "Maybe I would actually expect 31 zero equals, but OK.",
            "But if you in fact do the classical scaling, you try to get back from this distance matrix to vector representation.",
            "You actually find numerically that are 50 negative eigenvalues.",
            "OK, in this case it seems appropriate to just throw them out becausw, but generally of course you don't know from what what type of space you're dissimilarity."
        ],
        [
            "Trump.",
            "Here's another example that Bob calls lack of information.",
            "And the story goes as follows.",
            "We have two villages, V&J and people travel to the point X, and this was some sort of big glacier I think.",
            "The travel time was something like 4 to 8 hours or so to get from Vita Exxon from the J2X, but basically because people did not were not aware of each others.",
            "Travels there.",
            "They only knew that if we want to go from V2 J, you basically have to make this.",
            "I don't know for they detour.",
            "So here we have a clear violation of the.",
            "Of the triangular inequality, but basically because of lack of knowledge of.",
            "Well, if people would share a bit what they know about traveling between GX&J, they would of course fix it and then it would travel through X through X2J."
        ],
        [
            "Not a problem is over and underestimation.",
            "If you want to do it, for example graph matching, I would like to match these two graphs.",
            "Maybe they have attributes, maybe not.",
            "It can become very complicated and time consuming.",
            "So anyway, you would like to have minimum distance an you actually by definition more as you create an actual proper dissimilarity, or at least a proper metric.",
            "But it's still very grow large grass people try to come up with all kinds of shortcuts to make the match faster.",
            "And this this this.",
            "As a result, it might actually happen that if you look at the full dissimilarity matrix that you determine like this.",
            "You have a whole set of graphs.",
            "That you actually get again that you get non Euclidian kind of data.",
            "Well, maybe the more interesting one."
        ],
        [
            "Once Ryu have intrinsic non Euclidean is so we have for example the model OBAS dissimilarity wait which calculate pairwise between classes or which you put what you can, which people do calculate pairwise between classes.",
            "Idea is that to every time take two of them, you take the average covariance matrix and based on that to determine what the distances between these two classes.",
            "When you do that three times in this case.",
            "But just because every time you only compare two your shift somehow your frame of reference.",
            "And if these kind of things happen, then it might actually turn out that the overall dissimilarity that you calculate that it's actually non Euclidean."
        ],
        [
            "Maybe a bit more appealing or stronger examples if you if you're dealing with a variance, so it might be the case that you're in some sort of object space.",
            "Doesn't really matter what you have objects AB&C.",
            "And it might be that particular transformations of A&B&C that they basically consider them all to be the same kind of object.",
            "Well, so it could be something as simple like in computer vision that you would pose invariants etc.",
            "But it could be more complex.",
            "So.",
            "The Lions here basically are there more as the invariant spaces.",
            "Every point in here I would call object A. I only see it from a different sides.",
            "Well in this case, as the arrows indicates or the distance between B&C and the distance between A&B, the sum of these distances is smaller than the distance between.",
            "A&C.",
            "Again, we have a violation of the triangular inequality and we have a heavily non Euclidean similarity measure."
        ],
        [
            "Another example, human judgment, and this relates a bit to the model OBAS kind of way.",
            "If you let people judge in whatever kind of way, you can check the details in this in this spammy publication.",
            "Which is on non metric distances for image retrieval and class representation.",
            "Let people judge somehow the dissimilarity.",
            "Then it very often does violate.",
            "Also again even the triangular inequality.",
            "Because people have the tendency to say, well, no, this this has no holes in the human, has no similarity at all.",
            "But as soon as she should chip in this mythical figure, then they say wow.",
            "The easily inclined to match the things that indeed look similar and based their decision of how similar dissimilar objects are on that.",
            "So basically there is also some sort of shift of reference frame, and by this you get violations of the.",
            "Non Euclidean distance."
        ],
        [
            "Parity measures other intrinsically.",
            "Non Euclidean measures are that might just happen so that these people like each other very much.",
            "These people like each other very much.",
            "But that probably means.",
            "That does not necessarily mean that they these two people.",
            "This is, by the way, this is not Riemann.",
            "Is that these people like each other as well?",
            "It does not necessarily have to be the case."
        ],
        [
            "So part of the point is why?",
            "Why are these?",
            "The similarities interesting is because we want to do pattern recognition, maybe statistical pattern recognition on the similarity structures.",
            "Well, in some sense, better recognition tries to mimic human judgments.",
            "We try to classify in the sense that I mean the labels are given and maybe even representation is given.",
            "Anne.",
            "And the interesting part of the Dissimilarity's is why we would maybe want to stick to this notice is that they give us the opportunity that they in the structural setting is maybe often easier to come up with.",
            "The distance measure between objects, not necessarily vectorial representation of an object.",
            "And the nice thing of the structures of the similarities is that we, in a way we consider not structures as as degenerated points.",
            "We cannot have three points that have distance zero to each other.",
            "However, there are particular settings where we consider non Euclidean dissimilarity measures.",
            "Where three objects actually can have distance zero to each other, and for human this might actually make sense."
        ],
        [
            "And we would like to be able to deal with these kind of situations as well.",
            "So anyway, the similarities gives you the possibility through the, either through the embedding or through the the similarity approach to actually to actually deal with structural kind of pattern recognition problems.",
            "All we are however we have to pay for this up to now is that we we somehow have to properly deal with the non Euclidean nature of the data.",
            "And that's where lot of research issues I think are dog with the symbol project.",
            "Protect some of them but.",
            "We're certainly not done yet.",
            "OK, as a final."
        ],
        [
            "Just one of the final slides I'm going to illustrate a bit that indeed we classification setting these non Euclidean measures are.",
            "To try to convince you that these non collision meshes are indeed informative, well just."
        ],
        [
            "Explain very briefly, this is just a bunch of datasets.",
            "I show you the size of the data, the total number of objects, number of classes I show you how non metric it is in a sense because we just check how many triples of dissimilarity's actually violate the triangular inequality.",
            "This is a non Euclidean fraction.",
            "This basically means that you take in yours.",
            "If you do your classical scaling you take all your negative eigenvalues and you normalize by the total amount of eigenvalues.",
            "Which gives you some sort of impression of how non Euclidean it is.",
            "So this is how non metric it is.",
            "And this is how new kleidion is, it is if it's not not non Euclidean then of course it will also then it will be metric.",
            "So there should be no problem there.",
            "This is really this is.",
            "We do experiments with support vector machine and this is well this is random assignment.",
            "How did whatever you get there.",
            "These are the error rates where you will see the error rates on the original dissimilarity matrix.",
            "This is the dissimilarity matrix that we get if you only take the positive part of the multi dimension of the classical scaling.",
            "So, and this is the this similarity that we actually get every throw out the positive part and actually only keep the negative distances well which we in this case make positive, But that's not essential and we run experiments basically with this.",
            "So I'll first scare you with a huge amount of numbers, but.",
            "Try to pull out a couple of particular results.",
            "So in this case, we can actually conclude that the the negative.",
            "So the non Euclidean part of the dismantle matrix actually.",
            "Add something to the classification.",
            "Because this is the original kind of on the full matrix, this is the original result on the full matrix.",
            "Anne.",
            "And this shows that at least we can get something out of the negative matrix.",
            "But if you look at the positive ones, we see that if you only look at the positive part, then classification results worse actually.",
            "So this is a demonstration of that that if you throw out the negative part, we clearly we clearly get worse performance and this this non Euclidean eigen fraction shows indeed that it's non Euclidean.",
            "Although these matrices are metric in this case.",
            "This is a constructed example that was particularly constructed to show that you more or less can even push all the information in the negative part of the space.",
            "So you actually get on the original.",
            "The similarities you get almost 5050 error, so it's both non Euclidean metric.",
            "Also the positive part doesn't do anything but in the negative part.",
            "But you can almost get perfect classification all in the paper.",
            "You can check how this is constructed, and indeed it is a constructive example in this case.",
            "Well and there are clearly also examples where it's not informative at all here in this brain MRI data.",
            "Actually removing the negative part will get you slightly better performance.",
            "OK, well I call it conclusions but they are basic."
        ],
        [
            "The repetition of what I've been talking about.",
            "We have them give you a couple of courses or how actually non Euclidean dissimilarity's come about showed you some non intrinsic ones which might be not interesting, but it's difficult to decide whether these non Euclidean.",
            "That's not intrinsic, so I'll show you some intrinsic non Euclidean behaviors.",
            "And we think that it's essential to be able to deal properly with these kind of the similarities.",
            "If you would like to bridge statistical pattern recognition and structural pattern recognition and also give you some examples of where the non Euclidean is is in fact informative.",
            "So I."
        ],
        [
            "Yes, as the Messenger I can now ask you to shoot me, but maybe there's just some questions or.",
            "What do they like anybody like to shoot Marco?",
            "Would like to thank him for giving the presentation in the absence of Bob Dylan.",
            "If there is no burning question, then little behind schedule, so we'll continue.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it doesn't really matter that much what the picture actually shows.",
                    "label": 0
                },
                {
                    "sent": "I just took one nice picture from collection of photographs I made.",
                    "label": 0
                },
                {
                    "sent": "And if you look at typical images like this and it doesn't really matter whether it's image or whether you see it in real life.",
                    "label": 0
                },
                {
                    "sent": "If people observe a scene like this, you might actually wonder things like very basic things like so.",
                    "label": 0
                },
                {
                    "sent": "Can you give me what the distance is between this little girl?",
                    "label": 0
                },
                {
                    "sent": "Whatever she wants to do with the Matchbox and the actual Matchbox?",
                    "label": 0
                },
                {
                    "sent": "Well, I hope that you more or less all agree with me that probably the distance between this Matchbox and the girl.",
                    "label": 0
                },
                {
                    "sent": "Is 0 girls holding the matchbox?",
                    "label": 0
                },
                {
                    "sent": "Another distance that we might be interested in is what's the distance between the girl and the ground while she's standing on the floor.",
                    "label": 0
                },
                {
                    "sent": "So I guess we can all agree here that the distance between the girl and the floor is 0.",
                    "label": 0
                },
                {
                    "sent": "Now, what is the distance between the matchbox and the floor?",
                    "label": 0
                },
                {
                    "sent": "While it seems to be.",
                    "label": 0
                },
                {
                    "sent": "Someone higher up.",
                    "label": 0
                },
                {
                    "sent": "I don't know how tall this girl is.",
                    "label": 0
                },
                {
                    "sent": "But at least it's clearly non 0.",
                    "label": 0
                },
                {
                    "sent": "And I guess with many scenes that you can see around you, you have the same kind of configuration.",
                    "label": 0
                },
                {
                    "sent": "People are with their elbows on the table, so the people might have a distance 0 to the table.",
                    "label": 0
                },
                {
                    "sent": "There's a water bottle on the table.",
                    "label": 0
                },
                {
                    "sent": "The water bottle is has a distance of 0 to the table.",
                    "label": 0
                },
                {
                    "sent": "But the distance between this person and the water bottle might be larger than 0.",
                    "label": 0
                },
                {
                    "sent": "Thing that you should note from this.",
                    "label": 0
                },
                {
                    "sent": "Is that it's a typically used kind of distance measure between objects.",
                    "label": 0
                },
                {
                    "sent": "But it's actually heavily non Euclidean.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's even more metric in this case because it clearly violates the triangular inequality.",
                    "label": 0
                },
                {
                    "sent": "Oh, that's not.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this talk is going to be about non Euclidean dissimilarity's causes an informal informativeness.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bob down should actually be giving this talk, but while I will not dwell on the reasons for us absence, allies, Korth Ring it, and it's going to be as presented by me, marchelo.",
                    "label": 0
                },
                {
                    "sent": "So I'm part of Bob's Group, or maybe slowly on Bob is going to be part of my group.",
                    "label": 0
                },
                {
                    "sent": "But OK, there's discussion about this.",
                    "label": 0
                },
                {
                    "sent": "We both found out University of Technology in the Netherlands, an ally.",
                    "label": 1
                },
                {
                    "sent": "She is at the Mansion universe, Manchester University at the UK.",
                    "label": 0
                },
                {
                    "sent": "So they wrote the paper.",
                    "label": 0
                },
                {
                    "sent": "I try to make more or less old slides myself so you can partly complain to me partly.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have to complain to Bob, probably.",
                    "label": 0
                },
                {
                    "sent": "Of course there's no need for me to point out that I'm the so called Messenger.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll drill a bit more on on indeed just to also show you some further images.",
                    "label": 0
                },
                {
                    "sent": "Indeed, you see it everywhere.",
                    "label": 0
                },
                {
                    "sent": "Distance from the windows from take any window in this wall.",
                    "label": 0
                },
                {
                    "sent": "The distance from this window from every window to the wall is 0.",
                    "label": 0
                },
                {
                    "sent": "The distance between the windows is typically non zero.",
                    "label": 0
                },
                {
                    "sent": "We here again would describe this and we use distance that is known.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lydian again nonmetric even.",
                    "label": 0
                },
                {
                    "sent": "Distance from the backpack to the Walker is 0. the Walker is on this snowfield and the distance is zero.",
                    "label": 0
                },
                {
                    "sent": "However, the backpack has a positive distance to the snowfield with dealing with a non metric this similarity measure.",
                    "label": 0
                },
                {
                    "sent": "Another thing also in street.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Change scenes this applies.",
                    "label": 0
                },
                {
                    "sent": "There's a black Berry on a bench.",
                    "label": 0
                },
                {
                    "sent": "There's a woman sitting on the bench.",
                    "label": 0
                },
                {
                    "sent": "Both have zero distance to the bench.",
                    "label": 0
                },
                {
                    "sent": "The black Berry and woman are on a positive distance, so there's no motricity here.",
                    "label": 0
                },
                {
                    "sent": "Or maybe the black Berry is huge and touching.",
                    "label": 0
                },
                {
                    "sent": "The woman that I.",
                    "label": 0
                },
                {
                    "sent": "Think it's only a small one.",
                    "label": 0
                },
                {
                    "sent": "Maybe a bit.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Overkill, but to demonstrate you that it also works in more abstract settings.",
                    "label": 0
                },
                {
                    "sent": "These two sculptures they have a distance from each other while they're both have a distance of 0 to their pedestal.",
                    "label": 0
                },
                {
                    "sent": "And finally, yet another work of art somewhere in New York.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this frame.",
                    "label": 0
                },
                {
                    "sent": "As a distance of 0 to the wall, a distance of 0 to the floor, and actually in this case there's no kind of metric violation becausw, we could claim that the distance between the floor and the wall is actually also zero.",
                    "label": 0
                },
                {
                    "sent": "But this seems a bit strange.",
                    "label": 0
                },
                {
                    "sent": "I mean we have three objects.",
                    "label": 0
                },
                {
                    "sent": "They all have distance zero to each other.",
                    "label": 0
                },
                {
                    "sent": "Typically, if we would be in the typical feature space that we we treat, our pattern recognition problems in, we would actually decide that these three objects that they're basically the same object, which is clearly not the case here.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I'm actually going to talk about?",
                    "label": 0
                },
                {
                    "sent": "Well, first I'll give a brief overview or slight introduction to dissimilarity based pattern recognition.",
                    "label": 0
                },
                {
                    "sent": "I'll discuss a bit about dissimilarity space, embedding of the similarities, or distance matrices I briefly touch upon pseudo Euclidean spaces.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then I actually come to the two major points, let's say or two messages.",
                    "label": 0
                },
                {
                    "sent": "The causes of non Euclidean A's.",
                    "label": 0
                },
                {
                    "sent": "And how informative these similarities actually are, and I'll end with some conclusions if time permits.",
                    "label": 0
                },
                {
                    "sent": "So let's consider the typical pattern recognition system.",
                    "label": 1
                },
                {
                    "sent": "We have some sensors by mid by means we which.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By which means we sense some object.",
                    "label": 0
                },
                {
                    "sent": "We need to somehow represent.",
                    "label": 0
                },
                {
                    "sent": "By means of what the output of these sounds, we need to represent this object, typically in a future space, and from that we can do a classification, generalization, etc.",
                    "label": 0
                },
                {
                    "sent": "So the point is about mainly about this middle block here.",
                    "label": 0
                },
                {
                    "sent": "The representation bond, so indeed mostly probably everybody here is familiar with feature based better recognition.",
                    "label": 0
                },
                {
                    "sent": "You represent an object or you try to represent an object as a feature you extract from images, particular features, texture, features, whatever.",
                    "label": 0
                },
                {
                    "sent": "You try to represent it.",
                    "label": 0
                },
                {
                    "sent": "By means of features, sometimes you try to relax this a bit.",
                    "label": 0
                },
                {
                    "sent": "Do this kind of bag of words, representations you multiple instance learning, but still even in these typically you assume that you have, from the subcomponents you have from vector vectorial kind of representation.",
                    "label": 0
                },
                {
                    "sent": "The alternative that, well, maybe in other areas of science there may be more use with the Alternative Institute, or at least when it comes to this statistical pattern recognition people from the structural side.",
                    "label": 0
                },
                {
                    "sent": "They are more more used to the alternative of pairwise similarities.",
                    "label": 0
                },
                {
                    "sent": "This can be so bad this analysis mainly basically means we don't represent an object by feature vector, but we describe an object by how it relates to all other objects in our training sets.",
                    "label": 0
                },
                {
                    "sent": "Typically this is expert constructed and some people so Edelman in his book actually considers this pairwise dissimilarity based approach to be in a way more fundamental than feature based approach.",
                    "label": 1
                },
                {
                    "sent": "Well, I wouldn't say the archetypical classifier to use in the dissimilarity based.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approaches, for example, if their expert defined these similarities.",
                    "label": 0
                },
                {
                    "sent": "The way you go about doing classification with this in the typical way is that you actually do a nearest neighbor kind of classification.",
                    "label": 0
                },
                {
                    "sent": "So the simple idea is.",
                    "label": 0
                },
                {
                    "sent": "This is my matrix of Dissimilarity's, so here are seven objects.",
                    "label": 0
                },
                {
                    "sent": "Set out like this and this and I can calculate all their dis similarities.",
                    "label": 0
                },
                {
                    "sent": "Now the new object comes in that I would like to classify.",
                    "label": 0
                },
                {
                    "sent": "The nearest neighbor rule basically says well, I consider only the dissimilarity from this object two or objects in my training set.",
                    "label": 0
                },
                {
                    "sent": "So basically I only consider this vector of dis similarities.",
                    "label": 0
                },
                {
                    "sent": "And I check which of these disparities is the smallest Ann.",
                    "label": 0
                },
                {
                    "sent": "I assign my new incoming objects to either the red class or the blue class depending on where the smallest dissimilarity can be found.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But of course, in a way, this is a waste of.",
                    "label": 0
                },
                {
                    "sent": "Of resources, waste of data.",
                    "label": 0
                },
                {
                    "sent": "The point is that.",
                    "label": 0
                },
                {
                    "sent": "That might actually be much more in this dissimilarity matrix matrix.",
                    "label": 0
                },
                {
                    "sent": "We did nearest neighbor only based on this on this vector, but we might actually be able to learn something from all the dissimilarity's in the training set.",
                    "label": 0
                },
                {
                    "sent": "And we can generally ask the question, how can we actually build more general classifiers than nearest neighbor rule?",
                    "label": 0
                },
                {
                    "sent": "OK, that's the key.",
                    "label": 0
                },
                {
                    "sent": "Nearest neighborhood, but we would like to take it a bit further than that.",
                    "label": 0
                },
                {
                    "sent": "Although in a way we try to get rid of.",
                    "label": 0
                },
                {
                    "sent": "I'll get rid of that.",
                    "label": 0
                },
                {
                    "sent": "We try to do something else then feature based approach is still one typical thing.",
                    "label": 0
                },
                {
                    "sent": "Maybe to do is to see whether we can employ.",
                    "label": 0
                },
                {
                    "sent": "General better recognition tools that are based on vector vectorial representation.",
                    "label": 0
                },
                {
                    "sent": "Whether we can still use them for the similarities.",
                    "label": 0
                },
                {
                    "sent": "So in this case, are two possible approaches, or at least two possible approaches.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One is called.",
                    "label": 0
                },
                {
                    "sent": "Refer to us in this similarity space.",
                    "label": 0
                },
                {
                    "sent": "The simple idea is that basically I can consider every rule.",
                    "label": 0
                },
                {
                    "sent": "That belongs to a particular object, so this is all the similarities to all other seven object.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Object number one.",
                    "label": 0
                },
                {
                    "sent": "OK, it also has a distance to itself and I just interpret them as being features.",
                    "label": 0
                },
                {
                    "sent": "Another possibility is so basically I can for example choose let's say the 1st three dissimilarity's and based on this part I can then build a 3 dimensional feature space in which I can do my general better recognition tricks.",
                    "label": 0
                },
                {
                    "sent": "Do you say then called prototypes?",
                    "label": 0
                },
                {
                    "sent": "So you decide to which objects you would calculate your dissimilarity and build a feature space.",
                    "label": 0
                },
                {
                    "sent": "On the other possibility is to do an embedding, an embedding embedding basically means that I tried to take a Euclidean space and I tried to put my in this case seven points in this Euclidean space, such that if I calculate Euclidean distances between these points.",
                    "label": 0
                },
                {
                    "sent": "That they actually match exactly with the dissimilarity's that are initially defined.",
                    "label": 0
                },
                {
                    "sent": "And then you say OK, now I have data now have vectorial data that actually matches exactly with the dissimilarity's now and now in this vector space I can just build my classifier.",
                    "label": 0
                },
                {
                    "sent": "Well, one of the typical examples of embedding is.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Classical scaling or well, of course.",
                    "label": 0
                },
                {
                    "sent": "The relationships, the PCA etc.",
                    "label": 0
                },
                {
                    "sent": "And indeed it does simple things like.",
                    "label": 0
                },
                {
                    "sent": "We have here we can calculate distances between.",
                    "label": 0
                },
                {
                    "sent": "Cities they don't necessarily have to fulfill in to start with that they are in the Euclidean space.",
                    "label": 0
                },
                {
                    "sent": "Can in this case calculate my 13 by 13 distance matrix, and I can try to see whether I can embed them by means of a classical scaling or whatever.",
                    "label": 0
                },
                {
                    "sent": "And if I display the first 2 dimensions, you get something like this out, so they should to certain important to certain extent match the actual distances that you find here.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Does, however, a major problem in this, and that's the point that many popular dissimilarity measures they are actually not Euclidean.",
                    "label": 1
                },
                {
                    "sent": "And this actually means that you cannot embed them properly in Euclidean space.",
                    "label": 0
                },
                {
                    "sent": "This means that if you only want to stick to Euclidean space, there will be some sort of discrepancy between the distances you find in your Euclidean space and the similarities that you have that you received, or that you constructed yourself.",
                    "label": 0
                },
                {
                    "sent": "Of course, we all know things like an hour, one distance or a Hausdorff distance for shapes, album distance in histograms often used, or things like distances based on Fisher, where you try to measure the distance between one or more classes to a more classics.",
                    "label": 0
                },
                {
                    "sent": "Sometimes these distances are even non metric or the dissimilarity's are non metric.",
                    "label": 0
                },
                {
                    "sent": "One of the well known examples of its from clustering.",
                    "label": 0
                },
                {
                    "sent": "If you use something like single linkage it will it were very often violated the triangular inequality.",
                    "label": 0
                },
                {
                    "sent": "In some sense, all the pictures are showed they are all in some sense they are all examples of single single linkage.",
                    "label": 0
                },
                {
                    "sent": "Where you clearly can see that the distance between 2A and B is 02, B&C is zero.",
                    "label": 0
                },
                {
                    "sent": "An agency has a positive value.",
                    "label": 0
                },
                {
                    "sent": "Just as a reminder.",
                    "label": 0
                },
                {
                    "sent": "This is a kind of four point configuration where which is Euclidean.",
                    "label": 0
                },
                {
                    "sent": "This is possible to embed this in the Euclidean space.",
                    "label": 0
                },
                {
                    "sent": "Here this distance is between C&D and so become too short to actually properly bambata many Euclidean space.",
                    "label": 0
                },
                {
                    "sent": "So it's still metric.",
                    "label": 0
                },
                {
                    "sent": "And here where four points where even the triangular inequality's have been via.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Related, so it's not a metric even.",
                    "label": 0
                },
                {
                    "sent": "OK, so to some extent round, cancel resort to classical scaling.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is by means of.",
                    "label": 0
                },
                {
                    "sent": "If you allow pseudo Euclidean embedding.",
                    "label": 1
                },
                {
                    "sent": "Nope.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sketch this or Euclidean embedding basically means I have medicine, the similarities and I would like this to be fulfilled.",
                    "label": 0
                },
                {
                    "sent": "I have points XI and XJ, for which if I calculate the square distances to square the similarity saying if you however extend your space by, let's call it a negative space while you actually.",
                    "label": 0
                },
                {
                    "sent": "Add to the distances in such a way so you have one space in which you just calculate positive the distance in a normal way.",
                    "label": 0
                },
                {
                    "sent": "Normal Euclidean where you have another space where you do the normal Euclidean kind of calculations, but you actually allow the distances to be subtracted from each other, so this relates to indefinite kernels and crying space.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This and things like that.",
                    "label": 0
                },
                {
                    "sent": "But the point is, the point is that.",
                    "label": 0
                },
                {
                    "sent": "Many people have considered this to be an artifact of their data or whatever, and basically what they try to do in an embedding.",
                    "label": 0
                },
                {
                    "sent": "This is where you find negative eigenvector eigenvalues in your money, which is what they tried, but they simply say in the embedding as well.",
                    "label": 0
                },
                {
                    "sent": "Well, forget about this term.",
                    "label": 0
                },
                {
                    "sent": "Let's throw out all embedding directions that have the negative eigenvalue and will proceed with this part.",
                    "label": 0
                },
                {
                    "sent": "Well, just to mention about this, this work comes partly from the same bat project, which is a rather large European project where someone to organize here and so on are also involved in, and this focus on the study of non metric and indefinite non metric data and indefinite kernels etc.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The questions that the Dell Group asked and some of the other members in the in the consortium as well.",
                    "label": 0
                },
                {
                    "sent": "So why do they actually?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or why do we get actually non Euclidean data an II?",
                    "label": 0
                },
                {
                    "sent": "Are they actually in senchal?",
                    "label": 0
                },
                {
                    "sent": "Are they informative in some sort of way?",
                    "label": 0
                },
                {
                    "sent": "Well, now to other things.",
                    "label": 0
                },
                {
                    "sent": "Can we build classifiers for them?",
                    "label": 1
                },
                {
                    "sent": "We already discussed this in other work and can we transform them into Euclidean representations?",
                    "label": 0
                },
                {
                    "sent": "Yes we can, but that often comes at the loss of performance.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But I hear would like to say some things about which is the actual topic of the main topic of the papers.",
                    "label": 0
                },
                {
                    "sent": "Why do they occur an are they essential or are they informative?",
                    "label": 0
                },
                {
                    "sent": "I guess he's just some examples of how you get actually to non well non Euclidean is first of all we have things like computational noise.",
                    "label": 0
                },
                {
                    "sent": "OK this is something that just happens.",
                    "label": 0
                },
                {
                    "sent": "I mean this is not.",
                    "label": 0
                },
                {
                    "sent": "Anyway, it's not an intrinsic kind of event of the data.",
                    "label": 0
                },
                {
                    "sent": "So even if you do a little experiment like this and Matlab.",
                    "label": 0
                },
                {
                    "sent": "Maybe if you do it in Mathematica it will give you no problems.",
                    "label": 0
                },
                {
                    "sent": "If you can do the exact calculations but in Matlab.",
                    "label": 0
                },
                {
                    "sent": "Purely due to the noise in the representation of numbers, if I do 50 random points in 20 dimensions, calculate the distance matrix.",
                    "label": 1
                },
                {
                    "sent": "And then I would expect.",
                    "label": 0
                },
                {
                    "sent": "29 zero eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "Maybe I would actually expect 31 zero equals, but OK.",
                    "label": 0
                },
                {
                    "sent": "But if you in fact do the classical scaling, you try to get back from this distance matrix to vector representation.",
                    "label": 1
                },
                {
                    "sent": "You actually find numerically that are 50 negative eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "OK, in this case it seems appropriate to just throw them out becausw, but generally of course you don't know from what what type of space you're dissimilarity.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Trump.",
                    "label": 0
                },
                {
                    "sent": "Here's another example that Bob calls lack of information.",
                    "label": 0
                },
                {
                    "sent": "And the story goes as follows.",
                    "label": 0
                },
                {
                    "sent": "We have two villages, V&J and people travel to the point X, and this was some sort of big glacier I think.",
                    "label": 0
                },
                {
                    "sent": "The travel time was something like 4 to 8 hours or so to get from Vita Exxon from the J2X, but basically because people did not were not aware of each others.",
                    "label": 0
                },
                {
                    "sent": "Travels there.",
                    "label": 0
                },
                {
                    "sent": "They only knew that if we want to go from V2 J, you basically have to make this.",
                    "label": 0
                },
                {
                    "sent": "I don't know for they detour.",
                    "label": 0
                },
                {
                    "sent": "So here we have a clear violation of the.",
                    "label": 0
                },
                {
                    "sent": "Of the triangular inequality, but basically because of lack of knowledge of.",
                    "label": 0
                },
                {
                    "sent": "Well, if people would share a bit what they know about traveling between GX&J, they would of course fix it and then it would travel through X through X2J.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not a problem is over and underestimation.",
                    "label": 1
                },
                {
                    "sent": "If you want to do it, for example graph matching, I would like to match these two graphs.",
                    "label": 0
                },
                {
                    "sent": "Maybe they have attributes, maybe not.",
                    "label": 0
                },
                {
                    "sent": "It can become very complicated and time consuming.",
                    "label": 0
                },
                {
                    "sent": "So anyway, you would like to have minimum distance an you actually by definition more as you create an actual proper dissimilarity, or at least a proper metric.",
                    "label": 0
                },
                {
                    "sent": "But it's still very grow large grass people try to come up with all kinds of shortcuts to make the match faster.",
                    "label": 0
                },
                {
                    "sent": "And this this this.",
                    "label": 0
                },
                {
                    "sent": "As a result, it might actually happen that if you look at the full dissimilarity matrix that you determine like this.",
                    "label": 0
                },
                {
                    "sent": "You have a whole set of graphs.",
                    "label": 0
                },
                {
                    "sent": "That you actually get again that you get non Euclidian kind of data.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe the more interesting one.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once Ryu have intrinsic non Euclidean is so we have for example the model OBAS dissimilarity wait which calculate pairwise between classes or which you put what you can, which people do calculate pairwise between classes.",
                    "label": 0
                },
                {
                    "sent": "Idea is that to every time take two of them, you take the average covariance matrix and based on that to determine what the distances between these two classes.",
                    "label": 0
                },
                {
                    "sent": "When you do that three times in this case.",
                    "label": 0
                },
                {
                    "sent": "But just because every time you only compare two your shift somehow your frame of reference.",
                    "label": 0
                },
                {
                    "sent": "And if these kind of things happen, then it might actually turn out that the overall dissimilarity that you calculate that it's actually non Euclidean.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Maybe a bit more appealing or stronger examples if you if you're dealing with a variance, so it might be the case that you're in some sort of object space.",
                    "label": 1
                },
                {
                    "sent": "Doesn't really matter what you have objects AB&C.",
                    "label": 0
                },
                {
                    "sent": "And it might be that particular transformations of A&B&C that they basically consider them all to be the same kind of object.",
                    "label": 0
                },
                {
                    "sent": "Well, so it could be something as simple like in computer vision that you would pose invariants etc.",
                    "label": 0
                },
                {
                    "sent": "But it could be more complex.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The Lions here basically are there more as the invariant spaces.",
                    "label": 0
                },
                {
                    "sent": "Every point in here I would call object A. I only see it from a different sides.",
                    "label": 0
                },
                {
                    "sent": "Well in this case, as the arrows indicates or the distance between B&C and the distance between A&B, the sum of these distances is smaller than the distance between.",
                    "label": 0
                },
                {
                    "sent": "A&C.",
                    "label": 0
                },
                {
                    "sent": "Again, we have a violation of the triangular inequality and we have a heavily non Euclidean similarity measure.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another example, human judgment, and this relates a bit to the model OBAS kind of way.",
                    "label": 0
                },
                {
                    "sent": "If you let people judge in whatever kind of way, you can check the details in this in this spammy publication.",
                    "label": 0
                },
                {
                    "sent": "Which is on non metric distances for image retrieval and class representation.",
                    "label": 1
                },
                {
                    "sent": "Let people judge somehow the dissimilarity.",
                    "label": 0
                },
                {
                    "sent": "Then it very often does violate.",
                    "label": 0
                },
                {
                    "sent": "Also again even the triangular inequality.",
                    "label": 0
                },
                {
                    "sent": "Because people have the tendency to say, well, no, this this has no holes in the human, has no similarity at all.",
                    "label": 0
                },
                {
                    "sent": "But as soon as she should chip in this mythical figure, then they say wow.",
                    "label": 0
                },
                {
                    "sent": "The easily inclined to match the things that indeed look similar and based their decision of how similar dissimilar objects are on that.",
                    "label": 0
                },
                {
                    "sent": "So basically there is also some sort of shift of reference frame, and by this you get violations of the.",
                    "label": 0
                },
                {
                    "sent": "Non Euclidean distance.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parity measures other intrinsically.",
                    "label": 0
                },
                {
                    "sent": "Non Euclidean measures are that might just happen so that these people like each other very much.",
                    "label": 0
                },
                {
                    "sent": "These people like each other very much.",
                    "label": 0
                },
                {
                    "sent": "But that probably means.",
                    "label": 0
                },
                {
                    "sent": "That does not necessarily mean that they these two people.",
                    "label": 0
                },
                {
                    "sent": "This is, by the way, this is not Riemann.",
                    "label": 0
                },
                {
                    "sent": "Is that these people like each other as well?",
                    "label": 0
                },
                {
                    "sent": "It does not necessarily have to be the case.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So part of the point is why?",
                    "label": 0
                },
                {
                    "sent": "Why are these?",
                    "label": 0
                },
                {
                    "sent": "The similarities interesting is because we want to do pattern recognition, maybe statistical pattern recognition on the similarity structures.",
                    "label": 0
                },
                {
                    "sent": "Well, in some sense, better recognition tries to mimic human judgments.",
                    "label": 1
                },
                {
                    "sent": "We try to classify in the sense that I mean the labels are given and maybe even representation is given.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And the interesting part of the Dissimilarity's is why we would maybe want to stick to this notice is that they give us the opportunity that they in the structural setting is maybe often easier to come up with.",
                    "label": 0
                },
                {
                    "sent": "The distance measure between objects, not necessarily vectorial representation of an object.",
                    "label": 0
                },
                {
                    "sent": "And the nice thing of the structures of the similarities is that we, in a way we consider not structures as as degenerated points.",
                    "label": 0
                },
                {
                    "sent": "We cannot have three points that have distance zero to each other.",
                    "label": 0
                },
                {
                    "sent": "However, there are particular settings where we consider non Euclidean dissimilarity measures.",
                    "label": 0
                },
                {
                    "sent": "Where three objects actually can have distance zero to each other, and for human this might actually make sense.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we would like to be able to deal with these kind of situations as well.",
                    "label": 0
                },
                {
                    "sent": "So anyway, the similarities gives you the possibility through the, either through the embedding or through the the similarity approach to actually to actually deal with structural kind of pattern recognition problems.",
                    "label": 0
                },
                {
                    "sent": "All we are however we have to pay for this up to now is that we we somehow have to properly deal with the non Euclidean nature of the data.",
                    "label": 0
                },
                {
                    "sent": "And that's where lot of research issues I think are dog with the symbol project.",
                    "label": 0
                },
                {
                    "sent": "Protect some of them but.",
                    "label": 0
                },
                {
                    "sent": "We're certainly not done yet.",
                    "label": 0
                },
                {
                    "sent": "OK, as a final.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just one of the final slides I'm going to illustrate a bit that indeed we classification setting these non Euclidean measures are.",
                    "label": 0
                },
                {
                    "sent": "To try to convince you that these non collision meshes are indeed informative, well just.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Explain very briefly, this is just a bunch of datasets.",
                    "label": 0
                },
                {
                    "sent": "I show you the size of the data, the total number of objects, number of classes I show you how non metric it is in a sense because we just check how many triples of dissimilarity's actually violate the triangular inequality.",
                    "label": 0
                },
                {
                    "sent": "This is a non Euclidean fraction.",
                    "label": 0
                },
                {
                    "sent": "This basically means that you take in yours.",
                    "label": 0
                },
                {
                    "sent": "If you do your classical scaling you take all your negative eigenvalues and you normalize by the total amount of eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "Which gives you some sort of impression of how non Euclidean it is.",
                    "label": 0
                },
                {
                    "sent": "So this is how non metric it is.",
                    "label": 0
                },
                {
                    "sent": "And this is how new kleidion is, it is if it's not not non Euclidean then of course it will also then it will be metric.",
                    "label": 0
                },
                {
                    "sent": "So there should be no problem there.",
                    "label": 0
                },
                {
                    "sent": "This is really this is.",
                    "label": 0
                },
                {
                    "sent": "We do experiments with support vector machine and this is well this is random assignment.",
                    "label": 0
                },
                {
                    "sent": "How did whatever you get there.",
                    "label": 0
                },
                {
                    "sent": "These are the error rates where you will see the error rates on the original dissimilarity matrix.",
                    "label": 0
                },
                {
                    "sent": "This is the dissimilarity matrix that we get if you only take the positive part of the multi dimension of the classical scaling.",
                    "label": 0
                },
                {
                    "sent": "So, and this is the this similarity that we actually get every throw out the positive part and actually only keep the negative distances well which we in this case make positive, But that's not essential and we run experiments basically with this.",
                    "label": 0
                },
                {
                    "sent": "So I'll first scare you with a huge amount of numbers, but.",
                    "label": 0
                },
                {
                    "sent": "Try to pull out a couple of particular results.",
                    "label": 0
                },
                {
                    "sent": "So in this case, we can actually conclude that the the negative.",
                    "label": 0
                },
                {
                    "sent": "So the non Euclidean part of the dismantle matrix actually.",
                    "label": 0
                },
                {
                    "sent": "Add something to the classification.",
                    "label": 0
                },
                {
                    "sent": "Because this is the original kind of on the full matrix, this is the original result on the full matrix.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And this shows that at least we can get something out of the negative matrix.",
                    "label": 0
                },
                {
                    "sent": "But if you look at the positive ones, we see that if you only look at the positive part, then classification results worse actually.",
                    "label": 0
                },
                {
                    "sent": "So this is a demonstration of that that if you throw out the negative part, we clearly we clearly get worse performance and this this non Euclidean eigen fraction shows indeed that it's non Euclidean.",
                    "label": 0
                },
                {
                    "sent": "Although these matrices are metric in this case.",
                    "label": 0
                },
                {
                    "sent": "This is a constructed example that was particularly constructed to show that you more or less can even push all the information in the negative part of the space.",
                    "label": 0
                },
                {
                    "sent": "So you actually get on the original.",
                    "label": 0
                },
                {
                    "sent": "The similarities you get almost 5050 error, so it's both non Euclidean metric.",
                    "label": 0
                },
                {
                    "sent": "Also the positive part doesn't do anything but in the negative part.",
                    "label": 0
                },
                {
                    "sent": "But you can almost get perfect classification all in the paper.",
                    "label": 0
                },
                {
                    "sent": "You can check how this is constructed, and indeed it is a constructive example in this case.",
                    "label": 0
                },
                {
                    "sent": "Well and there are clearly also examples where it's not informative at all here in this brain MRI data.",
                    "label": 1
                },
                {
                    "sent": "Actually removing the negative part will get you slightly better performance.",
                    "label": 0
                },
                {
                    "sent": "OK, well I call it conclusions but they are basic.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The repetition of what I've been talking about.",
                    "label": 0
                },
                {
                    "sent": "We have them give you a couple of courses or how actually non Euclidean dissimilarity's come about showed you some non intrinsic ones which might be not interesting, but it's difficult to decide whether these non Euclidean.",
                    "label": 0
                },
                {
                    "sent": "That's not intrinsic, so I'll show you some intrinsic non Euclidean behaviors.",
                    "label": 0
                },
                {
                    "sent": "And we think that it's essential to be able to deal properly with these kind of the similarities.",
                    "label": 0
                },
                {
                    "sent": "If you would like to bridge statistical pattern recognition and structural pattern recognition and also give you some examples of where the non Euclidean is is in fact informative.",
                    "label": 0
                },
                {
                    "sent": "So I.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, as the Messenger I can now ask you to shoot me, but maybe there's just some questions or.",
                    "label": 0
                },
                {
                    "sent": "What do they like anybody like to shoot Marco?",
                    "label": 0
                },
                {
                    "sent": "Would like to thank him for giving the presentation in the absence of Bob Dylan.",
                    "label": 0
                },
                {
                    "sent": "If there is no burning question, then little behind schedule, so we'll continue.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}