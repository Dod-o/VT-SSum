{
    "id": "b3oz6tll7vexzexc67b6rlim7lzuuq7x",
    "title": "Challenges in online learning to rank for information retrieval",
    "info": {
        "author": [
            "Katja Hofmann, Microsoft Research, Cambridge, Microsoft Research"
        ],
        "published": "Nov. 7, 2013",
        "recorded": "September 2013",
        "category": [
            "Top->Computer Science->Decision Support",
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/lsoldm2013_hofmann_information_retrieval/",
    "segmentation": [
        [
            "So in my talk I will be focusing on challenges in online learning to rank for information retrieval.",
            "Talking about learning in big Data in a lot of settings, we can collect as much data as we could hope for pretty much as much as we can fit in one of our data centers, but in a lot of these case."
        ],
        [
            "Is getting labels for our big data is the real problem?",
            "In many cases it's really expensive to pay annotators to provide labels, or there might not be.",
            "Any human annotators actually able to do this task for us.",
            "One of the cases where it's hard to get explicit labels is."
        ],
        [
            "Web search.",
            "What everyone is familiar with Google.",
            "You type the crew.",
            "You get some list of results and in the setting we want to learn some kind of ranking function that tells us what a good result list looks like.",
            "In this scenario we have some context.",
            "So for example, we know the user, we know the query and we have some items, some web documents that we want to rank correctly for that particular user in that particular query.",
            "Usually the relationship between.",
            "User and query on the one hand and the candidate documents on the other hand is expressed in some kind of feature vector which may contain some kind of information about the match between a query and the document.",
            "So for example in the form of TF, IDF gives you some measure of popularity of that particular candidate page matches with the user history or popularity of those pages in a particular location, so usually will have feature vector that has maybe 100.",
            "Non sparse entries and the goal is to rank the documents to maximize some utility to the user.",
            "But usually we cannot observe that utility directly and it's actually very hard to train annotators to tell us what the useful information is, so."
        ],
        [
            "For example, if we have to create large scale learning, we have some trained annotators and you know it.",
            "Typically decision that they would have to make us.",
            "Whether this website that we're showing here is relevant to this query.",
            "Large scale learning, so we might look at it and say, well, it has something to do with the query so well.",
            "I guess it's relevant, but it becomes really, really hard to say.",
            "Well it's this perfect page.",
            "Is this a very good page?",
            "You know it's it's a four or five.",
            "So for an annotator it's usually very difficult to make that decision, whereas the person actually typing that query may have a very good idea of whether this is relevant or not.",
            "Um?"
        ],
        [
            "So when we have difficulties collecting labels for large scale learning, there's a couple of approaches that we could follow.",
            "One possibility would be to try to use the labels that we have observed as effectively as possible so to mind comfort samples, semi supervised learning approaches where we try to bootstrap from the few reliable labels that we have.",
            "We could try to do some kind of crowdsourcing where we get noisy labels from a large number of people and try to somehow figure out how reliable they are.",
            "Or we could try to learn.",
            "Innovate directly from the environment directly by interacting with the users of a specific system and in web search.",
            "We actually do have users that use our system, so this is the kind."
        ],
        [
            "Approach that we that we are focusing on in this scenario now why is it difficult to learn directly from users of a system?"
        ],
        [
            "There are two challenges in particular that I want to focus on in this talk.",
            "First of all, our users don't give us the kinds of labels that we might expect in a supervised learning setting.",
            "You know, there's no IID sample of items where we get unbiased estimates of, for example, the relevance of the webpage.",
            "So we need to understand how we can interpret the user interactions that we can observe.",
            "So the problem we run into is balancing exploration exploitation, because now we're directly interacting with users, we need to make sure that what we're showing them is useful at all points in time, but at the same time we present information in a way that still lets us pick up some information for learning in the future."
        ],
        [
            "So first of all, I look at interpreting user interactions and."
        ],
        [
            "Um?",
            "There's been a lot of work on how to interpret user interaction in information retrieval or web search specifically, and some of the most well known work comes from the group.",
            "Of course, new Akims and his colleagues and they ran a couple of user studies where they showed how exactly how biased the data is that we could extract from user interactions.",
            "So in this particular study they had people come to the lab.",
            "Search the web and then they recorded what people were looking at and also what results they clicked and they found that phenomenon called the position bias that people are very likely to look at the top results and subsequently click on the top results and as you go further down in the rank with cyclist, people become very unlikely to even look at your pages.",
            "So this basically shows that the kind of information you observe, the interactions you observe.",
            "Are very much biased by how you present the results.",
            "This has some implications for the kinds of things that we measure."
        ],
        [
            "Usually today people use some kind of absolute metric, for example in the context of a B testing to see whether one ranking works better than another.",
            "And this just list some of the absolute metrics that are typically used.",
            "For example, you could look at the number of queries in a session, the number of clicks on the result pages per query.",
            "The time to first take etc etc and some large scale experiments.",
            "Olivier Chappelle and his colleagues found that actually none of these absolute metrics reliably correlated with the quality of the ranking function that they were trying to measure.",
            "And in fact, none of the absolute metrics even showed monotonic behavior with changes in ranking quality.",
            "So it might go up when you change ranking quality a little bit.",
            "But then larger changes the absolute metrics might go in the completely opposite direction, so you cannot really use this to optimize your ranking function on.",
            "To solve these problems, people have come up with two different ways of interpreting user interactions in in a relative sense and."
        ],
        [
            "The first solution is to interpret, for example, clicks as pairwise relevance judgments and with or pairwise labels.",
            "The intuition here is that.",
            "Look, you assume that people go through the list of results in a linear way, and if they skip a document and then click the next one, they assume that this shows preference relationship between those two documents.",
            "So in this example here, the user skipped the first document, but they actually clicked on the second one, and we would interpret this as a preference for the second document over the first document, and this lets you formulate this problem as a supervised learning problem that you try to predict whether the two documents are in the correct order or not.",
            "You can actually observe labels for that."
        ],
        [
            "The second possibility for interpreting user interactions is called interleaved comparison methods, and this is a list wise comparison method.",
            "The goal is basically to compare two ranking functions and you do that by constructing the lists that you showed to users from the two candidate rankings.",
            "So you basically generate an interleaved recites list.",
            "So you could imagine that at every rank that you want to fill, you flip according to the site.",
            "Which ranking function should contribute the document?",
            "After constructing that introduced list, you show that to the user observe their interactions with the list and then project this interaction.",
            "So for example, the clicks back to the original rankings and infer which one would win the comparison between by that particular user.",
            "And this seems to be a very robust way of detecting user preferences for ranking function Sir.",
            "Similar.",
            "So then you would need more data basically to detect the differences, but you know.",
            "The the ranks from the other.",
            "Second, he would.",
            "Choose the save both both items.",
            "Choosing the first one.",
            "Second, when you can't choose that one, so you might get a great weight, so there's a couple of variants, and some of them.",
            "This is a problem.",
            "We developed a probabilistic extension that takes these kind of overlapped into account and also gives you a waiting by the distance in terms of rank, so more similar.",
            "Rankings would be very likely to not detect any differences, but so this is something people have addressed."
        ],
        [
            "Alright, so to summarize, we basically now have two choices for interpreting user interactions with web search result pages.",
            "You can look at.",
            "The document pairwise and the document list twice interpretations.",
            "So now I'm going to look at how we can learn from this kind of information and."
        ],
        [
            "Especially how to balance exploration exploitation in this setting and the work that I'm presenting here was part of my dissertation and is in collaboration with Shimon Whiteson and Marc Indica."
        ],
        [
            "First of all I want to explain a little bit more about our problem formulation, so we're formulating this problem as a contextual bandit problem, so we're assuming that we have some retrieval system or an agent that learns from interactions with the environment or user in this case.",
            "So we have a user that submits some query.",
            "The retrieval system has to respond with the document list, and then it can observe some kind of interaction of the user with the retrieval engine, and it can interpret that.",
            "To try to update its ranking function to improve performance in the future.",
            "We're optimizing here cumulative discounted regrets, so we reward sorry, cumulative discounted reward because we want to make sure that the system tries to learn as quickly as possible, because here it's important that.",
            "That we keep the users happy basically.",
            "While while we're learning."
        ],
        [
            "So in this setting then we can formulate an exploration exploitation challenge, meaning that we need to explore as effectively as possible to make sure that we obtain feedback that is useful for learning.",
            "At the same time, we need to exploit what we have already learned to keep users happy while they're interacting with the search engine, because otherwise we might collect data that is very useful for learning, but by the time we have learned a useful ranking function, everyone has abandoned our search engine and we don't have anyone to show our.",
            "Excellent ranking two anymore.",
            "All right, when we started working on this, the two learning to write methods that were applicable to the setting where either purely exploratory or purely exploitative, and I show how we change those two, allows some balance of exploration and exploitation."
        ],
        [
            "Alright, so the key question we were asking in this book is whether an online learning to rank can be improved by balancing exploration exploitation, and it's possible that if we just learn quickly enough we could just get away with having a brief exploration phase in the beginning, learn as well as possible and then exploit after that.",
            "But it turns out that that's not the case.",
            "We addressed this question by implementing extensions.",
            "22 algorithms, one pairwise and listwise, that allowed balancing, exploration and exploitation.",
            "And then we study the performance of this algorithm under different settings and mainly that means under different assumptions about user behavior and how users interact with the result pages."
        ],
        [
            "First of all, we modified the pairwise learning to rank approach.",
            "So here our input is some pairs of feature vectors, forgiven queries and document pairs and we want to predict whether the direction we want to predict the direction of preference for this document pair.",
            "So we want to say whether the I should be ranked before after DJ.",
            "So we do this in this case using simple stochastic gradient descent with an update rule that maintains some margin.",
            "Alright now."
        ],
        [
            "How can we explore in the setting?",
            "The baseline is purely exploitive, because in the baseline algorithm we would just, at every step takes the weight vector that we have learned so far, generate the ranking according to the state vector, and show that to the user.",
            "So given what we have already learned, this would give the best possible ranking.",
            "But there's no exploration in there at all.",
            "Our idea was to adapt, epsilon, greedy, and basically at every rank that we needed to fill.",
            "We would select the next exploitive document with probability 1 minus epsilon, and we would select a randomly sampled exploratory candidate document with probability epsilon and randomly.",
            "Sampled here means randomly sampled from a candidate pools.",
            "So that may make sure that there are some minimum quality or some minimum match between the query and the candidate document.",
            "And then the amount of exploration here would be determined by this parameter EPS."
        ],
        [
            "In the list price setting, we started from a purely exploratory algorithm that is called dueling bandit gradient descent and was developed by you song you and tossing your Kims and the idea here is that in every iteration or basically for every incoming query we generate the ranking of documents according to what we have learned so far and we also generate an exploratory rate vector.",
            "Example WT prime that is basically generated by randomly sampling a unit sphere around our current best weight vector.",
            "So at every iteration we have these two weight vectors.",
            "One exploratory want exploitive and we can compare those using this introduced comparison method that I mentioned before.",
            "So if our current best weight vector wins the comparison we just maintain this weight vector, otherwise we update in the direction of our exploratory candidate vector."
        ],
        [
            "Now this list baseline is purely exploratory because in the interleaving method you make sure that you have an even number of documents from the exploratory and the exploitive ranking, and this ensures that the information you get for learning is, as is maximized.",
            "Our idea here was no to allow for statistical interleaving, where you could change the ratio between exploratory and exploitive documents.",
            "Let's determined by this parameter K. So instead of this original interleaving where you ensure that you have this the same proportion of exploratory and exploitative documents, we can now change that ratio to create a more exploitive document list, and then after we observe the clicks and project them back to the original rankings.",
            "We compensate for the spiders that was introduced due to the change in documentary shows."
        ],
        [
            "Alright, so to briefly summarize, we have two approaches in which we want to understand how balancing exploration and exploitation effects online learning to rank for information retrieval.",
            "The pairwise approach exploits by presenting the current best rancor, and it explores by injecting random documents into the ranking.",
            "The listwise approach is exploratory by nature, but we explored more by showing more exploitive documents.",
            "We test our approaches in a simulation approach that is based on standard learning to rank datasets and probabilistic user model those."
        ],
        [
            "Running to rank datasets or based on web search settings and they provide you with queries and the extracted feature vectors for candidate documents and they also give us the ground truth annotations made by experts so we can simulate what happens for relevant and non relevant documents.",
            "Our probabilistic click model takes those datasets as input and it generates user behavior based on them, and this allows us to test our methods under different assumptions.",
            "So, for example, we can implement a perfect user that always goes through the over cyclist and clicks on all relevant documents and never clicks on non relevant documents.",
            "Or the more realistic scenario of a navigational user that tends to be pretty good in figuring out whether a document is relevant or not.",
            "But still once in awhile there might be some noise in that evaluation and they might.",
            "Accidentally click on a non relevant document and then the noisiest user model we tried.",
            "Here is the information the document where people information the model where the difference between the probability of clicking on a relevant document and a non relevant document is smallest.",
            "Right and then we basically simulate the interactions between our user model and the search engine that runs those different algorithms.",
            "OK."
        ],
        [
            "We first look at the results for the Paris approach, and this is for one data set only.",
            "We see here the performance under perfect user feedback, navigation and the noisiest informational click feedback.",
            "Epsilon here is varied between zero, which means pure exploitation, so that would be the baseline setting and one which is pure exploration.",
            "Now pure exploration means that we basically randomly shuffle the candidate documents and we can see that online performance in this setting is very low.",
            "We can also see that when we have perfect user like, this approach works very reliably.",
            "We can very quickly learn a good ranking function for this setting from the reliable labels that we that we observe.",
            "But we can also see that under noise performance very quickly degrades and the purely exploitive setting, especially is very much affected by noise, and it basically picks up on the wrong signal and converges to something on optimal we can slightly.",
            "Improve performance by injecting these exploratory documents.",
            "So you see that the optimal setting moves towards more exploratory setting as noise increases, but it's not enough to get back to the original performance."
        ],
        [
            "Right, yeah sure.",
            "Very high exploration, smallest.",
            "The performance is modest constant matrices.",
            "The data set right?",
            "So this is here because we're measuring online performance.",
            "So this means that we look at the result lists that users see, and we basically compute the performance of what users experience while the system is learning.",
            "So if you always randomly shuffle your re cyclists and they never see anything that is very useful for them.",
            "Exactly.",
            "We also looked at offline performance to understand how the algorithm actually learns in these different settings, and we can see that under under perfect user feedback, the algorithm learns very well and you can basically exploit as much as you want because it learns as well as possible in this setting, and there's no penalty to explore to exploiting a lot.",
            "MSU increase the amount of noise and user feedback, the exploitive settings, or less and less able to pick up the signal in the user feedback.",
            "And then you have to explore, to some degree to get back to a reasonable reasonable learning performance.",
            "Right, so we can see that for the Paris approach, it's very effective under reliable feedback, but high level of exploration is needed to counter noise and user feedback.",
            "Right?"
        ],
        [
            "Now, switching to the listwise approach.",
            "First of all, we can see that performance is much more robust to the exploratory or exploitive setting, and over here we very K, where K of 0.5 means pure exploration.",
            "The setting allows us to collect as reliable feedback as possible for learning and 0.1 SC.",
            "Minimum K that still allows you to learn something.",
            "So as I already mentioned, we can see that the approach is relatively robust to noise.",
            "We also see that the highest level of performance is achieved in more exploitive settings, irrespective of noise.",
            "So this shows that on the purely exploratory baseline that was known before, it's basically exploring too much.",
            "You can get away with a lot less exploration, for example by injecting one or two documents, exploratory documents per top 10 result lists still allows you to learn very well and achieve good online performance."
        ],
        [
            "Right, we also looked again at the offline performance and we see again that under reliable feedback, no matter what the level of exploration is, we learn very well and as noise increases.",
            "Obviously we learn a little bit better when we.",
            "Have 3 alright.",
            "We actually learn better when we have a somewhat exploitive setting, because it basically decreases the risk.",
            "Of showing that results to the users.",
            "So overall we can see that the baseline approach over explores we can decrease the amount of exploration to improve online performance.",
            "Also, we saw that the list price approach is much more robust to noise than the Paris approach we so earlier."
        ],
        [
            "In summary, I guess an example of an application that learns directly from user interactions, most promising in this setting is to interpret user interactions as relative feedback for learning.",
            "Then I looked at balancing exploration and exploitation in the setting and showed how it can improve online performance.",
            "The optimal performance here depends on or the optimal balance depends on the approach we're picking, and we saw that there quite big differences.",
            "Between the parents and the list price approach with the list price approach being much more robust to the amount of noise and user feedback.",
            "All code for this work is implemented and made available publicly, and there's some documentation about the code available here."
        ],
        [
            "Um, some related and ongoing work from our from our lab is looking, for example, at how you can interpret user feedback and one of the methods that we developed is probabilistic interleaf that I briefly mentioned earlier.",
            "This basically looks at generating the Internet for cyclists for users as a sampling process that you find some distribution over documents from which you sample, and this allows you to, well, first of all, infer interleaf comparison outcomes based on a graphical model, and it also allows data reuse based on, for example, important sampling which opens many new areas of application for this.",
            "For this type of feedback we then looked at.",
            "How you can actually learn from those introduced comparisons and we showed that the data reuse that it enables can vary dramatically.",
            "Reduce the amount of required exploration and can substantially speed up learning in an online setting.",
            "Great."
        ],
        [
            "There's a lot of ongoing work and a lot of directions for future work.",
            "One of the ideas that I wanted to discuss a smart exploration so so far we have shown that balancing exploration exploitation improves online performance in online learning to rank for R. But the approach we take to exploration is very simple at the moment.",
            "It's basically random exploration, so we're looking now into trying to model the solution space in a more sophisticated way, which would allow us to.",
            "Kind of zoom into the most promising areas, much more quickly than is currently possible.",
            "That concludes my talk.",
            "Thank you very much for attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in my talk I will be focusing on challenges in online learning to rank for information retrieval.",
                    "label": 0
                },
                {
                    "sent": "Talking about learning in big Data in a lot of settings, we can collect as much data as we could hope for pretty much as much as we can fit in one of our data centers, but in a lot of these case.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is getting labels for our big data is the real problem?",
                    "label": 1
                },
                {
                    "sent": "In many cases it's really expensive to pay annotators to provide labels, or there might not be.",
                    "label": 0
                },
                {
                    "sent": "Any human annotators actually able to do this task for us.",
                    "label": 0
                },
                {
                    "sent": "One of the cases where it's hard to get explicit labels is.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Web search.",
                    "label": 0
                },
                {
                    "sent": "What everyone is familiar with Google.",
                    "label": 0
                },
                {
                    "sent": "You type the crew.",
                    "label": 0
                },
                {
                    "sent": "You get some list of results and in the setting we want to learn some kind of ranking function that tells us what a good result list looks like.",
                    "label": 0
                },
                {
                    "sent": "In this scenario we have some context.",
                    "label": 0
                },
                {
                    "sent": "So for example, we know the user, we know the query and we have some items, some web documents that we want to rank correctly for that particular user in that particular query.",
                    "label": 0
                },
                {
                    "sent": "Usually the relationship between.",
                    "label": 0
                },
                {
                    "sent": "User and query on the one hand and the candidate documents on the other hand is expressed in some kind of feature vector which may contain some kind of information about the match between a query and the document.",
                    "label": 0
                },
                {
                    "sent": "So for example in the form of TF, IDF gives you some measure of popularity of that particular candidate page matches with the user history or popularity of those pages in a particular location, so usually will have feature vector that has maybe 100.",
                    "label": 0
                },
                {
                    "sent": "Non sparse entries and the goal is to rank the documents to maximize some utility to the user.",
                    "label": 1
                },
                {
                    "sent": "But usually we cannot observe that utility directly and it's actually very hard to train annotators to tell us what the useful information is, so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For example, if we have to create large scale learning, we have some trained annotators and you know it.",
                    "label": 1
                },
                {
                    "sent": "Typically decision that they would have to make us.",
                    "label": 0
                },
                {
                    "sent": "Whether this website that we're showing here is relevant to this query.",
                    "label": 0
                },
                {
                    "sent": "Large scale learning, so we might look at it and say, well, it has something to do with the query so well.",
                    "label": 0
                },
                {
                    "sent": "I guess it's relevant, but it becomes really, really hard to say.",
                    "label": 0
                },
                {
                    "sent": "Well it's this perfect page.",
                    "label": 0
                },
                {
                    "sent": "Is this a very good page?",
                    "label": 0
                },
                {
                    "sent": "You know it's it's a four or five.",
                    "label": 0
                },
                {
                    "sent": "So for an annotator it's usually very difficult to make that decision, whereas the person actually typing that query may have a very good idea of whether this is relevant or not.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when we have difficulties collecting labels for large scale learning, there's a couple of approaches that we could follow.",
                    "label": 0
                },
                {
                    "sent": "One possibility would be to try to use the labels that we have observed as effectively as possible so to mind comfort samples, semi supervised learning approaches where we try to bootstrap from the few reliable labels that we have.",
                    "label": 0
                },
                {
                    "sent": "We could try to do some kind of crowdsourcing where we get noisy labels from a large number of people and try to somehow figure out how reliable they are.",
                    "label": 0
                },
                {
                    "sent": "Or we could try to learn.",
                    "label": 0
                },
                {
                    "sent": "Innovate directly from the environment directly by interacting with the users of a specific system and in web search.",
                    "label": 1
                },
                {
                    "sent": "We actually do have users that use our system, so this is the kind.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approach that we that we are focusing on in this scenario now why is it difficult to learn directly from users of a system?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are two challenges in particular that I want to focus on in this talk.",
                    "label": 0
                },
                {
                    "sent": "First of all, our users don't give us the kinds of labels that we might expect in a supervised learning setting.",
                    "label": 0
                },
                {
                    "sent": "You know, there's no IID sample of items where we get unbiased estimates of, for example, the relevance of the webpage.",
                    "label": 0
                },
                {
                    "sent": "So we need to understand how we can interpret the user interactions that we can observe.",
                    "label": 1
                },
                {
                    "sent": "So the problem we run into is balancing exploration exploitation, because now we're directly interacting with users, we need to make sure that what we're showing them is useful at all points in time, but at the same time we present information in a way that still lets us pick up some information for learning in the future.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first of all, I look at interpreting user interactions and.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of work on how to interpret user interaction in information retrieval or web search specifically, and some of the most well known work comes from the group.",
                    "label": 0
                },
                {
                    "sent": "Of course, new Akims and his colleagues and they ran a couple of user studies where they showed how exactly how biased the data is that we could extract from user interactions.",
                    "label": 0
                },
                {
                    "sent": "So in this particular study they had people come to the lab.",
                    "label": 0
                },
                {
                    "sent": "Search the web and then they recorded what people were looking at and also what results they clicked and they found that phenomenon called the position bias that people are very likely to look at the top results and subsequently click on the top results and as you go further down in the rank with cyclist, people become very unlikely to even look at your pages.",
                    "label": 0
                },
                {
                    "sent": "So this basically shows that the kind of information you observe, the interactions you observe.",
                    "label": 0
                },
                {
                    "sent": "Are very much biased by how you present the results.",
                    "label": 0
                },
                {
                    "sent": "This has some implications for the kinds of things that we measure.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Usually today people use some kind of absolute metric, for example in the context of a B testing to see whether one ranking works better than another.",
                    "label": 0
                },
                {
                    "sent": "And this just list some of the absolute metrics that are typically used.",
                    "label": 1
                },
                {
                    "sent": "For example, you could look at the number of queries in a session, the number of clicks on the result pages per query.",
                    "label": 0
                },
                {
                    "sent": "The time to first take etc etc and some large scale experiments.",
                    "label": 0
                },
                {
                    "sent": "Olivier Chappelle and his colleagues found that actually none of these absolute metrics reliably correlated with the quality of the ranking function that they were trying to measure.",
                    "label": 0
                },
                {
                    "sent": "And in fact, none of the absolute metrics even showed monotonic behavior with changes in ranking quality.",
                    "label": 1
                },
                {
                    "sent": "So it might go up when you change ranking quality a little bit.",
                    "label": 0
                },
                {
                    "sent": "But then larger changes the absolute metrics might go in the completely opposite direction, so you cannot really use this to optimize your ranking function on.",
                    "label": 0
                },
                {
                    "sent": "To solve these problems, people have come up with two different ways of interpreting user interactions in in a relative sense and.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first solution is to interpret, for example, clicks as pairwise relevance judgments and with or pairwise labels.",
                    "label": 1
                },
                {
                    "sent": "The intuition here is that.",
                    "label": 0
                },
                {
                    "sent": "Look, you assume that people go through the list of results in a linear way, and if they skip a document and then click the next one, they assume that this shows preference relationship between those two documents.",
                    "label": 1
                },
                {
                    "sent": "So in this example here, the user skipped the first document, but they actually clicked on the second one, and we would interpret this as a preference for the second document over the first document, and this lets you formulate this problem as a supervised learning problem that you try to predict whether the two documents are in the correct order or not.",
                    "label": 0
                },
                {
                    "sent": "You can actually observe labels for that.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second possibility for interpreting user interactions is called interleaved comparison methods, and this is a list wise comparison method.",
                    "label": 1
                },
                {
                    "sent": "The goal is basically to compare two ranking functions and you do that by constructing the lists that you showed to users from the two candidate rankings.",
                    "label": 0
                },
                {
                    "sent": "So you basically generate an interleaved recites list.",
                    "label": 0
                },
                {
                    "sent": "So you could imagine that at every rank that you want to fill, you flip according to the site.",
                    "label": 0
                },
                {
                    "sent": "Which ranking function should contribute the document?",
                    "label": 0
                },
                {
                    "sent": "After constructing that introduced list, you show that to the user observe their interactions with the list and then project this interaction.",
                    "label": 0
                },
                {
                    "sent": "So for example, the clicks back to the original rankings and infer which one would win the comparison between by that particular user.",
                    "label": 0
                },
                {
                    "sent": "And this seems to be a very robust way of detecting user preferences for ranking function Sir.",
                    "label": 0
                },
                {
                    "sent": "Similar.",
                    "label": 0
                },
                {
                    "sent": "So then you would need more data basically to detect the differences, but you know.",
                    "label": 0
                },
                {
                    "sent": "The the ranks from the other.",
                    "label": 0
                },
                {
                    "sent": "Second, he would.",
                    "label": 0
                },
                {
                    "sent": "Choose the save both both items.",
                    "label": 0
                },
                {
                    "sent": "Choosing the first one.",
                    "label": 0
                },
                {
                    "sent": "Second, when you can't choose that one, so you might get a great weight, so there's a couple of variants, and some of them.",
                    "label": 0
                },
                {
                    "sent": "This is a problem.",
                    "label": 0
                },
                {
                    "sent": "We developed a probabilistic extension that takes these kind of overlapped into account and also gives you a waiting by the distance in terms of rank, so more similar.",
                    "label": 0
                },
                {
                    "sent": "Rankings would be very likely to not detect any differences, but so this is something people have addressed.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so to summarize, we basically now have two choices for interpreting user interactions with web search result pages.",
                    "label": 1
                },
                {
                    "sent": "You can look at.",
                    "label": 0
                },
                {
                    "sent": "The document pairwise and the document list twice interpretations.",
                    "label": 0
                },
                {
                    "sent": "So now I'm going to look at how we can learn from this kind of information and.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Especially how to balance exploration exploitation in this setting and the work that I'm presenting here was part of my dissertation and is in collaboration with Shimon Whiteson and Marc Indica.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First of all I want to explain a little bit more about our problem formulation, so we're formulating this problem as a contextual bandit problem, so we're assuming that we have some retrieval system or an agent that learns from interactions with the environment or user in this case.",
                    "label": 1
                },
                {
                    "sent": "So we have a user that submits some query.",
                    "label": 0
                },
                {
                    "sent": "The retrieval system has to respond with the document list, and then it can observe some kind of interaction of the user with the retrieval engine, and it can interpret that.",
                    "label": 0
                },
                {
                    "sent": "To try to update its ranking function to improve performance in the future.",
                    "label": 0
                },
                {
                    "sent": "We're optimizing here cumulative discounted regrets, so we reward sorry, cumulative discounted reward because we want to make sure that the system tries to learn as quickly as possible, because here it's important that.",
                    "label": 0
                },
                {
                    "sent": "That we keep the users happy basically.",
                    "label": 0
                },
                {
                    "sent": "While while we're learning.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this setting then we can formulate an exploration exploitation challenge, meaning that we need to explore as effectively as possible to make sure that we obtain feedback that is useful for learning.",
                    "label": 1
                },
                {
                    "sent": "At the same time, we need to exploit what we have already learned to keep users happy while they're interacting with the search engine, because otherwise we might collect data that is very useful for learning, but by the time we have learned a useful ranking function, everyone has abandoned our search engine and we don't have anyone to show our.",
                    "label": 0
                },
                {
                    "sent": "Excellent ranking two anymore.",
                    "label": 1
                },
                {
                    "sent": "All right, when we started working on this, the two learning to write methods that were applicable to the setting where either purely exploratory or purely exploitative, and I show how we change those two, allows some balance of exploration and exploitation.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so the key question we were asking in this book is whether an online learning to rank can be improved by balancing exploration exploitation, and it's possible that if we just learn quickly enough we could just get away with having a brief exploration phase in the beginning, learn as well as possible and then exploit after that.",
                    "label": 1
                },
                {
                    "sent": "But it turns out that that's not the case.",
                    "label": 0
                },
                {
                    "sent": "We addressed this question by implementing extensions.",
                    "label": 0
                },
                {
                    "sent": "22 algorithms, one pairwise and listwise, that allowed balancing, exploration and exploitation.",
                    "label": 1
                },
                {
                    "sent": "And then we study the performance of this algorithm under different settings and mainly that means under different assumptions about user behavior and how users interact with the result pages.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First of all, we modified the pairwise learning to rank approach.",
                    "label": 1
                },
                {
                    "sent": "So here our input is some pairs of feature vectors, forgiven queries and document pairs and we want to predict whether the direction we want to predict the direction of preference for this document pair.",
                    "label": 0
                },
                {
                    "sent": "So we want to say whether the I should be ranked before after DJ.",
                    "label": 0
                },
                {
                    "sent": "So we do this in this case using simple stochastic gradient descent with an update rule that maintains some margin.",
                    "label": 1
                },
                {
                    "sent": "Alright now.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How can we explore in the setting?",
                    "label": 0
                },
                {
                    "sent": "The baseline is purely exploitive, because in the baseline algorithm we would just, at every step takes the weight vector that we have learned so far, generate the ranking according to the state vector, and show that to the user.",
                    "label": 0
                },
                {
                    "sent": "So given what we have already learned, this would give the best possible ranking.",
                    "label": 0
                },
                {
                    "sent": "But there's no exploration in there at all.",
                    "label": 0
                },
                {
                    "sent": "Our idea was to adapt, epsilon, greedy, and basically at every rank that we needed to fill.",
                    "label": 0
                },
                {
                    "sent": "We would select the next exploitive document with probability 1 minus epsilon, and we would select a randomly sampled exploratory candidate document with probability epsilon and randomly.",
                    "label": 1
                },
                {
                    "sent": "Sampled here means randomly sampled from a candidate pools.",
                    "label": 0
                },
                {
                    "sent": "So that may make sure that there are some minimum quality or some minimum match between the query and the candidate document.",
                    "label": 1
                },
                {
                    "sent": "And then the amount of exploration here would be determined by this parameter EPS.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the list price setting, we started from a purely exploratory algorithm that is called dueling bandit gradient descent and was developed by you song you and tossing your Kims and the idea here is that in every iteration or basically for every incoming query we generate the ranking of documents according to what we have learned so far and we also generate an exploratory rate vector.",
                    "label": 0
                },
                {
                    "sent": "Example WT prime that is basically generated by randomly sampling a unit sphere around our current best weight vector.",
                    "label": 0
                },
                {
                    "sent": "So at every iteration we have these two weight vectors.",
                    "label": 0
                },
                {
                    "sent": "One exploratory want exploitive and we can compare those using this introduced comparison method that I mentioned before.",
                    "label": 0
                },
                {
                    "sent": "So if our current best weight vector wins the comparison we just maintain this weight vector, otherwise we update in the direction of our exploratory candidate vector.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now this list baseline is purely exploratory because in the interleaving method you make sure that you have an even number of documents from the exploratory and the exploitive ranking, and this ensures that the information you get for learning is, as is maximized.",
                    "label": 0
                },
                {
                    "sent": "Our idea here was no to allow for statistical interleaving, where you could change the ratio between exploratory and exploitive documents.",
                    "label": 1
                },
                {
                    "sent": "Let's determined by this parameter K. So instead of this original interleaving where you ensure that you have this the same proportion of exploratory and exploitative documents, we can now change that ratio to create a more exploitive document list, and then after we observe the clicks and project them back to the original rankings.",
                    "label": 1
                },
                {
                    "sent": "We compensate for the spiders that was introduced due to the change in documentary shows.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so to briefly summarize, we have two approaches in which we want to understand how balancing exploration and exploitation effects online learning to rank for information retrieval.",
                    "label": 0
                },
                {
                    "sent": "The pairwise approach exploits by presenting the current best rancor, and it explores by injecting random documents into the ranking.",
                    "label": 1
                },
                {
                    "sent": "The listwise approach is exploratory by nature, but we explored more by showing more exploitive documents.",
                    "label": 0
                },
                {
                    "sent": "We test our approaches in a simulation approach that is based on standard learning to rank datasets and probabilistic user model those.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Running to rank datasets or based on web search settings and they provide you with queries and the extracted feature vectors for candidate documents and they also give us the ground truth annotations made by experts so we can simulate what happens for relevant and non relevant documents.",
                    "label": 0
                },
                {
                    "sent": "Our probabilistic click model takes those datasets as input and it generates user behavior based on them, and this allows us to test our methods under different assumptions.",
                    "label": 1
                },
                {
                    "sent": "So, for example, we can implement a perfect user that always goes through the over cyclist and clicks on all relevant documents and never clicks on non relevant documents.",
                    "label": 0
                },
                {
                    "sent": "Or the more realistic scenario of a navigational user that tends to be pretty good in figuring out whether a document is relevant or not.",
                    "label": 0
                },
                {
                    "sent": "But still once in awhile there might be some noise in that evaluation and they might.",
                    "label": 0
                },
                {
                    "sent": "Accidentally click on a non relevant document and then the noisiest user model we tried.",
                    "label": 0
                },
                {
                    "sent": "Here is the information the document where people information the model where the difference between the probability of clicking on a relevant document and a non relevant document is smallest.",
                    "label": 0
                },
                {
                    "sent": "Right and then we basically simulate the interactions between our user model and the search engine that runs those different algorithms.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We first look at the results for the Paris approach, and this is for one data set only.",
                    "label": 1
                },
                {
                    "sent": "We see here the performance under perfect user feedback, navigation and the noisiest informational click feedback.",
                    "label": 1
                },
                {
                    "sent": "Epsilon here is varied between zero, which means pure exploitation, so that would be the baseline setting and one which is pure exploration.",
                    "label": 1
                },
                {
                    "sent": "Now pure exploration means that we basically randomly shuffle the candidate documents and we can see that online performance in this setting is very low.",
                    "label": 0
                },
                {
                    "sent": "We can also see that when we have perfect user like, this approach works very reliably.",
                    "label": 0
                },
                {
                    "sent": "We can very quickly learn a good ranking function for this setting from the reliable labels that we that we observe.",
                    "label": 0
                },
                {
                    "sent": "But we can also see that under noise performance very quickly degrades and the purely exploitive setting, especially is very much affected by noise, and it basically picks up on the wrong signal and converges to something on optimal we can slightly.",
                    "label": 0
                },
                {
                    "sent": "Improve performance by injecting these exploratory documents.",
                    "label": 0
                },
                {
                    "sent": "So you see that the optimal setting moves towards more exploratory setting as noise increases, but it's not enough to get back to the original performance.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, yeah sure.",
                    "label": 0
                },
                {
                    "sent": "Very high exploration, smallest.",
                    "label": 0
                },
                {
                    "sent": "The performance is modest constant matrices.",
                    "label": 0
                },
                {
                    "sent": "The data set right?",
                    "label": 0
                },
                {
                    "sent": "So this is here because we're measuring online performance.",
                    "label": 0
                },
                {
                    "sent": "So this means that we look at the result lists that users see, and we basically compute the performance of what users experience while the system is learning.",
                    "label": 0
                },
                {
                    "sent": "So if you always randomly shuffle your re cyclists and they never see anything that is very useful for them.",
                    "label": 0
                },
                {
                    "sent": "Exactly.",
                    "label": 0
                },
                {
                    "sent": "We also looked at offline performance to understand how the algorithm actually learns in these different settings, and we can see that under under perfect user feedback, the algorithm learns very well and you can basically exploit as much as you want because it learns as well as possible in this setting, and there's no penalty to explore to exploiting a lot.",
                    "label": 0
                },
                {
                    "sent": "MSU increase the amount of noise and user feedback, the exploitive settings, or less and less able to pick up the signal in the user feedback.",
                    "label": 0
                },
                {
                    "sent": "And then you have to explore, to some degree to get back to a reasonable reasonable learning performance.",
                    "label": 0
                },
                {
                    "sent": "Right, so we can see that for the Paris approach, it's very effective under reliable feedback, but high level of exploration is needed to counter noise and user feedback.",
                    "label": 1
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, switching to the listwise approach.",
                    "label": 1
                },
                {
                    "sent": "First of all, we can see that performance is much more robust to the exploratory or exploitive setting, and over here we very K, where K of 0.5 means pure exploration.",
                    "label": 0
                },
                {
                    "sent": "The setting allows us to collect as reliable feedback as possible for learning and 0.1 SC.",
                    "label": 0
                },
                {
                    "sent": "Minimum K that still allows you to learn something.",
                    "label": 0
                },
                {
                    "sent": "So as I already mentioned, we can see that the approach is relatively robust to noise.",
                    "label": 0
                },
                {
                    "sent": "We also see that the highest level of performance is achieved in more exploitive settings, irrespective of noise.",
                    "label": 1
                },
                {
                    "sent": "So this shows that on the purely exploratory baseline that was known before, it's basically exploring too much.",
                    "label": 0
                },
                {
                    "sent": "You can get away with a lot less exploration, for example by injecting one or two documents, exploratory documents per top 10 result lists still allows you to learn very well and achieve good online performance.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, we also looked again at the offline performance and we see again that under reliable feedback, no matter what the level of exploration is, we learn very well and as noise increases.",
                    "label": 0
                },
                {
                    "sent": "Obviously we learn a little bit better when we.",
                    "label": 0
                },
                {
                    "sent": "Have 3 alright.",
                    "label": 0
                },
                {
                    "sent": "We actually learn better when we have a somewhat exploitive setting, because it basically decreases the risk.",
                    "label": 0
                },
                {
                    "sent": "Of showing that results to the users.",
                    "label": 0
                },
                {
                    "sent": "So overall we can see that the baseline approach over explores we can decrease the amount of exploration to improve online performance.",
                    "label": 0
                },
                {
                    "sent": "Also, we saw that the list price approach is much more robust to noise than the Paris approach we so earlier.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In summary, I guess an example of an application that learns directly from user interactions, most promising in this setting is to interpret user interactions as relative feedback for learning.",
                    "label": 1
                },
                {
                    "sent": "Then I looked at balancing exploration and exploitation in the setting and showed how it can improve online performance.",
                    "label": 0
                },
                {
                    "sent": "The optimal performance here depends on or the optimal balance depends on the approach we're picking, and we saw that there quite big differences.",
                    "label": 0
                },
                {
                    "sent": "Between the parents and the list price approach with the list price approach being much more robust to the amount of noise and user feedback.",
                    "label": 0
                },
                {
                    "sent": "All code for this work is implemented and made available publicly, and there's some documentation about the code available here.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, some related and ongoing work from our from our lab is looking, for example, at how you can interpret user feedback and one of the methods that we developed is probabilistic interleaf that I briefly mentioned earlier.",
                    "label": 0
                },
                {
                    "sent": "This basically looks at generating the Internet for cyclists for users as a sampling process that you find some distribution over documents from which you sample, and this allows you to, well, first of all, infer interleaf comparison outcomes based on a graphical model, and it also allows data reuse based on, for example, important sampling which opens many new areas of application for this.",
                    "label": 1
                },
                {
                    "sent": "For this type of feedback we then looked at.",
                    "label": 0
                },
                {
                    "sent": "How you can actually learn from those introduced comparisons and we showed that the data reuse that it enables can vary dramatically.",
                    "label": 1
                },
                {
                    "sent": "Reduce the amount of required exploration and can substantially speed up learning in an online setting.",
                    "label": 0
                },
                {
                    "sent": "Great.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's a lot of ongoing work and a lot of directions for future work.",
                    "label": 0
                },
                {
                    "sent": "One of the ideas that I wanted to discuss a smart exploration so so far we have shown that balancing exploration exploitation improves online performance in online learning to rank for R. But the approach we take to exploration is very simple at the moment.",
                    "label": 1
                },
                {
                    "sent": "It's basically random exploration, so we're looking now into trying to model the solution space in a more sophisticated way, which would allow us to.",
                    "label": 0
                },
                {
                    "sent": "Kind of zoom into the most promising areas, much more quickly than is currently possible.",
                    "label": 0
                },
                {
                    "sent": "That concludes my talk.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for attention.",
                    "label": 0
                }
            ]
        }
    }
}