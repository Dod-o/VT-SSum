{
    "id": "kczaeliapxcfi5rxraew2zxkygyvjgcr",
    "title": "Frequency-Space Decomposition and Acquisition of Light Transport under Spatially Varying Illumination",
    "info": {
        "author": [
            "Ravi Ramamoorthi, UC Berkeley"
        ],
        "chairman": [
            "Bernt Schiele, Max Planck Institut Informatik, Max Planck Institute",
            "David Forsyth, Department of Computer Science, University of Illinois at Urbana-Champaign"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision->Color, Texture, Illumination & Reflectance"
        ]
    },
    "url": "http://videolectures.net/eccv2012_ramamoorthi_decomposition/",
    "segmentation": [
        [
            "Welcome everyone, so I'm going to talk about the composition and acquisition of light transport under specially varying lighting, and this is work with my postdoc Dick Pool Ready and Brian Curlis was sabbatical visitor.",
            "Unfortunately, Dick Powell can't be here because of visa issues."
        ],
        [
            "So first let me distinguish between distant and spatially varying lighting.",
            "Distant illumination is typically diffuse at the scene and comes from far away light sources, so the lighting varies angularly in different directions at the scene, but there's little or no spatial variation."
        ],
        [
            "In contrast, spatially varying lighting focuses on the scene, and so you get strong spatial variations.",
            "Usually the lighting comes from a small range of angles or from a single light source."
        ],
        [
            "There are many applications of spatially varying lighting.",
            "Perhaps one of the most popular is structured light to acquire the shape of objects, but beyond that we use image in with your projection augmented reality applications."
        ],
        [
            "And in this talk, we're going to consider a projector camera system, so you have a projector which projects some kind of pattern onto an object or onto a scene.",
            "In this case, I've shown seen modeled after the Cornell Box in computer graphics for illustration and to give a good example.",
            "The camera then sees this image and we assume that we've done the calibration so effectively they can be regarded as aligned or collocated, although in practice there of course not Co located in the set."
        ],
        [
            "What light transport tells us is that given an input projector pattern, what's the output camera image?",
            "So if I use this pattern from the projector, I would see this image in the camera."
        ],
        [
            "OK so here I'm showing lit by the floodlight, which is turning on the whole projector and there you can see the effects of diffuse interreflections from some of the walls of the box onto the ceiling and the floor.",
            "You can also see the subsurface scattering effects on the candle and you can now see little bit more clearly in dimmer lights.",
            "And these are the kinds of visual effects we want to be able to capture for a diffuse scene."
        ],
        [
            "So let's look at what the light transport matrix looks like.",
            "So first consider one column of the matrix and that corresponds to a particular projector pixel.",
            "So of course you get light which hits the scene and goes directly into the camera."
        ],
        [
            "But you can also get light at other camera pixel locations, such as from subsurface scattering."
        ],
        [
            "Or from diffuse interreflections.",
            "Now let's"
        ],
        [
            "Look at rule of the light transport matrix that corresponds to a given camera pixel, and throughout this talk will be considering a single camera pixel, which is really a rule of the light transport.",
            "So of course you get information from the projector that illuminates the point that the camera pixel sees."
        ],
        [
            "But you also get contributions from other projector pixels, such as from subsurface scattering or local interrupt."
        ],
        [
            "Elections as well as from more global diffuse interep."
        ],
        [
            "Elections.",
            "The light transport matrix is actually 4 dimensional, so it has two image dimensions and two projector dimensions.",
            "But to visualize it will look at a single scan line in the image in a single scanline in the projector.",
            "So it's 2D.",
            "And the IT consists of three main components for it.",
            "If you say so, first is the diagonal, which is the direct component.",
            "Remember I said we've calibrated it so the projector and camera can be considered to be aligned or colocated.",
            "Then we have the subsurface scattering, which is a banded diagonal and then you have the diffuse interreflections which are low rank and low frequency but effect the entire matrix.",
            "So what this paper shows is you can acquire."
        ],
        [
            "This entire light transport using very few patterns so you can acquire this full 128 by 128 projector that 16,380 four element projector pixels using more an order of magnitude fewer patterns with high Fidelity.",
            "So we used only 1000 instead of the 16,000."
        ],
        [
            "Atoms.",
            "And here's another example in different lighting conditions where you see the reconstructed image quite closely match."
        ],
        [
            "Just the original.",
            "Moreover, we decompose the light transport into its constituents, which is the direct lighting.",
            "Notice that the candle is almost entirely black because most of the image and the candle comes from subsurface scattering, so we're able to decompose the near field lighting as well as the far field lighting that has the interreflection components very clearly in that image."
        ],
        [
            "And so, here is another example under a different lighting condition."
        ],
        [
            "So our contributions are to decompose like transport into its physical direct near in far range components and to efficiently acquire them savings over in order of magnitude versus brute force and in fact achieving an optimality consideration with respect to the model we use.",
            "We analyze this using the projectors frequency space.",
            "Let me just say a little bit about previous work."
        ],
        [
            "Of the previous work is focused on distant illumination and making locally low rank assumptions spatially.",
            "Varying illumination has been considered, but most methods are brute force, and so it's very expensive to acquire the full light transport matrix."
        ],
        [
            "We are of course inspired by the great work on decomposition, so in particular the direct global separation of Myra Tall, but that's aimed at a single floodlit image, not the full light transport.",
            "And we also separate out the near and far field components in concurrent work.",
            "Too little.",
            "It's a graph presented an intuitive approach to recover certain light transport parts, but again focused in a single image, not the full light transport.",
            "So let me talk."
        ],
        [
            "Now about our technical approach."
        ],
        [
            "As I said earlier, the transport matrix includes three terms, so the first of these is the direct component, which is along the diagonal, and it has large magnitude."
        ],
        [
            "The second is the new range component, which is really a banded diagonal and sparse, and this mainly due to subsurface effects.",
            "Also local into reflect."
        ],
        [
            "And finally, the far range effects which are dense affect the entire matrix, but a small magnitude in low frequency."
        ],
        [
            "So here's the direct transport along the diagonal.",
            "And remember, I'm talking about a single camera pixel.",
            "Other pixels behave similarly, so I'm considering one row along the light transport."
        ],
        [
            "And so for that single camera pixel, if I consider the 2D space of the projector, we have really only one unknown, which is the projector pixel corresponding to that camera pixel.",
            "What is the intensity in the light transport matrix in the frequency domain?",
            "This will have full support because it's localized in the spatial."
        ],
        [
            "Maine.",
            "And therefore we can acquire it, since there's only one unknown.",
            "By using a single high frequency sinusoidal pattern."
        ],
        [
            "In practice, of course you need to separate the positive and negative components and once."
        ],
        [
            "If you do this, you can separate the directing global components.",
            "Remember that we are doing it for the full light transport matrix, and as we'll see in a moment, we also separate urine far away."
        ],
        [
            "Effects.",
            "Let's now talk about the far range light transport.",
            "Because of diffuse interreflections in this case, for the single camera pixel you will get a contribution from all of the projector pixels, which is why I've shaded the entire row and so you could have like transport parts like this, or like this an in general you get into reflection from each pair."
        ],
        [
            "Vector pixel.",
            "In the spatial domain, the support is the entire spatial domain."
        ],
        [
            "But we that means in the frequency domain it's a low frequency effect who support is localized and depending on how much the bandwidth of the diffuse interreflections is, assuming it's 2K FX in the X direction to KFY&Y direction, you will have a certain number of small number of unknowns which is 4K FXFY and those can be up."
        ],
        [
            "Paint by directly sampling the low frequency sinusoidal pattern.",
            "So here are some examples."
        ],
        [
            "The patterns that you would use.",
            "They're all low frequ."
        ],
        [
            "Nancy let's now talk about the new range, like transport.",
            "In this case, there's a band along the diagonal along the diagonal, and so for a given camera element you can see that you will get contributions from subsurface scattering or local interreflections."
        ],
        [
            "And if you look at the projector pixel support in the spatial domain, you have a W by W region that's non 0 where W is the spatial bandwidth of the local effects.",
            "And you have a corresponding frequency domain support.",
            "Now the standard application of the Nyquist theorem says that if you have frequencies that are band limited, you can use a regular spatial sampling corresponding to the frequency band limit.",
            "The converse of that is also true if your signal is bandlimited, spatially.",
            "In this case W by W, you can use a regular frequency domain sampling."
        ],
        [
            "Where the frequency samples are one by W apart and the number of unknowns is the same.",
            "So you have W square unknowns in the spatial domain you need W squares patterns in the frequency domain.",
            "So here are some of the example patterns that are used to acquire the near field if."
        ],
        [
            "It's."
        ],
        [
            "One problem, some of these patterns overlap with those we've used for the far range bandwidth.",
            "The far range frequencies, and therefore you can't disambiguate what's a far range component or near range component.",
            "Fortunately, it's not a big problem becausw only a small number of the patterns overlap, and so."
        ],
        [
            "They simply drop such sinusoidal patterns for the near range effects.",
            "Of course, once."
        ],
        [
            "I've done that.",
            "The system of equations is slightly under determined, and so we apply a regularizer based on it being sparse and having long tailed disk."
        ],
        [
            "Bution so here is the new range transport that we're acquiring."
        ],
        [
            "So it's summarizer transport model.",
            "It has the direct component which is a single element, then it has the banded near range and the far range that affects all elements.",
            "In the frequency domain it."
        ],
        [
            "The converse you have the full support for the direct component, the frequencies for the far range component is smallest.",
            "And if you look at how we acquire it in the frequency domain, we acquire densely the far range component, irregular sampling for the new range, and then a single sinusoidal pattern for the direct component.",
            "How many?"
        ],
        [
            "Measurements do we need for the direct component?",
            "There's one unknown and we use one pattern to it."
        ],
        [
            "Pirate for the new range component.",
            "There W square unknowns and because we dropped some of the frequencies that conflict with the far range, we actually have less than W square path."
        ],
        [
            "Once.",
            "And for the far range in the frequency domain, remember the new range and the direct component were sparse in the spatial domain.",
            "The far range is sparse in the frequency domain, and we're able to exploit both spatial and frequency domain sparseness.",
            "So in this case you have 4K FXKFY unknowns, and that's what you're using to acquire it.",
            "So token in sum the total now."
        ],
        [
            "Number of unknowns is corresponds to the number of parameters in your model.",
            "So we are achieving some level of optimality in the number of patterns.",
            "Of course, in practice we have to separate positive and negative components, so there will be additional patterns.",
            "But still this is kind of a proof."
        ],
        [
            "Of optimality in like transport acquisition.",
            "So here is an example where we are again getting a speedup of about a factor of 20 fewer patterns and you can see if you look at the Left 2 rules we quite closely match the original image with the reconstruction, and we've also separated the direct component.",
            "The near field effects includes the local interreflections in the group, and then you have this broad far field effect.",
            "One final Test is to compare with the work we presented earlier in compressive like Transpor."
        ],
        [
            "Sensing a few years ago.",
            "So here is the original light transport.",
            "Another method actually recovers it quite accurately, as seen in these reconstructions.",
            "And if you look at compressive like transport, it does do a recovery, but the certainly has more noise than our method that explicitly considers the components."
        ],
        [
            "Of course there are limitations, so projector camera correspondence is 1 issue.",
            "It's currently a preprocessing step and is difficult for specular objects.",
            "In the future, we'd like to jointly consider correspondence and transport estimation.",
            "The method is also designed for diffuse scenes.",
            "Some of the low frequency assumptions may not work as well for specular and transparency in solo.",
            "In practice moderate amounts of specularity are supported.",
            "So in."
        ],
        [
            "Conclusion We presented the decomposition of light transport that separates physically meaningful direct near and far field components be shown how you can acquire it with a simple projector camera setup, achieving close to the optimal number of patterns."
        ],
        [
            "Thank you.",
            "So if I understand it correctly, this is completely constrained to smooth objects, because if you have surface wrinkles and things it's going to, it's going to be too much, too complicated to solve the things.",
            "That's not correct because we are considering each camera pixel independently, so all of the analysis considers each camera pixel independently and requires the light transport at each camera pixel separately.",
            "So there's no consideration of spatial smoothness at all.",
            "If you have a complicated be IDF at each pixel, yes, so that's that's a separate issue.",
            "If the reflectance is complicated.",
            "So this has been named the diffuse scenes, but there's no consideration and geometrics.",
            "OK, thank you.",
            "So I had a question, but I think Robbie answered part of it, but let me try it anyhow, which is what happens if I stick the slide in the projector wrong.",
            "Yes, so obviously we are assuming you do calibration.",
            "You can imagine trying to correct for that, but it's not an issue we deal with.",
            "And I mean there are some artifacts you see from those things.",
            "I mean, some of it comes from the Super pixels and the way we average things.",
            "Some of it can be misalignment since we're dealing with diffuse scenes, the method is relatively insensitive to this, but.",
            "Become a bigger issue if you were dealing with mirrors and things where calibration is more important.",
            "Another question, nice big WAVY hand so we can see.",
            "It seems like we're done.",
            "Let us thank the speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Welcome everyone, so I'm going to talk about the composition and acquisition of light transport under specially varying lighting, and this is work with my postdoc Dick Pool Ready and Brian Curlis was sabbatical visitor.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, Dick Powell can't be here because of visa issues.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first let me distinguish between distant and spatially varying lighting.",
                    "label": 0
                },
                {
                    "sent": "Distant illumination is typically diffuse at the scene and comes from far away light sources, so the lighting varies angularly in different directions at the scene, but there's little or no spatial variation.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In contrast, spatially varying lighting focuses on the scene, and so you get strong spatial variations.",
                    "label": 0
                },
                {
                    "sent": "Usually the lighting comes from a small range of angles or from a single light source.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are many applications of spatially varying lighting.",
                    "label": 0
                },
                {
                    "sent": "Perhaps one of the most popular is structured light to acquire the shape of objects, but beyond that we use image in with your projection augmented reality applications.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this talk, we're going to consider a projector camera system, so you have a projector which projects some kind of pattern onto an object or onto a scene.",
                    "label": 0
                },
                {
                    "sent": "In this case, I've shown seen modeled after the Cornell Box in computer graphics for illustration and to give a good example.",
                    "label": 0
                },
                {
                    "sent": "The camera then sees this image and we assume that we've done the calibration so effectively they can be regarded as aligned or collocated, although in practice there of course not Co located in the set.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What light transport tells us is that given an input projector pattern, what's the output camera image?",
                    "label": 0
                },
                {
                    "sent": "So if I use this pattern from the projector, I would see this image in the camera.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so here I'm showing lit by the floodlight, which is turning on the whole projector and there you can see the effects of diffuse interreflections from some of the walls of the box onto the ceiling and the floor.",
                    "label": 0
                },
                {
                    "sent": "You can also see the subsurface scattering effects on the candle and you can now see little bit more clearly in dimmer lights.",
                    "label": 1
                },
                {
                    "sent": "And these are the kinds of visual effects we want to be able to capture for a diffuse scene.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's look at what the light transport matrix looks like.",
                    "label": 1
                },
                {
                    "sent": "So first consider one column of the matrix and that corresponds to a particular projector pixel.",
                    "label": 0
                },
                {
                    "sent": "So of course you get light which hits the scene and goes directly into the camera.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But you can also get light at other camera pixel locations, such as from subsurface scattering.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or from diffuse interreflections.",
                    "label": 0
                },
                {
                    "sent": "Now let's",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at rule of the light transport matrix that corresponds to a given camera pixel, and throughout this talk will be considering a single camera pixel, which is really a rule of the light transport.",
                    "label": 0
                },
                {
                    "sent": "So of course you get information from the projector that illuminates the point that the camera pixel sees.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But you also get contributions from other projector pixels, such as from subsurface scattering or local interrupt.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Elections as well as from more global diffuse interep.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Elections.",
                    "label": 0
                },
                {
                    "sent": "The light transport matrix is actually 4 dimensional, so it has two image dimensions and two projector dimensions.",
                    "label": 1
                },
                {
                    "sent": "But to visualize it will look at a single scan line in the image in a single scanline in the projector.",
                    "label": 0
                },
                {
                    "sent": "So it's 2D.",
                    "label": 0
                },
                {
                    "sent": "And the IT consists of three main components for it.",
                    "label": 1
                },
                {
                    "sent": "If you say so, first is the diagonal, which is the direct component.",
                    "label": 0
                },
                {
                    "sent": "Remember I said we've calibrated it so the projector and camera can be considered to be aligned or colocated.",
                    "label": 0
                },
                {
                    "sent": "Then we have the subsurface scattering, which is a banded diagonal and then you have the diffuse interreflections which are low rank and low frequency but effect the entire matrix.",
                    "label": 0
                },
                {
                    "sent": "So what this paper shows is you can acquire.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This entire light transport using very few patterns so you can acquire this full 128 by 128 projector that 16,380 four element projector pixels using more an order of magnitude fewer patterns with high Fidelity.",
                    "label": 0
                },
                {
                    "sent": "So we used only 1000 instead of the 16,000.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Atoms.",
                    "label": 0
                },
                {
                    "sent": "And here's another example in different lighting conditions where you see the reconstructed image quite closely match.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just the original.",
                    "label": 0
                },
                {
                    "sent": "Moreover, we decompose the light transport into its constituents, which is the direct lighting.",
                    "label": 0
                },
                {
                    "sent": "Notice that the candle is almost entirely black because most of the image and the candle comes from subsurface scattering, so we're able to decompose the near field lighting as well as the far field lighting that has the interreflection components very clearly in that image.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so, here is another example under a different lighting condition.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our contributions are to decompose like transport into its physical direct near in far range components and to efficiently acquire them savings over in order of magnitude versus brute force and in fact achieving an optimality consideration with respect to the model we use.",
                    "label": 1
                },
                {
                    "sent": "We analyze this using the projectors frequency space.",
                    "label": 0
                },
                {
                    "sent": "Let me just say a little bit about previous work.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the previous work is focused on distant illumination and making locally low rank assumptions spatially.",
                    "label": 0
                },
                {
                    "sent": "Varying illumination has been considered, but most methods are brute force, and so it's very expensive to acquire the full light transport matrix.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We are of course inspired by the great work on decomposition, so in particular the direct global separation of Myra Tall, but that's aimed at a single floodlit image, not the full light transport.",
                    "label": 1
                },
                {
                    "sent": "And we also separate out the near and far field components in concurrent work.",
                    "label": 0
                },
                {
                    "sent": "Too little.",
                    "label": 0
                },
                {
                    "sent": "It's a graph presented an intuitive approach to recover certain light transport parts, but again focused in a single image, not the full light transport.",
                    "label": 0
                },
                {
                    "sent": "So let me talk.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now about our technical approach.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I said earlier, the transport matrix includes three terms, so the first of these is the direct component, which is along the diagonal, and it has large magnitude.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second is the new range component, which is really a banded diagonal and sparse, and this mainly due to subsurface effects.",
                    "label": 0
                },
                {
                    "sent": "Also local into reflect.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, the far range effects which are dense affect the entire matrix, but a small magnitude in low frequency.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the direct transport along the diagonal.",
                    "label": 1
                },
                {
                    "sent": "And remember, I'm talking about a single camera pixel.",
                    "label": 0
                },
                {
                    "sent": "Other pixels behave similarly, so I'm considering one row along the light transport.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so for that single camera pixel, if I consider the 2D space of the projector, we have really only one unknown, which is the projector pixel corresponding to that camera pixel.",
                    "label": 1
                },
                {
                    "sent": "What is the intensity in the light transport matrix in the frequency domain?",
                    "label": 1
                },
                {
                    "sent": "This will have full support because it's localized in the spatial.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Maine.",
                    "label": 0
                },
                {
                    "sent": "And therefore we can acquire it, since there's only one unknown.",
                    "label": 0
                },
                {
                    "sent": "By using a single high frequency sinusoidal pattern.",
                    "label": 1
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In practice, of course you need to separate the positive and negative components and once.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you do this, you can separate the directing global components.",
                    "label": 0
                },
                {
                    "sent": "Remember that we are doing it for the full light transport matrix, and as we'll see in a moment, we also separate urine far away.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Effects.",
                    "label": 0
                },
                {
                    "sent": "Let's now talk about the far range light transport.",
                    "label": 0
                },
                {
                    "sent": "Because of diffuse interreflections in this case, for the single camera pixel you will get a contribution from all of the projector pixels, which is why I've shaded the entire row and so you could have like transport parts like this, or like this an in general you get into reflection from each pair.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vector pixel.",
                    "label": 0
                },
                {
                    "sent": "In the spatial domain, the support is the entire spatial domain.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we that means in the frequency domain it's a low frequency effect who support is localized and depending on how much the bandwidth of the diffuse interreflections is, assuming it's 2K FX in the X direction to KFY&Y direction, you will have a certain number of small number of unknowns which is 4K FXFY and those can be up.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Paint by directly sampling the low frequency sinusoidal pattern.",
                    "label": 0
                },
                {
                    "sent": "So here are some examples.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The patterns that you would use.",
                    "label": 0
                },
                {
                    "sent": "They're all low frequ.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nancy let's now talk about the new range, like transport.",
                    "label": 0
                },
                {
                    "sent": "In this case, there's a band along the diagonal along the diagonal, and so for a given camera element you can see that you will get contributions from subsurface scattering or local interreflections.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if you look at the projector pixel support in the spatial domain, you have a W by W region that's non 0 where W is the spatial bandwidth of the local effects.",
                    "label": 1
                },
                {
                    "sent": "And you have a corresponding frequency domain support.",
                    "label": 0
                },
                {
                    "sent": "Now the standard application of the Nyquist theorem says that if you have frequencies that are band limited, you can use a regular spatial sampling corresponding to the frequency band limit.",
                    "label": 0
                },
                {
                    "sent": "The converse of that is also true if your signal is bandlimited, spatially.",
                    "label": 0
                },
                {
                    "sent": "In this case W by W, you can use a regular frequency domain sampling.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where the frequency samples are one by W apart and the number of unknowns is the same.",
                    "label": 0
                },
                {
                    "sent": "So you have W square unknowns in the spatial domain you need W squares patterns in the frequency domain.",
                    "label": 0
                },
                {
                    "sent": "So here are some of the example patterns that are used to acquire the near field if.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One problem, some of these patterns overlap with those we've used for the far range bandwidth.",
                    "label": 0
                },
                {
                    "sent": "The far range frequencies, and therefore you can't disambiguate what's a far range component or near range component.",
                    "label": 0
                },
                {
                    "sent": "Fortunately, it's not a big problem becausw only a small number of the patterns overlap, and so.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They simply drop such sinusoidal patterns for the near range effects.",
                    "label": 0
                },
                {
                    "sent": "Of course, once.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've done that.",
                    "label": 0
                },
                {
                    "sent": "The system of equations is slightly under determined, and so we apply a regularizer based on it being sparse and having long tailed disk.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bution so here is the new range transport that we're acquiring.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's summarizer transport model.",
                    "label": 0
                },
                {
                    "sent": "It has the direct component which is a single element, then it has the banded near range and the far range that affects all elements.",
                    "label": 0
                },
                {
                    "sent": "In the frequency domain it.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The converse you have the full support for the direct component, the frequencies for the far range component is smallest.",
                    "label": 0
                },
                {
                    "sent": "And if you look at how we acquire it in the frequency domain, we acquire densely the far range component, irregular sampling for the new range, and then a single sinusoidal pattern for the direct component.",
                    "label": 0
                },
                {
                    "sent": "How many?",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Measurements do we need for the direct component?",
                    "label": 0
                },
                {
                    "sent": "There's one unknown and we use one pattern to it.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pirate for the new range component.",
                    "label": 0
                },
                {
                    "sent": "There W square unknowns and because we dropped some of the frequencies that conflict with the far range, we actually have less than W square path.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once.",
                    "label": 0
                },
                {
                    "sent": "And for the far range in the frequency domain, remember the new range and the direct component were sparse in the spatial domain.",
                    "label": 0
                },
                {
                    "sent": "The far range is sparse in the frequency domain, and we're able to exploit both spatial and frequency domain sparseness.",
                    "label": 0
                },
                {
                    "sent": "So in this case you have 4K FXKFY unknowns, and that's what you're using to acquire it.",
                    "label": 0
                },
                {
                    "sent": "So token in sum the total now.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Number of unknowns is corresponds to the number of parameters in your model.",
                    "label": 1
                },
                {
                    "sent": "So we are achieving some level of optimality in the number of patterns.",
                    "label": 0
                },
                {
                    "sent": "Of course, in practice we have to separate positive and negative components, so there will be additional patterns.",
                    "label": 0
                },
                {
                    "sent": "But still this is kind of a proof.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of optimality in like transport acquisition.",
                    "label": 0
                },
                {
                    "sent": "So here is an example where we are again getting a speedup of about a factor of 20 fewer patterns and you can see if you look at the Left 2 rules we quite closely match the original image with the reconstruction, and we've also separated the direct component.",
                    "label": 0
                },
                {
                    "sent": "The near field effects includes the local interreflections in the group, and then you have this broad far field effect.",
                    "label": 0
                },
                {
                    "sent": "One final Test is to compare with the work we presented earlier in compressive like Transpor.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sensing a few years ago.",
                    "label": 0
                },
                {
                    "sent": "So here is the original light transport.",
                    "label": 0
                },
                {
                    "sent": "Another method actually recovers it quite accurately, as seen in these reconstructions.",
                    "label": 0
                },
                {
                    "sent": "And if you look at compressive like transport, it does do a recovery, but the certainly has more noise than our method that explicitly considers the components.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course there are limitations, so projector camera correspondence is 1 issue.",
                    "label": 0
                },
                {
                    "sent": "It's currently a preprocessing step and is difficult for specular objects.",
                    "label": 0
                },
                {
                    "sent": "In the future, we'd like to jointly consider correspondence and transport estimation.",
                    "label": 0
                },
                {
                    "sent": "The method is also designed for diffuse scenes.",
                    "label": 0
                },
                {
                    "sent": "Some of the low frequency assumptions may not work as well for specular and transparency in solo.",
                    "label": 0
                },
                {
                    "sent": "In practice moderate amounts of specularity are supported.",
                    "label": 0
                },
                {
                    "sent": "So in.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Conclusion We presented the decomposition of light transport that separates physically meaningful direct near and far field components be shown how you can acquire it with a simple projector camera setup, achieving close to the optimal number of patterns.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So if I understand it correctly, this is completely constrained to smooth objects, because if you have surface wrinkles and things it's going to, it's going to be too much, too complicated to solve the things.",
                    "label": 0
                },
                {
                    "sent": "That's not correct because we are considering each camera pixel independently, so all of the analysis considers each camera pixel independently and requires the light transport at each camera pixel separately.",
                    "label": 0
                },
                {
                    "sent": "So there's no consideration of spatial smoothness at all.",
                    "label": 0
                },
                {
                    "sent": "If you have a complicated be IDF at each pixel, yes, so that's that's a separate issue.",
                    "label": 0
                },
                {
                    "sent": "If the reflectance is complicated.",
                    "label": 0
                },
                {
                    "sent": "So this has been named the diffuse scenes, but there's no consideration and geometrics.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "So I had a question, but I think Robbie answered part of it, but let me try it anyhow, which is what happens if I stick the slide in the projector wrong.",
                    "label": 0
                },
                {
                    "sent": "Yes, so obviously we are assuming you do calibration.",
                    "label": 0
                },
                {
                    "sent": "You can imagine trying to correct for that, but it's not an issue we deal with.",
                    "label": 0
                },
                {
                    "sent": "And I mean there are some artifacts you see from those things.",
                    "label": 0
                },
                {
                    "sent": "I mean, some of it comes from the Super pixels and the way we average things.",
                    "label": 0
                },
                {
                    "sent": "Some of it can be misalignment since we're dealing with diffuse scenes, the method is relatively insensitive to this, but.",
                    "label": 0
                },
                {
                    "sent": "Become a bigger issue if you were dealing with mirrors and things where calibration is more important.",
                    "label": 0
                },
                {
                    "sent": "Another question, nice big WAVY hand so we can see.",
                    "label": 0
                },
                {
                    "sent": "It seems like we're done.",
                    "label": 0
                },
                {
                    "sent": "Let us thank the speaker.",
                    "label": 0
                }
            ]
        }
    }
}