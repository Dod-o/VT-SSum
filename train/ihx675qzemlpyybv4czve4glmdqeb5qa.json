{
    "id": "ihx675qzemlpyybv4czve4glmdqeb5qa",
    "title": "LEX1/3: word sense disambiguation & crowdsourcing",
    "info": {
        "author": [
            "Roberto Navigli, Dipartimento di Informatica, Sapienza University of Rome"
        ],
        "published": "March 6, 2019",
        "recorded": "February 2019",
        "category": [
            "Top->Humanities->Linguistics->Lexicography",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/elexisobserver2019_navigli_word_sense_disambiguati/",
    "segmentation": [
        [
            "I'm Robert and ability from this appearance in your room.",
            "In this last presentation, I'm going to talk about word, senses, ambulation, and crowd sourcing within the Lexus project."
        ],
        [
            "So the point here is to for the project to show that lexicographic data and the data that will be interlinked in the project via the dictionary matrix will be useful for natural language processing tasks and also vice versa.",
            "That NLP can be useful and can be beneficial for improving and enhancing lexicographic data.",
            "So pragmatic task for this is where census emigration which will introduce briefly.",
            "In the next slide, and the idea is to show that these resources and these links between resources will greatly enhance disambiguation, will also talk about how NLP can help can do in order to help Mexico."
        ],
        [
            "Lexicography So what these were since the simulation, I think the easiest way to introduce this task is via an example an.",
            "Actually, here we see two tasks at.",
            "Once we see the sentence, Thomason, Mario, play the strikers in Munich, and actually, here you see that does not only words which are used in a specific sense like striker in the sense of the player, rather than someone who's on strike and play, which is very ambiguous, so it's used in a certain sense in the sense of participating in games.",
            "But we also see.",
            "Mentions 20 days like Thomas Marion, so who are these people?",
            "And so this means that disambiguation usually concerns words that you find in a dictionary.",
            "Like now, nouns, verbs, adjectives and so on.",
            "But actually a similar task called entity linking can be performed in order to associate encyclopaedic or any kind of.",
            "Identity too with with the mentioning context.",
            "So here with Thomas with Mario and so on.",
            "If these are well known, there will be found in a encyclopedia.",
            "Otherwise we need a database to provide this information.",
            "So in general this is a task in which we solve.",
            "We want to solve the ambiguity of words in context and."
        ],
        [
            "Why would be would be interesting for the Lex project to show that the dictionary matrix would provide benefit to this task?",
            "Well, because within the project will develop algorithms to use these resources.",
            "Once they are interconnected to bootstrap this application in several languages and the second objective will be to show high performance in many many languages and this will be done via quantitative evaluations to show that this application will improve in terms of percentage in terms of accuracy in general and also to show that we can use many different sense inventors to perform the examination task.",
            "So not only word net which is the most.",
            "Widely used dictionary, but once we have this dictionary matrix will be able to disambiguate text and associate meaning according to any dictionary within the Matrix, and this with high quality annotations."
        ],
        [
            "And what are the issues?",
            "The point is that this application is performed in two main ways.",
            "Why me is a supervised approach in which usually you need training data.",
            "You need many examples sense annotated by humans in order to train a supervised system, and this is not feasible if you want to scale across languages across inventories and so on.",
            "While another popular approach is called knowledge based.",
            "And this approach makes it possible for.",
            "Algorithms which are not necessarily trained on human Lee tagged sense tag data to perform the dissemination task and also scale across inventories and scale across languages by using the graph like this dictionary structure by using semantic locations and any other kind of information that can be found in these dictionaries.",
            "In fact, currently the sensing vendor is used in literature are word.",
            "Net, which is too fine grained and Wikipedia, which is way too rich.",
            "For any kind of disambiguation or entity linking task, so the idea is to improve this task in order to exploit the information that will result from Alexis.",
            "And this will be possible thanks to the Dictionary matrix that will be created.",
            "In a work package too."
        ],
        [
            "So the work plan for showing benefit to the installation task is to start from textual data and we are already working on.",
            "Corpora in many different languages from the Universal Dependencies project from the 10:10 corpora from lexical computing and also from semantical annotated core product, were provided by several partners.",
            "In the first phase, which is about to finish now we applied two disambiguation algorithms, one from Sapienza Babel 5, one from Jsi Wiki Fire, and we use the existing inventories because the dictionary metric is not yet available.",
            "And these inventories are Babel, net and Wikipedia to disambiguate these Corporation a large scale.",
            "The idea is already to show this data to lexicographers, plus the observers if you want and show benefit already in this first endeavour.",
            "And then later we will move to the Dictionary matrix.",
            "So the goal now is to prepare the framework for this dissemination task, and now that we are, we have performed the first dissemination of this corpora.",
            "We have to start an analysis phase and see what is the benefit.",
            "What kind of annotations?",
            "We can exploit and how we can improve the dissemination task."
        ],
        [
            "One of the inventors I mentioned is Babel net, so at Sapienza we're using Babel net as a shared multilingual inventor of meanings, but not only acceptance actually, because currently baby that is used by more than 800 University and research centers, which is a big number.",
            "We're very proud of it and it has wide coverage, almost 300 languages, 16,000,000 entries and it brings together information from different dictionaries and encyclopedias like Word, net, Wikipedia.",
            "Wiktionary wiki data and so on and so then it can be used as.",
            "Also John mentioned earlier for interconnecting dictionaries across languages."
        ],
        [
            "And as a disambiguation algorithm I'm mentioning here, Babel 5, but Wiki Fire performs a similar task using Wikipedia as an algorithm that can perform disambiguation on a large scale.",
            "For example, waiting text and so the key point with Babel size that you can use it to associate meanings with words in context.",
            "And here you see two colors green and yellow, and with green we are disambiguating common nouns, verbs, adjectives and so on.",
            "Dictionary words with the yellow.",
            "We are also associating maned entities with mentions.",
            "So for example, for writers that also.",
            "Can be found in one of the resources that are available in Babel.",
            "Net and the key thing is that we are using the information from the lexicographic side to disambiguate entity mentions and vice versa.",
            "We are using entity mentions to disambiguate.",
            "Words that can be found in a dictionary.",
            "So to find word sense is the right word sends the most suitable word sentence for words occurring in context, and so this is the interplay between the two kinds of information and passwords and some additional one on one side and entity linking on the other.",
            "And this is done jointly."
        ],
        [
            "And so because it's a knowledge based algorithm, it doesn't require supervision in a strict sense, doesn't require training data, so it can be applied to any language.",
            "And it can also applied in a so called language agnostic setting which you have data in different languages and you want to disambiguate this information independently of the language that is used for the various words in the context."
        ],
        [
            "This is an example where you can see the various possible meanings of the sentence I showed earlier.",
            "Mario Thomason, mirror player players strikers in Munich playing Munich, and you can see that there is some area of the of the whole interpretation graph in which this content is much more interconnected, and this gives the most likely meanings for the various mentions and ambiguous words in the context."
        ],
        [
            "So I'm providing here are some statistics of the datasets that we disaggregated with Babel file.",
            "I'm showing the statistics with Babel file, but we also jsi also disseminated the same text with Wiki Fire as I said.",
            "So here you can see for example, statistics of the English datasets from universal dependencies.",
            "As a result of the application of Babel file and you can see that the.",
            "Pretty good number of what types and word tokens.",
            "Half a million word tokens approximately and the number of these underrated word types is about 24,000, so it's a pretty good number of different words.",
            "But when you move to a much larger corpus, which is the 1010 corpus, this is the English."
        ],
        [
            "And 1010 corpus you can see the numbers grow considerably, and here you have millions of different word types.",
            "This emulated and many many sense associations in the order of for the token, see in the order of hundreds of millions.",
            "So it's really a lot of instances.",
            "A lot of words, word tokens that have been disintegrated with sentences, and the number of meanings is very high.",
            "As you can see.",
            "It's hundreds of thousands.",
            "And here you have a breakdown across parts of speech.",
            "You can see that most of the most frequent occurrences are nouns and verbs, and then older all the others.",
            "These are."
        ],
        [
            "Overall, statistics on words babyfied across languages.",
            "So because of size and pre processing and so on, you can see that this distribution and also depending on the size of the corpus, this distribution varies across languages, but it's interesting to see that here we have in any case pretty good number of word tokens across languages."
        ],
        [
            "And this these are the statistics for the 10:10 corpora, which are much higher of course, and you can see that here we also designed degraded.",
            "Overall, we did waited 14 languages if I recall.",
            "If I remember correctly, so it's a pretty good number of languages and we're moving to a larger batch of languages for later, later stage."
        ],
        [
            "Now that we have this this corporatism grated important question is how to evaluate the quality of this disambiguation so and we are here actually also to discuss this with you if you want this observers later and also within the consortium to determine what are the best ways to take advantage of these up this opportunity and we are in the process of defining this evaluation process so.",
            "Any feedback is welcome and we are discussing what is the best option.",
            "So should we see what kind of information we can exploit from this disambiguation?",
            "Should we just validate a sample of the annotations and see how this will scale across inventories?",
            "What evaluation measures do you want to use?",
            "What?",
            "Which will standard datasets do we want to?",
            "Leverage."
        ],
        [
            "And in the second phase, which will start from June this year and will finish in 2021, we will develop a new algorithm or new algorithms for disambiguation based on multilingual sense embedding, so that we will be able to perform higher performance multilingual disambiguation plus a semantic graphs, and we will be able overtime to use the LEXIS dictionary matrix.",
            "And the idea is to show that this data will benefit the dissemination task.",
            "So the goal is to show that we can scale across languages and across dictionaries."
        ],
        [
            "Very briefly, there's also another task that we are addressing, which goes the extra mile, so we move from the Association of meaning with a given word in context to the creation of.",
            "A meaning structure for a whole sentence, which is the task for semantic parsing.",
            "So this is something that has just started and we are starting to work on, but it's a very challenging so I just wanted to introduce you one or two slides and the idea is to take a sentence, parse this sentence at the semantic level, not only the syntactic labels at the semantic level produce a representation that is independent of the language, and so this is a key challenge that we are starting to address."
        ],
        [
            "Again, the use of the Lexie Alexis Alexa graphic data will be key because all the information that will count from the various dictionaries would be useful for creating a better representation that is language independent.",
            "If I."
        ],
        [
            "The task that is foreseen to show the benefit of a lexicographic data for NLP is actually a collection of 3, three subtasks, and the first one is sense clustering.",
            "So we are developing algorithms.",
            "Two group fine grain sense distinctions, and this will be done initially in English but also in other languages later.",
            "The point is that we all know that word net, for example, is very fine grade.",
            "They are very fine grained distinctions that the computational level are not very useful and so the idea is to come up with approaches that help group these senses together and reduce the ground at the finality of these dictionaries.",
            "The sex."
        ],
        [
            "Task is domain labeling of text and so this is relatively straightforward.",
            "So the idea is to show that the LEXIS dictionaries will help label text with domain tags.",
            "This is pretty pretty straightforward."
        ],
        [
            "And finally, I think very, very helpful and interesting, for especially for lexicographers, is to use the LEXIS dictionary matrix to improve diachronic study with their correct distribution of Sciences.",
            "Cause having all this information interconnected will make it possible to create software that is able to take text, disambiguate this text, and study the distribution of senses overtime and across dictionaries across languages and so on, I think.",
            "This is very, very interesting."
        ],
        [
            "So these are some of the challenges, but I will not go into detail here since clustering as the grotty issue domain labeling.",
            "Has to work across languages which is not obvious and their current distribution of senses requires the creation of reliable sense distributions in many languages."
        ],
        [
            "Finally, I have two slides on crowdsourcing and gamification.",
            "One thing is I mentioned that it's not only lexicographic data for NLP, but also NLP for lexical lexicography, and so an idea here is to how to take advantage of the information that comes as a result of dictionary linking and worsen simulation, and so, proposal, among others, is to put forward.",
            "They develop a. Crossword game that can acquire information from players based on how well they play with the definitions that are provided by the dictionary or the Dictionary Matrix.",
            "And so the goal is to collect experience from the consortium, the consortium and also the observers in order to see whether the quality of the dictionary definitions connected to the words that they are defining or other information that you want to validate, like pictures, like tags and so on.",
            "Is really of the expected quality so that one can intervene in the right direction."
        ],
        [
            "And so this is a video of a demo of this video game that we're developing and I'll just go to the some key points.",
            "So you will have a.",
            "This is a smartphone game.",
            "You will have.",
            "You will be able to select a word and then once you select one of these you will get a.",
            "A definition from one of the dictionaries, and if so, the expectation is that if enough players will be able to define that to find the right word that answers the definition, then it means that that definition has been connected correctly to that word, and the definition is over high quality or that is appropriate for the.",
            "Player to play with it, and so there's also a bonus mechanism so that players are also engaged within the game, and so we're going.",
            "We're working on this, and we're going to release this in the leader later this year."
        ],
        [
            "I'm done.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm Robert and ability from this appearance in your room.",
                    "label": 0
                },
                {
                    "sent": "In this last presentation, I'm going to talk about word, senses, ambulation, and crowd sourcing within the Lexus project.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the point here is to for the project to show that lexicographic data and the data that will be interlinked in the project via the dictionary matrix will be useful for natural language processing tasks and also vice versa.",
                    "label": 1
                },
                {
                    "sent": "That NLP can be useful and can be beneficial for improving and enhancing lexicographic data.",
                    "label": 0
                },
                {
                    "sent": "So pragmatic task for this is where census emigration which will introduce briefly.",
                    "label": 0
                },
                {
                    "sent": "In the next slide, and the idea is to show that these resources and these links between resources will greatly enhance disambiguation, will also talk about how NLP can help can do in order to help Mexico.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lexicography So what these were since the simulation, I think the easiest way to introduce this task is via an example an.",
                    "label": 0
                },
                {
                    "sent": "Actually, here we see two tasks at.",
                    "label": 0
                },
                {
                    "sent": "Once we see the sentence, Thomason, Mario, play the strikers in Munich, and actually, here you see that does not only words which are used in a specific sense like striker in the sense of the player, rather than someone who's on strike and play, which is very ambiguous, so it's used in a certain sense in the sense of participating in games.",
                    "label": 0
                },
                {
                    "sent": "But we also see.",
                    "label": 0
                },
                {
                    "sent": "Mentions 20 days like Thomas Marion, so who are these people?",
                    "label": 0
                },
                {
                    "sent": "And so this means that disambiguation usually concerns words that you find in a dictionary.",
                    "label": 0
                },
                {
                    "sent": "Like now, nouns, verbs, adjectives and so on.",
                    "label": 0
                },
                {
                    "sent": "But actually a similar task called entity linking can be performed in order to associate encyclopaedic or any kind of.",
                    "label": 0
                },
                {
                    "sent": "Identity too with with the mentioning context.",
                    "label": 0
                },
                {
                    "sent": "So here with Thomas with Mario and so on.",
                    "label": 0
                },
                {
                    "sent": "If these are well known, there will be found in a encyclopedia.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we need a database to provide this information.",
                    "label": 0
                },
                {
                    "sent": "So in general this is a task in which we solve.",
                    "label": 0
                },
                {
                    "sent": "We want to solve the ambiguity of words in context and.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why would be would be interesting for the Lex project to show that the dictionary matrix would provide benefit to this task?",
                    "label": 0
                },
                {
                    "sent": "Well, because within the project will develop algorithms to use these resources.",
                    "label": 1
                },
                {
                    "sent": "Once they are interconnected to bootstrap this application in several languages and the second objective will be to show high performance in many many languages and this will be done via quantitative evaluations to show that this application will improve in terms of percentage in terms of accuracy in general and also to show that we can use many different sense inventors to perform the examination task.",
                    "label": 1
                },
                {
                    "sent": "So not only word net which is the most.",
                    "label": 0
                },
                {
                    "sent": "Widely used dictionary, but once we have this dictionary matrix will be able to disambiguate text and associate meaning according to any dictionary within the Matrix, and this with high quality annotations.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what are the issues?",
                    "label": 0
                },
                {
                    "sent": "The point is that this application is performed in two main ways.",
                    "label": 1
                },
                {
                    "sent": "Why me is a supervised approach in which usually you need training data.",
                    "label": 0
                },
                {
                    "sent": "You need many examples sense annotated by humans in order to train a supervised system, and this is not feasible if you want to scale across languages across inventories and so on.",
                    "label": 0
                },
                {
                    "sent": "While another popular approach is called knowledge based.",
                    "label": 0
                },
                {
                    "sent": "And this approach makes it possible for.",
                    "label": 0
                },
                {
                    "sent": "Algorithms which are not necessarily trained on human Lee tagged sense tag data to perform the dissemination task and also scale across inventories and scale across languages by using the graph like this dictionary structure by using semantic locations and any other kind of information that can be found in these dictionaries.",
                    "label": 0
                },
                {
                    "sent": "In fact, currently the sensing vendor is used in literature are word.",
                    "label": 0
                },
                {
                    "sent": "Net, which is too fine grained and Wikipedia, which is way too rich.",
                    "label": 1
                },
                {
                    "sent": "For any kind of disambiguation or entity linking task, so the idea is to improve this task in order to exploit the information that will result from Alexis.",
                    "label": 0
                },
                {
                    "sent": "And this will be possible thanks to the Dictionary matrix that will be created.",
                    "label": 0
                },
                {
                    "sent": "In a work package too.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the work plan for showing benefit to the installation task is to start from textual data and we are already working on.",
                    "label": 0
                },
                {
                    "sent": "Corpora in many different languages from the Universal Dependencies project from the 10:10 corpora from lexical computing and also from semantical annotated core product, were provided by several partners.",
                    "label": 1
                },
                {
                    "sent": "In the first phase, which is about to finish now we applied two disambiguation algorithms, one from Sapienza Babel 5, one from Jsi Wiki Fire, and we use the existing inventories because the dictionary metric is not yet available.",
                    "label": 0
                },
                {
                    "sent": "And these inventories are Babel, net and Wikipedia to disambiguate these Corporation a large scale.",
                    "label": 0
                },
                {
                    "sent": "The idea is already to show this data to lexicographers, plus the observers if you want and show benefit already in this first endeavour.",
                    "label": 0
                },
                {
                    "sent": "And then later we will move to the Dictionary matrix.",
                    "label": 0
                },
                {
                    "sent": "So the goal now is to prepare the framework for this dissemination task, and now that we are, we have performed the first dissemination of this corpora.",
                    "label": 0
                },
                {
                    "sent": "We have to start an analysis phase and see what is the benefit.",
                    "label": 0
                },
                {
                    "sent": "What kind of annotations?",
                    "label": 0
                },
                {
                    "sent": "We can exploit and how we can improve the dissemination task.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One of the inventors I mentioned is Babel net, so at Sapienza we're using Babel net as a shared multilingual inventor of meanings, but not only acceptance actually, because currently baby that is used by more than 800 University and research centers, which is a big number.",
                    "label": 1
                },
                {
                    "sent": "We're very proud of it and it has wide coverage, almost 300 languages, 16,000,000 entries and it brings together information from different dictionaries and encyclopedias like Word, net, Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Wiktionary wiki data and so on and so then it can be used as.",
                    "label": 0
                },
                {
                    "sent": "Also John mentioned earlier for interconnecting dictionaries across languages.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And as a disambiguation algorithm I'm mentioning here, Babel 5, but Wiki Fire performs a similar task using Wikipedia as an algorithm that can perform disambiguation on a large scale.",
                    "label": 0
                },
                {
                    "sent": "For example, waiting text and so the key point with Babel size that you can use it to associate meanings with words in context.",
                    "label": 0
                },
                {
                    "sent": "And here you see two colors green and yellow, and with green we are disambiguating common nouns, verbs, adjectives and so on.",
                    "label": 1
                },
                {
                    "sent": "Dictionary words with the yellow.",
                    "label": 0
                },
                {
                    "sent": "We are also associating maned entities with mentions.",
                    "label": 0
                },
                {
                    "sent": "So for example, for writers that also.",
                    "label": 0
                },
                {
                    "sent": "Can be found in one of the resources that are available in Babel.",
                    "label": 0
                },
                {
                    "sent": "Net and the key thing is that we are using the information from the lexicographic side to disambiguate entity mentions and vice versa.",
                    "label": 0
                },
                {
                    "sent": "We are using entity mentions to disambiguate.",
                    "label": 0
                },
                {
                    "sent": "Words that can be found in a dictionary.",
                    "label": 1
                },
                {
                    "sent": "So to find word sense is the right word sends the most suitable word sentence for words occurring in context, and so this is the interplay between the two kinds of information and passwords and some additional one on one side and entity linking on the other.",
                    "label": 0
                },
                {
                    "sent": "And this is done jointly.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so because it's a knowledge based algorithm, it doesn't require supervision in a strict sense, doesn't require training data, so it can be applied to any language.",
                    "label": 0
                },
                {
                    "sent": "And it can also applied in a so called language agnostic setting which you have data in different languages and you want to disambiguate this information independently of the language that is used for the various words in the context.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is an example where you can see the various possible meanings of the sentence I showed earlier.",
                    "label": 0
                },
                {
                    "sent": "Mario Thomason, mirror player players strikers in Munich playing Munich, and you can see that there is some area of the of the whole interpretation graph in which this content is much more interconnected, and this gives the most likely meanings for the various mentions and ambiguous words in the context.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm providing here are some statistics of the datasets that we disaggregated with Babel file.",
                    "label": 0
                },
                {
                    "sent": "I'm showing the statistics with Babel file, but we also jsi also disseminated the same text with Wiki Fire as I said.",
                    "label": 0
                },
                {
                    "sent": "So here you can see for example, statistics of the English datasets from universal dependencies.",
                    "label": 1
                },
                {
                    "sent": "As a result of the application of Babel file and you can see that the.",
                    "label": 0
                },
                {
                    "sent": "Pretty good number of what types and word tokens.",
                    "label": 1
                },
                {
                    "sent": "Half a million word tokens approximately and the number of these underrated word types is about 24,000, so it's a pretty good number of different words.",
                    "label": 1
                },
                {
                    "sent": "But when you move to a much larger corpus, which is the 1010 corpus, this is the English.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And 1010 corpus you can see the numbers grow considerably, and here you have millions of different word types.",
                    "label": 1
                },
                {
                    "sent": "This emulated and many many sense associations in the order of for the token, see in the order of hundreds of millions.",
                    "label": 0
                },
                {
                    "sent": "So it's really a lot of instances.",
                    "label": 0
                },
                {
                    "sent": "A lot of words, word tokens that have been disintegrated with sentences, and the number of meanings is very high.",
                    "label": 1
                },
                {
                    "sent": "As you can see.",
                    "label": 0
                },
                {
                    "sent": "It's hundreds of thousands.",
                    "label": 0
                },
                {
                    "sent": "And here you have a breakdown across parts of speech.",
                    "label": 0
                },
                {
                    "sent": "You can see that most of the most frequent occurrences are nouns and verbs, and then older all the others.",
                    "label": 0
                },
                {
                    "sent": "These are.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Overall, statistics on words babyfied across languages.",
                    "label": 0
                },
                {
                    "sent": "So because of size and pre processing and so on, you can see that this distribution and also depending on the size of the corpus, this distribution varies across languages, but it's interesting to see that here we have in any case pretty good number of word tokens across languages.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this these are the statistics for the 10:10 corpora, which are much higher of course, and you can see that here we also designed degraded.",
                    "label": 0
                },
                {
                    "sent": "Overall, we did waited 14 languages if I recall.",
                    "label": 0
                },
                {
                    "sent": "If I remember correctly, so it's a pretty good number of languages and we're moving to a larger batch of languages for later, later stage.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now that we have this this corporatism grated important question is how to evaluate the quality of this disambiguation so and we are here actually also to discuss this with you if you want this observers later and also within the consortium to determine what are the best ways to take advantage of these up this opportunity and we are in the process of defining this evaluation process so.",
                    "label": 1
                },
                {
                    "sent": "Any feedback is welcome and we are discussing what is the best option.",
                    "label": 0
                },
                {
                    "sent": "So should we see what kind of information we can exploit from this disambiguation?",
                    "label": 0
                },
                {
                    "sent": "Should we just validate a sample of the annotations and see how this will scale across inventories?",
                    "label": 1
                },
                {
                    "sent": "What evaluation measures do you want to use?",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "Which will standard datasets do we want to?",
                    "label": 0
                },
                {
                    "sent": "Leverage.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in the second phase, which will start from June this year and will finish in 2021, we will develop a new algorithm or new algorithms for disambiguation based on multilingual sense embedding, so that we will be able to perform higher performance multilingual disambiguation plus a semantic graphs, and we will be able overtime to use the LEXIS dictionary matrix.",
                    "label": 1
                },
                {
                    "sent": "And the idea is to show that this data will benefit the dissemination task.",
                    "label": 1
                },
                {
                    "sent": "So the goal is to show that we can scale across languages and across dictionaries.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very briefly, there's also another task that we are addressing, which goes the extra mile, so we move from the Association of meaning with a given word in context to the creation of.",
                    "label": 0
                },
                {
                    "sent": "A meaning structure for a whole sentence, which is the task for semantic parsing.",
                    "label": 1
                },
                {
                    "sent": "So this is something that has just started and we are starting to work on, but it's a very challenging so I just wanted to introduce you one or two slides and the idea is to take a sentence, parse this sentence at the semantic level, not only the syntactic labels at the semantic level produce a representation that is independent of the language, and so this is a key challenge that we are starting to address.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, the use of the Lexie Alexis Alexa graphic data will be key because all the information that will count from the various dictionaries would be useful for creating a better representation that is language independent.",
                    "label": 0
                },
                {
                    "sent": "If I.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The task that is foreseen to show the benefit of a lexicographic data for NLP is actually a collection of 3, three subtasks, and the first one is sense clustering.",
                    "label": 1
                },
                {
                    "sent": "So we are developing algorithms.",
                    "label": 0
                },
                {
                    "sent": "Two group fine grain sense distinctions, and this will be done initially in English but also in other languages later.",
                    "label": 0
                },
                {
                    "sent": "The point is that we all know that word net, for example, is very fine grade.",
                    "label": 0
                },
                {
                    "sent": "They are very fine grained distinctions that the computational level are not very useful and so the idea is to come up with approaches that help group these senses together and reduce the ground at the finality of these dictionaries.",
                    "label": 0
                },
                {
                    "sent": "The sex.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Task is domain labeling of text and so this is relatively straightforward.",
                    "label": 1
                },
                {
                    "sent": "So the idea is to show that the LEXIS dictionaries will help label text with domain tags.",
                    "label": 0
                },
                {
                    "sent": "This is pretty pretty straightforward.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, I think very, very helpful and interesting, for especially for lexicographers, is to use the LEXIS dictionary matrix to improve diachronic study with their correct distribution of Sciences.",
                    "label": 0
                },
                {
                    "sent": "Cause having all this information interconnected will make it possible to create software that is able to take text, disambiguate this text, and study the distribution of senses overtime and across dictionaries across languages and so on, I think.",
                    "label": 0
                },
                {
                    "sent": "This is very, very interesting.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are some of the challenges, but I will not go into detail here since clustering as the grotty issue domain labeling.",
                    "label": 0
                },
                {
                    "sent": "Has to work across languages which is not obvious and their current distribution of senses requires the creation of reliable sense distributions in many languages.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, I have two slides on crowdsourcing and gamification.",
                    "label": 0
                },
                {
                    "sent": "One thing is I mentioned that it's not only lexicographic data for NLP, but also NLP for lexical lexicography, and so an idea here is to how to take advantage of the information that comes as a result of dictionary linking and worsen simulation, and so, proposal, among others, is to put forward.",
                    "label": 0
                },
                {
                    "sent": "They develop a. Crossword game that can acquire information from players based on how well they play with the definitions that are provided by the dictionary or the Dictionary Matrix.",
                    "label": 1
                },
                {
                    "sent": "And so the goal is to collect experience from the consortium, the consortium and also the observers in order to see whether the quality of the dictionary definitions connected to the words that they are defining or other information that you want to validate, like pictures, like tags and so on.",
                    "label": 0
                },
                {
                    "sent": "Is really of the expected quality so that one can intervene in the right direction.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so this is a video of a demo of this video game that we're developing and I'll just go to the some key points.",
                    "label": 0
                },
                {
                    "sent": "So you will have a.",
                    "label": 0
                },
                {
                    "sent": "This is a smartphone game.",
                    "label": 0
                },
                {
                    "sent": "You will have.",
                    "label": 0
                },
                {
                    "sent": "You will be able to select a word and then once you select one of these you will get a.",
                    "label": 0
                },
                {
                    "sent": "A definition from one of the dictionaries, and if so, the expectation is that if enough players will be able to define that to find the right word that answers the definition, then it means that that definition has been connected correctly to that word, and the definition is over high quality or that is appropriate for the.",
                    "label": 0
                },
                {
                    "sent": "Player to play with it, and so there's also a bonus mechanism so that players are also engaged within the game, and so we're going.",
                    "label": 0
                },
                {
                    "sent": "We're working on this, and we're going to release this in the leader later this year.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm done.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}