{
    "id": "kb6uzyusiighwk7ipt6gtgpbwuecyykp",
    "title": "The Role of Function Approximation for both Regression and Classifiction in Robotics",
    "info": {
        "author": [
            "Nicholas Roy, Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, MIT"
        ],
        "published": "Aug. 3, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Robotics"
        ]
    },
    "url": "http://videolectures.net/rraa09_roy_trfa/",
    "segmentation": [
        [
            "Like function approximation, very large topic so I decided to be contrarian.",
            "An not talk specifically about regression in terms of recovering functional forms from data etc, but just to talk more about the general role of function, approximation, robotics and also to talk a little bit about how classification.",
            "It can be as just a good function, approximators.",
            "Anything else I'm going to talk about a few things, and this is joint work with a number of people, and I will try and point connect them to the appropriate piece of research as we go.",
            "So let's think about."
        ],
        [
            "Learning as it applies to sort of a standard control system, so we might you know if we don't necessarily know the model ahead of time, then we're going to get a bunch of data from the world.",
            "We're going to use it to estimate models, etc.",
            "We're going to plan, and we're going to take actions and."
        ],
        [
            "So far this more at least in the morning.",
            "There was a lot of talk of, well, how can we use regression function exclamation when we don't necessarily have an exact model and we're going to allow the data to represent what we need about the world.",
            "But we might also think about scenarios where we actually do have a pretty good model, and we even have a very good way to evaluate exactly what we want.",
            "But we might want to do it faster and we might want to do it in a way that accelerates things.",
            "There's two ways that you can actually think about the complexity of this particular problem.",
            "One is just the computational complexity of learning a particular model and using it in many robot problems.",
            "There is models that we can evaluate very, very accurately and very, very effectively, but it's costly for us to do it.",
            "And then the other way.",
            "Other way in which we want to reduce complexities in terms of sample complexity.",
            "It's important when thinking about regression etc to think about how much data do we actually need in order to recover the model that we're going to be optimizing against, and I'm going to argue that when you think about functional approximation and you're thinking about regression etc, that any given techniques it's on a continuum of these things that you can be very, very computationally costly and there's a whole bunch of techniques like that are very good in terms of not requiring much data.",
            "And then at the other end of the continuum you can be very very cheap in terms of computation, But you might need a lot of data and you just have to.",
            "You don't necessarily have to think hard about balancing those, but you need to recognize that any one of your favorite techniques sits somewhere in that continuum, and there's interesting things that can be said about actually doing the opposite of sort of, you know, exploring other parts of the continuum that haven't been explored."
        ],
        [
            "Well."
        ],
        [
            "And so the first example I actually want to talk about this is joint work with Rust.",
            "Hedrick, this is from the Little Dog Project which some of you may know something about.",
            "And the idea is that you've got to get a dog to walk across some terrain, and in this particular problem, setting the pose of the dog is known perfectly because you have high accuracy, motion capture and you have high accuracy joining coders.",
            "And the other thing that you might have is another thing that you do have in this case is perfect knowledge of the terrain too.",
            "Very very high accuracy, so this is purely a in many respects, just a computational exercises like can you plan joint angles etc to get the dog across very, very complicated terrain as quickly as possible?",
            "Now I'm skipping out a lot of details, but at the end of the day you can write the whole thing down as an optimization if that is in fact what you wish to do.",
            "Now, one of the ways in which this particular optimization this particular planning problem."
        ],
        [
            "Be hard is you have a very high dimensional dog at trivial representation of the sort of the center of mass of the center of the body of the dog is 6 degrees of freedom, and then each one of the legs is 3 degrees of freedom.",
            "So you're talking about a 12 + 618 degree of freedom system as it is, and so you've actually got to figure out how that body, even if you treat it as a rigid body, is intersecting with the terrain given us current pose.",
            "And that's a computationally demanding geometric calculation.",
            "It's not exactly rocket science anymore.",
            "There are well understood techniques for doing this, but they're not particularly fast, and so if you're doing motion planning, particularly in keynote, dynamic motion planning where you're considering hundreds or thousands of these trajectory through the environment to get the dog to run in to figure out which ones are effective, which ones are stable, which ones are kinematically feasible because of the joint angles, or because of interactions with terrain, and you're going to be doing this evaluation very, very often.",
            "One of the things that we discovered in the course of this research project was that was actually a big bottleneck for us.",
            "Was determining whether or not the dog was actually in collision with the terrain and whether or not the dog was going to fall as a result.",
            "And so, like I say, we have a fast simulator that can actually answer this question for excuse me, not simulator, but fast kinematic evaluation system, but it's not fast enough.",
            "And so this is actually a function and a function that you could might want to approximate it's 01 function as opposed to a continuous function of parametric function which you could use a function approximator, essentially a classifier, in order as inside the inner loop of this particular planner, and perhaps get much more efficient, much faster evaluation."
        ],
        [
            "Of the terrain collisions.",
            "So we're going to cast this is generic model, free, in this case classification problem and we can use real data to learn classifiers is full at trajectories with the hope that it will be faster to evaluate.",
            "But at the same time accurate enough to actually allow us to plan effectively."
        ],
        [
            "So there's again, there's a continuum of things that you might do so at the one end of the continuum there's very high Fidelity geometric models.",
            "In this case, our dog was reasonably well approximated as a series of cylinders.",
            "The body, the dog is approximately cylindrical.",
            "Initialize it like this cylindrical.",
            "This is accurate, very expensive, a intermediate model is to approximate it.",
            "You"
        ],
        [
            "Using a line model that sort of captures the front of the legs.",
            "It's less accurate, but cheaper.",
            "And then the other thing you could actually just throw away a lot of the internal motion of the dog and just say."
        ],
        [
            "The beginning of the trajectory in collision is the end of the trajectory in collision.",
            "This is very very fast, but to evaluate but misses.",
            "Of course, the internal collisions that could occur as a dog moves from the pre step to this or the end of this step we call this the pre phase and the post phase during the step.",
            "Instead of actually backing off to one of these extremely approximate classifiers, we're just going to go ahead and learn this.",
            "Instead, we're going to classify the entire trip."
        ],
        [
            "Factory without evaluating samples directly within the trajectory.",
            "So one problem you have is feature."
        ],
        [
            "We take pieces of the terrain.",
            "In the local robots local coordinate frame and we take pieces of terrain and we use these as input features along with the pose of the dog, and we feed that to a classifier.",
            "And we take a generic classifier from machine learning and this we tried a number and ADA boost.",
            "In this case happened to work particularly well for us.",
            "We take like."
        ],
        [
            "These input features in the terrain, so the initial slope of the terrain, final slope of the terrain, step length, etc features a dog center body, joint angles, etc and we train up weak classifiers.",
            "In this case, decision trees that say whether or not the dog is actually going to collide.",
            "This is the function that we're approximating.",
            "It's a 01 function.",
            "And these are the features that a particular decision tree classified.",
            "And then we use Adaboost to improve the weak classifiers into a strong classifier."
        ],
        [
            "Now we want in this case we have information about the specific task because we're considering many trajectory through the environment, we want to be particularly sensitive to false negatives where a collision would occur, but we want to make sure that collision would occur, but we failed to detect it.",
            "We want to minimize the occurrence of those, and so we actually modify our objective function R 01 loss function so that we want to minimize as few as possible.",
            "We want to minimize as much as possible.",
            "The false positive.",
            "See hang on a second so future 151 is with you guys.",
            "So this slide actually doesn't show it nearly as well.",
            "Here we go.",
            "So this would be an example of a false negative where the actual collision occurs on the side of this particular decision tree feature that says the collision would occur, and so we're going to wait the output of the classifiers to strongly penalize these false negatives.",
            "So.",
            "Um?",
            "In terms of the reason that we're doing this function approximation, this is really probably the most important data point to remember is that we have the right answer, but for a single collision."
        ],
        [
            "Estimation we takes us on the order of four or five milliseconds to evaluate.",
            "We get an order of magnitude speedup in terms of extracting the features and classifying the result, and it's worth noting that here the dominant term in terms of classification is actually extracting the features from the train.",
            "If we were to optimally, if we were to use data structures that were designed to give us these features over the terrain, preprocess rain, etc.",
            "We can get this number down substantially, so even with very naive.",
            "Feature selection we get already an order of magnitude speedup.",
            "If we look in terms of the accuracy of the prediction, this is the RC curve.",
            "These are just samples drawn from it and we're getting as it says, 95% accuracy with fewer than 5% false positives.",
            "We picked that number because it gave us best performance in the tasks that we actually care about.",
            "We picked this point on the RC curve trade off and that it gave us the best performance and the thing we care about, which is actually the planning system."
        ],
        [
            "So.",
            "Data collected from hand labeled data.",
            "341 example robot steps and in each step we actually labeled whether or not the initial stance of each step led to a particular collision.",
            "Extract the features from each one of those example training instances and train up Ada boost and then we look at the frequency of miss collision detection and false collision detection, and it doesn't seem like it's doing all that particularly well.",
            "I'll grant you that the difference between these two lines here is that Ada boost alone with these features didn't necessarily do very well.",
            "So what we did is we added in that initial test on the initial.",
            "Stance and the final stands for the dog and the Adaboost with these explicit features in the terrain features, this is the best performance able to get.",
            "But the test that we actually care about is how well are we actually able to generate trajectory through the environment that quickly enough that are free of collisions?",
            "Because our goal is to generate trajectories very, very quickly that are free of collisions, I."
        ],
        [
            "Don't remember specifically how much time we allotted to the Planner in this case.",
            "It was an art planner, so it's sampling trajectory so it's online sampler.",
            "So the more time you give it, the better you're going to do.",
            "And so if we obviously, if we do no collision avoidance, then we do fairly poorly.",
            "If we only evaluate the initial and final stance of the dog at each step that it's going to take, we do reasonably well, which is a strong indicator for why incorporating these features explicitly in the learner was useful.",
            "But when we actually incorporate the learner in replace the actual.",
            "Geometric evaluation of potential terrain collisions with this function approximator that's approximating our collision detection.",
            "We do very well.",
            "And in terms of the number of collisions per run, we get the number down.",
            "It's this in particular is not great, but it actually turned out that these particular collisions were of relatively minor nature, that the reduction in collisions from say 6 or no collision.",
            "Checking to our learn collision checking is on the order of.",
            "Moving all of the major collisions.",
            "When we run this system with the actually incorporating the geometric evaluation, we of course do very, very well, but there's a question of how long you actually run, how many samples that you can incorporate?",
            "It's not real."
        ],
        [
            "A fair comparison between these planners and one that incorporates geometric system because you metric system simply doesn't have time to incorporate nearly as many samples.",
            "So this is just one somewhat different tack on the problem.",
            "Function approximation.",
            "Is it this?",
            "Many of these functions inside most robot systems, in particular in high dimensional systems where we actually need to evaluate functions where we have the right answer because we can do the full geometric evaluation, but we simply can't do it fast enough, it actually be useful to advertise the classification is one way to do that kind of function approximation.",
            "Christian, you probably want to turn off your screen saver.",
            "Excellent."
        ],
        [
            "You OK another problem that I want to talk about completely unrelated is this is some helicopter work that a Bernard at the back has been doing and he's going to show this video tomorrow in the UAV workshop and you'll hear more about it.",
            "So encourage you in the UAV workshop, but the idea here is that we have this micro air vehicle that's able to fly in indoor environments completely autonomously, and it's doing mapping and it's building a complete map.",
            "In this case of the first floor of this data center.",
            "Now.",
            "Mapping algorithms have come a long way in the last few years, but I think one question that still remains is how exactly plan trajectories as you explore.",
            "I mean, a lot of people have said interesting things about it, but I don't think we necessarily have the final word on how to plan exploration trajectories.",
            "And one of the reasons that this is still an important issue is that when you're."
        ],
        [
            "Generating a trajectory, you're optimizing a trajectory against an unknown map, then, implicitly, you reevaluating some cost function with respect to the distribution of possible Maps that you might be in, and you can write this optimization down and you can solve it, but it's very, very slow.",
            "The most general an most exact evaluations that I've seen of this in the last few years generate very, very reliable exploration trajectories that lead to very, very accurate Maps in the environment.",
            "But they tend to take a very long time to generate the next exploration strategy.",
            "And so there's two or two reasons why this problem is hard.",
            "One is that we frequently don't have exact parametric models of the map.",
            "We can generate some probability distribution, but it often contains strong independence assumptions that don't necessarily hold up and."
        ],
        [
            "Evaluating this very suspect and the other problem is that this is evaluating this activation trajectory with respect to the distribution of possible Maps is massively computationally intractable.",
            "So I'm going to suggest that we use reinforcement learning an our state space is going to be the current map in the robot pose.",
            "The action space is going to be trajectory through the map and our instantaneous reward, of course is the posterior map.",
            "Accuracy is fed through a. Mapping algorithm.",
            "Now, this is strongly related to many of the things that Peter spoke about this morning.",
            "But one of the things that makes this problem a little bit different is that even if we had a way to use reinforcement learning to generate, say, a value function or some Q function or some representation of the optimal policy representing that would actually be computationally demanding in its own right.",
            "And so instead what I'm going to do is I'm going to enter into a function approximator, but again, this is a discrete function approximator.",
            "We're no longer approximating A 01 loss function.",
            "We're actually going to learn a zero to N like an entery function that actually predicts, not, whether not were going like a collision, but it's going to predict what is the right action to take out of some particular scenario.",
            "So let's imagine that we have the class of cubic polynomials, and we can imagine that the classic cubic polynomials is some representation of the trajectories of the robot might take.",
            "Obviously, the robot can express more trajectories, but we're going to restrict ourselves to this class, and it's nice because a it allows us to ensure the parameterization of the trajectory using cubic polynomial ensures that you can interpolate two points to start location of robot and some goal position, and you can also interpolate given the current orientation of the robot you're not running on.",
            "The robots actually turn face some destination waypoint.",
            "And I would like to have my animation here, but current fund robot post controller integration."
        ],
        [
            "And what we have these three parameters?",
            "That is, the magnitude of the speed at the initial location and the angle of repose at the end location.",
            "And we're going to discretize these trajectories.",
            "Or this space introductory 160.",
            "And we're going to use a particular algorithm called policy so."
        ],
        [
            "Dynamic programming.",
            "And policy search dynamic programming is an algorithm that I really like for reinforcement learning, because again, it turns the function approximation problem, which we typically think of in reinforcement learning, is estimating the value or estimating the queue functions into a classification problem where you're trying to estimate what is the optimal action to take, and so how does this work?",
            "Well, we have some initial pose of the robot.",
            "And we have some map and let's imagine that we have some simulator and if we had that simulator, one thing that we could do is given initial map we could run the robot forward inside that simulator we have an accurate model of the robot dynamics in terms of the uncertainty in the sensing noise, the kind of thing that are spoke about this morning we could evaluate each one of these 160 trajectories and see which one gives us the least expected error.",
            "Minimum variance you choose your objective function at the end of those trajectories.",
            "But we don't want to do that.",
            "Because that's slow, so instead we're going to do is we're going to train this system up beforehand and learn to replace that evaluation system.",
            "So I sample a map.",
            "I have some sequence of waypoints that I'm traveling through between the environments and I'm going to mumble some things about how where these waypoints come from, but I can talk about it later if you like.",
            "And my goal here is to choose the trajectory that interpolate, interpolate these waypoints.",
            "And so for each action, each one of these 160 cubic polynomials that I have, I'm going to take the robot from, say, the waypoint and minus one to Waypoint add.",
            "I'm going to simulate the effect of that action A.",
            "And then I'm going to label the map in this particular goal with the best action, the one that gave me the most information or the least error, etc during simulation.",
            "So I simulate a bunch of these trajectories.",
            "And then I get out posterior estimates in terms of the accuracy and I'm going to train a classifier on this data in order to predict the best action given the input map imposing goes.",
            "Now I could I don't need to train this, I could do this in runtime and say I'm here.",
            "This is my pointer not working.",
            "I'm here, but this is my map.",
            "This is.",
            "These are the points I'm going through.",
            "Just tell me what the best trajectories are in terms of minimum uncertainty.",
            "But if I replace that with, say, in this particular example, we used a support vector machine to predict, given the high dimensional input of the robot pose and the map, what is the best output trajectory?",
            "Then I can reuse that here.",
            "This is a one step prediction I have.",
            "Nobody OK alright?",
            "Ha.",
            "Is that visible?",
            "Alright.",
            "OK, I'm just going to point.",
            "Angle your OK. Is this one of these pranks where you get me to stand at the back of the Hall and?",
            "No.",
            "Is that better?",
            "No, that's much worse, alright?",
            "We can certainly try that.",
            "How's that?",
            "That's why they pay Sebastian the big bucks.",
            "Oh, it's gone now.",
            "I guess PowerPoint didn't like that.",
            "I shouldn't have said that about Sebastian.",
            "I apologize.",
            "Alright, well I'm just going to stipulate wildly then, but the bottom line is that in this particular instance, our support vector machine is a one step classifier and I've replaced the function that's telling me what the best tell me what the best action is with the support vector machine.",
            "Now this is one step I can get a multi step trajectory out through the magic of dynamic programming by now taking my second problem which is to get from this location to that intermediate waypoints.",
            "And I can once again simulate all the set of actions, but I don't just simulate the one action I'm trying to learn here.",
            "I actually simulate the, you know, some cubic polynomial and then I carry on with what the previous classifier told me was the best thing here.",
            "And then I send simulate another action and then based on the posterior pose ended up at that intermediate waypoint and then simulate forward and I see what total uncertainty I got from the directory and repeat this over and over again and essentially what I'm doing now is I'm learning a controller for this step in the sequence that actually predicts what is going to be the total uncertainty at the end of the thing.",
            "I want to be clear that policy search dynamic programming is not my idea.",
            "This is due to Drew Bagnell at all, but the idea is that for exploration.",
            "It's there's a whole pile of training data, you know you need to do this repeatedly in order to learn the support vector machines for a given robot, but it's general to any map because the Maps are in the input features.",
            "And once I have this classifier, it's very very fit."
        ],
        [
            "To run.",
            "So in terms of minimizing map error during exploration, we did this on a particular robot where the robot was trained on data learned in a simulator.",
            "Given the physical characteristics of robot, and if you compare some shortest path exploration trajectory that simply just trying to go from unexplored error to unexplored area to unexplored area.",
            "What you see is the blue trajectory is the ground truth and the red trajectory is the estimated structure of the robot through the map, and you see that overtime, even with SLAM involved in generating the map estimate in the robot pose estimate, they start to diverge a little bit.",
            "Whereas if you compare the learn trajectory you see the structure is much smoother and the estimated trajectory and the true trajectory line up very very nicely.",
            "And we're doing nothing more than predicting what the uncertainty is going to be of the of each action given the map.",
            "But we're replacing that prediction with the support vector.",
            "Machine simply tells us what the.",
            "Best Best trajectory is so again this is another example of function approximation where it's not a continuous polynomial regression problem and it's not a 01 regression problem, it's a carrier regression problem or ennery but."
        ],
        [
            "It works very nicely, and if you compare the sort of the error in the map, sorry this is the error in the state estimate.",
            "Excuse me, overtime you see that it grows substantially overtime here.",
            "Here it stays nice and low.",
            "Obviously with these trajectories we don't necessarily have any bounds.",
            "Let's say that it's guaranteed to stay nice and low overtime, but in practice is."
        ],
        [
            "Works very well.",
            "So how much time do I have left?",
            "6 minutes OK.",
            "So I'm not going to get through the last thing that I wanted to talk about, but I've given sort of two examples of problems where we normally think of doing full blown computational optimization in order to evaluate the effect of trajectories in terms of uncertainty or evaluating the effect of.",
            "Geometric collision.",
            "But an intermediate point is model based reinforcement learning.",
            "So the model based reinforcement learning is very interesting to think about in terms of function approximation in regression, because it really makes explicit this tradeoff between how efficient you are with your data and how efficient you are with the optimization.",
            "If you're doing some kind of TD0 reinforcement learning, which I realize is not necessarily model based, then you're being very inefficient with your data and you are being very, very fast.",
            "And then if you do a full blown model based reinforcement learning algorithm where you collect the data, learn the model and replant in every time step, you are being as bad as efficient as you can possibly be with your data.",
            "But at the same time you're paying a big computational cost in terms of re optimizing every time, and you're still not even necessarily being as efficient with your data as you would like to be.",
            "And part of that is because we don't really think that much about how data in one part of this space can improve things in another part of the space.",
            "At least reinforcement learning and how they model dynamics has not typically done this.",
            "So for instance, if you model all the states is different than you can get very nice reinforcement learning bounds the Y cubed or metric cubed.",
            "If you have typed states, which I'll describe more carefully in a second, then.",
            "Are you still have discrete states?",
            "Then you get a little bit more representational power, but you don't get it.",
            "You get a little bit more generalization across types, but you don't necessarily get as much representation."
        ],
        [
            "And so I'm going to argue, or we don't need to argue, but I'm going to point to some work where there's actually spaces in here where there's a little bit more work that can be done so.",
            "This is joint work with Emma Brunskill and Michael Liben students Bethany."
        ],
        [
            "Only only, but the idea is that if you have continuous dynamics instead of discrete dynamics which you actually have sets of types that govern how the dynamics work, and you model these dynamics using standard common filter assumptions, so there's."
        ],
        [
            "See if I have it on the next slide.",
            "Yes, here we go, so you're right, can't point.",
            "So your state distribution is governed by some linear model, but that linear model is actually governed by a particular type, and so your state space is now a linear, Gaussian.",
            "Or excuse me, your dynamics are now linear Gaussian type of system with the types of attached in a sort of hybrid model that allow you to select which particular model you're using.",
            "Then two things happen.",
            "One is that you get very, very expressive dynamics and the hybrid control people have known this for a long time, but the other thing is is that you get very, very good data efficiency in terms of being able to reuse data in many parts of the space.",
            "When you learn something new about a particular type, all the states that share that type get that.",
            "Get that experience.",
            "Since I have relatively little time left, I'm just going to skip ahead to the important part, so I'm actually going to skip over this algorithm too."
        ],
        [
            "And just cut to this piece here.",
            "Which is given this type of model of the dynamics and we actually have a bound that basically says that the amount of data required to learn a model in terms of reinforcement learning converging to the auto policy is actually polynomial in the number of actions and the number of types.",
            "M. Here is our number of types and it's not a function of the number of states that we have in our world, or if we're doing operating continuous domain the we're doing some kind of fitted value iteration or using bases.",
            "It's not a function of the number of bases that we have in our world.",
            "It's strictly polynomial in terms of the number of types."
        ],
        [
            "And that's very nice, because if you look at many of the bounds that apply here, they exist, and they're good, and some of them are a little bit loose, but it's going to be very, very hard to defeat.",
            "The need to have an exponential amount of data where the exponent exponent is in terms of the number of dimensions in your state system.",
            "Here we actually have a pool and we've reduced it by having.",
            "Typically you have many fewer types.",
            "Then you do States and you're going to be polynomial with the state space dimension.",
            "Um, I'll admit that I'm being a little bit unfair to some of these other techniques because I'm assuming here that there's a uniform grid based discretization of the state space for some of these bounds, and you can often do better with using variable resolution or different kinds of bases.",
            "Nevertheless, the worst case bounds are still exponential, they're just much tighter, lower constant exponentials for these algorithms.",
            "So there is however an open problem here, which is that I'm assuming knowledge of these types, so I've taken my function approximation problem, which is I need to recover the value function over my state space from my learning problem and I've turned it into a learning problem over specific types of States and so I got two things.",
            "One is I got dramatic reduction in terms of the amount of data required, and this is one thing I see.",
            "The one thing that I got with that with these types as I got a polynomial.",
            "Reduction from exponential to a polynomial complexity in terms of the amount of data required to learn these things, and I have not put in here the statements that we can make also about the computational complexity, which are similarly nice."
        ],
        [
            "Um?",
            "Let me just a couple of results here.",
            "The computational cost.",
            "So yeah, this is I said I wasn't here, but the site is actually here.",
            "Is that in terms of actually using these models in terms of giving learning the models and then actually using the computer plan, the compact representation keeps the computational cost flat if we don't use types and we do the standard thing in terms of the learning, then we see a growth in both the computational complexity as well in terms of actually solve."
        ],
        [
            "In the policy, and then if we look at the actual performance overtime.",
            "If we take this, is this problem, here is a variant of the puzzle world problem and Q learning here.",
            "It takes a long time to converge to a reasonably good policy, does actually converge eventually.",
            "By incorporating types into our model, we do very very well because we will take a small amount of data and actually generalize that across the entire state space.",
            "If you have more types, obviously you don't generalize nearly as quickly, but you do are able to distinguish between the are able to make the distinctions that are actually important.",
            "So remember that I showed that sort of slide of the distinction, but or the two axes were generalization versus representation.",
            "The more types you have, the more powerful you representation is, but the longer it takes you to actually generalize in the appropriate manner.",
            "By having fewer types, which is the top graph that starts off very well at the beginning, it's able to generalize extremely quickly, but it's not actually able to represent the optimal policy.",
            "Now the open question that I refer to is exactly where do these types come from?",
            "So when we're making our initial design choices in terms of choosing a regressor, etc, we've actually got to make sure that we have, so we need to have this tradeoff between generalization versus representation and support and recognize where we fit in terms of that."
        ],
        [
            "Continuum.",
            "So I wasn't quite sure, so I realized that these pieces are a little bit disconnected in many respects, but at the core I believe that function approximation is essential for making many things that we know how to do fast, and when you make the decisions about what regression, receta use and where to put function approximation supporting recognize that you lie on a continuum, you're actually choosing to approximate somethings, either for computational speed or in terms of data efficiency.",
            "How much data you need in order to do their regression well, and the last conclusion I had is that I do think there is an open problem in terms of.",
            "Where did these types come from and how do you actually make that tradeoff between representation and generalization?",
            "So I will stop, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Like function approximation, very large topic so I decided to be contrarian.",
                    "label": 0
                },
                {
                    "sent": "An not talk specifically about regression in terms of recovering functional forms from data etc, but just to talk more about the general role of function, approximation, robotics and also to talk a little bit about how classification.",
                    "label": 1
                },
                {
                    "sent": "It can be as just a good function, approximators.",
                    "label": 0
                },
                {
                    "sent": "Anything else I'm going to talk about a few things, and this is joint work with a number of people, and I will try and point connect them to the appropriate piece of research as we go.",
                    "label": 0
                },
                {
                    "sent": "So let's think about.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learning as it applies to sort of a standard control system, so we might you know if we don't necessarily know the model ahead of time, then we're going to get a bunch of data from the world.",
                    "label": 0
                },
                {
                    "sent": "We're going to use it to estimate models, etc.",
                    "label": 1
                },
                {
                    "sent": "We're going to plan, and we're going to take actions and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So far this more at least in the morning.",
                    "label": 0
                },
                {
                    "sent": "There was a lot of talk of, well, how can we use regression function exclamation when we don't necessarily have an exact model and we're going to allow the data to represent what we need about the world.",
                    "label": 0
                },
                {
                    "sent": "But we might also think about scenarios where we actually do have a pretty good model, and we even have a very good way to evaluate exactly what we want.",
                    "label": 0
                },
                {
                    "sent": "But we might want to do it faster and we might want to do it in a way that accelerates things.",
                    "label": 0
                },
                {
                    "sent": "There's two ways that you can actually think about the complexity of this particular problem.",
                    "label": 0
                },
                {
                    "sent": "One is just the computational complexity of learning a particular model and using it in many robot problems.",
                    "label": 1
                },
                {
                    "sent": "There is models that we can evaluate very, very accurately and very, very effectively, but it's costly for us to do it.",
                    "label": 0
                },
                {
                    "sent": "And then the other way.",
                    "label": 0
                },
                {
                    "sent": "Other way in which we want to reduce complexities in terms of sample complexity.",
                    "label": 0
                },
                {
                    "sent": "It's important when thinking about regression etc to think about how much data do we actually need in order to recover the model that we're going to be optimizing against, and I'm going to argue that when you think about functional approximation and you're thinking about regression etc, that any given techniques it's on a continuum of these things that you can be very, very computationally costly and there's a whole bunch of techniques like that are very good in terms of not requiring much data.",
                    "label": 0
                },
                {
                    "sent": "And then at the other end of the continuum you can be very very cheap in terms of computation, But you might need a lot of data and you just have to.",
                    "label": 0
                },
                {
                    "sent": "You don't necessarily have to think hard about balancing those, but you need to recognize that any one of your favorite techniques sits somewhere in that continuum, and there's interesting things that can be said about actually doing the opposite of sort of, you know, exploring other parts of the continuum that haven't been explored.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the first example I actually want to talk about this is joint work with Rust.",
                    "label": 0
                },
                {
                    "sent": "Hedrick, this is from the Little Dog Project which some of you may know something about.",
                    "label": 0
                },
                {
                    "sent": "And the idea is that you've got to get a dog to walk across some terrain, and in this particular problem, setting the pose of the dog is known perfectly because you have high accuracy, motion capture and you have high accuracy joining coders.",
                    "label": 0
                },
                {
                    "sent": "And the other thing that you might have is another thing that you do have in this case is perfect knowledge of the terrain too.",
                    "label": 0
                },
                {
                    "sent": "Very very high accuracy, so this is purely a in many respects, just a computational exercises like can you plan joint angles etc to get the dog across very, very complicated terrain as quickly as possible?",
                    "label": 0
                },
                {
                    "sent": "Now I'm skipping out a lot of details, but at the end of the day you can write the whole thing down as an optimization if that is in fact what you wish to do.",
                    "label": 0
                },
                {
                    "sent": "Now, one of the ways in which this particular optimization this particular planning problem.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be hard is you have a very high dimensional dog at trivial representation of the sort of the center of mass of the center of the body of the dog is 6 degrees of freedom, and then each one of the legs is 3 degrees of freedom.",
                    "label": 0
                },
                {
                    "sent": "So you're talking about a 12 + 618 degree of freedom system as it is, and so you've actually got to figure out how that body, even if you treat it as a rigid body, is intersecting with the terrain given us current pose.",
                    "label": 0
                },
                {
                    "sent": "And that's a computationally demanding geometric calculation.",
                    "label": 0
                },
                {
                    "sent": "It's not exactly rocket science anymore.",
                    "label": 0
                },
                {
                    "sent": "There are well understood techniques for doing this, but they're not particularly fast, and so if you're doing motion planning, particularly in keynote, dynamic motion planning where you're considering hundreds or thousands of these trajectory through the environment to get the dog to run in to figure out which ones are effective, which ones are stable, which ones are kinematically feasible because of the joint angles, or because of interactions with terrain, and you're going to be doing this evaluation very, very often.",
                    "label": 0
                },
                {
                    "sent": "One of the things that we discovered in the course of this research project was that was actually a big bottleneck for us.",
                    "label": 0
                },
                {
                    "sent": "Was determining whether or not the dog was actually in collision with the terrain and whether or not the dog was going to fall as a result.",
                    "label": 0
                },
                {
                    "sent": "And so, like I say, we have a fast simulator that can actually answer this question for excuse me, not simulator, but fast kinematic evaluation system, but it's not fast enough.",
                    "label": 0
                },
                {
                    "sent": "And so this is actually a function and a function that you could might want to approximate it's 01 function as opposed to a continuous function of parametric function which you could use a function approximator, essentially a classifier, in order as inside the inner loop of this particular planner, and perhaps get much more efficient, much faster evaluation.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the terrain collisions.",
                    "label": 0
                },
                {
                    "sent": "So we're going to cast this is generic model, free, in this case classification problem and we can use real data to learn classifiers is full at trajectories with the hope that it will be faster to evaluate.",
                    "label": 1
                },
                {
                    "sent": "But at the same time accurate enough to actually allow us to plan effectively.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's again, there's a continuum of things that you might do so at the one end of the continuum there's very high Fidelity geometric models.",
                    "label": 0
                },
                {
                    "sent": "In this case, our dog was reasonably well approximated as a series of cylinders.",
                    "label": 0
                },
                {
                    "sent": "The body, the dog is approximately cylindrical.",
                    "label": 0
                },
                {
                    "sent": "Initialize it like this cylindrical.",
                    "label": 0
                },
                {
                    "sent": "This is accurate, very expensive, a intermediate model is to approximate it.",
                    "label": 0
                },
                {
                    "sent": "You",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Using a line model that sort of captures the front of the legs.",
                    "label": 1
                },
                {
                    "sent": "It's less accurate, but cheaper.",
                    "label": 1
                },
                {
                    "sent": "And then the other thing you could actually just throw away a lot of the internal motion of the dog and just say.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The beginning of the trajectory in collision is the end of the trajectory in collision.",
                    "label": 0
                },
                {
                    "sent": "This is very very fast, but to evaluate but misses.",
                    "label": 1
                },
                {
                    "sent": "Of course, the internal collisions that could occur as a dog moves from the pre step to this or the end of this step we call this the pre phase and the post phase during the step.",
                    "label": 0
                },
                {
                    "sent": "Instead of actually backing off to one of these extremely approximate classifiers, we're just going to go ahead and learn this.",
                    "label": 0
                },
                {
                    "sent": "Instead, we're going to classify the entire trip.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Factory without evaluating samples directly within the trajectory.",
                    "label": 0
                },
                {
                    "sent": "So one problem you have is feature.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We take pieces of the terrain.",
                    "label": 0
                },
                {
                    "sent": "In the local robots local coordinate frame and we take pieces of terrain and we use these as input features along with the pose of the dog, and we feed that to a classifier.",
                    "label": 1
                },
                {
                    "sent": "And we take a generic classifier from machine learning and this we tried a number and ADA boost.",
                    "label": 0
                },
                {
                    "sent": "In this case happened to work particularly well for us.",
                    "label": 0
                },
                {
                    "sent": "We take like.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These input features in the terrain, so the initial slope of the terrain, final slope of the terrain, step length, etc features a dog center body, joint angles, etc and we train up weak classifiers.",
                    "label": 1
                },
                {
                    "sent": "In this case, decision trees that say whether or not the dog is actually going to collide.",
                    "label": 0
                },
                {
                    "sent": "This is the function that we're approximating.",
                    "label": 0
                },
                {
                    "sent": "It's a 01 function.",
                    "label": 0
                },
                {
                    "sent": "And these are the features that a particular decision tree classified.",
                    "label": 0
                },
                {
                    "sent": "And then we use Adaboost to improve the weak classifiers into a strong classifier.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we want in this case we have information about the specific task because we're considering many trajectory through the environment, we want to be particularly sensitive to false negatives where a collision would occur, but we want to make sure that collision would occur, but we failed to detect it.",
                    "label": 0
                },
                {
                    "sent": "We want to minimize the occurrence of those, and so we actually modify our objective function R 01 loss function so that we want to minimize as few as possible.",
                    "label": 0
                },
                {
                    "sent": "We want to minimize as much as possible.",
                    "label": 0
                },
                {
                    "sent": "The false positive.",
                    "label": 0
                },
                {
                    "sent": "See hang on a second so future 151 is with you guys.",
                    "label": 0
                },
                {
                    "sent": "So this slide actually doesn't show it nearly as well.",
                    "label": 0
                },
                {
                    "sent": "Here we go.",
                    "label": 0
                },
                {
                    "sent": "So this would be an example of a false negative where the actual collision occurs on the side of this particular decision tree feature that says the collision would occur, and so we're going to wait the output of the classifiers to strongly penalize these false negatives.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "In terms of the reason that we're doing this function approximation, this is really probably the most important data point to remember is that we have the right answer, but for a single collision.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Estimation we takes us on the order of four or five milliseconds to evaluate.",
                    "label": 0
                },
                {
                    "sent": "We get an order of magnitude speedup in terms of extracting the features and classifying the result, and it's worth noting that here the dominant term in terms of classification is actually extracting the features from the train.",
                    "label": 0
                },
                {
                    "sent": "If we were to optimally, if we were to use data structures that were designed to give us these features over the terrain, preprocess rain, etc.",
                    "label": 0
                },
                {
                    "sent": "We can get this number down substantially, so even with very naive.",
                    "label": 0
                },
                {
                    "sent": "Feature selection we get already an order of magnitude speedup.",
                    "label": 0
                },
                {
                    "sent": "If we look in terms of the accuracy of the prediction, this is the RC curve.",
                    "label": 0
                },
                {
                    "sent": "These are just samples drawn from it and we're getting as it says, 95% accuracy with fewer than 5% false positives.",
                    "label": 1
                },
                {
                    "sent": "We picked that number because it gave us best performance in the tasks that we actually care about.",
                    "label": 0
                },
                {
                    "sent": "We picked this point on the RC curve trade off and that it gave us the best performance and the thing we care about, which is actually the planning system.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Data collected from hand labeled data.",
                    "label": 0
                },
                {
                    "sent": "341 example robot steps and in each step we actually labeled whether or not the initial stance of each step led to a particular collision.",
                    "label": 0
                },
                {
                    "sent": "Extract the features from each one of those example training instances and train up Ada boost and then we look at the frequency of miss collision detection and false collision detection, and it doesn't seem like it's doing all that particularly well.",
                    "label": 0
                },
                {
                    "sent": "I'll grant you that the difference between these two lines here is that Ada boost alone with these features didn't necessarily do very well.",
                    "label": 0
                },
                {
                    "sent": "So what we did is we added in that initial test on the initial.",
                    "label": 0
                },
                {
                    "sent": "Stance and the final stands for the dog and the Adaboost with these explicit features in the terrain features, this is the best performance able to get.",
                    "label": 0
                },
                {
                    "sent": "But the test that we actually care about is how well are we actually able to generate trajectory through the environment that quickly enough that are free of collisions?",
                    "label": 0
                },
                {
                    "sent": "Because our goal is to generate trajectories very, very quickly that are free of collisions, I.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Don't remember specifically how much time we allotted to the Planner in this case.",
                    "label": 0
                },
                {
                    "sent": "It was an art planner, so it's sampling trajectory so it's online sampler.",
                    "label": 0
                },
                {
                    "sent": "So the more time you give it, the better you're going to do.",
                    "label": 0
                },
                {
                    "sent": "And so if we obviously, if we do no collision avoidance, then we do fairly poorly.",
                    "label": 0
                },
                {
                    "sent": "If we only evaluate the initial and final stance of the dog at each step that it's going to take, we do reasonably well, which is a strong indicator for why incorporating these features explicitly in the learner was useful.",
                    "label": 0
                },
                {
                    "sent": "But when we actually incorporate the learner in replace the actual.",
                    "label": 0
                },
                {
                    "sent": "Geometric evaluation of potential terrain collisions with this function approximator that's approximating our collision detection.",
                    "label": 0
                },
                {
                    "sent": "We do very well.",
                    "label": 0
                },
                {
                    "sent": "And in terms of the number of collisions per run, we get the number down.",
                    "label": 0
                },
                {
                    "sent": "It's this in particular is not great, but it actually turned out that these particular collisions were of relatively minor nature, that the reduction in collisions from say 6 or no collision.",
                    "label": 0
                },
                {
                    "sent": "Checking to our learn collision checking is on the order of.",
                    "label": 0
                },
                {
                    "sent": "Moving all of the major collisions.",
                    "label": 0
                },
                {
                    "sent": "When we run this system with the actually incorporating the geometric evaluation, we of course do very, very well, but there's a question of how long you actually run, how many samples that you can incorporate?",
                    "label": 0
                },
                {
                    "sent": "It's not real.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A fair comparison between these planners and one that incorporates geometric system because you metric system simply doesn't have time to incorporate nearly as many samples.",
                    "label": 0
                },
                {
                    "sent": "So this is just one somewhat different tack on the problem.",
                    "label": 0
                },
                {
                    "sent": "Function approximation.",
                    "label": 0
                },
                {
                    "sent": "Is it this?",
                    "label": 0
                },
                {
                    "sent": "Many of these functions inside most robot systems, in particular in high dimensional systems where we actually need to evaluate functions where we have the right answer because we can do the full geometric evaluation, but we simply can't do it fast enough, it actually be useful to advertise the classification is one way to do that kind of function approximation.",
                    "label": 0
                },
                {
                    "sent": "Christian, you probably want to turn off your screen saver.",
                    "label": 0
                },
                {
                    "sent": "Excellent.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You OK another problem that I want to talk about completely unrelated is this is some helicopter work that a Bernard at the back has been doing and he's going to show this video tomorrow in the UAV workshop and you'll hear more about it.",
                    "label": 0
                },
                {
                    "sent": "So encourage you in the UAV workshop, but the idea here is that we have this micro air vehicle that's able to fly in indoor environments completely autonomously, and it's doing mapping and it's building a complete map.",
                    "label": 0
                },
                {
                    "sent": "In this case of the first floor of this data center.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Mapping algorithms have come a long way in the last few years, but I think one question that still remains is how exactly plan trajectories as you explore.",
                    "label": 0
                },
                {
                    "sent": "I mean, a lot of people have said interesting things about it, but I don't think we necessarily have the final word on how to plan exploration trajectories.",
                    "label": 0
                },
                {
                    "sent": "And one of the reasons that this is still an important issue is that when you're.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Generating a trajectory, you're optimizing a trajectory against an unknown map, then, implicitly, you reevaluating some cost function with respect to the distribution of possible Maps that you might be in, and you can write this optimization down and you can solve it, but it's very, very slow.",
                    "label": 0
                },
                {
                    "sent": "The most general an most exact evaluations that I've seen of this in the last few years generate very, very reliable exploration trajectories that lead to very, very accurate Maps in the environment.",
                    "label": 0
                },
                {
                    "sent": "But they tend to take a very long time to generate the next exploration strategy.",
                    "label": 0
                },
                {
                    "sent": "And so there's two or two reasons why this problem is hard.",
                    "label": 0
                },
                {
                    "sent": "One is that we frequently don't have exact parametric models of the map.",
                    "label": 0
                },
                {
                    "sent": "We can generate some probability distribution, but it often contains strong independence assumptions that don't necessarily hold up and.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Evaluating this very suspect and the other problem is that this is evaluating this activation trajectory with respect to the distribution of possible Maps is massively computationally intractable.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to suggest that we use reinforcement learning an our state space is going to be the current map in the robot pose.",
                    "label": 1
                },
                {
                    "sent": "The action space is going to be trajectory through the map and our instantaneous reward, of course is the posterior map.",
                    "label": 0
                },
                {
                    "sent": "Accuracy is fed through a. Mapping algorithm.",
                    "label": 0
                },
                {
                    "sent": "Now, this is strongly related to many of the things that Peter spoke about this morning.",
                    "label": 0
                },
                {
                    "sent": "But one of the things that makes this problem a little bit different is that even if we had a way to use reinforcement learning to generate, say, a value function or some Q function or some representation of the optimal policy representing that would actually be computationally demanding in its own right.",
                    "label": 0
                },
                {
                    "sent": "And so instead what I'm going to do is I'm going to enter into a function approximator, but again, this is a discrete function approximator.",
                    "label": 0
                },
                {
                    "sent": "We're no longer approximating A 01 loss function.",
                    "label": 0
                },
                {
                    "sent": "We're actually going to learn a zero to N like an entery function that actually predicts, not, whether not were going like a collision, but it's going to predict what is the right action to take out of some particular scenario.",
                    "label": 0
                },
                {
                    "sent": "So let's imagine that we have the class of cubic polynomials, and we can imagine that the classic cubic polynomials is some representation of the trajectories of the robot might take.",
                    "label": 0
                },
                {
                    "sent": "Obviously, the robot can express more trajectories, but we're going to restrict ourselves to this class, and it's nice because a it allows us to ensure the parameterization of the trajectory using cubic polynomial ensures that you can interpolate two points to start location of robot and some goal position, and you can also interpolate given the current orientation of the robot you're not running on.",
                    "label": 0
                },
                {
                    "sent": "The robots actually turn face some destination waypoint.",
                    "label": 0
                },
                {
                    "sent": "And I would like to have my animation here, but current fund robot post controller integration.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what we have these three parameters?",
                    "label": 0
                },
                {
                    "sent": "That is, the magnitude of the speed at the initial location and the angle of repose at the end location.",
                    "label": 1
                },
                {
                    "sent": "And we're going to discretize these trajectories.",
                    "label": 0
                },
                {
                    "sent": "Or this space introductory 160.",
                    "label": 0
                },
                {
                    "sent": "And we're going to use a particular algorithm called policy so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "And policy search dynamic programming is an algorithm that I really like for reinforcement learning, because again, it turns the function approximation problem, which we typically think of in reinforcement learning, is estimating the value or estimating the queue functions into a classification problem where you're trying to estimate what is the optimal action to take, and so how does this work?",
                    "label": 0
                },
                {
                    "sent": "Well, we have some initial pose of the robot.",
                    "label": 0
                },
                {
                    "sent": "And we have some map and let's imagine that we have some simulator and if we had that simulator, one thing that we could do is given initial map we could run the robot forward inside that simulator we have an accurate model of the robot dynamics in terms of the uncertainty in the sensing noise, the kind of thing that are spoke about this morning we could evaluate each one of these 160 trajectories and see which one gives us the least expected error.",
                    "label": 0
                },
                {
                    "sent": "Minimum variance you choose your objective function at the end of those trajectories.",
                    "label": 0
                },
                {
                    "sent": "But we don't want to do that.",
                    "label": 0
                },
                {
                    "sent": "Because that's slow, so instead we're going to do is we're going to train this system up beforehand and learn to replace that evaluation system.",
                    "label": 0
                },
                {
                    "sent": "So I sample a map.",
                    "label": 1
                },
                {
                    "sent": "I have some sequence of waypoints that I'm traveling through between the environments and I'm going to mumble some things about how where these waypoints come from, but I can talk about it later if you like.",
                    "label": 0
                },
                {
                    "sent": "And my goal here is to choose the trajectory that interpolate, interpolate these waypoints.",
                    "label": 1
                },
                {
                    "sent": "And so for each action, each one of these 160 cubic polynomials that I have, I'm going to take the robot from, say, the waypoint and minus one to Waypoint add.",
                    "label": 0
                },
                {
                    "sent": "I'm going to simulate the effect of that action A.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to label the map in this particular goal with the best action, the one that gave me the most information or the least error, etc during simulation.",
                    "label": 1
                },
                {
                    "sent": "So I simulate a bunch of these trajectories.",
                    "label": 1
                },
                {
                    "sent": "And then I get out posterior estimates in terms of the accuracy and I'm going to train a classifier on this data in order to predict the best action given the input map imposing goes.",
                    "label": 0
                },
                {
                    "sent": "Now I could I don't need to train this, I could do this in runtime and say I'm here.",
                    "label": 0
                },
                {
                    "sent": "This is my pointer not working.",
                    "label": 0
                },
                {
                    "sent": "I'm here, but this is my map.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "These are the points I'm going through.",
                    "label": 0
                },
                {
                    "sent": "Just tell me what the best trajectories are in terms of minimum uncertainty.",
                    "label": 0
                },
                {
                    "sent": "But if I replace that with, say, in this particular example, we used a support vector machine to predict, given the high dimensional input of the robot pose and the map, what is the best output trajectory?",
                    "label": 0
                },
                {
                    "sent": "Then I can reuse that here.",
                    "label": 0
                },
                {
                    "sent": "This is a one step prediction I have.",
                    "label": 0
                },
                {
                    "sent": "Nobody OK alright?",
                    "label": 0
                },
                {
                    "sent": "Ha.",
                    "label": 0
                },
                {
                    "sent": "Is that visible?",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm just going to point.",
                    "label": 0
                },
                {
                    "sent": "Angle your OK. Is this one of these pranks where you get me to stand at the back of the Hall and?",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Is that better?",
                    "label": 0
                },
                {
                    "sent": "No, that's much worse, alright?",
                    "label": 0
                },
                {
                    "sent": "We can certainly try that.",
                    "label": 0
                },
                {
                    "sent": "How's that?",
                    "label": 0
                },
                {
                    "sent": "That's why they pay Sebastian the big bucks.",
                    "label": 0
                },
                {
                    "sent": "Oh, it's gone now.",
                    "label": 0
                },
                {
                    "sent": "I guess PowerPoint didn't like that.",
                    "label": 0
                },
                {
                    "sent": "I shouldn't have said that about Sebastian.",
                    "label": 0
                },
                {
                    "sent": "I apologize.",
                    "label": 0
                },
                {
                    "sent": "Alright, well I'm just going to stipulate wildly then, but the bottom line is that in this particular instance, our support vector machine is a one step classifier and I've replaced the function that's telling me what the best tell me what the best action is with the support vector machine.",
                    "label": 0
                },
                {
                    "sent": "Now this is one step I can get a multi step trajectory out through the magic of dynamic programming by now taking my second problem which is to get from this location to that intermediate waypoints.",
                    "label": 0
                },
                {
                    "sent": "And I can once again simulate all the set of actions, but I don't just simulate the one action I'm trying to learn here.",
                    "label": 0
                },
                {
                    "sent": "I actually simulate the, you know, some cubic polynomial and then I carry on with what the previous classifier told me was the best thing here.",
                    "label": 0
                },
                {
                    "sent": "And then I send simulate another action and then based on the posterior pose ended up at that intermediate waypoint and then simulate forward and I see what total uncertainty I got from the directory and repeat this over and over again and essentially what I'm doing now is I'm learning a controller for this step in the sequence that actually predicts what is going to be the total uncertainty at the end of the thing.",
                    "label": 0
                },
                {
                    "sent": "I want to be clear that policy search dynamic programming is not my idea.",
                    "label": 0
                },
                {
                    "sent": "This is due to Drew Bagnell at all, but the idea is that for exploration.",
                    "label": 0
                },
                {
                    "sent": "It's there's a whole pile of training data, you know you need to do this repeatedly in order to learn the support vector machines for a given robot, but it's general to any map because the Maps are in the input features.",
                    "label": 0
                },
                {
                    "sent": "And once I have this classifier, it's very very fit.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To run.",
                    "label": 0
                },
                {
                    "sent": "So in terms of minimizing map error during exploration, we did this on a particular robot where the robot was trained on data learned in a simulator.",
                    "label": 0
                },
                {
                    "sent": "Given the physical characteristics of robot, and if you compare some shortest path exploration trajectory that simply just trying to go from unexplored error to unexplored area to unexplored area.",
                    "label": 0
                },
                {
                    "sent": "What you see is the blue trajectory is the ground truth and the red trajectory is the estimated structure of the robot through the map, and you see that overtime, even with SLAM involved in generating the map estimate in the robot pose estimate, they start to diverge a little bit.",
                    "label": 0
                },
                {
                    "sent": "Whereas if you compare the learn trajectory you see the structure is much smoother and the estimated trajectory and the true trajectory line up very very nicely.",
                    "label": 0
                },
                {
                    "sent": "And we're doing nothing more than predicting what the uncertainty is going to be of the of each action given the map.",
                    "label": 0
                },
                {
                    "sent": "But we're replacing that prediction with the support vector.",
                    "label": 0
                },
                {
                    "sent": "Machine simply tells us what the.",
                    "label": 0
                },
                {
                    "sent": "Best Best trajectory is so again this is another example of function approximation where it's not a continuous polynomial regression problem and it's not a 01 regression problem, it's a carrier regression problem or ennery but.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It works very nicely, and if you compare the sort of the error in the map, sorry this is the error in the state estimate.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, overtime you see that it grows substantially overtime here.",
                    "label": 0
                },
                {
                    "sent": "Here it stays nice and low.",
                    "label": 0
                },
                {
                    "sent": "Obviously with these trajectories we don't necessarily have any bounds.",
                    "label": 0
                },
                {
                    "sent": "Let's say that it's guaranteed to stay nice and low overtime, but in practice is.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Works very well.",
                    "label": 0
                },
                {
                    "sent": "So how much time do I have left?",
                    "label": 0
                },
                {
                    "sent": "6 minutes OK.",
                    "label": 0
                },
                {
                    "sent": "So I'm not going to get through the last thing that I wanted to talk about, but I've given sort of two examples of problems where we normally think of doing full blown computational optimization in order to evaluate the effect of trajectories in terms of uncertainty or evaluating the effect of.",
                    "label": 0
                },
                {
                    "sent": "Geometric collision.",
                    "label": 0
                },
                {
                    "sent": "But an intermediate point is model based reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "So the model based reinforcement learning is very interesting to think about in terms of function approximation in regression, because it really makes explicit this tradeoff between how efficient you are with your data and how efficient you are with the optimization.",
                    "label": 0
                },
                {
                    "sent": "If you're doing some kind of TD0 reinforcement learning, which I realize is not necessarily model based, then you're being very inefficient with your data and you are being very, very fast.",
                    "label": 0
                },
                {
                    "sent": "And then if you do a full blown model based reinforcement learning algorithm where you collect the data, learn the model and replant in every time step, you are being as bad as efficient as you can possibly be with your data.",
                    "label": 0
                },
                {
                    "sent": "But at the same time you're paying a big computational cost in terms of re optimizing every time, and you're still not even necessarily being as efficient with your data as you would like to be.",
                    "label": 0
                },
                {
                    "sent": "And part of that is because we don't really think that much about how data in one part of this space can improve things in another part of the space.",
                    "label": 0
                },
                {
                    "sent": "At least reinforcement learning and how they model dynamics has not typically done this.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if you model all the states is different than you can get very nice reinforcement learning bounds the Y cubed or metric cubed.",
                    "label": 0
                },
                {
                    "sent": "If you have typed states, which I'll describe more carefully in a second, then.",
                    "label": 0
                },
                {
                    "sent": "Are you still have discrete states?",
                    "label": 1
                },
                {
                    "sent": "Then you get a little bit more representational power, but you don't get it.",
                    "label": 0
                },
                {
                    "sent": "You get a little bit more generalization across types, but you don't necessarily get as much representation.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so I'm going to argue, or we don't need to argue, but I'm going to point to some work where there's actually spaces in here where there's a little bit more work that can be done so.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with Emma Brunskill and Michael Liben students Bethany.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only only, but the idea is that if you have continuous dynamics instead of discrete dynamics which you actually have sets of types that govern how the dynamics work, and you model these dynamics using standard common filter assumptions, so there's.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See if I have it on the next slide.",
                    "label": 0
                },
                {
                    "sent": "Yes, here we go, so you're right, can't point.",
                    "label": 0
                },
                {
                    "sent": "So your state distribution is governed by some linear model, but that linear model is actually governed by a particular type, and so your state space is now a linear, Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Or excuse me, your dynamics are now linear Gaussian type of system with the types of attached in a sort of hybrid model that allow you to select which particular model you're using.",
                    "label": 0
                },
                {
                    "sent": "Then two things happen.",
                    "label": 0
                },
                {
                    "sent": "One is that you get very, very expressive dynamics and the hybrid control people have known this for a long time, but the other thing is is that you get very, very good data efficiency in terms of being able to reuse data in many parts of the space.",
                    "label": 0
                },
                {
                    "sent": "When you learn something new about a particular type, all the states that share that type get that.",
                    "label": 0
                },
                {
                    "sent": "Get that experience.",
                    "label": 0
                },
                {
                    "sent": "Since I have relatively little time left, I'm just going to skip ahead to the important part, so I'm actually going to skip over this algorithm too.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And just cut to this piece here.",
                    "label": 0
                },
                {
                    "sent": "Which is given this type of model of the dynamics and we actually have a bound that basically says that the amount of data required to learn a model in terms of reinforcement learning converging to the auto policy is actually polynomial in the number of actions and the number of types.",
                    "label": 0
                },
                {
                    "sent": "M. Here is our number of types and it's not a function of the number of states that we have in our world, or if we're doing operating continuous domain the we're doing some kind of fitted value iteration or using bases.",
                    "label": 0
                },
                {
                    "sent": "It's not a function of the number of bases that we have in our world.",
                    "label": 0
                },
                {
                    "sent": "It's strictly polynomial in terms of the number of types.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that's very nice, because if you look at many of the bounds that apply here, they exist, and they're good, and some of them are a little bit loose, but it's going to be very, very hard to defeat.",
                    "label": 0
                },
                {
                    "sent": "The need to have an exponential amount of data where the exponent exponent is in terms of the number of dimensions in your state system.",
                    "label": 0
                },
                {
                    "sent": "Here we actually have a pool and we've reduced it by having.",
                    "label": 0
                },
                {
                    "sent": "Typically you have many fewer types.",
                    "label": 0
                },
                {
                    "sent": "Then you do States and you're going to be polynomial with the state space dimension.",
                    "label": 1
                },
                {
                    "sent": "Um, I'll admit that I'm being a little bit unfair to some of these other techniques because I'm assuming here that there's a uniform grid based discretization of the state space for some of these bounds, and you can often do better with using variable resolution or different kinds of bases.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, the worst case bounds are still exponential, they're just much tighter, lower constant exponentials for these algorithms.",
                    "label": 0
                },
                {
                    "sent": "So there is however an open problem here, which is that I'm assuming knowledge of these types, so I've taken my function approximation problem, which is I need to recover the value function over my state space from my learning problem and I've turned it into a learning problem over specific types of States and so I got two things.",
                    "label": 0
                },
                {
                    "sent": "One is I got dramatic reduction in terms of the amount of data required, and this is one thing I see.",
                    "label": 0
                },
                {
                    "sent": "The one thing that I got with that with these types as I got a polynomial.",
                    "label": 0
                },
                {
                    "sent": "Reduction from exponential to a polynomial complexity in terms of the amount of data required to learn these things, and I have not put in here the statements that we can make also about the computational complexity, which are similarly nice.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Let me just a couple of results here.",
                    "label": 0
                },
                {
                    "sent": "The computational cost.",
                    "label": 0
                },
                {
                    "sent": "So yeah, this is I said I wasn't here, but the site is actually here.",
                    "label": 0
                },
                {
                    "sent": "Is that in terms of actually using these models in terms of giving learning the models and then actually using the computer plan, the compact representation keeps the computational cost flat if we don't use types and we do the standard thing in terms of the learning, then we see a growth in both the computational complexity as well in terms of actually solve.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the policy, and then if we look at the actual performance overtime.",
                    "label": 0
                },
                {
                    "sent": "If we take this, is this problem, here is a variant of the puzzle world problem and Q learning here.",
                    "label": 0
                },
                {
                    "sent": "It takes a long time to converge to a reasonably good policy, does actually converge eventually.",
                    "label": 0
                },
                {
                    "sent": "By incorporating types into our model, we do very very well because we will take a small amount of data and actually generalize that across the entire state space.",
                    "label": 0
                },
                {
                    "sent": "If you have more types, obviously you don't generalize nearly as quickly, but you do are able to distinguish between the are able to make the distinctions that are actually important.",
                    "label": 0
                },
                {
                    "sent": "So remember that I showed that sort of slide of the distinction, but or the two axes were generalization versus representation.",
                    "label": 0
                },
                {
                    "sent": "The more types you have, the more powerful you representation is, but the longer it takes you to actually generalize in the appropriate manner.",
                    "label": 0
                },
                {
                    "sent": "By having fewer types, which is the top graph that starts off very well at the beginning, it's able to generalize extremely quickly, but it's not actually able to represent the optimal policy.",
                    "label": 0
                },
                {
                    "sent": "Now the open question that I refer to is exactly where do these types come from?",
                    "label": 0
                },
                {
                    "sent": "So when we're making our initial design choices in terms of choosing a regressor, etc, we've actually got to make sure that we have, so we need to have this tradeoff between generalization versus representation and support and recognize where we fit in terms of that.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Continuum.",
                    "label": 0
                },
                {
                    "sent": "So I wasn't quite sure, so I realized that these pieces are a little bit disconnected in many respects, but at the core I believe that function approximation is essential for making many things that we know how to do fast, and when you make the decisions about what regression, receta use and where to put function approximation supporting recognize that you lie on a continuum, you're actually choosing to approximate somethings, either for computational speed or in terms of data efficiency.",
                    "label": 1
                },
                {
                    "sent": "How much data you need in order to do their regression well, and the last conclusion I had is that I do think there is an open problem in terms of.",
                    "label": 0
                },
                {
                    "sent": "Where did these types come from and how do you actually make that tradeoff between representation and generalization?",
                    "label": 0
                },
                {
                    "sent": "So I will stop, thank you.",
                    "label": 0
                }
            ]
        }
    }
}