{
    "id": "il2moyzzxarzvexogmp54rf44jnqfjm6",
    "title": "An Effective Approach to Realizing Planning Programs",
    "info": {
        "author": [
            "Alfonso E. Gerevini, Facolt\u00e0 di Ingegneria, University of Brescia"
        ],
        "published": "July 21, 2011",
        "recorded": "June 2011",
        "category": [
            "Top->Computer Science->Artificial Intelligence->Planning and Scheduling"
        ]
    },
    "url": "http://videolectures.net/icaps2011_gerevini_planning/",
    "segmentation": [
        [
            "Hey, good afternoon this is joint work with Fabio Petriti and Alessandro."
        ],
        [
            "Safety planning programs have been recently introduced in the context of autonomous agents and multiagent systems by Digiacomo and his collaborators as a method to specify, at an eye level and the clarity of level, the behavior of one or more agents acting in a planning domain that can be specified.",
            "For example, using a PDF.",
            "Technically, planning program is a state transition system in which the transitions are labeled by goals that the agent can choose or ask to achieve, and this states represents decision points about what is the next goal or goals that the agent has to achieve.",
            "Fundamental problem in this framework is realizing a planning problem which essentially.",
            "Consist of a finding and combining a collection of plans I have for the transitions of the planning program so that the planning program is the executable.",
            "They original approach for computing the realization of a planning program was proposed last year and is very powerful, but it's also very inefficient as we will show in the in this presentation.",
            "In our work, we propose a simple approach, an alternative approach.",
            "It is strongly based on planning technology and can exploit the current fast domain independent planners to solve the reality.",
            "Alization problem much more quickly."
        ],
        [
            "In this talk, first I will briefly describe describe what are planning a program is and the problem of realizing a cleaning program.",
            "Then I will present our algorithm for solving this problem.",
            "Some experimental results and finally conclude."
        ],
        [
            "Johnson in future."
        ],
        [
            "Work.",
            "So essentially a planning problem can be described with this very simple example in which we have a Sailor representative that works for a company.",
            "For example, in in New York and initially he is in New York and the customers are in in Boston or in Washington, saw on customer requestor yes to fly to Washington or Boston and when he's in Boston or in Washington he has to go back to his company.",
            "Dear Sir, behavior can be described by this very simple planning program in which we have three States and for transitions that are labeled by the goals of the agent.",
            "Here the agent is P1 and the seller Presentative is P1 and we have this this goals I will."
        ],
        [
            "Come back to this example."
        ],
        [
            "More formally, planning problem is.",
            "Is it finding this way so it's a very simple extension?",
            "Well, it's a simple, very simple characterization.",
            "We have given a planning domain that originally there could be deterministic or non deterministic.",
            "In this work we focus on only on deterministic planning domains.",
            "So given a set of domain propositional set of actions in the state of transition function that describes Scribe describes the plane domain.",
            "We define a planning program as a couple.",
            "Performed by a set of program states.",
            "Keep an initial program state VOA set of possible goals over the domain propositions and program transition function that, given the state of the program and goal, gives another state of."
        ],
        [
            "The program.",
            "OK, so the definition of the problem realizing planning program is based on the notion of execution for a planning program during the execution of a planning program, we have that the domain the planning domain is always in a state and the the program is also in a state.",
            "So this system is in a joint state as the initially.",
            "The domain is in the initial status O.",
            "And the programming the initial program state VO when the system is in a joint state to SV, the agent selects a transition from the planning program and if there is a transition leaving from from V and executes a plan that achieves the goal.",
            "Labeling the transition from this state, the world state as.",
            "This can generate a new joint state as primary prime, and then we iterate this this process so the execution can be infinite.",
            "And realizing opinion problem consists of building a plan for every transition that can be selected during the execution of the training program.",
            "Considering at the car rental ministate.",
            "In this process it is possible to generate joint states which I have the same program stated, but the different states of the world.",
            "This means that when I have to realize a transition that is build a plan for the goal labelling the transition, I might have to consider more than one plan becauses the agent could be in more than one.",
            "State World state."
        ],
        [
            "So for right now we're very simple example of this.",
            "A function is the realization function for for our problem for our domain, which is a very simple logistics domain in which the actions that in type of functions are only flying boarding in the barking, an initially the program state is in state VO and we have that the sales representatives in New York and their plan is in Boston.",
            "So if the goal is to go to Boston, we have which is G2.",
            "We have that we can construct the plan A1A2A3A four, and if this this plan will be executed, a new state will be generated and so on.",
            "So this function is that what we the output or the solution of the realization problem for this."
        ],
        [
            "Training program.",
            "OK, the notion of planning program realization can of course be defined formally through an inductive definition.",
            "I will skip these details that are."
        ],
        [
            "In the paper.",
            "There are two approaches as I mentioned for solving this problem.",
            "The original project is based on the former synthesis in the context of linear temporal logic, and it's it has some advantages such as they can use available tools like TLV, and it's also easy to handle non deterministic domains.",
            "On the other hand, as I mentioned is very inefficient from a computational point of view and the new approaches that we proposed.",
            "It is a relatively simple.",
            "It requires a dedicated arguing, but it's not complicated as we will see and they can exploit the both current planning technology and also the structure of the planning program."
        ],
        [
            "OK, at the high level this is the algorithm is simple search in the program in the planning program an.",
            "Initially we have we have opened which is a list of state joint states that have to be processed and initially it's formed only by S0 and VO.",
            "We select a pair or joint status V from from open and we consider all the transitions outgoing from.",
            "The program state V. For each of these transitions.",
            "So we construct a plan pie which achieves the goal labeling the transition from state S. We updated the realization function and we progress the program and the worst date with possibly new joint state that is generated and we repeat this until we reach a fixed point in which are non you.",
            "There are no new joint states that have to be processed.",
            "Here it's important to .5 intact during the generation of the of the plane realizing a transition, we try to achieve a goal state, resulting state final state that has been already generated.",
            "So we there are some.",
            "We prefer spaces that we know already generated.",
            "This is becausw.",
            "It will reduce the number of joint states that are generated and so the open list will contain.",
            "Let's not have fewer and fewer joint states in that the resulting realization function will be more."
        ],
        [
            "Back or back.",
            "Very quickly our example.",
            "So this is the initial situation which we have acid awarding state SO and the program planning programming state, VO and we have two possible transitions that we have to realize.",
            "One is Golgi one and the other one."
        ],
        [
            "Goal Cheeto so we construct a plan from SO for these two goals."
        ],
        [
            "Also, and this produces 2 new joint states as one's view on S2V2 that are added to the list open and we continue selecting one of this one."
        ],
        [
            "Please and then we try to build a plan for the transition for a living."
        ],
        [
            "We want we go on.",
            "Let's see now when we do this, when we try to build, when we build a plan for GO.",
            "In state in state S2, we try to generate a plan which ends in a state or region already generated already considered, which is SO, but this is not possible, so we will."
        ],
        [
            "Generate a new state which work state which is S3 and so a new joint state that is added to the list open."
        ],
        [
            "Uh."
        ],
        [
            "While in if we continue, for example, in this case we try to construct a plan for GO starting from SO and preferring status is 0 and we can do that.",
            "So we sorry we preferring either's SO or as three and we can generate a final stated that is equal to S3.",
            "So we don't have to add anything to the list.",
            "Open."
        ],
        [
            "And so we can't."
        ],
        [
            "General until."
        ],
        [
            "We reached the iFixit point and the writers realization function is."
        ],
        [
            "I completed.",
            "And when we plan, of course we can fail, so we have to include in the in this algorithm form of backtracking.",
            "I will not explain this in detail because there is no name, not no time, and basically this is done by associating to the state states of the program planning program.",
            "Some taboo states that he states that are forbidden and that cannot be associated to this.",
            "Astata anymore.",
            "I will lift this."
        ],
        [
            "Questions in case there are some interesting.",
            "So the last part of the talk only two slides about the experiments.",
            "We have conducted.",
            "Some preliminary experiments are experiments are outgrowing the in this clean.",
            "This class of experiments we try to compare the new approach with the existing one.",
            "And here you can see that for a very simple domain like blocks work with only two blocks and the program structure forming a cycle.",
            "Just one cycle.",
            "We have an amazing gap in the imperfect."
        ],
        [
            "Almost another glass of experiments where where I'm testing the usefulness of prefer the States and.",
            "Also here we we proved that the use of preferences is very important for the approach, so in this life, for example we have results for again the blocks word with the number of blocks are ranging from 5 to 24 and a simple program structure for formed by.",
            "3A chain of three binary loops and as you see, the results are very strong for the for the new approach, that is much faster and solves more problems.",
            "Similar results have been obtained using other domains such as.",
            "Storage and Xeno travel in the other types of other structures of of."
        ],
        [
            "Programs, so conclusions we have proposed planning based method for realizing planning problems over deterministic domains.",
            "The approach is parametric with the planner.",
            "In our experiment we have used the LPG.",
            "But any other planar can be used is important that the planner can support directly or indirectly through a compilation.",
            "Soft goals because this give.",
            "Gives a stronger, much better performance and we have conducted starting my experiments which are not completed yet that show that the new approach is much faster than the original 1 and that the use of soft goals or preferred states is very important to have the approach to have an effective approach.",
            "Thank you.",
            "Looks like the problem is very actually algorithm and and the problem that you're dealing with, it's quite relative to the competition of what people called proper policies for M DPS.",
            "And there is actually an algorithm that those developers, some people.",
            "I don't recall exactly the names called NDP.",
            "I think by people Maryland OK that has exactly the same table lists and everything, so it may be worth 2 two.",
            "Relation between the two models.",
            "OK, because probably very similar algorithms can be used in both cases.",
            "Yeah, it would be great if this actually can be useful so far.",
            "Have the pizza I am not aware of this hardware so I will look at it.",
            "Thank you.",
            "Request OK well."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hey, good afternoon this is joint work with Fabio Petriti and Alessandro.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Safety planning programs have been recently introduced in the context of autonomous agents and multiagent systems by Digiacomo and his collaborators as a method to specify, at an eye level and the clarity of level, the behavior of one or more agents acting in a planning domain that can be specified.",
                    "label": 1
                },
                {
                    "sent": "For example, using a PDF.",
                    "label": 0
                },
                {
                    "sent": "Technically, planning program is a state transition system in which the transitions are labeled by goals that the agent can choose or ask to achieve, and this states represents decision points about what is the next goal or goals that the agent has to achieve.",
                    "label": 0
                },
                {
                    "sent": "Fundamental problem in this framework is realizing a planning problem which essentially.",
                    "label": 0
                },
                {
                    "sent": "Consist of a finding and combining a collection of plans I have for the transitions of the planning program so that the planning program is the executable.",
                    "label": 1
                },
                {
                    "sent": "They original approach for computing the realization of a planning program was proposed last year and is very powerful, but it's also very inefficient as we will show in the in this presentation.",
                    "label": 0
                },
                {
                    "sent": "In our work, we propose a simple approach, an alternative approach.",
                    "label": 0
                },
                {
                    "sent": "It is strongly based on planning technology and can exploit the current fast domain independent planners to solve the reality.",
                    "label": 0
                },
                {
                    "sent": "Alization problem much more quickly.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this talk, first I will briefly describe describe what are planning a program is and the problem of realizing a cleaning program.",
                    "label": 0
                },
                {
                    "sent": "Then I will present our algorithm for solving this problem.",
                    "label": 0
                },
                {
                    "sent": "Some experimental results and finally conclude.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Johnson in future.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work.",
                    "label": 0
                },
                {
                    "sent": "So essentially a planning problem can be described with this very simple example in which we have a Sailor representative that works for a company.",
                    "label": 0
                },
                {
                    "sent": "For example, in in New York and initially he is in New York and the customers are in in Boston or in Washington, saw on customer requestor yes to fly to Washington or Boston and when he's in Boston or in Washington he has to go back to his company.",
                    "label": 0
                },
                {
                    "sent": "Dear Sir, behavior can be described by this very simple planning program in which we have three States and for transitions that are labeled by the goals of the agent.",
                    "label": 0
                },
                {
                    "sent": "Here the agent is P1 and the seller Presentative is P1 and we have this this goals I will.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Come back to this example.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "More formally, planning problem is.",
                    "label": 1
                },
                {
                    "sent": "Is it finding this way so it's a very simple extension?",
                    "label": 0
                },
                {
                    "sent": "Well, it's a simple, very simple characterization.",
                    "label": 0
                },
                {
                    "sent": "We have given a planning domain that originally there could be deterministic or non deterministic.",
                    "label": 0
                },
                {
                    "sent": "In this work we focus on only on deterministic planning domains.",
                    "label": 0
                },
                {
                    "sent": "So given a set of domain propositional set of actions in the state of transition function that describes Scribe describes the plane domain.",
                    "label": 1
                },
                {
                    "sent": "We define a planning program as a couple.",
                    "label": 0
                },
                {
                    "sent": "Performed by a set of program states.",
                    "label": 1
                },
                {
                    "sent": "Keep an initial program state VOA set of possible goals over the domain propositions and program transition function that, given the state of the program and goal, gives another state of.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The program.",
                    "label": 0
                },
                {
                    "sent": "OK, so the definition of the problem realizing planning program is based on the notion of execution for a planning program during the execution of a planning program, we have that the domain the planning domain is always in a state and the the program is also in a state.",
                    "label": 0
                },
                {
                    "sent": "So this system is in a joint state as the initially.",
                    "label": 0
                },
                {
                    "sent": "The domain is in the initial status O.",
                    "label": 0
                },
                {
                    "sent": "And the programming the initial program state VO when the system is in a joint state to SV, the agent selects a transition from the planning program and if there is a transition leaving from from V and executes a plan that achieves the goal.",
                    "label": 1
                },
                {
                    "sent": "Labeling the transition from this state, the world state as.",
                    "label": 0
                },
                {
                    "sent": "This can generate a new joint state as primary prime, and then we iterate this this process so the execution can be infinite.",
                    "label": 0
                },
                {
                    "sent": "And realizing opinion problem consists of building a plan for every transition that can be selected during the execution of the training program.",
                    "label": 1
                },
                {
                    "sent": "Considering at the car rental ministate.",
                    "label": 0
                },
                {
                    "sent": "In this process it is possible to generate joint states which I have the same program stated, but the different states of the world.",
                    "label": 0
                },
                {
                    "sent": "This means that when I have to realize a transition that is build a plan for the goal labelling the transition, I might have to consider more than one plan becauses the agent could be in more than one.",
                    "label": 0
                },
                {
                    "sent": "State World state.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for right now we're very simple example of this.",
                    "label": 0
                },
                {
                    "sent": "A function is the realization function for for our problem for our domain, which is a very simple logistics domain in which the actions that in type of functions are only flying boarding in the barking, an initially the program state is in state VO and we have that the sales representatives in New York and their plan is in Boston.",
                    "label": 0
                },
                {
                    "sent": "So if the goal is to go to Boston, we have which is G2.",
                    "label": 0
                },
                {
                    "sent": "We have that we can construct the plan A1A2A3A four, and if this this plan will be executed, a new state will be generated and so on.",
                    "label": 0
                },
                {
                    "sent": "So this function is that what we the output or the solution of the realization problem for this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Training program.",
                    "label": 0
                },
                {
                    "sent": "OK, the notion of planning program realization can of course be defined formally through an inductive definition.",
                    "label": 0
                },
                {
                    "sent": "I will skip these details that are.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the paper.",
                    "label": 0
                },
                {
                    "sent": "There are two approaches as I mentioned for solving this problem.",
                    "label": 0
                },
                {
                    "sent": "The original project is based on the former synthesis in the context of linear temporal logic, and it's it has some advantages such as they can use available tools like TLV, and it's also easy to handle non deterministic domains.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, as I mentioned is very inefficient from a computational point of view and the new approaches that we proposed.",
                    "label": 0
                },
                {
                    "sent": "It is a relatively simple.",
                    "label": 0
                },
                {
                    "sent": "It requires a dedicated arguing, but it's not complicated as we will see and they can exploit the both current planning technology and also the structure of the planning program.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, at the high level this is the algorithm is simple search in the program in the planning program an.",
                    "label": 0
                },
                {
                    "sent": "Initially we have we have opened which is a list of state joint states that have to be processed and initially it's formed only by S0 and VO.",
                    "label": 0
                },
                {
                    "sent": "We select a pair or joint status V from from open and we consider all the transitions outgoing from.",
                    "label": 1
                },
                {
                    "sent": "The program state V. For each of these transitions.",
                    "label": 0
                },
                {
                    "sent": "So we construct a plan pie which achieves the goal labeling the transition from state S. We updated the realization function and we progress the program and the worst date with possibly new joint state that is generated and we repeat this until we reach a fixed point in which are non you.",
                    "label": 1
                },
                {
                    "sent": "There are no new joint states that have to be processed.",
                    "label": 0
                },
                {
                    "sent": "Here it's important to .5 intact during the generation of the of the plane realizing a transition, we try to achieve a goal state, resulting state final state that has been already generated.",
                    "label": 0
                },
                {
                    "sent": "So we there are some.",
                    "label": 0
                },
                {
                    "sent": "We prefer spaces that we know already generated.",
                    "label": 0
                },
                {
                    "sent": "This is becausw.",
                    "label": 0
                },
                {
                    "sent": "It will reduce the number of joint states that are generated and so the open list will contain.",
                    "label": 0
                },
                {
                    "sent": "Let's not have fewer and fewer joint states in that the resulting realization function will be more.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Back or back.",
                    "label": 0
                },
                {
                    "sent": "Very quickly our example.",
                    "label": 0
                },
                {
                    "sent": "So this is the initial situation which we have acid awarding state SO and the program planning programming state, VO and we have two possible transitions that we have to realize.",
                    "label": 0
                },
                {
                    "sent": "One is Golgi one and the other one.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Goal Cheeto so we construct a plan from SO for these two goals.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, and this produces 2 new joint states as one's view on S2V2 that are added to the list open and we continue selecting one of this one.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Please and then we try to build a plan for the transition for a living.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want we go on.",
                    "label": 0
                },
                {
                    "sent": "Let's see now when we do this, when we try to build, when we build a plan for GO.",
                    "label": 0
                },
                {
                    "sent": "In state in state S2, we try to generate a plan which ends in a state or region already generated already considered, which is SO, but this is not possible, so we will.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Generate a new state which work state which is S3 and so a new joint state that is added to the list open.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Uh.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "While in if we continue, for example, in this case we try to construct a plan for GO starting from SO and preferring status is 0 and we can do that.",
                    "label": 0
                },
                {
                    "sent": "So we sorry we preferring either's SO or as three and we can generate a final stated that is equal to S3.",
                    "label": 0
                },
                {
                    "sent": "So we don't have to add anything to the list.",
                    "label": 0
                },
                {
                    "sent": "Open.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we can't.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "General until.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We reached the iFixit point and the writers realization function is.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I completed.",
                    "label": 0
                },
                {
                    "sent": "And when we plan, of course we can fail, so we have to include in the in this algorithm form of backtracking.",
                    "label": 0
                },
                {
                    "sent": "I will not explain this in detail because there is no name, not no time, and basically this is done by associating to the state states of the program planning program.",
                    "label": 0
                },
                {
                    "sent": "Some taboo states that he states that are forbidden and that cannot be associated to this.",
                    "label": 0
                },
                {
                    "sent": "Astata anymore.",
                    "label": 0
                },
                {
                    "sent": "I will lift this.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Questions in case there are some interesting.",
                    "label": 0
                },
                {
                    "sent": "So the last part of the talk only two slides about the experiments.",
                    "label": 0
                },
                {
                    "sent": "We have conducted.",
                    "label": 0
                },
                {
                    "sent": "Some preliminary experiments are experiments are outgrowing the in this clean.",
                    "label": 0
                },
                {
                    "sent": "This class of experiments we try to compare the new approach with the existing one.",
                    "label": 0
                },
                {
                    "sent": "And here you can see that for a very simple domain like blocks work with only two blocks and the program structure forming a cycle.",
                    "label": 0
                },
                {
                    "sent": "Just one cycle.",
                    "label": 0
                },
                {
                    "sent": "We have an amazing gap in the imperfect.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Almost another glass of experiments where where I'm testing the usefulness of prefer the States and.",
                    "label": 0
                },
                {
                    "sent": "Also here we we proved that the use of preferences is very important for the approach, so in this life, for example we have results for again the blocks word with the number of blocks are ranging from 5 to 24 and a simple program structure for formed by.",
                    "label": 0
                },
                {
                    "sent": "3A chain of three binary loops and as you see, the results are very strong for the for the new approach, that is much faster and solves more problems.",
                    "label": 0
                },
                {
                    "sent": "Similar results have been obtained using other domains such as.",
                    "label": 0
                },
                {
                    "sent": "Storage and Xeno travel in the other types of other structures of of.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Programs, so conclusions we have proposed planning based method for realizing planning problems over deterministic domains.",
                    "label": 0
                },
                {
                    "sent": "The approach is parametric with the planner.",
                    "label": 0
                },
                {
                    "sent": "In our experiment we have used the LPG.",
                    "label": 0
                },
                {
                    "sent": "But any other planar can be used is important that the planner can support directly or indirectly through a compilation.",
                    "label": 0
                },
                {
                    "sent": "Soft goals because this give.",
                    "label": 0
                },
                {
                    "sent": "Gives a stronger, much better performance and we have conducted starting my experiments which are not completed yet that show that the new approach is much faster than the original 1 and that the use of soft goals or preferred states is very important to have the approach to have an effective approach.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Looks like the problem is very actually algorithm and and the problem that you're dealing with, it's quite relative to the competition of what people called proper policies for M DPS.",
                    "label": 0
                },
                {
                    "sent": "And there is actually an algorithm that those developers, some people.",
                    "label": 0
                },
                {
                    "sent": "I don't recall exactly the names called NDP.",
                    "label": 0
                },
                {
                    "sent": "I think by people Maryland OK that has exactly the same table lists and everything, so it may be worth 2 two.",
                    "label": 0
                },
                {
                    "sent": "Relation between the two models.",
                    "label": 0
                },
                {
                    "sent": "OK, because probably very similar algorithms can be used in both cases.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it would be great if this actually can be useful so far.",
                    "label": 0
                },
                {
                    "sent": "Have the pizza I am not aware of this hardware so I will look at it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Request OK well.",
                    "label": 0
                }
            ]
        }
    }
}