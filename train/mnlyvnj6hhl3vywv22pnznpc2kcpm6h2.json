{
    "id": "mnlyvnj6hhl3vywv22pnznpc2kcpm6h2",
    "title": "Link Mining",
    "info": {
        "author": [
            "Lise Getoor, Department of Computer Science, University of California Santa Cruz"
        ],
        "published": "Oct. 20, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/active09_getoor_lm/",
    "segmentation": [
        [
            "Please, we can we can make a sty.",
            "So we can afternoon of machine intelligence data mining.",
            "Our first speaker is another guest speaker.",
            "Please look at or where can I set correctly.",
            "Dutch name is it?",
            "No, it's actually.",
            "The last name is Armenian.",
            "Alright, but it got shortened, so that's just another script you could use.",
            "I see I mean it's OK. Usually it has Diana, then that's the at least the rule anyway.",
            "Ali says we University of Maryland, but she spends a lot of time also like like our previous speaker spends a lot of time in VR, has been spending a lot of time recently began working with Marco probably can his team at GSI.",
            "Yeah, and it's nice to be back in Slovenia.",
            "I was actually here for part of my sabbatical spring semester and I enjoyed it very much.",
            "And so it's it's nice to be back, and So what I'm going to be talking about is link mining and the way that I'm organizing the talk.",
            "It's supposed to be kind of a tutorial at a survey level.",
            "The first I don't know quarter or so is going to be a general introduction, and it's going to be a little bit more abstract and high level.",
            "And then I'm going to get into detail."
        ],
        [
            "Files on some particular link mining algorithms I won't go through all of them.",
            "And then do you conclusions.",
            "And just to get a little bit of a flavor of the audience, as Paul said, this afternoon is going to be this kind of machine learning data mining.",
            "Extravaganza, so how many people do have some background in machine learning and or data mining?",
            "OK, so I'm going to try and be general but it but do realize that I'm coming at it from kind of a machine learning centric approach.",
            "And as Michael said, so Michael had the disadvantage of talking at 4:00 AM.",
            "I think I've made it up to like 7:00 AM, so that's a little bit better, but it's after lunch, so those combined together so do definitely.",
            "If you have questions anywhere, let's make this as interactive as possible.",
            "And so.",
            "What do I mean by link mining?"
        ],
        [
            "Again, I'm kind of coming at it from the machine learning perspective that traditional machine learning approaches tended to assume that you had a kind of.",
            "A very nice random sample of homogeneous objects.",
            "All of the objects were of the same type, so coming from a single relation and then you would apply these very principled statistical inference techniques to learn a probability distribution, learn a classifier, and so on.",
            "So there's a rich tradition of work there.",
            "But the problem is real world datasets, especially the kinds of datasets that we're talking about in the active project, they just don't have that kind of uniform structure.",
            "You don't just have a set of papers, you know, as we saw in the talks this morning, you have different kinds of objects.",
            "You have different properties of objects, and you have relations between them.",
            "You know sometimes it's.",
            "Nice and structured in a database or in RDF or even better yet an owl.",
            "But oftentimes it's even worse than that.",
            "It's, you know.",
            "Semi structured or unstructured text and you need to deal with that.",
            "And so there's many many different areas that are trying to deal with this kind of mix of.",
            "Multi relational, heterogeneous data and some of them are very specific to the application that they're looking at.",
            "So if you look at hypertext classification that specifically looking at linked documents or things and social network analysis, so you're very much interested in people and their relationships.",
            "Who knows who and so on?",
            "Web mining.",
            "A number of other domains, but there's also starting to be a kind of general theory that's building up for kind of unifying some of the techniques from text mining, web mining, other kinds of things in graph mining, relational learning, inductive logic, programming, and umbrella of other kinds of terms.",
            "And what I'm going to try and do is I'm.",
            "Going to try and give you a sense of some of the algorithms and task involved in these.",
            "So first stop talking about the data.",
            "So I'm going to be."
        ],
        [
            "Pretty agnostic about this, but the general idea is that we have these kind of multi relational domains an I'm going to tend to use language that is assuming that I'm going to represent it as a graph and you know we saw lots of pictures of graphs in the previous talks.",
            "And I'm going to be a little bit agnostic about.",
            "You know what the exact syntactic form of that is, and I'm going to be talking about link mining as kind of mining these.",
            "Networks and grass, but realize that underneath it all you need some sort of representation that's powerful enough to capture the fact that there's.",
            "Different kinds of objects that the objects have attributes.",
            "Objects can have labels or classes associated with them.",
            "Edges while I'm going to show them as little binary edges, you know they could be.",
            "Hyper edges and so on, but the the notion is there's this rich structure here and so you know you can use.",
            "Underlying that is usually going to be some kind of logical representation to capture that.",
            "And so just to kind of rear reiterate, some of the kinds of domains so certainly or thinking about web data, so web data includes, obviously.",
            "Pages an links between pages."
        ],
        [
            "But it can also include things like weblogs, so you know the queries that someone made, the clicks that someone made on a page, and so on.",
            "Bibliographic data.",
            "So bibliographic data.",
            "Most of my examples where I have real data sets are going to be bibliographic domains, but that tends to be because that's the kind of datasets that are easy for academics to get their hands on an.",
            "Also, you know where academics so we can really relate to bibliographic domains.",
            "So a number of my examples will be bibliographic.",
            "Demands, but actually that's one of the things that I think is really interesting about the active project is the case studies.",
            "Are these kind of interesting multi relational datasets which I'm going to say more about in a minute?",
            "So social network analysis.",
            "So when we're talking about people, friends on Facebook, social media kinds of domains, epidemiological data.",
            "So people, you know what diseases are infected with the transmissions and so on is a kind of domain that a lot of these link mining task would be applicable for.",
            "Communication data so communication data, whether it's cell phone traffic.",
            "An or financial network kinds of data, whether it's email, communication, text, messaging, all of these things are things that can be described as a network where you have nodes are the people that are either sending or receiving the information, and you can view it as a network.",
            "So customer networks as well.",
            "So it could be the recommendation network.",
            "So a lot of the viral marketing kinds of things can be viewed.",
            "As setting.",
            "As the kind of multi relational heterogeneous data that we're talking about here, a lot of collaborative filtering or recommendation system.",
            "So you think of Amazon, you think of books and recommendations people make you think of restaurants and recommendations.",
            "People make other kind of product recommendations, trust networks, so you know that kind of thing where you're trying to, you know so and so, trust so and so well, does that mean that I?",
            "That's a kind of inference that I want to do that you know, if I trust someone then they trust someone else.",
            "Should I trust that person?",
            "Usually not.",
            "So you want to be able to do kind of these rich kinds of inferences about trust.",
            "Biological data this comes up all over the place needing to do link mining.",
            "There's a lot of work in protein, protein interaction networks, other kinds of biological data can be viewed as a network where you want to do some kind of link mining.",
            "And now I thought I was going to be the first one to assign homework.",
            "Since this is a summer school you guys have to have homework, right?",
            "But I think Michael already managed to assign a question.",
            "But so your guyses homework here is to come up with.",
            "Um?",
            "So weather.",
            "Some of that.",
            "Active specific.",
            "Problems.",
            "And so First off, just in terms of the active domains for the people that are in the project.",
            "I mean, what kinds of multi relational?",
            "Are different kinds of objects.",
            "Do you guys see?",
            "So someone had to be paying attention during Paul's intro.",
            "Keyboard company.",
            "People, companies.",
            "And the events.",
            "So what are the events?",
            "Uh huh.",
            "Anonym example.",
            "Organizations.",
            "Any other?",
            "Kinds of objects.",
            "Say again.",
            "Documents and the emails.",
            "Either you can think of the email as a document, or you can think of the email as a communication event.",
            "So part of The thing is, you know keeping track of that so.",
            "How did they do Paul?",
            "Do they leave out some major ones?",
            "Process is.",
            "Ice.",
            "Persons are eventually away, but yeah, so there's some interesting structure here between the events and the processes and the knowledge and so on, so.",
            "Keep thinking about this.",
            "Keep thinking about them in the context of active but also in the context and using context too many times.",
            "But in the context of other domains that do you guys work in?",
            "You know what are the different kinds of objects?",
            "And then as we go through this, we're going to talk about link mining task and I'd like you to think about kind of inferences that would be specific to these.",
            "Um, that fit with the.",
            "Examples that I'm going to go through, so I'm going to go over a collection of my link mining task and the key thing to note is I'm going to start off with things that are kind of so there's statistical info."
        ],
        [
            "So that's when I say inference or prediction.",
            "That's what I'm usually talking about.",
            "I'm going to start off with things that are kind of focused on nodes.",
            "In the network, and then I'm going to talk about things that are more talking about edges or relationships in the network, and then I'm going to kind of wrap up with some ones that are.",
            "Ann about collections of bigger collections of nodes and edges, and again at this point all I'm doing is kind of posing these at a very abstract level.",
            "A high level kind of description of the problem, and then I'll go into some specific algorithms for how you actually do these things.",
            "Let's start off with what I would say is the simplest one so.",
            "The simplest one is your starting offen."
        ],
        [
            "You have.",
            "You can think of it as you have this big, unlabeled graph and you're trying to put labels on the nodes in the graph.",
            "And so simple example would be predicting the category of a web page or the topic of a web page based on.",
            "And now here's a place where it starts changing because of the fact you're in this linked environment.",
            "It's based on, you know, attributes of the object itself.",
            "Are the node in the graph but also based on things that it links to attributes of things that it links to and so on.",
            "So you can kind of do this thing where you kind of crawl out the graph and get more information to help you do the inference of the label.",
            "So in the citation domain, so predicting the topic of the paper based on you know, of course, the words that appear on the paper but also based on you know the things that cites the things that are Co cited and so on.",
            "And, you know, in a biological domain predicting, say, the disease types based on characteristics of the patients infected by the disease, and so on.",
            "Um, so object classification is really you have some graph and you're trying to put some sort of label on the nodes and this is in contrast to traditional machine learning.",
            "There's an area called supervised classification where you go through and you put labels on objects and.",
            "The biggest thing here is we want to label not just a single object at a time, but this whole collection of objects and the objects are linked.",
            "And kind of as a sort of more of a subclass.",
            "Of this problem is object type prediction.",
            "So maybe it said you have this kind of heterogeneous graph where you have different kinds of."
        ],
        [
            "Objects, and so you're trying to figure out what.",
            "Kind of object.",
            "Each thing is and so this is really closely related to object classification.",
            "The only difference I would say is, for example, predicting the type of venue of a publication.",
            "You know the venue actually then has different attributes, so the actual structure of the object is different, so that's the place where it's a little bit kind of more complex than just putting a label on the node.",
            "It's like you're putting a label on the node and at the same time you're trying to figure out what kind of thing it is.",
            "So that you know what kind of attributes it has, so it makes sense.",
            "If I figured out it's a Journal publication, then I should go out and, you know, get the volume number and so on.",
            "But if it's a conference publication, then conference publications don't have those attributes, so it doesn't make sense for me to go look for them.",
            "Um?",
            "So those are some kind of object E node kind of inferences.",
            "You might want to make."
        ],
        [
            "There is very analogous kinds of inferences that you might want to make for the edges in the graph or the links in the graph.",
            "An one simple one is predicting kind of the flip side of object type classification.",
            "Predicting the type or purpose of a link.",
            "So suppose, for example, you have a web page, you have a link from one web page to another web page.",
            "So you know that link exists, but you're trying to figure out why does that link exist.",
            "So what kind of link is it?",
            "Is it an actual informational link or is it just a navigational link?",
            "Is it a spam link?",
            "So these are the.",
            "Kinds of things that you might want to do when you're trying to label the links in a network.",
            "Um, another one is there I said?"
        ],
        [
            "OK, I know that there's a link between these pages.",
            "What if instead what I'm trying to do is I'm trying to predict whether there is a link.",
            "So this is predicting the existence of a link.",
            "It turns out that that actually I'll say more about it, but this is a much harder problem than predicting the type of a link, and you can see where something like this could end up being useful.",
            "So if I had a model for predicting the existence of a link.",
            "And then I could use it to predict when something should link to something else.",
            "I predict there's a there should be a link in.",
            "There isn't a link there, then that could be something that I give to.",
            "A developer to help in the process or for a lot of the.",
            "Collaborative filtering domains.",
            "When you're trying to predict, you know who's would like this product.",
            "Who would like this book then?",
            "That can be formulated as a link existence kind of problem.",
            "Um, another thing that you might."
        ],
        [
            "Want to do with links is instead of actually predicting specific links between specific instances of objects.",
            "Instead be interested in predicting the number of links so it turns out as a statistical estimation problem, this actually can be easier, so if you know that you're actually in this situation, it's actually important to take that into account.",
            "And oftentimes this predicting then carnality, so the number of links serves as a surrogate for something like predicting the importance of something.",
            "So you know are the rank of something.",
            "So Page rank and so on have this flavor of kind of predicting how many in links something is going to have and because of the number of in links that.",
            "You know whatever that node represents, whether it's a person or paper or web page, is going to be a very influential.",
            "Um object and so this is essentially trying to estimate the degree of a node.",
            "Um?",
            "Another variant is."
        ],
        [
            "Where you're looking at larger.",
            "Longer path, so not just estimating the number of links into an object, but estimating the number of things that you'll reach through some sort of set of hops away from a node.",
            "And you could picture this as being useful for estimating the centrality of a node.",
            "The other thing that it's incredibly useful for is this is what's fundamental to any kind of database.",
            "Selectivity estimation where you're trying to figure out OK if I join together this relation with this relation.",
            "With this relation, you know how many objects do I expect to get back in order to do an efficient job of optimizing this, you need to have a good answer to this problem, so it may be that you're interested in this estimate for your.",
            "Data analysis, but it may be that you're interested in this question for your optimization, your algorithmic optimization as well.",
            "The so we had kind of basic node prediction kinds of."
        ],
        [
            "Things basic Edge link prediction kinds of things.",
            "The next thing is again about kind of nodes and links, but the specific link is the same as link, so predicting when two references to something are actually referring to the same underlying entity, so.",
            "You know I have Jay Smith and John Smith.",
            "String references.",
            "How do I figure out that those are referring to the same underlying individual?",
            "Or perhaps I have one John Smith in one place, another John Smith and another place, and they're actually referring to different individuals.",
            "This problem I will talk about in more detail further on in the presentation.",
            "Um?",
            "Another kind of."
        ],
        [
            "Prediction that includes both links and nodes is group detection, so trying to find communities.",
            "In a network and.",
            "There's a lot of methods that simply find communities based on the edges, so a lot of the spectral clustering algorithms are based on this.",
            "There's another collection of algorithms that do it based just on the attribute values, but being able to do something that combines both the kind of link structure together with the attributes when you're trying to find.",
            "Communities or tribes in these networks.",
            "Um?"
        ],
        [
            "Then a little bit more general than that is the whole notion of sub graph discovery, so finding common subgraphs that occur multiple places in the network.",
            "So this could be.",
            "Used for.",
            "The most common example is chemical substructure, drug discovery, and so on tends to have this flavor, but you could also think of the Community detection as a form of sub sub graph discovery.",
            "And then, um."
        ],
        [
            "Finally, you get to things that you know were mentioned this morning of being able to have two graphs where you actually need to do some sort of figuring out some alignment between them.",
            "Some sort of connections between them.",
            "So whether or not you're doing it at the most basic level of doing the entity resolution between them, you know when.",
            "Do two entities refer to the same thing, or kind of more complex?",
            "Schema mapping.",
            "Ontology alignment and so on or like some other work that my group is doing.",
            "Is this kind of folksonomy discovery so you have a bunch of little folksonomies and you're trying to glue them together and find some useful subcomponent that has a whole notion of alignment.",
            "And then in biology there are tons and tons of problems where you're trying to take these kind of biological graphs and then kind of line them up and find out the commonality is whether the commonality's are in terms of.",
            "The kind of mechanism the evolutionary mechanism, or whether it's more cross species kinds of comparisons.",
            "Um?",
            "So this is kind of my list of link mining tasks.",
            "It's not exclusive or exhaustive."
        ],
        [
            "Every time I give the talk, I end up adding a couple more.",
            "But this is meant to be kind of this high level abstract introduction to the kinds of statistical inferences you might want to do in networks.",
            "Um?",
            "And.",
            "Kind of to put with that.",
            "I would like to also say something about you know what makes these things hard?",
            "Or what are the common properties across all of these?",
            "Before I get into a specific one and say oh here's some algorithms for doing entity resolution, what kinds of problems come up in all of these?",
            "Um?",
            "Anne.",
            "These again are some of them and I'll go over them at a high level again.",
            "But the interesting thing, I think, is that I think these are.",
            "This is my opinion that these problems are.",
            "Our challenges are common no matter what formalism you end up using, so all the."
        ],
        [
            "The kinds of things that I'm going to talk about in some way combine statistical and logical information for their modeling and methods so you know there's been a lot of different things proposed Bayesian logic programs, conditional random fields, Markov logic, and so on, But the things that I'm going to talk about in the next 10 minutes are things that.",
            "All of these formalisms end up having to deal with and so the first one is kind of what I alluded to is that you you need to combine together in some way the fact that there's two kinds of dependencies going on, so one is this logical dependencies.",
            "So if A then B and so on.",
            "So how do I chain together things?",
            "How do I know if I'm in a graph?",
            "And I'm navigating links, you know it follow one to the other.",
            "How do I do that?",
            "How do I represent the ways of doing that?",
            "And then the other is a more kind of statistical dependence, so probabilistic dependence, you know correlations between attribute values.",
            "How do I?"
        ],
        [
            "Have a system that can talk about both of these in kind of a general way to support a lot of the problems.",
            "The AI problems AI challenges that.",
            "Michael raised in his talk, so, um.",
            "Let me show.",
            "One instance of this kind of general issue of combining logical and statistical dependence an this is.",
            "In the search over possible models.",
            "So this is an example that."
        ],
        [
            "I'm going to use in a couple of places, so it's just a really toy example where the peas are papers, so I have this paper P here, and that's suppose that's the one that I'm trying to figure out.",
            "What is the topic of this paper?",
            "And then I have some other papers sitting around.",
            "So I have P1P2 and P3.",
            "And then I have an author, so this a one say is author of.",
            "P1P2 and my?",
            "Paper, and, you know, maybe I have institution information associated with this author, so author One is at institution One.",
            "And so I could when I'm trying to predict the topic of.",
            "The paper I could use a model that just looks at other papers.",
            "And, um.",
            "In particular, other papers that cite this paper.",
            "And then I could build a statistical model over this.",
            "You know I'm being agnostic about what particular model you build.",
            "It could be a neural net.",
            "It could be decision tree, whatever flavor you want.",
            "But somehow I needed to know something about the logical structure of the domain so that I knew that papers that cite this paper are the ones that I should use.",
            "I shouldn't go and use arbitrary other papers, but the ones that cite this paper.",
            "Um and I might want to use information about the author, but again, I need to have the representation that tells me that you know getting to an author of a paper and then seeing if there's some statistical dependence on.",
            "You know, maybe the research area of the author and the topic of the paper, or how long they've been in the field, and that topic would make sense.",
            "Um?",
            "An I could go out longer chain so I could say, well the.",
            "The paper that cited the paper that cited this unknown one, so I could kind of grow these kind of attributes that I'm looking for dependence.",
            "Um?",
            "An I could then you know.",
            "Similarly do it for other kinds of objects.",
            "So go from the author of the paper to the Institute of the Author, Find some attribute of that and do this.",
            "But this whole thing of searching through the model space is something that you know in statistical machine learning you do feature selection, but normally you're given the set of features before hand.",
            "You don't actually kind of construct them on the fly using this.",
            "So the model search being informed by the underlying structure and the domain is something that's really important in these kinds of problems.",
            "Anne.",
            "And.",
            "When you're doing that."
        ],
        [
            "It turns out that in many cases the objects are connected not just to one object, so you don't have a functional relationship, but it's related to a set of objects and.",
            "Anne.",
            "Somehow, in most of the methods you need to construct a single feature from this set.",
            "That's going to then go into your statistical model an you know there's a couple of different common ones that are done.",
            "So if I go to.",
            "This setting.",
            "Anne, I'm"
        ],
        [
            "Again, predicting the paper here and suppose I'm going to say, well, I'm going to make this dependence depend on the topics of the papers that cite this paper.",
            "An I have two greens and one yellow.",
            "That site this an so the color space in this case is supposed to dinner at the topic of the paper well.",
            "One thing that I could do is I could look at that set an look at the most commonly occurring topic and then say, OK, you know.",
            "Since green occurs most often, I'm going to say that this one screen and there's a lot of different propagation models.",
            "It essentially boiled down to doing some flavor of this, whether it's a stochastic version or deterministic version of propagating the influence in this way.",
            "But the interesting thing from a machine learning perspective is, once I've done this, where it.",
            "Take the set and compute a single feature that I aggregate on and then I can go and I can apply it.",
            "In some setting that looks completely different, so I have different numbers of nodes and so on.",
            "But still, this notion of mode of the set of things that site me is well defined, so I can deal with kind of this varying kind of structure.",
            "I'm sorry, yeah.",
            "The translations, because you have the three green topics on the right from Jordan, right?",
            "Right, so the mode is really the majority label and so this is a simple majority label propagation algorithm.",
            "But it's doing it, or one way to think of it in a statistical inference algorithm, is it you're computing the mode of the neighbor and then propagating it too?",
            "That node but you could have a totally different method for doing the propagation, so it could be more of something which I'm calling a selection set up where again I have these neighbors.",
            "But somehow I figure out, you know, maybe through reputation or reasoning about trust, I figure out, Oh well, you know of all those papers.",
            "P1 is the most important one, so maybe P1 is."
        ],
        [
            "The most Seminole paper or P ones by the most famous author or something like that, but I instead of looking at the set an computing and aggregate, I'm going to look at the set an.",
            "Select a representative and then use that and then I could use it in the same way where I just copy the label, but it could be more complex.",
            "The inference doesn't have to be same label.",
            "So.",
            "There's kind of a."
        ],
        [
            "Similar thing that comes up with weather in my statistical model, my statistical probabilistic logical model.",
            "I'm trying to be agnostic to not pick out any one particular one.",
            "Whether I refer in the model to particular individuals or whether I refer to whole classes of individuals and let me try and make that more concrete so.",
            "The advantage of having it refer to specific individuals is.",
            "If the individual is really predictive, then I certainly want to make use of that so.",
            "Um?"
        ],
        [
            "In this case.",
            "Maybe P3 is you know such.",
            "Well known paper, or well known to be on a particular topic that I want to say.",
            "Any paper that cites P3.",
            "MP3 happens to be green.",
            "I likely to be green.",
            "So any customer that likes this particular movie.",
            "Yeah, Raiders of the Lost Ark.",
            "You know they are definitely going to like.",
            "You know all these other kinds of movies?",
            "Or an if you do that, then you know I would infer that all of these are likely to be green."
        ],
        [
            "Um?",
            "Or are you going to do something that's more general that's based on attributes of the object?",
            "So.",
            "Like the example that I was doing before, not talking about a particular paper, but talking about green papers.",
            "So papers that cite Green papers are likely to.",
            "B Green or people that like sci-fi movies are likely to not like.",
            "These do I make things that are?",
            "Do I have a model that kind of reasons at that level or at the more specific level?",
            "And the issue is Jake kind of skipped over.",
            "Is.",
            "You know you can get."
        ],
        [
            "Much more predictive models, if you're basing it on single instances, but they're much less general, so they're not going to apply in as many cases, so you have this tradeoff, and for example, if I learn a statistical model that's based on.",
            "Say.",
            "Publications in machine learning and how things go there an specific individuals there.",
            "Then I try and apply that in high energy finette physics.",
            "Then you know there's not even going to be any overlap in the people or overlapping the attributes, and that's going to be an issue, and it's interesting because a lot of this social network analysis algorithms are individual specific.",
            "And don't always generalize across attributes.",
            "Um?",
            "The other thing that I'm really going to be emphasizing later is the need for this collective nature."
        ],
        [
            "Of the inferences, so I infer labels on some nodes, and I need to propagate that information, and so there's not.",
            "So there's a dependence of what I label one node on what I label another node.",
            "And similarly."
        ],
        [
            "K for entity resolution.",
            "You know I don't make the entity resolution decisions about what refers to the same thing in dependently.",
            "I actually do the propagation, so there's this statistical inference and this kind of probabilistic propagation that's going on at the same time.",
            "There's potentially a logical inference happening based on the statistical conclusions that you're coming up with.",
            "Anne.",
            "Dealing with labeled and unlabeled data.",
            "This is something that is a kind of technical thing that.",
            "One worries about in machine learning."
        ],
        [
            "Doing a fair amount.",
            "An I'm actually I'll go into this in a little bit more detail later, and I have a slide that covers it, But the interesting thing is in one of these probabilistic logic frameworks, the issues with combining labeled and unlabeled to date data together and doing higher quality inferences is particularly interesting and useful, so you can.",
            "As a number of people have shown in different domains, get much more accurate inferences because of the fact that you have some labeled data where you know, say, the classes of the objects.",
            "You have some unlabeled data.",
            "I'm going to infer the labels for those things.",
            "Then I'm going to make use of those inferred labels to improve the accuracy on additional inferences.",
            "Um?",
            "For the link existence prediction, so one of the key issues here.",
            "Is when I'm trying to predict whether there exists a link between two nodes.",
            "The problem is, this is something that typically the prior probability of having a link is incredibly low, so it's usually .0002.",
            "An as anybody that is dealt with machine learning algorithms, when you have things that have such a biased distribution.",
            "That ends up introducing all kinds of complications, and you, not surprisingly, then, you can get a very accurate classifier that just said there's no links.",
            "So you know it will do very well in terms of accuracy, but it's probably not what you want.",
            "Oh.",
            "Actually, the somewhat surprising thing is we actually have had some success with building these models that explicitly model probabilities of existence of links for medium sized datasets, and to be honest, when we tried this, I thought it wasn't going to work at all, and so the fact that it sort of worked as good.",
            "But as you go to larger and larger datasets.",
            "This becomes completely infeasible, so there's a scale issue of whether or not you're explicitly modeling each pairwise.",
            "Edge existence as a different."
        ],
        [
            "Random variable if you do that for even a moderately sized data set, that's not going to scale, and so there's a lot of really interesting.",
            "Research issues in doing link prediction.",
            "And then the last one, kind of."
        ],
        [
            "Challenge that I'm going to mention is making what's called a.",
            "Closed world versus open world assumption.",
            "So in AI this is kind of the notion of do I know everything that exists in the world.",
            "Do I know all of the books in the world?",
            "Do I know all the people in the world?",
            "Most of the models technically rely on assumption.",
            "That does say I know all of them.",
            "Um, that's starting to change.",
            "I mean, there definitely are models that are doing more of an open world assumption, but especially for this statistical relational stuff, it still tends to make this because you have to make sure that your probability distributions, well defined, and to do that you need to makes it easy.",
            "If everything is finite, and so then you need to know the number and so on.",
            "So this is, I think, a really interesting challenge, and it's an interesting challenge that.",
            "I think comes up.",
            "In a lot of the.",
            "The problems that we were talking about this morning.",
            "So this is kind of."
        ],
        [
            "A summary of the task and the challenge is an.",
            "Again like I said in the intro.",
            "This is kind of that I'm trying to give an abstract overview of the general area.",
            "But let me pause here and see if anybody has some questions about what I've said so far.",
            "Prior probability.",
            "Yeah, because typically.",
            "If you do it in the naive way, it would scale as N ^2.",
            "And so.",
            "That maybe works for 100,000, but it definitely doesn't work, and even then it's pretty bad.",
            "So, so that's that's one of the big issues.",
            "If you're looking at each specific week.",
            "Not necessarily at the properties.",
            "Exactly exactly, so if you grounded out and look at each particular link, then in the naive way you'll get to this issue.",
            "When I get to, I'm going to talk about entity resolution.",
            "I'm going to talk about some of the methods that people do to get around that.",
            "Some of the basic methods for getting around it, but I still think that there's tons of interesting research issues there.",
            "Um?",
            "Other.",
            "Questions.",
            "Everybody's working on their homework right now, right?",
            "So you think of the.",
            "Active specific problems for all of these different things for doing object classification.",
            "Entity resolution and so on for domains that are describing the knowledge workers.",
            "'cause remember you have to send it to me.",
            "I need to put a due date on it.",
            "So what's the last talk on Sunday?",
            "Microsoft explains itself is talking later.",
            "OK, well I I won't have that do.",
            "I'll have it do before your talk so that they pay attention during your talk, because that's.",
            "OK, and you can email it to me.",
            "So get tour at cs.umd.edu if you Google Get tour you can find it written in a way that's more readable than that, OK?",
            "They told you you guys get grades at the end of this right?",
            "Complexity.",
            "So where you can do some sampling people sampling or see I mean do it like a way.",
            "Actually, yeah, an an.",
            "I'll talk about that, not in the context of link prediction, but doing some sort of.",
            "Various kinds of stochastic sampling are one way of doing the estimation.",
            "So yeah, yeah.",
            "So when I was saying the problems I was kind of posing it as like the most naive approach.",
            "Why the most naive approach isn't going to work well.",
            "But yeah, and that's usually sampling.",
            "Is 1 good way of getting around the complexity of doing inference?",
            "OK, so.",
            "I'm going to talk now."
        ],
        [
            "More in detail about collective object classification, entity Resolution, link prediction and I'll spend.",
            "The link prediction I won't spend as much time on, but I'll.",
            "Probably spend the most time on entity resolution just because that's the thing that my group has done a lot of work on and talk some about collective classification, because again, I think the collective classification."
        ],
        [
            "Is kind of the poster child link mining algorithm that you know it comes up in so many different guises.",
            "It's worth talking about.",
            "So the problem.",
            "So this is my cartoon kind of explanation of the problem so."
        ],
        [
            "Traditional machine learning classification.",
            "Statistical inference.",
            "First off, they tend to make a very strong assumption that you have.",
            "Training data the training data is completely separate from the test data.",
            "The training data is drawn by random sample.",
            "Independent.",
            "And.",
            "What you wanna do is you want to.",
            "Take this training data and here.",
            "The pinkish purple nodes are supposed to be the features, the attributes.",
            "And.",
            "I'm going to take these attributes and learn a predictive model for some output variable where here I've shown it as a blue node.",
            "And so it's going to be a conditional classifier that will tell me the probability of a particular value for Y.",
            "Particular label for a node given the attribute values, and again I'm going to be.",
            "I'm not agnostic as in terms of the functional form, but there's various statistical techniques that would do that, and so I do this on my training data.",
            "And then I take this thing that I estimated an I apply it to my test data and in the test data I should have shown this more.",
            "Clearly in the test data I don't.",
            "I'm not give her.",
            "I'll pretend like I just have the attribute values and I'll see how well this model does at predicting the Y value, and then I'll count.",
            "You know, how many did I get right?",
            "How many did I get wrong, or various other measures?",
            "So this is the kind of.",
            "You know classic view of machine learning, supervised learning, so any questions about the initial setup.",
            "OK, so this.",
            "Now we're going to complicate things.",
            "We're going to add in links.",
            "And."
        ],
        [
            "So.",
            "What does this do to the standard algorithm?",
            "Well, now the fact that I have links between the objects.",
            "Most often that's going to imply that there's a correlation.",
            "Um, the most common one is called auto correlation, so things that.",
            "Are linked.",
            "Are likely to have the same label now.",
            "This is the basis behind, you know many many forms of you know.",
            "Propagation in networks.",
            "You know we're friends, so we're likely to like the same music.",
            "We're friends, so we like the same restaurants, and I mean you can argue with these, whether they're correct or not, but there are tons of domains where this actually works surprisingly well, and so you can do something.",
            "Like the mode propagation or the majority neighbor propagation, and that works well.",
            "The interesting thing is the correlation.",
            "It could be.",
            "Because.",
            "So.",
            "If things are linked then they are likely to have the same label, but there's another variation, moffly, which is more.",
            "The still ends up introducing correlations the same way, but it says that, oh, there's more likely to be a link by the fact that.",
            "The values are the same, so.",
            "Either.",
            "Because I'm friends with someone, I'm likely to have similar taste or because we have similar taste, we're more likely to be friends.",
            "The causal, like what causes what is different, but the underlying statistical correlations are the same.",
            "So the same algorithms can work.",
            "It doesn't really matter, so it's only when you get to like marketing and viral marketing kinds of things and so on, where sometimes the causality is important so.",
            "This is the first change when you go from kind of vanilla statistical inference to inference in networks.",
            "You have these links.",
            "There's going to be correlations.",
            "You should be smart about them.",
            "Oftentimes the correlations are these kind of similar like I'm linked to similar things, but they don't have to be.",
            "It could be that you know.",
            "I linked to things of opposite type, so if you look in the.",
            "Like the web KB data set you know professors never linked to other professor pages they link to student pages, but they won't link to professor pages, so you can capture that in these kinds of models.",
            "It doesn't have to be as simple as correlations, so that's a kind of disassortative relationship potentially.",
            "Um?",
            "Other thing you wanna do when you go to?"
        ],
        [
            "Collective classification in link domains is deal with the fact that you may have irregular graph structure and that's kind of what I was getting to before with the computing the features, and I guess I'm going to actually repeat that.",
            "But you know now each of the things each of the objects I'm trying to classify could have different numbers of features.",
            "So how do I deal with that?",
            "And then the."
        ],
        [
            "Issue that I may actually have links that cross the training data and the test data and so the interesting thing about that is from a statistical inference perspective.",
            "It's like this is a big no no.",
            "It's like they're supposed to be completely separate.",
            "They're supposed to be independent, and you know some of the early work.",
            "It would drop the links if there were links because they didn't want to violate this assumption and or work really hard to make sure that there were no length.",
            "But the reality is that those links convey a lot of information, so if you can manage to have a statistical model that correctly makes use of the links between the training set and the test set, I mean you should do it because you're going to get the best information possible, and this is kind of this is a broad area in machine learning, so even transductive inference is kind of exploiting this fact, but it's something important to think about.",
            "Um, so the general problem and relational classification is just that you want to."
        ],
        [
            "Predict as I said before, the label of an object based on attributes of the object but also attributes in.",
            "The links to the object and the things that are linked to the object into things that are linked to the link.",
            "Things that are linked and so on.",
            "Um?",
            "And then collective classification.",
            "Is the notion of kind of propagating these things so that these things depend on each other and there's been a lot of work in recent years on this.",
            "And, you know, here's a list of some of the people I'm sure this isn't completely exhaustive, but some of the people looking at it in kind of this general framework of combining probabilistic and logical inference for doing this.",
            "Um?",
            "Again, this is the same example as before trying to highlight the multi."
        ],
        [
            "Relational aspect of this example.",
            "The papers and authors and institutes.",
            "And now let me something that I didn't emphasize before is.",
            "The different kinds of links you can have, so we talked about citation links.",
            "But once you have citation links, you can kind of start constructing other kinds of links that are often useful.",
            "For example, Co citation.",
            "The fact that.",
            "Which one?",
            "The P3 sites, both P1 and P4.",
            "It turns out that Co citation is actually a very useful relation to make use of in doing prediction of topics in bibliographic domains.",
            "It's actually more useful than the sites relation or the cited relation.",
            "So in order to do it, you actually have to infer it from 2 links.",
            "Um?",
            "Ann again you can have author of an affiliation and then in the example that I'm I'm going to continue using this example, but I changed the colors so that in this example I'm saying there's three different possible topics for the papers and the labels are.",
            "Light pink darker pink or purple and blue.",
            "So I have those three possible labels."
        ],
        [
            "And specifically, in terms of feature construction for collective classification.",
            "There's a number of works and a number of theses on this so.",
            "Sasha Popescu with Lyle Anger did his thesis on feature construction for these kinds of models and also Claudia Perlick any of this standard things like."
        ],
        [
            "Count Min, Max.",
            "Actually something that we've used.",
            "Is the proportion of neighbors that have different labels.",
            "That exists, and then, as I said before, you could have a way of selecting the nodes.",
            "Anne.",
            "And again we."
        ],
        [
            "This issue of.",
            "Instances versus generics or classes.",
            "So.",
            "Of some of the.",
            "Existing"
        ],
        [
            "Work out there in this space.",
            "You this is to give you a little bit of the sense of the kinds of features that people use so.",
            "Mode is definitely one of the most commonly used one.",
            "Um?",
            "Using Arbitrary 1st order logic, you know there has been some work that does feature constructed construction using this, but I would say that is a place where the surface has been barely scratched in terms of doing that, and even SQL.",
            "You know there's some work that did that.",
            "But I.",
            "For now, people have been sticking with these kind of simpler features.",
            "So this is a space that I think is wide open.",
            "Doing this in a kind of principled, more principled way.",
            "SQL is a database query language, so being able to specify features using just SQL 1st order logic fols is first order logic, so they're much more expressive ways of constructing features than just doing something like.",
            "You know mode or most common label.",
            "Tables pictures of the.",
            "Yeah, sorry I'm I'm condensing that a fair amount so the assumption is using SQL you're actually constructing arbitrary database queries over the tables that can have joins and selects an group buys and so on to construct features that will go into a classifier.",
            "And to be honest, the thing that is interesting about this is right now machine learning algorithms you have to do so much feature engineering before hand.",
            "But that's all outside of the kind of theory.",
            "But it's really where we spend all our time so.",
            "At least making the feature construction more declarative so the algorithm could search over the feature space a little bit more I think is hugely important.",
            "Uh.",
            "And actually, we're trying to make some steps towards doing that in these kinds of algorithms.",
            "But at this point it's still more of a black art.",
            "It's more like OK. Maybe I'll join table so I'll do.",
            "Neighbor of neighbor of and so on.",
            "That's something you can do automatically, but if you start having you know owl representation and then using the owl representation for constructing features.",
            "Um, OK, so these are about the features, but now about the different formulations.",
            "I'm gonna give you kind of a.",
            "10,000."
        ],
        [
            "Foot level view of the different algorithms, so the different algorithms tend to fall into.",
            "Two camps which I'm gonna call and realize that I'm making up the terminology for this.",
            "Local models and global models, so a local model is some collection of.",
            "Classifiers that can kind of propagate information and they do it in different ways.",
            "They tend to have kind of the.",
            "The notion which maybe has already been built in, and some of my description that.",
            "You have more of a directed model, so it's conditioned on the features I'm going to predict the label versus global models tend to be full probability distributions over all of the labels in the graph, and all of the attributes.",
            "Now.",
            "The most common one used by far is a pairwise Markov random field or other form of Markov random field, but there's other ones.",
            "The key thing that makes it global is the fact that you have this full probability distribution.",
            "Once you have a full probability distribution.",
            "That gives you nice things you can fill in the missing values for attributes and do proper probabilistic reasoning.",
            "It also has some drawbacks.",
            "There is a lot of work showing that in many cases the more what's called discriminative algorithms.",
            "The local models can be more accurate, which kind of makes sense.",
            "So there's this tradeoff and.",
            "Just again to get you give you a sense of the different kinds of algorithms that people have used."
        ],
        [
            "So of the main ones there's mean field, which is the kind of simplest.",
            "Anne."
        ],
        [
            "Mean field relaxation labeling?",
            "That's kind of a really simple global model loopy belief propagation.",
            "An is a more general method.",
            "There's.",
            "Something which I will go into more detail, iterative classification algorithm, ICA and Gibbs sampling.",
            "So Gibbs sampling is a very general method.",
            "So it actually you can use Gibbs sampling when you have local models or global models but.",
            "This gives you a say."
        ],
        [
            "Once you know everybody is using different algorithms, initially nobody was comparing algorithms, at least.",
            "Finally, some people at the bottom are doing more than one and comparing them.",
            "And to get into a little bit more detail of ICA.",
            "So this is kind of collection of local classifier."
        ],
        [
            "The different local classifiers people use include.",
            "I. NB which is naive Bayes, LR is logistic regression.",
            "DT is decision she is.",
            "KNN is key.",
            "Nearest neighbors an this WVRN is weighted nearest neighbors.",
            "So that's the one that is take the majority label of your neighbors and propagated.",
            "So again, this shows it a lot of people are using Naive Bayes.",
            "An naive Bayes is actually doesn't make our at least our experiences that logistic regression works way better than Naive Bayes, and it makes sense.",
            "You have bunch of conditional models.",
            "Naive Bayes is a generative model, full probabilistic generative model.",
            "It might not be the best thing, but it's nice because it's easy and it is.",
            "Kind of more complex than just doing the majority neighbor so this.",
            "All of the ones besides the weighted vote.",
            "Um neighbor.",
            "Do allow you to learn arbitrary dependencies so it doesn't have to be that you know Green label is likely to be next to a green label.",
            "It could be a green labels likely to be next to a red label, and so on, and you know it will use the training set to figure that out.",
            "Um, but let me try and give you a little bit more sense of."
        ],
        [
            "The ICA.",
            "The idea is.",
            "So this is the iterative collective.",
            "Um?",
            "Approach to doing the node labeling so the idea is you start up somebody gives you a fully labeled data set from this fully labeled data set, fully labeled training set.",
            "I'm going to learn local classifier now.",
            "When I'm doing it."
        ],
        [
            "In France, this is on my test graph where I don't have any labels.",
            "I'm actually going to make use of two classifiers that I learned from the training data.",
            "I'm going to learn one classifier that only used the information from the object.",
            "So I'm going to take that and bootstrap the labeling of these using just that information.",
            "So if it's papers I'm going to just use the words that appeared in the paper to predict the labels for the nodes.",
            "And from that I'm going to get this initial assignment.",
            "Of topics.",
            "And now once I have those, then I'm going to take the second classifier that I learned or the second classifier uses the objects, the attributes of the objects, but then also the neighbor information, the labels of the neighbors.",
            "And then I'm going to iteratively now update the labels.",
            "So.",
            "I know there's variations on this, but this is the most vanilla version that I start."
        ],
        [
            "If I do a bootstrap labeling just based on local information or the attributes, then I start doing this propagation where the propagation kind of looks at the in Ferd labels.",
            "And keeps iterating.",
            "And then you know.",
            "The question is, you know it was nice and my animation, it converged after 2 iterations so.",
            "Figuring out when you've reached convergence, whether you can prove anything about whether you reach convergence, all of those are somewhat open questions, so.",
            "I can say a little bit more about it in practice in a second.",
            "Um and so.",
            "OK, so just to give you a sense of some comparison.",
            "I'm."
        ],
        [
            "Going to compare.",
            "Actually, I think I have all four of them on the next slide of the different algorithms.",
            "I only really told you in detail about the ICA algorithm.",
            "She collections or two setups.",
            "One is unreal data, which is again like I said, we're academics, it's bibliographic data.",
            "So Cora and sites here are two different computer science citation collections that have topics and then web KB.",
            "So a lot of people here know and love web KB, but it's a data set that was constructed at CMU.",
            "Probably a 98, so it's a small data set of web pages that are labeled according to whether or not the web page is.",
            "Student web page.",
            "Professor webpage.",
            "At course.",
            "Web page.",
            "Um project page.",
            "There were like 5.",
            "To 7 labels on this.",
            "And then."
        ],
        [
            "So on synthetic data.",
            "So the interesting thing.",
            "Is.",
            "We have our different algorithms and our different datasets.",
            "And unfortunately, and this is accuracy, no.",
            "Actually this is F1.",
            "Sorry, which is a measure that combines together the that summarizes the performance.",
            "So.",
            "We see that.",
            "Unfortunately, there's no clear winner, so one data set.",
            "One algorithm works better, another data set, another algorithm works better.",
            "An actually if you want more details about the algorithms.",
            "I didn't go over this AI Magazine article does describe have the code and the formulas for the different algorithms.",
            "But one thing that I should note is.",
            "You know when we were doing these algorithms, um?",
            "The probabilistic algorithm there there was.",
            "There tended to be much more issues with convergence, so like if you had the right parameter settings and the right.",
            "Regularization parameter and so on.",
            "Then you could get it to work, but then half the time it won't work versus ICA in general you know it.",
            "It's a little bit less theoretically motivated, but it tends to be something that you know.",
            "Wood.",
            "Yeah you could.",
            "It would converge after 5 or 10 iterations.",
            "It wasn't as sensitive to the various parameter settings an, so we were really interested to try, and you know how do you characterize like win, which to use which algorithm?",
            "And unfortunately I would have to say we still don't have a really clear answer, but here's some result."
        ],
        [
            "So this is on synthetic data an it's synthetic data, or it's a very simple setup where we are assuming that there is this kind of auto correlation among labels and then we're varying the underlying.",
            "Link density, so how many edges are the degree of each node?",
            "And you see, in low density networks, the clear winner is loopy belief propagation.",
            "So when you have a.",
            "Relatively sparse network, loopy belief propagation works fine.",
            "And then as you go to more and more dense networks, it actually completely.",
            "Bombs out and.",
            "In that case you get.",
            "A better performance by ICA, an Gibbs sampling.",
            "The line that goes a cross is the one that is just using the content information, so it's not making use of the link information, so you see also that in general.",
            "Using link information helps, which is good.",
            "Otherwise I want to spent half an hour telling you about all this, but then it even can get to the point if it's bad enough that the link information can actually do worse than just using the local information attribute information and that actually is something as a research question is really interesting to figure out.",
            "It's like when should you go through the complexity of doing the relational graph stuff versus when should you just.",
            "And do the original thing, and that's something we're very interested in.",
            "Investing.",
            "For the accuracy.",
            "Um?",
            "It's a probability of there being a link.",
            "For most graphs.",
            "Ugly spots for nothing, then looking with propagation would be best or not.",
            "Um?",
            "It's all notes with notes.",
            "Yeah, um, actually I should check that that that I'm telling you the right thing about the that because that probably isn't right because I know I think.",
            "First off, you're correct that most networks are sparse.",
            "But for.",
            "Um?",
            "At least most real world social networks and so on are sparse.",
            "But there definitely are real world settings where the loopy belief propagation was giving us problems.",
            "Zero mean.",
            "I know Lindsey Tolan within the first point on each graph it should, but I think that that is actually off because if it was then they should all do exactly the same as the content only.",
            "Yeah.",
            "Why we add more information?",
            "Actually, For more information or training data, while the performance goal, Green shouldn't be so bad.",
            "I can imagine maybe a small you know decreasing internal performance, but I really understand why you can.",
            "Well, part part of it is because I haven't really explained to you loopy belief propagation algorithm, but loopy belief propagation is known not to work very well in dense graphs.",
            "Um, so it's it's something.",
            "I mean, notice it's not happening with the ICA algorithm that I told you about, so it is something special about the way that probabilities are propagated.",
            "An loopy belief propagation and basically you end up compounding errors as you get to the dense things.",
            "An I mean to be honest, it's a huge area of research.",
            "Convergence of these general belief propagation algorithms, and you know we're using a relatively vanilla.",
            "One here.",
            "The local malformed better with more data.",
            "So you have more leaf density.",
            "You have more local networks.",
            "Yeah, I mean that makes a lot of sense, and I think that.",
            "That is exactly the kind of spirit of the kinds of questions that we'd like to be able to answer more.",
            "Precisely because being able to say you know when to just use the local information versus when by using the global information it's a bad idea because you already had a good local model versus when your local model is so sparse.",
            "Or so you know, error ridden that so using this global information helps is exactly the spirit of these.",
            "But validation.",
            "Excuse me any other.",
            "I mean, I'm guessing you know cross validation would be the obvious way to check that.",
            "I can't think of anything else that will guarantee you somehow local model is good enough, because if you look at the real data set in the back previous light.",
            "All this is getting 3% more which is not worth it.",
            "Five years of research.",
            "Percent.",
            "How would you know what kind of things would you be using?",
            "Think about.",
            "Even the content is good enough.",
            "So, um.",
            "We've thought about that problem more in the context of entity resolution, so I can say something about that.",
            "So it is being able to have some estimate of the inherent.",
            "Underlying characteristics of the data set in terms of how ambiguous it is at a local level versus how much the relational information helps.",
            "I do think that you know these real datasets.",
            "You know, I've been."
        ],
        [
            "Saying their heterogeneous, they're not that heterogeneous, so doing this on real heterogeneous multi relational networks would be much more interesting and have a lot more questions.",
            "But to be honest, I've actually been trying to find the."
        ],
        [
            "Right kind of statistician to ask the question about how would I do a better job of theoretically analyzing this.",
            "But, you know, we tend to speak such different languages that, so far I haven't found the right one.",
            "That 'cause I think there is some interesting statistical theory that should be applicable, but I think.",
            "I don't know the right name for it yet.",
            "Anne.",
            "OK so um."
        ],
        [
            "The next problem that I want to talk about is entity resolution.",
            "And let me first stop."
        ],
        [
            "Scribe the problem, so let me motivate it by an."
        ],
        [
            "Actual real world data set.",
            "So this is a data set.",
            "Co author data set where the nodes are the authors and there's a link between the authors if they coauthored a paper together and the interesting thing about this data set, it was supposedly extensively hand cleaned.",
            "An it was used for an Infovis challenge in 2004, so but if you start looking at the data.",
            "A little bit, even though supposedly it was extensively hand cleaned.",
            "You start saying that there's some kind of serious problems with the data set.",
            "So maybe visualizing it before doing this data cleaning as an issue.",
            "So the problem is the original data set looked like this after you do the correct entity resolution.",
            "So you get this.",
            "An the problem with this for data analysis and network analysis is anything that any statistic that I computed on this original network is going to be wrong.",
            "I mean, First off, it's obvious there's a wrong number of nodes, there's around agree there is wrong connectivity, but if I look at it, it's kind of like.",
            "Oh, here's a big spaghetti mess versus here.",
            "There's a night tight collaboration structure, so one of the things that I want to emphasize is when you're doing.",
            "Analysis of graph data network data.",
            "You really want to do entity resolution before you do anything else, because if you don't, you're not getting the right answers.",
            "Um?",
            "And so entity resolution is a problem."
        ],
        [
            "Can be seen as this notion that I started off with some collection of.",
            "References and strings that are in my database.",
            "So Jonathan Smith, John Smith and so on.",
            "And then my problem is to take these strings or mentions.",
            "And.",
            "Figure out who the underlying entities are so that I can do, for example, the mapping from the strings to these entities.",
            "So I need to solve both an identification problem where I figure out that, oh, there's this guy, James Smith.",
            "And these are the strings.",
            "These are the aliases for James Smith.",
            "And then also the disambiguation.",
            "So I need to be able to figure out that if I have a J. Smith in one place, it's referring to this one entity John Smith and another place I have the string that looks exactly the same, but it's referring to this other guy.",
            "Um?",
            "And so typically this can be set up as kind of a pairwise classification prob."
        ],
        [
            "Where I'm going to show a little part of the problem where I take each reference?",
            "In my database and I cross it with all the other references.",
            "I compute some similarity between them.",
            "And then I say OK, if the similarities above this threshold, I'll say they're the same.",
            "And if it's below this threshold, I'll say they're different an the similarity.",
            "I mean there's lots of string similarities you could use.",
            "You could use more domain knowledge for constructing the similarity function, But the interesting thing is, once you've set it up as this attribute based decision problem.",
            "You're always going to come up with these issues.",
            "Well, actually, the first one happens no matter what you do, so you have to set a threshold.",
            "And based on this threshold, you're going to be choosing where you are in the precision recall tradeoff.",
            "But clearly in this setup.",
            "In one case I've tried to show these by colors from the previous slide where I had the two J. Smith.",
            "In one case, J. Smith and James Smith are supposed to be the same person.",
            "In another case, Jay Smith and James Smith are supposed to be different people, and there's no way that you can capture this with just a single threshold.",
            "So there's going to be this inability to do the disambiguation to figure out in one case, for the same pair you're supposed to say different things.",
            "And we're going to show how context basically is this thing that helps you do this.",
            "And then there's this issue of if you've done this pairwise thing, should you perform transitive closure?",
            "Well, kind of.",
            "Theoretically you should, but as I'll show in some experimental results, sometimes this is a good thing to do.",
            "Sometimes it's a bad thing to do.",
            "Um, so instead, you know?"
        ],
        [
            "Because the focus of this kind of tutorial is all about using the graph structure, we're going to show how you can use the graph structure to help with this.",
            "And the key thing."
        ],
        [
            "Is those references don't occur in isolation, they often they almost always Co occur in this Co occurrence information can be something that really helps you with doing the identification and disambiguation an you know the one that I'm going to be using for all these examples is the coauthor relation, but you see this in communication on two lists, easylist on emails and so on.",
            "That information helps you with doing the disambiguation.",
            "Um Ann.",
            "Again, this is an area where there's a lot of people doing work.",
            "You know it's an incredibly important problem.",
            "It happens all over in computer science.",
            "It happens for, you know, this intelligent information.",
            "Analysis, But it happens in computer vision, natural language processing, and a lot of other places.",
            "Um, and just to kind of make this more concrete.",
            "So he."
        ],
        [
            "Here I'm showing the example from before and the square nodes are the nodes that I'm trying to resolve, so I'm trying to figure out, do those square nodes refer to the same underlying individual or not, and then the way that I drew this graph is.",
            "I showed the common coauthors in the center.",
            "And the distinct coauthors on the sides.",
            "And in this case there are similar names, so if I do edit distance or any fans here string similarity, they look pretty much the same there's.",
            "Some shared Co authors and it turns out in fact these do refer to the same underlying it."
        ],
        [
            "Dividual here's another case where the string similarity again is 1 character difference essentially.",
            "But you quickly see you know there's no overlap in Co author, and in fact you know these turn out to be distinct, so this is information that can help you with doing the identification and disambiguation, but it starts getting more interesting when you use additional information.",
            "So first staff.",
            "If I ever see a link like this or I have a link between two things that I'm trying to resolve, at least in."
        ],
        [
            "The context of Co authors.",
            "In this case it would be a case where I wouldn't want to resolve them because someone can't be their own coauthor.",
            "So, um.",
            "In other demands this this won't necessarily hold, but you can use the fact that Co authors are typically distinct or the example from before that parents and.",
            "Children are distinct, or that's not exactly it, but.",
            "But still further the.",
            "Chal"
        ],
        [
            "Active part of all this is the fact that you actually want to be able to.",
            "Once I figured out that, say these two Elmendorf references are the same.",
            "So I figured out that they refer to the same underlying individual.",
            "Then that gives me additional evidence to infer that the singer references are the same, and so that's very much the thing that I want to do is no longer do this pairwise independent decisions about the resolutions, but.",
            "As I resolved, one thing had that propagate for resolving other things.",
            "Um?",
            "And.",
            "In the results I'm going to compare an algorithm that just does."
        ],
        [
            "The what I'm going to call naive relational entity resolution that just treats.",
            "Now the Co authors say as attributes with something that does this.",
            "You know somewhat more sophisticated collective entity resolution to see if it really makes a difference."
        ],
        [
            "Um and then?",
            "Let me talk about a couple algorithms for doing this.",
            "I actually will probably just.",
            "So it's 3:45.",
            "OK, so then I'll just talk about one.",
            "So.",
            "Let me again kind of illustrate it more by."
        ],
        [
            "Tune then.",
            "At least initially.",
            "So here's a collection of papers that are from sites here and I'm going to focus in on the Johnson References Co.",
            "Author references, and it turns out that in fact, looking at this date."
        ],
        [
            "Is that they really are two different Johnson researchers, one of 'em in the UK and the other in the US, and you know.",
            "These are distinct.",
            "Both are quite well known.",
            "So I'm gonna start off with kind of the simplest, most intuitive algorithm for doing relational entity resolution and what we do is we start oph an initial."
        ],
        [
            "The.",
            "All of these references are distinct, and I'm going to start merging them together when I figure out they refer to the same underlying entity.",
            "Now I do want to touch on this issue of how do I get this to scale because?",
            "I don't want to do all N cross N comparisons of the references, so.",
            "All of the algorithms for doing entity resolution, whether they are pair.",
            "My is attribute based or relational.",
            "Start off with a quick step of doing a binning of the references according to which references might be the same.",
            "Versus which ones are definitely distinct an this is usually use some sort of hash function.",
            "There's been some, there's been a some work, but I think more could be done about doing this, and I tried to indicate the initial binning by colors on these slides so all the things.",
            "Initially they're all distinct, but things that are the same shade.",
            "Like the Reds and Blues, those are in the same bucket, so those I will consider deciding to merge or not versus things that already start off being indistinct buckets like the a hoe and the Johnson.",
            "Those I've already decided they're two different, there isn't.",
            "Not the same.",
            "Um?",
            "And so this is something that helps to make these entity resolution algorithms scale.",
            "Something similar is appropriate for link prediction and general.",
            "So as a first step.",
            "Say I look based at, you know initially.",
            "Just the attribute information and I say OK these guys."
        ],
        [
            "R. Similar enough, I'm going to merge them.",
            "I figured out that these mentions refer to the same entity now.",
            "At this point I have some relational information, so when I look at.",
            "That this references, I say OK, well before you know maybe the names were so common I didn't want to merge them, but now they're very similar names.",
            "They have one coauthor in common.",
            "That's enough that all."
        ],
        [
            "Urge them.",
            "Now for the Johnsons for the Johnsons, I didn't merge them.",
            "Based on just one coauthor in common, but now I have.",
            "In one case, 3 coauthors in common.",
            "In another case, two coauthors in common, so at this point."
        ],
        [
            "I'm going to say, OK, yeah, they do refer to the same entity, and then I finally will.",
            "I will still do this comparison of the two Johnson.",
            "Entities, but because they don't share any coauthors, then I won't merge them.",
            "Um, so you can.",
            "One way of kind of understanding this kind of relational clustering."
        ],
        [
            "Is you can view it as comparing different ways of clustering.",
            "The reference is an.",
            "In one case you can look at kind of the similarity of the names in each cluster and the.",
            "Clustering.",
            "Over here is good because you know the similarity of the names is all very good like, especially if you look at this cluster versus this cluster.",
            "Um but.",
            "And this cluster now links to two different clusters versus in this clustering it links to only one.",
            "So we want to do this kind of trade off of.",
            "How similar the attributes are versus how similar the relations are or what you're linked to is an kind of put this into general hierarchical agglomerative clustering algorithm.",
            "Anne.",
            "And so the objective function."
        ],
        [
            "You can formulate it a bunch of different ways, this is.",
            "As the simplest way where we're just doing a linear combination of the similarity of the attribute values and the similarity of the relation neighborhood, and then we'll do a greedy clustering algorithm.",
            "Basically, look at the difference in this function.",
            "Find the two clusters that are closest together, merge them.",
            "Update similarity and continue.",
            "So."
        ],
        [
            "For the attribute similarity.",
            "This wasn't really the focus of our research so much, but a lot of people have studied this, and there's actually a very good.",
            "Open source implementation of many of the string similarities.",
            "Dad, William County has done and we used that where it has implementations of soft TF IDF.",
            "Liechtenstein Jaro, Jaro, Winkler and a number of other kind of standard string similarity measures.",
            "And then.",
            "If you have.",
            "So strings is the most common thing that you're using, but sometimes you also have attribute information.",
            "You can combine that in as well, and then when you're doing clustering, there is again a number of different ways you can combine things.",
            "Whether you do single link, average link or complete link.",
            "Anne, I'm going."
        ],
        [
            "Skip over these now."
        ],
        [
            "Now there's the relational."
        ],
        [
            "Similarity, so we compare the attributes.",
            "Now we need to look at how.",
            "Similar are the in this domain.",
            "The Co authors of the references and notice that that's actually a multiset, so I have two multisets that I'm trying to compare.",
            "And you could consider the neighborhood directly as a multi set and do the matching across a multi set and so on.",
            "Fortunately that's really expensive.",
            "We thought it was the right thing to do when we first did it it actually.",
            "You don't have to do that, you can just collapse the multi set on to a set and.",
            "Do any of the standard set similarity measures, like counting the number of common neighbors or more commonly used jaccard's coefficient, where you normalize by the size of the Union?",
            "We also tried doing things like higher order similarity like neighbors of Neighbors and at least for the problems we looked at that actually didn't help things.",
            "And so their relational clustering algorithm just is the same as.",
            "Uh."
        ],
        [
            "Regular hierarchical clustering except for we have this first step of doing the blocking which is doing the binning and then the other thing that's different is when I do the merge.",
            "I actually have to update the similarity of anything that is linked to these things and that is a subtle difference between that an other clustering algorithms.",
            "So you just have to be efficient about being able to look up which things you have to update the similarity for."
        ],
        [
            "So we also did a probabilistic model, and again, this is the difference between a local model versus a global model.",
            "Given time, I'm not going to go into much detail about."
        ],
        [
            "At."
        ],
        [
            "The key thing is.",
            "It really models how the references the collaborations are generated, and it can discover this and discovering this from data is actually a useful thing.",
            "It's also somewhat challenging thing so.",
            "It's based on one of these LDA."
        ],
        [
            "Models which are popular in text classification, we made some modifications for doing it for entity resolution, and I guess the slides have more details."
        ],
        [
            "I."
        ],
        [
            "So.",
            "Any generative model.",
            "The nice thing is you can then just throw in Gibbs sampling.",
            "The problem is just throwing in Gibbs sampling takes a really long time, so actually the part that was our research was how to make it more efficient an this was."
        ],
        [
            "Doing a kind of block sampling for entity resolution, which was interesting, let me get to the."
        ],
        [
            "Experimental evaluation"
        ],
        [
            "I'm.",
            "So we compared three different citation datasets sites here, which is a computer science papers machine learning papers archive, which is a collection of high energy physics papers and.",
            "This bio base, which is a collection of biology papers.",
            "They are varying sizes, so some are pretty small and some get larger.",
            "Uh, and then our baselines that we compared."
        ],
        [
            "So we compared something that used just attributes and we tried to be as smart as possible about how we did the attributes.",
            "Are attributes with doing transitive closure.",
            "And this naive relational entity resolution that I mentioned where we made use of the neighbor information and then our evaluation was evaluating pairwise decisions using F1 measure."
        ],
        [
            "And, um.",
            "Our results are here.",
            "The key thing again, I'm starting to speed up to try and finish so the key thing is doing the relational stuff helps, and so that was good.",
            "Otherwise I want to wasted your time with it.",
            "And you can look at this paper for more details, but then kind of getting to a similar point we have with the collective classification.",
            "Um?",
            "The.",
            "Compare."
        ],
        [
            "Person across the datasets is interesting, so for sites here which is a machine learning data set?",
            "OK, yeah we're doing a little bit better, but we were already.",
            "We're doing really well with attributes, so it's like this is a domain that wasn't that ambiguous.",
            "There was no point in going through all this work, or maybe a little bit of point versus archive so the physics data set OK, that one was.",
            "You know you got.",
            "7000 more correct references of 20% error reduction, but it was biobased where you really got a huge reduction by doing this, and So what is it that's different about these datasets?",
            "What's underlying difficulty of these datasets?",
            "Why the biobased one was better or this was needed, and so one thing is, this was a challenge problem, so they intentionally made it hard by.",
            "Removing, or just initialing the first names, so we only have first initial and last name, and then they chose, specifically Asian.",
            "Bias so Asian names.",
            "Are more ambiguous when you're just looking at the last name and then they just the fact of biology papers you think of biology papers.",
            "They have like hundreds of coauthors, or at least 10s of coauthors, so that's a case where the relational information is really going to help you.",
            "That Co author information is really going to help you, so that was something that we found.",
            "Governess?",
            "Um and then?"
        ],
        [
            "To say a little bit."
        ],
        [
            "About link prediction."
        ],
        [
            "This again."
        ],
        [
            "When is the?"
        ],
        [
            "Um?",
            "The notion of.",
            "I have maybe some things that I've observed, like some communication relationships.",
            "Someone emailed their text, messaged and what I'd like to do is.",
            "I'd like to figure out a more semantic relationship so."
        ],
        [
            "From the communication information, can I infer that someone's a manager or someone, or that someone's parent of someone, and so that's the problem and I already mentioned some of the different issues here and then predicting the links is really hard, there's some."
        ],
        [
            "Interesting variations like the one that I like that I think is actually interesting application.",
            "An active is something called leak detection.",
            "This is a problem where you're sending email you're trying to predict other people you sent to, which is the most likely person that you didn't intend to send the message to.",
            "So this is called a leak and.",
            "Is important to discover.",
            "Anne.",
            "So."
        ],
        [
            "To conclude, one of the things we really want to do, I've described each."
        ],
        [
            "These problems kind of in isolation.",
            "We really want to kind of chain them all together and have the entity resolution and form the collective classification and so on, and so my group is working on some subset of the problems and trying to kind of combine them together.",
            "And we're calling that general problem graph identification.",
            "Um?",
            "The issues."
        ],
        [
            "Are that OK?",
            "We can have this full probabilistic model that I mentioned in a couple of places, but that is.",
            "Has a number of issues or we can have combinations of local classifiers you know that has some.",
            "Other kinds of issues, and so there's a lot of really interesting and challenging research problems.",
            "I think in doing link mining, right?",
            "Kind of combining together all this information.",
            "Um?",
            "And then a caveat that's definitely worth mentioning."
        ],
        [
            "Is in all this link mining.",
            "There's a privacy issue so.",
            "Some of what we're trying to do is just understand better theoretically.",
            "Once you have linked data.",
            "You know what are the privacy implications and how sensitive should you be to these?",
            "Kind of the flip side.",
            "Can we guarantee that you can't do the predictions?",
            "And we've done a little bit of work in this in the context of predicting links, so a lot of people are interested in this one.",
            "Obviously the biological data, if you know something about family."
        ],
        [
            "Then you may be able to infer sensitive data.",
            "Also search data so once being able to figure out that those two searches were made by the same user may not be something you want to be able to do.",
            "There's a lot of work in anonymizing search log data that's interesting.",
            "Also in on line social networks we've looked so."
        ],
        [
            "At attribute disclosure, so you know how much information does joining a group on a social network give away, at least in the data we were looking at, gives away a lot, so it's something to be aware of.",
            "Again, I'm I'm kind of speeding through this, but definitely feel free to ask me more details offline."
        ],
        [
            "So overall, hopefully I've convinced you that relationships matter, so the links are important.",
            "The edges in the graph are important.",
            "The actual structure is important, so understanding the density of the graph and so on has a lot of implications that I don't think we understand yet, but.",
            "There is a lot of really interesting applications.",
            "An for example, I think all the last three are all ones that fit very much in a number of EU projects, but in particular and active these all kind of tide together to kind of help the knowledge worker an hopefully.",
            "I've convinced you while you have to worry about some things like this statistical confidence and privacy, there's a lot of benefits and pay offs.",
            "And your homework is to figure out all the benefits and pay us for active.",
            "OK thanks."
        ],
        [
            "So one minute.",
            "Earlier.",
            "About this, hoping say pacification settings.",
            "Yeah, and you didn't actually have time to talk about that.",
            "You will talk to you briefly.",
            "Give a shot.",
            "Especially in this point.",
            "So.",
            "So much of it is trying to infer.",
            "Functional.",
            "Information so.",
            "I can actually give you a pointer to someone in Maryland.",
            "Is doing a whole course and network analysis for biology and so there he has a. I was just looking at them another day.",
            "He has the slides up for the intro and I could give you the pointer for that.",
            "And so there's there's a lot of different.",
            "Um problems there.",
            "I'm guessing if you Google his name it will come up so it's.",
            "And one of the things that's incredibly interesting about the biological data is so much of the experimental data.",
            "Is so noisy that you know if you do, just you really need these statistical techniques to be able to deal with it and understand it so.",
            "Protein protein interaction networks are are known to be famously noisy, and then you know a lot of what is done to deal with.",
            "That is, you have to control for the experimental conditions so much you don't have very much data, But then some of the work, for example, one of my students is doing is trying to combine together more data sources.",
            "Under different experimental conditions, but kind of combine them in a robust way so that you can.",
            "To appropriate classification.",
            "But yeah, it really is a huge area of doing biological network analysis, and much of it, I think link prediction, collective classification and group discovery are the one and alignment are the big ones there.",
            "Task.",
            "OK, thanks Lisa, thanks again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Please, we can we can make a sty.",
                    "label": 0
                },
                {
                    "sent": "So we can afternoon of machine intelligence data mining.",
                    "label": 0
                },
                {
                    "sent": "Our first speaker is another guest speaker.",
                    "label": 0
                },
                {
                    "sent": "Please look at or where can I set correctly.",
                    "label": 0
                },
                {
                    "sent": "Dutch name is it?",
                    "label": 0
                },
                {
                    "sent": "No, it's actually.",
                    "label": 0
                },
                {
                    "sent": "The last name is Armenian.",
                    "label": 0
                },
                {
                    "sent": "Alright, but it got shortened, so that's just another script you could use.",
                    "label": 0
                },
                {
                    "sent": "I see I mean it's OK. Usually it has Diana, then that's the at least the rule anyway.",
                    "label": 0
                },
                {
                    "sent": "Ali says we University of Maryland, but she spends a lot of time also like like our previous speaker spends a lot of time in VR, has been spending a lot of time recently began working with Marco probably can his team at GSI.",
                    "label": 1
                },
                {
                    "sent": "Yeah, and it's nice to be back in Slovenia.",
                    "label": 0
                },
                {
                    "sent": "I was actually here for part of my sabbatical spring semester and I enjoyed it very much.",
                    "label": 0
                },
                {
                    "sent": "And so it's it's nice to be back, and So what I'm going to be talking about is link mining and the way that I'm organizing the talk.",
                    "label": 0
                },
                {
                    "sent": "It's supposed to be kind of a tutorial at a survey level.",
                    "label": 0
                },
                {
                    "sent": "The first I don't know quarter or so is going to be a general introduction, and it's going to be a little bit more abstract and high level.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to get into detail.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Files on some particular link mining algorithms I won't go through all of them.",
                    "label": 1
                },
                {
                    "sent": "And then do you conclusions.",
                    "label": 0
                },
                {
                    "sent": "And just to get a little bit of a flavor of the audience, as Paul said, this afternoon is going to be this kind of machine learning data mining.",
                    "label": 0
                },
                {
                    "sent": "Extravaganza, so how many people do have some background in machine learning and or data mining?",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to try and be general but it but do realize that I'm coming at it from kind of a machine learning centric approach.",
                    "label": 0
                },
                {
                    "sent": "And as Michael said, so Michael had the disadvantage of talking at 4:00 AM.",
                    "label": 0
                },
                {
                    "sent": "I think I've made it up to like 7:00 AM, so that's a little bit better, but it's after lunch, so those combined together so do definitely.",
                    "label": 0
                },
                {
                    "sent": "If you have questions anywhere, let's make this as interactive as possible.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 1
                },
                {
                    "sent": "What do I mean by link mining?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again, I'm kind of coming at it from the machine learning perspective that traditional machine learning approaches tended to assume that you had a kind of.",
                    "label": 0
                },
                {
                    "sent": "A very nice random sample of homogeneous objects.",
                    "label": 1
                },
                {
                    "sent": "All of the objects were of the same type, so coming from a single relation and then you would apply these very principled statistical inference techniques to learn a probability distribution, learn a classifier, and so on.",
                    "label": 0
                },
                {
                    "sent": "So there's a rich tradition of work there.",
                    "label": 0
                },
                {
                    "sent": "But the problem is real world datasets, especially the kinds of datasets that we're talking about in the active project, they just don't have that kind of uniform structure.",
                    "label": 0
                },
                {
                    "sent": "You don't just have a set of papers, you know, as we saw in the talks this morning, you have different kinds of objects.",
                    "label": 0
                },
                {
                    "sent": "You have different properties of objects, and you have relations between them.",
                    "label": 0
                },
                {
                    "sent": "You know sometimes it's.",
                    "label": 0
                },
                {
                    "sent": "Nice and structured in a database or in RDF or even better yet an owl.",
                    "label": 0
                },
                {
                    "sent": "But oftentimes it's even worse than that.",
                    "label": 0
                },
                {
                    "sent": "It's, you know.",
                    "label": 0
                },
                {
                    "sent": "Semi structured or unstructured text and you need to deal with that.",
                    "label": 0
                },
                {
                    "sent": "And so there's many many different areas that are trying to deal with this kind of mix of.",
                    "label": 0
                },
                {
                    "sent": "Multi relational, heterogeneous data and some of them are very specific to the application that they're looking at.",
                    "label": 0
                },
                {
                    "sent": "So if you look at hypertext classification that specifically looking at linked documents or things and social network analysis, so you're very much interested in people and their relationships.",
                    "label": 0
                },
                {
                    "sent": "Who knows who and so on?",
                    "label": 0
                },
                {
                    "sent": "Web mining.",
                    "label": 1
                },
                {
                    "sent": "A number of other domains, but there's also starting to be a kind of general theory that's building up for kind of unifying some of the techniques from text mining, web mining, other kinds of things in graph mining, relational learning, inductive logic, programming, and umbrella of other kinds of terms.",
                    "label": 0
                },
                {
                    "sent": "And what I'm going to try and do is I'm.",
                    "label": 0
                },
                {
                    "sent": "Going to try and give you a sense of some of the algorithms and task involved in these.",
                    "label": 0
                },
                {
                    "sent": "So first stop talking about the data.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to be.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pretty agnostic about this, but the general idea is that we have these kind of multi relational domains an I'm going to tend to use language that is assuming that I'm going to represent it as a graph and you know we saw lots of pictures of graphs in the previous talks.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to be a little bit agnostic about.",
                    "label": 0
                },
                {
                    "sent": "You know what the exact syntactic form of that is, and I'm going to be talking about link mining as kind of mining these.",
                    "label": 0
                },
                {
                    "sent": "Networks and grass, but realize that underneath it all you need some sort of representation that's powerful enough to capture the fact that there's.",
                    "label": 0
                },
                {
                    "sent": "Different kinds of objects that the objects have attributes.",
                    "label": 1
                },
                {
                    "sent": "Objects can have labels or classes associated with them.",
                    "label": 0
                },
                {
                    "sent": "Edges while I'm going to show them as little binary edges, you know they could be.",
                    "label": 0
                },
                {
                    "sent": "Hyper edges and so on, but the the notion is there's this rich structure here and so you know you can use.",
                    "label": 0
                },
                {
                    "sent": "Underlying that is usually going to be some kind of logical representation to capture that.",
                    "label": 0
                },
                {
                    "sent": "And so just to kind of rear reiterate, some of the kinds of domains so certainly or thinking about web data, so web data includes, obviously.",
                    "label": 0
                },
                {
                    "sent": "Pages an links between pages.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But it can also include things like weblogs, so you know the queries that someone made, the clicks that someone made on a page, and so on.",
                    "label": 0
                },
                {
                    "sent": "Bibliographic data.",
                    "label": 0
                },
                {
                    "sent": "So bibliographic data.",
                    "label": 0
                },
                {
                    "sent": "Most of my examples where I have real data sets are going to be bibliographic domains, but that tends to be because that's the kind of datasets that are easy for academics to get their hands on an.",
                    "label": 0
                },
                {
                    "sent": "Also, you know where academics so we can really relate to bibliographic domains.",
                    "label": 0
                },
                {
                    "sent": "So a number of my examples will be bibliographic.",
                    "label": 0
                },
                {
                    "sent": "Demands, but actually that's one of the things that I think is really interesting about the active project is the case studies.",
                    "label": 0
                },
                {
                    "sent": "Are these kind of interesting multi relational datasets which I'm going to say more about in a minute?",
                    "label": 0
                },
                {
                    "sent": "So social network analysis.",
                    "label": 0
                },
                {
                    "sent": "So when we're talking about people, friends on Facebook, social media kinds of domains, epidemiological data.",
                    "label": 0
                },
                {
                    "sent": "So people, you know what diseases are infected with the transmissions and so on is a kind of domain that a lot of these link mining task would be applicable for.",
                    "label": 0
                },
                {
                    "sent": "Communication data so communication data, whether it's cell phone traffic.",
                    "label": 1
                },
                {
                    "sent": "An or financial network kinds of data, whether it's email, communication, text, messaging, all of these things are things that can be described as a network where you have nodes are the people that are either sending or receiving the information, and you can view it as a network.",
                    "label": 0
                },
                {
                    "sent": "So customer networks as well.",
                    "label": 1
                },
                {
                    "sent": "So it could be the recommendation network.",
                    "label": 0
                },
                {
                    "sent": "So a lot of the viral marketing kinds of things can be viewed.",
                    "label": 0
                },
                {
                    "sent": "As setting.",
                    "label": 0
                },
                {
                    "sent": "As the kind of multi relational heterogeneous data that we're talking about here, a lot of collaborative filtering or recommendation system.",
                    "label": 0
                },
                {
                    "sent": "So you think of Amazon, you think of books and recommendations people make you think of restaurants and recommendations.",
                    "label": 0
                },
                {
                    "sent": "People make other kind of product recommendations, trust networks, so you know that kind of thing where you're trying to, you know so and so, trust so and so well, does that mean that I?",
                    "label": 0
                },
                {
                    "sent": "That's a kind of inference that I want to do that you know, if I trust someone then they trust someone else.",
                    "label": 0
                },
                {
                    "sent": "Should I trust that person?",
                    "label": 0
                },
                {
                    "sent": "Usually not.",
                    "label": 1
                },
                {
                    "sent": "So you want to be able to do kind of these rich kinds of inferences about trust.",
                    "label": 0
                },
                {
                    "sent": "Biological data this comes up all over the place needing to do link mining.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of work in protein, protein interaction networks, other kinds of biological data can be viewed as a network where you want to do some kind of link mining.",
                    "label": 0
                },
                {
                    "sent": "And now I thought I was going to be the first one to assign homework.",
                    "label": 0
                },
                {
                    "sent": "Since this is a summer school you guys have to have homework, right?",
                    "label": 0
                },
                {
                    "sent": "But I think Michael already managed to assign a question.",
                    "label": 0
                },
                {
                    "sent": "But so your guyses homework here is to come up with.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So weather.",
                    "label": 0
                },
                {
                    "sent": "Some of that.",
                    "label": 0
                },
                {
                    "sent": "Active specific.",
                    "label": 0
                },
                {
                    "sent": "Problems.",
                    "label": 0
                },
                {
                    "sent": "And so First off, just in terms of the active domains for the people that are in the project.",
                    "label": 0
                },
                {
                    "sent": "I mean, what kinds of multi relational?",
                    "label": 0
                },
                {
                    "sent": "Are different kinds of objects.",
                    "label": 0
                },
                {
                    "sent": "Do you guys see?",
                    "label": 0
                },
                {
                    "sent": "So someone had to be paying attention during Paul's intro.",
                    "label": 0
                },
                {
                    "sent": "Keyboard company.",
                    "label": 0
                },
                {
                    "sent": "People, companies.",
                    "label": 0
                },
                {
                    "sent": "And the events.",
                    "label": 0
                },
                {
                    "sent": "So what are the events?",
                    "label": 0
                },
                {
                    "sent": "Uh huh.",
                    "label": 0
                },
                {
                    "sent": "Anonym example.",
                    "label": 0
                },
                {
                    "sent": "Organizations.",
                    "label": 0
                },
                {
                    "sent": "Any other?",
                    "label": 0
                },
                {
                    "sent": "Kinds of objects.",
                    "label": 0
                },
                {
                    "sent": "Say again.",
                    "label": 0
                },
                {
                    "sent": "Documents and the emails.",
                    "label": 0
                },
                {
                    "sent": "Either you can think of the email as a document, or you can think of the email as a communication event.",
                    "label": 0
                },
                {
                    "sent": "So part of The thing is, you know keeping track of that so.",
                    "label": 0
                },
                {
                    "sent": "How did they do Paul?",
                    "label": 0
                },
                {
                    "sent": "Do they leave out some major ones?",
                    "label": 0
                },
                {
                    "sent": "Process is.",
                    "label": 0
                },
                {
                    "sent": "Ice.",
                    "label": 0
                },
                {
                    "sent": "Persons are eventually away, but yeah, so there's some interesting structure here between the events and the processes and the knowledge and so on, so.",
                    "label": 0
                },
                {
                    "sent": "Keep thinking about this.",
                    "label": 0
                },
                {
                    "sent": "Keep thinking about them in the context of active but also in the context and using context too many times.",
                    "label": 0
                },
                {
                    "sent": "But in the context of other domains that do you guys work in?",
                    "label": 0
                },
                {
                    "sent": "You know what are the different kinds of objects?",
                    "label": 0
                },
                {
                    "sent": "And then as we go through this, we're going to talk about link mining task and I'd like you to think about kind of inferences that would be specific to these.",
                    "label": 0
                },
                {
                    "sent": "Um, that fit with the.",
                    "label": 0
                },
                {
                    "sent": "Examples that I'm going to go through, so I'm going to go over a collection of my link mining task and the key thing to note is I'm going to start off with things that are kind of so there's statistical info.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's when I say inference or prediction.",
                    "label": 0
                },
                {
                    "sent": "That's what I'm usually talking about.",
                    "label": 0
                },
                {
                    "sent": "I'm going to start off with things that are kind of focused on nodes.",
                    "label": 0
                },
                {
                    "sent": "In the network, and then I'm going to talk about things that are more talking about edges or relationships in the network, and then I'm going to kind of wrap up with some ones that are.",
                    "label": 0
                },
                {
                    "sent": "Ann about collections of bigger collections of nodes and edges, and again at this point all I'm doing is kind of posing these at a very abstract level.",
                    "label": 0
                },
                {
                    "sent": "A high level kind of description of the problem, and then I'll go into some specific algorithms for how you actually do these things.",
                    "label": 0
                },
                {
                    "sent": "Let's start off with what I would say is the simplest one so.",
                    "label": 0
                },
                {
                    "sent": "The simplest one is your starting offen.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You have.",
                    "label": 0
                },
                {
                    "sent": "You can think of it as you have this big, unlabeled graph and you're trying to put labels on the nodes in the graph.",
                    "label": 0
                },
                {
                    "sent": "And so simple example would be predicting the category of a web page or the topic of a web page based on.",
                    "label": 1
                },
                {
                    "sent": "And now here's a place where it starts changing because of the fact you're in this linked environment.",
                    "label": 1
                },
                {
                    "sent": "It's based on, you know, attributes of the object itself.",
                    "label": 0
                },
                {
                    "sent": "Are the node in the graph but also based on things that it links to attributes of things that it links to and so on.",
                    "label": 0
                },
                {
                    "sent": "So you can kind of do this thing where you kind of crawl out the graph and get more information to help you do the inference of the label.",
                    "label": 0
                },
                {
                    "sent": "So in the citation domain, so predicting the topic of the paper based on you know, of course, the words that appear on the paper but also based on you know the things that cites the things that are Co cited and so on.",
                    "label": 1
                },
                {
                    "sent": "And, you know, in a biological domain predicting, say, the disease types based on characteristics of the patients infected by the disease, and so on.",
                    "label": 0
                },
                {
                    "sent": "Um, so object classification is really you have some graph and you're trying to put some sort of label on the nodes and this is in contrast to traditional machine learning.",
                    "label": 0
                },
                {
                    "sent": "There's an area called supervised classification where you go through and you put labels on objects and.",
                    "label": 0
                },
                {
                    "sent": "The biggest thing here is we want to label not just a single object at a time, but this whole collection of objects and the objects are linked.",
                    "label": 0
                },
                {
                    "sent": "And kind of as a sort of more of a subclass.",
                    "label": 0
                },
                {
                    "sent": "Of this problem is object type prediction.",
                    "label": 0
                },
                {
                    "sent": "So maybe it said you have this kind of heterogeneous graph where you have different kinds of.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Objects, and so you're trying to figure out what.",
                    "label": 0
                },
                {
                    "sent": "Kind of object.",
                    "label": 0
                },
                {
                    "sent": "Each thing is and so this is really closely related to object classification.",
                    "label": 0
                },
                {
                    "sent": "The only difference I would say is, for example, predicting the type of venue of a publication.",
                    "label": 1
                },
                {
                    "sent": "You know the venue actually then has different attributes, so the actual structure of the object is different, so that's the place where it's a little bit kind of more complex than just putting a label on the node.",
                    "label": 0
                },
                {
                    "sent": "It's like you're putting a label on the node and at the same time you're trying to figure out what kind of thing it is.",
                    "label": 0
                },
                {
                    "sent": "So that you know what kind of attributes it has, so it makes sense.",
                    "label": 0
                },
                {
                    "sent": "If I figured out it's a Journal publication, then I should go out and, you know, get the volume number and so on.",
                    "label": 0
                },
                {
                    "sent": "But if it's a conference publication, then conference publications don't have those attributes, so it doesn't make sense for me to go look for them.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So those are some kind of object E node kind of inferences.",
                    "label": 0
                },
                {
                    "sent": "You might want to make.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There is very analogous kinds of inferences that you might want to make for the edges in the graph or the links in the graph.",
                    "label": 0
                },
                {
                    "sent": "An one simple one is predicting kind of the flip side of object type classification.",
                    "label": 1
                },
                {
                    "sent": "Predicting the type or purpose of a link.",
                    "label": 1
                },
                {
                    "sent": "So suppose, for example, you have a web page, you have a link from one web page to another web page.",
                    "label": 1
                },
                {
                    "sent": "So you know that link exists, but you're trying to figure out why does that link exist.",
                    "label": 0
                },
                {
                    "sent": "So what kind of link is it?",
                    "label": 1
                },
                {
                    "sent": "Is it an actual informational link or is it just a navigational link?",
                    "label": 0
                },
                {
                    "sent": "Is it a spam link?",
                    "label": 0
                },
                {
                    "sent": "So these are the.",
                    "label": 0
                },
                {
                    "sent": "Kinds of things that you might want to do when you're trying to label the links in a network.",
                    "label": 0
                },
                {
                    "sent": "Um, another one is there I said?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, I know that there's a link between these pages.",
                    "label": 1
                },
                {
                    "sent": "What if instead what I'm trying to do is I'm trying to predict whether there is a link.",
                    "label": 1
                },
                {
                    "sent": "So this is predicting the existence of a link.",
                    "label": 0
                },
                {
                    "sent": "It turns out that that actually I'll say more about it, but this is a much harder problem than predicting the type of a link, and you can see where something like this could end up being useful.",
                    "label": 0
                },
                {
                    "sent": "So if I had a model for predicting the existence of a link.",
                    "label": 1
                },
                {
                    "sent": "And then I could use it to predict when something should link to something else.",
                    "label": 0
                },
                {
                    "sent": "I predict there's a there should be a link in.",
                    "label": 0
                },
                {
                    "sent": "There isn't a link there, then that could be something that I give to.",
                    "label": 0
                },
                {
                    "sent": "A developer to help in the process or for a lot of the.",
                    "label": 0
                },
                {
                    "sent": "Collaborative filtering domains.",
                    "label": 1
                },
                {
                    "sent": "When you're trying to predict, you know who's would like this product.",
                    "label": 0
                },
                {
                    "sent": "Who would like this book then?",
                    "label": 0
                },
                {
                    "sent": "That can be formulated as a link existence kind of problem.",
                    "label": 0
                },
                {
                    "sent": "Um, another thing that you might.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Want to do with links is instead of actually predicting specific links between specific instances of objects.",
                    "label": 0
                },
                {
                    "sent": "Instead be interested in predicting the number of links so it turns out as a statistical estimation problem, this actually can be easier, so if you know that you're actually in this situation, it's actually important to take that into account.",
                    "label": 1
                },
                {
                    "sent": "And oftentimes this predicting then carnality, so the number of links serves as a surrogate for something like predicting the importance of something.",
                    "label": 1
                },
                {
                    "sent": "So you know are the rank of something.",
                    "label": 1
                },
                {
                    "sent": "So Page rank and so on have this flavor of kind of predicting how many in links something is going to have and because of the number of in links that.",
                    "label": 0
                },
                {
                    "sent": "You know whatever that node represents, whether it's a person or paper or web page, is going to be a very influential.",
                    "label": 0
                },
                {
                    "sent": "Um object and so this is essentially trying to estimate the degree of a node.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Another variant is.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where you're looking at larger.",
                    "label": 0
                },
                {
                    "sent": "Longer path, so not just estimating the number of links into an object, but estimating the number of things that you'll reach through some sort of set of hops away from a node.",
                    "label": 1
                },
                {
                    "sent": "And you could picture this as being useful for estimating the centrality of a node.",
                    "label": 0
                },
                {
                    "sent": "The other thing that it's incredibly useful for is this is what's fundamental to any kind of database.",
                    "label": 0
                },
                {
                    "sent": "Selectivity estimation where you're trying to figure out OK if I join together this relation with this relation.",
                    "label": 0
                },
                {
                    "sent": "With this relation, you know how many objects do I expect to get back in order to do an efficient job of optimizing this, you need to have a good answer to this problem, so it may be that you're interested in this estimate for your.",
                    "label": 0
                },
                {
                    "sent": "Data analysis, but it may be that you're interested in this question for your optimization, your algorithmic optimization as well.",
                    "label": 0
                },
                {
                    "sent": "The so we had kind of basic node prediction kinds of.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Things basic Edge link prediction kinds of things.",
                    "label": 1
                },
                {
                    "sent": "The next thing is again about kind of nodes and links, but the specific link is the same as link, so predicting when two references to something are actually referring to the same underlying entity, so.",
                    "label": 0
                },
                {
                    "sent": "You know I have Jay Smith and John Smith.",
                    "label": 0
                },
                {
                    "sent": "String references.",
                    "label": 0
                },
                {
                    "sent": "How do I figure out that those are referring to the same underlying individual?",
                    "label": 0
                },
                {
                    "sent": "Or perhaps I have one John Smith in one place, another John Smith and another place, and they're actually referring to different individuals.",
                    "label": 0
                },
                {
                    "sent": "This problem I will talk about in more detail further on in the presentation.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Another kind of.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Prediction that includes both links and nodes is group detection, so trying to find communities.",
                    "label": 1
                },
                {
                    "sent": "In a network and.",
                    "label": 1
                },
                {
                    "sent": "There's a lot of methods that simply find communities based on the edges, so a lot of the spectral clustering algorithms are based on this.",
                    "label": 0
                },
                {
                    "sent": "There's another collection of algorithms that do it based just on the attribute values, but being able to do something that combines both the kind of link structure together with the attributes when you're trying to find.",
                    "label": 1
                },
                {
                    "sent": "Communities or tribes in these networks.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then a little bit more general than that is the whole notion of sub graph discovery, so finding common subgraphs that occur multiple places in the network.",
                    "label": 0
                },
                {
                    "sent": "So this could be.",
                    "label": 0
                },
                {
                    "sent": "Used for.",
                    "label": 0
                },
                {
                    "sent": "The most common example is chemical substructure, drug discovery, and so on tends to have this flavor, but you could also think of the Community detection as a form of sub sub graph discovery.",
                    "label": 0
                },
                {
                    "sent": "And then, um.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, you get to things that you know were mentioned this morning of being able to have two graphs where you actually need to do some sort of figuring out some alignment between them.",
                    "label": 0
                },
                {
                    "sent": "Some sort of connections between them.",
                    "label": 0
                },
                {
                    "sent": "So whether or not you're doing it at the most basic level of doing the entity resolution between them, you know when.",
                    "label": 0
                },
                {
                    "sent": "Do two entities refer to the same thing, or kind of more complex?",
                    "label": 0
                },
                {
                    "sent": "Schema mapping.",
                    "label": 0
                },
                {
                    "sent": "Ontology alignment and so on or like some other work that my group is doing.",
                    "label": 0
                },
                {
                    "sent": "Is this kind of folksonomy discovery so you have a bunch of little folksonomies and you're trying to glue them together and find some useful subcomponent that has a whole notion of alignment.",
                    "label": 0
                },
                {
                    "sent": "And then in biology there are tons and tons of problems where you're trying to take these kind of biological graphs and then kind of line them up and find out the commonality is whether the commonality's are in terms of.",
                    "label": 0
                },
                {
                    "sent": "The kind of mechanism the evolutionary mechanism, or whether it's more cross species kinds of comparisons.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So this is kind of my list of link mining tasks.",
                    "label": 0
                },
                {
                    "sent": "It's not exclusive or exhaustive.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Every time I give the talk, I end up adding a couple more.",
                    "label": 0
                },
                {
                    "sent": "But this is meant to be kind of this high level abstract introduction to the kinds of statistical inferences you might want to do in networks.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Kind of to put with that.",
                    "label": 0
                },
                {
                    "sent": "I would like to also say something about you know what makes these things hard?",
                    "label": 0
                },
                {
                    "sent": "Or what are the common properties across all of these?",
                    "label": 0
                },
                {
                    "sent": "Before I get into a specific one and say oh here's some algorithms for doing entity resolution, what kinds of problems come up in all of these?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "These again are some of them and I'll go over them at a high level again.",
                    "label": 0
                },
                {
                    "sent": "But the interesting thing, I think, is that I think these are.",
                    "label": 0
                },
                {
                    "sent": "This is my opinion that these problems are.",
                    "label": 0
                },
                {
                    "sent": "Our challenges are common no matter what formalism you end up using, so all the.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The kinds of things that I'm going to talk about in some way combine statistical and logical information for their modeling and methods so you know there's been a lot of different things proposed Bayesian logic programs, conditional random fields, Markov logic, and so on, But the things that I'm going to talk about in the next 10 minutes are things that.",
                    "label": 1
                },
                {
                    "sent": "All of these formalisms end up having to deal with and so the first one is kind of what I alluded to is that you you need to combine together in some way the fact that there's two kinds of dependencies going on, so one is this logical dependencies.",
                    "label": 0
                },
                {
                    "sent": "So if A then B and so on.",
                    "label": 0
                },
                {
                    "sent": "So how do I chain together things?",
                    "label": 0
                },
                {
                    "sent": "How do I know if I'm in a graph?",
                    "label": 0
                },
                {
                    "sent": "And I'm navigating links, you know it follow one to the other.",
                    "label": 0
                },
                {
                    "sent": "How do I do that?",
                    "label": 0
                },
                {
                    "sent": "How do I represent the ways of doing that?",
                    "label": 0
                },
                {
                    "sent": "And then the other is a more kind of statistical dependence, so probabilistic dependence, you know correlations between attribute values.",
                    "label": 0
                },
                {
                    "sent": "How do I?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have a system that can talk about both of these in kind of a general way to support a lot of the problems.",
                    "label": 0
                },
                {
                    "sent": "The AI problems AI challenges that.",
                    "label": 0
                },
                {
                    "sent": "Michael raised in his talk, so, um.",
                    "label": 0
                },
                {
                    "sent": "Let me show.",
                    "label": 0
                },
                {
                    "sent": "One instance of this kind of general issue of combining logical and statistical dependence an this is.",
                    "label": 0
                },
                {
                    "sent": "In the search over possible models.",
                    "label": 0
                },
                {
                    "sent": "So this is an example that.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to use in a couple of places, so it's just a really toy example where the peas are papers, so I have this paper P here, and that's suppose that's the one that I'm trying to figure out.",
                    "label": 0
                },
                {
                    "sent": "What is the topic of this paper?",
                    "label": 0
                },
                {
                    "sent": "And then I have some other papers sitting around.",
                    "label": 0
                },
                {
                    "sent": "So I have P1P2 and P3.",
                    "label": 0
                },
                {
                    "sent": "And then I have an author, so this a one say is author of.",
                    "label": 0
                },
                {
                    "sent": "P1P2 and my?",
                    "label": 0
                },
                {
                    "sent": "Paper, and, you know, maybe I have institution information associated with this author, so author One is at institution One.",
                    "label": 0
                },
                {
                    "sent": "And so I could when I'm trying to predict the topic of.",
                    "label": 0
                },
                {
                    "sent": "The paper I could use a model that just looks at other papers.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "In particular, other papers that cite this paper.",
                    "label": 0
                },
                {
                    "sent": "And then I could build a statistical model over this.",
                    "label": 0
                },
                {
                    "sent": "You know I'm being agnostic about what particular model you build.",
                    "label": 0
                },
                {
                    "sent": "It could be a neural net.",
                    "label": 0
                },
                {
                    "sent": "It could be decision tree, whatever flavor you want.",
                    "label": 0
                },
                {
                    "sent": "But somehow I needed to know something about the logical structure of the domain so that I knew that papers that cite this paper are the ones that I should use.",
                    "label": 0
                },
                {
                    "sent": "I shouldn't go and use arbitrary other papers, but the ones that cite this paper.",
                    "label": 0
                },
                {
                    "sent": "Um and I might want to use information about the author, but again, I need to have the representation that tells me that you know getting to an author of a paper and then seeing if there's some statistical dependence on.",
                    "label": 0
                },
                {
                    "sent": "You know, maybe the research area of the author and the topic of the paper, or how long they've been in the field, and that topic would make sense.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "An I could go out longer chain so I could say, well the.",
                    "label": 0
                },
                {
                    "sent": "The paper that cited the paper that cited this unknown one, so I could kind of grow these kind of attributes that I'm looking for dependence.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "An I could then you know.",
                    "label": 0
                },
                {
                    "sent": "Similarly do it for other kinds of objects.",
                    "label": 0
                },
                {
                    "sent": "So go from the author of the paper to the Institute of the Author, Find some attribute of that and do this.",
                    "label": 0
                },
                {
                    "sent": "But this whole thing of searching through the model space is something that you know in statistical machine learning you do feature selection, but normally you're given the set of features before hand.",
                    "label": 0
                },
                {
                    "sent": "You don't actually kind of construct them on the fly using this.",
                    "label": 0
                },
                {
                    "sent": "So the model search being informed by the underlying structure and the domain is something that's really important in these kinds of problems.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "When you're doing that.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It turns out that in many cases the objects are connected not just to one object, so you don't have a functional relationship, but it's related to a set of objects and.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 1
                },
                {
                    "sent": "Somehow, in most of the methods you need to construct a single feature from this set.",
                    "label": 0
                },
                {
                    "sent": "That's going to then go into your statistical model an you know there's a couple of different common ones that are done.",
                    "label": 0
                },
                {
                    "sent": "So if I go to.",
                    "label": 0
                },
                {
                    "sent": "This setting.",
                    "label": 0
                },
                {
                    "sent": "Anne, I'm",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, predicting the paper here and suppose I'm going to say, well, I'm going to make this dependence depend on the topics of the papers that cite this paper.",
                    "label": 0
                },
                {
                    "sent": "An I have two greens and one yellow.",
                    "label": 0
                },
                {
                    "sent": "That site this an so the color space in this case is supposed to dinner at the topic of the paper well.",
                    "label": 0
                },
                {
                    "sent": "One thing that I could do is I could look at that set an look at the most commonly occurring topic and then say, OK, you know.",
                    "label": 0
                },
                {
                    "sent": "Since green occurs most often, I'm going to say that this one screen and there's a lot of different propagation models.",
                    "label": 0
                },
                {
                    "sent": "It essentially boiled down to doing some flavor of this, whether it's a stochastic version or deterministic version of propagating the influence in this way.",
                    "label": 0
                },
                {
                    "sent": "But the interesting thing from a machine learning perspective is, once I've done this, where it.",
                    "label": 0
                },
                {
                    "sent": "Take the set and compute a single feature that I aggregate on and then I can go and I can apply it.",
                    "label": 0
                },
                {
                    "sent": "In some setting that looks completely different, so I have different numbers of nodes and so on.",
                    "label": 0
                },
                {
                    "sent": "But still, this notion of mode of the set of things that site me is well defined, so I can deal with kind of this varying kind of structure.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, yeah.",
                    "label": 0
                },
                {
                    "sent": "The translations, because you have the three green topics on the right from Jordan, right?",
                    "label": 0
                },
                {
                    "sent": "Right, so the mode is really the majority label and so this is a simple majority label propagation algorithm.",
                    "label": 0
                },
                {
                    "sent": "But it's doing it, or one way to think of it in a statistical inference algorithm, is it you're computing the mode of the neighbor and then propagating it too?",
                    "label": 0
                },
                {
                    "sent": "That node but you could have a totally different method for doing the propagation, so it could be more of something which I'm calling a selection set up where again I have these neighbors.",
                    "label": 0
                },
                {
                    "sent": "But somehow I figure out, you know, maybe through reputation or reasoning about trust, I figure out, Oh well, you know of all those papers.",
                    "label": 0
                },
                {
                    "sent": "P1 is the most important one, so maybe P1 is.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The most Seminole paper or P ones by the most famous author or something like that, but I instead of looking at the set an computing and aggregate, I'm going to look at the set an.",
                    "label": 0
                },
                {
                    "sent": "Select a representative and then use that and then I could use it in the same way where I just copy the label, but it could be more complex.",
                    "label": 0
                },
                {
                    "sent": "The inference doesn't have to be same label.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There's kind of a.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Similar thing that comes up with weather in my statistical model, my statistical probabilistic logical model.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to be agnostic to not pick out any one particular one.",
                    "label": 0
                },
                {
                    "sent": "Whether I refer in the model to particular individuals or whether I refer to whole classes of individuals and let me try and make that more concrete so.",
                    "label": 0
                },
                {
                    "sent": "The advantage of having it refer to specific individuals is.",
                    "label": 0
                },
                {
                    "sent": "If the individual is really predictive, then I certainly want to make use of that so.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this case.",
                    "label": 0
                },
                {
                    "sent": "Maybe P3 is you know such.",
                    "label": 0
                },
                {
                    "sent": "Well known paper, or well known to be on a particular topic that I want to say.",
                    "label": 0
                },
                {
                    "sent": "Any paper that cites P3.",
                    "label": 0
                },
                {
                    "sent": "MP3 happens to be green.",
                    "label": 0
                },
                {
                    "sent": "I likely to be green.",
                    "label": 1
                },
                {
                    "sent": "So any customer that likes this particular movie.",
                    "label": 0
                },
                {
                    "sent": "Yeah, Raiders of the Lost Ark.",
                    "label": 0
                },
                {
                    "sent": "You know they are definitely going to like.",
                    "label": 0
                },
                {
                    "sent": "You know all these other kinds of movies?",
                    "label": 0
                },
                {
                    "sent": "Or an if you do that, then you know I would infer that all of these are likely to be green.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Or are you going to do something that's more general that's based on attributes of the object?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Like the example that I was doing before, not talking about a particular paper, but talking about green papers.",
                    "label": 0
                },
                {
                    "sent": "So papers that cite Green papers are likely to.",
                    "label": 1
                },
                {
                    "sent": "B Green or people that like sci-fi movies are likely to not like.",
                    "label": 0
                },
                {
                    "sent": "These do I make things that are?",
                    "label": 0
                },
                {
                    "sent": "Do I have a model that kind of reasons at that level or at the more specific level?",
                    "label": 0
                },
                {
                    "sent": "And the issue is Jake kind of skipped over.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "You know you can get.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Much more predictive models, if you're basing it on single instances, but they're much less general, so they're not going to apply in as many cases, so you have this tradeoff, and for example, if I learn a statistical model that's based on.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                },
                {
                    "sent": "Publications in machine learning and how things go there an specific individuals there.",
                    "label": 0
                },
                {
                    "sent": "Then I try and apply that in high energy finette physics.",
                    "label": 0
                },
                {
                    "sent": "Then you know there's not even going to be any overlap in the people or overlapping the attributes, and that's going to be an issue, and it's interesting because a lot of this social network analysis algorithms are individual specific.",
                    "label": 0
                },
                {
                    "sent": "And don't always generalize across attributes.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The other thing that I'm really going to be emphasizing later is the need for this collective nature.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the inferences, so I infer labels on some nodes, and I need to propagate that information, and so there's not.",
                    "label": 0
                },
                {
                    "sent": "So there's a dependence of what I label one node on what I label another node.",
                    "label": 0
                },
                {
                    "sent": "And similarly.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "K for entity resolution.",
                    "label": 0
                },
                {
                    "sent": "You know I don't make the entity resolution decisions about what refers to the same thing in dependently.",
                    "label": 1
                },
                {
                    "sent": "I actually do the propagation, so there's this statistical inference and this kind of probabilistic propagation that's going on at the same time.",
                    "label": 0
                },
                {
                    "sent": "There's potentially a logical inference happening based on the statistical conclusions that you're coming up with.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Dealing with labeled and unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "This is something that is a kind of technical thing that.",
                    "label": 0
                },
                {
                    "sent": "One worries about in machine learning.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Doing a fair amount.",
                    "label": 0
                },
                {
                    "sent": "An I'm actually I'll go into this in a little bit more detail later, and I have a slide that covers it, But the interesting thing is in one of these probabilistic logic frameworks, the issues with combining labeled and unlabeled to date data together and doing higher quality inferences is particularly interesting and useful, so you can.",
                    "label": 0
                },
                {
                    "sent": "As a number of people have shown in different domains, get much more accurate inferences because of the fact that you have some labeled data where you know, say, the classes of the objects.",
                    "label": 1
                },
                {
                    "sent": "You have some unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "I'm going to infer the labels for those things.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to make use of those inferred labels to improve the accuracy on additional inferences.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "For the link existence prediction, so one of the key issues here.",
                    "label": 0
                },
                {
                    "sent": "Is when I'm trying to predict whether there exists a link between two nodes.",
                    "label": 0
                },
                {
                    "sent": "The problem is, this is something that typically the prior probability of having a link is incredibly low, so it's usually .0002.",
                    "label": 0
                },
                {
                    "sent": "An as anybody that is dealt with machine learning algorithms, when you have things that have such a biased distribution.",
                    "label": 0
                },
                {
                    "sent": "That ends up introducing all kinds of complications, and you, not surprisingly, then, you can get a very accurate classifier that just said there's no links.",
                    "label": 0
                },
                {
                    "sent": "So you know it will do very well in terms of accuracy, but it's probably not what you want.",
                    "label": 0
                },
                {
                    "sent": "Oh.",
                    "label": 0
                },
                {
                    "sent": "Actually, the somewhat surprising thing is we actually have had some success with building these models that explicitly model probabilities of existence of links for medium sized datasets, and to be honest, when we tried this, I thought it wasn't going to work at all, and so the fact that it sort of worked as good.",
                    "label": 0
                },
                {
                    "sent": "But as you go to larger and larger datasets.",
                    "label": 0
                },
                {
                    "sent": "This becomes completely infeasible, so there's a scale issue of whether or not you're explicitly modeling each pairwise.",
                    "label": 0
                },
                {
                    "sent": "Edge existence as a different.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Random variable if you do that for even a moderately sized data set, that's not going to scale, and so there's a lot of really interesting.",
                    "label": 0
                },
                {
                    "sent": "Research issues in doing link prediction.",
                    "label": 0
                },
                {
                    "sent": "And then the last one, kind of.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Challenge that I'm going to mention is making what's called a.",
                    "label": 0
                },
                {
                    "sent": "Closed world versus open world assumption.",
                    "label": 1
                },
                {
                    "sent": "So in AI this is kind of the notion of do I know everything that exists in the world.",
                    "label": 0
                },
                {
                    "sent": "Do I know all of the books in the world?",
                    "label": 1
                },
                {
                    "sent": "Do I know all the people in the world?",
                    "label": 0
                },
                {
                    "sent": "Most of the models technically rely on assumption.",
                    "label": 0
                },
                {
                    "sent": "That does say I know all of them.",
                    "label": 0
                },
                {
                    "sent": "Um, that's starting to change.",
                    "label": 0
                },
                {
                    "sent": "I mean, there definitely are models that are doing more of an open world assumption, but especially for this statistical relational stuff, it still tends to make this because you have to make sure that your probability distributions, well defined, and to do that you need to makes it easy.",
                    "label": 0
                },
                {
                    "sent": "If everything is finite, and so then you need to know the number and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is, I think, a really interesting challenge, and it's an interesting challenge that.",
                    "label": 0
                },
                {
                    "sent": "I think comes up.",
                    "label": 1
                },
                {
                    "sent": "In a lot of the.",
                    "label": 0
                },
                {
                    "sent": "The problems that we were talking about this morning.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A summary of the task and the challenge is an.",
                    "label": 0
                },
                {
                    "sent": "Again like I said in the intro.",
                    "label": 0
                },
                {
                    "sent": "This is kind of that I'm trying to give an abstract overview of the general area.",
                    "label": 0
                },
                {
                    "sent": "But let me pause here and see if anybody has some questions about what I've said so far.",
                    "label": 0
                },
                {
                    "sent": "Prior probability.",
                    "label": 0
                },
                {
                    "sent": "Yeah, because typically.",
                    "label": 0
                },
                {
                    "sent": "If you do it in the naive way, it would scale as N ^2.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "That maybe works for 100,000, but it definitely doesn't work, and even then it's pretty bad.",
                    "label": 0
                },
                {
                    "sent": "So, so that's that's one of the big issues.",
                    "label": 0
                },
                {
                    "sent": "If you're looking at each specific week.",
                    "label": 0
                },
                {
                    "sent": "Not necessarily at the properties.",
                    "label": 0
                },
                {
                    "sent": "Exactly exactly, so if you grounded out and look at each particular link, then in the naive way you'll get to this issue.",
                    "label": 0
                },
                {
                    "sent": "When I get to, I'm going to talk about entity resolution.",
                    "label": 1
                },
                {
                    "sent": "I'm going to talk about some of the methods that people do to get around that.",
                    "label": 0
                },
                {
                    "sent": "Some of the basic methods for getting around it, but I still think that there's tons of interesting research issues there.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Other.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Everybody's working on their homework right now, right?",
                    "label": 0
                },
                {
                    "sent": "So you think of the.",
                    "label": 1
                },
                {
                    "sent": "Active specific problems for all of these different things for doing object classification.",
                    "label": 0
                },
                {
                    "sent": "Entity resolution and so on for domains that are describing the knowledge workers.",
                    "label": 0
                },
                {
                    "sent": "'cause remember you have to send it to me.",
                    "label": 0
                },
                {
                    "sent": "I need to put a due date on it.",
                    "label": 0
                },
                {
                    "sent": "So what's the last talk on Sunday?",
                    "label": 0
                },
                {
                    "sent": "Microsoft explains itself is talking later.",
                    "label": 0
                },
                {
                    "sent": "OK, well I I won't have that do.",
                    "label": 0
                },
                {
                    "sent": "I'll have it do before your talk so that they pay attention during your talk, because that's.",
                    "label": 0
                },
                {
                    "sent": "OK, and you can email it to me.",
                    "label": 0
                },
                {
                    "sent": "So get tour at cs.umd.edu if you Google Get tour you can find it written in a way that's more readable than that, OK?",
                    "label": 0
                },
                {
                    "sent": "They told you you guys get grades at the end of this right?",
                    "label": 0
                },
                {
                    "sent": "Complexity.",
                    "label": 0
                },
                {
                    "sent": "So where you can do some sampling people sampling or see I mean do it like a way.",
                    "label": 1
                },
                {
                    "sent": "Actually, yeah, an an.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about that, not in the context of link prediction, but doing some sort of.",
                    "label": 0
                },
                {
                    "sent": "Various kinds of stochastic sampling are one way of doing the estimation.",
                    "label": 0
                },
                {
                    "sent": "So yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "So when I was saying the problems I was kind of posing it as like the most naive approach.",
                    "label": 0
                },
                {
                    "sent": "Why the most naive approach isn't going to work well.",
                    "label": 0
                },
                {
                    "sent": "But yeah, and that's usually sampling.",
                    "label": 0
                },
                {
                    "sent": "Is 1 good way of getting around the complexity of doing inference?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk now.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "More in detail about collective object classification, entity Resolution, link prediction and I'll spend.",
                    "label": 1
                },
                {
                    "sent": "The link prediction I won't spend as much time on, but I'll.",
                    "label": 0
                },
                {
                    "sent": "Probably spend the most time on entity resolution just because that's the thing that my group has done a lot of work on and talk some about collective classification, because again, I think the collective classification.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is kind of the poster child link mining algorithm that you know it comes up in so many different guises.",
                    "label": 0
                },
                {
                    "sent": "It's worth talking about.",
                    "label": 0
                },
                {
                    "sent": "So the problem.",
                    "label": 0
                },
                {
                    "sent": "So this is my cartoon kind of explanation of the problem so.",
                    "label": 1
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Traditional machine learning classification.",
                    "label": 0
                },
                {
                    "sent": "Statistical inference.",
                    "label": 0
                },
                {
                    "sent": "First off, they tend to make a very strong assumption that you have.",
                    "label": 0
                },
                {
                    "sent": "Training data the training data is completely separate from the test data.",
                    "label": 1
                },
                {
                    "sent": "The training data is drawn by random sample.",
                    "label": 0
                },
                {
                    "sent": "Independent.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "What you wanna do is you want to.",
                    "label": 0
                },
                {
                    "sent": "Take this training data and here.",
                    "label": 0
                },
                {
                    "sent": "The pinkish purple nodes are supposed to be the features, the attributes.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I'm going to take these attributes and learn a predictive model for some output variable where here I've shown it as a blue node.",
                    "label": 0
                },
                {
                    "sent": "And so it's going to be a conditional classifier that will tell me the probability of a particular value for Y.",
                    "label": 0
                },
                {
                    "sent": "Particular label for a node given the attribute values, and again I'm going to be.",
                    "label": 0
                },
                {
                    "sent": "I'm not agnostic as in terms of the functional form, but there's various statistical techniques that would do that, and so I do this on my training data.",
                    "label": 0
                },
                {
                    "sent": "And then I take this thing that I estimated an I apply it to my test data and in the test data I should have shown this more.",
                    "label": 0
                },
                {
                    "sent": "Clearly in the test data I don't.",
                    "label": 0
                },
                {
                    "sent": "I'm not give her.",
                    "label": 0
                },
                {
                    "sent": "I'll pretend like I just have the attribute values and I'll see how well this model does at predicting the Y value, and then I'll count.",
                    "label": 0
                },
                {
                    "sent": "You know, how many did I get right?",
                    "label": 0
                },
                {
                    "sent": "How many did I get wrong, or various other measures?",
                    "label": 0
                },
                {
                    "sent": "So this is the kind of.",
                    "label": 0
                },
                {
                    "sent": "You know classic view of machine learning, supervised learning, so any questions about the initial setup.",
                    "label": 0
                },
                {
                    "sent": "OK, so this.",
                    "label": 0
                },
                {
                    "sent": "Now we're going to complicate things.",
                    "label": 0
                },
                {
                    "sent": "We're going to add in links.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What does this do to the standard algorithm?",
                    "label": 0
                },
                {
                    "sent": "Well, now the fact that I have links between the objects.",
                    "label": 0
                },
                {
                    "sent": "Most often that's going to imply that there's a correlation.",
                    "label": 0
                },
                {
                    "sent": "Um, the most common one is called auto correlation, so things that.",
                    "label": 0
                },
                {
                    "sent": "Are linked.",
                    "label": 0
                },
                {
                    "sent": "Are likely to have the same label now.",
                    "label": 1
                },
                {
                    "sent": "This is the basis behind, you know many many forms of you know.",
                    "label": 0
                },
                {
                    "sent": "Propagation in networks.",
                    "label": 0
                },
                {
                    "sent": "You know we're friends, so we're likely to like the same music.",
                    "label": 0
                },
                {
                    "sent": "We're friends, so we like the same restaurants, and I mean you can argue with these, whether they're correct or not, but there are tons of domains where this actually works surprisingly well, and so you can do something.",
                    "label": 0
                },
                {
                    "sent": "Like the mode propagation or the majority neighbor propagation, and that works well.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing is the correlation.",
                    "label": 0
                },
                {
                    "sent": "It could be.",
                    "label": 0
                },
                {
                    "sent": "Because.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If things are linked then they are likely to have the same label, but there's another variation, moffly, which is more.",
                    "label": 0
                },
                {
                    "sent": "The still ends up introducing correlations the same way, but it says that, oh, there's more likely to be a link by the fact that.",
                    "label": 0
                },
                {
                    "sent": "The values are the same, so.",
                    "label": 0
                },
                {
                    "sent": "Either.",
                    "label": 0
                },
                {
                    "sent": "Because I'm friends with someone, I'm likely to have similar taste or because we have similar taste, we're more likely to be friends.",
                    "label": 0
                },
                {
                    "sent": "The causal, like what causes what is different, but the underlying statistical correlations are the same.",
                    "label": 0
                },
                {
                    "sent": "So the same algorithms can work.",
                    "label": 0
                },
                {
                    "sent": "It doesn't really matter, so it's only when you get to like marketing and viral marketing kinds of things and so on, where sometimes the causality is important so.",
                    "label": 0
                },
                {
                    "sent": "This is the first change when you go from kind of vanilla statistical inference to inference in networks.",
                    "label": 0
                },
                {
                    "sent": "You have these links.",
                    "label": 0
                },
                {
                    "sent": "There's going to be correlations.",
                    "label": 0
                },
                {
                    "sent": "You should be smart about them.",
                    "label": 0
                },
                {
                    "sent": "Oftentimes the correlations are these kind of similar like I'm linked to similar things, but they don't have to be.",
                    "label": 0
                },
                {
                    "sent": "It could be that you know.",
                    "label": 0
                },
                {
                    "sent": "I linked to things of opposite type, so if you look in the.",
                    "label": 0
                },
                {
                    "sent": "Like the web KB data set you know professors never linked to other professor pages they link to student pages, but they won't link to professor pages, so you can capture that in these kinds of models.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have to be as simple as correlations, so that's a kind of disassortative relationship potentially.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Other thing you wanna do when you go to?",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Collective classification in link domains is deal with the fact that you may have irregular graph structure and that's kind of what I was getting to before with the computing the features, and I guess I'm going to actually repeat that.",
                    "label": 1
                },
                {
                    "sent": "But you know now each of the things each of the objects I'm trying to classify could have different numbers of features.",
                    "label": 0
                },
                {
                    "sent": "So how do I deal with that?",
                    "label": 0
                },
                {
                    "sent": "And then the.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Issue that I may actually have links that cross the training data and the test data and so the interesting thing about that is from a statistical inference perspective.",
                    "label": 1
                },
                {
                    "sent": "It's like this is a big no no.",
                    "label": 0
                },
                {
                    "sent": "It's like they're supposed to be completely separate.",
                    "label": 0
                },
                {
                    "sent": "They're supposed to be independent, and you know some of the early work.",
                    "label": 0
                },
                {
                    "sent": "It would drop the links if there were links because they didn't want to violate this assumption and or work really hard to make sure that there were no length.",
                    "label": 0
                },
                {
                    "sent": "But the reality is that those links convey a lot of information, so if you can manage to have a statistical model that correctly makes use of the links between the training set and the test set, I mean you should do it because you're going to get the best information possible, and this is kind of this is a broad area in machine learning, so even transductive inference is kind of exploiting this fact, but it's something important to think about.",
                    "label": 1
                },
                {
                    "sent": "Um, so the general problem and relational classification is just that you want to.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Predict as I said before, the label of an object based on attributes of the object but also attributes in.",
                    "label": 0
                },
                {
                    "sent": "The links to the object and the things that are linked to the object into things that are linked to the link.",
                    "label": 0
                },
                {
                    "sent": "Things that are linked and so on.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And then collective classification.",
                    "label": 0
                },
                {
                    "sent": "Is the notion of kind of propagating these things so that these things depend on each other and there's been a lot of work in recent years on this.",
                    "label": 0
                },
                {
                    "sent": "And, you know, here's a list of some of the people I'm sure this isn't completely exhaustive, but some of the people looking at it in kind of this general framework of combining probabilistic and logical inference for doing this.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Again, this is the same example as before trying to highlight the multi.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Relational aspect of this example.",
                    "label": 0
                },
                {
                    "sent": "The papers and authors and institutes.",
                    "label": 0
                },
                {
                    "sent": "And now let me something that I didn't emphasize before is.",
                    "label": 0
                },
                {
                    "sent": "The different kinds of links you can have, so we talked about citation links.",
                    "label": 0
                },
                {
                    "sent": "But once you have citation links, you can kind of start constructing other kinds of links that are often useful.",
                    "label": 0
                },
                {
                    "sent": "For example, Co citation.",
                    "label": 0
                },
                {
                    "sent": "The fact that.",
                    "label": 0
                },
                {
                    "sent": "Which one?",
                    "label": 0
                },
                {
                    "sent": "The P3 sites, both P1 and P4.",
                    "label": 0
                },
                {
                    "sent": "It turns out that Co citation is actually a very useful relation to make use of in doing prediction of topics in bibliographic domains.",
                    "label": 0
                },
                {
                    "sent": "It's actually more useful than the sites relation or the cited relation.",
                    "label": 0
                },
                {
                    "sent": "So in order to do it, you actually have to infer it from 2 links.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Ann again you can have author of an affiliation and then in the example that I'm I'm going to continue using this example, but I changed the colors so that in this example I'm saying there's three different possible topics for the papers and the labels are.",
                    "label": 0
                },
                {
                    "sent": "Light pink darker pink or purple and blue.",
                    "label": 0
                },
                {
                    "sent": "So I have those three possible labels.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And specifically, in terms of feature construction for collective classification.",
                    "label": 0
                },
                {
                    "sent": "There's a number of works and a number of theses on this so.",
                    "label": 0
                },
                {
                    "sent": "Sasha Popescu with Lyle Anger did his thesis on feature construction for these kinds of models and also Claudia Perlick any of this standard things like.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Count Min, Max.",
                    "label": 0
                },
                {
                    "sent": "Actually something that we've used.",
                    "label": 0
                },
                {
                    "sent": "Is the proportion of neighbors that have different labels.",
                    "label": 0
                },
                {
                    "sent": "That exists, and then, as I said before, you could have a way of selecting the nodes.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And again we.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This issue of.",
                    "label": 0
                },
                {
                    "sent": "Instances versus generics or classes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Of some of the.",
                    "label": 0
                },
                {
                    "sent": "Existing",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work out there in this space.",
                    "label": 0
                },
                {
                    "sent": "You this is to give you a little bit of the sense of the kinds of features that people use so.",
                    "label": 0
                },
                {
                    "sent": "Mode is definitely one of the most commonly used one.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Using Arbitrary 1st order logic, you know there has been some work that does feature constructed construction using this, but I would say that is a place where the surface has been barely scratched in terms of doing that, and even SQL.",
                    "label": 0
                },
                {
                    "sent": "You know there's some work that did that.",
                    "label": 0
                },
                {
                    "sent": "But I.",
                    "label": 0
                },
                {
                    "sent": "For now, people have been sticking with these kind of simpler features.",
                    "label": 0
                },
                {
                    "sent": "So this is a space that I think is wide open.",
                    "label": 0
                },
                {
                    "sent": "Doing this in a kind of principled, more principled way.",
                    "label": 0
                },
                {
                    "sent": "SQL is a database query language, so being able to specify features using just SQL 1st order logic fols is first order logic, so they're much more expressive ways of constructing features than just doing something like.",
                    "label": 0
                },
                {
                    "sent": "You know mode or most common label.",
                    "label": 0
                },
                {
                    "sent": "Tables pictures of the.",
                    "label": 0
                },
                {
                    "sent": "Yeah, sorry I'm I'm condensing that a fair amount so the assumption is using SQL you're actually constructing arbitrary database queries over the tables that can have joins and selects an group buys and so on to construct features that will go into a classifier.",
                    "label": 0
                },
                {
                    "sent": "And to be honest, the thing that is interesting about this is right now machine learning algorithms you have to do so much feature engineering before hand.",
                    "label": 0
                },
                {
                    "sent": "But that's all outside of the kind of theory.",
                    "label": 0
                },
                {
                    "sent": "But it's really where we spend all our time so.",
                    "label": 0
                },
                {
                    "sent": "At least making the feature construction more declarative so the algorithm could search over the feature space a little bit more I think is hugely important.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "And actually, we're trying to make some steps towards doing that in these kinds of algorithms.",
                    "label": 0
                },
                {
                    "sent": "But at this point it's still more of a black art.",
                    "label": 0
                },
                {
                    "sent": "It's more like OK. Maybe I'll join table so I'll do.",
                    "label": 0
                },
                {
                    "sent": "Neighbor of neighbor of and so on.",
                    "label": 0
                },
                {
                    "sent": "That's something you can do automatically, but if you start having you know owl representation and then using the owl representation for constructing features.",
                    "label": 0
                },
                {
                    "sent": "Um, OK, so these are about the features, but now about the different formulations.",
                    "label": 0
                },
                {
                    "sent": "I'm gonna give you kind of a.",
                    "label": 0
                },
                {
                    "sent": "10,000.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Foot level view of the different algorithms, so the different algorithms tend to fall into.",
                    "label": 0
                },
                {
                    "sent": "Two camps which I'm gonna call and realize that I'm making up the terminology for this.",
                    "label": 0
                },
                {
                    "sent": "Local models and global models, so a local model is some collection of.",
                    "label": 1
                },
                {
                    "sent": "Classifiers that can kind of propagate information and they do it in different ways.",
                    "label": 0
                },
                {
                    "sent": "They tend to have kind of the.",
                    "label": 0
                },
                {
                    "sent": "The notion which maybe has already been built in, and some of my description that.",
                    "label": 0
                },
                {
                    "sent": "You have more of a directed model, so it's conditioned on the features I'm going to predict the label versus global models tend to be full probability distributions over all of the labels in the graph, and all of the attributes.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "The most common one used by far is a pairwise Markov random field or other form of Markov random field, but there's other ones.",
                    "label": 0
                },
                {
                    "sent": "The key thing that makes it global is the fact that you have this full probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Once you have a full probability distribution.",
                    "label": 0
                },
                {
                    "sent": "That gives you nice things you can fill in the missing values for attributes and do proper probabilistic reasoning.",
                    "label": 0
                },
                {
                    "sent": "It also has some drawbacks.",
                    "label": 0
                },
                {
                    "sent": "There is a lot of work showing that in many cases the more what's called discriminative algorithms.",
                    "label": 0
                },
                {
                    "sent": "The local models can be more accurate, which kind of makes sense.",
                    "label": 0
                },
                {
                    "sent": "So there's this tradeoff and.",
                    "label": 0
                },
                {
                    "sent": "Just again to get you give you a sense of the different kinds of algorithms that people have used.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So of the main ones there's mean field, which is the kind of simplest.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mean field relaxation labeling?",
                    "label": 0
                },
                {
                    "sent": "That's kind of a really simple global model loopy belief propagation.",
                    "label": 0
                },
                {
                    "sent": "An is a more general method.",
                    "label": 0
                },
                {
                    "sent": "There's.",
                    "label": 0
                },
                {
                    "sent": "Something which I will go into more detail, iterative classification algorithm, ICA and Gibbs sampling.",
                    "label": 1
                },
                {
                    "sent": "So Gibbs sampling is a very general method.",
                    "label": 0
                },
                {
                    "sent": "So it actually you can use Gibbs sampling when you have local models or global models but.",
                    "label": 0
                },
                {
                    "sent": "This gives you a say.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once you know everybody is using different algorithms, initially nobody was comparing algorithms, at least.",
                    "label": 0
                },
                {
                    "sent": "Finally, some people at the bottom are doing more than one and comparing them.",
                    "label": 0
                },
                {
                    "sent": "And to get into a little bit more detail of ICA.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of collection of local classifier.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The different local classifiers people use include.",
                    "label": 0
                },
                {
                    "sent": "I. NB which is naive Bayes, LR is logistic regression.",
                    "label": 0
                },
                {
                    "sent": "DT is decision she is.",
                    "label": 0
                },
                {
                    "sent": "KNN is key.",
                    "label": 0
                },
                {
                    "sent": "Nearest neighbors an this WVRN is weighted nearest neighbors.",
                    "label": 0
                },
                {
                    "sent": "So that's the one that is take the majority label of your neighbors and propagated.",
                    "label": 0
                },
                {
                    "sent": "So again, this shows it a lot of people are using Naive Bayes.",
                    "label": 0
                },
                {
                    "sent": "An naive Bayes is actually doesn't make our at least our experiences that logistic regression works way better than Naive Bayes, and it makes sense.",
                    "label": 0
                },
                {
                    "sent": "You have bunch of conditional models.",
                    "label": 0
                },
                {
                    "sent": "Naive Bayes is a generative model, full probabilistic generative model.",
                    "label": 0
                },
                {
                    "sent": "It might not be the best thing, but it's nice because it's easy and it is.",
                    "label": 0
                },
                {
                    "sent": "Kind of more complex than just doing the majority neighbor so this.",
                    "label": 0
                },
                {
                    "sent": "All of the ones besides the weighted vote.",
                    "label": 0
                },
                {
                    "sent": "Um neighbor.",
                    "label": 0
                },
                {
                    "sent": "Do allow you to learn arbitrary dependencies so it doesn't have to be that you know Green label is likely to be next to a green label.",
                    "label": 0
                },
                {
                    "sent": "It could be a green labels likely to be next to a red label, and so on, and you know it will use the training set to figure that out.",
                    "label": 0
                },
                {
                    "sent": "Um, but let me try and give you a little bit more sense of.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The ICA.",
                    "label": 0
                },
                {
                    "sent": "The idea is.",
                    "label": 0
                },
                {
                    "sent": "So this is the iterative collective.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Approach to doing the node labeling so the idea is you start up somebody gives you a fully labeled data set from this fully labeled data set, fully labeled training set.",
                    "label": 1
                },
                {
                    "sent": "I'm going to learn local classifier now.",
                    "label": 0
                },
                {
                    "sent": "When I'm doing it.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In France, this is on my test graph where I don't have any labels.",
                    "label": 0
                },
                {
                    "sent": "I'm actually going to make use of two classifiers that I learned from the training data.",
                    "label": 0
                },
                {
                    "sent": "I'm going to learn one classifier that only used the information from the object.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to take that and bootstrap the labeling of these using just that information.",
                    "label": 0
                },
                {
                    "sent": "So if it's papers I'm going to just use the words that appeared in the paper to predict the labels for the nodes.",
                    "label": 0
                },
                {
                    "sent": "And from that I'm going to get this initial assignment.",
                    "label": 0
                },
                {
                    "sent": "Of topics.",
                    "label": 0
                },
                {
                    "sent": "And now once I have those, then I'm going to take the second classifier that I learned or the second classifier uses the objects, the attributes of the objects, but then also the neighbor information, the labels of the neighbors.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to iteratively now update the labels.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I know there's variations on this, but this is the most vanilla version that I start.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If I do a bootstrap labeling just based on local information or the attributes, then I start doing this propagation where the propagation kind of looks at the in Ferd labels.",
                    "label": 0
                },
                {
                    "sent": "And keeps iterating.",
                    "label": 0
                },
                {
                    "sent": "And then you know.",
                    "label": 0
                },
                {
                    "sent": "The question is, you know it was nice and my animation, it converged after 2 iterations so.",
                    "label": 0
                },
                {
                    "sent": "Figuring out when you've reached convergence, whether you can prove anything about whether you reach convergence, all of those are somewhat open questions, so.",
                    "label": 0
                },
                {
                    "sent": "I can say a little bit more about it in practice in a second.",
                    "label": 0
                },
                {
                    "sent": "Um and so.",
                    "label": 0
                },
                {
                    "sent": "OK, so just to give you a sense of some comparison.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to compare.",
                    "label": 0
                },
                {
                    "sent": "Actually, I think I have all four of them on the next slide of the different algorithms.",
                    "label": 0
                },
                {
                    "sent": "I only really told you in detail about the ICA algorithm.",
                    "label": 0
                },
                {
                    "sent": "She collections or two setups.",
                    "label": 0
                },
                {
                    "sent": "One is unreal data, which is again like I said, we're academics, it's bibliographic data.",
                    "label": 0
                },
                {
                    "sent": "So Cora and sites here are two different computer science citation collections that have topics and then web KB.",
                    "label": 0
                },
                {
                    "sent": "So a lot of people here know and love web KB, but it's a data set that was constructed at CMU.",
                    "label": 0
                },
                {
                    "sent": "Probably a 98, so it's a small data set of web pages that are labeled according to whether or not the web page is.",
                    "label": 0
                },
                {
                    "sent": "Student web page.",
                    "label": 0
                },
                {
                    "sent": "Professor webpage.",
                    "label": 0
                },
                {
                    "sent": "At course.",
                    "label": 0
                },
                {
                    "sent": "Web page.",
                    "label": 0
                },
                {
                    "sent": "Um project page.",
                    "label": 0
                },
                {
                    "sent": "There were like 5.",
                    "label": 0
                },
                {
                    "sent": "To 7 labels on this.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So on synthetic data.",
                    "label": 0
                },
                {
                    "sent": "So the interesting thing.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "We have our different algorithms and our different datasets.",
                    "label": 0
                },
                {
                    "sent": "And unfortunately, and this is accuracy, no.",
                    "label": 0
                },
                {
                    "sent": "Actually this is F1.",
                    "label": 0
                },
                {
                    "sent": "Sorry, which is a measure that combines together the that summarizes the performance.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We see that.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, there's no clear winner, so one data set.",
                    "label": 0
                },
                {
                    "sent": "One algorithm works better, another data set, another algorithm works better.",
                    "label": 0
                },
                {
                    "sent": "An actually if you want more details about the algorithms.",
                    "label": 0
                },
                {
                    "sent": "I didn't go over this AI Magazine article does describe have the code and the formulas for the different algorithms.",
                    "label": 0
                },
                {
                    "sent": "But one thing that I should note is.",
                    "label": 0
                },
                {
                    "sent": "You know when we were doing these algorithms, um?",
                    "label": 0
                },
                {
                    "sent": "The probabilistic algorithm there there was.",
                    "label": 0
                },
                {
                    "sent": "There tended to be much more issues with convergence, so like if you had the right parameter settings and the right.",
                    "label": 0
                },
                {
                    "sent": "Regularization parameter and so on.",
                    "label": 0
                },
                {
                    "sent": "Then you could get it to work, but then half the time it won't work versus ICA in general you know it.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit less theoretically motivated, but it tends to be something that you know.",
                    "label": 0
                },
                {
                    "sent": "Wood.",
                    "label": 0
                },
                {
                    "sent": "Yeah you could.",
                    "label": 0
                },
                {
                    "sent": "It would converge after 5 or 10 iterations.",
                    "label": 0
                },
                {
                    "sent": "It wasn't as sensitive to the various parameter settings an, so we were really interested to try, and you know how do you characterize like win, which to use which algorithm?",
                    "label": 0
                },
                {
                    "sent": "And unfortunately I would have to say we still don't have a really clear answer, but here's some result.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is on synthetic data an it's synthetic data, or it's a very simple setup where we are assuming that there is this kind of auto correlation among labels and then we're varying the underlying.",
                    "label": 0
                },
                {
                    "sent": "Link density, so how many edges are the degree of each node?",
                    "label": 0
                },
                {
                    "sent": "And you see, in low density networks, the clear winner is loopy belief propagation.",
                    "label": 0
                },
                {
                    "sent": "So when you have a.",
                    "label": 0
                },
                {
                    "sent": "Relatively sparse network, loopy belief propagation works fine.",
                    "label": 0
                },
                {
                    "sent": "And then as you go to more and more dense networks, it actually completely.",
                    "label": 0
                },
                {
                    "sent": "Bombs out and.",
                    "label": 0
                },
                {
                    "sent": "In that case you get.",
                    "label": 0
                },
                {
                    "sent": "A better performance by ICA, an Gibbs sampling.",
                    "label": 0
                },
                {
                    "sent": "The line that goes a cross is the one that is just using the content information, so it's not making use of the link information, so you see also that in general.",
                    "label": 0
                },
                {
                    "sent": "Using link information helps, which is good.",
                    "label": 0
                },
                {
                    "sent": "Otherwise I want to spent half an hour telling you about all this, but then it even can get to the point if it's bad enough that the link information can actually do worse than just using the local information attribute information and that actually is something as a research question is really interesting to figure out.",
                    "label": 0
                },
                {
                    "sent": "It's like when should you go through the complexity of doing the relational graph stuff versus when should you just.",
                    "label": 0
                },
                {
                    "sent": "And do the original thing, and that's something we're very interested in.",
                    "label": 0
                },
                {
                    "sent": "Investing.",
                    "label": 0
                },
                {
                    "sent": "For the accuracy.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "It's a probability of there being a link.",
                    "label": 0
                },
                {
                    "sent": "For most graphs.",
                    "label": 0
                },
                {
                    "sent": "Ugly spots for nothing, then looking with propagation would be best or not.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "It's all notes with notes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, um, actually I should check that that that I'm telling you the right thing about the that because that probably isn't right because I know I think.",
                    "label": 0
                },
                {
                    "sent": "First off, you're correct that most networks are sparse.",
                    "label": 0
                },
                {
                    "sent": "But for.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "At least most real world social networks and so on are sparse.",
                    "label": 0
                },
                {
                    "sent": "But there definitely are real world settings where the loopy belief propagation was giving us problems.",
                    "label": 0
                },
                {
                    "sent": "Zero mean.",
                    "label": 0
                },
                {
                    "sent": "I know Lindsey Tolan within the first point on each graph it should, but I think that that is actually off because if it was then they should all do exactly the same as the content only.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Why we add more information?",
                    "label": 0
                },
                {
                    "sent": "Actually, For more information or training data, while the performance goal, Green shouldn't be so bad.",
                    "label": 0
                },
                {
                    "sent": "I can imagine maybe a small you know decreasing internal performance, but I really understand why you can.",
                    "label": 0
                },
                {
                    "sent": "Well, part part of it is because I haven't really explained to you loopy belief propagation algorithm, but loopy belief propagation is known not to work very well in dense graphs.",
                    "label": 0
                },
                {
                    "sent": "Um, so it's it's something.",
                    "label": 0
                },
                {
                    "sent": "I mean, notice it's not happening with the ICA algorithm that I told you about, so it is something special about the way that probabilities are propagated.",
                    "label": 0
                },
                {
                    "sent": "An loopy belief propagation and basically you end up compounding errors as you get to the dense things.",
                    "label": 0
                },
                {
                    "sent": "An I mean to be honest, it's a huge area of research.",
                    "label": 0
                },
                {
                    "sent": "Convergence of these general belief propagation algorithms, and you know we're using a relatively vanilla.",
                    "label": 0
                },
                {
                    "sent": "One here.",
                    "label": 0
                },
                {
                    "sent": "The local malformed better with more data.",
                    "label": 0
                },
                {
                    "sent": "So you have more leaf density.",
                    "label": 0
                },
                {
                    "sent": "You have more local networks.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean that makes a lot of sense, and I think that.",
                    "label": 0
                },
                {
                    "sent": "That is exactly the kind of spirit of the kinds of questions that we'd like to be able to answer more.",
                    "label": 0
                },
                {
                    "sent": "Precisely because being able to say you know when to just use the local information versus when by using the global information it's a bad idea because you already had a good local model versus when your local model is so sparse.",
                    "label": 0
                },
                {
                    "sent": "Or so you know, error ridden that so using this global information helps is exactly the spirit of these.",
                    "label": 0
                },
                {
                    "sent": "But validation.",
                    "label": 0
                },
                {
                    "sent": "Excuse me any other.",
                    "label": 0
                },
                {
                    "sent": "I mean, I'm guessing you know cross validation would be the obvious way to check that.",
                    "label": 0
                },
                {
                    "sent": "I can't think of anything else that will guarantee you somehow local model is good enough, because if you look at the real data set in the back previous light.",
                    "label": 0
                },
                {
                    "sent": "All this is getting 3% more which is not worth it.",
                    "label": 0
                },
                {
                    "sent": "Five years of research.",
                    "label": 0
                },
                {
                    "sent": "Percent.",
                    "label": 0
                },
                {
                    "sent": "How would you know what kind of things would you be using?",
                    "label": 0
                },
                {
                    "sent": "Think about.",
                    "label": 0
                },
                {
                    "sent": "Even the content is good enough.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "We've thought about that problem more in the context of entity resolution, so I can say something about that.",
                    "label": 0
                },
                {
                    "sent": "So it is being able to have some estimate of the inherent.",
                    "label": 0
                },
                {
                    "sent": "Underlying characteristics of the data set in terms of how ambiguous it is at a local level versus how much the relational information helps.",
                    "label": 0
                },
                {
                    "sent": "I do think that you know these real datasets.",
                    "label": 0
                },
                {
                    "sent": "You know, I've been.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Saying their heterogeneous, they're not that heterogeneous, so doing this on real heterogeneous multi relational networks would be much more interesting and have a lot more questions.",
                    "label": 0
                },
                {
                    "sent": "But to be honest, I've actually been trying to find the.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right kind of statistician to ask the question about how would I do a better job of theoretically analyzing this.",
                    "label": 0
                },
                {
                    "sent": "But, you know, we tend to speak such different languages that, so far I haven't found the right one.",
                    "label": 0
                },
                {
                    "sent": "That 'cause I think there is some interesting statistical theory that should be applicable, but I think.",
                    "label": 0
                },
                {
                    "sent": "I don't know the right name for it yet.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "OK so um.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next problem that I want to talk about is entity resolution.",
                    "label": 0
                },
                {
                    "sent": "And let me first stop.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Scribe the problem, so let me motivate it by an.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actual real world data set.",
                    "label": 0
                },
                {
                    "sent": "So this is a data set.",
                    "label": 0
                },
                {
                    "sent": "Co author data set where the nodes are the authors and there's a link between the authors if they coauthored a paper together and the interesting thing about this data set, it was supposedly extensively hand cleaned.",
                    "label": 0
                },
                {
                    "sent": "An it was used for an Infovis challenge in 2004, so but if you start looking at the data.",
                    "label": 0
                },
                {
                    "sent": "A little bit, even though supposedly it was extensively hand cleaned.",
                    "label": 0
                },
                {
                    "sent": "You start saying that there's some kind of serious problems with the data set.",
                    "label": 0
                },
                {
                    "sent": "So maybe visualizing it before doing this data cleaning as an issue.",
                    "label": 0
                },
                {
                    "sent": "So the problem is the original data set looked like this after you do the correct entity resolution.",
                    "label": 0
                },
                {
                    "sent": "So you get this.",
                    "label": 0
                },
                {
                    "sent": "An the problem with this for data analysis and network analysis is anything that any statistic that I computed on this original network is going to be wrong.",
                    "label": 0
                },
                {
                    "sent": "I mean, First off, it's obvious there's a wrong number of nodes, there's around agree there is wrong connectivity, but if I look at it, it's kind of like.",
                    "label": 0
                },
                {
                    "sent": "Oh, here's a big spaghetti mess versus here.",
                    "label": 0
                },
                {
                    "sent": "There's a night tight collaboration structure, so one of the things that I want to emphasize is when you're doing.",
                    "label": 0
                },
                {
                    "sent": "Analysis of graph data network data.",
                    "label": 0
                },
                {
                    "sent": "You really want to do entity resolution before you do anything else, because if you don't, you're not getting the right answers.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And so entity resolution is a problem.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can be seen as this notion that I started off with some collection of.",
                    "label": 0
                },
                {
                    "sent": "References and strings that are in my database.",
                    "label": 0
                },
                {
                    "sent": "So Jonathan Smith, John Smith and so on.",
                    "label": 1
                },
                {
                    "sent": "And then my problem is to take these strings or mentions.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Figure out who the underlying entities are so that I can do, for example, the mapping from the strings to these entities.",
                    "label": 0
                },
                {
                    "sent": "So I need to solve both an identification problem where I figure out that, oh, there's this guy, James Smith.",
                    "label": 0
                },
                {
                    "sent": "And these are the strings.",
                    "label": 0
                },
                {
                    "sent": "These are the aliases for James Smith.",
                    "label": 0
                },
                {
                    "sent": "And then also the disambiguation.",
                    "label": 0
                },
                {
                    "sent": "So I need to be able to figure out that if I have a J. Smith in one place, it's referring to this one entity John Smith and another place I have the string that looks exactly the same, but it's referring to this other guy.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And so typically this can be set up as kind of a pairwise classification prob.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where I'm going to show a little part of the problem where I take each reference?",
                    "label": 0
                },
                {
                    "sent": "In my database and I cross it with all the other references.",
                    "label": 0
                },
                {
                    "sent": "I compute some similarity between them.",
                    "label": 0
                },
                {
                    "sent": "And then I say OK, if the similarities above this threshold, I'll say they're the same.",
                    "label": 0
                },
                {
                    "sent": "And if it's below this threshold, I'll say they're different an the similarity.",
                    "label": 0
                },
                {
                    "sent": "I mean there's lots of string similarities you could use.",
                    "label": 0
                },
                {
                    "sent": "You could use more domain knowledge for constructing the similarity function, But the interesting thing is, once you've set it up as this attribute based decision problem.",
                    "label": 0
                },
                {
                    "sent": "You're always going to come up with these issues.",
                    "label": 0
                },
                {
                    "sent": "Well, actually, the first one happens no matter what you do, so you have to set a threshold.",
                    "label": 0
                },
                {
                    "sent": "And based on this threshold, you're going to be choosing where you are in the precision recall tradeoff.",
                    "label": 0
                },
                {
                    "sent": "But clearly in this setup.",
                    "label": 0
                },
                {
                    "sent": "In one case I've tried to show these by colors from the previous slide where I had the two J. Smith.",
                    "label": 0
                },
                {
                    "sent": "In one case, J. Smith and James Smith are supposed to be the same person.",
                    "label": 1
                },
                {
                    "sent": "In another case, Jay Smith and James Smith are supposed to be different people, and there's no way that you can capture this with just a single threshold.",
                    "label": 0
                },
                {
                    "sent": "So there's going to be this inability to do the disambiguation to figure out in one case, for the same pair you're supposed to say different things.",
                    "label": 0
                },
                {
                    "sent": "And we're going to show how context basically is this thing that helps you do this.",
                    "label": 0
                },
                {
                    "sent": "And then there's this issue of if you've done this pairwise thing, should you perform transitive closure?",
                    "label": 0
                },
                {
                    "sent": "Well, kind of.",
                    "label": 0
                },
                {
                    "sent": "Theoretically you should, but as I'll show in some experimental results, sometimes this is a good thing to do.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's a bad thing to do.",
                    "label": 0
                },
                {
                    "sent": "Um, so instead, you know?",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because the focus of this kind of tutorial is all about using the graph structure, we're going to show how you can use the graph structure to help with this.",
                    "label": 0
                },
                {
                    "sent": "And the key thing.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is those references don't occur in isolation, they often they almost always Co occur in this Co occurrence information can be something that really helps you with doing the identification and disambiguation an you know the one that I'm going to be using for all these examples is the coauthor relation, but you see this in communication on two lists, easylist on emails and so on.",
                    "label": 0
                },
                {
                    "sent": "That information helps you with doing the disambiguation.",
                    "label": 0
                },
                {
                    "sent": "Um Ann.",
                    "label": 0
                },
                {
                    "sent": "Again, this is an area where there's a lot of people doing work.",
                    "label": 0
                },
                {
                    "sent": "You know it's an incredibly important problem.",
                    "label": 0
                },
                {
                    "sent": "It happens all over in computer science.",
                    "label": 0
                },
                {
                    "sent": "It happens for, you know, this intelligent information.",
                    "label": 0
                },
                {
                    "sent": "Analysis, But it happens in computer vision, natural language processing, and a lot of other places.",
                    "label": 0
                },
                {
                    "sent": "Um, and just to kind of make this more concrete.",
                    "label": 0
                },
                {
                    "sent": "So he.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here I'm showing the example from before and the square nodes are the nodes that I'm trying to resolve, so I'm trying to figure out, do those square nodes refer to the same underlying individual or not, and then the way that I drew this graph is.",
                    "label": 0
                },
                {
                    "sent": "I showed the common coauthors in the center.",
                    "label": 0
                },
                {
                    "sent": "And the distinct coauthors on the sides.",
                    "label": 0
                },
                {
                    "sent": "And in this case there are similar names, so if I do edit distance or any fans here string similarity, they look pretty much the same there's.",
                    "label": 1
                },
                {
                    "sent": "Some shared Co authors and it turns out in fact these do refer to the same underlying it.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dividual here's another case where the string similarity again is 1 character difference essentially.",
                    "label": 0
                },
                {
                    "sent": "But you quickly see you know there's no overlap in Co author, and in fact you know these turn out to be distinct, so this is information that can help you with doing the identification and disambiguation, but it starts getting more interesting when you use additional information.",
                    "label": 0
                },
                {
                    "sent": "So first staff.",
                    "label": 0
                },
                {
                    "sent": "If I ever see a link like this or I have a link between two things that I'm trying to resolve, at least in.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The context of Co authors.",
                    "label": 0
                },
                {
                    "sent": "In this case it would be a case where I wouldn't want to resolve them because someone can't be their own coauthor.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "In other demands this this won't necessarily hold, but you can use the fact that Co authors are typically distinct or the example from before that parents and.",
                    "label": 1
                },
                {
                    "sent": "Children are distinct, or that's not exactly it, but.",
                    "label": 0
                },
                {
                    "sent": "But still further the.",
                    "label": 0
                },
                {
                    "sent": "Chal",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Active part of all this is the fact that you actually want to be able to.",
                    "label": 0
                },
                {
                    "sent": "Once I figured out that, say these two Elmendorf references are the same.",
                    "label": 0
                },
                {
                    "sent": "So I figured out that they refer to the same underlying individual.",
                    "label": 0
                },
                {
                    "sent": "Then that gives me additional evidence to infer that the singer references are the same, and so that's very much the thing that I want to do is no longer do this pairwise independent decisions about the resolutions, but.",
                    "label": 0
                },
                {
                    "sent": "As I resolved, one thing had that propagate for resolving other things.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "In the results I'm going to compare an algorithm that just does.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The what I'm going to call naive relational entity resolution that just treats.",
                    "label": 1
                },
                {
                    "sent": "Now the Co authors say as attributes with something that does this.",
                    "label": 1
                },
                {
                    "sent": "You know somewhat more sophisticated collective entity resolution to see if it really makes a difference.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um and then?",
                    "label": 0
                },
                {
                    "sent": "Let me talk about a couple algorithms for doing this.",
                    "label": 0
                },
                {
                    "sent": "I actually will probably just.",
                    "label": 0
                },
                {
                    "sent": "So it's 3:45.",
                    "label": 0
                },
                {
                    "sent": "OK, so then I'll just talk about one.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let me again kind of illustrate it more by.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tune then.",
                    "label": 0
                },
                {
                    "sent": "At least initially.",
                    "label": 0
                },
                {
                    "sent": "So here's a collection of papers that are from sites here and I'm going to focus in on the Johnson References Co.",
                    "label": 0
                },
                {
                    "sent": "Author references, and it turns out that in fact, looking at this date.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that they really are two different Johnson researchers, one of 'em in the UK and the other in the US, and you know.",
                    "label": 0
                },
                {
                    "sent": "These are distinct.",
                    "label": 0
                },
                {
                    "sent": "Both are quite well known.",
                    "label": 0
                },
                {
                    "sent": "So I'm gonna start off with kind of the simplest, most intuitive algorithm for doing relational entity resolution and what we do is we start oph an initial.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "All of these references are distinct, and I'm going to start merging them together when I figure out they refer to the same underlying entity.",
                    "label": 0
                },
                {
                    "sent": "Now I do want to touch on this issue of how do I get this to scale because?",
                    "label": 0
                },
                {
                    "sent": "I don't want to do all N cross N comparisons of the references, so.",
                    "label": 0
                },
                {
                    "sent": "All of the algorithms for doing entity resolution, whether they are pair.",
                    "label": 0
                },
                {
                    "sent": "My is attribute based or relational.",
                    "label": 0
                },
                {
                    "sent": "Start off with a quick step of doing a binning of the references according to which references might be the same.",
                    "label": 0
                },
                {
                    "sent": "Versus which ones are definitely distinct an this is usually use some sort of hash function.",
                    "label": 0
                },
                {
                    "sent": "There's been some, there's been a some work, but I think more could be done about doing this, and I tried to indicate the initial binning by colors on these slides so all the things.",
                    "label": 0
                },
                {
                    "sent": "Initially they're all distinct, but things that are the same shade.",
                    "label": 0
                },
                {
                    "sent": "Like the Reds and Blues, those are in the same bucket, so those I will consider deciding to merge or not versus things that already start off being indistinct buckets like the a hoe and the Johnson.",
                    "label": 0
                },
                {
                    "sent": "Those I've already decided they're two different, there isn't.",
                    "label": 0
                },
                {
                    "sent": "Not the same.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And so this is something that helps to make these entity resolution algorithms scale.",
                    "label": 0
                },
                {
                    "sent": "Something similar is appropriate for link prediction and general.",
                    "label": 0
                },
                {
                    "sent": "So as a first step.",
                    "label": 0
                },
                {
                    "sent": "Say I look based at, you know initially.",
                    "label": 0
                },
                {
                    "sent": "Just the attribute information and I say OK these guys.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "R. Similar enough, I'm going to merge them.",
                    "label": 0
                },
                {
                    "sent": "I figured out that these mentions refer to the same entity now.",
                    "label": 0
                },
                {
                    "sent": "At this point I have some relational information, so when I look at.",
                    "label": 0
                },
                {
                    "sent": "That this references, I say OK, well before you know maybe the names were so common I didn't want to merge them, but now they're very similar names.",
                    "label": 0
                },
                {
                    "sent": "They have one coauthor in common.",
                    "label": 0
                },
                {
                    "sent": "That's enough that all.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Urge them.",
                    "label": 0
                },
                {
                    "sent": "Now for the Johnsons for the Johnsons, I didn't merge them.",
                    "label": 0
                },
                {
                    "sent": "Based on just one coauthor in common, but now I have.",
                    "label": 0
                },
                {
                    "sent": "In one case, 3 coauthors in common.",
                    "label": 0
                },
                {
                    "sent": "In another case, two coauthors in common, so at this point.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to say, OK, yeah, they do refer to the same entity, and then I finally will.",
                    "label": 0
                },
                {
                    "sent": "I will still do this comparison of the two Johnson.",
                    "label": 0
                },
                {
                    "sent": "Entities, but because they don't share any coauthors, then I won't merge them.",
                    "label": 0
                },
                {
                    "sent": "Um, so you can.",
                    "label": 0
                },
                {
                    "sent": "One way of kind of understanding this kind of relational clustering.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is you can view it as comparing different ways of clustering.",
                    "label": 0
                },
                {
                    "sent": "The reference is an.",
                    "label": 0
                },
                {
                    "sent": "In one case you can look at kind of the similarity of the names in each cluster and the.",
                    "label": 0
                },
                {
                    "sent": "Clustering.",
                    "label": 0
                },
                {
                    "sent": "Over here is good because you know the similarity of the names is all very good like, especially if you look at this cluster versus this cluster.",
                    "label": 0
                },
                {
                    "sent": "Um but.",
                    "label": 0
                },
                {
                    "sent": "And this cluster now links to two different clusters versus in this clustering it links to only one.",
                    "label": 0
                },
                {
                    "sent": "So we want to do this kind of trade off of.",
                    "label": 0
                },
                {
                    "sent": "How similar the attributes are versus how similar the relations are or what you're linked to is an kind of put this into general hierarchical agglomerative clustering algorithm.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And so the objective function.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can formulate it a bunch of different ways, this is.",
                    "label": 0
                },
                {
                    "sent": "As the simplest way where we're just doing a linear combination of the similarity of the attribute values and the similarity of the relation neighborhood, and then we'll do a greedy clustering algorithm.",
                    "label": 1
                },
                {
                    "sent": "Basically, look at the difference in this function.",
                    "label": 0
                },
                {
                    "sent": "Find the two clusters that are closest together, merge them.",
                    "label": 0
                },
                {
                    "sent": "Update similarity and continue.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the attribute similarity.",
                    "label": 0
                },
                {
                    "sent": "This wasn't really the focus of our research so much, but a lot of people have studied this, and there's actually a very good.",
                    "label": 0
                },
                {
                    "sent": "Open source implementation of many of the string similarities.",
                    "label": 0
                },
                {
                    "sent": "Dad, William County has done and we used that where it has implementations of soft TF IDF.",
                    "label": 0
                },
                {
                    "sent": "Liechtenstein Jaro, Jaro, Winkler and a number of other kind of standard string similarity measures.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "If you have.",
                    "label": 0
                },
                {
                    "sent": "So strings is the most common thing that you're using, but sometimes you also have attribute information.",
                    "label": 0
                },
                {
                    "sent": "You can combine that in as well, and then when you're doing clustering, there is again a number of different ways you can combine things.",
                    "label": 0
                },
                {
                    "sent": "Whether you do single link, average link or complete link.",
                    "label": 1
                },
                {
                    "sent": "Anne, I'm going.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Skip over these now.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there's the relational.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Similarity, so we compare the attributes.",
                    "label": 0
                },
                {
                    "sent": "Now we need to look at how.",
                    "label": 0
                },
                {
                    "sent": "Similar are the in this domain.",
                    "label": 0
                },
                {
                    "sent": "The Co authors of the references and notice that that's actually a multiset, so I have two multisets that I'm trying to compare.",
                    "label": 0
                },
                {
                    "sent": "And you could consider the neighborhood directly as a multi set and do the matching across a multi set and so on.",
                    "label": 0
                },
                {
                    "sent": "Fortunately that's really expensive.",
                    "label": 0
                },
                {
                    "sent": "We thought it was the right thing to do when we first did it it actually.",
                    "label": 0
                },
                {
                    "sent": "You don't have to do that, you can just collapse the multi set on to a set and.",
                    "label": 0
                },
                {
                    "sent": "Do any of the standard set similarity measures, like counting the number of common neighbors or more commonly used jaccard's coefficient, where you normalize by the size of the Union?",
                    "label": 1
                },
                {
                    "sent": "We also tried doing things like higher order similarity like neighbors of Neighbors and at least for the problems we looked at that actually didn't help things.",
                    "label": 1
                },
                {
                    "sent": "And so their relational clustering algorithm just is the same as.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Regular hierarchical clustering except for we have this first step of doing the blocking which is doing the binning and then the other thing that's different is when I do the merge.",
                    "label": 0
                },
                {
                    "sent": "I actually have to update the similarity of anything that is linked to these things and that is a subtle difference between that an other clustering algorithms.",
                    "label": 0
                },
                {
                    "sent": "So you just have to be efficient about being able to look up which things you have to update the similarity for.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we also did a probabilistic model, and again, this is the difference between a local model versus a global model.",
                    "label": 0
                },
                {
                    "sent": "Given time, I'm not going to go into much detail about.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The key thing is.",
                    "label": 0
                },
                {
                    "sent": "It really models how the references the collaborations are generated, and it can discover this and discovering this from data is actually a useful thing.",
                    "label": 0
                },
                {
                    "sent": "It's also somewhat challenging thing so.",
                    "label": 0
                },
                {
                    "sent": "It's based on one of these LDA.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Models which are popular in text classification, we made some modifications for doing it for entity resolution, and I guess the slides have more details.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Any generative model.",
                    "label": 0
                },
                {
                    "sent": "The nice thing is you can then just throw in Gibbs sampling.",
                    "label": 0
                },
                {
                    "sent": "The problem is just throwing in Gibbs sampling takes a really long time, so actually the part that was our research was how to make it more efficient an this was.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doing a kind of block sampling for entity resolution, which was interesting, let me get to the.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Experimental evaluation",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "So we compared three different citation datasets sites here, which is a computer science papers machine learning papers archive, which is a collection of high energy physics papers and.",
                    "label": 1
                },
                {
                    "sent": "This bio base, which is a collection of biology papers.",
                    "label": 0
                },
                {
                    "sent": "They are varying sizes, so some are pretty small and some get larger.",
                    "label": 0
                },
                {
                    "sent": "Uh, and then our baselines that we compared.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we compared something that used just attributes and we tried to be as smart as possible about how we did the attributes.",
                    "label": 0
                },
                {
                    "sent": "Are attributes with doing transitive closure.",
                    "label": 1
                },
                {
                    "sent": "And this naive relational entity resolution that I mentioned where we made use of the neighbor information and then our evaluation was evaluating pairwise decisions using F1 measure.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "Our results are here.",
                    "label": 0
                },
                {
                    "sent": "The key thing again, I'm starting to speed up to try and finish so the key thing is doing the relational stuff helps, and so that was good.",
                    "label": 0
                },
                {
                    "sent": "Otherwise I want to wasted your time with it.",
                    "label": 0
                },
                {
                    "sent": "And you can look at this paper for more details, but then kind of getting to a similar point we have with the collective classification.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Compare.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Person across the datasets is interesting, so for sites here which is a machine learning data set?",
                    "label": 0
                },
                {
                    "sent": "OK, yeah we're doing a little bit better, but we were already.",
                    "label": 0
                },
                {
                    "sent": "We're doing really well with attributes, so it's like this is a domain that wasn't that ambiguous.",
                    "label": 0
                },
                {
                    "sent": "There was no point in going through all this work, or maybe a little bit of point versus archive so the physics data set OK, that one was.",
                    "label": 0
                },
                {
                    "sent": "You know you got.",
                    "label": 0
                },
                {
                    "sent": "7000 more correct references of 20% error reduction, but it was biobased where you really got a huge reduction by doing this, and So what is it that's different about these datasets?",
                    "label": 0
                },
                {
                    "sent": "What's underlying difficulty of these datasets?",
                    "label": 0
                },
                {
                    "sent": "Why the biobased one was better or this was needed, and so one thing is, this was a challenge problem, so they intentionally made it hard by.",
                    "label": 0
                },
                {
                    "sent": "Removing, or just initialing the first names, so we only have first initial and last name, and then they chose, specifically Asian.",
                    "label": 0
                },
                {
                    "sent": "Bias so Asian names.",
                    "label": 0
                },
                {
                    "sent": "Are more ambiguous when you're just looking at the last name and then they just the fact of biology papers you think of biology papers.",
                    "label": 0
                },
                {
                    "sent": "They have like hundreds of coauthors, or at least 10s of coauthors, so that's a case where the relational information is really going to help you.",
                    "label": 0
                },
                {
                    "sent": "That Co author information is really going to help you, so that was something that we found.",
                    "label": 0
                },
                {
                    "sent": "Governess?",
                    "label": 0
                },
                {
                    "sent": "Um and then?",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To say a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About link prediction.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This again.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When is the?",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The notion of.",
                    "label": 0
                },
                {
                    "sent": "I have maybe some things that I've observed, like some communication relationships.",
                    "label": 0
                },
                {
                    "sent": "Someone emailed their text, messaged and what I'd like to do is.",
                    "label": 0
                },
                {
                    "sent": "I'd like to figure out a more semantic relationship so.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the communication information, can I infer that someone's a manager or someone, or that someone's parent of someone, and so that's the problem and I already mentioned some of the different issues here and then predicting the links is really hard, there's some.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interesting variations like the one that I like that I think is actually interesting application.",
                    "label": 0
                },
                {
                    "sent": "An active is something called leak detection.",
                    "label": 0
                },
                {
                    "sent": "This is a problem where you're sending email you're trying to predict other people you sent to, which is the most likely person that you didn't intend to send the message to.",
                    "label": 0
                },
                {
                    "sent": "So this is called a leak and.",
                    "label": 0
                },
                {
                    "sent": "Is important to discover.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To conclude, one of the things we really want to do, I've described each.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These problems kind of in isolation.",
                    "label": 0
                },
                {
                    "sent": "We really want to kind of chain them all together and have the entity resolution and form the collective classification and so on, and so my group is working on some subset of the problems and trying to kind of combine them together.",
                    "label": 0
                },
                {
                    "sent": "And we're calling that general problem graph identification.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The issues.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are that OK?",
                    "label": 0
                },
                {
                    "sent": "We can have this full probabilistic model that I mentioned in a couple of places, but that is.",
                    "label": 0
                },
                {
                    "sent": "Has a number of issues or we can have combinations of local classifiers you know that has some.",
                    "label": 1
                },
                {
                    "sent": "Other kinds of issues, and so there's a lot of really interesting and challenging research problems.",
                    "label": 1
                },
                {
                    "sent": "I think in doing link mining, right?",
                    "label": 0
                },
                {
                    "sent": "Kind of combining together all this information.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And then a caveat that's definitely worth mentioning.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is in all this link mining.",
                    "label": 0
                },
                {
                    "sent": "There's a privacy issue so.",
                    "label": 0
                },
                {
                    "sent": "Some of what we're trying to do is just understand better theoretically.",
                    "label": 0
                },
                {
                    "sent": "Once you have linked data.",
                    "label": 0
                },
                {
                    "sent": "You know what are the privacy implications and how sensitive should you be to these?",
                    "label": 0
                },
                {
                    "sent": "Kind of the flip side.",
                    "label": 0
                },
                {
                    "sent": "Can we guarantee that you can't do the predictions?",
                    "label": 0
                },
                {
                    "sent": "And we've done a little bit of work in this in the context of predicting links, so a lot of people are interested in this one.",
                    "label": 0
                },
                {
                    "sent": "Obviously the biological data, if you know something about family.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you may be able to infer sensitive data.",
                    "label": 0
                },
                {
                    "sent": "Also search data so once being able to figure out that those two searches were made by the same user may not be something you want to be able to do.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of work in anonymizing search log data that's interesting.",
                    "label": 0
                },
                {
                    "sent": "Also in on line social networks we've looked so.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At attribute disclosure, so you know how much information does joining a group on a social network give away, at least in the data we were looking at, gives away a lot, so it's something to be aware of.",
                    "label": 0
                },
                {
                    "sent": "Again, I'm I'm kind of speeding through this, but definitely feel free to ask me more details offline.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So overall, hopefully I've convinced you that relationships matter, so the links are important.",
                    "label": 1
                },
                {
                    "sent": "The edges in the graph are important.",
                    "label": 0
                },
                {
                    "sent": "The actual structure is important, so understanding the density of the graph and so on has a lot of implications that I don't think we understand yet, but.",
                    "label": 0
                },
                {
                    "sent": "There is a lot of really interesting applications.",
                    "label": 0
                },
                {
                    "sent": "An for example, I think all the last three are all ones that fit very much in a number of EU projects, but in particular and active these all kind of tide together to kind of help the knowledge worker an hopefully.",
                    "label": 0
                },
                {
                    "sent": "I've convinced you while you have to worry about some things like this statistical confidence and privacy, there's a lot of benefits and pay offs.",
                    "label": 1
                },
                {
                    "sent": "And your homework is to figure out all the benefits and pay us for active.",
                    "label": 0
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one minute.",
                    "label": 0
                },
                {
                    "sent": "Earlier.",
                    "label": 0
                },
                {
                    "sent": "About this, hoping say pacification settings.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and you didn't actually have time to talk about that.",
                    "label": 0
                },
                {
                    "sent": "You will talk to you briefly.",
                    "label": 0
                },
                {
                    "sent": "Give a shot.",
                    "label": 0
                },
                {
                    "sent": "Especially in this point.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So much of it is trying to infer.",
                    "label": 0
                },
                {
                    "sent": "Functional.",
                    "label": 0
                },
                {
                    "sent": "Information so.",
                    "label": 0
                },
                {
                    "sent": "I can actually give you a pointer to someone in Maryland.",
                    "label": 0
                },
                {
                    "sent": "Is doing a whole course and network analysis for biology and so there he has a. I was just looking at them another day.",
                    "label": 0
                },
                {
                    "sent": "He has the slides up for the intro and I could give you the pointer for that.",
                    "label": 0
                },
                {
                    "sent": "And so there's there's a lot of different.",
                    "label": 0
                },
                {
                    "sent": "Um problems there.",
                    "label": 0
                },
                {
                    "sent": "I'm guessing if you Google his name it will come up so it's.",
                    "label": 0
                },
                {
                    "sent": "And one of the things that's incredibly interesting about the biological data is so much of the experimental data.",
                    "label": 0
                },
                {
                    "sent": "Is so noisy that you know if you do, just you really need these statistical techniques to be able to deal with it and understand it so.",
                    "label": 0
                },
                {
                    "sent": "Protein protein interaction networks are are known to be famously noisy, and then you know a lot of what is done to deal with.",
                    "label": 0
                },
                {
                    "sent": "That is, you have to control for the experimental conditions so much you don't have very much data, But then some of the work, for example, one of my students is doing is trying to combine together more data sources.",
                    "label": 0
                },
                {
                    "sent": "Under different experimental conditions, but kind of combine them in a robust way so that you can.",
                    "label": 0
                },
                {
                    "sent": "To appropriate classification.",
                    "label": 0
                },
                {
                    "sent": "But yeah, it really is a huge area of doing biological network analysis, and much of it, I think link prediction, collective classification and group discovery are the one and alignment are the big ones there.",
                    "label": 0
                },
                {
                    "sent": "Task.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks Lisa, thanks again.",
                    "label": 0
                }
            ]
        }
    }
}