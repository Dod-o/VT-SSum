{
    "id": "bxeyy36veuadfmdr7m4ntyywmbxb6kvp",
    "title": "Convergence Rates of Inexact Proximal-Gradient Methods for Convex Optimization",
    "info": {
        "author": [
            "Mark Schmidt, Department of Computer Science, University of British Columbia"
        ],
        "published": "Jan. 25, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Optimization Methods->Convex Optimization"
        ]
    },
    "url": "http://videolectures.net/nips2011_schmidt_convex/",
    "segmentation": [
        [
            "So I'm going to start with just motivation and over your contribution.",
            "The goal here is to, for those of you not familiar with proximal gradient methods, to sort of tell you why you should care about this type of method and then briefly overview what the method actually is before we get into our technical results."
        ],
        [
            "So in this talk, we're going to think about this very, very simple problem.",
            "We have a function G of X.",
            "We have function H of X.",
            "We want to optimize their sum.",
            "We're going to assume that both of them are convex, but only the H term is going to be smooth."
        ],
        [
            "So typical example G will be a data fitting term, so this will be like the negative log likelihood in logistic regression or a conditional random field or a smooth support vector machine and H will be some sort of regularizer and the most well studied example is L1 regularised least squares, where you have the X -- B squared and then you have an L1 regularization to."
        ],
        [
            "So for this problem, there's a variety of approaches you."
        ],
        [
            "Think of applying and in some sense the optimal method for black box convex optimization is the subgradient method and this has well known convergence rates.",
            "For convex objectives the error on iteration case can be 1 / sqrt K and for strongly convex it's going to be."
        ],
        [
            "Over K. But proxamol great answer a little bit faster 'cause they're going to use the structure of that problem with it, more so in the convex case you're already at 1 / K, and in the strongly convex case you get an exponential convergence rate.",
            "You get 1 minus gamma where gamma is less than 1 to the power of case we converge."
        ],
        [
            "Is very quickly there's also something called the accelerated proximal gradient methods and that actually gets you an even faster."
        ],
        [
            "Convergence rate.",
            "And the thing I want to emphasize here is that proximal gradient methods for composite optimization have the same convergence rates as gradient methods and accelerated gradient methods for smooth optimization."
        ],
        [
            "So to introduce the proximal gradient method, I'm first going to look at sort of a non standard view of the."
        ],
        [
            "Standard gradient method.",
            "So in the gradient method we have one to minimize a smooth function G of X.",
            "And we're going to use a quadratic bound on G, so we have our function G of XK.",
            "We have the 1st order linear term, and then we have this distance to the previous iteration, and so this is in the previous talk.",
            "This was called a mirror descent style."
        ],
        [
            "Method.",
            "Just by completing the square and multiplying through by Alpha, you can rewrite this as a simple quadratic optimization problem."
        ],
        [
            "And it has the trivial solution given by the well known formula for the gradient descent algorithm.",
            "So we can motivate the proximal gradient algorithm from base."
        ],
        [
            "The same idea, so we're going to talk about the proximal gradient method instead of minimizing smooth."
        ],
        [
            "Geovax, we're minimizing a smooth function plus a non smooth function.",
            "We're still going to make."
        ],
        [
            "Quadratic upper bound on G, but now we're just going to add RH of X, so now we have a upper bound on the global function."
        ],
        [
            "When you do the same manipulation, you get what's called the proximal optimization problem."
        ],
        [
            "And the solution is called the proximal gradient algorithm.",
            "So it's quite similar.",
            "We went from the gradient to the proximal gradient algorithm just by sort of adding the H term inside our bound."
        ],
        [
            "So an important special case are projected gradient methods.",
            "So if your H of X function is zero when you're inside some convex set and it's Infinity when you're outside the set, then you get projected gradient methods especially."
        ],
        [
            "Face.",
            "So this is a little cartoon I have.",
            "We've drawn the contours of some function here and then we've got a feasible set, denoted here, and we're at some iteration XK."
        ],
        [
            "So we take our gradient step.",
            "We're going orthogonal to the level curves of the function with some step size.",
            "That's the first part, and then the proximal step."
        ],
        [
            "Is the projection onto the set, so you want to find the closest point inside the feasible set to the steps that you've taken, and that's the proximal step."
        ],
        [
            "And then you take that step.",
            "And we have a little demo of this prepared by Mr Arguillo Moshinsky.",
            "Then I'm going to show you to hopefully better illustrate the point.",
            "Alright.",
            "Maybe we should watch that one more time.",
            "I really like young shorts.",
            "Here.",
            "No, it's not going to go again."
        ],
        [
            "Sorry you have to come to the poster to see the shorts.",
            "Alright, another important special cases iterative soft thresholding.",
            "So in this case H of X is the L1 regularizer."
        ],
        [
            "And in this case, the proximal operator is very simple.",
            "You shrink the absolute value of each variable by the minimum of its absolute value and the step length."
        ],
        [
            "Times the regularization constant, so we can draw a similar picture of that we've got RN."
        ],
        [
            "OK, we take our gradient step with respect to Geo."
        ],
        [
            "Max.",
            "And then in this court we shrink along each coordinate.",
            "So this coordinate is actually bigger than Alpha K times Lambda, so it just gets shrunk and this one is smaller.",
            "So it gets set to exactly 0 and this is a very nice property of the proximal gradient methods, because unlike a lot of competing methods like smoothing methods mentioned Lagrangian here you want sparse solutions in the algorithm actually gives you."
        ],
        [
            "Doctors are solutions.",
            "So that's the proximal step, and Mademoiselle Caitlin is going to give us a little demonstration of this algorithm."
        ],
        [
            "To be sure, we watched that again.",
            "Alright, so the point of size here.",
            "Proxamol grading methods have the same convergence rate as grade."
        ],
        [
            "Methods for smooth optimization for smooth optimization, we know that we can use Nesterov's algorithm to add an even faster rate, so this is a very simple variant on the gradient descent algorithm.",
            "We have this extra momentum or heavy ball step and we choose those beta case to give us a."
        ],
        [
            "Faster rate and for concept problems, the accelerated version is very simple.",
            "We just take the proxy."
        ],
        [
            "Here.",
            "So the question.",
            "So this seems really nice.",
            "We can get these fast convergence rates with a very simple algorithm, but of course we need to compute."
        ],
        [
            "Proximity operator, so there's a bunch of cases where we can compute it.",
            "The most famous is like L1 regularization and lower upper bounds on the variables, but there's also a few other cases like group L1 and simplex consed."
        ],
        [
            "Hanson Euclidean cone.",
            "But for a lot of problems we can't officially compute that proximity operator either.",
            "We know how to compute analytically, but it's very expensive or we just don't have an ad."
        ],
        [
            "Other way to compute it?",
            "But"
        ],
        [
            "There's a lot of problems where we can efficiently approximate the proximity operator, so this includes a lot of things that are of interest to the NIPS community, so we've got total variation, regularization, and things like graph data Fusion, fused lasso, nuclear norm regularization, another singular value regularizers, what got me interested in these methods is the overlapping group L1 with general groups.",
            "But there's also the positive semidefinite cone combinations."
        ],
        [
            "Simple functions, and so because we have these ways to efficiently approximate the proximity operator, the whole bunch of recent work has actually just used inexact proximal gradient methods and showing that."
        ],
        [
            "Actually work really well.",
            "But our question was, are they actually achieving the fast convergence rates that I used to motivate the approximate?"
        ],
        [
            "Gradient methods in the 1st place and the contribution of our paper is that in fact, if you control the errors in an appropriate way, you do get those fast."
        ],
        [
            "Convergence rates, so I'm going to really emphasize the error in the proximity step, but our analysis also lets you have an error in the gradient, and we do a few."
        ],
        [
            "It's two based on the analysis, so first I'm going to very briefly review some related work on inexact."
        ],
        [
            "Rhythms.",
            "So one of the most important ones is proximal gradient methods, where you consider the error to be a zero mean random variable with some sort of."
        ],
        [
            "And on the variance.",
            "But when you make this assumption, it gives you the same slow convergence rates as when you use the subgrade."
        ],
        [
            "Method so our analysis is going to be a little bit different.",
            "We're actually going to consider decreasing sequence of errors and this is going to let us keep the fast convergence rates.",
            "And it's also going to let us apply analysis in the case where the errors are actually deterministic and not random or even adversarially."
        ],
        [
            "A lot of authors have analyzed projected gradient methods."
        ],
        [
            "The fixed error magnitude so that actually gives you the fast convergence rate, but only up to some error."
        ],
        [
            "Magnitude.",
            "So we're going to allow the error magnitude to change on every iterations.",
            "This is actually lead to global convergence, and it's going to let us use a larger error in the early iterations when we're far from the solution."
        ],
        [
            "And some authors have looked at project treatment methods."
        ],
        [
            "Decreasing error magnitudes these were works.",
            "Either don't consider the accelerated version.",
            "They assume you have the exact projection, or they require that."
        ],
        [
            "The domain is compact, so in our work we're not going to make any of those three restrictions.",
            "We're going to consider the accelerator cases.",
            "We're gonna have an exact projection, and we're not going to need to assume that the domain is come back compact.",
            "And finally, we also generalize to the."
        ],
        [
            "Proximal gradient case.",
            "So inexact proximal grade."
        ],
        [
            "Methods are actually been analyzed for a little while in terms of global conversion, so we know that they actually converge under fairly simple assumptions, and this goes all the way back to."
        ],
        [
            "At the mid 90s, but when we wrote this paper, there was no prior work on what the convergence rate of these is."
        ],
        [
            "An exact case.",
            "So I'm now going to introduce our notation and our results."
        ],
        [
            "So repeating our basic problem, we're minimizing a smooth function G of X and a non smooth function H of X.",
            "The basic proximal gradient has this simple."
        ],
        [
            "Form an the accelerated proximal gradient just has an extra momentum step."
        ],
        [
            "And our results are going to rely on sort of a set of standard assumptions.",
            "So first we're going to the GS convex and that its derivative is L Lipschitz continuous, meaning that it doesn't change too quickly as a function of the parameters and for twice differentiable functions this is just a quote to assume that the eigenvalues of the Hessian are between zero and L."
        ],
        [
            "In contrast to that, we're only going to assume that H is a lower semi continuous proper convex function, so if you don't know what that is, that's that's OK.",
            "It just basically includes every real valued convex function, but it also includes some more exotic things like the indicator on convex sets that I showed early."
        ],
        [
            "For the projected grading case.",
            "We're going to assume that there exists some solution X star.",
            "We're going to fix the step size at 1 / L, although that."
        ],
        [
            "Be relaxed, we're going to.",
            "The gradient is computed with some Mary Kay, and whether it's a XC is an epsilon K approximate solution.",
            "The proximity operator in terms of this, and this is a very nice way to analyze the error, because if you have a duality gap on your approximal problem, you can usually check that condition in practice."
        ],
        [
            "So just to repeat the convergence rates from the very first slide, the subgradient method has these rates and the proximal gradient and accelerated proximal gradient have these known rates."
        ],
        [
            "And so our results basically give conditions on the sequence of gradient errors and the proximity errors such that you can get all of these convergence rates."
        ],
        [
            "So the 1st result is for the basic proximal gradient.",
            "If we have these two sequences as summable, then the basic proximal gradient method is going to achieve this 1 / K rate."
        ],
        [
            "At least for the average illiterate.",
            "So for example, we could make those two sequences decrease as 1 / K to the one plus Delta for so."
        ],
        [
            "Positive Delta you could also look at the if you want to make them decreases 1 / K then you get an extra log factor and we give the exact constants in the paper.",
            "If you want to see that."
        ],
        [
            "For the accelerated gradient method, you need to have these two sequences be solvable, so you need the iteration times the error and the iteration times the root of the proximity error to be sellable, and then you get the."
        ],
        [
            "1 / K ^2 rate so they could decrease this one over."
        ],
        [
            "The K plus Delta and again in the extreme case you just get an extra log factor and it's sort of interesting because the analysis indicates that the accelerated method is actually more sensitive to errors because you have to control for the number of iterations there."
        ],
        [
            "So we also considered the."
        ],
        [
            "Only convex case.",
            "So we say that a function is strongly convex if you can.",
            "If G of X minus mu times the norm of X squared is a convex function for some positive mu for twice differentiable functions, this is just equivalent to saying that the eigenvalues are all bigger than mu everywhere."
        ],
        [
            "Some positive mu.",
            "And in this case we can obtain exponential rates for the proximal."
        ],
        [
            "Eating method.",
            "So if we have that these two sequences are bounded above by some linearly convergent sequence with parameter row less than one minus mu over L, then the proximal gradient method gets the same inexact method gets the same convergence."
        ],
        [
            "It is the exact method if they converge with sumrow bigger than that constant then you just get that constant and in the boundary case you get K times the constant which is a linear convergence rate with a slightly faster or slightly."
        ],
        [
            "Slower rate.",
            "And finally, for the accelerated method you need to control if you control these two sequences, you can get this convergence rate with the especially chosen beta.",
            "That depends on you and L."
        ],
        [
            "And we stated this in terms of the function values, but strong convexity implies about on the iterates too, so you also get a convergence rate in terms of how fast theater."
        ],
        [
            "Converge.",
            "So because this is nips, we did some new some experiment."
        ],
        [
            "So we consider this matrix approximate matrix factorization.",
            "So here we want to approximate a matrix W. In terms of a sparse set of rows and columns, so we put a group L1 on the Rosanna Group One on the columns.",
            "So this is."
        ],
        [
            "Overlapping group L1 problem.",
            "So for appropriate choices of this Pinot arm, you get sparse, Rosen, sparse columns, so it's choosing Rosen choosing columns.",
            "So in the previous work that shows P equals Infinity, because there's no known exact algorithm for the more natural case of P = 2, so P equals Infinity forces, the magnitudes of the rows and columns to also be similar, which is not necessarily."
        ],
        [
            "Viable so, but there's a very efficient way to compute approximate proximity operators, so we use the proximal Dijkstra algorithm to compute an approximate proximity operator.",
            "In this case, where there's no exact algorithm and then that algorithm actually gives you duality gap so that you can actually check the condition on your inexactness to ensure you get the converge."
        ],
        [
            "Straight.",
            "So here I'm just showing a sequence 1 / K cube which actually achieves the optimal convergence rate, and then I'm choosing different sequences of solving to affix duality gap on each iteration.",
            "We basically see that if you solve it quickly every time, then you converge fast, but then you sort of bottom out and then the more accurately affixed duality gap you get, the more you sort of keep making progress.",
            "But the adaptive duality gap does even better."
        ],
        [
            "So some authors, instead of using a fixed duality gap, they run the approximate proxy over for a fixed number of iterations, and we see basically the same trend."
        ],
        [
            "Is there?",
            "And here is just comparing different possible rates of decreasing the errors.",
            "Now I'm just showing the results for the gradient method and the results, at least for these datasets, were overwhelmingly clear.",
            "The accelerated graphic grading method was a little bit more messy and you can see the results on the other datasets too.",
            "If you come to the poster."
        ],
        [
            "Look at the paper.",
            "So just a few points of discussion, I think these algorithms might be useful for other applications and total variation in nuclear norm regularization or to the people are already using inexact proximal gradient methods for our analysis let's you have errors in the gradient, so I think that could be useful for a lot of things like undirected graphical models where using TRVP too."
        ],
        [
            "Proximate the log partition.",
            "It would be nice to extend our analysis to have an unknown elenu or to try and adaptively update the errors.",
            "And of course Approximal Newton methods or an application that."
        ],
        [
            "Very interested in and finally between submission and acceptance of this paper and submitting the final version.",
            "Two authors independently analyzed the accelerated proximal gradient method for the case of exact gradient, but in exact proximity for the convex G. So they did one element of."
        ],
        [
            "The table too.",
            "So just to conclude, approximal grading methods are appealing because of their good theoretical and empirical converge."
        ],
        [
            "It's rates, but they require the calculation of that PROC."
        ],
        [
            "Committee operator, so a lot of authors have recently used these methods under inexact proximity."
        ],
        [
            "Operator and we show that you actually preserve the convergence rates if you control that inexactness in an appropriate way.",
            "So thanks a lot for letting me speak.",
            "So, so the question is, does the theory suggest a form of how the epsilon K values decrease and it does?",
            "You basically want to have 1 / K to the Alpha for some Alpha big enough, but our theory doesn't suggest what you want that constants to be in that.",
            "It's problem dependent.",
            "It depends on how fast you can solve the approximate prox.",
            "For sure, so it gets."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to start with just motivation and over your contribution.",
                    "label": 0
                },
                {
                    "sent": "The goal here is to, for those of you not familiar with proximal gradient methods, to sort of tell you why you should care about this type of method and then briefly overview what the method actually is before we get into our technical results.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this talk, we're going to think about this very, very simple problem.",
                    "label": 0
                },
                {
                    "sent": "We have a function G of X.",
                    "label": 0
                },
                {
                    "sent": "We have function H of X.",
                    "label": 0
                },
                {
                    "sent": "We want to optimize their sum.",
                    "label": 0
                },
                {
                    "sent": "We're going to assume that both of them are convex, but only the H term is going to be smooth.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So typical example G will be a data fitting term, so this will be like the negative log likelihood in logistic regression or a conditional random field or a smooth support vector machine and H will be some sort of regularizer and the most well studied example is L1 regularised least squares, where you have the X -- B squared and then you have an L1 regularization to.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for this problem, there's a variety of approaches you.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Think of applying and in some sense the optimal method for black box convex optimization is the subgradient method and this has well known convergence rates.",
                    "label": 0
                },
                {
                    "sent": "For convex objectives the error on iteration case can be 1 / sqrt K and for strongly convex it's going to be.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Over K. But proxamol great answer a little bit faster 'cause they're going to use the structure of that problem with it, more so in the convex case you're already at 1 / K, and in the strongly convex case you get an exponential convergence rate.",
                    "label": 0
                },
                {
                    "sent": "You get 1 minus gamma where gamma is less than 1 to the power of case we converge.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is very quickly there's also something called the accelerated proximal gradient methods and that actually gets you an even faster.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Convergence rate.",
                    "label": 0
                },
                {
                    "sent": "And the thing I want to emphasize here is that proximal gradient methods for composite optimization have the same convergence rates as gradient methods and accelerated gradient methods for smooth optimization.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to introduce the proximal gradient method, I'm first going to look at sort of a non standard view of the.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Standard gradient method.",
                    "label": 0
                },
                {
                    "sent": "So in the gradient method we have one to minimize a smooth function G of X.",
                    "label": 1
                },
                {
                    "sent": "And we're going to use a quadratic bound on G, so we have our function G of XK.",
                    "label": 1
                },
                {
                    "sent": "We have the 1st order linear term, and then we have this distance to the previous iteration, and so this is in the previous talk.",
                    "label": 0
                },
                {
                    "sent": "This was called a mirror descent style.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Method.",
                    "label": 0
                },
                {
                    "sent": "Just by completing the square and multiplying through by Alpha, you can rewrite this as a simple quadratic optimization problem.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it has the trivial solution given by the well known formula for the gradient descent algorithm.",
                    "label": 0
                },
                {
                    "sent": "So we can motivate the proximal gradient algorithm from base.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same idea, so we're going to talk about the proximal gradient method instead of minimizing smooth.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Geovax, we're minimizing a smooth function plus a non smooth function.",
                    "label": 0
                },
                {
                    "sent": "We're still going to make.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quadratic upper bound on G, but now we're just going to add RH of X, so now we have a upper bound on the global function.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When you do the same manipulation, you get what's called the proximal optimization problem.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the solution is called the proximal gradient algorithm.",
                    "label": 1
                },
                {
                    "sent": "So it's quite similar.",
                    "label": 0
                },
                {
                    "sent": "We went from the gradient to the proximal gradient algorithm just by sort of adding the H term inside our bound.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So an important special case are projected gradient methods.",
                    "label": 0
                },
                {
                    "sent": "So if your H of X function is zero when you're inside some convex set and it's Infinity when you're outside the set, then you get projected gradient methods especially.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Face.",
                    "label": 0
                },
                {
                    "sent": "So this is a little cartoon I have.",
                    "label": 0
                },
                {
                    "sent": "We've drawn the contours of some function here and then we've got a feasible set, denoted here, and we're at some iteration XK.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we take our gradient step.",
                    "label": 0
                },
                {
                    "sent": "We're going orthogonal to the level curves of the function with some step size.",
                    "label": 0
                },
                {
                    "sent": "That's the first part, and then the proximal step.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the projection onto the set, so you want to find the closest point inside the feasible set to the steps that you've taken, and that's the proximal step.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you take that step.",
                    "label": 0
                },
                {
                    "sent": "And we have a little demo of this prepared by Mr Arguillo Moshinsky.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to show you to hopefully better illustrate the point.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Maybe we should watch that one more time.",
                    "label": 0
                },
                {
                    "sent": "I really like young shorts.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "No, it's not going to go again.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry you have to come to the poster to see the shorts.",
                    "label": 0
                },
                {
                    "sent": "Alright, another important special cases iterative soft thresholding.",
                    "label": 0
                },
                {
                    "sent": "So in this case H of X is the L1 regularizer.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this case, the proximal operator is very simple.",
                    "label": 0
                },
                {
                    "sent": "You shrink the absolute value of each variable by the minimum of its absolute value and the step length.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Times the regularization constant, so we can draw a similar picture of that we've got RN.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, we take our gradient step with respect to Geo.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Max.",
                    "label": 0
                },
                {
                    "sent": "And then in this court we shrink along each coordinate.",
                    "label": 0
                },
                {
                    "sent": "So this coordinate is actually bigger than Alpha K times Lambda, so it just gets shrunk and this one is smaller.",
                    "label": 0
                },
                {
                    "sent": "So it gets set to exactly 0 and this is a very nice property of the proximal gradient methods, because unlike a lot of competing methods like smoothing methods mentioned Lagrangian here you want sparse solutions in the algorithm actually gives you.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doctors are solutions.",
                    "label": 0
                },
                {
                    "sent": "So that's the proximal step, and Mademoiselle Caitlin is going to give us a little demonstration of this algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To be sure, we watched that again.",
                    "label": 0
                },
                {
                    "sent": "Alright, so the point of size here.",
                    "label": 0
                },
                {
                    "sent": "Proxamol grading methods have the same convergence rate as grade.",
                    "label": 1
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Methods for smooth optimization for smooth optimization, we know that we can use Nesterov's algorithm to add an even faster rate, so this is a very simple variant on the gradient descent algorithm.",
                    "label": 0
                },
                {
                    "sent": "We have this extra momentum or heavy ball step and we choose those beta case to give us a.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Faster rate and for concept problems, the accelerated version is very simple.",
                    "label": 0
                },
                {
                    "sent": "We just take the proxy.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "So the question.",
                    "label": 0
                },
                {
                    "sent": "So this seems really nice.",
                    "label": 0
                },
                {
                    "sent": "We can get these fast convergence rates with a very simple algorithm, but of course we need to compute.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Proximity operator, so there's a bunch of cases where we can compute it.",
                    "label": 0
                },
                {
                    "sent": "The most famous is like L1 regularization and lower upper bounds on the variables, but there's also a few other cases like group L1 and simplex consed.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hanson Euclidean cone.",
                    "label": 0
                },
                {
                    "sent": "But for a lot of problems we can't officially compute that proximity operator either.",
                    "label": 1
                },
                {
                    "sent": "We know how to compute analytically, but it's very expensive or we just don't have an ad.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other way to compute it?",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's a lot of problems where we can efficiently approximate the proximity operator, so this includes a lot of things that are of interest to the NIPS community, so we've got total variation, regularization, and things like graph data Fusion, fused lasso, nuclear norm regularization, another singular value regularizers, what got me interested in these methods is the overlapping group L1 with general groups.",
                    "label": 0
                },
                {
                    "sent": "But there's also the positive semidefinite cone combinations.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simple functions, and so because we have these ways to efficiently approximate the proximity operator, the whole bunch of recent work has actually just used inexact proximal gradient methods and showing that.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually work really well.",
                    "label": 0
                },
                {
                    "sent": "But our question was, are they actually achieving the fast convergence rates that I used to motivate the approximate?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gradient methods in the 1st place and the contribution of our paper is that in fact, if you control the errors in an appropriate way, you do get those fast.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Convergence rates, so I'm going to really emphasize the error in the proximity step, but our analysis also lets you have an error in the gradient, and we do a few.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's two based on the analysis, so first I'm going to very briefly review some related work on inexact.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rhythms.",
                    "label": 0
                },
                {
                    "sent": "So one of the most important ones is proximal gradient methods, where you consider the error to be a zero mean random variable with some sort of.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And on the variance.",
                    "label": 0
                },
                {
                    "sent": "But when you make this assumption, it gives you the same slow convergence rates as when you use the subgrade.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Method so our analysis is going to be a little bit different.",
                    "label": 0
                },
                {
                    "sent": "We're actually going to consider decreasing sequence of errors and this is going to let us keep the fast convergence rates.",
                    "label": 1
                },
                {
                    "sent": "And it's also going to let us apply analysis in the case where the errors are actually deterministic and not random or even adversarially.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A lot of authors have analyzed projected gradient methods.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The fixed error magnitude so that actually gives you the fast convergence rate, but only up to some error.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Magnitude.",
                    "label": 0
                },
                {
                    "sent": "So we're going to allow the error magnitude to change on every iterations.",
                    "label": 1
                },
                {
                    "sent": "This is actually lead to global convergence, and it's going to let us use a larger error in the early iterations when we're far from the solution.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And some authors have looked at project treatment methods.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Decreasing error magnitudes these were works.",
                    "label": 1
                },
                {
                    "sent": "Either don't consider the accelerated version.",
                    "label": 0
                },
                {
                    "sent": "They assume you have the exact projection, or they require that.",
                    "label": 1
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The domain is compact, so in our work we're not going to make any of those three restrictions.",
                    "label": 1
                },
                {
                    "sent": "We're going to consider the accelerator cases.",
                    "label": 0
                },
                {
                    "sent": "We're gonna have an exact projection, and we're not going to need to assume that the domain is come back compact.",
                    "label": 1
                },
                {
                    "sent": "And finally, we also generalize to the.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Proximal gradient case.",
                    "label": 0
                },
                {
                    "sent": "So inexact proximal grade.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Methods are actually been analyzed for a little while in terms of global conversion, so we know that they actually converge under fairly simple assumptions, and this goes all the way back to.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the mid 90s, but when we wrote this paper, there was no prior work on what the convergence rate of these is.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An exact case.",
                    "label": 0
                },
                {
                    "sent": "So I'm now going to introduce our notation and our results.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So repeating our basic problem, we're minimizing a smooth function G of X and a non smooth function H of X.",
                    "label": 0
                },
                {
                    "sent": "The basic proximal gradient has this simple.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Form an the accelerated proximal gradient just has an extra momentum step.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And our results are going to rely on sort of a set of standard assumptions.",
                    "label": 0
                },
                {
                    "sent": "So first we're going to the GS convex and that its derivative is L Lipschitz continuous, meaning that it doesn't change too quickly as a function of the parameters and for twice differentiable functions this is just a quote to assume that the eigenvalues of the Hessian are between zero and L.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In contrast to that, we're only going to assume that H is a lower semi continuous proper convex function, so if you don't know what that is, that's that's OK.",
                    "label": 0
                },
                {
                    "sent": "It just basically includes every real valued convex function, but it also includes some more exotic things like the indicator on convex sets that I showed early.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the projected grading case.",
                    "label": 0
                },
                {
                    "sent": "We're going to assume that there exists some solution X star.",
                    "label": 0
                },
                {
                    "sent": "We're going to fix the step size at 1 / L, although that.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Be relaxed, we're going to.",
                    "label": 0
                },
                {
                    "sent": "The gradient is computed with some Mary Kay, and whether it's a XC is an epsilon K approximate solution.",
                    "label": 1
                },
                {
                    "sent": "The proximity operator in terms of this, and this is a very nice way to analyze the error, because if you have a duality gap on your approximal problem, you can usually check that condition in practice.",
                    "label": 1
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to repeat the convergence rates from the very first slide, the subgradient method has these rates and the proximal gradient and accelerated proximal gradient have these known rates.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so our results basically give conditions on the sequence of gradient errors and the proximity errors such that you can get all of these convergence rates.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the 1st result is for the basic proximal gradient.",
                    "label": 0
                },
                {
                    "sent": "If we have these two sequences as summable, then the basic proximal gradient method is going to achieve this 1 / K rate.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At least for the average illiterate.",
                    "label": 0
                },
                {
                    "sent": "So for example, we could make those two sequences decrease as 1 / K to the one plus Delta for so.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Positive Delta you could also look at the if you want to make them decreases 1 / K then you get an extra log factor and we give the exact constants in the paper.",
                    "label": 0
                },
                {
                    "sent": "If you want to see that.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the accelerated gradient method, you need to have these two sequences be solvable, so you need the iteration times the error and the iteration times the root of the proximity error to be sellable, and then you get the.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1 / K ^2 rate so they could decrease this one over.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The K plus Delta and again in the extreme case you just get an extra log factor and it's sort of interesting because the analysis indicates that the accelerated method is actually more sensitive to errors because you have to control for the number of iterations there.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we also considered the.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Only convex case.",
                    "label": 0
                },
                {
                    "sent": "So we say that a function is strongly convex if you can.",
                    "label": 1
                },
                {
                    "sent": "If G of X minus mu times the norm of X squared is a convex function for some positive mu for twice differentiable functions, this is just equivalent to saying that the eigenvalues are all bigger than mu everywhere.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some positive mu.",
                    "label": 0
                },
                {
                    "sent": "And in this case we can obtain exponential rates for the proximal.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Eating method.",
                    "label": 0
                },
                {
                    "sent": "So if we have that these two sequences are bounded above by some linearly convergent sequence with parameter row less than one minus mu over L, then the proximal gradient method gets the same inexact method gets the same convergence.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is the exact method if they converge with sumrow bigger than that constant then you just get that constant and in the boundary case you get K times the constant which is a linear convergence rate with a slightly faster or slightly.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Slower rate.",
                    "label": 0
                },
                {
                    "sent": "And finally, for the accelerated method you need to control if you control these two sequences, you can get this convergence rate with the especially chosen beta.",
                    "label": 0
                },
                {
                    "sent": "That depends on you and L.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we stated this in terms of the function values, but strong convexity implies about on the iterates too, so you also get a convergence rate in terms of how fast theater.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Converge.",
                    "label": 0
                },
                {
                    "sent": "So because this is nips, we did some new some experiment.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we consider this matrix approximate matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "So here we want to approximate a matrix W. In terms of a sparse set of rows and columns, so we put a group L1 on the Rosanna Group One on the columns.",
                    "label": 1
                },
                {
                    "sent": "So this is.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Overlapping group L1 problem.",
                    "label": 0
                },
                {
                    "sent": "So for appropriate choices of this Pinot arm, you get sparse, Rosen, sparse columns, so it's choosing Rosen choosing columns.",
                    "label": 0
                },
                {
                    "sent": "So in the previous work that shows P equals Infinity, because there's no known exact algorithm for the more natural case of P = 2, so P equals Infinity forces, the magnitudes of the rows and columns to also be similar, which is not necessarily.",
                    "label": 1
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Viable so, but there's a very efficient way to compute approximate proximity operators, so we use the proximal Dijkstra algorithm to compute an approximate proximity operator.",
                    "label": 0
                },
                {
                    "sent": "In this case, where there's no exact algorithm and then that algorithm actually gives you duality gap so that you can actually check the condition on your inexactness to ensure you get the converge.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Straight.",
                    "label": 0
                },
                {
                    "sent": "So here I'm just showing a sequence 1 / K cube which actually achieves the optimal convergence rate, and then I'm choosing different sequences of solving to affix duality gap on each iteration.",
                    "label": 0
                },
                {
                    "sent": "We basically see that if you solve it quickly every time, then you converge fast, but then you sort of bottom out and then the more accurately affixed duality gap you get, the more you sort of keep making progress.",
                    "label": 0
                },
                {
                    "sent": "But the adaptive duality gap does even better.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So some authors, instead of using a fixed duality gap, they run the approximate proxy over for a fixed number of iterations, and we see basically the same trend.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is there?",
                    "label": 0
                },
                {
                    "sent": "And here is just comparing different possible rates of decreasing the errors.",
                    "label": 0
                },
                {
                    "sent": "Now I'm just showing the results for the gradient method and the results, at least for these datasets, were overwhelmingly clear.",
                    "label": 0
                },
                {
                    "sent": "The accelerated graphic grading method was a little bit more messy and you can see the results on the other datasets too.",
                    "label": 0
                },
                {
                    "sent": "If you come to the poster.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at the paper.",
                    "label": 0
                },
                {
                    "sent": "So just a few points of discussion, I think these algorithms might be useful for other applications and total variation in nuclear norm regularization or to the people are already using inexact proximal gradient methods for our analysis let's you have errors in the gradient, so I think that could be useful for a lot of things like undirected graphical models where using TRVP too.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Proximate the log partition.",
                    "label": 0
                },
                {
                    "sent": "It would be nice to extend our analysis to have an unknown elenu or to try and adaptively update the errors.",
                    "label": 1
                },
                {
                    "sent": "And of course Approximal Newton methods or an application that.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very interested in and finally between submission and acceptance of this paper and submitting the final version.",
                    "label": 0
                },
                {
                    "sent": "Two authors independently analyzed the accelerated proximal gradient method for the case of exact gradient, but in exact proximity for the convex G. So they did one element of.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The table too.",
                    "label": 0
                },
                {
                    "sent": "So just to conclude, approximal grading methods are appealing because of their good theoretical and empirical converge.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's rates, but they require the calculation of that PROC.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Committee operator, so a lot of authors have recently used these methods under inexact proximity.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Operator and we show that you actually preserve the convergence rates if you control that inexactness in an appropriate way.",
                    "label": 1
                },
                {
                    "sent": "So thanks a lot for letting me speak.",
                    "label": 0
                },
                {
                    "sent": "So, so the question is, does the theory suggest a form of how the epsilon K values decrease and it does?",
                    "label": 0
                },
                {
                    "sent": "You basically want to have 1 / K to the Alpha for some Alpha big enough, but our theory doesn't suggest what you want that constants to be in that.",
                    "label": 0
                },
                {
                    "sent": "It's problem dependent.",
                    "label": 0
                },
                {
                    "sent": "It depends on how fast you can solve the approximate prox.",
                    "label": 0
                },
                {
                    "sent": "For sure, so it gets.",
                    "label": 0
                }
            ]
        }
    }
}