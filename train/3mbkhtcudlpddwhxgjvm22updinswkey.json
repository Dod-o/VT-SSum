{
    "id": "3mbkhtcudlpddwhxgjvm22updinswkey",
    "title": "Bayesian inference and Gaussian processes",
    "info": {
        "author": [
            "Carl Edward Rasmussen, Max Planck Institute"
        ],
        "published": "Aug. 20, 2007",
        "recorded": "August 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning",
            "Top->Computer Science->Machine Learning->Gaussian Processes"
        ]
    },
    "url": "http://videolectures.net/mlss07_rasmussen_bigp/",
    "segmentation": [
        [
            "OK, good morning.",
            "Um?",
            "I'm going to talk about Bayesian inference and Gaussian process and today of this morning I'm only going to talk about Bayesian inference, so the organizers asked me to talk about.",
            "Based on inference and I think it may be a good idea to talk about Bayesian inference, but I find it I find it quite hard because I think the topic is.",
            "What about at a conceptual level?",
            "You know I'm so it will be easy to talk about Bayesian inference property for a particular model, but that's not run supposed to do right.",
            "I'm just doing.",
            "I'm supposed to talk about Bayesian inference as such, so I'll try and do that and I guess also that your background here also.",
            "Quite different, so some people maybe go over some stuff that you already know, and to some people it will maybe be a little bit tough going, but I'll try to do today.",
            "I'm going to try to focus on.",
            "On on getting across the idea about what is what is Bayesian about Bayesian inference, unfortunately that's a little bit hard to hard to say in a vacuum, right?",
            "So I'll have to contrast it to what other kinds of things one could do, and the easiest way to do this is to contrast classical or frequency statistics with Bayesian statistics.",
            "So I'll be doing.",
            "I'll be doing that a lot.",
            "Um?",
            "So it's also interesting in the statistics community.",
            "There's a big division between people who do things in a basin way, and people who don't do things in a basic way, right?",
            "And this is really a severe.",
            "Cut in the community and people don't talk to each other and they don't go to each other conferences and they don't publish US papers.",
            "And I mean it's very used to be extremely bad and now it's only very bad.",
            "I think it's improving a little bit.",
            "In the machine learning community, people don't seem to be so upset about this particular division.",
            "And as I'll try to explain, it's interesting because the division is actually is actually over very small.",
            "It's a very small point that people are quarreling about right?",
            "They actually using a lot of the same methodology, but there's only there's only sort of 1 little Atom of difference, but that leads to a version of the ways that you think about in France.",
            "Um?",
            "So I I tend to do a lot of Bayesian inference, but I'm also happy about, you know, thinking about other kinds of inference.",
            "Sometimes based inferences has some problems and sometimes it's easier to do things another way, so I'm not.",
            "I'm not particularly hooked on on doing these things, but I think the basic framework gives you some advantages and some things that are really quite easy to do.",
            "Um?",
            "Right, so also there's an interesting distinction historically.",
            "So, so along time ago, everybody will were Bayesians, so there were only basins, and then at some point in their search uses British statistician.",
            "Fisher came around and he had these other ideas about how you could do things.",
            "Any sort of managed to switch the whole field around, so there was no basins around after Fisher and then some basin started appearing again and this sort of interesting that these ideas.",
            "Can we switch around?",
            "That rapidly.",
            "OK, so I'm happy to take questions so so because I don't know exactly what you do and what you know and what you don't know.",
            "You should really stop me if things are sounding mysterious right?",
            "So I'm I'm I'm.",
            "I'm trying to stay with the essence of the idea, so I won't.",
            "I'll try to try to stay away from complicated.",
            "Pieces of mathematics.",
            "So unfortunately, that means that I only consider extremely simple inference problem, right?",
            "Because 'cause I want to stay in a place where we don't have to worry about how to actually compute these things that they should be trivial to compute, right?",
            "So, but tomorrow you'll get some more derivations for your money.",
            "So, but what I'm trying to say here is that it's really clear what I'm saying, right?",
            "And you should really object if it's not right, and even if.",
            "Of course, yes.",
            "This is what this is.",
            "What the talk is going to be about, right?"
        ],
        [
            "OK so today, so I'll talk a little bit about what is the motivation of thinking about probabilistic models in machine learning.",
            "So why is it?",
            "Why is that an interesting framework to do do machine learning?",
            "And then I'll talk about this distinction between classical frequentist off you, Sherry and Listex and Bayesian.",
            "Probability and I'll talk about how how you do inference in these models.",
            "What happens when you observe some data?",
            "How does that?",
            "Change your view of the world and then I have this little simple example and I again so I apologize for having this sort of extremely simple example where I think is the best way of thinking about what the conceptual differences are.",
            "Um?",
            "And then I'll talk about one of the crucial aspects.",
            "Here is what sometimes refers to us as Occam's Razor, and this is something that exists exists in the Bayesian.",
            "And based inference, and it's something else that set space and inference apart from from from from simple forms at least the classical inference.",
            "And I'll talk a little bit about model selection and I'll talk about a topic which usually is not considered.",
            "Very much in machine learning, which is related to testing, so you can test a hypothesis and I want to talk about that because that really pinpoints a lot of a lot of the crucial difference is now trying to do a summary well also I.",
            "Go through a bunch of terms and really try to define relatively precisely what these terms mean and the reason why I'm going to that is that there's a lot of confusion over over terminology.",
            "Different subparts of the of the of the Community uses different terms to mean different things or use the same terms would be different things, which is very unfortunate and is something that we probably have to live with, but I'll just try to point out these things that might be useful for you in some of the next lectures to try to.",
            "Be very careful about you know what meaning some some term top right that doesn't really belong in a talk, but I think it's going to be useful later on, so I have a few slides on that.",
            "OK, I'll also practically I'll have a 10 minute break about halfway through.",
            "Um?",
            "So it's supposed to be short enough that you don't have enough time to ask for coffee.",
            "I've been told OK, so now you know that."
        ],
        [
            "Um?",
            "Alright, so let's let's think about motivation.",
            "So why?",
            "Why would you think about probabilistic models when you're interested in machine learning?",
            "There are quite a few reasons.",
            "The main one is that probabilities provide a language for representing uncertainty, right?",
            "And if you're doing machine learning, then the idea is that you're not trying to.",
            "You don't have, you don't have a set of rules that the machine knows about and tries to find a rule that matches in a certain set of circumstances, but rather you show the machine some examples and it's supposed to extract somehow some regularity's from these examples.",
            "But because you only showed a few examples and, or at least the finite.",
            "Amount of data and because these data examples can be can be noisy like some examples are maybe not typical of their relationship.",
            "In the data, the learning system can actually be absolutely sure about about things, right?",
            "So it can say well, actually seeing if you have a character recognition system.",
            "I've seen something that actually looks a bit like this a couple of times and every time I saw it I was told that this was a tool.",
            "So probably this one is also a tool, right?",
            "But it's not.",
            "I can't really be sure like I only saw, you know, ten of these things right?",
            "So there will be some.",
            "Depending on exactly how closely on and depending on how how different things that were, not tools where you know there's going to be some kind of trade off there, and probabilities are nice language to actually express this kind of uncertainty, right?",
            "So say OK, I'm I'm 90% confidence that it's a tool that means something very particular.",
            "And again, so that the data that we observed can provide evidence for and against different explanations, right?",
            "So I might have might have two different different hypothesis about what the world looks like, and then I gather some data and some of the data might favor one of the hypothesis more than another one.",
            "And the ability to quantify how much.",
            "This data gives evidence for and against these types of explanations.",
            "This seems to be sort of a crucial element of something that's supposed to be able to learn relationships from data.",
            "Um?",
            "So one of the probabilities used used for their, so they used to represent knowledge, so I can put probability distributions over things.",
            "I can say well I've measured the Heights of people in.",
            "They tend to be 1.7 meters plus and minus 4.2 meters or something like that, right?",
            "So that's probability distribution over that thing will actually capture and capture my knowledge about that.",
            "Um?",
            "And also I can infer new states of knowledge.",
            "So if I have some knowledge and then I make some new observations then I update my knowledge that influences my knowledge somehow and I have to have to know how to be able to do that.",
            "Also, I need to be able to make optimal decisions, so if I have some some knowledge about how I think the world works, I need to be able to make decisions based on this.",
            "Let me I need to be able to well buy that stock or sell that one right?",
            "Things like that.",
            "So that's a different decision theory which is built upon representations of knowledge of how things work.",
            "And also there are a number of other ways of formalizing these systems that actually turned out to be equivalent to these probabilistic.",
            "Model so one of them is to start derived from information theory, and there's also a sort of physical analogy, and turns out that these are extremely closely related or sometimes even identical ways of looking at things using a different kind of language.",
            "But mathematically the same."
        ],
        [
            "OK, so let's try to get into the meat of things so.",
            "So this little Atom of difference is related to exactly what this probability means.",
            "Alright, so let's try to examine some statement.",
            "So I've written up here the probability of rolling A6 with this die is 1 / 6 OK.",
            "So people think this is a very, very reasonable statement.",
            "But what exactly does it mean?",
            "So one interpretation here is this is related to the frequency frequentist probability, so it's defined in terms of.",
            "The long one frequency of a repeatable experiment.",
            "So in that definition, what it means is it means if I roll the die lots of times, then the the the.",
            "The number of outcomes of sixes will tend to end over 6 as N goes to Infinity.",
            "That's sort of.",
            "Moral ethic the exact.",
            "Definition here, and that's why it's related to frequency.",
            "So deliberate activity to the frequency of things happening in the limit of doing the experiment.",
            "A large number of times, but this seems like a good definition of probability.",
            "Unfortunately, you can't always apply this definition right, because you can only apply it if you have repeatable experiments, right?",
            "Of course, I can roll the die again and again in some cases, even if you can't repeat the experiment, you can at least think about.",
            "What would happen if you sort of conceptually, would repeat it?",
            "But sometimes that's not even possible, so here's a here's an example.",
            "So the statement here, the probability that the last US soldier has left Iraq in 10 years is pretty low.",
            "OK, that's not.",
            "That's not even really possible to conceptually.",
            "Think about how can you repeat that kind of thing, right?",
            "You have to have an infinite sequence of Iraq wars or something is that this doesn't really make sense.",
            "Would be half farfetched to think about it.",
            "So does this mean that this this statement doesn't have any meaning?",
            "Well, inside the frequency count it doesn't.",
            "This is illegal to say things like that, or at least doesn't have any meaning if you do.",
            "So, but there is a basic interpretation, interpretation and the base interpretation is that, well, probability can reflect the degree of belief, right?",
            "So I could rephrase it to say instead of the probability that the last years older, I could say I believe that.",
            "OK, but then it may be a little bit less controversial.",
            "So sort of clear, it's not clear intuitively what it means, right?",
            "And so it just means that I don't really believe that they can sort it out in 10 years, right?",
            "But but there's there's some problems when you actually look at, you know what's the exact?",
            "Definition OK, so there are many other interpretations of probability.",
            "I won't list them here.",
            "The most of them.",
            "Are quite quite tricky, right?",
            "And it's because they've been invented by people who are not satisfied with either of these definitions, right?",
            "So people are usually not.",
            "Happy about this one because it's subjective.",
            "Somebody else might say, well, I think the probability is high.",
            "And then people could say well, what assistant is this science?",
            "If you think it's high, and I think it's low, you know what is it?",
            "What?",
            "What are we supposed to do about that?",
            "And so basically just says, well, you know different people might have different opinions, but fine.",
            "OK, I'll try to.",
            "I'll try to be a little bit more more specific about that so.",
            "So now the interesting thing is that although these although this sort of, it seems like maybe a small difference.",
            "But and once we get once we get going once we tried to actually do inference in these models and it turns out that we were using the same rules of probability like the calculus of probability is already set out right?",
            "And people don't debate that.",
            "They don't debate how you're supposed to manipulate random variables.",
            "That's always done in the same way.",
            "Completely, irrespective of what interpretation you have of what's going on.",
            "But it's interesting that we'll see that you actually tend to treat the problem differently depending on whether you allow or they want, or for the other kind of interpretation.",
            "So based on probability is used to describe all kinds of uncertainty.",
            "So one kind of uncertainty is things that are that are intrinsically stochastic, right?",
            "So the classic example is that I have an Atom are radioactive Atom and I'm waiting for it to emit an Alpha particle or something like that.",
            "I'm going to say, well, what's the probability that will emit this Alpha particle in the next 10 minutes?",
            "And people think this is this is really intrinsically random.",
            "Other people again, thinks that that intrinsically random doesn't actually exist, like there is another another view, another viewpoint.",
            "Um?",
            "So another way of thinking about this is a subjective view, so and just say, well, this is my opinion like so based on my experiences in the world and view of the world.",
            "And this is what I think things are like right then and then this is sort of very very subjective.",
            "And another interesting example is that it could be a consequence of ignorance, right?",
            "So here's an example.",
            "So I have a coin.",
            "Then I flip the coin.",
            "So now I have here either.",
            "Heads or tails?",
            "But I haven't looked yet.",
            "Right, well, actually I don't know.",
            "So my belief could be 5050.",
            "But it's a head or tail.",
            "But you could say, well, this is silly.",
            "There's nothing sarcastic about that.",
            "It's either head or tail.",
            "I just don't happen to know.",
            "OK, so frequencies might say, well, that's silly to think about a stochastic process.",
            "There's nothing sarcastic about that.",
            "It's either heads or tails.",
            "You just happen to be ignorant about whether it's.",
            "Short tails.",
            "But we're basing.",
            "That's fine if I don't know.",
            "Then I rebooted stochastic process.",
            "Then it's a random variable.",
            "To me.",
            "It's a random variable like I could show it to you, right?",
            "If I show you whether it's heads or tails like, then you actually know whether it's heads or tails, right?",
            "I still haven't looked so now our subjective views are that he knows it's tails and I don't know.",
            "So we have different views.",
            "OK, and that seems to be entirely OK.",
            "So now.",
            "Yes.",
            "Everything there is.",
            "What?",
            "Factors.",
            "Actually I choose not to because.",
            "Yeah, that's correct.",
            "So one objection might be that, well, throwing a die or flipping a coin.",
            "There's nothing sarcastic about that at all.",
            "It's just following rules of Newtonian mechanics and you can just solve.",
            "It might be that you have to be bitter cumbersome, but in principle there's nothing wrong that that's fine.",
            "That's fine, OK, but still if I haven't done it.",
            "I would treat it as a random variable.",
            "Right, that's a crucial difference.",
            "And we'd like to see an example of that of how.",
            "You can invent some.",
            "Question.",
            "Sorry.",
            "Yeah I should.",
            "I should repeat the questions.",
            "OK. OK, so we were talking about the fact that if you happen not to have made a measurement then you can simply treat your ignorance about this thing.",
            "Although you could have made the measurement if you happen not to have made the measurement, then you can treat it as a random variable, right?",
            "And weather.",
            "Whether it's really random or not, that's irrelevant.",
            "If you don't know what the value is, you just treat it as a random variable."
        ],
        [
            "OK, so now I just have to give you a little bit of notation.",
            "I hope some of this should be mostly familiar, but then at least you will get used to the way that I write things.",
            "OK, let's just let's just run through these.",
            "So OK, probabilities are non negative, so probabilities.",
            "I usually don't distinguish between probability densities, which are probabilities over continuous domains and real probabilities that are probabilities of discrete events, or just call them all P. So probably all probabilities are.",
            "Not negative and probability real probabilities are between zero and one.",
            "Of course probability densities can be larger than one probability, normalized right?",
            "So the probability if you sum over all possible outcomes X, then some there is one.",
            "Or in discrete case the interval should be one.",
            "And then I'll talk about use joint probability alright, as P of X&Y is that the joint probability of X&Y.",
            "And.",
            "So that now the marginal probability of X is given by.",
            "Summing out the variables that you're not interested in.",
            "So in this case, from the joint distribution summing up the Y, or if it's continuous variable integrating out there, why are variable?",
            "And conditional probability will also use that.",
            "So the probability condition probability of X given some particular value of Y is related to the ratio of the joint probability of X&Y and the marginal probability of Y.",
            "And then we will be using something called Bayes rule.",
            "So this is one of the one of the unfortunate namings.",
            "Sort of the better this was called the rule of conditional probability, because there's nothing intrinsically besen about that.",
            "This is just a rule about how to manipulate.",
            "Conditional probability is basically so you can write down the joint probability as the condition of X given Y times the probability of Y.",
            "So this is going to be the joint of X&Y.",
            "By just using this definition, but you could also write it as the probability of Y given X times the probability of X.",
            "And now we can just rearrange terms.",
            "You can then write the probability of Y given X as the probability of X given Y times the ratio of give Y&P of X and this is a rule that is often used when you're doing Bayesian inference.",
            "See, but there's nothing really Bayesian about it.",
            "I think we can change the name by now, unfortunately."
        ],
        [
            "Alright, so let's let's try to start getting into the meat of things.",
            "So first of all, there's the likelihood function, so the likelihood function is used in all kinds of in all interpretation, so the likelihood function is simply.",
            "Is the probability of the observed data given the parameters.",
            "So let's think about having a model that has some parameters in it, and then the likelihood function is just the the probability of those particular observations given some particular setting of those parameters.",
            "Anne.",
            "So here we're here.",
            "Let's let's try to look at the again.",
            "I've tried to choose the simplest example that you can think about, so independent conflicts again.",
            "So we have a parameter in the model which is, which is \u03c0 and \u03c0 stands for the probability that you're going to head.",
            "Um?",
            "So we say that the random variable here X take the value 0 if you get a tail and takes the value of 1 if you get ahead, OK.",
            "So now a reasonable model for this is the Bernoulli likelihood, and that simply says the.",
            "Now the probability of the data given the.",
            "The parameter in the parameter here is \u03c0.",
            "But in the actual probability written here in a slightly weird form, but I say it's \u03c0 to the X * 1 -- \u03c0 to the 1 -- X, right?",
            "But remember X can only be one or zero, so if X is 1 then you get pie here, right?",
            "You get high to the power one and you get 1 -- \u03c0 to the power zero, which is just one.",
            "This is just sort of a weird way of writing that the probability is \u03c0 and the probability of of 0 is 1 -- \u03c0, because they probably have to sum up.",
            "Alright, so this is this.",
            "Is this the likelihood function?",
            "And let's say we make a number of experiments.",
            "Went up North experiments.",
            "And we collect those those outcomes in a data set D and we observe that K of these are our heads.",
            "So now the likelihood for the for the entire experiment.",
            "So each of the experiments are independent from each other.",
            "'cause the coin is only like the what the outcome of the coin doesn't.",
            "Doesn't doesn't have any impact on what's going to happen in the next.",
            "And next experiment and now the probability here is just going to be will have K. Times will have probably pie and end.",
            "This K times will have probability 1 -- \u03c0. OK, so that's it.",
            "Difference here about whether you think of this as being an ordered set or you think of being an unordered set, right?",
            "If you're only interested strictly only interested in the number and the number of cases, there might be sort of a combinatorial factor in front of this, so I just I just leave that away just to keep things simple.",
            "So strictly I'm thinking about that particular sequence.",
            "But yet you have to be put in that.",
            "In that case, they, like your function looks like this.",
            "Now, so an interesting thing that will come back to is that the likelihood function.",
            "Is a probability distribution over data over observations.",
            "Not over parameters, right?",
            "So this is not.",
            "This is a probability distribution over these things, right?",
            "But this is not necessarily a random variable like this is just a parameter.",
            "That would be that would be important when we come to do.",
            "When we come to do inference."
        ],
        [
            "OK, so let's see.",
            "Well, how do we actually do inference in?",
            "In this kind of model.",
            "But the classical inference is based on the idea of estimators, right?",
            "So if you want to, if you want to make inference about something, then the first thing you do is you need to invent an estimator.",
            "And one of the estimated, which often uses the so called maximum likelihood estimator, right?",
            "And it basically says, well, let's use an estimate of the parameter, the parameter that actually maximizes the probability of the outcomes that we actually observed.",
            "So this sort of sounds like a pretty reasonable.",
            "A type of.",
            "Estimator, but notice that that we could have chosen other estimators as well, right?",
            "So the maximum likelihood estimator is just is just sort of 1.",
            "One kind of estimator in statistics, people work on proving various properties of different estimators, right?",
            "So you can maybe, maybe you can prove something about a particular kind of estimator that has some nice properties and that would then be a reason why this is a good estimator, right?",
            "But notice that the estimator, although it sounds pretty reasonable, it doesn't really come from anywhere like.",
            "It's just an invention.",
            "Like somebody thought thought about this, this estimator and this is you can find that in the literature you can find proposals of various kinds of estimators for various properties in various complicated models, right?",
            "So this is, this is what you do if your classical statistician right, you invent estimators, improve things about them, yes?",
            "What would be a different estimator?",
            "Well, different estimator would be things like penalized maximum likelihood estimators.",
            "So you say, well, I want to maximize likelihood, but I also have some other constraints that I also want to satisfy, right?",
            "Or it could be things like leave on out estimators so you can.",
            "You can estimate you can sort of manipulate your data set, or estimators that are based on resampling ideas or bootstrapping estimators.",
            "Do somehow manipulate your data set in various ways and then you do inference based on on on what happens in those cases.",
            "And the game is open, right?",
            "You can you can.",
            "You can invent any kind of estimate.",
            "Alright, you can say my estimate is 56.",
            "There's no, there's no, there's no, there's no formal requirement that has to be related to your data like it's just any procedure where you can sort of compute things.",
            "This is a valid estimate.",
            "It might be.",
            "It might not have very good properties.",
            "Alright, So what would happen if we actually if you actually try to talk to maximize the likelihood in this case?",
            "Well, we can.",
            "We can simply compute the the maximum here.",
            "So if you take the derivative of the of the likelihood or the log likelihood, respect pie and set that zero and solve for \u03c0, then you get that pie should be K / N. Um?",
            "So is this a good answer?",
            "Anybody have?",
            "It seems like good answer, right?",
            "If you roll the die 100 times and 56 times it comes out, or if you flip a coin.",
            "100 * 56 times it comes out heads, then the estimate is 56% chance.",
            "Yeah, that sounds pretty good.",
            "Why?",
            "Right, so that's good.",
            "Important objection, so let's say I flip the coin twice and I got 2 heads.",
            "Now what's my probability?",
            "Would be 0.",
            "OK, and 0 means I'm absolutely certain that it won't happen.",
            "That doesn't seem right, like there's something there's something a little bit about that right?",
            "And there are ways to fix the properties of these estimators, right?",
            "So maximum likelihood estimators are generally, if you have very small datasets, there are some problems there, right?",
            "You should, you should worry about that.",
            "OK, and there are ways to fix these things, but conceptually this is the kind of this is the kind of scheme you would have to go through right.",
            "Then you have to think about an estimator that has had a little bit better properties.",
            "The one way of inventing better properties.",
            "Is to say, well, let's just pretend that we have actually observed ahead and entail before we start.",
            "So you can sort of introduce these pseudo observations and that will that will.",
            "That will prevent this thing from ever reaching one or zero.",
            "You can say, well, no matter how many tails I observe.",
            "Could still happen that a tail comes out right and the probability if you only observe if you make any observations and you have this sort of extra pseudo account then you would only be able to conclude that things would happen in at most one over or at least 1 / N would be the probability.",
            "And that's also seems reasonable, right?",
            "If you only made end experiments, how can you then be sure about outcomes that have probabilities lower than 1 / N?",
            "It doesn't seem you can really gain information about things that happened that infrequently.",
            "If you only made any observations right, so that would be a way to fix this kind of estimator."
        ],
        [
            "OK, So what do you do if your if you want to do things in a basic way so?",
            "Initially the Bayesian framework.",
            "It's a little bit more complicated, but there are more ingredients in how to formalize your problem.",
            "But what I'll?",
            "I'll try to show here is that in many cases the the outcome of your analysis and the actual procedure that you are applying will actually be conceptually a lot simpler in this case.",
            "So let's try to do it so again, you have the likelihood function, which is the same as before.",
            "The likelihood is the probability of observation given the parameters.",
            "And you have a new thing here which is called, which called the prior, and the prior is the knowledge or the assumptions you make about the parameters before you make any observations.",
            "OK, and this is called.",
            "This is the prize is P of pie, so it's what do you know about pie before you start?",
            "What do you think about the properties of the coin right?",
            "It's not related to the observations, that's called the prior.",
            "So.",
            "So tomorrow I talk a lot more about priorities.",
            "Today I'll sort of sidestep this a little bit, so I'll talk about.",
            "So in this case you have to say, well, what do you think about the coin before you start, right?",
            "And people get people get a little bit uneasy about this and say, well, I don't know anything about the coin before stop.",
            "And then the Bayesian would say well, then then you can't do inference, right?",
            "There's no way that you can if you simply say anything could happen.",
            "For a coin, is a little bit a little bit hard to imagine, but maybe it balances on the edge or something, right, but?",
            "It's a little bit hard to imagine, but let's say you are using a more complicated in a more complicated scenario list that you are trading stocks, for example and say, well, what do you think?",
            "What do you think the properties of stocks are?",
            "You say?",
            "Oh, I don't know.",
            "I just want to look at the data, right?",
            "And and there's some problems in that, right?",
            "So and of course, the stock prices are not.",
            "They can't do just anything like if you could do just anything, then it would be impossible to model, but they were doing right.",
            "You say?",
            "Well, the stocks have had a value of, you know.",
            "It had about 200 yesterday and today it has a value of 101.",
            "What do you think it has tomorrow?",
            "Say well, I have no idea.",
            "Could the value be 10 to 26?",
            "Probably not.",
            "That seems unlikely, but you do know something.",
            "Of course you don't know exactly.",
            "What the stock is going to be tomorrow, right?",
            "If you did that, you wouldn't be here.",
            "OK.",
            "So the prior tells us, what do we know about the promises before we start OK and we'll get back to what kind of things you could know about.",
            "Bernoulli experiment, although in that experiment is not so interesting, like tomorrow, I'll talk about inference about functions.",
            "So then we have prior distribution functions.",
            "Then things will start becoming interesting.",
            "Um?",
            "OK, and then then we what we compute is known as the posterior.",
            "So the posterior probability the probability distribution over of the of the parameters after we made observations and so now that the probability of Pi given the observation that we made.",
            "OK, I notice that the difference between the the the posterior and likelihood is exactly that.",
            "It's the reverse kind of probability, right?",
            "So the likelihood was PD given pie and the posterior Steve Pie.",
            "Given D, what does that?",
            "What does the likelihood and the prior imply about?",
            "The distribution over over \u03c0.",
            "Now when we when we plug into this Bayes rule here by using this by swapping these conditional probabilities.",
            "To get the ratio here of the prior time, the vacuum to prior divided by PFD PFD.",
            "Here is just the probability of the data.",
            "Sometimes refer to it the marginal likelihood or the evidence.",
            "So now so now Bayesian inference simply consists of computing what is the posterior probability.",
            "OK, you start by some knowledge about the data which is incorporated in the prior and then you update that based on the likelihood and then you get your posterior distribution.",
            "And then you've finished doing inference.",
            "Once you have your posterior, then your and then you're done.",
            "So now.",
            "What do we use the posterior for?",
            "Well, you can use it to make predictions about what's going to happen in the future, so.",
            "How do we do that?",
            "Well, the predictions that we want to make is.",
            "We want to make want to have a probability distribution over what would a future outcome be.",
            "I used to start.",
            "To the random variable to denote a few.",
            "Here I can just write that as I have an integral here of P of X dark, even \u03c0 times P of Pi given D, so that when you multiply these two conditional probabilities together, you get P of XR.",
            "An pie, even D right?",
            "So it's a joint probability of XR and Pi given D and then I sum out the Pi variable.",
            "So that gives me just the probability of X star given D. So this is exactly the thing that I'm looking for, right?",
            "I want to know what does the observed data tell me about what's going to happen in the future.",
            "OK, so notice that this is not something this is not something I invented, right?",
            "I'm just writing down the thing that I want to know OK, and then I can expand it in this particular way by using the joint probability of P of XR and Pi given D and that can be written in terms of this product where one of the terms is the posterior distribution.",
            "And the other term here is that just the likelihood function, right?",
            "If the probability of an observation given a parameter.",
            "Alright, so that means that in the in the basin setting you simply you simply workout the probability of the thing that you're interested in and you just use the rules of probability.",
            "And.",
            "And notice also that the posterior distribution.",
            "Anne.",
            "Is A is a probability distribution over the thing that we're interested in right parameter of the model?",
            "It's not a probability distribution over data.",
            "Like the data is considered to be fixed here 'cause we actually observe that it has the particular value that we observe in our experiment.",
            "So another thing to notice here is that the.",
            "That the that the predictions here are averages over different possible possible promises, settings, right?",
            "So it's actually you actually take the prediction here and you average together that based on how much you believe in different settings, right?",
            "So you might have to also seem unlikely we'll have some weight in this interval, right?",
            "The more likely they are, the less weight they will have and the more likely ones or the more the ones that have higher posterior problems, will have larger weight in this interval, right?",
            "But you can't rule them out like even if things have seemed to have low probability, it might still be.",
            "Still be the truth right?",
            "You just you just just had some unlucky observations, so they should.",
            "They should also be taken into consideration.",
            "And this is also a contrast between the maximum likelihood setting.",
            "We just say, well, I believe that my parameter has this particular value K / N for example.",
            "I disregard all the settings because they're not the maximum likelihood value."
        ],
        [
            "OK, so there's a little bit more too.",
            "Two in the inpatient scheme, which is related to model selection.",
            "So I won't.",
            "I didn't say anything about model selection in the frequency.",
            "Setting, I'll come back to how you can sort of do things like model selection, but in the Basin inference scheme, it's sort of it's sort of a natural component inside the inference scheme, whereas in the in the frequency setting you have to do something from the outside, you have to sort of.",
            "Do something separate to figure out how to do do model selection.",
            "I'll try to come back to that with a little example.",
            "Um?",
            "OK, let's say we have.",
            "We have two different two different interpretations of how the world behaves.",
            "Right now we make some, make some situations and we want to know which one of these models is the right one, or which one seems to be the most likely one.",
            "Given those observations.",
            "Yes, there's a question.",
            "Yes.",
            "OK, yeah.",
            "So I should I should repeat the question for Barnhart.",
            "So the question is.",
            "In in classical statistics, you can prove various properties about these estimators.",
            "So for example that in the limit of.",
            "Acquiring an infinite amount of data that you have some notion of consistency you have, for example the Creamer out bound that tells you something about how fast you ask you.",
            "You approach the right answer.",
            "So does this kind of property exist for Bayesian inference scheme?",
            "No, it doesn't, and this is this is.",
            "This is also a reason why people are unhappy about this right.",
            "Why doesn't it?",
            "Well, it doesn't because it's subjective, right?",
            "It starts by it starts by having the prior notion about about parameters, right?",
            "So let's say your prior notion was that it's absolutely impossible to get ahead.",
            "So now I make experiments and sometimes I get heads.",
            "But if my prior was that you can't get ahead.",
            "So that my prior would say it's impossible to get ahead, right?",
            "So what happens when I get heads?",
            "But you're right, I'll just have to sort of ignore it, right?",
            "I can't do anything about that, so there's no sort of real guarantee that under all circumstances you really approach the right answer, right?",
            "If the right answer was not inside the class of things that you were considering.",
            "Um?",
            "From the start, then it also won't be apart of the of the things that you consider at the end, right?",
            "So there's some problems here, right?",
            "So now people, people try to say, well, you know, if your prior wasn't that wrong.",
            "Would you then get this kind of property and then the answer is sort of yes, but there's a lot of technical questions about.",
            "You know exactly what you mean by not being that wrong, right?",
            "Bye.",
            "No, it's not unbiased is not unbiased because it takes in.",
            "It takes into consideration.",
            "Also, I should repeat the question, sorry.",
            "Is a Bayesian estimator unbiased?",
            "And it's not unbiased.",
            "The basin estimators typically biased and it's biased because it's a combination of the likelihood term but also of the prior, and the prior could be biased, right?",
            "If I say, well, I actually think heads are more likely when I start off right.",
            "But even though I get a lot of evidence that they are equally likely, then there's the prior still has a small contribution, right?",
            "So the so the estimate will be will be biased, right?",
            "So so there's a lot of, so one of the properties of the favorite properties of the classical statistics is minimum variance unbiased estimators, right?",
            "So it means among the class of unbiased estimators.",
            "This is the one that has the smallest variance.",
            "And this sort of sounds like a nice property, but I think the more you think about it, it's not.",
            "It doesn't seem to be crucial that things are unbiased.",
            "Sure, it's nice if they are, but it doesn't mean if I say well, I have a biased estimator here, but actually have it has much less variance than.",
            "And then the minimum variance unbiased estimator.",
            "Then what are you going to do?",
            "Right?",
            "The estimator is biased.",
            "You could reduce the variance as much as you can.",
            "Right, so there's a whole thing.",
            "Classical statistics people often think about.",
            "A tradeoff between.",
            "Bias and variance.",
            "So you can think about.",
            "Can think about.",
            "The notion of regularization, so it says, well, the maximum likelihood the pure maximum likelihood model has some some nasty properties in the terms that the variances of the estimators can be quite large and you can reduce that variant by introducing regularization.",
            "But the consequence of introducing regularization is that you actually get a little bit of bias right, and then by adjusting the so called regularization parameter you can adjust the amount of bias and then you can.",
            "You can think about trying to make the optimal tradeoff between.",
            "Variance and squared bias right and?",
            "That's right.",
            "OK, so sorry, I apologize, but for for not being completely clear about this, I didn't actually tell you what I mean by bias.",
            "There were some questions here.",
            "I sort of want to try and stay away from some of these studies.",
            "Technical points and try to focus on the conceptual level.",
            "So I think that more we have more questions.",
            "OK, so we reach the model comparison here.",
            "So the idea is that I have two different models of how my coin behaves and now how can I use the framework here to make inferences about which which model is best?",
            "And again, you just you, just you actually just compute the probability.",
            "The posterior probability of the model.",
            "But let's try to do that.",
            "So now we have a likelihood term which I wrote before as PFD.",
            "Given pie.",
            "Now right.",
            "Vegan pie, an hi so hi, just means a particular kind of model number.",
            "Hi, OK. Um?",
            "And now my prior might also depend on which model class I'm looking at, the price now P of Pi given HI.",
            "And my posterior is just going to be a pie given D and hi.",
            "OK so I can do so.",
            "I can workout the posterior probability for or for all of my different models.",
            "And now.",
            "What we what we?",
            "I'm.",
            "OK, so this is this is wrong.",
            "I see here, so this should be Piave.",
            "Hi, given Pi and H right so it's the.",
            "The reverse of the other probability here.",
            "So here.",
            "Hi I'm sorry bout that correct that it should be P of hi given the pie.",
            "It's correct the way I have it on the slightly confused here.",
            "Oh sorry, yeah, I'm a little bit ahead of myself.",
            "Sorry so this is just this is just the posterior probability for the parameters for each model class.",
            "OK, so it's the same expression as I had before, except that are now everywhere conditioning on hi OK. And now the the normalizing constant of the that we had before here, which would just be a fee, is now PSD.",
            "Given a child, which is again is now called the marginal likelihood, or evidenced for model HI.",
            "And what I want to know is I want to know what is the probability of the different models given my observations.",
            "And I use Bayes rule again to swap around.",
            "B&H, right?",
            "So it's going to be the the.",
            "Marginal likelihood for hi Times Now I have P of hi so now this is my prior over hi so it may be that before I start I actually think that one of the one of the models is a lot more likely to be true than the other one.",
            "But I can't rule the other one out right.",
            "So maybe if the data really favored the other one then maybe I would change my mind so I can encode again my my.",
            "By prior beliefs using.",
            "Using the prior here.",
            "And the and the marginal likelihood here is just the normalizing constant of the previous stage of inference and the previous stage of inference.",
            "You just.",
            "It's just the normalizing constant of the likelihood times the prior.",
            "OK. We were trying to do that."
        ],
        [
            "Apple.",
            "OK, so so this is going to be this boring example again, right?",
            "So we can actually just compute everything.",
            "So now we have two different models or two different learners.",
            "I call them to be able to call this machine learning so one learner believe that the coin is fair, so it's actually not really a learner.",
            "It doesn't learn anything, just believes that the coin is fair.",
            "Learn Apiaceae does believe something.",
            "Just learn something so it believes that.",
            "All possible that all all values of Pi between zero and one are equally plausible.",
            "Right?",
            "This is a particular kind of probably, so the prior belief written as a probability distribution would look like this right.",
            "All possible values of Pi equally likely.",
            "Um?",
            "Now it turns out that it's convenient to write the prior distribution in terms of a beta probability distribution, so it turns out that a uniform on interval like this is actually what's known as a as a beta 11 distribution.",
            "So a piece of distribution are written down the expression for beta distribution here, so it's very closely related to the to the Bernoulli random variables, so it's a.",
            "It's a normalizing constant constant here that doesn't depend on \u03c0.",
            "This just makes the probabilities over \u03c0 the integral of \u03c0.",
            "One, so it's a proper probability distribution and then essentially it says it's \u03c0 to some power, also minus one, where Alpha is a parameter of the distribution times 1 -- \u03c0 to the power detail minus one.",
            "So the two parameters are open beta.",
            "And Peter distributions kind of look in various ways.",
            "So here's a fee to 55.",
            "Distribution that says that you know any value in the in the central area is reasonably reasonably probable and values sort of below say oh point 1 or above.",
            "Oh, Point 9 are quite unlikely.",
            "And you can also have skewed kind of distribution.",
            "So here is saying that values above oh point 8 are quite unlikely, but sort of other things are.",
            "Quite likely so the feature distribution here is called the conjugate prior because it has the same form that makes analysis very easy."
        ],
        [
            "Um?",
            "Alright, so let's try and make some observations.",
            "So I made some observations, so I got.",
            "I made 10 observations, SO33 heads and.",
            "And seven tail.",
            "Uh.",
            "And now my question is, what do my two learners?",
            "What do they?",
            "What do they actually do?",
            "What do they predict?",
            "Well, the learner a which wasn't really a learner, just predicts half again, right?",
            "It ignores the data essentially.",
            "Um?",
            "What about what about Lenape?",
            "So I should what I should do is I should workout the posterior distribution.",
            "And now the posterior distribution.",
            "I get by multiplying the prior which was a beta 11.",
            "With the with the likelihood and the likelihood, here is going to be super new likelihood, right?",
            "So it's \u03c0 to the power three times.",
            "I haven't.",
            "And.",
            "1 -- \u03c0 To the power 7.",
            "OK, so that means that the.",
            "The posterior distribution is again of this beta form.",
            "In particular, is the beta 4, 8 because the powers are three and seven?",
            "That means that the the posterior distribution looks like this, so the posterior now says well.",
            "It actually thinks that given these observations.",
            "Um?",
            "It's unlikely that Pie has a very high value, right?",
            "It's unlikely that the value is greater than 7.8, right?",
            "Because then it would seem odd that you got 7.",
            "Seven tails and only three heads.",
            "If the probability of getting head was really that much higher than the probability of getting tails.",
            "It's quite, it's quite likely that the probability would be a half, and it could even be the probability is quite low.",
            "You could still get this.",
            "Kind of data.",
            "So now what is the what is now the?",
            "The what predictions do those learner B make based on this data?",
            "With the predictions are.",
            "Now the probability of of some new outcome given the particular data set we observed.",
            "And given this model class D. So now we should average together the predictions that the model make and the predictions are just pie in this case, right?",
            "And you should average that over the posterior distribution.",
            "And if you do that, then again things turn out to be.",
            "Easy, so it's the just the normalizing constant here of the from the from the posterior.",
            "And then we need to.",
            "Um?",
            "We need to multiply by the five, five \u03c0 to 3 * 1, Five 7, and then we need to multiply high, so that will give us another \u03c0 term in here, so it'll be high to the four as one of those parts of the 7.",
            "And we then do the integral.",
            "Here.",
            "We just get the normalizing constant of that.",
            "So that's just the reverse ratio of this thing here.",
            "But we have now 13.",
            "The total count is is 13 and we have five of the pies instead of four.",
            "Is that before?",
            "And if you work this out, this is going to be.",
            "This has a value of 1 / 3.",
            "Like so, given the observations, the predictions here are that it thinks that you get heads 1/3 of the time, whereas the other model just keeps keeps on thinking that you get.",
            "Um?",
            "Half the time.",
            "OK now so which model is the best?",
            "Anyone have any who thinks Model A is the best in this case?",
            "Model A that just just believes that it's a 5050 coin.",
            "No one does anybody believe that B is the best.",
            "No one believes anything.",
            "Oh OK, a few hands here.",
            "Alright, so B seems to be the best model, right?",
            "Because it actually it actually takes into account the observations here, right?",
            "So it actually actually modifies its belief.",
            "OK, so let's try to work this out.",
            "So we have the machinery from the future."
        ],
        [
            "Before is actually trying to work out what is the probability of of the different models.",
            "So now for learner a learner that's not a learner.",
            "What's the probability of?",
            "We can workout the.",
            "Um?",
            "The probability of the data give the model and let's say a prayer I we don't know which model is right.",
            "So let's say that the prior on each model is just half half half.",
            "We think either could be true, but we don't really assign a preference here.",
            "So in that case the.",
            "The top level inference here.",
            "So now we want to do the inference here.",
            "Now, if this thing is the same for all model classes, then we should just rank the models instead of ranking according to the posterior probability of the model will be the same ranking it just according to the marginal likelihood, right?",
            "So we are working out the marginal likelihood now.",
            "So the margin activity here is just for the, for the for the learner who is not a learner, the probability of any data set is just.",
            "1/2 to the Power 10 right, because every observation has a probability of how.",
            "And 1/2 to the power 10 is this small number 4.0098.",
            "So what about Lenape?",
            "Well, learn RP just has this.",
            "To be now the normalizing constant of the prior times likelihood.",
            "And that happens to again have this particular beta form.",
            "So the normalizing constant is actually the gamma, four times gamma 8 divided by gamma 12.",
            "Which is open 076.",
            "This means this case the.",
            "The inference would say that learner B is a little bit less likely than learner A. OK.",
            "So how can that be so?",
            "Learner B actually took the data into account and now it comes out that learner B seems to be a little bit less preferred doing this.",
            "Using this analysis.",
            "Well, let's try to think about on to think about the probability according to the maximum likelihood estimate.",
            "So our maximum likelihood estimate here would be 3 / 10 right?",
            "Because we got three of the outcomes were ahead.",
            "So we have the masculine or \u03c0 will be 3 / 10.",
            "And the probability of the data set given our maximum likelihood estimate is going to be free over 10 to the Power 3 and 7 / 10 to the power of 7 * 7 / 10 power.",
            "Seven years we get because this outcome seven times in this outcome three times right?",
            "And that's open 022.",
            "So that's much much higher.",
            "Than any of the other properties.",
            "In particular, is much higher than the learner that doesn't learn, but there not a right.",
            "And why is it much higher than a?",
            "Well, because it actually, it actually moves the probability mass to things that happen to occur and observations, right?",
            "But in some sense that a little bit unreasonable, right?",
            "Because because we already, we already looked at the data, right?",
            "So the data contains some random fluctuations that we don't expect, even if the probability was 5050.",
            "We don't know for sure that we would get five of one type in five of the other right.",
            "We could be that we get could even be that you get free in seven, actually three and seven doesn't seem that unlikely, even if the coin was completely fair.",
            "So the so the maximum likelihood estimator it simply says, well, you know this is my.",
            "This is my maximum likelihood estimate and the probability of my data set based on that is just going to be given by just focusing the mass where where the outcomes.",
            "Where we actually saw the outcome.",
            "But if you then compare these two bottles then you would say, well, this model seems to be do a much better job of modeling the data, but there's something a little bit wrong about that right?",
            "Because?",
            "Yeah, it's clear if you have a parameter that you can you can fiddle with, then you can model the data better, but that doesn't really prove that that the.",
            "That the model is better, right?",
            "And this is related to.",
            "Notion, which is called overfitting.",
            "So if you have a data set, if you train a model so this is a very simple example of that right?",
            "But even if you have more complicated models which I use, the machine learning if you fit the parameters in your model to your particular data set then you are very good at modeling that particular data set, but that's not really what you're interested in, right?",
            "What you are interested in is modeling the the relationship that are intrinsic to the data, right?",
            "Not that particular outcome.",
            "You already know what that outcome is.",
            "Don't need to model that we want to model things about.",
            "What's going to happen in the future?",
            "And somehow it seems that this this Bayesian scheme wasn't fooled by that, right?",
            "It didn't just go for modeling the data in a better way.",
            "OK, so let's leave.",
            "Resolving this.",
            "Issue, try to explain what's going on here till after a 10 minute break where you can't have any coffee.",
            "OK.",
            "So I'll take you can come and talk to me.",
            "And if people have questions I can repeat the questions after when we start again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, good morning.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about Bayesian inference and Gaussian process and today of this morning I'm only going to talk about Bayesian inference, so the organizers asked me to talk about.",
                    "label": 1
                },
                {
                    "sent": "Based on inference and I think it may be a good idea to talk about Bayesian inference, but I find it I find it quite hard because I think the topic is.",
                    "label": 0
                },
                {
                    "sent": "What about at a conceptual level?",
                    "label": 0
                },
                {
                    "sent": "You know I'm so it will be easy to talk about Bayesian inference property for a particular model, but that's not run supposed to do right.",
                    "label": 0
                },
                {
                    "sent": "I'm just doing.",
                    "label": 0
                },
                {
                    "sent": "I'm supposed to talk about Bayesian inference as such, so I'll try and do that and I guess also that your background here also.",
                    "label": 0
                },
                {
                    "sent": "Quite different, so some people maybe go over some stuff that you already know, and to some people it will maybe be a little bit tough going, but I'll try to do today.",
                    "label": 0
                },
                {
                    "sent": "I'm going to try to focus on.",
                    "label": 0
                },
                {
                    "sent": "On on getting across the idea about what is what is Bayesian about Bayesian inference, unfortunately that's a little bit hard to hard to say in a vacuum, right?",
                    "label": 0
                },
                {
                    "sent": "So I'll have to contrast it to what other kinds of things one could do, and the easiest way to do this is to contrast classical or frequency statistics with Bayesian statistics.",
                    "label": 0
                },
                {
                    "sent": "So I'll be doing.",
                    "label": 0
                },
                {
                    "sent": "I'll be doing that a lot.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So it's also interesting in the statistics community.",
                    "label": 0
                },
                {
                    "sent": "There's a big division between people who do things in a basin way, and people who don't do things in a basic way, right?",
                    "label": 0
                },
                {
                    "sent": "And this is really a severe.",
                    "label": 0
                },
                {
                    "sent": "Cut in the community and people don't talk to each other and they don't go to each other conferences and they don't publish US papers.",
                    "label": 0
                },
                {
                    "sent": "And I mean it's very used to be extremely bad and now it's only very bad.",
                    "label": 0
                },
                {
                    "sent": "I think it's improving a little bit.",
                    "label": 0
                },
                {
                    "sent": "In the machine learning community, people don't seem to be so upset about this particular division.",
                    "label": 0
                },
                {
                    "sent": "And as I'll try to explain, it's interesting because the division is actually is actually over very small.",
                    "label": 0
                },
                {
                    "sent": "It's a very small point that people are quarreling about right?",
                    "label": 0
                },
                {
                    "sent": "They actually using a lot of the same methodology, but there's only there's only sort of 1 little Atom of difference, but that leads to a version of the ways that you think about in France.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So I I tend to do a lot of Bayesian inference, but I'm also happy about, you know, thinking about other kinds of inference.",
                    "label": 0
                },
                {
                    "sent": "Sometimes based inferences has some problems and sometimes it's easier to do things another way, so I'm not.",
                    "label": 0
                },
                {
                    "sent": "I'm not particularly hooked on on doing these things, but I think the basic framework gives you some advantages and some things that are really quite easy to do.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Right, so also there's an interesting distinction historically.",
                    "label": 0
                },
                {
                    "sent": "So, so along time ago, everybody will were Bayesians, so there were only basins, and then at some point in their search uses British statistician.",
                    "label": 0
                },
                {
                    "sent": "Fisher came around and he had these other ideas about how you could do things.",
                    "label": 0
                },
                {
                    "sent": "Any sort of managed to switch the whole field around, so there was no basins around after Fisher and then some basin started appearing again and this sort of interesting that these ideas.",
                    "label": 0
                },
                {
                    "sent": "Can we switch around?",
                    "label": 0
                },
                {
                    "sent": "That rapidly.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm happy to take questions so so because I don't know exactly what you do and what you know and what you don't know.",
                    "label": 0
                },
                {
                    "sent": "You should really stop me if things are sounding mysterious right?",
                    "label": 0
                },
                {
                    "sent": "So I'm I'm I'm.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to stay with the essence of the idea, so I won't.",
                    "label": 0
                },
                {
                    "sent": "I'll try to try to stay away from complicated.",
                    "label": 0
                },
                {
                    "sent": "Pieces of mathematics.",
                    "label": 0
                },
                {
                    "sent": "So unfortunately, that means that I only consider extremely simple inference problem, right?",
                    "label": 0
                },
                {
                    "sent": "Because 'cause I want to stay in a place where we don't have to worry about how to actually compute these things that they should be trivial to compute, right?",
                    "label": 0
                },
                {
                    "sent": "So, but tomorrow you'll get some more derivations for your money.",
                    "label": 0
                },
                {
                    "sent": "So, but what I'm trying to say here is that it's really clear what I'm saying, right?",
                    "label": 0
                },
                {
                    "sent": "And you should really object if it's not right, and even if.",
                    "label": 0
                },
                {
                    "sent": "Of course, yes.",
                    "label": 0
                },
                {
                    "sent": "This is what this is.",
                    "label": 0
                },
                {
                    "sent": "What the talk is going to be about, right?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so today, so I'll talk a little bit about what is the motivation of thinking about probabilistic models in machine learning.",
                    "label": 0
                },
                {
                    "sent": "So why is it?",
                    "label": 0
                },
                {
                    "sent": "Why is that an interesting framework to do do machine learning?",
                    "label": 0
                },
                {
                    "sent": "And then I'll talk about this distinction between classical frequentist off you, Sherry and Listex and Bayesian.",
                    "label": 0
                },
                {
                    "sent": "Probability and I'll talk about how how you do inference in these models.",
                    "label": 0
                },
                {
                    "sent": "What happens when you observe some data?",
                    "label": 0
                },
                {
                    "sent": "How does that?",
                    "label": 0
                },
                {
                    "sent": "Change your view of the world and then I have this little simple example and I again so I apologize for having this sort of extremely simple example where I think is the best way of thinking about what the conceptual differences are.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And then I'll talk about one of the crucial aspects.",
                    "label": 0
                },
                {
                    "sent": "Here is what sometimes refers to us as Occam's Razor, and this is something that exists exists in the Bayesian.",
                    "label": 1
                },
                {
                    "sent": "And based inference, and it's something else that set space and inference apart from from from from simple forms at least the classical inference.",
                    "label": 0
                },
                {
                    "sent": "And I'll talk a little bit about model selection and I'll talk about a topic which usually is not considered.",
                    "label": 0
                },
                {
                    "sent": "Very much in machine learning, which is related to testing, so you can test a hypothesis and I want to talk about that because that really pinpoints a lot of a lot of the crucial difference is now trying to do a summary well also I.",
                    "label": 0
                },
                {
                    "sent": "Go through a bunch of terms and really try to define relatively precisely what these terms mean and the reason why I'm going to that is that there's a lot of confusion over over terminology.",
                    "label": 0
                },
                {
                    "sent": "Different subparts of the of the of the Community uses different terms to mean different things or use the same terms would be different things, which is very unfortunate and is something that we probably have to live with, but I'll just try to point out these things that might be useful for you in some of the next lectures to try to.",
                    "label": 0
                },
                {
                    "sent": "Be very careful about you know what meaning some some term top right that doesn't really belong in a talk, but I think it's going to be useful later on, so I have a few slides on that.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll also practically I'll have a 10 minute break about halfway through.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So it's supposed to be short enough that you don't have enough time to ask for coffee.",
                    "label": 0
                },
                {
                    "sent": "I've been told OK, so now you know that.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Alright, so let's let's think about motivation.",
                    "label": 0
                },
                {
                    "sent": "So why?",
                    "label": 0
                },
                {
                    "sent": "Why would you think about probabilistic models when you're interested in machine learning?",
                    "label": 1
                },
                {
                    "sent": "There are quite a few reasons.",
                    "label": 0
                },
                {
                    "sent": "The main one is that probabilities provide a language for representing uncertainty, right?",
                    "label": 1
                },
                {
                    "sent": "And if you're doing machine learning, then the idea is that you're not trying to.",
                    "label": 0
                },
                {
                    "sent": "You don't have, you don't have a set of rules that the machine knows about and tries to find a rule that matches in a certain set of circumstances, but rather you show the machine some examples and it's supposed to extract somehow some regularity's from these examples.",
                    "label": 0
                },
                {
                    "sent": "But because you only showed a few examples and, or at least the finite.",
                    "label": 1
                },
                {
                    "sent": "Amount of data and because these data examples can be can be noisy like some examples are maybe not typical of their relationship.",
                    "label": 0
                },
                {
                    "sent": "In the data, the learning system can actually be absolutely sure about about things, right?",
                    "label": 0
                },
                {
                    "sent": "So it can say well, actually seeing if you have a character recognition system.",
                    "label": 0
                },
                {
                    "sent": "I've seen something that actually looks a bit like this a couple of times and every time I saw it I was told that this was a tool.",
                    "label": 0
                },
                {
                    "sent": "So probably this one is also a tool, right?",
                    "label": 0
                },
                {
                    "sent": "But it's not.",
                    "label": 0
                },
                {
                    "sent": "I can't really be sure like I only saw, you know, ten of these things right?",
                    "label": 0
                },
                {
                    "sent": "So there will be some.",
                    "label": 0
                },
                {
                    "sent": "Depending on exactly how closely on and depending on how how different things that were, not tools where you know there's going to be some kind of trade off there, and probabilities are nice language to actually express this kind of uncertainty, right?",
                    "label": 0
                },
                {
                    "sent": "So say OK, I'm I'm 90% confidence that it's a tool that means something very particular.",
                    "label": 1
                },
                {
                    "sent": "And again, so that the data that we observed can provide evidence for and against different explanations, right?",
                    "label": 0
                },
                {
                    "sent": "So I might have might have two different different hypothesis about what the world looks like, and then I gather some data and some of the data might favor one of the hypothesis more than another one.",
                    "label": 0
                },
                {
                    "sent": "And the ability to quantify how much.",
                    "label": 0
                },
                {
                    "sent": "This data gives evidence for and against these types of explanations.",
                    "label": 1
                },
                {
                    "sent": "This seems to be sort of a crucial element of something that's supposed to be able to learn relationships from data.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So one of the probabilities used used for their, so they used to represent knowledge, so I can put probability distributions over things.",
                    "label": 0
                },
                {
                    "sent": "I can say well I've measured the Heights of people in.",
                    "label": 1
                },
                {
                    "sent": "They tend to be 1.7 meters plus and minus 4.2 meters or something like that, right?",
                    "label": 0
                },
                {
                    "sent": "So that's probability distribution over that thing will actually capture and capture my knowledge about that.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And also I can infer new states of knowledge.",
                    "label": 0
                },
                {
                    "sent": "So if I have some knowledge and then I make some new observations then I update my knowledge that influences my knowledge somehow and I have to have to know how to be able to do that.",
                    "label": 0
                },
                {
                    "sent": "Also, I need to be able to make optimal decisions, so if I have some some knowledge about how I think the world works, I need to be able to make decisions based on this.",
                    "label": 0
                },
                {
                    "sent": "Let me I need to be able to well buy that stock or sell that one right?",
                    "label": 0
                },
                {
                    "sent": "Things like that.",
                    "label": 0
                },
                {
                    "sent": "So that's a different decision theory which is built upon representations of knowledge of how things work.",
                    "label": 0
                },
                {
                    "sent": "And also there are a number of other ways of formalizing these systems that actually turned out to be equivalent to these probabilistic.",
                    "label": 0
                },
                {
                    "sent": "Model so one of them is to start derived from information theory, and there's also a sort of physical analogy, and turns out that these are extremely closely related or sometimes even identical ways of looking at things using a different kind of language.",
                    "label": 0
                },
                {
                    "sent": "But mathematically the same.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's try to get into the meat of things so.",
                    "label": 0
                },
                {
                    "sent": "So this little Atom of difference is related to exactly what this probability means.",
                    "label": 0
                },
                {
                    "sent": "Alright, so let's try to examine some statement.",
                    "label": 0
                },
                {
                    "sent": "So I've written up here the probability of rolling A6 with this die is 1 / 6 OK.",
                    "label": 1
                },
                {
                    "sent": "So people think this is a very, very reasonable statement.",
                    "label": 1
                },
                {
                    "sent": "But what exactly does it mean?",
                    "label": 0
                },
                {
                    "sent": "So one interpretation here is this is related to the frequency frequentist probability, so it's defined in terms of.",
                    "label": 0
                },
                {
                    "sent": "The long one frequency of a repeatable experiment.",
                    "label": 0
                },
                {
                    "sent": "So in that definition, what it means is it means if I roll the die lots of times, then the the the.",
                    "label": 0
                },
                {
                    "sent": "The number of outcomes of sixes will tend to end over 6 as N goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "That's sort of.",
                    "label": 0
                },
                {
                    "sent": "Moral ethic the exact.",
                    "label": 0
                },
                {
                    "sent": "Definition here, and that's why it's related to frequency.",
                    "label": 0
                },
                {
                    "sent": "So deliberate activity to the frequency of things happening in the limit of doing the experiment.",
                    "label": 0
                },
                {
                    "sent": "A large number of times, but this seems like a good definition of probability.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, you can't always apply this definition right, because you can only apply it if you have repeatable experiments, right?",
                    "label": 0
                },
                {
                    "sent": "Of course, I can roll the die again and again in some cases, even if you can't repeat the experiment, you can at least think about.",
                    "label": 0
                },
                {
                    "sent": "What would happen if you sort of conceptually, would repeat it?",
                    "label": 0
                },
                {
                    "sent": "But sometimes that's not even possible, so here's a here's an example.",
                    "label": 0
                },
                {
                    "sent": "So the statement here, the probability that the last US soldier has left Iraq in 10 years is pretty low.",
                    "label": 1
                },
                {
                    "sent": "OK, that's not.",
                    "label": 0
                },
                {
                    "sent": "That's not even really possible to conceptually.",
                    "label": 0
                },
                {
                    "sent": "Think about how can you repeat that kind of thing, right?",
                    "label": 0
                },
                {
                    "sent": "You have to have an infinite sequence of Iraq wars or something is that this doesn't really make sense.",
                    "label": 0
                },
                {
                    "sent": "Would be half farfetched to think about it.",
                    "label": 0
                },
                {
                    "sent": "So does this mean that this this statement doesn't have any meaning?",
                    "label": 0
                },
                {
                    "sent": "Well, inside the frequency count it doesn't.",
                    "label": 0
                },
                {
                    "sent": "This is illegal to say things like that, or at least doesn't have any meaning if you do.",
                    "label": 0
                },
                {
                    "sent": "So, but there is a basic interpretation, interpretation and the base interpretation is that, well, probability can reflect the degree of belief, right?",
                    "label": 0
                },
                {
                    "sent": "So I could rephrase it to say instead of the probability that the last years older, I could say I believe that.",
                    "label": 0
                },
                {
                    "sent": "OK, but then it may be a little bit less controversial.",
                    "label": 0
                },
                {
                    "sent": "So sort of clear, it's not clear intuitively what it means, right?",
                    "label": 1
                },
                {
                    "sent": "And so it just means that I don't really believe that they can sort it out in 10 years, right?",
                    "label": 0
                },
                {
                    "sent": "But but there's there's some problems when you actually look at, you know what's the exact?",
                    "label": 1
                },
                {
                    "sent": "Definition OK, so there are many other interpretations of probability.",
                    "label": 0
                },
                {
                    "sent": "I won't list them here.",
                    "label": 0
                },
                {
                    "sent": "The most of them.",
                    "label": 0
                },
                {
                    "sent": "Are quite quite tricky, right?",
                    "label": 0
                },
                {
                    "sent": "And it's because they've been invented by people who are not satisfied with either of these definitions, right?",
                    "label": 0
                },
                {
                    "sent": "So people are usually not.",
                    "label": 0
                },
                {
                    "sent": "Happy about this one because it's subjective.",
                    "label": 0
                },
                {
                    "sent": "Somebody else might say, well, I think the probability is high.",
                    "label": 0
                },
                {
                    "sent": "And then people could say well, what assistant is this science?",
                    "label": 0
                },
                {
                    "sent": "If you think it's high, and I think it's low, you know what is it?",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "What are we supposed to do about that?",
                    "label": 0
                },
                {
                    "sent": "And so basically just says, well, you know different people might have different opinions, but fine.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll try to.",
                    "label": 0
                },
                {
                    "sent": "I'll try to be a little bit more more specific about that so.",
                    "label": 0
                },
                {
                    "sent": "So now the interesting thing is that although these although this sort of, it seems like maybe a small difference.",
                    "label": 0
                },
                {
                    "sent": "But and once we get once we get going once we tried to actually do inference in these models and it turns out that we were using the same rules of probability like the calculus of probability is already set out right?",
                    "label": 0
                },
                {
                    "sent": "And people don't debate that.",
                    "label": 0
                },
                {
                    "sent": "They don't debate how you're supposed to manipulate random variables.",
                    "label": 0
                },
                {
                    "sent": "That's always done in the same way.",
                    "label": 0
                },
                {
                    "sent": "Completely, irrespective of what interpretation you have of what's going on.",
                    "label": 0
                },
                {
                    "sent": "But it's interesting that we'll see that you actually tend to treat the problem differently depending on whether you allow or they want, or for the other kind of interpretation.",
                    "label": 1
                },
                {
                    "sent": "So based on probability is used to describe all kinds of uncertainty.",
                    "label": 0
                },
                {
                    "sent": "So one kind of uncertainty is things that are that are intrinsically stochastic, right?",
                    "label": 0
                },
                {
                    "sent": "So the classic example is that I have an Atom are radioactive Atom and I'm waiting for it to emit an Alpha particle or something like that.",
                    "label": 0
                },
                {
                    "sent": "I'm going to say, well, what's the probability that will emit this Alpha particle in the next 10 minutes?",
                    "label": 0
                },
                {
                    "sent": "And people think this is this is really intrinsically random.",
                    "label": 0
                },
                {
                    "sent": "Other people again, thinks that that intrinsically random doesn't actually exist, like there is another another view, another viewpoint.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So another way of thinking about this is a subjective view, so and just say, well, this is my opinion like so based on my experiences in the world and view of the world.",
                    "label": 0
                },
                {
                    "sent": "And this is what I think things are like right then and then this is sort of very very subjective.",
                    "label": 0
                },
                {
                    "sent": "And another interesting example is that it could be a consequence of ignorance, right?",
                    "label": 0
                },
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "So I have a coin.",
                    "label": 0
                },
                {
                    "sent": "Then I flip the coin.",
                    "label": 0
                },
                {
                    "sent": "So now I have here either.",
                    "label": 0
                },
                {
                    "sent": "Heads or tails?",
                    "label": 0
                },
                {
                    "sent": "But I haven't looked yet.",
                    "label": 0
                },
                {
                    "sent": "Right, well, actually I don't know.",
                    "label": 0
                },
                {
                    "sent": "So my belief could be 5050.",
                    "label": 0
                },
                {
                    "sent": "But it's a head or tail.",
                    "label": 0
                },
                {
                    "sent": "But you could say, well, this is silly.",
                    "label": 0
                },
                {
                    "sent": "There's nothing sarcastic about that.",
                    "label": 0
                },
                {
                    "sent": "It's either head or tail.",
                    "label": 0
                },
                {
                    "sent": "I just don't happen to know.",
                    "label": 0
                },
                {
                    "sent": "OK, so frequencies might say, well, that's silly to think about a stochastic process.",
                    "label": 0
                },
                {
                    "sent": "There's nothing sarcastic about that.",
                    "label": 0
                },
                {
                    "sent": "It's either heads or tails.",
                    "label": 0
                },
                {
                    "sent": "You just happen to be ignorant about whether it's.",
                    "label": 0
                },
                {
                    "sent": "Short tails.",
                    "label": 0
                },
                {
                    "sent": "But we're basing.",
                    "label": 0
                },
                {
                    "sent": "That's fine if I don't know.",
                    "label": 0
                },
                {
                    "sent": "Then I rebooted stochastic process.",
                    "label": 0
                },
                {
                    "sent": "Then it's a random variable.",
                    "label": 0
                },
                {
                    "sent": "To me.",
                    "label": 0
                },
                {
                    "sent": "It's a random variable like I could show it to you, right?",
                    "label": 0
                },
                {
                    "sent": "If I show you whether it's heads or tails like, then you actually know whether it's heads or tails, right?",
                    "label": 0
                },
                {
                    "sent": "I still haven't looked so now our subjective views are that he knows it's tails and I don't know.",
                    "label": 0
                },
                {
                    "sent": "So we have different views.",
                    "label": 0
                },
                {
                    "sent": "OK, and that seems to be entirely OK.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Everything there is.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "Factors.",
                    "label": 0
                },
                {
                    "sent": "Actually I choose not to because.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's correct.",
                    "label": 0
                },
                {
                    "sent": "So one objection might be that, well, throwing a die or flipping a coin.",
                    "label": 0
                },
                {
                    "sent": "There's nothing sarcastic about that at all.",
                    "label": 0
                },
                {
                    "sent": "It's just following rules of Newtonian mechanics and you can just solve.",
                    "label": 0
                },
                {
                    "sent": "It might be that you have to be bitter cumbersome, but in principle there's nothing wrong that that's fine.",
                    "label": 0
                },
                {
                    "sent": "That's fine, OK, but still if I haven't done it.",
                    "label": 0
                },
                {
                    "sent": "I would treat it as a random variable.",
                    "label": 0
                },
                {
                    "sent": "Right, that's a crucial difference.",
                    "label": 0
                },
                {
                    "sent": "And we'd like to see an example of that of how.",
                    "label": 0
                },
                {
                    "sent": "You can invent some.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Yeah I should.",
                    "label": 0
                },
                {
                    "sent": "I should repeat the questions.",
                    "label": 0
                },
                {
                    "sent": "OK. OK, so we were talking about the fact that if you happen not to have made a measurement then you can simply treat your ignorance about this thing.",
                    "label": 0
                },
                {
                    "sent": "Although you could have made the measurement if you happen not to have made the measurement, then you can treat it as a random variable, right?",
                    "label": 0
                },
                {
                    "sent": "And weather.",
                    "label": 0
                },
                {
                    "sent": "Whether it's really random or not, that's irrelevant.",
                    "label": 0
                },
                {
                    "sent": "If you don't know what the value is, you just treat it as a random variable.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now I just have to give you a little bit of notation.",
                    "label": 0
                },
                {
                    "sent": "I hope some of this should be mostly familiar, but then at least you will get used to the way that I write things.",
                    "label": 0
                },
                {
                    "sent": "OK, let's just let's just run through these.",
                    "label": 0
                },
                {
                    "sent": "So OK, probabilities are non negative, so probabilities.",
                    "label": 0
                },
                {
                    "sent": "I usually don't distinguish between probability densities, which are probabilities over continuous domains and real probabilities that are probabilities of discrete events, or just call them all P. So probably all probabilities are.",
                    "label": 0
                },
                {
                    "sent": "Not negative and probability real probabilities are between zero and one.",
                    "label": 0
                },
                {
                    "sent": "Of course probability densities can be larger than one probability, normalized right?",
                    "label": 0
                },
                {
                    "sent": "So the probability if you sum over all possible outcomes X, then some there is one.",
                    "label": 0
                },
                {
                    "sent": "Or in discrete case the interval should be one.",
                    "label": 0
                },
                {
                    "sent": "And then I'll talk about use joint probability alright, as P of X&Y is that the joint probability of X&Y.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So that now the marginal probability of X is given by.",
                    "label": 0
                },
                {
                    "sent": "Summing out the variables that you're not interested in.",
                    "label": 0
                },
                {
                    "sent": "So in this case, from the joint distribution summing up the Y, or if it's continuous variable integrating out there, why are variable?",
                    "label": 0
                },
                {
                    "sent": "And conditional probability will also use that.",
                    "label": 0
                },
                {
                    "sent": "So the probability condition probability of X given some particular value of Y is related to the ratio of the joint probability of X&Y and the marginal probability of Y.",
                    "label": 1
                },
                {
                    "sent": "And then we will be using something called Bayes rule.",
                    "label": 0
                },
                {
                    "sent": "So this is one of the one of the unfortunate namings.",
                    "label": 0
                },
                {
                    "sent": "Sort of the better this was called the rule of conditional probability, because there's nothing intrinsically besen about that.",
                    "label": 0
                },
                {
                    "sent": "This is just a rule about how to manipulate.",
                    "label": 0
                },
                {
                    "sent": "Conditional probability is basically so you can write down the joint probability as the condition of X given Y times the probability of Y.",
                    "label": 0
                },
                {
                    "sent": "So this is going to be the joint of X&Y.",
                    "label": 0
                },
                {
                    "sent": "By just using this definition, but you could also write it as the probability of Y given X times the probability of X.",
                    "label": 0
                },
                {
                    "sent": "And now we can just rearrange terms.",
                    "label": 0
                },
                {
                    "sent": "You can then write the probability of Y given X as the probability of X given Y times the ratio of give Y&P of X and this is a rule that is often used when you're doing Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "See, but there's nothing really Bayesian about it.",
                    "label": 0
                },
                {
                    "sent": "I think we can change the name by now, unfortunately.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so let's let's try to start getting into the meat of things.",
                    "label": 0
                },
                {
                    "sent": "So first of all, there's the likelihood function, so the likelihood function is used in all kinds of in all interpretation, so the likelihood function is simply.",
                    "label": 1
                },
                {
                    "sent": "Is the probability of the observed data given the parameters.",
                    "label": 1
                },
                {
                    "sent": "So let's think about having a model that has some parameters in it, and then the likelihood function is just the the probability of those particular observations given some particular setting of those parameters.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So here we're here.",
                    "label": 0
                },
                {
                    "sent": "Let's let's try to look at the again.",
                    "label": 0
                },
                {
                    "sent": "I've tried to choose the simplest example that you can think about, so independent conflicts again.",
                    "label": 0
                },
                {
                    "sent": "So we have a parameter in the model which is, which is \u03c0 and \u03c0 stands for the probability that you're going to head.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So we say that the random variable here X take the value 0 if you get a tail and takes the value of 1 if you get ahead, OK.",
                    "label": 0
                },
                {
                    "sent": "So now a reasonable model for this is the Bernoulli likelihood, and that simply says the.",
                    "label": 0
                },
                {
                    "sent": "Now the probability of the data given the.",
                    "label": 0
                },
                {
                    "sent": "The parameter in the parameter here is \u03c0.",
                    "label": 0
                },
                {
                    "sent": "But in the actual probability written here in a slightly weird form, but I say it's \u03c0 to the X * 1 -- \u03c0 to the 1 -- X, right?",
                    "label": 0
                },
                {
                    "sent": "But remember X can only be one or zero, so if X is 1 then you get pie here, right?",
                    "label": 0
                },
                {
                    "sent": "You get high to the power one and you get 1 -- \u03c0 to the power zero, which is just one.",
                    "label": 0
                },
                {
                    "sent": "This is just sort of a weird way of writing that the probability is \u03c0 and the probability of of 0 is 1 -- \u03c0, because they probably have to sum up.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this is this.",
                    "label": 0
                },
                {
                    "sent": "Is this the likelihood function?",
                    "label": 0
                },
                {
                    "sent": "And let's say we make a number of experiments.",
                    "label": 0
                },
                {
                    "sent": "Went up North experiments.",
                    "label": 0
                },
                {
                    "sent": "And we collect those those outcomes in a data set D and we observe that K of these are our heads.",
                    "label": 0
                },
                {
                    "sent": "So now the likelihood for the for the entire experiment.",
                    "label": 0
                },
                {
                    "sent": "So each of the experiments are independent from each other.",
                    "label": 0
                },
                {
                    "sent": "'cause the coin is only like the what the outcome of the coin doesn't.",
                    "label": 0
                },
                {
                    "sent": "Doesn't doesn't have any impact on what's going to happen in the next.",
                    "label": 0
                },
                {
                    "sent": "And next experiment and now the probability here is just going to be will have K. Times will have probably pie and end.",
                    "label": 0
                },
                {
                    "sent": "This K times will have probability 1 -- \u03c0. OK, so that's it.",
                    "label": 0
                },
                {
                    "sent": "Difference here about whether you think of this as being an ordered set or you think of being an unordered set, right?",
                    "label": 0
                },
                {
                    "sent": "If you're only interested strictly only interested in the number and the number of cases, there might be sort of a combinatorial factor in front of this, so I just I just leave that away just to keep things simple.",
                    "label": 0
                },
                {
                    "sent": "So strictly I'm thinking about that particular sequence.",
                    "label": 0
                },
                {
                    "sent": "But yet you have to be put in that.",
                    "label": 0
                },
                {
                    "sent": "In that case, they, like your function looks like this.",
                    "label": 0
                },
                {
                    "sent": "Now, so an interesting thing that will come back to is that the likelihood function.",
                    "label": 1
                },
                {
                    "sent": "Is a probability distribution over data over observations.",
                    "label": 0
                },
                {
                    "sent": "Not over parameters, right?",
                    "label": 0
                },
                {
                    "sent": "So this is not.",
                    "label": 0
                },
                {
                    "sent": "This is a probability distribution over these things, right?",
                    "label": 0
                },
                {
                    "sent": "But this is not necessarily a random variable like this is just a parameter.",
                    "label": 0
                },
                {
                    "sent": "That would be that would be important when we come to do.",
                    "label": 0
                },
                {
                    "sent": "When we come to do inference.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's see.",
                    "label": 0
                },
                {
                    "sent": "Well, how do we actually do inference in?",
                    "label": 0
                },
                {
                    "sent": "In this kind of model.",
                    "label": 0
                },
                {
                    "sent": "But the classical inference is based on the idea of estimators, right?",
                    "label": 1
                },
                {
                    "sent": "So if you want to, if you want to make inference about something, then the first thing you do is you need to invent an estimator.",
                    "label": 0
                },
                {
                    "sent": "And one of the estimated, which often uses the so called maximum likelihood estimator, right?",
                    "label": 0
                },
                {
                    "sent": "And it basically says, well, let's use an estimate of the parameter, the parameter that actually maximizes the probability of the outcomes that we actually observed.",
                    "label": 1
                },
                {
                    "sent": "So this sort of sounds like a pretty reasonable.",
                    "label": 0
                },
                {
                    "sent": "A type of.",
                    "label": 1
                },
                {
                    "sent": "Estimator, but notice that that we could have chosen other estimators as well, right?",
                    "label": 0
                },
                {
                    "sent": "So the maximum likelihood estimator is just is just sort of 1.",
                    "label": 0
                },
                {
                    "sent": "One kind of estimator in statistics, people work on proving various properties of different estimators, right?",
                    "label": 0
                },
                {
                    "sent": "So you can maybe, maybe you can prove something about a particular kind of estimator that has some nice properties and that would then be a reason why this is a good estimator, right?",
                    "label": 0
                },
                {
                    "sent": "But notice that the estimator, although it sounds pretty reasonable, it doesn't really come from anywhere like.",
                    "label": 0
                },
                {
                    "sent": "It's just an invention.",
                    "label": 0
                },
                {
                    "sent": "Like somebody thought thought about this, this estimator and this is you can find that in the literature you can find proposals of various kinds of estimators for various properties in various complicated models, right?",
                    "label": 0
                },
                {
                    "sent": "So this is, this is what you do if your classical statistician right, you invent estimators, improve things about them, yes?",
                    "label": 0
                },
                {
                    "sent": "What would be a different estimator?",
                    "label": 0
                },
                {
                    "sent": "Well, different estimator would be things like penalized maximum likelihood estimators.",
                    "label": 0
                },
                {
                    "sent": "So you say, well, I want to maximize likelihood, but I also have some other constraints that I also want to satisfy, right?",
                    "label": 0
                },
                {
                    "sent": "Or it could be things like leave on out estimators so you can.",
                    "label": 0
                },
                {
                    "sent": "You can estimate you can sort of manipulate your data set, or estimators that are based on resampling ideas or bootstrapping estimators.",
                    "label": 0
                },
                {
                    "sent": "Do somehow manipulate your data set in various ways and then you do inference based on on on what happens in those cases.",
                    "label": 0
                },
                {
                    "sent": "And the game is open, right?",
                    "label": 0
                },
                {
                    "sent": "You can you can.",
                    "label": 0
                },
                {
                    "sent": "You can invent any kind of estimate.",
                    "label": 1
                },
                {
                    "sent": "Alright, you can say my estimate is 56.",
                    "label": 0
                },
                {
                    "sent": "There's no, there's no, there's no, there's no formal requirement that has to be related to your data like it's just any procedure where you can sort of compute things.",
                    "label": 0
                },
                {
                    "sent": "This is a valid estimate.",
                    "label": 0
                },
                {
                    "sent": "It might be.",
                    "label": 0
                },
                {
                    "sent": "It might not have very good properties.",
                    "label": 0
                },
                {
                    "sent": "Alright, So what would happen if we actually if you actually try to talk to maximize the likelihood in this case?",
                    "label": 0
                },
                {
                    "sent": "Well, we can.",
                    "label": 0
                },
                {
                    "sent": "We can simply compute the the maximum here.",
                    "label": 1
                },
                {
                    "sent": "So if you take the derivative of the of the likelihood or the log likelihood, respect pie and set that zero and solve for \u03c0, then you get that pie should be K / N. Um?",
                    "label": 0
                },
                {
                    "sent": "So is this a good answer?",
                    "label": 0
                },
                {
                    "sent": "Anybody have?",
                    "label": 0
                },
                {
                    "sent": "It seems like good answer, right?",
                    "label": 0
                },
                {
                    "sent": "If you roll the die 100 times and 56 times it comes out, or if you flip a coin.",
                    "label": 0
                },
                {
                    "sent": "100 * 56 times it comes out heads, then the estimate is 56% chance.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that sounds pretty good.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Right, so that's good.",
                    "label": 0
                },
                {
                    "sent": "Important objection, so let's say I flip the coin twice and I got 2 heads.",
                    "label": 0
                },
                {
                    "sent": "Now what's my probability?",
                    "label": 0
                },
                {
                    "sent": "Would be 0.",
                    "label": 0
                },
                {
                    "sent": "OK, and 0 means I'm absolutely certain that it won't happen.",
                    "label": 0
                },
                {
                    "sent": "That doesn't seem right, like there's something there's something a little bit about that right?",
                    "label": 0
                },
                {
                    "sent": "And there are ways to fix the properties of these estimators, right?",
                    "label": 0
                },
                {
                    "sent": "So maximum likelihood estimators are generally, if you have very small datasets, there are some problems there, right?",
                    "label": 0
                },
                {
                    "sent": "You should, you should worry about that.",
                    "label": 0
                },
                {
                    "sent": "OK, and there are ways to fix these things, but conceptually this is the kind of this is the kind of scheme you would have to go through right.",
                    "label": 0
                },
                {
                    "sent": "Then you have to think about an estimator that has had a little bit better properties.",
                    "label": 0
                },
                {
                    "sent": "The one way of inventing better properties.",
                    "label": 0
                },
                {
                    "sent": "Is to say, well, let's just pretend that we have actually observed ahead and entail before we start.",
                    "label": 0
                },
                {
                    "sent": "So you can sort of introduce these pseudo observations and that will that will.",
                    "label": 0
                },
                {
                    "sent": "That will prevent this thing from ever reaching one or zero.",
                    "label": 0
                },
                {
                    "sent": "You can say, well, no matter how many tails I observe.",
                    "label": 0
                },
                {
                    "sent": "Could still happen that a tail comes out right and the probability if you only observe if you make any observations and you have this sort of extra pseudo account then you would only be able to conclude that things would happen in at most one over or at least 1 / N would be the probability.",
                    "label": 0
                },
                {
                    "sent": "And that's also seems reasonable, right?",
                    "label": 0
                },
                {
                    "sent": "If you only made end experiments, how can you then be sure about outcomes that have probabilities lower than 1 / N?",
                    "label": 0
                },
                {
                    "sent": "It doesn't seem you can really gain information about things that happened that infrequently.",
                    "label": 0
                },
                {
                    "sent": "If you only made any observations right, so that would be a way to fix this kind of estimator.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what do you do if your if you want to do things in a basic way so?",
                    "label": 0
                },
                {
                    "sent": "Initially the Bayesian framework.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit more complicated, but there are more ingredients in how to formalize your problem.",
                    "label": 0
                },
                {
                    "sent": "But what I'll?",
                    "label": 0
                },
                {
                    "sent": "I'll try to show here is that in many cases the the outcome of your analysis and the actual procedure that you are applying will actually be conceptually a lot simpler in this case.",
                    "label": 0
                },
                {
                    "sent": "So let's try to do it so again, you have the likelihood function, which is the same as before.",
                    "label": 0
                },
                {
                    "sent": "The likelihood is the probability of observation given the parameters.",
                    "label": 0
                },
                {
                    "sent": "And you have a new thing here which is called, which called the prior, and the prior is the knowledge or the assumptions you make about the parameters before you make any observations.",
                    "label": 1
                },
                {
                    "sent": "OK, and this is called.",
                    "label": 0
                },
                {
                    "sent": "This is the prize is P of pie, so it's what do you know about pie before you start?",
                    "label": 0
                },
                {
                    "sent": "What do you think about the properties of the coin right?",
                    "label": 0
                },
                {
                    "sent": "It's not related to the observations, that's called the prior.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So tomorrow I talk a lot more about priorities.",
                    "label": 0
                },
                {
                    "sent": "Today I'll sort of sidestep this a little bit, so I'll talk about.",
                    "label": 0
                },
                {
                    "sent": "So in this case you have to say, well, what do you think about the coin before you start, right?",
                    "label": 0
                },
                {
                    "sent": "And people get people get a little bit uneasy about this and say, well, I don't know anything about the coin before stop.",
                    "label": 0
                },
                {
                    "sent": "And then the Bayesian would say well, then then you can't do inference, right?",
                    "label": 0
                },
                {
                    "sent": "There's no way that you can if you simply say anything could happen.",
                    "label": 0
                },
                {
                    "sent": "For a coin, is a little bit a little bit hard to imagine, but maybe it balances on the edge or something, right, but?",
                    "label": 0
                },
                {
                    "sent": "It's a little bit hard to imagine, but let's say you are using a more complicated in a more complicated scenario list that you are trading stocks, for example and say, well, what do you think?",
                    "label": 0
                },
                {
                    "sent": "What do you think the properties of stocks are?",
                    "label": 0
                },
                {
                    "sent": "You say?",
                    "label": 0
                },
                {
                    "sent": "Oh, I don't know.",
                    "label": 0
                },
                {
                    "sent": "I just want to look at the data, right?",
                    "label": 0
                },
                {
                    "sent": "And and there's some problems in that, right?",
                    "label": 0
                },
                {
                    "sent": "So and of course, the stock prices are not.",
                    "label": 0
                },
                {
                    "sent": "They can't do just anything like if you could do just anything, then it would be impossible to model, but they were doing right.",
                    "label": 0
                },
                {
                    "sent": "You say?",
                    "label": 0
                },
                {
                    "sent": "Well, the stocks have had a value of, you know.",
                    "label": 0
                },
                {
                    "sent": "It had about 200 yesterday and today it has a value of 101.",
                    "label": 0
                },
                {
                    "sent": "What do you think it has tomorrow?",
                    "label": 0
                },
                {
                    "sent": "Say well, I have no idea.",
                    "label": 0
                },
                {
                    "sent": "Could the value be 10 to 26?",
                    "label": 0
                },
                {
                    "sent": "Probably not.",
                    "label": 0
                },
                {
                    "sent": "That seems unlikely, but you do know something.",
                    "label": 0
                },
                {
                    "sent": "Of course you don't know exactly.",
                    "label": 0
                },
                {
                    "sent": "What the stock is going to be tomorrow, right?",
                    "label": 0
                },
                {
                    "sent": "If you did that, you wouldn't be here.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the prior tells us, what do we know about the promises before we start OK and we'll get back to what kind of things you could know about.",
                    "label": 0
                },
                {
                    "sent": "Bernoulli experiment, although in that experiment is not so interesting, like tomorrow, I'll talk about inference about functions.",
                    "label": 0
                },
                {
                    "sent": "So then we have prior distribution functions.",
                    "label": 0
                },
                {
                    "sent": "Then things will start becoming interesting.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, and then then we what we compute is known as the posterior.",
                    "label": 0
                },
                {
                    "sent": "So the posterior probability the probability distribution over of the of the parameters after we made observations and so now that the probability of Pi given the observation that we made.",
                    "label": 0
                },
                {
                    "sent": "OK, I notice that the difference between the the the posterior and likelihood is exactly that.",
                    "label": 0
                },
                {
                    "sent": "It's the reverse kind of probability, right?",
                    "label": 0
                },
                {
                    "sent": "So the likelihood was PD given pie and the posterior Steve Pie.",
                    "label": 0
                },
                {
                    "sent": "Given D, what does that?",
                    "label": 0
                },
                {
                    "sent": "What does the likelihood and the prior imply about?",
                    "label": 0
                },
                {
                    "sent": "The distribution over over \u03c0.",
                    "label": 0
                },
                {
                    "sent": "Now when we when we plug into this Bayes rule here by using this by swapping these conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "To get the ratio here of the prior time, the vacuum to prior divided by PFD PFD.",
                    "label": 1
                },
                {
                    "sent": "Here is just the probability of the data.",
                    "label": 1
                },
                {
                    "sent": "Sometimes refer to it the marginal likelihood or the evidence.",
                    "label": 0
                },
                {
                    "sent": "So now so now Bayesian inference simply consists of computing what is the posterior probability.",
                    "label": 0
                },
                {
                    "sent": "OK, you start by some knowledge about the data which is incorporated in the prior and then you update that based on the likelihood and then you get your posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "And then you've finished doing inference.",
                    "label": 0
                },
                {
                    "sent": "Once you have your posterior, then your and then you're done.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "What do we use the posterior for?",
                    "label": 0
                },
                {
                    "sent": "Well, you can use it to make predictions about what's going to happen in the future, so.",
                    "label": 0
                },
                {
                    "sent": "How do we do that?",
                    "label": 0
                },
                {
                    "sent": "Well, the predictions that we want to make is.",
                    "label": 1
                },
                {
                    "sent": "We want to make want to have a probability distribution over what would a future outcome be.",
                    "label": 0
                },
                {
                    "sent": "I used to start.",
                    "label": 0
                },
                {
                    "sent": "To the random variable to denote a few.",
                    "label": 0
                },
                {
                    "sent": "Here I can just write that as I have an integral here of P of X dark, even \u03c0 times P of Pi given D, so that when you multiply these two conditional probabilities together, you get P of XR.",
                    "label": 0
                },
                {
                    "sent": "An pie, even D right?",
                    "label": 0
                },
                {
                    "sent": "So it's a joint probability of XR and Pi given D and then I sum out the Pi variable.",
                    "label": 0
                },
                {
                    "sent": "So that gives me just the probability of X star given D. So this is exactly the thing that I'm looking for, right?",
                    "label": 0
                },
                {
                    "sent": "I want to know what does the observed data tell me about what's going to happen in the future.",
                    "label": 0
                },
                {
                    "sent": "OK, so notice that this is not something this is not something I invented, right?",
                    "label": 0
                },
                {
                    "sent": "I'm just writing down the thing that I want to know OK, and then I can expand it in this particular way by using the joint probability of P of XR and Pi given D and that can be written in terms of this product where one of the terms is the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "And the other term here is that just the likelihood function, right?",
                    "label": 0
                },
                {
                    "sent": "If the probability of an observation given a parameter.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that means that in the in the basin setting you simply you simply workout the probability of the thing that you're interested in and you just use the rules of probability.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And notice also that the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Is A is a probability distribution over the thing that we're interested in right parameter of the model?",
                    "label": 0
                },
                {
                    "sent": "It's not a probability distribution over data.",
                    "label": 0
                },
                {
                    "sent": "Like the data is considered to be fixed here 'cause we actually observe that it has the particular value that we observe in our experiment.",
                    "label": 0
                },
                {
                    "sent": "So another thing to notice here is that the.",
                    "label": 0
                },
                {
                    "sent": "That the that the predictions here are averages over different possible possible promises, settings, right?",
                    "label": 0
                },
                {
                    "sent": "So it's actually you actually take the prediction here and you average together that based on how much you believe in different settings, right?",
                    "label": 0
                },
                {
                    "sent": "So you might have to also seem unlikely we'll have some weight in this interval, right?",
                    "label": 0
                },
                {
                    "sent": "The more likely they are, the less weight they will have and the more likely ones or the more the ones that have higher posterior problems, will have larger weight in this interval, right?",
                    "label": 0
                },
                {
                    "sent": "But you can't rule them out like even if things have seemed to have low probability, it might still be.",
                    "label": 0
                },
                {
                    "sent": "Still be the truth right?",
                    "label": 0
                },
                {
                    "sent": "You just you just just had some unlucky observations, so they should.",
                    "label": 1
                },
                {
                    "sent": "They should also be taken into consideration.",
                    "label": 0
                },
                {
                    "sent": "And this is also a contrast between the maximum likelihood setting.",
                    "label": 0
                },
                {
                    "sent": "We just say, well, I believe that my parameter has this particular value K / N for example.",
                    "label": 0
                },
                {
                    "sent": "I disregard all the settings because they're not the maximum likelihood value.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so there's a little bit more too.",
                    "label": 0
                },
                {
                    "sent": "Two in the inpatient scheme, which is related to model selection.",
                    "label": 0
                },
                {
                    "sent": "So I won't.",
                    "label": 0
                },
                {
                    "sent": "I didn't say anything about model selection in the frequency.",
                    "label": 0
                },
                {
                    "sent": "Setting, I'll come back to how you can sort of do things like model selection, but in the Basin inference scheme, it's sort of it's sort of a natural component inside the inference scheme, whereas in the in the frequency setting you have to do something from the outside, you have to sort of.",
                    "label": 0
                },
                {
                    "sent": "Do something separate to figure out how to do do model selection.",
                    "label": 0
                },
                {
                    "sent": "I'll try to come back to that with a little example.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, let's say we have.",
                    "label": 0
                },
                {
                    "sent": "We have two different two different interpretations of how the world behaves.",
                    "label": 0
                },
                {
                    "sent": "Right now we make some, make some situations and we want to know which one of these models is the right one, or which one seems to be the most likely one.",
                    "label": 0
                },
                {
                    "sent": "Given those observations.",
                    "label": 0
                },
                {
                    "sent": "Yes, there's a question.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah.",
                    "label": 0
                },
                {
                    "sent": "So I should I should repeat the question for Barnhart.",
                    "label": 0
                },
                {
                    "sent": "So the question is.",
                    "label": 0
                },
                {
                    "sent": "In in classical statistics, you can prove various properties about these estimators.",
                    "label": 0
                },
                {
                    "sent": "So for example that in the limit of.",
                    "label": 0
                },
                {
                    "sent": "Acquiring an infinite amount of data that you have some notion of consistency you have, for example the Creamer out bound that tells you something about how fast you ask you.",
                    "label": 0
                },
                {
                    "sent": "You approach the right answer.",
                    "label": 0
                },
                {
                    "sent": "So does this kind of property exist for Bayesian inference scheme?",
                    "label": 0
                },
                {
                    "sent": "No, it doesn't, and this is this is.",
                    "label": 0
                },
                {
                    "sent": "This is also a reason why people are unhappy about this right.",
                    "label": 0
                },
                {
                    "sent": "Why doesn't it?",
                    "label": 0
                },
                {
                    "sent": "Well, it doesn't because it's subjective, right?",
                    "label": 0
                },
                {
                    "sent": "It starts by it starts by having the prior notion about about parameters, right?",
                    "label": 0
                },
                {
                    "sent": "So let's say your prior notion was that it's absolutely impossible to get ahead.",
                    "label": 0
                },
                {
                    "sent": "So now I make experiments and sometimes I get heads.",
                    "label": 0
                },
                {
                    "sent": "But if my prior was that you can't get ahead.",
                    "label": 0
                },
                {
                    "sent": "So that my prior would say it's impossible to get ahead, right?",
                    "label": 0
                },
                {
                    "sent": "So what happens when I get heads?",
                    "label": 0
                },
                {
                    "sent": "But you're right, I'll just have to sort of ignore it, right?",
                    "label": 0
                },
                {
                    "sent": "I can't do anything about that, so there's no sort of real guarantee that under all circumstances you really approach the right answer, right?",
                    "label": 0
                },
                {
                    "sent": "If the right answer was not inside the class of things that you were considering.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "From the start, then it also won't be apart of the of the things that you consider at the end, right?",
                    "label": 0
                },
                {
                    "sent": "So there's some problems here, right?",
                    "label": 0
                },
                {
                    "sent": "So now people, people try to say, well, you know, if your prior wasn't that wrong.",
                    "label": 0
                },
                {
                    "sent": "Would you then get this kind of property and then the answer is sort of yes, but there's a lot of technical questions about.",
                    "label": 0
                },
                {
                    "sent": "You know exactly what you mean by not being that wrong, right?",
                    "label": 0
                },
                {
                    "sent": "Bye.",
                    "label": 0
                },
                {
                    "sent": "No, it's not unbiased is not unbiased because it takes in.",
                    "label": 0
                },
                {
                    "sent": "It takes into consideration.",
                    "label": 0
                },
                {
                    "sent": "Also, I should repeat the question, sorry.",
                    "label": 0
                },
                {
                    "sent": "Is a Bayesian estimator unbiased?",
                    "label": 0
                },
                {
                    "sent": "And it's not unbiased.",
                    "label": 0
                },
                {
                    "sent": "The basin estimators typically biased and it's biased because it's a combination of the likelihood term but also of the prior, and the prior could be biased, right?",
                    "label": 0
                },
                {
                    "sent": "If I say, well, I actually think heads are more likely when I start off right.",
                    "label": 0
                },
                {
                    "sent": "But even though I get a lot of evidence that they are equally likely, then there's the prior still has a small contribution, right?",
                    "label": 0
                },
                {
                    "sent": "So the so the estimate will be will be biased, right?",
                    "label": 0
                },
                {
                    "sent": "So so there's a lot of, so one of the properties of the favorite properties of the classical statistics is minimum variance unbiased estimators, right?",
                    "label": 0
                },
                {
                    "sent": "So it means among the class of unbiased estimators.",
                    "label": 0
                },
                {
                    "sent": "This is the one that has the smallest variance.",
                    "label": 0
                },
                {
                    "sent": "And this sort of sounds like a nice property, but I think the more you think about it, it's not.",
                    "label": 0
                },
                {
                    "sent": "It doesn't seem to be crucial that things are unbiased.",
                    "label": 0
                },
                {
                    "sent": "Sure, it's nice if they are, but it doesn't mean if I say well, I have a biased estimator here, but actually have it has much less variance than.",
                    "label": 0
                },
                {
                    "sent": "And then the minimum variance unbiased estimator.",
                    "label": 0
                },
                {
                    "sent": "Then what are you going to do?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "The estimator is biased.",
                    "label": 0
                },
                {
                    "sent": "You could reduce the variance as much as you can.",
                    "label": 0
                },
                {
                    "sent": "Right, so there's a whole thing.",
                    "label": 0
                },
                {
                    "sent": "Classical statistics people often think about.",
                    "label": 0
                },
                {
                    "sent": "A tradeoff between.",
                    "label": 0
                },
                {
                    "sent": "Bias and variance.",
                    "label": 0
                },
                {
                    "sent": "So you can think about.",
                    "label": 0
                },
                {
                    "sent": "Can think about.",
                    "label": 0
                },
                {
                    "sent": "The notion of regularization, so it says, well, the maximum likelihood the pure maximum likelihood model has some some nasty properties in the terms that the variances of the estimators can be quite large and you can reduce that variant by introducing regularization.",
                    "label": 0
                },
                {
                    "sent": "But the consequence of introducing regularization is that you actually get a little bit of bias right, and then by adjusting the so called regularization parameter you can adjust the amount of bias and then you can.",
                    "label": 0
                },
                {
                    "sent": "You can think about trying to make the optimal tradeoff between.",
                    "label": 0
                },
                {
                    "sent": "Variance and squared bias right and?",
                    "label": 0
                },
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "OK, so sorry, I apologize, but for for not being completely clear about this, I didn't actually tell you what I mean by bias.",
                    "label": 0
                },
                {
                    "sent": "There were some questions here.",
                    "label": 0
                },
                {
                    "sent": "I sort of want to try and stay away from some of these studies.",
                    "label": 0
                },
                {
                    "sent": "Technical points and try to focus on the conceptual level.",
                    "label": 0
                },
                {
                    "sent": "So I think that more we have more questions.",
                    "label": 0
                },
                {
                    "sent": "OK, so we reach the model comparison here.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that I have two different models of how my coin behaves and now how can I use the framework here to make inferences about which which model is best?",
                    "label": 0
                },
                {
                    "sent": "And again, you just you, just you actually just compute the probability.",
                    "label": 0
                },
                {
                    "sent": "The posterior probability of the model.",
                    "label": 1
                },
                {
                    "sent": "But let's try to do that.",
                    "label": 0
                },
                {
                    "sent": "So now we have a likelihood term which I wrote before as PFD.",
                    "label": 0
                },
                {
                    "sent": "Given pie.",
                    "label": 0
                },
                {
                    "sent": "Now right.",
                    "label": 0
                },
                {
                    "sent": "Vegan pie, an hi so hi, just means a particular kind of model number.",
                    "label": 0
                },
                {
                    "sent": "Hi, OK. Um?",
                    "label": 0
                },
                {
                    "sent": "And now my prior might also depend on which model class I'm looking at, the price now P of Pi given HI.",
                    "label": 0
                },
                {
                    "sent": "And my posterior is just going to be a pie given D and hi.",
                    "label": 0
                },
                {
                    "sent": "OK so I can do so.",
                    "label": 0
                },
                {
                    "sent": "I can workout the posterior probability for or for all of my different models.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                },
                {
                    "sent": "What we what we?",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is this is wrong.",
                    "label": 0
                },
                {
                    "sent": "I see here, so this should be Piave.",
                    "label": 0
                },
                {
                    "sent": "Hi, given Pi and H right so it's the.",
                    "label": 0
                },
                {
                    "sent": "The reverse of the other probability here.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "Hi I'm sorry bout that correct that it should be P of hi given the pie.",
                    "label": 0
                },
                {
                    "sent": "It's correct the way I have it on the slightly confused here.",
                    "label": 0
                },
                {
                    "sent": "Oh sorry, yeah, I'm a little bit ahead of myself.",
                    "label": 0
                },
                {
                    "sent": "Sorry so this is just this is just the posterior probability for the parameters for each model class.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's the same expression as I had before, except that are now everywhere conditioning on hi OK. And now the the normalizing constant of the that we had before here, which would just be a fee, is now PSD.",
                    "label": 0
                },
                {
                    "sent": "Given a child, which is again is now called the marginal likelihood, or evidenced for model HI.",
                    "label": 1
                },
                {
                    "sent": "And what I want to know is I want to know what is the probability of the different models given my observations.",
                    "label": 0
                },
                {
                    "sent": "And I use Bayes rule again to swap around.",
                    "label": 0
                },
                {
                    "sent": "B&H, right?",
                    "label": 0
                },
                {
                    "sent": "So it's going to be the the.",
                    "label": 0
                },
                {
                    "sent": "Marginal likelihood for hi Times Now I have P of hi so now this is my prior over hi so it may be that before I start I actually think that one of the one of the models is a lot more likely to be true than the other one.",
                    "label": 0
                },
                {
                    "sent": "But I can't rule the other one out right.",
                    "label": 0
                },
                {
                    "sent": "So maybe if the data really favored the other one then maybe I would change my mind so I can encode again my my.",
                    "label": 0
                },
                {
                    "sent": "By prior beliefs using.",
                    "label": 0
                },
                {
                    "sent": "Using the prior here.",
                    "label": 0
                },
                {
                    "sent": "And the and the marginal likelihood here is just the normalizing constant of the previous stage of inference and the previous stage of inference.",
                    "label": 0
                },
                {
                    "sent": "You just.",
                    "label": 0
                },
                {
                    "sent": "It's just the normalizing constant of the likelihood times the prior.",
                    "label": 0
                },
                {
                    "sent": "OK. We were trying to do that.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Apple.",
                    "label": 0
                },
                {
                    "sent": "OK, so so this is going to be this boring example again, right?",
                    "label": 0
                },
                {
                    "sent": "So we can actually just compute everything.",
                    "label": 1
                },
                {
                    "sent": "So now we have two different models or two different learners.",
                    "label": 1
                },
                {
                    "sent": "I call them to be able to call this machine learning so one learner believe that the coin is fair, so it's actually not really a learner.",
                    "label": 1
                },
                {
                    "sent": "It doesn't learn anything, just believes that the coin is fair.",
                    "label": 1
                },
                {
                    "sent": "Learn Apiaceae does believe something.",
                    "label": 0
                },
                {
                    "sent": "Just learn something so it believes that.",
                    "label": 1
                },
                {
                    "sent": "All possible that all all values of Pi between zero and one are equally plausible.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 1
                },
                {
                    "sent": "This is a particular kind of probably, so the prior belief written as a probability distribution would look like this right.",
                    "label": 0
                },
                {
                    "sent": "All possible values of Pi equally likely.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Now it turns out that it's convenient to write the prior distribution in terms of a beta probability distribution, so it turns out that a uniform on interval like this is actually what's known as a as a beta 11 distribution.",
                    "label": 0
                },
                {
                    "sent": "So a piece of distribution are written down the expression for beta distribution here, so it's very closely related to the to the Bernoulli random variables, so it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a normalizing constant constant here that doesn't depend on \u03c0.",
                    "label": 0
                },
                {
                    "sent": "This just makes the probabilities over \u03c0 the integral of \u03c0.",
                    "label": 0
                },
                {
                    "sent": "One, so it's a proper probability distribution and then essentially it says it's \u03c0 to some power, also minus one, where Alpha is a parameter of the distribution times 1 -- \u03c0 to the power detail minus one.",
                    "label": 0
                },
                {
                    "sent": "So the two parameters are open beta.",
                    "label": 0
                },
                {
                    "sent": "And Peter distributions kind of look in various ways.",
                    "label": 0
                },
                {
                    "sent": "So here's a fee to 55.",
                    "label": 0
                },
                {
                    "sent": "Distribution that says that you know any value in the in the central area is reasonably reasonably probable and values sort of below say oh point 1 or above.",
                    "label": 0
                },
                {
                    "sent": "Oh, Point 9 are quite unlikely.",
                    "label": 0
                },
                {
                    "sent": "And you can also have skewed kind of distribution.",
                    "label": 0
                },
                {
                    "sent": "So here is saying that values above oh point 8 are quite unlikely, but sort of other things are.",
                    "label": 0
                },
                {
                    "sent": "Quite likely so the feature distribution here is called the conjugate prior because it has the same form that makes analysis very easy.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Alright, so let's try and make some observations.",
                    "label": 0
                },
                {
                    "sent": "So I made some observations, so I got.",
                    "label": 0
                },
                {
                    "sent": "I made 10 observations, SO33 heads and.",
                    "label": 0
                },
                {
                    "sent": "And seven tail.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "And now my question is, what do my two learners?",
                    "label": 1
                },
                {
                    "sent": "What do they?",
                    "label": 0
                },
                {
                    "sent": "What do they actually do?",
                    "label": 0
                },
                {
                    "sent": "What do they predict?",
                    "label": 0
                },
                {
                    "sent": "Well, the learner a which wasn't really a learner, just predicts half again, right?",
                    "label": 0
                },
                {
                    "sent": "It ignores the data essentially.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "What about what about Lenape?",
                    "label": 0
                },
                {
                    "sent": "So I should what I should do is I should workout the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "And now the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "I get by multiplying the prior which was a beta 11.",
                    "label": 0
                },
                {
                    "sent": "With the with the likelihood and the likelihood, here is going to be super new likelihood, right?",
                    "label": 0
                },
                {
                    "sent": "So it's \u03c0 to the power three times.",
                    "label": 0
                },
                {
                    "sent": "I haven't.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "1 -- \u03c0 To the power 7.",
                    "label": 0
                },
                {
                    "sent": "OK, so that means that the.",
                    "label": 0
                },
                {
                    "sent": "The posterior distribution is again of this beta form.",
                    "label": 0
                },
                {
                    "sent": "In particular, is the beta 4, 8 because the powers are three and seven?",
                    "label": 0
                },
                {
                    "sent": "That means that the the posterior distribution looks like this, so the posterior now says well.",
                    "label": 0
                },
                {
                    "sent": "It actually thinks that given these observations.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "It's unlikely that Pie has a very high value, right?",
                    "label": 0
                },
                {
                    "sent": "It's unlikely that the value is greater than 7.8, right?",
                    "label": 0
                },
                {
                    "sent": "Because then it would seem odd that you got 7.",
                    "label": 0
                },
                {
                    "sent": "Seven tails and only three heads.",
                    "label": 0
                },
                {
                    "sent": "If the probability of getting head was really that much higher than the probability of getting tails.",
                    "label": 0
                },
                {
                    "sent": "It's quite, it's quite likely that the probability would be a half, and it could even be the probability is quite low.",
                    "label": 0
                },
                {
                    "sent": "You could still get this.",
                    "label": 0
                },
                {
                    "sent": "Kind of data.",
                    "label": 0
                },
                {
                    "sent": "So now what is the what is now the?",
                    "label": 1
                },
                {
                    "sent": "The what predictions do those learner B make based on this data?",
                    "label": 0
                },
                {
                    "sent": "With the predictions are.",
                    "label": 0
                },
                {
                    "sent": "Now the probability of of some new outcome given the particular data set we observed.",
                    "label": 0
                },
                {
                    "sent": "And given this model class D. So now we should average together the predictions that the model make and the predictions are just pie in this case, right?",
                    "label": 0
                },
                {
                    "sent": "And you should average that over the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "And if you do that, then again things turn out to be.",
                    "label": 0
                },
                {
                    "sent": "Easy, so it's the just the normalizing constant here of the from the from the posterior.",
                    "label": 0
                },
                {
                    "sent": "And then we need to.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We need to multiply by the five, five \u03c0 to 3 * 1, Five 7, and then we need to multiply high, so that will give us another \u03c0 term in here, so it'll be high to the four as one of those parts of the 7.",
                    "label": 0
                },
                {
                    "sent": "And we then do the integral.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "We just get the normalizing constant of that.",
                    "label": 0
                },
                {
                    "sent": "So that's just the reverse ratio of this thing here.",
                    "label": 0
                },
                {
                    "sent": "But we have now 13.",
                    "label": 0
                },
                {
                    "sent": "The total count is is 13 and we have five of the pies instead of four.",
                    "label": 0
                },
                {
                    "sent": "Is that before?",
                    "label": 0
                },
                {
                    "sent": "And if you work this out, this is going to be.",
                    "label": 0
                },
                {
                    "sent": "This has a value of 1 / 3.",
                    "label": 1
                },
                {
                    "sent": "Like so, given the observations, the predictions here are that it thinks that you get heads 1/3 of the time, whereas the other model just keeps keeps on thinking that you get.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Half the time.",
                    "label": 0
                },
                {
                    "sent": "OK now so which model is the best?",
                    "label": 0
                },
                {
                    "sent": "Anyone have any who thinks Model A is the best in this case?",
                    "label": 0
                },
                {
                    "sent": "Model A that just just believes that it's a 5050 coin.",
                    "label": 0
                },
                {
                    "sent": "No one does anybody believe that B is the best.",
                    "label": 0
                },
                {
                    "sent": "No one believes anything.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, a few hands here.",
                    "label": 0
                },
                {
                    "sent": "Alright, so B seems to be the best model, right?",
                    "label": 0
                },
                {
                    "sent": "Because it actually it actually takes into account the observations here, right?",
                    "label": 0
                },
                {
                    "sent": "So it actually actually modifies its belief.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's try to work this out.",
                    "label": 0
                },
                {
                    "sent": "So we have the machinery from the future.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Before is actually trying to work out what is the probability of of the different models.",
                    "label": 0
                },
                {
                    "sent": "So now for learner a learner that's not a learner.",
                    "label": 0
                },
                {
                    "sent": "What's the probability of?",
                    "label": 0
                },
                {
                    "sent": "We can workout the.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The probability of the data give the model and let's say a prayer I we don't know which model is right.",
                    "label": 0
                },
                {
                    "sent": "So let's say that the prior on each model is just half half half.",
                    "label": 0
                },
                {
                    "sent": "We think either could be true, but we don't really assign a preference here.",
                    "label": 0
                },
                {
                    "sent": "So in that case the.",
                    "label": 0
                },
                {
                    "sent": "The top level inference here.",
                    "label": 0
                },
                {
                    "sent": "So now we want to do the inference here.",
                    "label": 0
                },
                {
                    "sent": "Now, if this thing is the same for all model classes, then we should just rank the models instead of ranking according to the posterior probability of the model will be the same ranking it just according to the marginal likelihood, right?",
                    "label": 0
                },
                {
                    "sent": "So we are working out the marginal likelihood now.",
                    "label": 0
                },
                {
                    "sent": "So the margin activity here is just for the, for the for the learner who is not a learner, the probability of any data set is just.",
                    "label": 0
                },
                {
                    "sent": "1/2 to the Power 10 right, because every observation has a probability of how.",
                    "label": 0
                },
                {
                    "sent": "And 1/2 to the power 10 is this small number 4.0098.",
                    "label": 0
                },
                {
                    "sent": "So what about Lenape?",
                    "label": 0
                },
                {
                    "sent": "Well, learn RP just has this.",
                    "label": 0
                },
                {
                    "sent": "To be now the normalizing constant of the prior times likelihood.",
                    "label": 0
                },
                {
                    "sent": "And that happens to again have this particular beta form.",
                    "label": 0
                },
                {
                    "sent": "So the normalizing constant is actually the gamma, four times gamma 8 divided by gamma 12.",
                    "label": 0
                },
                {
                    "sent": "Which is open 076.",
                    "label": 0
                },
                {
                    "sent": "This means this case the.",
                    "label": 0
                },
                {
                    "sent": "The inference would say that learner B is a little bit less likely than learner A. OK.",
                    "label": 1
                },
                {
                    "sent": "So how can that be so?",
                    "label": 0
                },
                {
                    "sent": "Learner B actually took the data into account and now it comes out that learner B seems to be a little bit less preferred doing this.",
                    "label": 0
                },
                {
                    "sent": "Using this analysis.",
                    "label": 0
                },
                {
                    "sent": "Well, let's try to think about on to think about the probability according to the maximum likelihood estimate.",
                    "label": 0
                },
                {
                    "sent": "So our maximum likelihood estimate here would be 3 / 10 right?",
                    "label": 1
                },
                {
                    "sent": "Because we got three of the outcomes were ahead.",
                    "label": 0
                },
                {
                    "sent": "So we have the masculine or \u03c0 will be 3 / 10.",
                    "label": 0
                },
                {
                    "sent": "And the probability of the data set given our maximum likelihood estimate is going to be free over 10 to the Power 3 and 7 / 10 to the power of 7 * 7 / 10 power.",
                    "label": 0
                },
                {
                    "sent": "Seven years we get because this outcome seven times in this outcome three times right?",
                    "label": 0
                },
                {
                    "sent": "And that's open 022.",
                    "label": 0
                },
                {
                    "sent": "So that's much much higher.",
                    "label": 0
                },
                {
                    "sent": "Than any of the other properties.",
                    "label": 0
                },
                {
                    "sent": "In particular, is much higher than the learner that doesn't learn, but there not a right.",
                    "label": 0
                },
                {
                    "sent": "And why is it much higher than a?",
                    "label": 0
                },
                {
                    "sent": "Well, because it actually, it actually moves the probability mass to things that happen to occur and observations, right?",
                    "label": 0
                },
                {
                    "sent": "But in some sense that a little bit unreasonable, right?",
                    "label": 0
                },
                {
                    "sent": "Because because we already, we already looked at the data, right?",
                    "label": 0
                },
                {
                    "sent": "So the data contains some random fluctuations that we don't expect, even if the probability was 5050.",
                    "label": 0
                },
                {
                    "sent": "We don't know for sure that we would get five of one type in five of the other right.",
                    "label": 0
                },
                {
                    "sent": "We could be that we get could even be that you get free in seven, actually three and seven doesn't seem that unlikely, even if the coin was completely fair.",
                    "label": 0
                },
                {
                    "sent": "So the so the maximum likelihood estimator it simply says, well, you know this is my.",
                    "label": 0
                },
                {
                    "sent": "This is my maximum likelihood estimate and the probability of my data set based on that is just going to be given by just focusing the mass where where the outcomes.",
                    "label": 0
                },
                {
                    "sent": "Where we actually saw the outcome.",
                    "label": 0
                },
                {
                    "sent": "But if you then compare these two bottles then you would say, well, this model seems to be do a much better job of modeling the data, but there's something a little bit wrong about that right?",
                    "label": 0
                },
                {
                    "sent": "Because?",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's clear if you have a parameter that you can you can fiddle with, then you can model the data better, but that doesn't really prove that that the.",
                    "label": 0
                },
                {
                    "sent": "That the model is better, right?",
                    "label": 0
                },
                {
                    "sent": "And this is related to.",
                    "label": 0
                },
                {
                    "sent": "Notion, which is called overfitting.",
                    "label": 0
                },
                {
                    "sent": "So if you have a data set, if you train a model so this is a very simple example of that right?",
                    "label": 0
                },
                {
                    "sent": "But even if you have more complicated models which I use, the machine learning if you fit the parameters in your model to your particular data set then you are very good at modeling that particular data set, but that's not really what you're interested in, right?",
                    "label": 0
                },
                {
                    "sent": "What you are interested in is modeling the the relationship that are intrinsic to the data, right?",
                    "label": 0
                },
                {
                    "sent": "Not that particular outcome.",
                    "label": 0
                },
                {
                    "sent": "You already know what that outcome is.",
                    "label": 0
                },
                {
                    "sent": "Don't need to model that we want to model things about.",
                    "label": 0
                },
                {
                    "sent": "What's going to happen in the future?",
                    "label": 0
                },
                {
                    "sent": "And somehow it seems that this this Bayesian scheme wasn't fooled by that, right?",
                    "label": 0
                },
                {
                    "sent": "It didn't just go for modeling the data in a better way.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's leave.",
                    "label": 0
                },
                {
                    "sent": "Resolving this.",
                    "label": 0
                },
                {
                    "sent": "Issue, try to explain what's going on here till after a 10 minute break where you can't have any coffee.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I'll take you can come and talk to me.",
                    "label": 0
                },
                {
                    "sent": "And if people have questions I can repeat the questions after when we start again.",
                    "label": 0
                }
            ]
        }
    }
}