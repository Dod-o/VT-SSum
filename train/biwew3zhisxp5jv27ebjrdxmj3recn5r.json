{
    "id": "biwew3zhisxp5jv27ebjrdxmj3recn5r",
    "title": "Probabilistic Inference and Differential Privacy",
    "info": {
        "author": [
            "Frank McSherry, Microsoft Research"
        ],
        "published": "March 25, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Principal Component Analysis"
        ]
    },
    "url": "http://videolectures.net/nips2010_mcsherry_pid/",
    "segmentation": [
        [
            "Hello so the poster is T72 I think, but let me let me tell you about what you will be seeing.",
            "So differential privacy is this really cool new privacy criterion that's come around recently.",
            "The definitions up there.",
            "You don't need to read it, but the rough idea is that it in a very crisp way, prevents inference about individual records and input data set, so precludes certain outcomes being incredibly likely with and without single individual records, which would potentially disclose their presence.",
            "Now the privacy is neat.",
            "It unfortunately precludes direct observation of the underlying data set.",
            "That's too bad, but it doesn't preclude relatively good probabilistic inference about.",
            "About the data itself, so large trends can be revealed even if specific individual records are not now historically what people have done with differential privacy is just to say, let's imagine the data is so large that we can just take the output as true, right?",
            "If you go and we actually measure an average or account or something like that will just say let's just call it, call it correct.",
            "Different prices generally has this even nicer property.",
            "Descend down here that no one's really tinkered with much before, which is that it explicitly exposes the conditional probabilities between datasets and outcomes, and this hasn't been used before.",
            "The Fox stock sale results makes a lot of sense here.",
            "Nips to talk about."
        ],
        [
            "Actually doing proper probabilistic inference and trying to get a bit more of a intelligent understanding about what our observations that we made actually did tell us about the data, potentially about parameters of the data.",
            "So that's what we're really going to.",
            "We're going to set up a model that.",
            "Whereas in the past we might have had a theater and then a bunch of directly observable data from which we do inference back over the data, we no longer have directly observable data.",
            "We have now instead, a noisy sensor applied to the data.",
            "We would have liked to have directly observed, but we can still write down the mathematics for what the conditional probabilities between these observations and the model parameters are, and this integral is pretty big and gross units over.",
            "Typically millions of records and.",
            "The dimensionality is enormous, so we have to be a bit clever.",
            "Want to go out and do these things.",
            "The method is perfectly simply defined now here on this slide.",
            "The reasons we might want to do."
        ],
        [
            "Yes, I'm not going to tell you how we do things are complicated.",
            "You can come and chat with me about them, but the reasons hopefully are clear.",
            "These are things that are new to differential privacy, obviously not new to the NIPS crowd, though.",
            "The ability to put together lots of different observations, integrate understanding, express our confidence about what they tell us about the parameters.",
            "Folding in priors about about these datasets.",
            "This is really important.",
            "Lot of people come to these datasets with some knowledge, for example, that counts are always non negative at something that differential privacy had some problems with in the past.",
            "And finally one of the big challenges that a lot of these privacy mechanisms have is that there's a lot of different people want to use the same resources secret data and they might like to ask questions that other people haven't asked yet and you can actually use probabilistic inference very naturally to derive posteriors over questions that haven't explicitly been posed of the data set.",
            "So we can look at.",
            "Other questions that have been asked that might be approximate and drive drive posteriors.",
            "We have some pretty pictures up here of some stuff we did with principal components analysis, though I should hold off on that until the.",
            "The poster."
        ],
        [
            "Just to pitch a little bit about.",
            "Can this actually be useful?",
            "Does it actually work?",
            "We went and we tried this out with logistic regression on a few different datasets.",
            "The main takeaways from these pictures.",
            "Again, we can talk about them, or is that there's a heuristic algorithm that we put together?",
            "It's very simple gradient descent.",
            "We layered probabilistic inference on top of it, and so I noted improvements in both the error rates which have dropped and the concentration, which also shrunk and compared it.",
            "Not especially thoroughly, but compared it to paper from NIPS 08 where they were also looking at logistic regression on a synthetic data set of their choosing and found that this is one of the one of the better approaches that we're currently aware of for doing logistic regression with differential privacy.",
            "Bringing out this probabilistic probabilistic inference technology, little pretty pictures at the bottom are showing the CDF, so the error rates or see them shift from the dotted heuristic to the concentrated blue, which is probabilistic inference, but I'll stop there.",
            "Poster #72 if you'd like to combine here bout probabilistic inference in differential privacy or just machine learning, differential privacy.",
            "Generally happy to chat about that too, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello so the poster is T72 I think, but let me let me tell you about what you will be seeing.",
                    "label": 0
                },
                {
                    "sent": "So differential privacy is this really cool new privacy criterion that's come around recently.",
                    "label": 1
                },
                {
                    "sent": "The definitions up there.",
                    "label": 0
                },
                {
                    "sent": "You don't need to read it, but the rough idea is that it in a very crisp way, prevents inference about individual records and input data set, so precludes certain outcomes being incredibly likely with and without single individual records, which would potentially disclose their presence.",
                    "label": 1
                },
                {
                    "sent": "Now the privacy is neat.",
                    "label": 0
                },
                {
                    "sent": "It unfortunately precludes direct observation of the underlying data set.",
                    "label": 1
                },
                {
                    "sent": "That's too bad, but it doesn't preclude relatively good probabilistic inference about.",
                    "label": 0
                },
                {
                    "sent": "About the data itself, so large trends can be revealed even if specific individual records are not now historically what people have done with differential privacy is just to say, let's imagine the data is so large that we can just take the output as true, right?",
                    "label": 1
                },
                {
                    "sent": "If you go and we actually measure an average or account or something like that will just say let's just call it, call it correct.",
                    "label": 0
                },
                {
                    "sent": "Different prices generally has this even nicer property.",
                    "label": 0
                },
                {
                    "sent": "Descend down here that no one's really tinkered with much before, which is that it explicitly exposes the conditional probabilities between datasets and outcomes, and this hasn't been used before.",
                    "label": 0
                },
                {
                    "sent": "The Fox stock sale results makes a lot of sense here.",
                    "label": 0
                },
                {
                    "sent": "Nips to talk about.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually doing proper probabilistic inference and trying to get a bit more of a intelligent understanding about what our observations that we made actually did tell us about the data, potentially about parameters of the data.",
                    "label": 1
                },
                {
                    "sent": "So that's what we're really going to.",
                    "label": 0
                },
                {
                    "sent": "We're going to set up a model that.",
                    "label": 0
                },
                {
                    "sent": "Whereas in the past we might have had a theater and then a bunch of directly observable data from which we do inference back over the data, we no longer have directly observable data.",
                    "label": 1
                },
                {
                    "sent": "We have now instead, a noisy sensor applied to the data.",
                    "label": 0
                },
                {
                    "sent": "We would have liked to have directly observed, but we can still write down the mathematics for what the conditional probabilities between these observations and the model parameters are, and this integral is pretty big and gross units over.",
                    "label": 0
                },
                {
                    "sent": "Typically millions of records and.",
                    "label": 0
                },
                {
                    "sent": "The dimensionality is enormous, so we have to be a bit clever.",
                    "label": 0
                },
                {
                    "sent": "Want to go out and do these things.",
                    "label": 0
                },
                {
                    "sent": "The method is perfectly simply defined now here on this slide.",
                    "label": 0
                },
                {
                    "sent": "The reasons we might want to do.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, I'm not going to tell you how we do things are complicated.",
                    "label": 0
                },
                {
                    "sent": "You can come and chat with me about them, but the reasons hopefully are clear.",
                    "label": 0
                },
                {
                    "sent": "These are things that are new to differential privacy, obviously not new to the NIPS crowd, though.",
                    "label": 0
                },
                {
                    "sent": "The ability to put together lots of different observations, integrate understanding, express our confidence about what they tell us about the parameters.",
                    "label": 0
                },
                {
                    "sent": "Folding in priors about about these datasets.",
                    "label": 0
                },
                {
                    "sent": "This is really important.",
                    "label": 0
                },
                {
                    "sent": "Lot of people come to these datasets with some knowledge, for example, that counts are always non negative at something that differential privacy had some problems with in the past.",
                    "label": 0
                },
                {
                    "sent": "And finally one of the big challenges that a lot of these privacy mechanisms have is that there's a lot of different people want to use the same resources secret data and they might like to ask questions that other people haven't asked yet and you can actually use probabilistic inference very naturally to derive posteriors over questions that haven't explicitly been posed of the data set.",
                    "label": 0
                },
                {
                    "sent": "So we can look at.",
                    "label": 0
                },
                {
                    "sent": "Other questions that have been asked that might be approximate and drive drive posteriors.",
                    "label": 0
                },
                {
                    "sent": "We have some pretty pictures up here of some stuff we did with principal components analysis, though I should hold off on that until the.",
                    "label": 0
                },
                {
                    "sent": "The poster.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just to pitch a little bit about.",
                    "label": 0
                },
                {
                    "sent": "Can this actually be useful?",
                    "label": 0
                },
                {
                    "sent": "Does it actually work?",
                    "label": 0
                },
                {
                    "sent": "We went and we tried this out with logistic regression on a few different datasets.",
                    "label": 0
                },
                {
                    "sent": "The main takeaways from these pictures.",
                    "label": 0
                },
                {
                    "sent": "Again, we can talk about them, or is that there's a heuristic algorithm that we put together?",
                    "label": 0
                },
                {
                    "sent": "It's very simple gradient descent.",
                    "label": 0
                },
                {
                    "sent": "We layered probabilistic inference on top of it, and so I noted improvements in both the error rates which have dropped and the concentration, which also shrunk and compared it.",
                    "label": 1
                },
                {
                    "sent": "Not especially thoroughly, but compared it to paper from NIPS 08 where they were also looking at logistic regression on a synthetic data set of their choosing and found that this is one of the one of the better approaches that we're currently aware of for doing logistic regression with differential privacy.",
                    "label": 1
                },
                {
                    "sent": "Bringing out this probabilistic probabilistic inference technology, little pretty pictures at the bottom are showing the CDF, so the error rates or see them shift from the dotted heuristic to the concentrated blue, which is probabilistic inference, but I'll stop there.",
                    "label": 0
                },
                {
                    "sent": "Poster #72 if you'd like to combine here bout probabilistic inference in differential privacy or just machine learning, differential privacy.",
                    "label": 0
                },
                {
                    "sent": "Generally happy to chat about that too, thanks.",
                    "label": 0
                }
            ]
        }
    }
}