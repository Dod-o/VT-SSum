{
    "id": "dshfkyqp24zbig6xafsgaygfrvwtumgj",
    "title": "FEASIBLE: A Featured-Based SPARQL Benchmarks Generation Framework",
    "info": {
        "author": [
            "Muhammad Saleem, Agile Knowledge Engineering and Semantic Web (AKSW), University of Leipzig"
        ],
        "published": "Nov. 10, 2015",
        "recorded": "October 2015",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2015_saleem_featured_based/",
    "segmentation": [
        [
            "Today I'm going to present feasible, which is a feature based particle benchmark generation framework.",
            "So the whole problem statement is that, for example, we have many users with different requirements and they want to test their triple stores with different requirements.",
            "For example, there is a person who want to test their triple stores with for example queries containing triple patterns greater than 10.",
            "And let's suppose they want that filter should be included.",
            "Union should be included and they just don't want only sparkle select queries.",
            "They also want to include.",
            "For example, ask queries so they just want to customize their benchmark and test according to you know their requirement.",
            "So here is the solution for that.",
            "So this is a sparkle benchmark generation framework out of the real query logs, so it takes as input as a query log and then you can specify all of your filters and then the number of queries in.",
            "You will get the results for that.",
            "So if you want to try right now, here is the link for that.",
            "So just a live demo available for that.",
            "You can try that feasible.aksw.org.",
            "And you can generate a benchmark of your choice.",
            "So."
        ],
        [
            "So in general we talking Sparkle benchmark can be categorized into 2 main categories.",
            "One is based on the synthetic data and one is best based on the real data in real queries.",
            "Each one has its pros and cons, so it depends.",
            "For example, synthetic benchmark there of course make use of the synthetic data and maybe having some data generators in synthetic queries.",
            "So what is the advantage of that?",
            "You can test the scalability of your system because you can generate your NOT benchmark of varying.",
            "Sorry you can generate benchmark of Europe varying data set sizes in different queries and it's up to you.",
            "It's like you can test the scalability, but on the other side there is a problem with this as well.",
            "Do they really reflect the reality?",
            "So that's a question like if there is a sparkle endpoints an you are getting, you know you know real queries so there.",
            "So do the benchmark really reflect the actual queries that is expecting by the sparkle endpoint?",
            "That's a question that need to be addressed.",
            "So the synthetic benchmarks are famous examples.",
            "Aurelia VM, S, B2B bench, and BS BM, and the recent one Waterloop benchmarks.",
            "So these are all synthetic benchmarks and there are real benchmark as well.",
            "So an example of that is DB pedia and the one solution we're just provided is also feasible.",
            "So it has also advantages and disadvantages.",
            "But the main advantage is that if your approach is really good.",
            "And then you can generate something benchmark that is close to the reality.",
            "It cannot be exact, you know very, you know perfect, but it can be close to the reality.",
            "So there's the advantage of that.",
            "And of course you can.",
            "You can test the scalability of the system as well.",
            "For different, you know, data set sizes and different number of queries."
        ],
        [
            "So since our benchmark is based on the real queries and so I will try, I will try to explain the only one that that I know to the best of my knowledge is that is based on the real queries.",
            "Benchmark is a DB pedia so.",
            "It is based on the DB pedia, real queries and here you can have a benchmark of different data set sizes and different queries so you can test the scalability of your system with 10% of DB pedia, 2050 whatever you want.",
            "But one problem is that it only selects sparkle, it only considers sparkle select queries.",
            "But we have 4 forms of query sparkle ask we have described we have construct.",
            "So these these other three forms are not included in the DB pedia.",
            "And another important feature that is missing is some of the important query features that was that are proven to effect the overall query performance or not.",
            "Considering the DB Pedia sparkle benchmark, for example in the water loop benchmark, they they shown that the number of join what it says N triple patron selectivity is all these things.",
            "All effects the query performance but they didn't in the DB pedia.",
            "These kind of things are not included.",
            "In this study, Pedia benchmark is not that much highly customizable according to the use case specific requirement."
        ],
        [
            "So to address these problems, we come up with a new benchmark generation framework which is called feasible.",
            "Here.",
            "It can be applied to any sparkle query logs.",
            "And it consider any of the four query forms, and it's also considered the important query features.",
            "For example, the number of join, what is triple patterns?",
            "Selectivity is be GPS and unions filter or whatever like not whatever, but like the majority of the features are covered here.",
            "And the advantage of that is you can generate a customizable and use case specific benchmarks out of using feasible."
        ],
        [
            "So here how the how you how a user can generate a benchmark.",
            "There are four steps.",
            "So the first one is data set cleaning and the second one is a feature selection and normalization I mean feature vectors and then the selection of exemplars, and then the selection of benchmark queries.",
            "So I will explain each step one by."
        ],
        [
            "So the first one is data set cleaning.",
            "We buy data set cleaning.",
            "I mean the query logs cleaning so there can be a lot of you know queries in the in the in the log that have let synthetic errors that can have 0 results that can help like different issues.",
            "So we just to generate a more high quality benchmark.",
            "We remove this kind of queries, But there this is an optional step you can include or you can remove it.",
            "So the."
        ],
        [
            "Second one is the feature vector selection and the normalization.",
            "I will just explain an example here.",
            "Let's suppose I have a query which is containing two triple Petra petronela limit and select query.",
            "So here are some features.",
            "For example the query type is selected in the result sizes 13 basic graph patterns or one join vertices or 1 min triple pattern.",
            "Selectivity is 2.",
            "So we have like a 16 various features in.",
            "Similarly we have like what are the.",
            "You know important features included.",
            "For example Union order by limit offset filter group by an.",
            "Also the query runtime.",
            "So I would like to mention this query runtime is not the real one.",
            "Rather we just you know executed on a local sparkle endpoint.",
            "It just give a rough idea to the user.",
            "So here are some features that are considered in our benchmark.",
            "So how we do that?",
            "First, we represent each of these feature is at.",
            "Feature vector, so all those values that are numbers, for example 1311 they are written as it is, but for the German there are some Boolean variables.",
            "For example distinct is use or not order by use or not.",
            "So if it's used that we use one value for that.",
            "If it's not used then we use zero value for that.",
            "So we have a feature vector pertaining to each of the sparkle query.",
            "Now the next step is we normalize this vector.",
            "These features from zero to 1.",
            "So here is the result for that.",
            "So once we normalize all all of those features from zero to 1 then."
        ],
        [
            "Go to the second step, which is the selection of examplars and now here is an example.",
            "I have a query.",
            "Let's suppose I have a set of queries which are 10 from Q1 to Q10 and just for the sake of simplicity here I'm only showing 2 feature because just to have a 2 dimensional space.",
            "But in reality we have like 16 or 18 dimensions.",
            "So here I'm only taking two features and there are some values for that given.",
            "So the first, the first step is that you just need to plot these vectors.",
            "I mean these 10 queries represented as a feature vectors in a multi dimensional space.",
            "So here is the representation for that.",
            "Now, once you represent each query in the multi dimensional space then the second thing is.",
            "Just left suppose is an example.",
            "We have 10 queries and a user is interested to select a benchmark of three queries out of 10, but that should reflect the overall 10 queries.",
            "There's the whole problem."
        ],
        [
            "Now how we are doing this?",
            "Once you plug those queries in a multi dimensional space, you just need to find the middle point where is the middle point or the average.",
            "So you can, you can see it is.",
            "I hope you can see it's like in a red dot near to the query #5.",
            "So once you find the middle of the multi dimensional space, Now the 1st."
        ],
        [
            "Thing is that you need to select.",
            "You need to compute the distances.",
            "To the to the middle of all queries and pick that query that has the minimum distance.",
            "So in our case the minimum distance to averages Q #5.",
            "So that is our first example are secure #5 is selected.",
            "Now the next step is that same since we need to generate a benchmark of three queries.",
            "So we need to reply to.",
            "You know process the to repeat the same step three times.",
            "So the next question is that now we need to find the.",
            "Created date has the longest distance from Q5.",
            "So here if we can see it.",
            "OK so here is, as I mentioned, the red red dots showing the example that we have selected."
        ],
        [
            "Now, if you want to find what is the maximum distance from Q5 and here it turns out.",
            "That Q4 is the longest from Q5, so we will select."
        ],
        [
            "That is the 2nd example now."
        ],
        [
            "In the third step, we need to select the the example that has the longest distance from these two.",
            "I mean that is the farthest distance from Q5 and Q4 and that is Q #9."
        ],
        [
            "So once we selected the example."
        ],
        [
            "Now we go to the final step, which is the clustering.",
            "So we start we start with query number one and compute the distances of queue number one to each of the example are in bind that query to the to the minimum distance example or so."
        ],
        [
            "Here query number one is shortest to Q #5, so that's A1 cluster study.",
            "Now we go to cure a number 2."
        ],
        [
            "So clearly #2 is also close to Q5 and now we."
        ],
        [
            "Go to three and four."
        ],
        [
            "And similarly you are."
        ],
        [
            "Going annual"
        ],
        [
            "Repeat the whole pro."
        ],
        [
            "For all queries now we have 3, three different clusters and now the final thing is that we just need to.",
            "You need to again find the middle of each cluster and select that query that has the shortest distance to that average."
        ],
        [
            "So here."
        ],
        [
            "So if you say that average is here and."
        ],
        [
            "Acute.",
            "Number two is the shortest distance to the average, so Q2 is the query that is finally selected as a benchmark and similarly similarly the for the other cluster."
        ],
        [
            "So we have generated a benchmark of three queries out of that."
        ],
        [
            "So."
        ],
        [
            "Now the next problem is how we can evaluate that?",
            "OK, how efficient is my benchmark pertaining to the real query log?",
            "So here we have a formula for that due to shortage of time, I will not explain, but it's like mean square root error of the mean values and the standard deviation.",
            "So we just combine them in that formula."
        ],
        [
            "Then what we tested we tested fourth was a sparkle endpoints virtuoso SISMI, an for dicianno limb.",
            "And the setup was almost like the same that each each of these was using six GP."
        ],
        [
            "Frame and the first important comparison is there to to see what is the composite error, how efficient we are closely, how closely we are reflecting the query logs.",
            "So here is the result.",
            "If we compare with the DB pedia so.",
            "Our feasible is able to generate your benchmark which has error 54.5% less than DB pedia.",
            "I just like to mention we tried those experiments on DB pedia query log and the semantic Web dog food query query log."
        ],
        [
            "So here are some results since the previous experiments were only based on Sparkle select query.",
            "We also included and check whether the there is any difference among the sparkle, ask and escribed and the other four query forms.",
            "And it turns out that virtuoso is the fastest one for the rest of the three, but for the describe queries is not the fastest rather."
        ],
        [
            "Olim sorry, the position is the fastest for that and here is some other.",
            "Results for is as well."
        ],
        [
            "So, just to summarize the result, what we did, we just rank the each of the sparkle endpoint in.",
            "The values are here showing are in percentages, so for example for semantic web dog, food virtuoso is number one in 38% of queries and so on.",
            "So now if you if if you just summarize the result based on these tables, we come up to some of the very interesting results.",
            "The first one is that none of the system is all winner or solos are for a specific, you know, perform particular link rank and virtuoso performance, usually in the Top Rank rank one airing 24Z key is usually in the middle ranked second and third.",
            "And Oleum is it is on the slower side.",
            "Usually rank three or four.",
            "An interesting observation is about Sesame is either too fast or either too slow so.",
            "And you can see the result about that."
        ],
        [
            "So that's all from my side.",
            "If you want to try the demo there.",
            "We have a demo session as well and you can generate a benchmark whatever you want.",
            "Here is the demo for that, that's all.",
            "Thank you for your listening and now I'm happy to take questions.",
            "How does your approach compared to random sampling of queries?",
            "Here we compared to.",
            "Yeah, actually, that's a very good question.",
            "There are like different clustering approaches that we should compare, but for this we didn't compare.",
            "We just select this approach based on our previous experiments.",
            "Experimental result of there is a lines, you know link discovery framework.",
            "So we adopted from there.",
            "But now we are trying to compare for example with.",
            "Came in clustering random sampling.",
            "All this stuff and see like whether we get more, you know efficient benchmark or not.",
            "But currently we haven't compared with any of the existing clustering approaches.",
            "Could have a question, So what you seem to indicate there is that your method chooses like representative queries if I like so I was wondering how this distance measure.",
            "So you basically say there is a.",
            "The distance distance measure chooses representative queries for for the, for the, for the query logs.",
            "Yeah, I have to say I'm not 100% sure where this intuition necessarily holds, because if you compute this by these distances you might just end up with picking one in the middle where there is only one and around there there are queries with other characteristic of which you maybe have not considered in your feature set that are would be more common.",
            "Yeah, that's exactly like as I said, this benchmark is highly flexible, so it's not.",
            "You could add more features.",
            "For example, there are some features that were not covered.",
            "We have 16 features, but Sparkle 1.1 features are not covered, but it's very, very easily extendable and you can add whatever you want and that will be one more dimension to the you know, the overall multi dimensional space and then like you can compute the composite error.",
            "I hope it will be almost the same so it's highly flexible so you can add whatever you want."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Today I'm going to present feasible, which is a feature based particle benchmark generation framework.",
                    "label": 1
                },
                {
                    "sent": "So the whole problem statement is that, for example, we have many users with different requirements and they want to test their triple stores with different requirements.",
                    "label": 0
                },
                {
                    "sent": "For example, there is a person who want to test their triple stores with for example queries containing triple patterns greater than 10.",
                    "label": 0
                },
                {
                    "sent": "And let's suppose they want that filter should be included.",
                    "label": 0
                },
                {
                    "sent": "Union should be included and they just don't want only sparkle select queries.",
                    "label": 0
                },
                {
                    "sent": "They also want to include.",
                    "label": 0
                },
                {
                    "sent": "For example, ask queries so they just want to customize their benchmark and test according to you know their requirement.",
                    "label": 0
                },
                {
                    "sent": "So here is the solution for that.",
                    "label": 0
                },
                {
                    "sent": "So this is a sparkle benchmark generation framework out of the real query logs, so it takes as input as a query log and then you can specify all of your filters and then the number of queries in.",
                    "label": 0
                },
                {
                    "sent": "You will get the results for that.",
                    "label": 0
                },
                {
                    "sent": "So if you want to try right now, here is the link for that.",
                    "label": 0
                },
                {
                    "sent": "So just a live demo available for that.",
                    "label": 0
                },
                {
                    "sent": "You can try that feasible.aksw.org.",
                    "label": 0
                },
                {
                    "sent": "And you can generate a benchmark of your choice.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in general we talking Sparkle benchmark can be categorized into 2 main categories.",
                    "label": 0
                },
                {
                    "sent": "One is based on the synthetic data and one is best based on the real data in real queries.",
                    "label": 0
                },
                {
                    "sent": "Each one has its pros and cons, so it depends.",
                    "label": 0
                },
                {
                    "sent": "For example, synthetic benchmark there of course make use of the synthetic data and maybe having some data generators in synthetic queries.",
                    "label": 1
                },
                {
                    "sent": "So what is the advantage of that?",
                    "label": 0
                },
                {
                    "sent": "You can test the scalability of your system because you can generate your NOT benchmark of varying.",
                    "label": 0
                },
                {
                    "sent": "Sorry you can generate benchmark of Europe varying data set sizes in different queries and it's up to you.",
                    "label": 0
                },
                {
                    "sent": "It's like you can test the scalability, but on the other side there is a problem with this as well.",
                    "label": 1
                },
                {
                    "sent": "Do they really reflect the reality?",
                    "label": 0
                },
                {
                    "sent": "So that's a question like if there is a sparkle endpoints an you are getting, you know you know real queries so there.",
                    "label": 0
                },
                {
                    "sent": "So do the benchmark really reflect the actual queries that is expecting by the sparkle endpoint?",
                    "label": 1
                },
                {
                    "sent": "That's a question that need to be addressed.",
                    "label": 0
                },
                {
                    "sent": "So the synthetic benchmarks are famous examples.",
                    "label": 0
                },
                {
                    "sent": "Aurelia VM, S, B2B bench, and BS BM, and the recent one Waterloop benchmarks.",
                    "label": 0
                },
                {
                    "sent": "So these are all synthetic benchmarks and there are real benchmark as well.",
                    "label": 0
                },
                {
                    "sent": "So an example of that is DB pedia and the one solution we're just provided is also feasible.",
                    "label": 0
                },
                {
                    "sent": "So it has also advantages and disadvantages.",
                    "label": 0
                },
                {
                    "sent": "But the main advantage is that if your approach is really good.",
                    "label": 0
                },
                {
                    "sent": "And then you can generate something benchmark that is close to the reality.",
                    "label": 1
                },
                {
                    "sent": "It cannot be exact, you know very, you know perfect, but it can be close to the reality.",
                    "label": 0
                },
                {
                    "sent": "So there's the advantage of that.",
                    "label": 1
                },
                {
                    "sent": "And of course you can.",
                    "label": 0
                },
                {
                    "sent": "You can test the scalability of the system as well.",
                    "label": 0
                },
                {
                    "sent": "For different, you know, data set sizes and different number of queries.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So since our benchmark is based on the real queries and so I will try, I will try to explain the only one that that I know to the best of my knowledge is that is based on the real queries.",
                    "label": 0
                },
                {
                    "sent": "Benchmark is a DB pedia so.",
                    "label": 0
                },
                {
                    "sent": "It is based on the DB pedia, real queries and here you can have a benchmark of different data set sizes and different queries so you can test the scalability of your system with 10% of DB pedia, 2050 whatever you want.",
                    "label": 1
                },
                {
                    "sent": "But one problem is that it only selects sparkle, it only considers sparkle select queries.",
                    "label": 0
                },
                {
                    "sent": "But we have 4 forms of query sparkle ask we have described we have construct.",
                    "label": 0
                },
                {
                    "sent": "So these these other three forms are not included in the DB pedia.",
                    "label": 1
                },
                {
                    "sent": "And another important feature that is missing is some of the important query features that was that are proven to effect the overall query performance or not.",
                    "label": 1
                },
                {
                    "sent": "Considering the DB Pedia sparkle benchmark, for example in the water loop benchmark, they they shown that the number of join what it says N triple patron selectivity is all these things.",
                    "label": 0
                },
                {
                    "sent": "All effects the query performance but they didn't in the DB pedia.",
                    "label": 0
                },
                {
                    "sent": "These kind of things are not included.",
                    "label": 0
                },
                {
                    "sent": "In this study, Pedia benchmark is not that much highly customizable according to the use case specific requirement.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to address these problems, we come up with a new benchmark generation framework which is called feasible.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "It can be applied to any sparkle query logs.",
                    "label": 1
                },
                {
                    "sent": "And it consider any of the four query forms, and it's also considered the important query features.",
                    "label": 1
                },
                {
                    "sent": "For example, the number of join, what is triple patterns?",
                    "label": 0
                },
                {
                    "sent": "Selectivity is be GPS and unions filter or whatever like not whatever, but like the majority of the features are covered here.",
                    "label": 0
                },
                {
                    "sent": "And the advantage of that is you can generate a customizable and use case specific benchmarks out of using feasible.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here how the how you how a user can generate a benchmark.",
                    "label": 0
                },
                {
                    "sent": "There are four steps.",
                    "label": 0
                },
                {
                    "sent": "So the first one is data set cleaning and the second one is a feature selection and normalization I mean feature vectors and then the selection of exemplars, and then the selection of benchmark queries.",
                    "label": 1
                },
                {
                    "sent": "So I will explain each step one by.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first one is data set cleaning.",
                    "label": 0
                },
                {
                    "sent": "We buy data set cleaning.",
                    "label": 0
                },
                {
                    "sent": "I mean the query logs cleaning so there can be a lot of you know queries in the in the in the log that have let synthetic errors that can have 0 results that can help like different issues.",
                    "label": 0
                },
                {
                    "sent": "So we just to generate a more high quality benchmark.",
                    "label": 0
                },
                {
                    "sent": "We remove this kind of queries, But there this is an optional step you can include or you can remove it.",
                    "label": 1
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Second one is the feature vector selection and the normalization.",
                    "label": 1
                },
                {
                    "sent": "I will just explain an example here.",
                    "label": 0
                },
                {
                    "sent": "Let's suppose I have a query which is containing two triple Petra petronela limit and select query.",
                    "label": 0
                },
                {
                    "sent": "So here are some features.",
                    "label": 0
                },
                {
                    "sent": "For example the query type is selected in the result sizes 13 basic graph patterns or one join vertices or 1 min triple pattern.",
                    "label": 1
                },
                {
                    "sent": "Selectivity is 2.",
                    "label": 0
                },
                {
                    "sent": "So we have like a 16 various features in.",
                    "label": 0
                },
                {
                    "sent": "Similarly we have like what are the.",
                    "label": 0
                },
                {
                    "sent": "You know important features included.",
                    "label": 1
                },
                {
                    "sent": "For example Union order by limit offset filter group by an.",
                    "label": 0
                },
                {
                    "sent": "Also the query runtime.",
                    "label": 0
                },
                {
                    "sent": "So I would like to mention this query runtime is not the real one.",
                    "label": 0
                },
                {
                    "sent": "Rather we just you know executed on a local sparkle endpoint.",
                    "label": 0
                },
                {
                    "sent": "It just give a rough idea to the user.",
                    "label": 0
                },
                {
                    "sent": "So here are some features that are considered in our benchmark.",
                    "label": 0
                },
                {
                    "sent": "So how we do that?",
                    "label": 0
                },
                {
                    "sent": "First, we represent each of these feature is at.",
                    "label": 0
                },
                {
                    "sent": "Feature vector, so all those values that are numbers, for example 1311 they are written as it is, but for the German there are some Boolean variables.",
                    "label": 0
                },
                {
                    "sent": "For example distinct is use or not order by use or not.",
                    "label": 1
                },
                {
                    "sent": "So if it's used that we use one value for that.",
                    "label": 0
                },
                {
                    "sent": "If it's not used then we use zero value for that.",
                    "label": 0
                },
                {
                    "sent": "So we have a feature vector pertaining to each of the sparkle query.",
                    "label": 0
                },
                {
                    "sent": "Now the next step is we normalize this vector.",
                    "label": 0
                },
                {
                    "sent": "These features from zero to 1.",
                    "label": 0
                },
                {
                    "sent": "So here is the result for that.",
                    "label": 0
                },
                {
                    "sent": "So once we normalize all all of those features from zero to 1 then.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go to the second step, which is the selection of examplars and now here is an example.",
                    "label": 1
                },
                {
                    "sent": "I have a query.",
                    "label": 0
                },
                {
                    "sent": "Let's suppose I have a set of queries which are 10 from Q1 to Q10 and just for the sake of simplicity here I'm only showing 2 feature because just to have a 2 dimensional space.",
                    "label": 0
                },
                {
                    "sent": "But in reality we have like 16 or 18 dimensions.",
                    "label": 0
                },
                {
                    "sent": "So here I'm only taking two features and there are some values for that given.",
                    "label": 0
                },
                {
                    "sent": "So the first, the first step is that you just need to plot these vectors.",
                    "label": 0
                },
                {
                    "sent": "I mean these 10 queries represented as a feature vectors in a multi dimensional space.",
                    "label": 1
                },
                {
                    "sent": "So here is the representation for that.",
                    "label": 0
                },
                {
                    "sent": "Now, once you represent each query in the multi dimensional space then the second thing is.",
                    "label": 0
                },
                {
                    "sent": "Just left suppose is an example.",
                    "label": 1
                },
                {
                    "sent": "We have 10 queries and a user is interested to select a benchmark of three queries out of 10, but that should reflect the overall 10 queries.",
                    "label": 0
                },
                {
                    "sent": "There's the whole problem.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now how we are doing this?",
                    "label": 0
                },
                {
                    "sent": "Once you plug those queries in a multi dimensional space, you just need to find the middle point where is the middle point or the average.",
                    "label": 0
                },
                {
                    "sent": "So you can, you can see it is.",
                    "label": 0
                },
                {
                    "sent": "I hope you can see it's like in a red dot near to the query #5.",
                    "label": 0
                },
                {
                    "sent": "So once you find the middle of the multi dimensional space, Now the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thing is that you need to select.",
                    "label": 0
                },
                {
                    "sent": "You need to compute the distances.",
                    "label": 0
                },
                {
                    "sent": "To the to the middle of all queries and pick that query that has the minimum distance.",
                    "label": 0
                },
                {
                    "sent": "So in our case the minimum distance to averages Q #5.",
                    "label": 1
                },
                {
                    "sent": "So that is our first example are secure #5 is selected.",
                    "label": 1
                },
                {
                    "sent": "Now the next step is that same since we need to generate a benchmark of three queries.",
                    "label": 0
                },
                {
                    "sent": "So we need to reply to.",
                    "label": 0
                },
                {
                    "sent": "You know process the to repeat the same step three times.",
                    "label": 0
                },
                {
                    "sent": "So the next question is that now we need to find the.",
                    "label": 0
                },
                {
                    "sent": "Created date has the longest distance from Q5.",
                    "label": 0
                },
                {
                    "sent": "So here if we can see it.",
                    "label": 0
                },
                {
                    "sent": "OK so here is, as I mentioned, the red red dots showing the example that we have selected.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, if you want to find what is the maximum distance from Q5 and here it turns out.",
                    "label": 0
                },
                {
                    "sent": "That Q4 is the longest from Q5, so we will select.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That is the 2nd example now.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the third step, we need to select the the example that has the longest distance from these two.",
                    "label": 0
                },
                {
                    "sent": "I mean that is the farthest distance from Q5 and Q4 and that is Q #9.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So once we selected the example.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we go to the final step, which is the clustering.",
                    "label": 0
                },
                {
                    "sent": "So we start we start with query number one and compute the distances of queue number one to each of the example are in bind that query to the to the minimum distance example or so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here query number one is shortest to Q #5, so that's A1 cluster study.",
                    "label": 0
                },
                {
                    "sent": "Now we go to cure a number 2.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So clearly #2 is also close to Q5 and now we.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go to three and four.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And similarly you are.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going annual",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Repeat the whole pro.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For all queries now we have 3, three different clusters and now the final thing is that we just need to.",
                    "label": 0
                },
                {
                    "sent": "You need to again find the middle of each cluster and select that query that has the shortest distance to that average.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you say that average is here and.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Acute.",
                    "label": 0
                },
                {
                    "sent": "Number two is the shortest distance to the average, so Q2 is the query that is finally selected as a benchmark and similarly similarly the for the other cluster.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have generated a benchmark of three queries out of that.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the next problem is how we can evaluate that?",
                    "label": 0
                },
                {
                    "sent": "OK, how efficient is my benchmark pertaining to the real query log?",
                    "label": 1
                },
                {
                    "sent": "So here we have a formula for that due to shortage of time, I will not explain, but it's like mean square root error of the mean values and the standard deviation.",
                    "label": 0
                },
                {
                    "sent": "So we just combine them in that formula.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then what we tested we tested fourth was a sparkle endpoints virtuoso SISMI, an for dicianno limb.",
                    "label": 0
                },
                {
                    "sent": "And the setup was almost like the same that each each of these was using six GP.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Frame and the first important comparison is there to to see what is the composite error, how efficient we are closely, how closely we are reflecting the query logs.",
                    "label": 0
                },
                {
                    "sent": "So here is the result.",
                    "label": 0
                },
                {
                    "sent": "If we compare with the DB pedia so.",
                    "label": 0
                },
                {
                    "sent": "Our feasible is able to generate your benchmark which has error 54.5% less than DB pedia.",
                    "label": 1
                },
                {
                    "sent": "I just like to mention we tried those experiments on DB pedia query log and the semantic Web dog food query query log.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some results since the previous experiments were only based on Sparkle select query.",
                    "label": 0
                },
                {
                    "sent": "We also included and check whether the there is any difference among the sparkle, ask and escribed and the other four query forms.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that virtuoso is the fastest one for the rest of the three, but for the describe queries is not the fastest rather.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Olim sorry, the position is the fastest for that and here is some other.",
                    "label": 0
                },
                {
                    "sent": "Results for is as well.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, just to summarize the result, what we did, we just rank the each of the sparkle endpoint in.",
                    "label": 0
                },
                {
                    "sent": "The values are here showing are in percentages, so for example for semantic web dog, food virtuoso is number one in 38% of queries and so on.",
                    "label": 1
                },
                {
                    "sent": "So now if you if if you just summarize the result based on these tables, we come up to some of the very interesting results.",
                    "label": 0
                },
                {
                    "sent": "The first one is that none of the system is all winner or solos are for a specific, you know, perform particular link rank and virtuoso performance, usually in the Top Rank rank one airing 24Z key is usually in the middle ranked second and third.",
                    "label": 1
                },
                {
                    "sent": "And Oleum is it is on the slower side.",
                    "label": 1
                },
                {
                    "sent": "Usually rank three or four.",
                    "label": 0
                },
                {
                    "sent": "An interesting observation is about Sesame is either too fast or either too slow so.",
                    "label": 0
                },
                {
                    "sent": "And you can see the result about that.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's all from my side.",
                    "label": 0
                },
                {
                    "sent": "If you want to try the demo there.",
                    "label": 0
                },
                {
                    "sent": "We have a demo session as well and you can generate a benchmark whatever you want.",
                    "label": 0
                },
                {
                    "sent": "Here is the demo for that, that's all.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your listening and now I'm happy to take questions.",
                    "label": 0
                },
                {
                    "sent": "How does your approach compared to random sampling of queries?",
                    "label": 0
                },
                {
                    "sent": "Here we compared to.",
                    "label": 0
                },
                {
                    "sent": "Yeah, actually, that's a very good question.",
                    "label": 0
                },
                {
                    "sent": "There are like different clustering approaches that we should compare, but for this we didn't compare.",
                    "label": 0
                },
                {
                    "sent": "We just select this approach based on our previous experiments.",
                    "label": 0
                },
                {
                    "sent": "Experimental result of there is a lines, you know link discovery framework.",
                    "label": 0
                },
                {
                    "sent": "So we adopted from there.",
                    "label": 0
                },
                {
                    "sent": "But now we are trying to compare for example with.",
                    "label": 0
                },
                {
                    "sent": "Came in clustering random sampling.",
                    "label": 0
                },
                {
                    "sent": "All this stuff and see like whether we get more, you know efficient benchmark or not.",
                    "label": 0
                },
                {
                    "sent": "But currently we haven't compared with any of the existing clustering approaches.",
                    "label": 0
                },
                {
                    "sent": "Could have a question, So what you seem to indicate there is that your method chooses like representative queries if I like so I was wondering how this distance measure.",
                    "label": 0
                },
                {
                    "sent": "So you basically say there is a.",
                    "label": 0
                },
                {
                    "sent": "The distance distance measure chooses representative queries for for the, for the, for the query logs.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I have to say I'm not 100% sure where this intuition necessarily holds, because if you compute this by these distances you might just end up with picking one in the middle where there is only one and around there there are queries with other characteristic of which you maybe have not considered in your feature set that are would be more common.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's exactly like as I said, this benchmark is highly flexible, so it's not.",
                    "label": 0
                },
                {
                    "sent": "You could add more features.",
                    "label": 0
                },
                {
                    "sent": "For example, there are some features that were not covered.",
                    "label": 0
                },
                {
                    "sent": "We have 16 features, but Sparkle 1.1 features are not covered, but it's very, very easily extendable and you can add whatever you want and that will be one more dimension to the you know, the overall multi dimensional space and then like you can compute the composite error.",
                    "label": 0
                },
                {
                    "sent": "I hope it will be almost the same so it's highly flexible so you can add whatever you want.",
                    "label": 0
                }
            ]
        }
    }
}