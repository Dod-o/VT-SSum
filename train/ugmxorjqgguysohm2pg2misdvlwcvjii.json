{
    "id": "ugmxorjqgguysohm2pg2misdvlwcvjii",
    "title": "Missing information impediments to learnability",
    "info": {
        "author": [
            "Loizos Michael, Open University of Cyprus"
        ],
        "published": "Aug. 16, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/colt2011_michael_missing/",
    "segmentation": [
        [
            "So missing information impediments to learnability.",
            "So before starting talking about impediments, we should have a concrete learning model and for the purposes of this talk I'll just use the PAC learning model.",
            "Presumably the questions imposing will also carry to other."
        ],
        [
            "That's so here's how this works.",
            "We have unstructured distribution from which we get a bit string, an example, some functions on target function is applied on the B string, so we get the label for the example.",
            "The standard pack learning requirement is given a bunch of these pairs efficiently and with high probability derived hypothesis, such that when the hypothesis is applied in a future example drawn from the same recall, it will not contradict the label except with his more probability in."
        ],
        [
            "To discuss impediments through due to missing information will just use one of many possible models in this particular model there is a masking process which we know nothing about that Heights.",
            "Part of the example we still get to see the label, but we don't get to see the entire example.",
            "So we have observations and the underlying label of the underlying example.",
            "The learning requirement is very close to the pack model model.",
            "We get a bunch of these pairs.",
            "We are expected to be high, probably inefficiently, producer hypothesis such that when applied on the future observation, it will not contradict.",
            "The label exhibit has more probability that exactly my model of learning with the focus of attention from 90 three.",
            "I'm sorry I have a model learning with restricted corpus of attention.",
            "In Code 93, right, which is exactly like that, and otherwise what can be learned in this one.",
            "OK, I'll show some differences free related work, so two things to note."
        ],
        [
            "First, there example.",
            "The hypothesis is still mapping examples to attributes, so we're not mapping ternary strings to attributes, just examples.",
            "We need to apply this hypothesis on observations.",
            "So what does it mean for the hypothesis to contradict the label?",
            "It means that in the case that hypothesis is defined on the observation, then that value should not contradict.",
            "It's not defined, we don't penalize the hypothese."
        ],
        [
            "So I'd like to if you'll be more words on the hypothesis and abstention in this model.",
            "So hypothesis encode the underlying structure of examples, so we don't assume any structure on the masking process.",
            "It could hide as much or as little information as the masking process once, so our hypothesis do not care about that structure of the of the observation, just the underlying reality.",
            "So we use typical hypothesis and.",
            "You can, you can see that this hypothesis can be valid on any example, but in that particular observation it will not give a value.",
            "It remains undefined and will not be penalized.",
            "For that we are not looking for hypothesis that actually read the observation and make predictions based on the observation."
        ],
        [
            "On the matter of extensions, the masking process is, as I said, arbitrary, so.",
            "In particular, it should be able to encompass the missing, not at random property from statistics, which means that something might be missing, and the reason that it might be missing might depend on the value that's actually hidden.",
            "It's also stochastic in the sense that the same example could be could be mapped to numerous observations overtime.",
            "While this model is not too hard, it's because the more information is missing observations.",
            "The more likely is for the hypothesis to abstain and not get penalized for that abstention.",
            "On the other hand, it's not too easy because we require learning to hold for any masking process, including the identity function, which is the pad model, so it can't be too easy to learn in this model.",
            "Also, extensions are not actively chosen by the hypothesis.",
            "The hypothesis abstains exactly when there is not sufficient information.",
            "In any particular observation for the hypothesis to make a prediction."
        ],
        [
            "So what is known to be learnable in this case?",
            "Any pack class of functions and any class of functions like this part learnable and also so monotone contains Morton functions.",
            "You can trivially show that you can learn that class and the proof is just take any observation you get from the Oracle.",
            "Replace every star with the label of the observation and you can see that this actually preserves all the things that need to be preserved for learning to hold.",
            "So you pack learn from these examples.",
            "And then you use whatever hypothesis you end up with.",
            "To make predictions on future observations and things actually work by a typical reduction, you can also show that red ones formulas also have are learnable in this sense."
        ],
        [
            "However, the interesting thing is that learning reductions kind of breakdown after after conjunctions after one CN F Ann.",
            "And there isn't is that in learning reduction.",
            "One key aspect is that you want you want to be able to evaluate a function modularly, take its terms, evaluate the terms, and then combine the values to get the value of the original formula.",
            "And this is true and examples, but it breaks down on observations, so here's one function here whose value on the example and observation is zero.",
            "And if you evaluate modularity on the example, you still get the right answer zero, and one is 0.",
            "But you could try to do so on the observation.",
            "You get undefined an undefined and then you cannot deduce the value for three CNF formulas.",
            "There is an additional problem, which is that evaluating 3 CNF on examples is tractable, but not so observations, so I'm not sure if there's a general result that says that if you cannot evaluate your formula, you cannot learn it.",
            "Maybe there is, I don't know, but in any case, 3 CNF formulas cannot be efficiently evaluated on observations, so.",
            "I don't know where you can learn them or not."
        ],
        [
            "On the negative side of things, you cannot properly learn parities in this model, and the proof is follows typical proofs from the literature for this kind of results.",
            "Now you have the extra possibility of using stars in your observations, and this allows you to encode even more constraints on what the end hypothesis should look like, so you can actually prove that parties although pack learnable, they're not learnable.",
            "In this model.",
            "You need to worry about some extra complications in in these proofs, in the sense that you cannot choose your observations that.",
            "But really you need to worry about showing the existence of examples underlying underneath the observations that would give rise to the observations.",
            "An interesting point here is that even if you are allowed to hide only three attributes in each observation, you can still make the result go through, so it's the quality of missing information that makes things unlearnable and not the quantity.",
            "So decision lists you can't.",
            "You can prove by a similarity."
        ],
        [
            "Of course they may not.",
            "Problem here is to establish the non proper learnability of these classes, but more generally.",
            "The question is, are there classes of formulas that are not shallow in the sense that they are not closed?",
            "Two more conform?",
            "You cannot easily reduce tomorrow in formulas that you can learn, so maybe a new approach will be needed for this."
        ],
        [
            "Racism.",
            "So here's why we should care why I care.",
            "This result is the underlying distribution uniform or some something some other.",
            "What is the so you choose a set of observations and then you take the uniform distribution over that set so you know no, no it's not.",
            "So here's why I care about these questions.",
            "First of all, it's an interesting philosophical questions to understand how much missing information in Pitts learnability in the cases that we know that learnability is possible, we heard the invited talk earlier today about real corpora having missing information.",
            "In many cases, there is no clear way of how information is missing.",
            "There is no clear description of how information is missing in this corpora.",
            "So by having a worst case masking process model and proving positive results in this model, you can actually carry these results to these settings and final kind of motivating example for me is that these results guide to what I call the auto adaptive learning model which is the following.",
            "You still get observations with must attributes, but now there is no label in the observation and your goal is to learn from these unlabeled observations to predict the missing values.",
            "In future unlabeled observations.",
            "So of course, the distribution has some structure.",
            "It cannot be arbitrary, otherwise you couldn't do anything about that.",
            "But this kind of relates to the matrix completion problem, where we heard earlier about, and that's it.",
            "I hope to get some questions or some answers on these problems.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So missing information impediments to learnability.",
                    "label": 0
                },
                {
                    "sent": "So before starting talking about impediments, we should have a concrete learning model and for the purposes of this talk I'll just use the PAC learning model.",
                    "label": 0
                },
                {
                    "sent": "Presumably the questions imposing will also carry to other.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's so here's how this works.",
                    "label": 0
                },
                {
                    "sent": "We have unstructured distribution from which we get a bit string, an example, some functions on target function is applied on the B string, so we get the label for the example.",
                    "label": 0
                },
                {
                    "sent": "The standard pack learning requirement is given a bunch of these pairs efficiently and with high probability derived hypothesis, such that when the hypothesis is applied in a future example drawn from the same recall, it will not contradict the label except with his more probability in.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To discuss impediments through due to missing information will just use one of many possible models in this particular model there is a masking process which we know nothing about that Heights.",
                    "label": 0
                },
                {
                    "sent": "Part of the example we still get to see the label, but we don't get to see the entire example.",
                    "label": 0
                },
                {
                    "sent": "So we have observations and the underlying label of the underlying example.",
                    "label": 0
                },
                {
                    "sent": "The learning requirement is very close to the pack model model.",
                    "label": 0
                },
                {
                    "sent": "We get a bunch of these pairs.",
                    "label": 0
                },
                {
                    "sent": "We are expected to be high, probably inefficiently, producer hypothesis such that when applied on the future observation, it will not contradict.",
                    "label": 0
                },
                {
                    "sent": "The label exhibit has more probability that exactly my model of learning with the focus of attention from 90 three.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry I have a model learning with restricted corpus of attention.",
                    "label": 0
                },
                {
                    "sent": "In Code 93, right, which is exactly like that, and otherwise what can be learned in this one.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll show some differences free related work, so two things to note.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, there example.",
                    "label": 0
                },
                {
                    "sent": "The hypothesis is still mapping examples to attributes, so we're not mapping ternary strings to attributes, just examples.",
                    "label": 0
                },
                {
                    "sent": "We need to apply this hypothesis on observations.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean for the hypothesis to contradict the label?",
                    "label": 0
                },
                {
                    "sent": "It means that in the case that hypothesis is defined on the observation, then that value should not contradict.",
                    "label": 0
                },
                {
                    "sent": "It's not defined, we don't penalize the hypothese.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'd like to if you'll be more words on the hypothesis and abstention in this model.",
                    "label": 0
                },
                {
                    "sent": "So hypothesis encode the underlying structure of examples, so we don't assume any structure on the masking process.",
                    "label": 1
                },
                {
                    "sent": "It could hide as much or as little information as the masking process once, so our hypothesis do not care about that structure of the of the observation, just the underlying reality.",
                    "label": 0
                },
                {
                    "sent": "So we use typical hypothesis and.",
                    "label": 0
                },
                {
                    "sent": "You can, you can see that this hypothesis can be valid on any example, but in that particular observation it will not give a value.",
                    "label": 0
                },
                {
                    "sent": "It remains undefined and will not be penalized.",
                    "label": 0
                },
                {
                    "sent": "For that we are not looking for hypothesis that actually read the observation and make predictions based on the observation.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the matter of extensions, the masking process is, as I said, arbitrary, so.",
                    "label": 0
                },
                {
                    "sent": "In particular, it should be able to encompass the missing, not at random property from statistics, which means that something might be missing, and the reason that it might be missing might depend on the value that's actually hidden.",
                    "label": 0
                },
                {
                    "sent": "It's also stochastic in the sense that the same example could be could be mapped to numerous observations overtime.",
                    "label": 0
                },
                {
                    "sent": "While this model is not too hard, it's because the more information is missing observations.",
                    "label": 1
                },
                {
                    "sent": "The more likely is for the hypothesis to abstain and not get penalized for that abstention.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, it's not too easy because we require learning to hold for any masking process, including the identity function, which is the pad model, so it can't be too easy to learn in this model.",
                    "label": 0
                },
                {
                    "sent": "Also, extensions are not actively chosen by the hypothesis.",
                    "label": 1
                },
                {
                    "sent": "The hypothesis abstains exactly when there is not sufficient information.",
                    "label": 0
                },
                {
                    "sent": "In any particular observation for the hypothesis to make a prediction.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is known to be learnable in this case?",
                    "label": 0
                },
                {
                    "sent": "Any pack class of functions and any class of functions like this part learnable and also so monotone contains Morton functions.",
                    "label": 0
                },
                {
                    "sent": "You can trivially show that you can learn that class and the proof is just take any observation you get from the Oracle.",
                    "label": 0
                },
                {
                    "sent": "Replace every star with the label of the observation and you can see that this actually preserves all the things that need to be preserved for learning to hold.",
                    "label": 0
                },
                {
                    "sent": "So you pack learn from these examples.",
                    "label": 0
                },
                {
                    "sent": "And then you use whatever hypothesis you end up with.",
                    "label": 0
                },
                {
                    "sent": "To make predictions on future observations and things actually work by a typical reduction, you can also show that red ones formulas also have are learnable in this sense.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, the interesting thing is that learning reductions kind of breakdown after after conjunctions after one CN F Ann.",
                    "label": 1
                },
                {
                    "sent": "And there isn't is that in learning reduction.",
                    "label": 1
                },
                {
                    "sent": "One key aspect is that you want you want to be able to evaluate a function modularly, take its terms, evaluate the terms, and then combine the values to get the value of the original formula.",
                    "label": 1
                },
                {
                    "sent": "And this is true and examples, but it breaks down on observations, so here's one function here whose value on the example and observation is zero.",
                    "label": 0
                },
                {
                    "sent": "And if you evaluate modularity on the example, you still get the right answer zero, and one is 0.",
                    "label": 0
                },
                {
                    "sent": "But you could try to do so on the observation.",
                    "label": 0
                },
                {
                    "sent": "You get undefined an undefined and then you cannot deduce the value for three CNF formulas.",
                    "label": 0
                },
                {
                    "sent": "There is an additional problem, which is that evaluating 3 CNF on examples is tractable, but not so observations, so I'm not sure if there's a general result that says that if you cannot evaluate your formula, you cannot learn it.",
                    "label": 0
                },
                {
                    "sent": "Maybe there is, I don't know, but in any case, 3 CNF formulas cannot be efficiently evaluated on observations, so.",
                    "label": 0
                },
                {
                    "sent": "I don't know where you can learn them or not.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the negative side of things, you cannot properly learn parities in this model, and the proof is follows typical proofs from the literature for this kind of results.",
                    "label": 1
                },
                {
                    "sent": "Now you have the extra possibility of using stars in your observations, and this allows you to encode even more constraints on what the end hypothesis should look like, so you can actually prove that parties although pack learnable, they're not learnable.",
                    "label": 0
                },
                {
                    "sent": "In this model.",
                    "label": 1
                },
                {
                    "sent": "You need to worry about some extra complications in in these proofs, in the sense that you cannot choose your observations that.",
                    "label": 1
                },
                {
                    "sent": "But really you need to worry about showing the existence of examples underlying underneath the observations that would give rise to the observations.",
                    "label": 0
                },
                {
                    "sent": "An interesting point here is that even if you are allowed to hide only three attributes in each observation, you can still make the result go through, so it's the quality of missing information that makes things unlearnable and not the quantity.",
                    "label": 1
                },
                {
                    "sent": "So decision lists you can't.",
                    "label": 0
                },
                {
                    "sent": "You can prove by a similarity.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of course they may not.",
                    "label": 0
                },
                {
                    "sent": "Problem here is to establish the non proper learnability of these classes, but more generally.",
                    "label": 1
                },
                {
                    "sent": "The question is, are there classes of formulas that are not shallow in the sense that they are not closed?",
                    "label": 1
                },
                {
                    "sent": "Two more conform?",
                    "label": 0
                },
                {
                    "sent": "You cannot easily reduce tomorrow in formulas that you can learn, so maybe a new approach will be needed for this.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Racism.",
                    "label": 0
                },
                {
                    "sent": "So here's why we should care why I care.",
                    "label": 0
                },
                {
                    "sent": "This result is the underlying distribution uniform or some something some other.",
                    "label": 0
                },
                {
                    "sent": "What is the so you choose a set of observations and then you take the uniform distribution over that set so you know no, no it's not.",
                    "label": 0
                },
                {
                    "sent": "So here's why I care about these questions.",
                    "label": 1
                },
                {
                    "sent": "First of all, it's an interesting philosophical questions to understand how much missing information in Pitts learnability in the cases that we know that learnability is possible, we heard the invited talk earlier today about real corpora having missing information.",
                    "label": 1
                },
                {
                    "sent": "In many cases, there is no clear way of how information is missing.",
                    "label": 0
                },
                {
                    "sent": "There is no clear description of how information is missing in this corpora.",
                    "label": 0
                },
                {
                    "sent": "So by having a worst case masking process model and proving positive results in this model, you can actually carry these results to these settings and final kind of motivating example for me is that these results guide to what I call the auto adaptive learning model which is the following.",
                    "label": 0
                },
                {
                    "sent": "You still get observations with must attributes, but now there is no label in the observation and your goal is to learn from these unlabeled observations to predict the missing values.",
                    "label": 0
                },
                {
                    "sent": "In future unlabeled observations.",
                    "label": 0
                },
                {
                    "sent": "So of course, the distribution has some structure.",
                    "label": 0
                },
                {
                    "sent": "It cannot be arbitrary, otherwise you couldn't do anything about that.",
                    "label": 1
                },
                {
                    "sent": "But this kind of relates to the matrix completion problem, where we heard earlier about, and that's it.",
                    "label": 0
                },
                {
                    "sent": "I hope to get some questions or some answers on these problems.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}