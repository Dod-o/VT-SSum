{
    "id": "untug4m4vbyezbsbn2cypwooo243bl7m",
    "title": "KMV-Peer: A Robust and Adaptive Peer-Selection Algorithm",
    "info": {
        "author": [
            "Yosi Mass, IBM Haifa Research Lab"
        ],
        "published": "Aug. 9, 2011",
        "recorded": "February 2011",
        "category": [
            "Top->Computer Science->Web Search"
        ]
    },
    "url": "http://videolectures.net/wsdm2011_mass_kmv/",
    "segmentation": [
        [
            "So I'm going to talk about the.",
            "Selection algorithm for information retrieval and this is joint work, so I'm just imagine this is a joint work with the Shasta give and me Hall and it's a collaboration between the IBM Haifa Research Lab and Hebrew University of Georgia."
        ],
        [
            "Slim so the motivation we want to scale up indexing and retrieval of large data collection.",
            "We present the solution in the context of a pill pill system so each peer has its own air collection.",
            "Actually, we can divide the collection we have.",
            "We might have a huge collection that we divide, divide between peers or we might think of.",
            "In a system where bills come with their own collection and actually we want to be able to search in all these collection, an more precisely the public statement is actually we want to find a good approximation of a centralized system.",
            "So assume that this data was in a centralized system, but now it's divided between the pills.",
            "So we want to answer.",
            "Currently this work is focusing on.",
            "A conjunctive multiturn queries and we want to keep at a minimum the number of peers that we contact an also to minimize the communication cost."
        ],
        [
            "So the solution framework.",
            "This is not gnu.",
            "Explain what they already suggested earlier in several work.",
            "I'll just repeat it and then I just show about the improved.",
            "So the solution framework is the following.",
            "We have peers connected.",
            "We are talking about cooperative peers, or they are willing to share some information.",
            "So each peer that's got its ornate collection in this example assume that we have a P1 and this is let's say, the.",
            "Inverted index of P1.",
            "Now the basic idea is that each peer creates locali, some compact statistics about each collection, an specifically it's done per letter, and then this is still a locali.",
            "But then we would like to make this statistics globally available.",
            "So what the feels.",
            "It do is actually we use ADHD distributed a stable N distributions are stable allows us to actually assign appear that is responsible for each query term.",
            "So for example, let's say that this Pier Petri is now become responsible for term one.",
            "So what will happen is that all the peers in the system will send their own statistics about the one we use the concept.",
            "A Sigma IJ to denote the statistics of here I bought EM.",
            "AJ so for example Sigma 1 two minutes statistics of Pier One for term 2.",
            "So now.",
            "P3 as all the statistics of all the other pills in the system about the one.",
            "Similarly, let's assume this is a P4 is responsible for Tito, so all the pills will send their statistics to feel full so.",
            "This is the."
        ],
        [
            "Frameworks now what is our contribution to this level?",
            "So first is the knew statistics.",
            "So we mentioned that each peer creates statistics.",
            "So the first contribution is the new statistic and this is based on KVK minimal value which is presented by Bear in segment 2007.",
            "The second contribution is how to use the statistics for a very clever appeal selection algorithm.",
            "And finally we show by experiments that we can improve state of the art by a factor of."
        ],
        [
            "Full so we describe the collection statistics.",
            "We then describe the field selection algorithm and then experiments and conclude with some."
        ],
        [
            "Summer in future work.",
            "So what is the statistics that we are suggesting?",
            "So we are doing it for each term for the DJ so.",
            "Assume that so now we are locally at each peer, so assume that the field this is the posting list of them DJ and what we do with sort the documents by relevance to this.",
            "If there was a query with only this time, so we solve the document by relevance to this term and also we divide them to act with the score intervals.",
            "In this example we have M score interval.",
            "So we group the documents by intervals an.",
            "Now what we do is for each such interval we apply KMV statistics an accurate some A.",
            "What we call LIJM.",
            "I'm sorry for the notations.",
            "All the details are in the paper, but the idea is that we take the documents in each interval we apply some hash uniform hash function.",
            "That guarantees we take enough bits that guarantees that there are no duplicates.",
            "An actually we end up with what we call the CNV synopsis for each interval, and actually what it does it just take the LL minimal values from each.",
            "Output of the hash function.",
            "So for each interval we apply as function uniform hash function and we take the L minimal value.",
            "So for each interval we have a synopsis and all together Web Sigma IJ which is all the synopsis for a PPI for temp TJ and specifically each cell here is a synopsis for a specific interval, so this is the synopsis."
        ],
        [
            "This.",
            "And now we want to show how to use this synopsis in order to decide how to link the pills or relevant to the query.",
            "So assume we are given a query with N terms.",
            "Assume that we collected the statistics of specific peel for all the query terms I'll show later how we do it, But basically we can approach the pills that are responsible for the query terms and collect the statistics and assume now that we have this test statistic for a specific field.",
            "Now how do we use it to decide if the pier is is as God documents that are relevant for the query?",
            "So intuitively let's assume there was a document.",
            "With all the query terms, we remember that we are now dealing with.",
            "Conjunctive a.",
            "Clearly time, so this coming of this document would be some aggregation function on the scores that the document would get for each individual term.",
            "An actually we want to do something similar here so we don't have the documents.",
            "We have the statistics, so for PPI we have the statistics.",
            "Let's say for the query terms all the Sigma IJ for all the query type.",
            "The question is if we can apply some function which will actually be somehow similar to this original scoring function on these statistics to decide if this pier is relevant to the query or node."
        ],
        [
            "So how do we do it?",
            "So what we'll do is actually we take.",
            "Remember that we created those synopsis.",
            "So assume now again we have N query terms and these are all the synopsis of this pier for the query time.",
            "So what we would like to do is actually consider all the possible combinations when we select.",
            "Each time we select a interval from a different interval for each query to.",
            "So we define this H vector.",
            "This is example for example, that we took the second interval for the first, the last interval for the second term, and so on.",
            "So we have a now a combination of any synopsis for an interval an now assume if there was a document actually appeared here that is represented by this synopsis.",
            "There we could figure out that the score of this document for this term would be some.",
            "We can take the middle point.",
            "Remember that this intervals are sorted by.",
            "So we could take the middle point deal to say this would be the score of this document for this term and altogether.",
            "We can say now that similarly as we did for the document, we can say now that scoring of this vector, this combination, we still don't know if there is a document there.",
            "Maybe there is no document that actually fits here and here and here, but if there was a document then we could figure out the score of this document could be the same G the same scoring function that is used applied to the middle point of.",
            "Each of the intervals that are selected.",
            "So the next question is actually to try to estimate if there is actually a document there, because if there is no document in this interval there, there is no contribution to discover this field.",
            "We would like to consider only combinations of interval that actually are not empty so that there is some document there so."
        ],
        [
            "How do we do it so we have actually a two scoring function to try to estimate this so the first one we called them we call it came free in which is the intersection score and a.",
            "This is very simple.",
            "One of the properties of the CNV synopsis is that we can estimate, so we have actually NA intervals an we can estimate if the intervals are empty of or not.",
            "Because remember, we took each interval is just the L minimal values of the documents of the hash function of the documents that appeared in this interval.",
            "So the non emptiness intersection is just.",
            "We can just check if there is.",
            "A value that appearing all this interval.",
            "If there is a value there then we are sure there is a document there.",
            "We're show there is a document in this field that actually had this school for this term and so on.",
            "So we can define this caused appear now to be.",
            "We look at all the intersections that are not empty.",
            "We know there is a document there and actually we take the Max.",
            "The maximum of the scores that this document would get.",
            "But the problem is that actually this is a non emptiness intersection.",
            "Can be an underestimate becausw, especially if we deal with values with a large number of terms then.",
            "Liberty probability that the intersection is empty even though there is a real document.",
            "There just increases because remember, we just took the L minimal values so.",
            "We can get in many cases they.",
            "The intersection is empty, but still there is a document there, but we missed it because of the KMV synopsis."
        ],
        [
            "So in order to fix this, we apply what we call can be expected, which is the expected score of the pill and the idea I will not go into detail because I don't have time.",
            "But the idea here is that we try to estimate the probability that there is a document that exists.",
            "So again we take all all combinations and we try to estimate the probability that there is a document there.",
            "And actually we sum over all the.",
            "If possible combination and then multiply by this, call that if there was a document this was discarded, it would get, so these are the."
        ],
        [
            "So scrolling function that we use and now we go to the peer selection algorithm.",
            "So basic field selection algorithm would be the following.",
            "Assume that we have a query with NA.",
            "I would like to get the top K result and assume that we get another parameter which is a large capital K. It says what is the maximum number of pills that we are willing to contact.",
            "So a straightforward algorithm would be first to use the DHT to locate the fields that are responsible for the query terms, and then just collect all the statistics that therefore the query term.",
            "So now.",
            "Hey I just didn't mention that actually, because we're dealing with a period.",
            "So that the query can be initiated by any peer so they feel that initiated query now actually collect all the statistics for the very term and now what it can do.",
            "It can try to estimate or actually two rank the peers because now.",
            "As all the statistics, for example for Pier One, it has all the statistics of Pier One for the query terms, so we can try to apply the two scoring function that we have this drive to estimate the relevance of the score of the field.",
            "So we start by Kambri is which is more accurate and then it came in.",
            "Gives no more way feels that Allie is nonempty intersection.",
            "Then we go to the camp Exp.",
            "And then we can take the top K peers and then contact them and get their results and then merge the result.",
            "No, the problem with this algorithm is actually that it requires a lot of communication cause cause we need to go to all the get all this statistics and this can be very large if we're dealing with a lot of peers."
        ],
        [
            "So the first improvement that we suggest is actually to improve this.",
            "The communication cost, so we don't want to send all the statistics we want to send only a subset of it.",
            "When I'm talking about query runtime, I'm not talking now about indexing time, so at indexing time we assume that the statistics somehow arrive to this appears that are responsible for the terrorism.",
            "Now I'm talking about very time optimization.",
            "So instead of going to this N Pierce at responsiblefor, the correct terms and get this statistic.",
            "What we can do is we can go and ask them what is the length of their statistics so each.",
            "Of the N terms of the MPs would just give us number the length of the statistics that they have from all the other peers and then what we can do is we can select the two pills with this two shortest.",
            "At least let's call them TF for the first Ain TS 42nd and now the query initiating peer pick.",
            "You can just forward the very tapir PTS to the to the pier with the 2nd.",
            "Longest Sam.",
            "Posting list and now this bill becomes responsible for performing the query and now what this pill can do.",
            "It can ignore who is the pier with the shortest.",
            "So it can get the statistics on this field, so this is the shortest tactics that we can get.",
            "Then it applies the CRV in on all the fields that are in the listing.",
            "Now we get a very small subset of peers that are candidate two FA result.",
            "This feels actually.",
            "We have to be.",
            "It is guaranteed that they F documents with the two terms with the terms PS and PS.",
            "Are these actually eliminate the large number of appeals and now the next step of actually the last step is actually to get the rest of the statistics from the other peers that are responsible for the returns that asked to do it only for the peers that are candidates?",
            "Which is the set P?",
            "So this saves."
        ],
        [
            "Out of communication costs, the next improvement is to apply an adaptive ranking algorithm.",
            "So I remembering the basic algorithm, we just ranked the top K Capital K peers and contacted.",
            "Contacted all of them simultaneously.",
            "Here we can walk in rounds and actually in each week and select K prime which is smaller than a capital K and what we will do is each round actually will.",
            "Rank only K prime peers and then we contact this peer.",
            "We get the results back.",
            "Is that?",
            "And then we take a threshold which is we call it a min K which is actually the score of the document at the Kate position.",
            "So we have actually some results already from this capeline pills and we can see what is the score of the document at the K position and now actually we can adaptively rank the rest of the peers because we can just actually remember that we have this.",
            "All this combination and we can actually filter out peers.",
            "That cannot reach this mean case code now, instead of taking the middle point of each interval, we can take actually to be safe the right point, which is the Max code.",
            "If there was a document, this would be the Max code that it would get if it was in this interval.",
            "So we can actually ignore because we are looking at all possible combination we can ignore combination which cannot reach this threshold score."
        ],
        [
            "This is the full algorithm I know."
        ],
        [
            "I will not.",
            "It's in the paper.",
            "I will not go into detail so experiments we use the two data set one of them with 2K.",
            "OK Gov 2 collection between 10,000,000 documents.",
            "The other one is a whole load.",
            "If we did this was a 2 million documents and actually we had the tree set up.",
            "The Recollection I2 setups 175 / 10 billion documents into 10,000 field each having 1000 documents and the second set up is we actually use 1000 fields in each having.",
            "10,000 documents and for the blog used as a bill for queries, we took a slightly took 50 Ferris on the topic distillation track and field locally took a 75 queries from the block track of like 2008.",
            "The parameters that vary.",
            "Add the.",
            "KB size how many values we take from the hash function.",
            "M is the number of intervals that we use.",
            "Angie is another matter.",
            "If the bill is that many documents that we can divide it into logical groups and actually apply NP synopsis to each group, again, all the details are in the paper for evaluation we use in DCG and also map."
        ],
        [
            "So these are the result.",
            "Battle of the flag 10K10K.",
            "It means that life is 10,000 pills.",
            "Each field is 1000 documents.",
            "The setup that uses L then meaning that we took 10 values for each interval.",
            "Abuse five story from box.",
            "You can see this this alter results, so the graph shows this is the number of selected fields and this is the end DCG and you can see that even when we select 10 pills.",
            "This is our method even when selecting selecting then feels out of the 10,000 field we already get very high values of N, DCG and of course they improve as we select more, buy more peers and the other method.",
            "For example, Kohli, some collection statistics, but it's not.",
            "So I find lenders that people using CRC estimated that takes a sample of the each peel and then use this to estimate the elements of the field.",
            "These are the results for blog.",
            "Leonik communication costs, so this is our method, so this is in kilobytes, so this is the average communication costs the query and you can see that actually it's more or less this is some other metal.",
            "If we decide last dealing CIK.",
            "You can see that can be more or less the same level as the simple a query of CDF CDF and this is actually thanks to the filtering that we did in the saving the communication cost in contacting the second clear and so on."
        ],
        [
            "This shows some may playing with the parameter of the algorithm, so it will be valid.",
            "The number of CNV values that we take.",
            "Another of this calling about the number of groups and of course as we take both groups and more values then results improve.",
            "Actually our baseline is is this one is a.",
            "One thing keep in values then like this quality of life which is actually this one OK?"
        ],
        [
            "This graph shows actually the effect of the two scoring function there.",
            "We intend to KBS and using the adaptive of ignoring the adaptive mode.",
            "So for example used it you can see for the black one OK that this yellow one is actually using the intersection score only.",
            "If that is the adaptive and non adaptive in this case, actually even the nonadaptive perform a little bit better, but you can see that moving to KMP XP improve the result and then using both can be expected score the adaptive actually give the best result here.",
            "For blog this is interesting.",
            "What we can see is actually using only the cavi in is quite a bounded.",
            "Again, this shows the number of selected fields.",
            "This shows the MVC two values.",
            "We can see that using only KMV in we cannot get too far and the reason is because for blog actually we were using.",
            "With a large number of them.",
            "7 times and so on are compared to track it allowed just barely was only five years, so this is the effect of the underestimate of the intersection operator and but you can see that moving to can be expected, actually improves alot."
        ],
        [
            "We also tested the different calling function and this is actually.",
            "Some important observation one can ask how we compare the scores between the bills, because each field actually rate.",
            "It's only posting listen each field.",
            "K so there documents according to its local scoring function.",
            "So the question is how we can measure results.",
            "How we can compare scores between peers so?",
            "In this table actually shows the result and the anti CG values.",
            "When selecting 20 fields and model.",
            "Consider these are the three collection.",
            "OK, give Me 2 minutes.",
            "About the political actions, what you can see.",
            "Lucene is actually we were using implemented everything on top of Lucene and actually this line is Lucille, but we did actually some global synchronization of the parameters so we did some preprocessing and each field actually sent to all the other peers.",
            "It's a let's say it's IDF for each term.",
            "Once we have this global information, then this code at each peer compute locally for each document is actually the same as as it would be obtained in a centralized system because we have all the global collection parameters.",
            "This line is we will using VM25 and this line is actually using Lucina grain bug.",
            "Each field actually compute its own local scores so one can say that these calls are not compatible because the example the IDF.",
            "The first document frequency is different, but we can still see that even without.",
            "Actually synchronizing the parameter we can see that still get really nice results for entity, which is which are Mount much higher than the other system so."
        ],
        [
            "I'm going to whip up so conclusions we presented a fully decentralized peer selection algorithm that uses only a small subset of the peers and also safe communication costs.",
            "We describe two scoring function.",
            "One of them was the intersection score, one of the second ones.",
            "They expect the expected score.",
            "It per outperforms other methods, but more than 400% an regarding communication 'cause we showed how we can save the communication caused by contacting the second pier and so on."
        ],
        [
            "So for future VO we would like to investigate further reduction in the communication costs and we would like to consider the less less less restrictive, non empty emptiness and simulator.",
            "And in particular you would like to look also at a.",
            "So it should be distinct.",
            "This disjunctive.",
            "That's it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to talk about the.",
                    "label": 0
                },
                {
                    "sent": "Selection algorithm for information retrieval and this is joint work, so I'm just imagine this is a joint work with the Shasta give and me Hall and it's a collaboration between the IBM Haifa Research Lab and Hebrew University of Georgia.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Slim so the motivation we want to scale up indexing and retrieval of large data collection.",
                    "label": 1
                },
                {
                    "sent": "We present the solution in the context of a pill pill system so each peer has its own air collection.",
                    "label": 0
                },
                {
                    "sent": "Actually, we can divide the collection we have.",
                    "label": 1
                },
                {
                    "sent": "We might have a huge collection that we divide, divide between peers or we might think of.",
                    "label": 0
                },
                {
                    "sent": "In a system where bills come with their own collection and actually we want to be able to search in all these collection, an more precisely the public statement is actually we want to find a good approximation of a centralized system.",
                    "label": 0
                },
                {
                    "sent": "So assume that this data was in a centralized system, but now it's divided between the pills.",
                    "label": 0
                },
                {
                    "sent": "So we want to answer.",
                    "label": 0
                },
                {
                    "sent": "Currently this work is focusing on.",
                    "label": 0
                },
                {
                    "sent": "A conjunctive multiturn queries and we want to keep at a minimum the number of peers that we contact an also to minimize the communication cost.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the solution framework.",
                    "label": 0
                },
                {
                    "sent": "This is not gnu.",
                    "label": 0
                },
                {
                    "sent": "Explain what they already suggested earlier in several work.",
                    "label": 0
                },
                {
                    "sent": "I'll just repeat it and then I just show about the improved.",
                    "label": 0
                },
                {
                    "sent": "So the solution framework is the following.",
                    "label": 1
                },
                {
                    "sent": "We have peers connected.",
                    "label": 0
                },
                {
                    "sent": "We are talking about cooperative peers, or they are willing to share some information.",
                    "label": 0
                },
                {
                    "sent": "So each peer that's got its ornate collection in this example assume that we have a P1 and this is let's say, the.",
                    "label": 0
                },
                {
                    "sent": "Inverted index of P1.",
                    "label": 0
                },
                {
                    "sent": "Now the basic idea is that each peer creates locali, some compact statistics about each collection, an specifically it's done per letter, and then this is still a locali.",
                    "label": 0
                },
                {
                    "sent": "But then we would like to make this statistics globally available.",
                    "label": 1
                },
                {
                    "sent": "So what the feels.",
                    "label": 1
                },
                {
                    "sent": "It do is actually we use ADHD distributed a stable N distributions are stable allows us to actually assign appear that is responsible for each query term.",
                    "label": 1
                },
                {
                    "sent": "So for example, let's say that this Pier Petri is now become responsible for term one.",
                    "label": 0
                },
                {
                    "sent": "So what will happen is that all the peers in the system will send their own statistics about the one we use the concept.",
                    "label": 1
                },
                {
                    "sent": "A Sigma IJ to denote the statistics of here I bought EM.",
                    "label": 0
                },
                {
                    "sent": "AJ so for example Sigma 1 two minutes statistics of Pier One for term 2.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "P3 as all the statistics of all the other pills in the system about the one.",
                    "label": 1
                },
                {
                    "sent": "Similarly, let's assume this is a P4 is responsible for Tito, so all the pills will send their statistics to feel full so.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Frameworks now what is our contribution to this level?",
                    "label": 0
                },
                {
                    "sent": "So first is the knew statistics.",
                    "label": 0
                },
                {
                    "sent": "So we mentioned that each peer creates statistics.",
                    "label": 0
                },
                {
                    "sent": "So the first contribution is the new statistic and this is based on KVK minimal value which is presented by Bear in segment 2007.",
                    "label": 0
                },
                {
                    "sent": "The second contribution is how to use the statistics for a very clever appeal selection algorithm.",
                    "label": 0
                },
                {
                    "sent": "And finally we show by experiments that we can improve state of the art by a factor of.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Full so we describe the collection statistics.",
                    "label": 0
                },
                {
                    "sent": "We then describe the field selection algorithm and then experiments and conclude with some.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Summer in future work.",
                    "label": 0
                },
                {
                    "sent": "So what is the statistics that we are suggesting?",
                    "label": 0
                },
                {
                    "sent": "So we are doing it for each term for the DJ so.",
                    "label": 0
                },
                {
                    "sent": "Assume that so now we are locally at each peer, so assume that the field this is the posting list of them DJ and what we do with sort the documents by relevance to this.",
                    "label": 0
                },
                {
                    "sent": "If there was a query with only this time, so we solve the document by relevance to this term and also we divide them to act with the score intervals.",
                    "label": 0
                },
                {
                    "sent": "In this example we have M score interval.",
                    "label": 0
                },
                {
                    "sent": "So we group the documents by intervals an.",
                    "label": 0
                },
                {
                    "sent": "Now what we do is for each such interval we apply KMV statistics an accurate some A.",
                    "label": 0
                },
                {
                    "sent": "What we call LIJM.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry for the notations.",
                    "label": 0
                },
                {
                    "sent": "All the details are in the paper, but the idea is that we take the documents in each interval we apply some hash uniform hash function.",
                    "label": 0
                },
                {
                    "sent": "That guarantees we take enough bits that guarantees that there are no duplicates.",
                    "label": 0
                },
                {
                    "sent": "An actually we end up with what we call the CNV synopsis for each interval, and actually what it does it just take the LL minimal values from each.",
                    "label": 0
                },
                {
                    "sent": "Output of the hash function.",
                    "label": 0
                },
                {
                    "sent": "So for each interval we apply as function uniform hash function and we take the L minimal value.",
                    "label": 1
                },
                {
                    "sent": "So for each interval we have a synopsis and all together Web Sigma IJ which is all the synopsis for a PPI for temp TJ and specifically each cell here is a synopsis for a specific interval, so this is the synopsis.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "And now we want to show how to use this synopsis in order to decide how to link the pills or relevant to the query.",
                    "label": 0
                },
                {
                    "sent": "So assume we are given a query with N terms.",
                    "label": 1
                },
                {
                    "sent": "Assume that we collected the statistics of specific peel for all the query terms I'll show later how we do it, But basically we can approach the pills that are responsible for the query terms and collect the statistics and assume now that we have this test statistic for a specific field.",
                    "label": 1
                },
                {
                    "sent": "Now how do we use it to decide if the pier is is as God documents that are relevant for the query?",
                    "label": 0
                },
                {
                    "sent": "So intuitively let's assume there was a document.",
                    "label": 0
                },
                {
                    "sent": "With all the query terms, we remember that we are now dealing with.",
                    "label": 0
                },
                {
                    "sent": "Conjunctive a.",
                    "label": 0
                },
                {
                    "sent": "Clearly time, so this coming of this document would be some aggregation function on the scores that the document would get for each individual term.",
                    "label": 0
                },
                {
                    "sent": "An actually we want to do something similar here so we don't have the documents.",
                    "label": 0
                },
                {
                    "sent": "We have the statistics, so for PPI we have the statistics.",
                    "label": 0
                },
                {
                    "sent": "Let's say for the query terms all the Sigma IJ for all the query type.",
                    "label": 0
                },
                {
                    "sent": "The question is if we can apply some function which will actually be somehow similar to this original scoring function on these statistics to decide if this pier is relevant to the query or node.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we do it?",
                    "label": 0
                },
                {
                    "sent": "So what we'll do is actually we take.",
                    "label": 0
                },
                {
                    "sent": "Remember that we created those synopsis.",
                    "label": 0
                },
                {
                    "sent": "So assume now again we have N query terms and these are all the synopsis of this pier for the query time.",
                    "label": 0
                },
                {
                    "sent": "So what we would like to do is actually consider all the possible combinations when we select.",
                    "label": 0
                },
                {
                    "sent": "Each time we select a interval from a different interval for each query to.",
                    "label": 1
                },
                {
                    "sent": "So we define this H vector.",
                    "label": 0
                },
                {
                    "sent": "This is example for example, that we took the second interval for the first, the last interval for the second term, and so on.",
                    "label": 0
                },
                {
                    "sent": "So we have a now a combination of any synopsis for an interval an now assume if there was a document actually appeared here that is represented by this synopsis.",
                    "label": 0
                },
                {
                    "sent": "There we could figure out that the score of this document for this term would be some.",
                    "label": 0
                },
                {
                    "sent": "We can take the middle point.",
                    "label": 0
                },
                {
                    "sent": "Remember that this intervals are sorted by.",
                    "label": 1
                },
                {
                    "sent": "So we could take the middle point deal to say this would be the score of this document for this term and altogether.",
                    "label": 0
                },
                {
                    "sent": "We can say now that similarly as we did for the document, we can say now that scoring of this vector, this combination, we still don't know if there is a document there.",
                    "label": 1
                },
                {
                    "sent": "Maybe there is no document that actually fits here and here and here, but if there was a document then we could figure out the score of this document could be the same G the same scoring function that is used applied to the middle point of.",
                    "label": 0
                },
                {
                    "sent": "Each of the intervals that are selected.",
                    "label": 0
                },
                {
                    "sent": "So the next question is actually to try to estimate if there is actually a document there, because if there is no document in this interval there, there is no contribution to discover this field.",
                    "label": 1
                },
                {
                    "sent": "We would like to consider only combinations of interval that actually are not empty so that there is some document there so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do we do it so we have actually a two scoring function to try to estimate this so the first one we called them we call it came free in which is the intersection score and a.",
                    "label": 0
                },
                {
                    "sent": "This is very simple.",
                    "label": 0
                },
                {
                    "sent": "One of the properties of the CNV synopsis is that we can estimate, so we have actually NA intervals an we can estimate if the intervals are empty of or not.",
                    "label": 0
                },
                {
                    "sent": "Because remember, we took each interval is just the L minimal values of the documents of the hash function of the documents that appeared in this interval.",
                    "label": 0
                },
                {
                    "sent": "So the non emptiness intersection is just.",
                    "label": 0
                },
                {
                    "sent": "We can just check if there is.",
                    "label": 0
                },
                {
                    "sent": "A value that appearing all this interval.",
                    "label": 0
                },
                {
                    "sent": "If there is a value there then we are sure there is a document there.",
                    "label": 1
                },
                {
                    "sent": "We're show there is a document in this field that actually had this school for this term and so on.",
                    "label": 0
                },
                {
                    "sent": "So we can define this caused appear now to be.",
                    "label": 1
                },
                {
                    "sent": "We look at all the intersections that are not empty.",
                    "label": 0
                },
                {
                    "sent": "We know there is a document there and actually we take the Max.",
                    "label": 0
                },
                {
                    "sent": "The maximum of the scores that this document would get.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that actually this is a non emptiness intersection.",
                    "label": 0
                },
                {
                    "sent": "Can be an underestimate becausw, especially if we deal with values with a large number of terms then.",
                    "label": 1
                },
                {
                    "sent": "Liberty probability that the intersection is empty even though there is a real document.",
                    "label": 0
                },
                {
                    "sent": "There just increases because remember, we just took the L minimal values so.",
                    "label": 0
                },
                {
                    "sent": "We can get in many cases they.",
                    "label": 0
                },
                {
                    "sent": "The intersection is empty, but still there is a document there, but we missed it because of the KMV synopsis.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in order to fix this, we apply what we call can be expected, which is the expected score of the pill and the idea I will not go into detail because I don't have time.",
                    "label": 0
                },
                {
                    "sent": "But the idea here is that we try to estimate the probability that there is a document that exists.",
                    "label": 0
                },
                {
                    "sent": "So again we take all all combinations and we try to estimate the probability that there is a document there.",
                    "label": 0
                },
                {
                    "sent": "And actually we sum over all the.",
                    "label": 0
                },
                {
                    "sent": "If possible combination and then multiply by this, call that if there was a document this was discarded, it would get, so these are the.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So scrolling function that we use and now we go to the peer selection algorithm.",
                    "label": 0
                },
                {
                    "sent": "So basic field selection algorithm would be the following.",
                    "label": 0
                },
                {
                    "sent": "Assume that we have a query with NA.",
                    "label": 0
                },
                {
                    "sent": "I would like to get the top K result and assume that we get another parameter which is a large capital K. It says what is the maximum number of pills that we are willing to contact.",
                    "label": 0
                },
                {
                    "sent": "So a straightforward algorithm would be first to use the DHT to locate the fields that are responsible for the query terms, and then just collect all the statistics that therefore the query term.",
                    "label": 1
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "Hey I just didn't mention that actually, because we're dealing with a period.",
                    "label": 0
                },
                {
                    "sent": "So that the query can be initiated by any peer so they feel that initiated query now actually collect all the statistics for the very term and now what it can do.",
                    "label": 0
                },
                {
                    "sent": "It can try to estimate or actually two rank the peers because now.",
                    "label": 0
                },
                {
                    "sent": "As all the statistics, for example for Pier One, it has all the statistics of Pier One for the query terms, so we can try to apply the two scoring function that we have this drive to estimate the relevance of the score of the field.",
                    "label": 0
                },
                {
                    "sent": "So we start by Kambri is which is more accurate and then it came in.",
                    "label": 0
                },
                {
                    "sent": "Gives no more way feels that Allie is nonempty intersection.",
                    "label": 0
                },
                {
                    "sent": "Then we go to the camp Exp.",
                    "label": 1
                },
                {
                    "sent": "And then we can take the top K peers and then contact them and get their results and then merge the result.",
                    "label": 0
                },
                {
                    "sent": "No, the problem with this algorithm is actually that it requires a lot of communication cause cause we need to go to all the get all this statistics and this can be very large if we're dealing with a lot of peers.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first improvement that we suggest is actually to improve this.",
                    "label": 0
                },
                {
                    "sent": "The communication cost, so we don't want to send all the statistics we want to send only a subset of it.",
                    "label": 0
                },
                {
                    "sent": "When I'm talking about query runtime, I'm not talking now about indexing time, so at indexing time we assume that the statistics somehow arrive to this appears that are responsible for the terrorism.",
                    "label": 0
                },
                {
                    "sent": "Now I'm talking about very time optimization.",
                    "label": 0
                },
                {
                    "sent": "So instead of going to this N Pierce at responsiblefor, the correct terms and get this statistic.",
                    "label": 0
                },
                {
                    "sent": "What we can do is we can go and ask them what is the length of their statistics so each.",
                    "label": 0
                },
                {
                    "sent": "Of the N terms of the MPs would just give us number the length of the statistics that they have from all the other peers and then what we can do is we can select the two pills with this two shortest.",
                    "label": 0
                },
                {
                    "sent": "At least let's call them TF for the first Ain TS 42nd and now the query initiating peer pick.",
                    "label": 1
                },
                {
                    "sent": "You can just forward the very tapir PTS to the to the pier with the 2nd.",
                    "label": 0
                },
                {
                    "sent": "Longest Sam.",
                    "label": 0
                },
                {
                    "sent": "Posting list and now this bill becomes responsible for performing the query and now what this pill can do.",
                    "label": 0
                },
                {
                    "sent": "It can ignore who is the pier with the shortest.",
                    "label": 0
                },
                {
                    "sent": "So it can get the statistics on this field, so this is the shortest tactics that we can get.",
                    "label": 0
                },
                {
                    "sent": "Then it applies the CRV in on all the fields that are in the listing.",
                    "label": 0
                },
                {
                    "sent": "Now we get a very small subset of peers that are candidate two FA result.",
                    "label": 0
                },
                {
                    "sent": "This feels actually.",
                    "label": 0
                },
                {
                    "sent": "We have to be.",
                    "label": 0
                },
                {
                    "sent": "It is guaranteed that they F documents with the two terms with the terms PS and PS.",
                    "label": 1
                },
                {
                    "sent": "Are these actually eliminate the large number of appeals and now the next step of actually the last step is actually to get the rest of the statistics from the other peers that are responsible for the returns that asked to do it only for the peers that are candidates?",
                    "label": 1
                },
                {
                    "sent": "Which is the set P?",
                    "label": 0
                },
                {
                    "sent": "So this saves.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Out of communication costs, the next improvement is to apply an adaptive ranking algorithm.",
                    "label": 1
                },
                {
                    "sent": "So I remembering the basic algorithm, we just ranked the top K Capital K peers and contacted.",
                    "label": 0
                },
                {
                    "sent": "Contacted all of them simultaneously.",
                    "label": 0
                },
                {
                    "sent": "Here we can walk in rounds and actually in each week and select K prime which is smaller than a capital K and what we will do is each round actually will.",
                    "label": 1
                },
                {
                    "sent": "Rank only K prime peers and then we contact this peer.",
                    "label": 0
                },
                {
                    "sent": "We get the results back.",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "And then we take a threshold which is we call it a min K which is actually the score of the document at the Kate position.",
                    "label": 0
                },
                {
                    "sent": "So we have actually some results already from this capeline pills and we can see what is the score of the document at the K position and now actually we can adaptively rank the rest of the peers because we can just actually remember that we have this.",
                    "label": 1
                },
                {
                    "sent": "All this combination and we can actually filter out peers.",
                    "label": 0
                },
                {
                    "sent": "That cannot reach this mean case code now, instead of taking the middle point of each interval, we can take actually to be safe the right point, which is the Max code.",
                    "label": 0
                },
                {
                    "sent": "If there was a document, this would be the Max code that it would get if it was in this interval.",
                    "label": 0
                },
                {
                    "sent": "So we can actually ignore because we are looking at all possible combination we can ignore combination which cannot reach this threshold score.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the full algorithm I know.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will not.",
                    "label": 0
                },
                {
                    "sent": "It's in the paper.",
                    "label": 0
                },
                {
                    "sent": "I will not go into detail so experiments we use the two data set one of them with 2K.",
                    "label": 0
                },
                {
                    "sent": "OK Gov 2 collection between 10,000,000 documents.",
                    "label": 0
                },
                {
                    "sent": "The other one is a whole load.",
                    "label": 0
                },
                {
                    "sent": "If we did this was a 2 million documents and actually we had the tree set up.",
                    "label": 0
                },
                {
                    "sent": "The Recollection I2 setups 175 / 10 billion documents into 10,000 field each having 1000 documents and the second set up is we actually use 1000 fields in each having.",
                    "label": 1
                },
                {
                    "sent": "10,000 documents and for the blog used as a bill for queries, we took a slightly took 50 Ferris on the topic distillation track and field locally took a 75 queries from the block track of like 2008.",
                    "label": 1
                },
                {
                    "sent": "The parameters that vary.",
                    "label": 1
                },
                {
                    "sent": "Add the.",
                    "label": 0
                },
                {
                    "sent": "KB size how many values we take from the hash function.",
                    "label": 0
                },
                {
                    "sent": "M is the number of intervals that we use.",
                    "label": 0
                },
                {
                    "sent": "Angie is another matter.",
                    "label": 0
                },
                {
                    "sent": "If the bill is that many documents that we can divide it into logical groups and actually apply NP synopsis to each group, again, all the details are in the paper for evaluation we use in DCG and also map.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are the result.",
                    "label": 0
                },
                {
                    "sent": "Battle of the flag 10K10K.",
                    "label": 0
                },
                {
                    "sent": "It means that life is 10,000 pills.",
                    "label": 0
                },
                {
                    "sent": "Each field is 1000 documents.",
                    "label": 0
                },
                {
                    "sent": "The setup that uses L then meaning that we took 10 values for each interval.",
                    "label": 0
                },
                {
                    "sent": "Abuse five story from box.",
                    "label": 0
                },
                {
                    "sent": "You can see this this alter results, so the graph shows this is the number of selected fields and this is the end DCG and you can see that even when we select 10 pills.",
                    "label": 0
                },
                {
                    "sent": "This is our method even when selecting selecting then feels out of the 10,000 field we already get very high values of N, DCG and of course they improve as we select more, buy more peers and the other method.",
                    "label": 0
                },
                {
                    "sent": "For example, Kohli, some collection statistics, but it's not.",
                    "label": 0
                },
                {
                    "sent": "So I find lenders that people using CRC estimated that takes a sample of the each peel and then use this to estimate the elements of the field.",
                    "label": 0
                },
                {
                    "sent": "These are the results for blog.",
                    "label": 0
                },
                {
                    "sent": "Leonik communication costs, so this is our method, so this is in kilobytes, so this is the average communication costs the query and you can see that actually it's more or less this is some other metal.",
                    "label": 0
                },
                {
                    "sent": "If we decide last dealing CIK.",
                    "label": 0
                },
                {
                    "sent": "You can see that can be more or less the same level as the simple a query of CDF CDF and this is actually thanks to the filtering that we did in the saving the communication cost in contacting the second clear and so on.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This shows some may playing with the parameter of the algorithm, so it will be valid.",
                    "label": 0
                },
                {
                    "sent": "The number of CNV values that we take.",
                    "label": 0
                },
                {
                    "sent": "Another of this calling about the number of groups and of course as we take both groups and more values then results improve.",
                    "label": 0
                },
                {
                    "sent": "Actually our baseline is is this one is a.",
                    "label": 0
                },
                {
                    "sent": "One thing keep in values then like this quality of life which is actually this one OK?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This graph shows actually the effect of the two scoring function there.",
                    "label": 0
                },
                {
                    "sent": "We intend to KBS and using the adaptive of ignoring the adaptive mode.",
                    "label": 0
                },
                {
                    "sent": "So for example used it you can see for the black one OK that this yellow one is actually using the intersection score only.",
                    "label": 0
                },
                {
                    "sent": "If that is the adaptive and non adaptive in this case, actually even the nonadaptive perform a little bit better, but you can see that moving to KMP XP improve the result and then using both can be expected score the adaptive actually give the best result here.",
                    "label": 0
                },
                {
                    "sent": "For blog this is interesting.",
                    "label": 0
                },
                {
                    "sent": "What we can see is actually using only the cavi in is quite a bounded.",
                    "label": 0
                },
                {
                    "sent": "Again, this shows the number of selected fields.",
                    "label": 1
                },
                {
                    "sent": "This shows the MVC two values.",
                    "label": 0
                },
                {
                    "sent": "We can see that using only KMV in we cannot get too far and the reason is because for blog actually we were using.",
                    "label": 1
                },
                {
                    "sent": "With a large number of them.",
                    "label": 0
                },
                {
                    "sent": "7 times and so on are compared to track it allowed just barely was only five years, so this is the effect of the underestimate of the intersection operator and but you can see that moving to can be expected, actually improves alot.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also tested the different calling function and this is actually.",
                    "label": 0
                },
                {
                    "sent": "Some important observation one can ask how we compare the scores between the bills, because each field actually rate.",
                    "label": 0
                },
                {
                    "sent": "It's only posting listen each field.",
                    "label": 0
                },
                {
                    "sent": "K so there documents according to its local scoring function.",
                    "label": 0
                },
                {
                    "sent": "So the question is how we can measure results.",
                    "label": 0
                },
                {
                    "sent": "How we can compare scores between peers so?",
                    "label": 0
                },
                {
                    "sent": "In this table actually shows the result and the anti CG values.",
                    "label": 0
                },
                {
                    "sent": "When selecting 20 fields and model.",
                    "label": 0
                },
                {
                    "sent": "Consider these are the three collection.",
                    "label": 0
                },
                {
                    "sent": "OK, give Me 2 minutes.",
                    "label": 0
                },
                {
                    "sent": "About the political actions, what you can see.",
                    "label": 0
                },
                {
                    "sent": "Lucene is actually we were using implemented everything on top of Lucene and actually this line is Lucille, but we did actually some global synchronization of the parameters so we did some preprocessing and each field actually sent to all the other peers.",
                    "label": 1
                },
                {
                    "sent": "It's a let's say it's IDF for each term.",
                    "label": 0
                },
                {
                    "sent": "Once we have this global information, then this code at each peer compute locally for each document is actually the same as as it would be obtained in a centralized system because we have all the global collection parameters.",
                    "label": 0
                },
                {
                    "sent": "This line is we will using VM25 and this line is actually using Lucina grain bug.",
                    "label": 1
                },
                {
                    "sent": "Each field actually compute its own local scores so one can say that these calls are not compatible because the example the IDF.",
                    "label": 0
                },
                {
                    "sent": "The first document frequency is different, but we can still see that even without.",
                    "label": 0
                },
                {
                    "sent": "Actually synchronizing the parameter we can see that still get really nice results for entity, which is which are Mount much higher than the other system so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to whip up so conclusions we presented a fully decentralized peer selection algorithm that uses only a small subset of the peers and also safe communication costs.",
                    "label": 1
                },
                {
                    "sent": "We describe two scoring function.",
                    "label": 1
                },
                {
                    "sent": "One of them was the intersection score, one of the second ones.",
                    "label": 0
                },
                {
                    "sent": "They expect the expected score.",
                    "label": 1
                },
                {
                    "sent": "It per outperforms other methods, but more than 400% an regarding communication 'cause we showed how we can save the communication caused by contacting the second pier and so on.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for future VO we would like to investigate further reduction in the communication costs and we would like to consider the less less less restrictive, non empty emptiness and simulator.",
                    "label": 1
                },
                {
                    "sent": "And in particular you would like to look also at a.",
                    "label": 0
                },
                {
                    "sent": "So it should be distinct.",
                    "label": 0
                },
                {
                    "sent": "This disjunctive.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}