{
    "id": "aruil3yqv45gf2g232nhawzurxufntfe",
    "title": "XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks",
    "info": {
        "author": [
            "Mohammad Rastegari, Allen Institute for Artificial Intelligence (AI2)"
        ],
        "published": "Oct. 24, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2016_rastegari_neural_networks/",
    "segmentation": [
        [
            "Hi, I'm Mohamed, I'm gonna present ignore that this is a joint work with decent Ordonez, Joseph Redmond and Ali Farhadi.",
            "Let me refresh some near memory for you."
        ],
        [
            "Most of us have been sitting either side of this desk, either asking our advisor or mentor for a project to work on, or trying to convince him on the project, but."
        ],
        [
            "Regardless, these days always the answer is deep learning and when it comes to deep learning, the very first step is to ask for."
        ],
        [
            "The GPU server and hopefully a beefy one and the reaction obviously is."
        ],
        [
            "This is."
        ],
        [
            "The beefy machine I'm talking about this is what we really need to run a state of the art recognition methods.",
            "Our recent."
        ],
        [
            "Learning methods are so expensive in terms of memory computation and power.",
            "For example, the amount of power that we need to classify a single image is enough to perform world changing tasks to blow there."
        ],
        [
            "By this specific hair."
        ],
        [
            "That can make the world great again.",
            "Now that you're all very convinced that our recent deep learning method is so expensive, let's look at."
        ],
        [
            "One of the most common deep learning pipeline in computer vision, convolutional neural network where is single image has to go through several convolutional layers and a."
        ],
        [
            "Solutional operations are applied between two tensors of real values that has a lot of floating point operations.",
            "For example, in Alex Net it requires 1.5 billion floating point operation.",
            "In Weegy network it requires about 20 billion floating point operations, and this amount of floating point operation is so expensive for CPU and that's why we need GPU.",
            "But do we really need the floating point operations?"
        ],
        [
            "Most of the recent deep learning methods are using 32 bit to represent data and operations, but reducing the precision we can save in memory and computation.",
            "In this work we take this idea to its extreme scenario and we reduce the precision to 1 bit where we represent only positive and negative values are recent.",
            "This study shows that the parameters of convolutional neural network can be represented by a binomial distribution, so we can.",
            "Transfer the operations in the plus one and negative one to the operation in the bitwise domain.",
            "For example, the multiplication can be translated to the ignore operation and the addition and subtraction can be translated to bit count operation and these operations are so efficient that."
        ],
        [
            "We can easily implement them in most of the processors and they are so efficient that we can use them in low power device.",
            "All we need to do now is to figure out a way to create a neural network can use binary operations.",
            "OK, now."
        ],
        [
            "We know that the critical point of the convolutional neural network is the convolution operation that requires addition, subtraction and multiplication.",
            "Now what if we binarize the weight filters?",
            "Then we can implement convolution without any multiplication and finalizing the filters, saves memory for us in 232, about 32 X, and save computation about two 2X, but we can go even one step further and binarize both the input and the weight filters.",
            "Now we can implement convolution without any arithmetic operations.",
            "And only with logical operation X nor and bit count.",
            "In this case we also save memory in by 32 X, but also the computation about 58 X."
        ],
        [
            "So throughout this talk we refer to the network with binary fade filter as a binary rate network and then network with both input and the weight filter binarized as an ignore network, let's see."
        ],
        [
            "How we can create a network with binary weight filters so in?"
        ],
        [
            "Convolution we usually element."
        ],
        [
            "The product the weight filter with all the spatial location of the input tensor."
        ],
        [
            "And a piece of this convolution is the input tensor, X is elementwise product by an input rate field by await filter in the real value.",
            "So we want to find the binary version of the weight value that approximate this element wise product.",
            "This directly translates to finding the binary version of the weight filter and this trade solution would be taking the sine function of the weight filters.",
            "But that introduces a huge."
        ],
        [
            "Amount of quantization error too.",
            "Sorry to intrude.",
            "To compensate for this quantization error, we introduced."
        ],
        [
            "Knew a scaling factor in our binarization function.",
            "Here, we want to optimize both for the scaling factor Anna binary weight filter that we that minimize the reconstruction error for the original weight filter.",
            "Luckily, this has a closed form solution and we can use this course with solution to estimate the convolution between two real value tensor by a binary rate Anna single scaling."
        ],
        [
            "But now how can we train in neural network with binary rate filters and a straight solution or naive solution?"
        ],
        [
            "Is we just train a neural network with real value parameters and at the end we just binarize the weight filters, but well that seems."
        ],
        [
            "That does not work easily, so here I'm showing the accuracy of the method of the full precision in compared with the naive solution using Alex Net trained on image net on top one measure.",
            "So unfortunately, binarization of the weight filters destroy all the information in the parameters of the neural network and the main challenge here is to find a set of."
        ],
        [
            "8 filters that if we binary."
        ],
        [
            "Is it we can rely abli class?"
        ],
        [
            "So for the categories of the objects in the image and for that we adopt A modified version of stochastic gradient dissent as follows."
        ],
        [
            "First, randomly initialize the weight filters."
        ],
        [
            "And then we pick a random image and then we take a copy of."
        ],
        [
            "The original wait filters and then we binarize."
        ],
        [
            "Using a closed form solution, then we forward."
        ],
        [
            "Cast image to the binary rate filters, then we."
        ],
        [
            "Compute the loss function at the end, and then we compute the."
        ],
        [
            "Agent in backward pass with respect of all the binary weight filters.",
            "Once we have the gradient, we cannot."
        ],
        [
            "Data original weight filters with a proper learning rate and the rest will be lots of lots of iteration until convergence.",
            "And if we train our."
        ],
        [
            "Using this algorithm, we can match the accuracy of full precision network."
        ],
        [
            "This."
        ],
        [
            "Is a method that the convolution does not use any multiplication and also it saves memory by factor of 32 X and it saved computation by factor of about 2X.",
            "Now let's see."
        ],
        [
            "How we can train?"
        ],
        [
            "Ignore it."
        ],
        [
            "It's."
        ],
        [
            "In external, the problem is very similar to the winery rate network.",
            "Here we only want to have the both input and the weight filter to be binary, and we already know that this."
        ],
        [
            "Healing factor is very important, so we introduced two scaling factor, one for the binary weights and the other one for the binary input now."
        ],
        [
            "Can convert this problem to the problem of single tensor binarization.",
            "So for that we already know the closed form solution and using this solution we can find the solution for both the input and the weight filter.",
            "So now we can approximate the convolution between 2:00."
        ],
        [
            "Value tensor why convolution between two binary tensor and a single matrix scaling?",
            "If we adopt this convolution into our training algorithm?"
        ],
        [
            "We will get this accuracy, so here there is still a lot."
        ],
        [
            "Large gap.",
            "In order to understand the this gap, we need to scrutinize the structure of the."
        ],
        [
            "Neural network, so this is a typical blocking structure in CNN is start with convolution and followed by batch normalization, activation and pulling.",
            "And in our case the activate."
        ],
        [
            "There is usually sign function.",
            "But here the input to the."
        ],
        [
            "Pooling layer will be a binary matrix and then the output of the pooling after the Max."
        ],
        [
            "Bing will often we unity matrix.",
            "This means that we are almost passing no information to the next convolutional layer, but not.",
            "Also we lose information in the forward path, but in."
        ],
        [
            "Backward plus we also often see more than one Maxima.",
            "That means that we don't know which one to be penalized.",
            "So one would assume that."
        ],
        [
            "With switching between two layers we can solve this issue, let's see."
        ],
        [
            "Here the input of the pooling layer is a real value matrix, and then the output will."
        ],
        [
            "We often a positive matrix and then the."
        ],
        [
            "Activation will turn it to the unity matrix again, so again we're losing information for the next layer, but here."
        ],
        [
            "We don't have the penalization problem in the backward pass, this is."
        ],
        [
            "The proposed blocker structure for the binary neural network as an extranet.",
            "So here it starts with batch normalization activation and then followed by convolution and pooling.",
            "Here the input of the convolution."
        ],
        [
            "Is a binary matrix that generates a."
        ],
        [
            "Value matrix which goes to."
        ],
        [
            "Pulling in the pooling will get a positive metrics and this goes to the next layer."
        ],
        [
            "For the batch normalization and then the mean centering of the."
        ],
        [
            "Batch normalization generates negative value for us, and when that goes to the active."
        ],
        [
            "And it creates a proper binary matrix to pass through the next layer.",
            "And if you put together."
        ],
        [
            "All the pieces we can get this act."
        ],
        [
            "Yeah, see which we improved by 14% over the default blocking structure of CNN and we only lose 13% in compared with the full precision network.",
            "Note that this is."
        ],
        [
            "A method that reduces the memory by factor of 32 weeks.",
            "It means that the very large models like widget can be represented in a few megabytes."
        ],
        [
            "And we get to this speed in to the extent that we can run this state of the art deep learning on this CPU of low power device.",
            "We will also."
        ],
        [
            "See the similar trend in top one in top five accuracy showed with darker color here and our method is not specific to Alex.",
            "That is a generalized solution that can be applied even to other networks, for example."
        ],
        [
            "We run it on deeper network on Resnet and we see this similar trend and same same thing happens for the."
        ],
        [
            "Eaglenet now to showcase the efficiency of our method, we run object with."
        ],
        [
            "Action where we want to.",
            "Localized and recognize the categories of the objects in the image in the Lost city, P."
        ],
        [
            "My coauthor Joe presented the fastest object detection on the on his GPU powered laptop."
        ],
        [
            "This was his laptop.",
            "Now what if we run Yolo on this?"
        ],
        [
            "CPU of a fairly strong laptop."
        ],
        [
            "This would be this bit in which we can perform object detection on the CPU of a laptop, but Yolo empowered by ignore."
        ],
        [
            "It can run in real time in the CPU of the laptop."
        ],
        [
            "And this is the speed that you can see.",
            "But the power of exploring it enables us to push even further.",
            "We we want to run deep."
        ],
        [
            "Learning on the CPU of a low powered device.",
            "So in fact we are able to run object detection on a cell phone and here I want to show you a live demo of object detection running an iPhone and because I cannot project it directly here, alley is there and running a real time object detection and iPhone there for you.",
            "You can see that he's doing the demo there.",
            "So here we gotta have some fun objects and these are these are like the detections zebra.",
            "I think you need to restart.",
            "OK.",
            "Suggested to restart it.",
            "So for us it is very exciting that we can run the object detection on this CPU of an iPhone.",
            "So you can see that yeah, he's running.",
            "Sorry for the because we were supposed to run it here, but now it's there so it's very exciting for us.",
            "We can run this state of the art object detection on this CPU of the iPhone again, I'm saying that it is on the CPU.",
            "We're not even touching the GPU and.",
            "It's even getting more exciting, so if you're going back to the slide.",
            "We we can we ignore it, we can even push further and then we can."
        ],
        [
            "Run our state of the art object detection on Raspberry Pi Zero.",
            "This is a $5 computer with an ARM CPU and only 512 megabytes of RAM.",
            "For more discussion on Raspberry Pi, please stop by my poster.",
            "And at the end I."
        ],
        [
            "I thank all the people that helped me throughout this project.",
            "I want to have any specific tank Carlo and Dimitri who had a great contribution into implementing extranet on CPU.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, I'm Mohamed, I'm gonna present ignore that this is a joint work with decent Ordonez, Joseph Redmond and Ali Farhadi.",
                    "label": 0
                },
                {
                    "sent": "Let me refresh some near memory for you.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Most of us have been sitting either side of this desk, either asking our advisor or mentor for a project to work on, or trying to convince him on the project, but.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Regardless, these days always the answer is deep learning and when it comes to deep learning, the very first step is to ask for.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The GPU server and hopefully a beefy one and the reaction obviously is.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The beefy machine I'm talking about this is what we really need to run a state of the art recognition methods.",
                    "label": 0
                },
                {
                    "sent": "Our recent.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learning methods are so expensive in terms of memory computation and power.",
                    "label": 0
                },
                {
                    "sent": "For example, the amount of power that we need to classify a single image is enough to perform world changing tasks to blow there.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By this specific hair.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That can make the world great again.",
                    "label": 0
                },
                {
                    "sent": "Now that you're all very convinced that our recent deep learning method is so expensive, let's look at.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of the most common deep learning pipeline in computer vision, convolutional neural network where is single image has to go through several convolutional layers and a.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Solutional operations are applied between two tensors of real values that has a lot of floating point operations.",
                    "label": 0
                },
                {
                    "sent": "For example, in Alex Net it requires 1.5 billion floating point operation.",
                    "label": 0
                },
                {
                    "sent": "In Weegy network it requires about 20 billion floating point operations, and this amount of floating point operation is so expensive for CPU and that's why we need GPU.",
                    "label": 0
                },
                {
                    "sent": "But do we really need the floating point operations?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Most of the recent deep learning methods are using 32 bit to represent data and operations, but reducing the precision we can save in memory and computation.",
                    "label": 0
                },
                {
                    "sent": "In this work we take this idea to its extreme scenario and we reduce the precision to 1 bit where we represent only positive and negative values are recent.",
                    "label": 0
                },
                {
                    "sent": "This study shows that the parameters of convolutional neural network can be represented by a binomial distribution, so we can.",
                    "label": 0
                },
                {
                    "sent": "Transfer the operations in the plus one and negative one to the operation in the bitwise domain.",
                    "label": 0
                },
                {
                    "sent": "For example, the multiplication can be translated to the ignore operation and the addition and subtraction can be translated to bit count operation and these operations are so efficient that.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can easily implement them in most of the processors and they are so efficient that we can use them in low power device.",
                    "label": 1
                },
                {
                    "sent": "All we need to do now is to figure out a way to create a neural network can use binary operations.",
                    "label": 0
                },
                {
                    "sent": "OK, now.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We know that the critical point of the convolutional neural network is the convolution operation that requires addition, subtraction and multiplication.",
                    "label": 0
                },
                {
                    "sent": "Now what if we binarize the weight filters?",
                    "label": 0
                },
                {
                    "sent": "Then we can implement convolution without any multiplication and finalizing the filters, saves memory for us in 232, about 32 X, and save computation about two 2X, but we can go even one step further and binarize both the input and the weight filters.",
                    "label": 0
                },
                {
                    "sent": "Now we can implement convolution without any arithmetic operations.",
                    "label": 0
                },
                {
                    "sent": "And only with logical operation X nor and bit count.",
                    "label": 0
                },
                {
                    "sent": "In this case we also save memory in by 32 X, but also the computation about 58 X.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So throughout this talk we refer to the network with binary fade filter as a binary rate network and then network with both input and the weight filter binarized as an ignore network, let's see.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How we can create a network with binary weight filters so in?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Convolution we usually element.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The product the weight filter with all the spatial location of the input tensor.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And a piece of this convolution is the input tensor, X is elementwise product by an input rate field by await filter in the real value.",
                    "label": 0
                },
                {
                    "sent": "So we want to find the binary version of the weight value that approximate this element wise product.",
                    "label": 0
                },
                {
                    "sent": "This directly translates to finding the binary version of the weight filter and this trade solution would be taking the sine function of the weight filters.",
                    "label": 0
                },
                {
                    "sent": "But that introduces a huge.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Amount of quantization error too.",
                    "label": 1
                },
                {
                    "sent": "Sorry to intrude.",
                    "label": 0
                },
                {
                    "sent": "To compensate for this quantization error, we introduced.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Knew a scaling factor in our binarization function.",
                    "label": 0
                },
                {
                    "sent": "Here, we want to optimize both for the scaling factor Anna binary weight filter that we that minimize the reconstruction error for the original weight filter.",
                    "label": 0
                },
                {
                    "sent": "Luckily, this has a closed form solution and we can use this course with solution to estimate the convolution between two real value tensor by a binary rate Anna single scaling.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But now how can we train in neural network with binary rate filters and a straight solution or naive solution?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is we just train a neural network with real value parameters and at the end we just binarize the weight filters, but well that seems.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That does not work easily, so here I'm showing the accuracy of the method of the full precision in compared with the naive solution using Alex Net trained on image net on top one measure.",
                    "label": 0
                },
                {
                    "sent": "So unfortunately, binarization of the weight filters destroy all the information in the parameters of the neural network and the main challenge here is to find a set of.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "8 filters that if we binary.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is it we can rely abli class?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the categories of the objects in the image and for that we adopt A modified version of stochastic gradient dissent as follows.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, randomly initialize the weight filters.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we pick a random image and then we take a copy of.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The original wait filters and then we binarize.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using a closed form solution, then we forward.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cast image to the binary rate filters, then we.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compute the loss function at the end, and then we compute the.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Agent in backward pass with respect of all the binary weight filters.",
                    "label": 0
                },
                {
                    "sent": "Once we have the gradient, we cannot.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data original weight filters with a proper learning rate and the rest will be lots of lots of iteration until convergence.",
                    "label": 0
                },
                {
                    "sent": "And if we train our.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using this algorithm, we can match the accuracy of full precision network.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a method that the convolution does not use any multiplication and also it saves memory by factor of 32 X and it saved computation by factor of about 2X.",
                    "label": 0
                },
                {
                    "sent": "Now let's see.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How we can train?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ignore it.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In external, the problem is very similar to the winery rate network.",
                    "label": 0
                },
                {
                    "sent": "Here we only want to have the both input and the weight filter to be binary, and we already know that this.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Healing factor is very important, so we introduced two scaling factor, one for the binary weights and the other one for the binary input now.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can convert this problem to the problem of single tensor binarization.",
                    "label": 0
                },
                {
                    "sent": "So for that we already know the closed form solution and using this solution we can find the solution for both the input and the weight filter.",
                    "label": 1
                },
                {
                    "sent": "So now we can approximate the convolution between 2:00.",
                    "label": 1
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Value tensor why convolution between two binary tensor and a single matrix scaling?",
                    "label": 0
                },
                {
                    "sent": "If we adopt this convolution into our training algorithm?",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will get this accuracy, so here there is still a lot.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Large gap.",
                    "label": 0
                },
                {
                    "sent": "In order to understand the this gap, we need to scrutinize the structure of the.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Neural network, so this is a typical blocking structure in CNN is start with convolution and followed by batch normalization, activation and pulling.",
                    "label": 0
                },
                {
                    "sent": "And in our case the activate.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is usually sign function.",
                    "label": 0
                },
                {
                    "sent": "But here the input to the.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pooling layer will be a binary matrix and then the output of the pooling after the Max.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bing will often we unity matrix.",
                    "label": 0
                },
                {
                    "sent": "This means that we are almost passing no information to the next convolutional layer, but not.",
                    "label": 0
                },
                {
                    "sent": "Also we lose information in the forward path, but in.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Backward plus we also often see more than one Maxima.",
                    "label": 0
                },
                {
                    "sent": "That means that we don't know which one to be penalized.",
                    "label": 0
                },
                {
                    "sent": "So one would assume that.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With switching between two layers we can solve this issue, let's see.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here the input of the pooling layer is a real value matrix, and then the output will.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We often a positive matrix and then the.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Activation will turn it to the unity matrix again, so again we're losing information for the next layer, but here.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We don't have the penalization problem in the backward pass, this is.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The proposed blocker structure for the binary neural network as an extranet.",
                    "label": 0
                },
                {
                    "sent": "So here it starts with batch normalization activation and then followed by convolution and pooling.",
                    "label": 0
                },
                {
                    "sent": "Here the input of the convolution.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a binary matrix that generates a.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Value matrix which goes to.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pulling in the pooling will get a positive metrics and this goes to the next layer.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the batch normalization and then the mean centering of the.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Batch normalization generates negative value for us, and when that goes to the active.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it creates a proper binary matrix to pass through the next layer.",
                    "label": 0
                },
                {
                    "sent": "And if you put together.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All the pieces we can get this act.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, see which we improved by 14% over the default blocking structure of CNN and we only lose 13% in compared with the full precision network.",
                    "label": 0
                },
                {
                    "sent": "Note that this is.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A method that reduces the memory by factor of 32 weeks.",
                    "label": 0
                },
                {
                    "sent": "It means that the very large models like widget can be represented in a few megabytes.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we get to this speed in to the extent that we can run this state of the art deep learning on this CPU of low power device.",
                    "label": 0
                },
                {
                    "sent": "We will also.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See the similar trend in top one in top five accuracy showed with darker color here and our method is not specific to Alex.",
                    "label": 0
                },
                {
                    "sent": "That is a generalized solution that can be applied even to other networks, for example.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We run it on deeper network on Resnet and we see this similar trend and same same thing happens for the.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Eaglenet now to showcase the efficiency of our method, we run object with.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Action where we want to.",
                    "label": 0
                },
                {
                    "sent": "Localized and recognize the categories of the objects in the image in the Lost city, P.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My coauthor Joe presented the fastest object detection on the on his GPU powered laptop.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This was his laptop.",
                    "label": 0
                },
                {
                    "sent": "Now what if we run Yolo on this?",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "CPU of a fairly strong laptop.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This would be this bit in which we can perform object detection on the CPU of a laptop, but Yolo empowered by ignore.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It can run in real time in the CPU of the laptop.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the speed that you can see.",
                    "label": 0
                },
                {
                    "sent": "But the power of exploring it enables us to push even further.",
                    "label": 0
                },
                {
                    "sent": "We we want to run deep.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learning on the CPU of a low powered device.",
                    "label": 0
                },
                {
                    "sent": "So in fact we are able to run object detection on a cell phone and here I want to show you a live demo of object detection running an iPhone and because I cannot project it directly here, alley is there and running a real time object detection and iPhone there for you.",
                    "label": 0
                },
                {
                    "sent": "You can see that he's doing the demo there.",
                    "label": 0
                },
                {
                    "sent": "So here we gotta have some fun objects and these are these are like the detections zebra.",
                    "label": 0
                },
                {
                    "sent": "I think you need to restart.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Suggested to restart it.",
                    "label": 0
                },
                {
                    "sent": "So for us it is very exciting that we can run the object detection on this CPU of an iPhone.",
                    "label": 0
                },
                {
                    "sent": "So you can see that yeah, he's running.",
                    "label": 0
                },
                {
                    "sent": "Sorry for the because we were supposed to run it here, but now it's there so it's very exciting for us.",
                    "label": 0
                },
                {
                    "sent": "We can run this state of the art object detection on this CPU of the iPhone again, I'm saying that it is on the CPU.",
                    "label": 0
                },
                {
                    "sent": "We're not even touching the GPU and.",
                    "label": 0
                },
                {
                    "sent": "It's even getting more exciting, so if you're going back to the slide.",
                    "label": 0
                },
                {
                    "sent": "We we can we ignore it, we can even push further and then we can.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Run our state of the art object detection on Raspberry Pi Zero.",
                    "label": 1
                },
                {
                    "sent": "This is a $5 computer with an ARM CPU and only 512 megabytes of RAM.",
                    "label": 0
                },
                {
                    "sent": "For more discussion on Raspberry Pi, please stop by my poster.",
                    "label": 0
                },
                {
                    "sent": "And at the end I.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I thank all the people that helped me throughout this project.",
                    "label": 0
                },
                {
                    "sent": "I want to have any specific tank Carlo and Dimitri who had a great contribution into implementing extranet on CPU.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}