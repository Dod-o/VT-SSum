{
    "id": "6rlxxki3rz72pn3i4rcymwf76epsyot3",
    "title": "Efficient Kernels Couple Visual Words Through Categorical Opponency",
    "info": {
        "author": [
            "Ioannis Alexiou, Imperial College London"
        ],
        "published": "Oct. 9, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Technology->Engineering->Bioengineering"
        ]
    },
    "url": "http://videolectures.net/bmvc2012_alexiou_categorical_opponency/",
    "segmentation": [
        [
            "Hello, I'm here.",
            "This student and this is joint work with my supervisor and Bart.",
            "I'm so the overview of this."
        ],
        [
            "It will be in the introduction to our method related work.",
            "The visual structure of pairing experiment results, conclusions and filter work.",
            "So I'll"
        ],
        [
            "Add with a with an overview of related methods to our work so the most popular, the most well known method is the deformable part model, which is has been proven very useful especially for object detection.",
            "Next is here article models by Zoom published in APT 2009.",
            "We say they use four different levels of hierarchy, which starting from very simple features in its time adding up and more complex structure.",
            "To finalize the learned console.",
            "So below is another similar approach using 4 levels as well, and you can see the reconstructed models for its level, which they usually.",
            "It's very.",
            "It's very commonly found in.",
            "A starting with wavelets going up to the exactions parts of controls and finally conscious self, and on the right hand side is the method with more close to ours, with the authors here, detect Co occurrences of triplets or any higher order of words and they mapped it back to enough space.",
            "And finally, using a on the bottom right, finally the authors.",
            "Here's a monitor.",
            "The pairwise interactions just conditional random fields starting with simple features as edges.",
            "So then so all three of these methods have a common thing with the same hidden here, OK, and it's very closely related to a neuro."
        ],
        [
            "Science modeled by which has been published or proposed by.",
            "Um, by the massacre.",
            "This group and the starts the first level of hierarchy usually start with simple features which are selective to edge orientations.",
            "And as we going up into levels of hierarchy, we those feats will become much more complex, such as corners.",
            "Did junctions another high order conjunctions to find the next levels?",
            "We were the complexity of the structure increases.",
            "So what we thought here is that usually the computer vision community.",
            "Can detect those features easily with a key point detection and some of them with descriptors and actually quantized them.",
            "Or cluster them using interfacial words and we thought to replace to simplify the problem to a single node.",
            "And replace the leaves of the nodes with visual words.",
            "So the next problem is to detect the Co occurrences of visual words, which can be proven."
        ],
        [
            "Useful, there are very discriminate towards classes, so the way we formulate this is we have.",
            "We already have the prior knowledge of the database, which is actually the distribution of the words of the train set.",
            "So we can stay awake.",
            "So if we start with the joint probability we have that given one word WI, WI is has occurred.",
            "With penalized this word, and as you can see in the blue histograms.",
            "So this word is set to 0 and we monitor all the occurrences of all the other words.",
            "So in that way we have a we have a view of probable currencies and we repeat the same process for all the for the rest of the code book.",
            "To create a 2D array, the next thing to do is that we have the power knowledge with this represented by the red histogram, and this is actually the IDF term of is the inverse document frequency term we have from the database.",
            "The reason we use that prayer is that this will down wait very frequent words and the user leave those very frequent words occur in all the classes.",
            "So it is very likely food on weight.",
            "And we know we will have very like high likelihood to monitor words with that are very unique to a class and on the right.",
            "If I have an example of how the final 2D array should look like.",
            "So the next thing is we constructed 23D."
        ],
        [
            "Array of those layers of those two D matrices and its layer corresponds to category.",
            "So let's say that will start searching for visual for visual work occurrences from the same first category, then next thing is we want will do is within Vault layer will detect Maxima that belong that lie only within this category.",
            "So we search a look maximum loan categories.",
            "The next thing will do here is to find the second maximum occurrence regardless of the category with this language.",
            "So finally we will form a ratio of those two of the 1st and the 2nd Max, which is very indicative hired, erases it is is more likely for this pair to be very dominant.",
            "Very unique to this class and we call this resource categorical opponency.",
            "So finally so."
        ],
        [
            "We can convert converted those my maximum points within that layer, interations, and we map the coordinates which are actually correspond to visual word indices.",
            "So the way it's done now to create a code book of pair words is just a store.",
            "The indices of the words we have found.",
            "And with that we do this process for its category.",
            "So we have a fixed amount.",
            "Well, actually.",
            "The number of the code book is disabled by the user.",
            "It depends only with how much performance and what what are you after exactly to your application.",
            "So another into."
        ],
        [
            "Rotation of the ratio would be a radius of this circle.",
            "I borrowed a taxonomy from ideas of internal by Binder to show you that low ratio or actually usually the lowest value in the ratio is usually close one, so ratio having a ratio closed one will be.",
            "We will acquire pairs close to the central node of this taxonomy, which actually will point back out to all species.",
            "And if you are able or you formulate the previous metric system the right way to have high very high ratios, those ratio will be very likely to point.",
            "Today or even less pieces.",
            "So actually those those person would be very unique to the class or very discriminate towards those classes.",
            "And also we have the formulation of the equation which can be found in the paper and what expressed here is that the first maximum is the.",
            "The first maximum over the second maximum has.",
            "Max paration so we use the well.",
            "We use two kinds of."
        ],
        [
            "Action method two kinds of key points, one which is the grid bakes, which is the length of the size of the descriptor is fixed in a fixed radius, another one using the SIFT detector using the field fit driver.",
            "So the information we're using here is the feature itself.",
            "They assign work to it, which is very useful.",
            "This this is the Euclidean distance which is denoted by D. I'd say between the two features and the Sigma Sigma example, they represent the radius of the parties.",
            "An actually this can be acquired by the output of the scale estimate itself or or you can use the initial value, but I afterwards with razor with absolutely remove the initial bias of the scale.",
            "So we have three kinds of measures to.",
            "Three kinds of criteria to measure safety ratings.",
            "The first is the conclusion of the undecan itself.",
            "The second is the relative overlap of the.",
            "Of the two words with this, actually, the Euclidean distance of the absolute the relative Euclidean distance of those pairs, minus their some of their radii over there, some clarity itself, and the Max operation which is very similar to some might remind the hinge loss, penalized or overlapping too much with each other.",
            "And finally, we use this.",
            "We import this ratio.",
            "We introduce this relation to the sigmoid function along with the slope, which is noted by Alpha.",
            "And with time to figure out which is the best way to measure those Co occurrences, so on the right hand side on the top we have a two diagrams with, so the outputs of those sigmoid function the first diagram as enjoy increasing their.",
            "Their slopes are more a step and they offer values.",
            "Here is set to one and on the right one the Alpha value is set to 10.",
            "This the effect which has this is the 2nd.",
            "There's another slope is that words that are further apart are more likely to be paired up and the figure down is a is done is the cross validation results of using a linear SVM.",
            "As you as you vary the Alpha, the Alpha value so they think the decrease of the increases the performance we might have and this is done in the class account Pascal 2011.",
            "So how, how, now?"
        ],
        [
            "Detect the person.",
            "Create a histogram of paired words.",
            "So the first thing, let's say that we have detected features an we have assigned visual words which already pre computed.",
            "So the next thing is to look back in the codebook.",
            "So let's say I look back at the same code at the second entry.",
            "Which will have two words, will show me back to indices, so I'll search those indices within the assigned words I have done in the month.",
            "So for illustration purposes only, I have separated those detected features.",
            "I have signs of features.",
            "The two words I have I'm looking for.",
            "So the next thing is.",
            "I'm under the occurrences of those words, so every row goes there, they won world.",
            "The occurrence of one word and the row and column wise goes the occurrence of the other words of the other word.",
            "So the next thing is to apply.",
            "So once I have created this small matrix, I apply those functions.",
            "The previous functions that I saw you in the previous light to to estimate or to measure the pairwise relationships.",
            "Of these words.",
            "So this so the next thing will do so the red dots PN is symbolized by B and so that the output of the function of one of the three functions.",
            "There are three different tests.",
            "Test an.",
            "We maximize this array along the largest dimension.",
            "So what it remains is the maximum value and the maximum value along this dimension and.",
            "Then the rest of the dimension, the other dimension itself.",
            "So with this actually, if you maximize along once we get the minimum of the other.",
            "So the next thing is what we get from this is that that we have a some kind of.",
            "A bird relationships of the words which is symbolized by the red lines and well, many of you can see it as a nearest neighbor assignment.",
            "So the next thing that we do here is we sum up their best meets their estimates, which is pointed by the Blue Mother.",
            "Sorry by the red lines and the assignment up and accumulate to the original build build.",
            "We started looking for.",
            "So we read the same process for every pair of words to find the core occurrences, detect the.",
            "No worries, relationship and some of them up.",
            "To create a histogram of words."
        ],
        [
            "So the next thing is to compare those words.",
            "Those histograms with a special pyramids by us has been implemented by laws of Nick and the blue.",
            "The blue Line notes, the pyramids, implementation of the Pyramids and the red lines denote the performance.",
            "So the so the average is we have repeated the process 10 times, so the averages are the line in the middle of the colored.",
            "Areas, the colored areas itself so that the vision after 10 iterations and for illustration purposes only, we have sorted the accuracies.",
            "To be more clear to the idea, difference in performance in these graphs, so they learn the classifier, uses a linear SVM which is not very.",
            "Which is not.",
            "Rate is the highest performance for the Special Pyramids, but if you sit down to the right, the average precision I get from the pyramids is 60% and lots of like using the minimum intersection kernel is has raised, has risks 64 so well.",
            "I'm 4% back using a linear SVM and one one thing is which is very.",
            "Will easily notice here is that the key point based approaches can significantly boost it by using the purse.",
            "So it means that those key points are not so useless comparing to a grid.",
            "And so finally we have described the way of selecting a rocking with visual words."
        ],
        [
            "Based on their abilities collectivized.",
            "Will try next to fight to apply it on different feature different scale estimation method.",
            "Different detectors in different descriptors and it will be very interesting to to see if this Sparks coding sparse coding approaches along with Max pooling can boost this performance as well because the whole method is based on hard assignment on the visual words.",
            "And thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello, I'm here.",
                    "label": 0
                },
                {
                    "sent": "This student and this is joint work with my supervisor and Bart.",
                    "label": 0
                },
                {
                    "sent": "I'm so the overview of this.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It will be in the introduction to our method related work.",
                    "label": 1
                },
                {
                    "sent": "The visual structure of pairing experiment results, conclusions and filter work.",
                    "label": 1
                },
                {
                    "sent": "So I'll",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Add with a with an overview of related methods to our work so the most popular, the most well known method is the deformable part model, which is has been proven very useful especially for object detection.",
                    "label": 1
                },
                {
                    "sent": "Next is here article models by Zoom published in APT 2009.",
                    "label": 0
                },
                {
                    "sent": "We say they use four different levels of hierarchy, which starting from very simple features in its time adding up and more complex structure.",
                    "label": 0
                },
                {
                    "sent": "To finalize the learned console.",
                    "label": 0
                },
                {
                    "sent": "So below is another similar approach using 4 levels as well, and you can see the reconstructed models for its level, which they usually.",
                    "label": 0
                },
                {
                    "sent": "It's very.",
                    "label": 0
                },
                {
                    "sent": "It's very commonly found in.",
                    "label": 0
                },
                {
                    "sent": "A starting with wavelets going up to the exactions parts of controls and finally conscious self, and on the right hand side is the method with more close to ours, with the authors here, detect Co occurrences of triplets or any higher order of words and they mapped it back to enough space.",
                    "label": 0
                },
                {
                    "sent": "And finally, using a on the bottom right, finally the authors.",
                    "label": 0
                },
                {
                    "sent": "Here's a monitor.",
                    "label": 0
                },
                {
                    "sent": "The pairwise interactions just conditional random fields starting with simple features as edges.",
                    "label": 1
                },
                {
                    "sent": "So then so all three of these methods have a common thing with the same hidden here, OK, and it's very closely related to a neuro.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Science modeled by which has been published or proposed by.",
                    "label": 0
                },
                {
                    "sent": "Um, by the massacre.",
                    "label": 0
                },
                {
                    "sent": "This group and the starts the first level of hierarchy usually start with simple features which are selective to edge orientations.",
                    "label": 0
                },
                {
                    "sent": "And as we going up into levels of hierarchy, we those feats will become much more complex, such as corners.",
                    "label": 1
                },
                {
                    "sent": "Did junctions another high order conjunctions to find the next levels?",
                    "label": 0
                },
                {
                    "sent": "We were the complexity of the structure increases.",
                    "label": 0
                },
                {
                    "sent": "So what we thought here is that usually the computer vision community.",
                    "label": 0
                },
                {
                    "sent": "Can detect those features easily with a key point detection and some of them with descriptors and actually quantized them.",
                    "label": 0
                },
                {
                    "sent": "Or cluster them using interfacial words and we thought to replace to simplify the problem to a single node.",
                    "label": 1
                },
                {
                    "sent": "And replace the leaves of the nodes with visual words.",
                    "label": 0
                },
                {
                    "sent": "So the next problem is to detect the Co occurrences of visual words, which can be proven.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Useful, there are very discriminate towards classes, so the way we formulate this is we have.",
                    "label": 1
                },
                {
                    "sent": "We already have the prior knowledge of the database, which is actually the distribution of the words of the train set.",
                    "label": 1
                },
                {
                    "sent": "So we can stay awake.",
                    "label": 1
                },
                {
                    "sent": "So if we start with the joint probability we have that given one word WI, WI is has occurred.",
                    "label": 0
                },
                {
                    "sent": "With penalized this word, and as you can see in the blue histograms.",
                    "label": 0
                },
                {
                    "sent": "So this word is set to 0 and we monitor all the occurrences of all the other words.",
                    "label": 0
                },
                {
                    "sent": "So in that way we have a we have a view of probable currencies and we repeat the same process for all the for the rest of the code book.",
                    "label": 1
                },
                {
                    "sent": "To create a 2D array, the next thing to do is that we have the power knowledge with this represented by the red histogram, and this is actually the IDF term of is the inverse document frequency term we have from the database.",
                    "label": 0
                },
                {
                    "sent": "The reason we use that prayer is that this will down wait very frequent words and the user leave those very frequent words occur in all the classes.",
                    "label": 0
                },
                {
                    "sent": "So it is very likely food on weight.",
                    "label": 0
                },
                {
                    "sent": "And we know we will have very like high likelihood to monitor words with that are very unique to a class and on the right.",
                    "label": 0
                },
                {
                    "sent": "If I have an example of how the final 2D array should look like.",
                    "label": 0
                },
                {
                    "sent": "So the next thing is we constructed 23D.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Array of those layers of those two D matrices and its layer corresponds to category.",
                    "label": 0
                },
                {
                    "sent": "So let's say that will start searching for visual for visual work occurrences from the same first category, then next thing is we want will do is within Vault layer will detect Maxima that belong that lie only within this category.",
                    "label": 0
                },
                {
                    "sent": "So we search a look maximum loan categories.",
                    "label": 0
                },
                {
                    "sent": "The next thing will do here is to find the second maximum occurrence regardless of the category with this language.",
                    "label": 0
                },
                {
                    "sent": "So finally we will form a ratio of those two of the 1st and the 2nd Max, which is very indicative hired, erases it is is more likely for this pair to be very dominant.",
                    "label": 0
                },
                {
                    "sent": "Very unique to this class and we call this resource categorical opponency.",
                    "label": 1
                },
                {
                    "sent": "So finally so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can convert converted those my maximum points within that layer, interations, and we map the coordinates which are actually correspond to visual word indices.",
                    "label": 0
                },
                {
                    "sent": "So the way it's done now to create a code book of pair words is just a store.",
                    "label": 1
                },
                {
                    "sent": "The indices of the words we have found.",
                    "label": 0
                },
                {
                    "sent": "And with that we do this process for its category.",
                    "label": 0
                },
                {
                    "sent": "So we have a fixed amount.",
                    "label": 0
                },
                {
                    "sent": "Well, actually.",
                    "label": 0
                },
                {
                    "sent": "The number of the code book is disabled by the user.",
                    "label": 0
                },
                {
                    "sent": "It depends only with how much performance and what what are you after exactly to your application.",
                    "label": 0
                },
                {
                    "sent": "So another into.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rotation of the ratio would be a radius of this circle.",
                    "label": 0
                },
                {
                    "sent": "I borrowed a taxonomy from ideas of internal by Binder to show you that low ratio or actually usually the lowest value in the ratio is usually close one, so ratio having a ratio closed one will be.",
                    "label": 0
                },
                {
                    "sent": "We will acquire pairs close to the central node of this taxonomy, which actually will point back out to all species.",
                    "label": 0
                },
                {
                    "sent": "And if you are able or you formulate the previous metric system the right way to have high very high ratios, those ratio will be very likely to point.",
                    "label": 0
                },
                {
                    "sent": "Today or even less pieces.",
                    "label": 0
                },
                {
                    "sent": "So actually those those person would be very unique to the class or very discriminate towards those classes.",
                    "label": 0
                },
                {
                    "sent": "And also we have the formulation of the equation which can be found in the paper and what expressed here is that the first maximum is the.",
                    "label": 0
                },
                {
                    "sent": "The first maximum over the second maximum has.",
                    "label": 0
                },
                {
                    "sent": "Max paration so we use the well.",
                    "label": 0
                },
                {
                    "sent": "We use two kinds of.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Action method two kinds of key points, one which is the grid bakes, which is the length of the size of the descriptor is fixed in a fixed radius, another one using the SIFT detector using the field fit driver.",
                    "label": 0
                },
                {
                    "sent": "So the information we're using here is the feature itself.",
                    "label": 0
                },
                {
                    "sent": "They assign work to it, which is very useful.",
                    "label": 0
                },
                {
                    "sent": "This this is the Euclidean distance which is denoted by D. I'd say between the two features and the Sigma Sigma example, they represent the radius of the parties.",
                    "label": 0
                },
                {
                    "sent": "An actually this can be acquired by the output of the scale estimate itself or or you can use the initial value, but I afterwards with razor with absolutely remove the initial bias of the scale.",
                    "label": 0
                },
                {
                    "sent": "So we have three kinds of measures to.",
                    "label": 0
                },
                {
                    "sent": "Three kinds of criteria to measure safety ratings.",
                    "label": 0
                },
                {
                    "sent": "The first is the conclusion of the undecan itself.",
                    "label": 0
                },
                {
                    "sent": "The second is the relative overlap of the.",
                    "label": 0
                },
                {
                    "sent": "Of the two words with this, actually, the Euclidean distance of the absolute the relative Euclidean distance of those pairs, minus their some of their radii over there, some clarity itself, and the Max operation which is very similar to some might remind the hinge loss, penalized or overlapping too much with each other.",
                    "label": 0
                },
                {
                    "sent": "And finally, we use this.",
                    "label": 0
                },
                {
                    "sent": "We import this ratio.",
                    "label": 0
                },
                {
                    "sent": "We introduce this relation to the sigmoid function along with the slope, which is noted by Alpha.",
                    "label": 0
                },
                {
                    "sent": "And with time to figure out which is the best way to measure those Co occurrences, so on the right hand side on the top we have a two diagrams with, so the outputs of those sigmoid function the first diagram as enjoy increasing their.",
                    "label": 0
                },
                {
                    "sent": "Their slopes are more a step and they offer values.",
                    "label": 0
                },
                {
                    "sent": "Here is set to one and on the right one the Alpha value is set to 10.",
                    "label": 0
                },
                {
                    "sent": "This the effect which has this is the 2nd.",
                    "label": 0
                },
                {
                    "sent": "There's another slope is that words that are further apart are more likely to be paired up and the figure down is a is done is the cross validation results of using a linear SVM.",
                    "label": 0
                },
                {
                    "sent": "As you as you vary the Alpha, the Alpha value so they think the decrease of the increases the performance we might have and this is done in the class account Pascal 2011.",
                    "label": 0
                },
                {
                    "sent": "So how, how, now?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Detect the person.",
                    "label": 0
                },
                {
                    "sent": "Create a histogram of paired words.",
                    "label": 0
                },
                {
                    "sent": "So the first thing, let's say that we have detected features an we have assigned visual words which already pre computed.",
                    "label": 0
                },
                {
                    "sent": "So the next thing is to look back in the codebook.",
                    "label": 0
                },
                {
                    "sent": "So let's say I look back at the same code at the second entry.",
                    "label": 0
                },
                {
                    "sent": "Which will have two words, will show me back to indices, so I'll search those indices within the assigned words I have done in the month.",
                    "label": 0
                },
                {
                    "sent": "So for illustration purposes only, I have separated those detected features.",
                    "label": 0
                },
                {
                    "sent": "I have signs of features.",
                    "label": 0
                },
                {
                    "sent": "The two words I have I'm looking for.",
                    "label": 0
                },
                {
                    "sent": "So the next thing is.",
                    "label": 0
                },
                {
                    "sent": "I'm under the occurrences of those words, so every row goes there, they won world.",
                    "label": 0
                },
                {
                    "sent": "The occurrence of one word and the row and column wise goes the occurrence of the other words of the other word.",
                    "label": 0
                },
                {
                    "sent": "So the next thing is to apply.",
                    "label": 0
                },
                {
                    "sent": "So once I have created this small matrix, I apply those functions.",
                    "label": 0
                },
                {
                    "sent": "The previous functions that I saw you in the previous light to to estimate or to measure the pairwise relationships.",
                    "label": 0
                },
                {
                    "sent": "Of these words.",
                    "label": 0
                },
                {
                    "sent": "So this so the next thing will do so the red dots PN is symbolized by B and so that the output of the function of one of the three functions.",
                    "label": 0
                },
                {
                    "sent": "There are three different tests.",
                    "label": 0
                },
                {
                    "sent": "Test an.",
                    "label": 0
                },
                {
                    "sent": "We maximize this array along the largest dimension.",
                    "label": 0
                },
                {
                    "sent": "So what it remains is the maximum value and the maximum value along this dimension and.",
                    "label": 0
                },
                {
                    "sent": "Then the rest of the dimension, the other dimension itself.",
                    "label": 0
                },
                {
                    "sent": "So with this actually, if you maximize along once we get the minimum of the other.",
                    "label": 0
                },
                {
                    "sent": "So the next thing is what we get from this is that that we have a some kind of.",
                    "label": 0
                },
                {
                    "sent": "A bird relationships of the words which is symbolized by the red lines and well, many of you can see it as a nearest neighbor assignment.",
                    "label": 0
                },
                {
                    "sent": "So the next thing that we do here is we sum up their best meets their estimates, which is pointed by the Blue Mother.",
                    "label": 0
                },
                {
                    "sent": "Sorry by the red lines and the assignment up and accumulate to the original build build.",
                    "label": 0
                },
                {
                    "sent": "We started looking for.",
                    "label": 0
                },
                {
                    "sent": "So we read the same process for every pair of words to find the core occurrences, detect the.",
                    "label": 0
                },
                {
                    "sent": "No worries, relationship and some of them up.",
                    "label": 0
                },
                {
                    "sent": "To create a histogram of words.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the next thing is to compare those words.",
                    "label": 0
                },
                {
                    "sent": "Those histograms with a special pyramids by us has been implemented by laws of Nick and the blue.",
                    "label": 0
                },
                {
                    "sent": "The blue Line notes, the pyramids, implementation of the Pyramids and the red lines denote the performance.",
                    "label": 0
                },
                {
                    "sent": "So the so the average is we have repeated the process 10 times, so the averages are the line in the middle of the colored.",
                    "label": 0
                },
                {
                    "sent": "Areas, the colored areas itself so that the vision after 10 iterations and for illustration purposes only, we have sorted the accuracies.",
                    "label": 0
                },
                {
                    "sent": "To be more clear to the idea, difference in performance in these graphs, so they learn the classifier, uses a linear SVM which is not very.",
                    "label": 0
                },
                {
                    "sent": "Which is not.",
                    "label": 0
                },
                {
                    "sent": "Rate is the highest performance for the Special Pyramids, but if you sit down to the right, the average precision I get from the pyramids is 60% and lots of like using the minimum intersection kernel is has raised, has risks 64 so well.",
                    "label": 0
                },
                {
                    "sent": "I'm 4% back using a linear SVM and one one thing is which is very.",
                    "label": 0
                },
                {
                    "sent": "Will easily notice here is that the key point based approaches can significantly boost it by using the purse.",
                    "label": 0
                },
                {
                    "sent": "So it means that those key points are not so useless comparing to a grid.",
                    "label": 0
                },
                {
                    "sent": "And so finally we have described the way of selecting a rocking with visual words.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Based on their abilities collectivized.",
                    "label": 0
                },
                {
                    "sent": "Will try next to fight to apply it on different feature different scale estimation method.",
                    "label": 0
                },
                {
                    "sent": "Different detectors in different descriptors and it will be very interesting to to see if this Sparks coding sparse coding approaches along with Max pooling can boost this performance as well because the whole method is based on hard assignment on the visual words.",
                    "label": 0
                },
                {
                    "sent": "And thank you.",
                    "label": 0
                }
            ]
        }
    }
}