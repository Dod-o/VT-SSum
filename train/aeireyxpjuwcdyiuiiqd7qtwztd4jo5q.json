{
    "id": "aeireyxpjuwcdyiuiiqd7qtwztd4jo5q",
    "title": "Selecting the state representation in reinforcement Learning",
    "info": {
        "author": [
            "Odalric-Ambrym Maillard, INRIA Lille - Nord Europe"
        ],
        "published": "Jan. 25, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Reinforcement Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_maillard_reinforcement/",
    "segmentation": [
        [
            "So hello, so first I want to thank the organizers organizer for setting this workshops and want also to point out that this is John talk with dining table and minnows.",
            "So here in this work we want to do.",
            "Two questions, the notion of state in Markov decision process."
        ],
        [
            "So the so it comes from a practical question so.",
            "So we will first wondering when you are when you're walking Andy Pijani.",
            "You are given a state and Oh yeah, I can go of course so yeah.",
            "Well first morning setting so you are given a state and then based on that and we want an action to try to learn the policy.",
            "Point is that in often in practice you don't really have a state, but you just have observations an you have to do fancy stuff to create emotional state.",
            "So this means that you may have different notion of States and may alot of them, maybe just improper emotional state, meaning that it does not need to appropriate to MDP, meaning that you don't have a Markov decision process with this national state so."
        ],
        [
            "Here.",
            "So.",
            "OK, which is what is here.",
            "And so the question is, what is what can we do an this work will?"
        ],
        [
            "Assume that we start with the notion of state representation, so means that we have a bunch of functions that will map the history the past history.",
            "So history, observation, action and we both observation state can be arbitrary.",
            "And and so you have a bunch of such functions that gives you a notion of candidate state.",
            "I know you will work with all these things and try."
        ],
        [
            "To compete against the.",
            "The best the best policies were based on there, so just to be more precise, so under is given a set.",
            "A finite set of search for instructions, and we assume that at least one of these functions leads to a proper MVP from exactly this.",
            "This process is a Markov decision process.",
            "We don't put any assumption on the other ones, so it can be arbitrary, bad functional condition.",
            "So we assume also that this this true MVP is weekly communicating and OK we have national diameter.",
            "So OK. Of course, if we know the antics of the best of the two and GP.",
            "Function we have stored on MVP and we can solve it and we're happy.",
            "So the question is, what if we don't know this index?",
            "Can we still compute?",
            "Sorry, can we still compute the like and we still compete with the optimal policy for the correct model or for the best of the correct model?"
        ],
        [
            "So we can have many motivations just to add some motivation.",
            "For example, you can consider that.",
            "You are expensive observation, which is a data stream or video stream and you have your functions.",
            "How higher harder feature extraction.",
            "So you have.",
            "For example, you can feature that tells you in the video.",
            "While here I recognize that there is some person or somebody is moving his hand so very high level stuff and you will assume that based on these features you have some Markov.",
            "So high demand, lack of market dynamics.",
            "What?"
        ],
        [
            "They handle we can consider also assumptions like if you have a key or the MVP not one or the NTP we but you don't know key.",
            "Just know rough account you want to compete with this with this mode key and not not using just the bigger key.",
            "Older because this leads to an exponential number of states.",
            "If you want to 40 and fold it into one of the NDP."
        ],
        [
            "OK, you have a weekend of so."
        ],
        [
            "We can also have other things so OK.",
            "Here is 1 solution how to actually go from this features to states or OK so we consider that.",
            "So the question is for you have to repeat.",
            "So how do we go from this national feature to state?",
            "So we assume that you are given these features and this has functions that map the history of past observation action 21 notion of state.",
            "So each features gives you one notion of state when one state space.",
            "So each one suspect for each function so it's given so you don't have now to build such function, so I will come back.",
            "So this is part of the open questions here OK?"
        ],
        [
            "So here I just simple solution.",
            "So first our regular criterion is an average regret battalion and OK, we want to compute with the best policy of the best model or if."
        ],
        [
            "Her baseline, so we will use another integration, so I don't know how I got some which is using it as a baseline that you share algorithms that works for an MVP where when you already have this national state, so we stand on MVP.",
            "So it's open Bong Switch algorithm.",
            "So by Jackson Highland picture where and when I got there.",
            "So it's based off of a per confidence bounds.",
            "So it's optimistic, so do not sell.",
            "The idea is based on the observation of rewards and traditions.",
            "You compute an optimistic model of transitions and working Mystic model of rewards and then you compute the optimistic policy and you run it for some time.",
            "So the nice property of this algorithm is that we have one regret and edges and if you run this algorithm photo too many consecutive steps, it has to be consecutive.",
            "You have a regret bound of this order and the scaling basically is.",
            "Well that I have G which is so it makes that important purpose.",
            "Features of MVP which is a diameter.",
            "So the minimum expecting.",
            "Length of time you have to to reach one state forming user one OK and the diameter does not need to be known as legalism, which is important which is very important here for what?"
        ],
        [
            "OK.",
            "Here is an idea as agreed.",
            "So of course, since we don't have any assumptions on the Civil War models.",
            "So we will have to to explore all models and do that musically for all all all time.",
            "So we will do an algorithm that works in phases of different stage and in each stage stage is as increasing length.",
            "So we've just double click and you have exploration and exploitation.",
            "So in this profession it's very easy.",
            "So expression is.",
            "The producer, so most of the time we do exploitation and exploration is just too small, so in exploration it's easy.",
            "You will just consider each model.",
            "You will you will.",
            "You will explore the model for exactly the same amount of time.",
            "For each we would just split this step into Jaimini Windows and you do that then."
        ],
        [
            "Computes the.",
            "I'm pretty cool means.",
            "Easy.",
            "And then based on such you will do some exploration.",
            "So the idea is that.",
            "If if we have, so if if we're wrong model, what will happen is that now if you if you so things happen when you explore this model as we want that we get maybe high, it may be surprising, but since you have higher words, it's not a problem.",
            "Who are happy?",
            "Because your words are hard.",
            "Or it may be the case that the rewards just go too low.",
            "And what I mean by by law, which means that it goes below the lower bound that can we.",
            "Richard, based on the on the bonds that we know for you said.",
            "So is she was already too low.",
            "We just can see that it's not appropriate model so."
        ],
        [
            "His idea is that you recompute based on these expressions, step some candidate.",
            "From coordinator Modera an you will you run it as long as empirical we won't get bigger than such lower bound, so it's kind of person."
        ],
        [
            "Stick approach, so here if I consider 11 bad mother so at some so we was we at some point go some threshold."
        ],
        [
            "So we just discard it."
        ],
        [
            "Do the same at some point.",
            "Will we absolutely one good mother and to provide you with a good model is that with high probability by provincial shared by how pretty you will pass all the tests for all time length.",
            "So it means that after we found one good model we will just run it for.",
            "OK, and now we do that.",
            "Sorry, now you will just iterate that because we have to explore and exploit with time and so we can get a regret."
        ],
        [
            "OK, so.",
            "Yeah, so it's important that each time we when I am out of town.",
            "So here it's important that each each time you run the user algorithm, it has to be bench.",
            "You have to run it for consecutive minutes steps, otherwise it doesn't work.",
            "OK and OK."
        ],
        [
            "It's just technical indicators.",
            "So the intuition is rhythm, that's what I explained, so we don't need really to test whether we are in a good model or not, because we have the we want.",
            "So based on the reward system so well that you get.",
            "And if we wanted to load just can discount this model, and if good we're happy."
        ],
        [
            "OK, here's the result, so it's four.",
            "So just to remind setting have a single window, so no reset and we have strict in reception on one balance.",
            "So of course, since we have no exceptional models, we can not.",
            "We cannot do miracles.",
            "Best here we can have something 5 minutes for me perfect.",
            "OK, so here's one.",
            "So here we see something so fast, so cheesy.",
            "Timer, memories.",
            "And then we have a regret that scales with teacher to serve.",
            "So of course it's worth it.",
            "This qualities that we're used to and the point is that here these two shop comes from the passage.",
            "We have no assumption of the role models, so of course, since we.",
            "While we vote in assumption, we cannot really unclear whether we can do better, but probably not so.",
            "But if there are some assumptions.",
            "On the on the wall models on those and others may be possible to have something big better.",
            "So next part of this bar is this J, which is a number of models.",
            "So here you see that square root of number of models.",
            "And again, this is the reason for this.",
            "Credit is that we don't put assumption on.",
            "I mean on the information shared by models.",
            "So if we learn something in model, we cannot transfer it to other models.",
            "And so since we don't have any kind of that, we cannot better bonds and square root or Jay.",
            "If we were able, if we are.",
            "If we Altima Sumption like the models are embedded orphan exactly so if we can share information then you will possibly be able to reduce is too large.",
            "OK so but these are just technically called the most important thing here is this thing consisting.",
            "So here you see that this is a constant term and there is this function F key so FT. Comes from the fact that you know this regret bound for you, Cheryl.",
            "So make that piece of diameter of the of the MVP.",
            "And of course we don't know the diameter.",
            "And since we do not hit an offer, no, we don't know.",
            "Also the models.",
            "It's very tricky to estimate.",
            "So we use this function F. As a guess, so we are two things as a.",
            "Since we don't know the limiter Heather, we tried to estimate it online or we use the Porsche return, which is guessing with functions that is increasing function of time.",
            "So what happens that if FT is too small, so lesson G, the bonds that we use.",
            "Instagram is not a true bond becauses diameter is is bigger.",
            "So it means that we have we cannot control the regret for the.",
            "For the ones, for the corresponding ones.",
            "And this means that we need to wait that T is sufficient enough and we see this constantly happens.",
            "OK, and so cheese vision loss.",
            "So if you take F equals lucky, you have two 2D.",
            "So it's OK with time because it's constant, but still it's two to the beach, can be big so you know.",
            "OK, one nice thing is that you can somehow fix it.",
            "Using FT, which is reporting your monkey and you get to you get.",
            "A dependency with time, which is a bit worse, but you will get something which point your mouse.",
            "OK, so the diameter.",
            "So here's this nasty temps come from the fact that we don't know the diameter of 20P.",
            "And of course it will be very difficult in this situation since we don't have well.",
            "If you have an improper NDP.",
            "What version of diameter?",
            "So it's tricky, twisty measure diameter here."
        ],
        [
            "So.",
            "The two things that I want to point for the last two minutes is that first asking matching the diameter in MVP so.",
            "Just for one MVP's, already not clear with how to do that online inefficient way, so I ask you the question how to do that?",
            "And the second point is that here in this setting we heavily rely on the fact that there exists at least one function that leads you to prepare and GP.",
            "But it may be the case that it was just no function of this case.",
            "And so the question is how to relax a notion of MDP?",
            "Because here?",
            "So here's the result is really unsmooth with respect to that.",
            "If the function if.",
            "Is the model.",
            "So if you very normal attrition DP, everything collapse because we don't have a regret bound for an approximate MVP.",
            "So we would like to develop sources feature work, how to develop models of approximate for approximately peas in the sense.",
            "Over information share."
        ],
        [
            "Go figure.",
            "And just.",
            "Thank you.",
            "OK, so the question is why do I get the square root of J and not log G?",
            "So the answer is that here we have no information across the models, so I don't.",
            "I cannot transfer information from one model to another one.",
            "And so we cannot, and also so you know, that's why blogs follow up on your next part setting you, will.",
            "You will observe that if you compete for reverting answered.",
            "So here we don't do that because we want to target the absolute favorite.",
            "And so because we don't have any information across the models, we cannot really do not.",
            "From one observation we cannot transfer.",
            "In front of the.",
            "We cannot transfer the knowledge on the on the camera and the reward of the corresponding models to other models because it was just no information."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So hello, so first I want to thank the organizers organizer for setting this workshops and want also to point out that this is John talk with dining table and minnows.",
                    "label": 0
                },
                {
                    "sent": "So here in this work we want to do.",
                    "label": 0
                },
                {
                    "sent": "Two questions, the notion of state in Markov decision process.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the so it comes from a practical question so.",
                    "label": 1
                },
                {
                    "sent": "So we will first wondering when you are when you're walking Andy Pijani.",
                    "label": 0
                },
                {
                    "sent": "You are given a state and Oh yeah, I can go of course so yeah.",
                    "label": 0
                },
                {
                    "sent": "Well first morning setting so you are given a state and then based on that and we want an action to try to learn the policy.",
                    "label": 0
                },
                {
                    "sent": "Point is that in often in practice you don't really have a state, but you just have observations an you have to do fancy stuff to create emotional state.",
                    "label": 0
                },
                {
                    "sent": "So this means that you may have different notion of States and may alot of them, maybe just improper emotional state, meaning that it does not need to appropriate to MDP, meaning that you don't have a Markov decision process with this national state so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, which is what is here.",
                    "label": 0
                },
                {
                    "sent": "And so the question is, what is what can we do an this work will?",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Assume that we start with the notion of state representation, so means that we have a bunch of functions that will map the history the past history.",
                    "label": 0
                },
                {
                    "sent": "So history, observation, action and we both observation state can be arbitrary.",
                    "label": 0
                },
                {
                    "sent": "And and so you have a bunch of such functions that gives you a notion of candidate state.",
                    "label": 0
                },
                {
                    "sent": "I know you will work with all these things and try.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To compete against the.",
                    "label": 0
                },
                {
                    "sent": "The best the best policies were based on there, so just to be more precise, so under is given a set.",
                    "label": 1
                },
                {
                    "sent": "A finite set of search for instructions, and we assume that at least one of these functions leads to a proper MVP from exactly this.",
                    "label": 0
                },
                {
                    "sent": "This process is a Markov decision process.",
                    "label": 1
                },
                {
                    "sent": "We don't put any assumption on the other ones, so it can be arbitrary, bad functional condition.",
                    "label": 0
                },
                {
                    "sent": "So we assume also that this this true MVP is weekly communicating and OK we have national diameter.",
                    "label": 1
                },
                {
                    "sent": "So OK. Of course, if we know the antics of the best of the two and GP.",
                    "label": 0
                },
                {
                    "sent": "Function we have stored on MVP and we can solve it and we're happy.",
                    "label": 0
                },
                {
                    "sent": "So the question is, what if we don't know this index?",
                    "label": 0
                },
                {
                    "sent": "Can we still compute?",
                    "label": 0
                },
                {
                    "sent": "Sorry, can we still compute the like and we still compete with the optimal policy for the correct model or for the best of the correct model?",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we can have many motivations just to add some motivation.",
                    "label": 0
                },
                {
                    "sent": "For example, you can consider that.",
                    "label": 0
                },
                {
                    "sent": "You are expensive observation, which is a data stream or video stream and you have your functions.",
                    "label": 1
                },
                {
                    "sent": "How higher harder feature extraction.",
                    "label": 0
                },
                {
                    "sent": "So you have.",
                    "label": 0
                },
                {
                    "sent": "For example, you can feature that tells you in the video.",
                    "label": 0
                },
                {
                    "sent": "While here I recognize that there is some person or somebody is moving his hand so very high level stuff and you will assume that based on these features you have some Markov.",
                    "label": 0
                },
                {
                    "sent": "So high demand, lack of market dynamics.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They handle we can consider also assumptions like if you have a key or the MVP not one or the NTP we but you don't know key.",
                    "label": 0
                },
                {
                    "sent": "Just know rough account you want to compete with this with this mode key and not not using just the bigger key.",
                    "label": 1
                },
                {
                    "sent": "Older because this leads to an exponential number of states.",
                    "label": 0
                },
                {
                    "sent": "If you want to 40 and fold it into one of the NDP.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, you have a weekend of so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can also have other things so OK.",
                    "label": 0
                },
                {
                    "sent": "Here is 1 solution how to actually go from this features to states or OK so we consider that.",
                    "label": 0
                },
                {
                    "sent": "So the question is for you have to repeat.",
                    "label": 0
                },
                {
                    "sent": "So how do we go from this national feature to state?",
                    "label": 0
                },
                {
                    "sent": "So we assume that you are given these features and this has functions that map the history of past observation action 21 notion of state.",
                    "label": 0
                },
                {
                    "sent": "So each features gives you one notion of state when one state space.",
                    "label": 0
                },
                {
                    "sent": "So each one suspect for each function so it's given so you don't have now to build such function, so I will come back.",
                    "label": 0
                },
                {
                    "sent": "So this is part of the open questions here OK?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here I just simple solution.",
                    "label": 0
                },
                {
                    "sent": "So first our regular criterion is an average regret battalion and OK, we want to compute with the best policy of the best model or if.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Her baseline, so we will use another integration, so I don't know how I got some which is using it as a baseline that you share algorithms that works for an MVP where when you already have this national state, so we stand on MVP.",
                    "label": 0
                },
                {
                    "sent": "So it's open Bong Switch algorithm.",
                    "label": 0
                },
                {
                    "sent": "So by Jackson Highland picture where and when I got there.",
                    "label": 0
                },
                {
                    "sent": "So it's based off of a per confidence bounds.",
                    "label": 0
                },
                {
                    "sent": "So it's optimistic, so do not sell.",
                    "label": 0
                },
                {
                    "sent": "The idea is based on the observation of rewards and traditions.",
                    "label": 1
                },
                {
                    "sent": "You compute an optimistic model of transitions and working Mystic model of rewards and then you compute the optimistic policy and you run it for some time.",
                    "label": 0
                },
                {
                    "sent": "So the nice property of this algorithm is that we have one regret and edges and if you run this algorithm photo too many consecutive steps, it has to be consecutive.",
                    "label": 0
                },
                {
                    "sent": "You have a regret bound of this order and the scaling basically is.",
                    "label": 0
                },
                {
                    "sent": "Well that I have G which is so it makes that important purpose.",
                    "label": 0
                },
                {
                    "sent": "Features of MVP which is a diameter.",
                    "label": 0
                },
                {
                    "sent": "So the minimum expecting.",
                    "label": 0
                },
                {
                    "sent": "Length of time you have to to reach one state forming user one OK and the diameter does not need to be known as legalism, which is important which is very important here for what?",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Here is an idea as agreed.",
                    "label": 0
                },
                {
                    "sent": "So of course, since we don't have any assumptions on the Civil War models.",
                    "label": 0
                },
                {
                    "sent": "So we will have to to explore all models and do that musically for all all all time.",
                    "label": 0
                },
                {
                    "sent": "So we will do an algorithm that works in phases of different stage and in each stage stage is as increasing length.",
                    "label": 0
                },
                {
                    "sent": "So we've just double click and you have exploration and exploitation.",
                    "label": 0
                },
                {
                    "sent": "So in this profession it's very easy.",
                    "label": 0
                },
                {
                    "sent": "So expression is.",
                    "label": 0
                },
                {
                    "sent": "The producer, so most of the time we do exploitation and exploration is just too small, so in exploration it's easy.",
                    "label": 0
                },
                {
                    "sent": "You will just consider each model.",
                    "label": 0
                },
                {
                    "sent": "You will you will.",
                    "label": 0
                },
                {
                    "sent": "You will explore the model for exactly the same amount of time.",
                    "label": 0
                },
                {
                    "sent": "For each we would just split this step into Jaimini Windows and you do that then.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Computes the.",
                    "label": 0
                },
                {
                    "sent": "I'm pretty cool means.",
                    "label": 0
                },
                {
                    "sent": "Easy.",
                    "label": 0
                },
                {
                    "sent": "And then based on such you will do some exploration.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that.",
                    "label": 0
                },
                {
                    "sent": "If if we have, so if if we're wrong model, what will happen is that now if you if you so things happen when you explore this model as we want that we get maybe high, it may be surprising, but since you have higher words, it's not a problem.",
                    "label": 0
                },
                {
                    "sent": "Who are happy?",
                    "label": 0
                },
                {
                    "sent": "Because your words are hard.",
                    "label": 0
                },
                {
                    "sent": "Or it may be the case that the rewards just go too low.",
                    "label": 0
                },
                {
                    "sent": "And what I mean by by law, which means that it goes below the lower bound that can we.",
                    "label": 0
                },
                {
                    "sent": "Richard, based on the on the bonds that we know for you said.",
                    "label": 0
                },
                {
                    "sent": "So is she was already too low.",
                    "label": 0
                },
                {
                    "sent": "We just can see that it's not appropriate model so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "His idea is that you recompute based on these expressions, step some candidate.",
                    "label": 0
                },
                {
                    "sent": "From coordinator Modera an you will you run it as long as empirical we won't get bigger than such lower bound, so it's kind of person.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stick approach, so here if I consider 11 bad mother so at some so we was we at some point go some threshold.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we just discard it.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do the same at some point.",
                    "label": 0
                },
                {
                    "sent": "Will we absolutely one good mother and to provide you with a good model is that with high probability by provincial shared by how pretty you will pass all the tests for all time length.",
                    "label": 0
                },
                {
                    "sent": "So it means that after we found one good model we will just run it for.",
                    "label": 0
                },
                {
                    "sent": "OK, and now we do that.",
                    "label": 0
                },
                {
                    "sent": "Sorry, now you will just iterate that because we have to explore and exploit with time and so we can get a regret.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's important that each time we when I am out of town.",
                    "label": 0
                },
                {
                    "sent": "So here it's important that each each time you run the user algorithm, it has to be bench.",
                    "label": 0
                },
                {
                    "sent": "You have to run it for consecutive minutes steps, otherwise it doesn't work.",
                    "label": 0
                },
                {
                    "sent": "OK and OK.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's just technical indicators.",
                    "label": 0
                },
                {
                    "sent": "So the intuition is rhythm, that's what I explained, so we don't need really to test whether we are in a good model or not, because we have the we want.",
                    "label": 0
                },
                {
                    "sent": "So based on the reward system so well that you get.",
                    "label": 0
                },
                {
                    "sent": "And if we wanted to load just can discount this model, and if good we're happy.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, here's the result, so it's four.",
                    "label": 0
                },
                {
                    "sent": "So just to remind setting have a single window, so no reset and we have strict in reception on one balance.",
                    "label": 0
                },
                {
                    "sent": "So of course, since we have no exceptional models, we can not.",
                    "label": 0
                },
                {
                    "sent": "We cannot do miracles.",
                    "label": 0
                },
                {
                    "sent": "Best here we can have something 5 minutes for me perfect.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's one.",
                    "label": 0
                },
                {
                    "sent": "So here we see something so fast, so cheesy.",
                    "label": 0
                },
                {
                    "sent": "Timer, memories.",
                    "label": 0
                },
                {
                    "sent": "And then we have a regret that scales with teacher to serve.",
                    "label": 0
                },
                {
                    "sent": "So of course it's worth it.",
                    "label": 0
                },
                {
                    "sent": "This qualities that we're used to and the point is that here these two shop comes from the passage.",
                    "label": 0
                },
                {
                    "sent": "We have no assumption of the role models, so of course, since we.",
                    "label": 1
                },
                {
                    "sent": "While we vote in assumption, we cannot really unclear whether we can do better, but probably not so.",
                    "label": 0
                },
                {
                    "sent": "But if there are some assumptions.",
                    "label": 0
                },
                {
                    "sent": "On the on the wall models on those and others may be possible to have something big better.",
                    "label": 0
                },
                {
                    "sent": "So next part of this bar is this J, which is a number of models.",
                    "label": 0
                },
                {
                    "sent": "So here you see that square root of number of models.",
                    "label": 0
                },
                {
                    "sent": "And again, this is the reason for this.",
                    "label": 1
                },
                {
                    "sent": "Credit is that we don't put assumption on.",
                    "label": 0
                },
                {
                    "sent": "I mean on the information shared by models.",
                    "label": 0
                },
                {
                    "sent": "So if we learn something in model, we cannot transfer it to other models.",
                    "label": 0
                },
                {
                    "sent": "And so since we don't have any kind of that, we cannot better bonds and square root or Jay.",
                    "label": 0
                },
                {
                    "sent": "If we were able, if we are.",
                    "label": 0
                },
                {
                    "sent": "If we Altima Sumption like the models are embedded orphan exactly so if we can share information then you will possibly be able to reduce is too large.",
                    "label": 0
                },
                {
                    "sent": "OK so but these are just technically called the most important thing here is this thing consisting.",
                    "label": 0
                },
                {
                    "sent": "So here you see that this is a constant term and there is this function F key so FT. Comes from the fact that you know this regret bound for you, Cheryl.",
                    "label": 0
                },
                {
                    "sent": "So make that piece of diameter of the of the MVP.",
                    "label": 0
                },
                {
                    "sent": "And of course we don't know the diameter.",
                    "label": 0
                },
                {
                    "sent": "And since we do not hit an offer, no, we don't know.",
                    "label": 0
                },
                {
                    "sent": "Also the models.",
                    "label": 1
                },
                {
                    "sent": "It's very tricky to estimate.",
                    "label": 0
                },
                {
                    "sent": "So we use this function F. As a guess, so we are two things as a.",
                    "label": 0
                },
                {
                    "sent": "Since we don't know the limiter Heather, we tried to estimate it online or we use the Porsche return, which is guessing with functions that is increasing function of time.",
                    "label": 0
                },
                {
                    "sent": "So what happens that if FT is too small, so lesson G, the bonds that we use.",
                    "label": 1
                },
                {
                    "sent": "Instagram is not a true bond becauses diameter is is bigger.",
                    "label": 0
                },
                {
                    "sent": "So it means that we have we cannot control the regret for the.",
                    "label": 0
                },
                {
                    "sent": "For the ones, for the corresponding ones.",
                    "label": 0
                },
                {
                    "sent": "And this means that we need to wait that T is sufficient enough and we see this constantly happens.",
                    "label": 0
                },
                {
                    "sent": "OK, and so cheese vision loss.",
                    "label": 0
                },
                {
                    "sent": "So if you take F equals lucky, you have two 2D.",
                    "label": 1
                },
                {
                    "sent": "So it's OK with time because it's constant, but still it's two to the beach, can be big so you know.",
                    "label": 0
                },
                {
                    "sent": "OK, one nice thing is that you can somehow fix it.",
                    "label": 0
                },
                {
                    "sent": "Using FT, which is reporting your monkey and you get to you get.",
                    "label": 0
                },
                {
                    "sent": "A dependency with time, which is a bit worse, but you will get something which point your mouse.",
                    "label": 0
                },
                {
                    "sent": "OK, so the diameter.",
                    "label": 0
                },
                {
                    "sent": "So here's this nasty temps come from the fact that we don't know the diameter of 20P.",
                    "label": 0
                },
                {
                    "sent": "And of course it will be very difficult in this situation since we don't have well.",
                    "label": 0
                },
                {
                    "sent": "If you have an improper NDP.",
                    "label": 0
                },
                {
                    "sent": "What version of diameter?",
                    "label": 0
                },
                {
                    "sent": "So it's tricky, twisty measure diameter here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The two things that I want to point for the last two minutes is that first asking matching the diameter in MVP so.",
                    "label": 0
                },
                {
                    "sent": "Just for one MVP's, already not clear with how to do that online inefficient way, so I ask you the question how to do that?",
                    "label": 0
                },
                {
                    "sent": "And the second point is that here in this setting we heavily rely on the fact that there exists at least one function that leads you to prepare and GP.",
                    "label": 0
                },
                {
                    "sent": "But it may be the case that it was just no function of this case.",
                    "label": 0
                },
                {
                    "sent": "And so the question is how to relax a notion of MDP?",
                    "label": 0
                },
                {
                    "sent": "Because here?",
                    "label": 0
                },
                {
                    "sent": "So here's the result is really unsmooth with respect to that.",
                    "label": 0
                },
                {
                    "sent": "If the function if.",
                    "label": 0
                },
                {
                    "sent": "Is the model.",
                    "label": 0
                },
                {
                    "sent": "So if you very normal attrition DP, everything collapse because we don't have a regret bound for an approximate MVP.",
                    "label": 0
                },
                {
                    "sent": "So we would like to develop sources feature work, how to develop models of approximate for approximately peas in the sense.",
                    "label": 0
                },
                {
                    "sent": "Over information share.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go figure.",
                    "label": 0
                },
                {
                    "sent": "And just.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, so the question is why do I get the square root of J and not log G?",
                    "label": 0
                },
                {
                    "sent": "So the answer is that here we have no information across the models, so I don't.",
                    "label": 0
                },
                {
                    "sent": "I cannot transfer information from one model to another one.",
                    "label": 0
                },
                {
                    "sent": "And so we cannot, and also so you know, that's why blogs follow up on your next part setting you, will.",
                    "label": 0
                },
                {
                    "sent": "You will observe that if you compete for reverting answered.",
                    "label": 0
                },
                {
                    "sent": "So here we don't do that because we want to target the absolute favorite.",
                    "label": 0
                },
                {
                    "sent": "And so because we don't have any information across the models, we cannot really do not.",
                    "label": 0
                },
                {
                    "sent": "From one observation we cannot transfer.",
                    "label": 0
                },
                {
                    "sent": "In front of the.",
                    "label": 0
                },
                {
                    "sent": "We cannot transfer the knowledge on the on the camera and the reward of the corresponding models to other models because it was just no information.",
                    "label": 0
                }
            ]
        }
    }
}