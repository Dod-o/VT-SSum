{
    "id": "kaburlvtjamvxnp45le3rabg75dol23j",
    "title": "Planning Problems for Social Robots",
    "info": {
        "author": [
            "Gian Diego Tipaldi, Department of Computer Science, University of Freiburg"
        ],
        "published": "July 21, 2011",
        "recorded": "June 2011",
        "category": [
            "Top->Computer Science->Robotics"
        ]
    },
    "url": "http://videolectures.net/icaps2011_tipaldi_robots/",
    "segmentation": [
        [
            "So thank you for the introduction, I'm done.",
            "This is joint work with Cai Olivarez from the Social Robotics Lab at the University of Freiburg.",
            "They all talk is about I'm going to present 2 problems that I think are interesting for planning with."
        ],
        [
            "Robot, so what's the?",
            "What's the meaning of social robot?",
            "So this social robotics.",
            "There are several definitions robotics, but we are interested in is to have robots that are socially compatible.",
            "The meaning is that robots that are able to plan and act and reason in an environment filled by humans and they are able to blend into the human activities.",
            "So the first thing that we want to understand is how can we model human activities.",
            "How can we reason about human activities learning them?",
            "And that's the first part of this talk.",
            "I will just briefly go around and explain what's our model to reason about activities.",
            "And in this particular case, active are interested in is actually the presence of a person in a certain place in certain place in the environment.",
            "And then we represent the first problem which we call maximum encounter probability planning and the idea is that the robot is somewhere in the world and needs to find someone.",
            "And the second problem is that what we call minima.",
            "Minimal hindrance coverage.",
            "The robot is to perform a task in environment and as to avoid people because they may be annoyed by him.",
            "So first."
        ],
        [
            "Thing is, we want to learn activity pattern, so activity patterns happen in space and time.",
            "So you want to find the model that allows us to actually answer questions like how probable is that this activity actually really happens now at this part of the environment and this specific time?",
            "What actually what I have to wait?",
            "How long do I have to wait as long as certain activity happened?",
            "And also if I'm moving, which is the interesting part for this talk?",
            "So if I'm planning a path around the environment?",
            "What's actually is there will be a thought I encounter someone or I do not encounter someone and."
        ],
        [
            "The reason to the the answer to this question is we can use a probabilistic model.",
            "You can use a person process and in this case is a normal genius.",
            "Special person.",
            "Promised normal genus means that the rate in which some events happen changes overtime and special means that you also changes over space.",
            "I don't know if you're familiar with with some policies, but the idea is that it's a probability distribution that allows you to model what's the probability that a certain number of events happen in a certain time or space, and in this case when certain space, time window, and so the whole thing that we need to learn understand is what we call here rate function.",
            "And this rate function is actually the representation, or often a certain event happened, and this is a big space there's.",
            "A continuous SpaceX Y in the world and time, so we can use some function approximator for machine learning.",
            "But this will be too expensive, so our idea is that we discretize the world in cells in spacetime cells.",
            "So we have kind of voxel like cube that represents a part of the environment at specific time.",
            "So we need to learn them to learn them.",
            "We use standard by Asian learning, so we basically have observed the people in environment for certain period of time and we have positive observation which says OK, an event happened and negative observation that says anyone didn't happen and there are some.",
            "Classic based on learning rules to how to play this distribution, I will not go too much into detail here, but you will find them in the paper and so."
        ],
        [
            "Here I show you a. Online learning on the discourse map of this person rate function.",
            "Here you see we use lasers can I don't know if you're familiar with but the sensor that can allows you to measure the space around you and gives you the what's the distance towards the closest obstacles from the robot.",
            "And this black dots actually measurement of the environment is like a planner scandal.",
            "This and this cylinder.",
            "Actually people real people that we are tracking overtime.",
            "And the darker the value of the cell, the higher is the rate in this individual cell.",
            "So and this the problem with this is that."
        ],
        [
            "Dealing with people and collecting data from real people is actually complex, so in order to really develop and test our algorithm, we need tomato of a simulator with drift of sending that actually allows us to collect a huge amount of data but in a short time and in a repetitive fashion.",
            "So we developed a people simulator.",
            "We we developed three different environments an office like Environment I warehouse like environments and the House environment and we.",
            "Every three layer architecture in the sense that we have activity architecture where we define a set of different activities that are scheduled to work today and we have beyond below the activities.",
            "We have actions and below the actually actually the execution of the individual action in the world so.",
            "The activities actually are learn from some questionnaire that we administered to our colleagues and our friends such that they are as much realistic as possible.",
            "Of course, you cannot really reach the realism of real life, but we try to get close to that."
        ],
        [
            "Next, slide OK, so that's the first problem I'm presenting here.",
            "If the maximum counter probability planning and as an example of this problem, imagine that you have a coffee delivery robot that has to deliver the coffee to you while you're actually moving in your environment.",
            "While you are doing your own usual activities like you're in office at certain time, you have a meeting.",
            "You go to meeting.",
            "You forgot that you ask the robot to bring you the coffee, but the robot knows it and bring it to you.",
            "And the idea is that you have a deadline, so the coffee.",
            "As to be let's say hot so the robot doesn't, we don't want the robot to search for the whole environment.",
            "We know that we want the robot actually before use and be as fast as possible to reach us."
        ],
        [
            "And how we do that?",
            "We model this as a Markov decision process.",
            "We have a state, the individual cells of the world's reaction are the typical action issue over the solution like that where the robot can go next cell on the 8th neighborhood we have reward, which is actually both on rate.",
            "'cause this is proportional to the probability of encountering someone and actually the sum of the individual rate is equal to the.",
            "Product of the different events.",
            "So the joint event in probabilistic sent.",
            "And we have also, if an authorize and so that is represented by our deadline.",
            "The challenges here is that their eyes on actually is reducing in time.",
            "So every time we do one step, Verizon is reduced.",
            "Next Step Horizon is reduced.",
            "That means that we cannot reuse space in normal and Marco decision process thing.",
            "And the second problem is that the world changes overtime.",
            "So if I visit the sale at a certain time, it's different than if I sleep in a different time.",
            "So we.",
            "We did some prelim."
        ],
        [
            "Naughty experiment, so before the experiment we did a preliminary analysis of what actually MVP does an for soil.",
            "We found out that the time complex in the space complexity may be problematic because we want to be able to have a faster planning in case of dynamic changes in the environment, and we may want to have this also in a small robot like Jennifer familiar with Roomba Vacuum cleaner, which is really limited memory memory, limited memory.",
            "And so we can including some memories work for big environment.",
            "But what we realized and I'll show you later on that behavior of them.",
            "The piranha is actually trying to go towards the most probable area in the whole map, and to trade off at length with probability of encountering people.",
            "So we decide that we can relax this stochastic city of the action in this case to just.",
            "I'm having a controller which actually ensure assure us that we can follow the path and we can use a star towards the to plan path towards this."
        ],
        [
            "And that's because if you see here the behavior of the MDP that's just for if we follow the policy in the under from the starting location that is trying with a short deadline is trying to reach this place, because that's the thing."
        ],
        [
            "This time if you give more time in trying to reach this other place which is higher probability and."
        ],
        [
            "If you give really long time, is able to reach the global thing in the old map if you compare it with realistic with a story."
        ],
        [
            "Mystic, we have that this terroristic doesn't really behave too bad.",
            "But the problem here is that instead of going through this high probable part of the environment actually decides to get the shortcuts and we would like to avoid this behavior because there's a really highly frequented place.",
            "Because people are basically moves on this corridor and it is not frequently used."
        ],
        [
            "So if you compare the general behavior, we did some experiment with our simulator.",
            "We learn the map for simulating 10 days.",
            "We learn and then we test all the things thousand generated paths in over again 10 days with changing the location at the time, and we use as a metric the success rate.",
            "So simulate the path.",
            "Like if the robot actually encounter someone and we found out actually the MVP and the stylistic which are there, which we call here in form one, actually perform quite Similarly if we give enough time for this letter in this far away, as long as the deadline being shorter and shorter and shorter, you can see that the gap is actually widening up and we like also to be able to have a good touristic for this short deadline time.",
            "That's."
        ],
        [
            "Is it for the first problem?",
            "The second problem is the minimum interference coverage, and again here as a practical example.",
            "As I said, we have a vacuum cleaner that has to clean the whole house and so he has to go on every node in every room in the house.",
            "And just to do it where people are not in the room so that they are not annoyed or not disturbed by the robot.",
            "So."
        ],
        [
            "So again, we.",
            "Try to model this problem as a time independent traveling salesman problem where we have nodes in the graph which are represented by the individual rooms, kitchen, dining room, living room.",
            "Edges we have the doorways so the real access waypoints from one room to another one, and again we have the Postal rates, but in this time in this case they are costs because we want to avoid people while before they were rewards because we want to meet them.",
            "The challenges here is that actually this particular problem is sparse because there are not so many doors in House, specially if it's a big one.",
            "While normally when you address the DSP you actually use a complete graph and you perform.",
            "Either the nanny Premier approaches or greedy eristic or drop throughout, but under full connected graph and it's a symmetric because we have cost in the nodes, which is the cost of clean of the people being in a room of cost on the edges because we go around and discuss changes overtime.",
            "So if I first clean the kitchen and then I go to the bathroom is different than if I first clean the bathroom.",
            "Then I go to the kitchen.",
            "So.",
            "If you want to have."
        ],
        [
            "It shot idea of the algorithm.",
            "Here we have our environment."
        ],
        [
            "We first generate the room graph, so we have the graph, then we use."
        ],
        [
            "Find virtual to complete the graph and then we basic."
        ],
        [
            "Solve the resulting display problem with using dynamic programming we modified.",
            "I'm programming to take care of the.",
            "They cause the changes overtime."
        ],
        [
            "We did some preliminary results also using some standard touristics 40 SP problems, so we use the greedy and the nearest neighbour autistics.",
            "And then we also wanted to see if actually this this costs are reasonable in this kind of problem.",
            "So we also use a general TZP where the costs are actually the travel cost and not the encountering cost.",
            "What we see that the full.",
            "PSP with encounter cost is actually performing Bad 11 performing best, but it's not really a big surprise even if for if you count the number of people that have been encountered during the whole task or if you count the amount of time that the robot and the person we're in the same room and they actually surprise here is that the greedy and nearest neighbor Ristic of the DSP.",
            "They actually do not perform better or two better than a general GSP where we don't.",
            "You don't know the.",
            "They cost function an and that's quite.",
            "It was quite surprising because we were expecting something more like this behavior, but a bit on the like mid more costly but not the same behavior as the general to speak and we still we're still trying to understand what's the reason behind that, but probably those are not good touristic for the for the problem."
        ],
        [
            "That we are considering.",
            "So concluding this problem.",
            "The dynamic programming approach works, but it's too expensive because it's exponential entire in time and space.",
            "Even completing the graph from the sparse graph to complete graph is expensive because we need to compute flight partial for each time step.",
            "So we have the Ncube complexity of the flight virtual plus the fact that we have anytime step and then at the power of four and also we found that the risztics, although there are like nice from the complexity or interview, they still need to have the flight partial completion algorithm so.",
            "These are just for the risk, but the complexity of the problem is still an at the power of four and also do not give too many too much improvement over the rest.",
            "So probably The thing is that DSP maybe not the best.",
            "Formulation for this kind of problem and we are trying to look, and that's actually what we like to 1st.",
            "A bit of discussion here.",
            "If you have any idea when possible alternative that we can use instead of DSP of if you have an idea of how formulate this in PDL or."
        ],
        [
            "Similar, so that's the conclusion.",
            "I presented two different problems that we think are interesting for social robotics, and I hope that I was able to convince you that this problem actually interesting.",
            "Also, for the planning community, I show how we actually can learn activities, and I also show that we have a simulator engine that allows us to deal with the activity of people and their code will.",
            "I'm working on releasing the code open source and if you're interested just send me an email.",
            "That's my email address.",
            "And we're pretty happy to give you the code or give you information when they're ready.",
            "That's it from my side.",
            "Thank you very much.",
            "So we have plenty of time for questions or proposals of different approaches.",
            "Yeah, so considering the first problem when you model it as MDP and then you said it wasn't scalable, right?",
            "Sound like that.",
            "Which kind of algorithm wasn't scalable?",
            "Like naive Val?",
            "Yeah, just use the Bellman equation then if any solution that is scalable.",
            "I think that even modified policy iteration would be much better.",
            "But I think that sampling techniques and can prove to be quite helpful.",
            "They will not give you optimal.",
            "Maybe in the behavior, but will give you quite effective behavior.",
            "Also I think.",
            "Value iteration is.",
            "So no questions, I have another question, so at one point you tried to encounter person in the other problem you want to avoid persons, but for example if you want to bring some coffee to some guy maybe at the same time you want to avoid the others as this hum somehow form.",
            "Can you somehow formulate this in one of your approaches, like having positive and negative costs respectively rewards?",
            "Yeah, I think you can introduce the cost in the first planning problem and the cost will be let's say not the same cost function, But you can have like a blending of the two like rewards and cost function.",
            "Or actually, what can also be done is that you can also include this interactive be reactive behavior of the of the of the label itself, so you don't actually plan for them as obstacles while you try to be on the path that you planned but trying reactive toward people.",
            "And that's another way of approaching this.",
            "Kate.",
            "Some other questions.",
            "Well, actually I'm pretty happy about this work because we had this robot Albert always really annoyed me when he really commanded me to go out of its way.",
            "So thank you.",
            "So if there are no more questions, I think we should wait for the other session to end before we start the closing remarks of the conference here."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So thank you for the introduction, I'm done.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with Cai Olivarez from the Social Robotics Lab at the University of Freiburg.",
                    "label": 1
                },
                {
                    "sent": "They all talk is about I'm going to present 2 problems that I think are interesting for planning with.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Robot, so what's the?",
                    "label": 0
                },
                {
                    "sent": "What's the meaning of social robot?",
                    "label": 0
                },
                {
                    "sent": "So this social robotics.",
                    "label": 0
                },
                {
                    "sent": "There are several definitions robotics, but we are interested in is to have robots that are socially compatible.",
                    "label": 1
                },
                {
                    "sent": "The meaning is that robots that are able to plan and act and reason in an environment filled by humans and they are able to blend into the human activities.",
                    "label": 1
                },
                {
                    "sent": "So the first thing that we want to understand is how can we model human activities.",
                    "label": 0
                },
                {
                    "sent": "How can we reason about human activities learning them?",
                    "label": 0
                },
                {
                    "sent": "And that's the first part of this talk.",
                    "label": 0
                },
                {
                    "sent": "I will just briefly go around and explain what's our model to reason about activities.",
                    "label": 0
                },
                {
                    "sent": "And in this particular case, active are interested in is actually the presence of a person in a certain place in certain place in the environment.",
                    "label": 0
                },
                {
                    "sent": "And then we represent the first problem which we call maximum encounter probability planning and the idea is that the robot is somewhere in the world and needs to find someone.",
                    "label": 0
                },
                {
                    "sent": "And the second problem is that what we call minima.",
                    "label": 0
                },
                {
                    "sent": "Minimal hindrance coverage.",
                    "label": 0
                },
                {
                    "sent": "The robot is to perform a task in environment and as to avoid people because they may be annoyed by him.",
                    "label": 0
                },
                {
                    "sent": "So first.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thing is, we want to learn activity pattern, so activity patterns happen in space and time.",
                    "label": 0
                },
                {
                    "sent": "So you want to find the model that allows us to actually answer questions like how probable is that this activity actually really happens now at this part of the environment and this specific time?",
                    "label": 1
                },
                {
                    "sent": "What actually what I have to wait?",
                    "label": 1
                },
                {
                    "sent": "How long do I have to wait as long as certain activity happened?",
                    "label": 1
                },
                {
                    "sent": "And also if I'm moving, which is the interesting part for this talk?",
                    "label": 0
                },
                {
                    "sent": "So if I'm planning a path around the environment?",
                    "label": 0
                },
                {
                    "sent": "What's actually is there will be a thought I encounter someone or I do not encounter someone and.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The reason to the the answer to this question is we can use a probabilistic model.",
                    "label": 0
                },
                {
                    "sent": "You can use a person process and in this case is a normal genius.",
                    "label": 0
                },
                {
                    "sent": "Special person.",
                    "label": 0
                },
                {
                    "sent": "Promised normal genus means that the rate in which some events happen changes overtime and special means that you also changes over space.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you're familiar with with some policies, but the idea is that it's a probability distribution that allows you to model what's the probability that a certain number of events happen in a certain time or space, and in this case when certain space, time window, and so the whole thing that we need to learn understand is what we call here rate function.",
                    "label": 0
                },
                {
                    "sent": "And this rate function is actually the representation, or often a certain event happened, and this is a big space there's.",
                    "label": 0
                },
                {
                    "sent": "A continuous SpaceX Y in the world and time, so we can use some function approximator for machine learning.",
                    "label": 0
                },
                {
                    "sent": "But this will be too expensive, so our idea is that we discretize the world in cells in spacetime cells.",
                    "label": 0
                },
                {
                    "sent": "So we have kind of voxel like cube that represents a part of the environment at specific time.",
                    "label": 0
                },
                {
                    "sent": "So we need to learn them to learn them.",
                    "label": 0
                },
                {
                    "sent": "We use standard by Asian learning, so we basically have observed the people in environment for certain period of time and we have positive observation which says OK, an event happened and negative observation that says anyone didn't happen and there are some.",
                    "label": 0
                },
                {
                    "sent": "Classic based on learning rules to how to play this distribution, I will not go too much into detail here, but you will find them in the paper and so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here I show you a. Online learning on the discourse map of this person rate function.",
                    "label": 0
                },
                {
                    "sent": "Here you see we use lasers can I don't know if you're familiar with but the sensor that can allows you to measure the space around you and gives you the what's the distance towards the closest obstacles from the robot.",
                    "label": 0
                },
                {
                    "sent": "And this black dots actually measurement of the environment is like a planner scandal.",
                    "label": 0
                },
                {
                    "sent": "This and this cylinder.",
                    "label": 0
                },
                {
                    "sent": "Actually people real people that we are tracking overtime.",
                    "label": 0
                },
                {
                    "sent": "And the darker the value of the cell, the higher is the rate in this individual cell.",
                    "label": 0
                },
                {
                    "sent": "So and this the problem with this is that.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dealing with people and collecting data from real people is actually complex, so in order to really develop and test our algorithm, we need tomato of a simulator with drift of sending that actually allows us to collect a huge amount of data but in a short time and in a repetitive fashion.",
                    "label": 1
                },
                {
                    "sent": "So we developed a people simulator.",
                    "label": 1
                },
                {
                    "sent": "We we developed three different environments an office like Environment I warehouse like environments and the House environment and we.",
                    "label": 0
                },
                {
                    "sent": "Every three layer architecture in the sense that we have activity architecture where we define a set of different activities that are scheduled to work today and we have beyond below the activities.",
                    "label": 0
                },
                {
                    "sent": "We have actions and below the actually actually the execution of the individual action in the world so.",
                    "label": 0
                },
                {
                    "sent": "The activities actually are learn from some questionnaire that we administered to our colleagues and our friends such that they are as much realistic as possible.",
                    "label": 0
                },
                {
                    "sent": "Of course, you cannot really reach the realism of real life, but we try to get close to that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next, slide OK, so that's the first problem I'm presenting here.",
                    "label": 0
                },
                {
                    "sent": "If the maximum counter probability planning and as an example of this problem, imagine that you have a coffee delivery robot that has to deliver the coffee to you while you're actually moving in your environment.",
                    "label": 1
                },
                {
                    "sent": "While you are doing your own usual activities like you're in office at certain time, you have a meeting.",
                    "label": 0
                },
                {
                    "sent": "You go to meeting.",
                    "label": 0
                },
                {
                    "sent": "You forgot that you ask the robot to bring you the coffee, but the robot knows it and bring it to you.",
                    "label": 1
                },
                {
                    "sent": "And the idea is that you have a deadline, so the coffee.",
                    "label": 0
                },
                {
                    "sent": "As to be let's say hot so the robot doesn't, we don't want the robot to search for the whole environment.",
                    "label": 0
                },
                {
                    "sent": "We know that we want the robot actually before use and be as fast as possible to reach us.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And how we do that?",
                    "label": 0
                },
                {
                    "sent": "We model this as a Markov decision process.",
                    "label": 0
                },
                {
                    "sent": "We have a state, the individual cells of the world's reaction are the typical action issue over the solution like that where the robot can go next cell on the 8th neighborhood we have reward, which is actually both on rate.",
                    "label": 0
                },
                {
                    "sent": "'cause this is proportional to the probability of encountering someone and actually the sum of the individual rate is equal to the.",
                    "label": 0
                },
                {
                    "sent": "Product of the different events.",
                    "label": 0
                },
                {
                    "sent": "So the joint event in probabilistic sent.",
                    "label": 0
                },
                {
                    "sent": "And we have also, if an authorize and so that is represented by our deadline.",
                    "label": 0
                },
                {
                    "sent": "The challenges here is that their eyes on actually is reducing in time.",
                    "label": 0
                },
                {
                    "sent": "So every time we do one step, Verizon is reduced.",
                    "label": 0
                },
                {
                    "sent": "Next Step Horizon is reduced.",
                    "label": 0
                },
                {
                    "sent": "That means that we cannot reuse space in normal and Marco decision process thing.",
                    "label": 0
                },
                {
                    "sent": "And the second problem is that the world changes overtime.",
                    "label": 0
                },
                {
                    "sent": "So if I visit the sale at a certain time, it's different than if I sleep in a different time.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                },
                {
                    "sent": "We did some prelim.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Naughty experiment, so before the experiment we did a preliminary analysis of what actually MVP does an for soil.",
                    "label": 0
                },
                {
                    "sent": "We found out that the time complex in the space complexity may be problematic because we want to be able to have a faster planning in case of dynamic changes in the environment, and we may want to have this also in a small robot like Jennifer familiar with Roomba Vacuum cleaner, which is really limited memory memory, limited memory.",
                    "label": 0
                },
                {
                    "sent": "And so we can including some memories work for big environment.",
                    "label": 0
                },
                {
                    "sent": "But what we realized and I'll show you later on that behavior of them.",
                    "label": 0
                },
                {
                    "sent": "The piranha is actually trying to go towards the most probable area in the whole map, and to trade off at length with probability of encountering people.",
                    "label": 1
                },
                {
                    "sent": "So we decide that we can relax this stochastic city of the action in this case to just.",
                    "label": 1
                },
                {
                    "sent": "I'm having a controller which actually ensure assure us that we can follow the path and we can use a star towards the to plan path towards this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's because if you see here the behavior of the MDP that's just for if we follow the policy in the under from the starting location that is trying with a short deadline is trying to reach this place, because that's the thing.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This time if you give more time in trying to reach this other place which is higher probability and.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you give really long time, is able to reach the global thing in the old map if you compare it with realistic with a story.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mystic, we have that this terroristic doesn't really behave too bad.",
                    "label": 0
                },
                {
                    "sent": "But the problem here is that instead of going through this high probable part of the environment actually decides to get the shortcuts and we would like to avoid this behavior because there's a really highly frequented place.",
                    "label": 0
                },
                {
                    "sent": "Because people are basically moves on this corridor and it is not frequently used.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you compare the general behavior, we did some experiment with our simulator.",
                    "label": 0
                },
                {
                    "sent": "We learn the map for simulating 10 days.",
                    "label": 0
                },
                {
                    "sent": "We learn and then we test all the things thousand generated paths in over again 10 days with changing the location at the time, and we use as a metric the success rate.",
                    "label": 0
                },
                {
                    "sent": "So simulate the path.",
                    "label": 0
                },
                {
                    "sent": "Like if the robot actually encounter someone and we found out actually the MVP and the stylistic which are there, which we call here in form one, actually perform quite Similarly if we give enough time for this letter in this far away, as long as the deadline being shorter and shorter and shorter, you can see that the gap is actually widening up and we like also to be able to have a good touristic for this short deadline time.",
                    "label": 0
                },
                {
                    "sent": "That's.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is it for the first problem?",
                    "label": 0
                },
                {
                    "sent": "The second problem is the minimum interference coverage, and again here as a practical example.",
                    "label": 1
                },
                {
                    "sent": "As I said, we have a vacuum cleaner that has to clean the whole house and so he has to go on every node in every room in the house.",
                    "label": 0
                },
                {
                    "sent": "And just to do it where people are not in the room so that they are not annoyed or not disturbed by the robot.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, we.",
                    "label": 0
                },
                {
                    "sent": "Try to model this problem as a time independent traveling salesman problem where we have nodes in the graph which are represented by the individual rooms, kitchen, dining room, living room.",
                    "label": 0
                },
                {
                    "sent": "Edges we have the doorways so the real access waypoints from one room to another one, and again we have the Postal rates, but in this time in this case they are costs because we want to avoid people while before they were rewards because we want to meet them.",
                    "label": 0
                },
                {
                    "sent": "The challenges here is that actually this particular problem is sparse because there are not so many doors in House, specially if it's a big one.",
                    "label": 0
                },
                {
                    "sent": "While normally when you address the DSP you actually use a complete graph and you perform.",
                    "label": 0
                },
                {
                    "sent": "Either the nanny Premier approaches or greedy eristic or drop throughout, but under full connected graph and it's a symmetric because we have cost in the nodes, which is the cost of clean of the people being in a room of cost on the edges because we go around and discuss changes overtime.",
                    "label": 0
                },
                {
                    "sent": "So if I first clean the kitchen and then I go to the bathroom is different than if I first clean the bathroom.",
                    "label": 0
                },
                {
                    "sent": "Then I go to the kitchen.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If you want to have.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It shot idea of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Here we have our environment.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We first generate the room graph, so we have the graph, then we use.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find virtual to complete the graph and then we basic.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Solve the resulting display problem with using dynamic programming we modified.",
                    "label": 1
                },
                {
                    "sent": "I'm programming to take care of the.",
                    "label": 0
                },
                {
                    "sent": "They cause the changes overtime.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We did some preliminary results also using some standard touristics 40 SP problems, so we use the greedy and the nearest neighbour autistics.",
                    "label": 0
                },
                {
                    "sent": "And then we also wanted to see if actually this this costs are reasonable in this kind of problem.",
                    "label": 0
                },
                {
                    "sent": "So we also use a general TZP where the costs are actually the travel cost and not the encountering cost.",
                    "label": 0
                },
                {
                    "sent": "What we see that the full.",
                    "label": 0
                },
                {
                    "sent": "PSP with encounter cost is actually performing Bad 11 performing best, but it's not really a big surprise even if for if you count the number of people that have been encountered during the whole task or if you count the amount of time that the robot and the person we're in the same room and they actually surprise here is that the greedy and nearest neighbor Ristic of the DSP.",
                    "label": 0
                },
                {
                    "sent": "They actually do not perform better or two better than a general GSP where we don't.",
                    "label": 0
                },
                {
                    "sent": "You don't know the.",
                    "label": 0
                },
                {
                    "sent": "They cost function an and that's quite.",
                    "label": 0
                },
                {
                    "sent": "It was quite surprising because we were expecting something more like this behavior, but a bit on the like mid more costly but not the same behavior as the general to speak and we still we're still trying to understand what's the reason behind that, but probably those are not good touristic for the for the problem.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we are considering.",
                    "label": 0
                },
                {
                    "sent": "So concluding this problem.",
                    "label": 0
                },
                {
                    "sent": "The dynamic programming approach works, but it's too expensive because it's exponential entire in time and space.",
                    "label": 1
                },
                {
                    "sent": "Even completing the graph from the sparse graph to complete graph is expensive because we need to compute flight partial for each time step.",
                    "label": 0
                },
                {
                    "sent": "So we have the Ncube complexity of the flight virtual plus the fact that we have anytime step and then at the power of four and also we found that the risztics, although there are like nice from the complexity or interview, they still need to have the flight partial completion algorithm so.",
                    "label": 0
                },
                {
                    "sent": "These are just for the risk, but the complexity of the problem is still an at the power of four and also do not give too many too much improvement over the rest.",
                    "label": 0
                },
                {
                    "sent": "So probably The thing is that DSP maybe not the best.",
                    "label": 0
                },
                {
                    "sent": "Formulation for this kind of problem and we are trying to look, and that's actually what we like to 1st.",
                    "label": 0
                },
                {
                    "sent": "A bit of discussion here.",
                    "label": 0
                },
                {
                    "sent": "If you have any idea when possible alternative that we can use instead of DSP of if you have an idea of how formulate this in PDL or.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Similar, so that's the conclusion.",
                    "label": 0
                },
                {
                    "sent": "I presented two different problems that we think are interesting for social robotics, and I hope that I was able to convince you that this problem actually interesting.",
                    "label": 0
                },
                {
                    "sent": "Also, for the planning community, I show how we actually can learn activities, and I also show that we have a simulator engine that allows us to deal with the activity of people and their code will.",
                    "label": 0
                },
                {
                    "sent": "I'm working on releasing the code open source and if you're interested just send me an email.",
                    "label": 0
                },
                {
                    "sent": "That's my email address.",
                    "label": 0
                },
                {
                    "sent": "And we're pretty happy to give you the code or give you information when they're ready.",
                    "label": 0
                },
                {
                    "sent": "That's it from my side.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "So we have plenty of time for questions or proposals of different approaches.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so considering the first problem when you model it as MDP and then you said it wasn't scalable, right?",
                    "label": 0
                },
                {
                    "sent": "Sound like that.",
                    "label": 0
                },
                {
                    "sent": "Which kind of algorithm wasn't scalable?",
                    "label": 0
                },
                {
                    "sent": "Like naive Val?",
                    "label": 0
                },
                {
                    "sent": "Yeah, just use the Bellman equation then if any solution that is scalable.",
                    "label": 0
                },
                {
                    "sent": "I think that even modified policy iteration would be much better.",
                    "label": 0
                },
                {
                    "sent": "But I think that sampling techniques and can prove to be quite helpful.",
                    "label": 0
                },
                {
                    "sent": "They will not give you optimal.",
                    "label": 0
                },
                {
                    "sent": "Maybe in the behavior, but will give you quite effective behavior.",
                    "label": 0
                },
                {
                    "sent": "Also I think.",
                    "label": 0
                },
                {
                    "sent": "Value iteration is.",
                    "label": 0
                },
                {
                    "sent": "So no questions, I have another question, so at one point you tried to encounter person in the other problem you want to avoid persons, but for example if you want to bring some coffee to some guy maybe at the same time you want to avoid the others as this hum somehow form.",
                    "label": 0
                },
                {
                    "sent": "Can you somehow formulate this in one of your approaches, like having positive and negative costs respectively rewards?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think you can introduce the cost in the first planning problem and the cost will be let's say not the same cost function, But you can have like a blending of the two like rewards and cost function.",
                    "label": 0
                },
                {
                    "sent": "Or actually, what can also be done is that you can also include this interactive be reactive behavior of the of the of the label itself, so you don't actually plan for them as obstacles while you try to be on the path that you planned but trying reactive toward people.",
                    "label": 0
                },
                {
                    "sent": "And that's another way of approaching this.",
                    "label": 0
                },
                {
                    "sent": "Kate.",
                    "label": 0
                },
                {
                    "sent": "Some other questions.",
                    "label": 0
                },
                {
                    "sent": "Well, actually I'm pretty happy about this work because we had this robot Albert always really annoyed me when he really commanded me to go out of its way.",
                    "label": 0
                },
                {
                    "sent": "So thank you.",
                    "label": 0
                },
                {
                    "sent": "So if there are no more questions, I think we should wait for the other session to end before we start the closing remarks of the conference here.",
                    "label": 0
                }
            ]
        }
    }
}