{
    "id": "2xcdssb67zjvril3dda6hyqqetxxf2qe",
    "title": "MCMC Learning",
    "info": {
        "author": [
            "Varun Kanade, \u00c9cole normale sup\u00e9rieure Paris"
        ],
        "published": "Aug. 20, 2015",
        "recorded": "July 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2015_kanade_mcmc_learning/",
    "segmentation": [
        [
            "Look with Allison and Muscle who's at Berkeley and Japan."
        ],
        [
            "OK, so let me just remind you what the PAC learning model is and so impact learning.",
            "You get unlabeled data from some distribution and for this talk I'll just say you get this distribution over the Boolean hypercube.",
            "And these examples are labeled and the guarantee here is that they labeled according to some function that comes from a class is relatively simple class.",
            "So let's say linear separator or something.",
            "And you see the labels as positive or negative depending on the function value.",
            "And the goal in this setup is that you want to come up with a hypothesis that predicts the label of the point correctly.",
            "So in particular we look at the probability that the label predicted by the hypothesis is different from the actual label, and we want this quantity to be smaller than epsilon, and we want this to hold with high probability and in particular one of the stringent requirement is that this should work for all distributions over the unlabeled data.",
            "So no matter what the distribution is, you want the learning algorithm to be successful.",
            "Thing."
        ],
        [
            "So the model of agnostic learning which can be viewed as a generalization of the fact learning framework.",
            "And and here you just get labeled data directly, so you have an arbitrary distribution over the labeled data, and so now what is exactly the goal here?",
            "Well, we look at some classes of functions again, so let's say how spaces and we can ask what is the best half space that explains the data.",
            "So we call.",
            "This is the best half space, so it has some error opt and the learning requirement for the learning algorithm.",
            "Here is again you have to find some hypothesis that has error that's not much more than opt, so you cannot get very accurate classifiers, but you don't want to be much worse than the best classifier from certain class.",
            "And again here the requirement is that you want to work your algorithm to work for all distributions D. So no matter what.",
            "Distribution you have over the label data.",
            "Your algorithm should have such a guarantee, and these are quite strong guarantees."
        ],
        [
            "And.",
            "And in this talk I'm going to focus on 01 error or 01 loss or classification error and for these problems, for almost every class of functions, it turns out that empirical risk minimization, which is optimal in some sense for statistical reasons, is computationally intractable.",
            "So the goal in this talk is going to be focusing on algorithms that are both computationally and statistically efficient."
        ],
        [
            "So so because these problems turn out to be quite hard.",
            "There's been focus on restrictions, and one of this was what happens if we don't want algorithms to succeed for all distributions.",
            "But what if we have a uniform distribution on the Boolean hypercube?",
            "Can we do something in this case and in a breakthrough paper by Linial, Mansour, and Nissan in the early 90s, they showed that under this assumption you can learn all of AC0, which is, say constant depth circuits with and and or gates can be learned in quasipolynomial time.",
            "Then there was other work in this.",
            "Under the uniform distribution.",
            "So if you allow algorithm to make queries so kushilevitz and Mansour showed that you can learn decision trees and Jeff Jackson should, you can learn DNF formulas and there's been a lot of work since then on this.",
            "Assuming that the distribution is uniform over the Boolean hypercube.",
            "And this also connected theory of learning to other areas of theoretical computer science, mainly cryptography and complexity, and some of these learning results actually use quite sophisticated mathematical ideas.",
            "And so the main tool and all of these results is discrete Fourier analysis.",
            "So if you restrict ourselves to the uniform distribution, we have an explicit and succinct Fourier expansion, which is in terms of these parity functions.",
            "So here for any subset you have a product of all the bits in that subset, and these bits here are minus one and one valued.",
            "So this just represents a parity and you can write any function in terms of this, this basis, and this is the main tool that is helpful for learning under the uniform distribution.",
            "So this is.",
            "Very nice and deep mathematical theory.",
            "But"
        ],
        [
            "Of course you know it's uniform distribution is too much of an idealization in practice, so you don't expect ever to have data that comes from a uniform distribution over the Boolean hypercube.",
            "You will always have variables that are correlated in any distribution that you encounter in real life, and the question is that do we have to throw away everything that we know or can we actually try and solve some of this?",
            "So in this talk, I want to convince you that maybe we can save something and we present.",
            "So the first steps in this direction in this this talk.",
            "OK, so."
        ],
        [
            "So we're going to look at a more vastly more general class of distributions, so this is distributions that are generated by Markov random fields.",
            "So what are these distributions?",
            "So there's a graph on end nodes with some edges, and for each node there's there's a value that comes from some finite set, let's say just minus one one, and this defines a distribution over this set A to the N, and this distribution is given in terms of potential functions over clicks.",
            "I don't want to go into the details of this if you haven't seen them there, it doesn't matter.",
            "Too much, but I want to say that the uniform distribution is a special case where you have no edges, so it's just isolated vertices.",
            "And so what's and?",
            "Of course, if you have a complete graph, then you can represent any distribution.",
            "So what I'm going to talk about is not going to work for Hallmark of random fields, but for some kinds of Markov random fields."
        ],
        [
            "So when I look at Markov random fields so they're very popular as as a model for distributions in statistics and other areas of machine learning, so they've been used in computer vision, computational biology, and many other areas.",
            "And there's also a lot of extensive work on.",
            "On sort of sampling from these distributions and also trying to infer about the structure of the graph and the parameters are given.",
            "Is it examples or unlabeled data from these distributions?",
            "So here we are going to focus on something that's slightly different, so we want to if you want to learn with respect with the distribution.",
            "So you have some unknown target function and you promise that the distribution on the unlabeled.",
            "Examples come from some Markov random field.",
            "Can we learn from this, and in particular what we want to understand is can be utilized the structure of the Markov random field for learning."
        ],
        [
            "OK.",
            "So let me say what the model we have here is so it's so whether it's back or agnostic is sort of not very relevant here, but so we have a Markov random field and this defines some distribution \u03c0, and we have some target function.",
            "If that's defined from this space A to the end.",
            "Let's say it's a Boolean function.",
            "So the learning algorithm has access to independent, identically distributed examples from this distribution which are labeled.",
            "And we assume that the algorithm also knows the Markov random field.",
            "OK, so so let me be a bit more precise by what I mean by knows this, it doesn't have to know it exactly.",
            "But"
        ],
        [
            "What we want is for any Markov random field, there is a Markov chain called the Gibbs Markov chain.",
            "It is it's a Markov chain Monte Carlo algorithm, which is where the name comes from and what does this algorithm do?",
            "So you start with any point in the state space, so we have a vector in A to the N. And you run it in time and at each time the algorithm takes a pixel coordinate at random.",
            "And then fixes all the other coordinates and samples from the conditional distribution to reset the value of this coordinate.",
            "And."
        ],
        [
            "And and this it keeps repeating this.",
            "So this is this is the Markov chain.",
            "And what do we know about this Markov chain where the stationary distribution of this chain is indeed the distribution of the Markov random fields of this was came from Sammarco random field and.",
            "In particular, if the Markov random field is is a nice graph.",
            "So if there's constant degree graph, then this is change is very easy to implement, so and we're going to focus on on the cases where this changes rapidly mixing so it may not be rapidly mixing, but otherwise we don't know what to do, so we're going to focus on cases where this is actually rapidly mixing Markov chain.",
            "OK.",
            "I don't want to go into details about the eising model, but if for those of you know about this is an example of this is easing models and me just flashes for a few seconds, but this is an example.",
            "In some cases you have a rapidly mixing Markov chain from that results from using models."
        ],
        [
            "OK, so So what do we want to actually?",
            "Do so we would like to do free analysis again with respect to these distributions.",
            "How do we do this so we have a state space which is A to the N and there's this Markov chain that gives Markov chain and what do we know about this Markov chain?",
            "Well, it turns out that it's reversible, and we know that the stationary distribution is actually the distribution defined by the Markov chain.",
            "So, So what does reverse ability give us what it does us is if you look at the eigenvectors of the transition matrix, which are just functions from the state space Omega reals.",
            "And this actually forms an orthogonal basis.",
            "So can we do free analysis with respect to this basis?",
            "So this is the question we want to try and understand.",
            "And just to point out, if you look back at the uniform distribution, the parity functions are just eigenvectors.",
            "If you look at the suitable Markov chain for the uniform distribution.",
            "OK, so."
        ],
        [
            "First off, this approach would seem a bit naive because first of all these this matrix is exponentially large, so every eigenvector itself is exponentially large.",
            "So how do we even find this eigenvector or write it down?",
            "And even if we could find these eigenvectors, how do we find how expressive function in terms of these eigenvectors?",
            "So it's not obvious how one would actually handle these questions if we don't have a succinct representation for these eigenvectors.",
            "And what I want to show you now is that maybe we can do a little bit and."
        ],
        [
            "Let me go over this light slightly slowly.",
            "So let's say we have some function G. Let's define from this Omega which is 8 to the N to some minus one one less.",
            "It's the function with a bounded range and we can decompose J in terms of eigenvectors of the transition matrix.",
            "And then we see what happens if we apply the transition matrix to this function.",
            "So if we apply the teeth power of the transition matrix, what we get is that all the eigenvectors eigenvalues are raised to the 10th power, so that the highest the largest eigenvalue eigenvector corresponding to that is pushed up.",
            "Everything else is pushed down.",
            "Now if we apply this vector 1X, which is basically a vector with zeros everywhere except in the position corresponding to some point, XX is a point in Omega.",
            "This is just.",
            "We can write this where in terms of the eigenvectors value of the eigenvectors at position X on the right hand side.",
            "OK, so so this gives us some handle on what for a given point X what the value of the largest eigenvector that is in G might be.",
            "But how do we actually?"
        ],
        [
            "Still evaluate this quantity so this One X transpose PT power of PG.",
            "But if we think about it, if you look at this One X transpose and the power of P. This is actually just the distribution that you get on the space if you start at X and run the Markov chain 40 steps.",
            "And if we have access to the Markov chain, we can actually run, do this and so we can for any given function G IF we have black box access to G, we can estimate this value by this value by just sampling.",
            "And in particular, it means that we can get an approximate value of this top eigenvector in this, and by suitable subtractions later on, we can in fact all the eigenvectors that are in G. We can write them as some linear combinations of different powers of P applied to G. So this is what?"
        ],
        [
            "For a second, of course, I'm cheating a bit here, right?",
            "So we are hiding a lot of these things, so a lot of it depends on what the eigenvalues of the transition matrix actually look like.",
            "So so we want the spectrum to show sharp drops.",
            "Otherwise we can't really expect to separate the eigenvectors.",
            "And so this is what we call this discrete spectrum, and it's hard to characterize when exactly you would have a discrete spectrum.",
            "But it looks like if you have weakly correlated variables then one might have a discrete step spectrum.",
            "The second point is of course that we have to find such a function.",
            "Jesus.",
            "So far I just said, let's assume we have black box access or some function G. We don't know where these functions would come from.",
            "And this is also sort of difficult, but the reason why you would do this kind of free analysis at all is if you expect your target functions to have a good low degree X free expansion in this basis in some sense.",
            "So, so we would expect that the functions from this class itself should be a reasonable basis as a starting point.",
            "So I'll say a little bit more about this point, but these points later I want to show what?"
        ],
        [
            "The spectrum of so this is an easing model on a cycle at various values of temperature.",
            "So beta equal to 0 means infinite temperature, and so this is just the uniform distribution, and indeed we get a very discrete spectrum with sharp drops everywhere.",
            "And as we lower the temperature slightly we get something that still discrete and at some point of time it starts looking very continuous.",
            "So we're in a very high temperature regime.",
            "We would actually expect the spectrum of transition matrix for the easing model to actually be quite discreet, and this might be true for in many other Markov random fields as well.",
            "OK."
        ],
        [
            "Let me say what the learning algorithm now is.",
            "It's it's actually just L1 regression algorithm of collide klivans Monster answer video.",
            "So the input will be some basis functions.",
            "And access to this Markov chain and some sample and all, we're going to try to do is take many powers of the transition matrix, apply them to these functions, and treat them as features.",
            "And we're just trying to learn a linear function and fitted to the labels doing this and so for all of these functions we take many powers of the transition matrix, apply them to this G, and fit this up to and have some constraint on the total weight of this.",
            "And then what I pointed out earlier is that we can show that if these functions satisfy some nice properties, then we can write these eigenvectors actually as linear combinations of powers of the transition matrix applied to this.",
            "So in fact this if the function has a good expansion in the Fourier basis, this will fit it.",
            "So you can come talk to me afterwards if you want some more details on this, but.",
            "For that, and then the output is is is quite simple, so it's just, well, HX is a linear function, and if you want to binary prediction we just use random thresholding and this is what makes the prediction.",
            "So it's really the standard algorithm you will use for agnostic learning, but using slightly different features, it's just not, it's not polynomials."
        ],
        [
            "And so, so here's the informal theorem.",
            "So say that informal version of the theorem.",
            "So if you have a class of function that's well approximated by eigenvectors corresponding to higher eigenvalues, and it happens that we have a discrete spectrum for the transition matrix and access to the useful selection of basis functions, then we can do agnostic learning for this function class F. OK, so.",
            "So the first thing to notice that does this really generalize the uniform distribution case?",
            "And it does in the sense that if you run it for the uniform distribution and used, let's say, these basis functions should be just conjunctions or disjunctions on a few variables, then you would get exactly the same guarantees as you would get by algorithm of linear, Montserrat Nissan.",
            "The next question is why do we focus on eigenvectors corresponding to high eigenvalues?",
            "Well, partly it is just because this part of the spectrum is easier to access.",
            "It's really hard to get eigenvectors with low eigenvalues, but also that these are somehow stable, so so.",
            "So what do I mean by stable?",
            "If we if we actually think of the distribution being generated by the Markov chain and if we stop at some time T or some time T plus Delta T, the function value won't change on the point very often.",
            "If for these eigenvectors which are.",
            "Which are stable, but they will for if they're sort of low eigenvalue eigenvectors, and so in some sense this generalizes the notion of noise sensitivity, and This is why we're this part of the spectrum.",
            "It makes sense to look at it."
        ],
        [
            "So let me just conclude by some open questions.",
            "So like the obvious question is, well first, can we characterize a simple enough Markov random field and the class of functions for which we can actually prove that?",
            "This the functions in this class are well approximated by eigenvectors for high eigen values.",
            "For this transition matrix.",
            "So we show something in this direction.",
            "So what do we show?",
            "So if we have high temperature using models and let's I won't say what exactly those are.",
            "And if you look at half spaces or linear separators then these functions actually do have a representation of in terms of eigenvectors, tigon values and we prove this by generalizing the notion of noise sensitivity.",
            "And this is how we show that this is the case.",
            "Second this week and ask that what actually happens if we get labeled examples from a Markov chain.",
            "So right now we're assuming that we just can access the Markov chain for unlabeled examples, but we're getting ID examples as labels.",
            "Can we do something?",
            "It turns out and under some conditions is a very simple algorithm where you can learn hunters, but even this required some conditions.",
            "So can we just just rapid mixing enough for learning hunters?",
            "So we don't know the answer to this question.",
            "And sort of the more generally, I think the interesting question would be can can we understand what kinds of Markov chains would actually have discrete spectrum?",
            "This is so, so thanks very much questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look with Allison and Muscle who's at Berkeley and Japan.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let me just remind you what the PAC learning model is and so impact learning.",
                    "label": 1
                },
                {
                    "sent": "You get unlabeled data from some distribution and for this talk I'll just say you get this distribution over the Boolean hypercube.",
                    "label": 0
                },
                {
                    "sent": "And these examples are labeled and the guarantee here is that they labeled according to some function that comes from a class is relatively simple class.",
                    "label": 0
                },
                {
                    "sent": "So let's say linear separator or something.",
                    "label": 0
                },
                {
                    "sent": "And you see the labels as positive or negative depending on the function value.",
                    "label": 0
                },
                {
                    "sent": "And the goal in this setup is that you want to come up with a hypothesis that predicts the label of the point correctly.",
                    "label": 0
                },
                {
                    "sent": "So in particular we look at the probability that the label predicted by the hypothesis is different from the actual label, and we want this quantity to be smaller than epsilon, and we want this to hold with high probability and in particular one of the stringent requirement is that this should work for all distributions over the unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "So no matter what the distribution is, you want the learning algorithm to be successful.",
                    "label": 1
                },
                {
                    "sent": "Thing.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the model of agnostic learning which can be viewed as a generalization of the fact learning framework.",
                    "label": 1
                },
                {
                    "sent": "And and here you just get labeled data directly, so you have an arbitrary distribution over the labeled data, and so now what is exactly the goal here?",
                    "label": 0
                },
                {
                    "sent": "Well, we look at some classes of functions again, so let's say how spaces and we can ask what is the best half space that explains the data.",
                    "label": 0
                },
                {
                    "sent": "So we call.",
                    "label": 0
                },
                {
                    "sent": "This is the best half space, so it has some error opt and the learning requirement for the learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "Here is again you have to find some hypothesis that has error that's not much more than opt, so you cannot get very accurate classifiers, but you don't want to be much worse than the best classifier from certain class.",
                    "label": 0
                },
                {
                    "sent": "And again here the requirement is that you want to work your algorithm to work for all distributions D. So no matter what.",
                    "label": 1
                },
                {
                    "sent": "Distribution you have over the label data.",
                    "label": 0
                },
                {
                    "sent": "Your algorithm should have such a guarantee, and these are quite strong guarantees.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And in this talk I'm going to focus on 01 error or 01 loss or classification error and for these problems, for almost every class of functions, it turns out that empirical risk minimization, which is optimal in some sense for statistical reasons, is computationally intractable.",
                    "label": 1
                },
                {
                    "sent": "So the goal in this talk is going to be focusing on algorithms that are both computationally and statistically efficient.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so because these problems turn out to be quite hard.",
                    "label": 0
                },
                {
                    "sent": "There's been focus on restrictions, and one of this was what happens if we don't want algorithms to succeed for all distributions.",
                    "label": 0
                },
                {
                    "sent": "But what if we have a uniform distribution on the Boolean hypercube?",
                    "label": 0
                },
                {
                    "sent": "Can we do something in this case and in a breakthrough paper by Linial, Mansour, and Nissan in the early 90s, they showed that under this assumption you can learn all of AC0, which is, say constant depth circuits with and and or gates can be learned in quasipolynomial time.",
                    "label": 0
                },
                {
                    "sent": "Then there was other work in this.",
                    "label": 0
                },
                {
                    "sent": "Under the uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "So if you allow algorithm to make queries so kushilevitz and Mansour showed that you can learn decision trees and Jeff Jackson should, you can learn DNF formulas and there's been a lot of work since then on this.",
                    "label": 0
                },
                {
                    "sent": "Assuming that the distribution is uniform over the Boolean hypercube.",
                    "label": 0
                },
                {
                    "sent": "And this also connected theory of learning to other areas of theoretical computer science, mainly cryptography and complexity, and some of these learning results actually use quite sophisticated mathematical ideas.",
                    "label": 0
                },
                {
                    "sent": "And so the main tool and all of these results is discrete Fourier analysis.",
                    "label": 1
                },
                {
                    "sent": "So if you restrict ourselves to the uniform distribution, we have an explicit and succinct Fourier expansion, which is in terms of these parity functions.",
                    "label": 0
                },
                {
                    "sent": "So here for any subset you have a product of all the bits in that subset, and these bits here are minus one and one valued.",
                    "label": 0
                },
                {
                    "sent": "So this just represents a parity and you can write any function in terms of this, this basis, and this is the main tool that is helpful for learning under the uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "Very nice and deep mathematical theory.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of course you know it's uniform distribution is too much of an idealization in practice, so you don't expect ever to have data that comes from a uniform distribution over the Boolean hypercube.",
                    "label": 1
                },
                {
                    "sent": "You will always have variables that are correlated in any distribution that you encounter in real life, and the question is that do we have to throw away everything that we know or can we actually try and solve some of this?",
                    "label": 0
                },
                {
                    "sent": "So in this talk, I want to convince you that maybe we can save something and we present.",
                    "label": 1
                },
                {
                    "sent": "So the first steps in this direction in this this talk.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we're going to look at a more vastly more general class of distributions, so this is distributions that are generated by Markov random fields.",
                    "label": 0
                },
                {
                    "sent": "So what are these distributions?",
                    "label": 0
                },
                {
                    "sent": "So there's a graph on end nodes with some edges, and for each node there's there's a value that comes from some finite set, let's say just minus one one, and this defines a distribution over this set A to the N, and this distribution is given in terms of potential functions over clicks.",
                    "label": 1
                },
                {
                    "sent": "I don't want to go into the details of this if you haven't seen them there, it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "Too much, but I want to say that the uniform distribution is a special case where you have no edges, so it's just isolated vertices.",
                    "label": 0
                },
                {
                    "sent": "And so what's and?",
                    "label": 0
                },
                {
                    "sent": "Of course, if you have a complete graph, then you can represent any distribution.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to talk about is not going to work for Hallmark of random fields, but for some kinds of Markov random fields.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when I look at Markov random fields so they're very popular as as a model for distributions in statistics and other areas of machine learning, so they've been used in computer vision, computational biology, and many other areas.",
                    "label": 1
                },
                {
                    "sent": "And there's also a lot of extensive work on.",
                    "label": 0
                },
                {
                    "sent": "On sort of sampling from these distributions and also trying to infer about the structure of the graph and the parameters are given.",
                    "label": 0
                },
                {
                    "sent": "Is it examples or unlabeled data from these distributions?",
                    "label": 0
                },
                {
                    "sent": "So here we are going to focus on something that's slightly different, so we want to if you want to learn with respect with the distribution.",
                    "label": 0
                },
                {
                    "sent": "So you have some unknown target function and you promise that the distribution on the unlabeled.",
                    "label": 0
                },
                {
                    "sent": "Examples come from some Markov random field.",
                    "label": 0
                },
                {
                    "sent": "Can we learn from this, and in particular what we want to understand is can be utilized the structure of the Markov random field for learning.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So let me say what the model we have here is so it's so whether it's back or agnostic is sort of not very relevant here, but so we have a Markov random field and this defines some distribution \u03c0, and we have some target function.",
                    "label": 0
                },
                {
                    "sent": "If that's defined from this space A to the end.",
                    "label": 0
                },
                {
                    "sent": "Let's say it's a Boolean function.",
                    "label": 0
                },
                {
                    "sent": "So the learning algorithm has access to independent, identically distributed examples from this distribution which are labeled.",
                    "label": 1
                },
                {
                    "sent": "And we assume that the algorithm also knows the Markov random field.",
                    "label": 0
                },
                {
                    "sent": "OK, so so let me be a bit more precise by what I mean by knows this, it doesn't have to know it exactly.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we want is for any Markov random field, there is a Markov chain called the Gibbs Markov chain.",
                    "label": 0
                },
                {
                    "sent": "It is it's a Markov chain Monte Carlo algorithm, which is where the name comes from and what does this algorithm do?",
                    "label": 0
                },
                {
                    "sent": "So you start with any point in the state space, so we have a vector in A to the N. And you run it in time and at each time the algorithm takes a pixel coordinate at random.",
                    "label": 0
                },
                {
                    "sent": "And then fixes all the other coordinates and samples from the conditional distribution to reset the value of this coordinate.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And and this it keeps repeating this.",
                    "label": 0
                },
                {
                    "sent": "So this is this is the Markov chain.",
                    "label": 0
                },
                {
                    "sent": "And what do we know about this Markov chain where the stationary distribution of this chain is indeed the distribution of the Markov random fields of this was came from Sammarco random field and.",
                    "label": 0
                },
                {
                    "sent": "In particular, if the Markov random field is is a nice graph.",
                    "label": 0
                },
                {
                    "sent": "So if there's constant degree graph, then this is change is very easy to implement, so and we're going to focus on on the cases where this changes rapidly mixing so it may not be rapidly mixing, but otherwise we don't know what to do, so we're going to focus on cases where this is actually rapidly mixing Markov chain.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I don't want to go into details about the eising model, but if for those of you know about this is an example of this is easing models and me just flashes for a few seconds, but this is an example.",
                    "label": 0
                },
                {
                    "sent": "In some cases you have a rapidly mixing Markov chain from that results from using models.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so So what do we want to actually?",
                    "label": 0
                },
                {
                    "sent": "Do so we would like to do free analysis again with respect to these distributions.",
                    "label": 0
                },
                {
                    "sent": "How do we do this so we have a state space which is A to the N and there's this Markov chain that gives Markov chain and what do we know about this Markov chain?",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out that it's reversible, and we know that the stationary distribution is actually the distribution defined by the Markov chain.",
                    "label": 0
                },
                {
                    "sent": "So, So what does reverse ability give us what it does us is if you look at the eigenvectors of the transition matrix, which are just functions from the state space Omega reals.",
                    "label": 0
                },
                {
                    "sent": "And this actually forms an orthogonal basis.",
                    "label": 0
                },
                {
                    "sent": "So can we do free analysis with respect to this basis?",
                    "label": 1
                },
                {
                    "sent": "So this is the question we want to try and understand.",
                    "label": 0
                },
                {
                    "sent": "And just to point out, if you look back at the uniform distribution, the parity functions are just eigenvectors.",
                    "label": 1
                },
                {
                    "sent": "If you look at the suitable Markov chain for the uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First off, this approach would seem a bit naive because first of all these this matrix is exponentially large, so every eigenvector itself is exponentially large.",
                    "label": 0
                },
                {
                    "sent": "So how do we even find this eigenvector or write it down?",
                    "label": 1
                },
                {
                    "sent": "And even if we could find these eigenvectors, how do we find how expressive function in terms of these eigenvectors?",
                    "label": 1
                },
                {
                    "sent": "So it's not obvious how one would actually handle these questions if we don't have a succinct representation for these eigenvectors.",
                    "label": 0
                },
                {
                    "sent": "And what I want to show you now is that maybe we can do a little bit and.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me go over this light slightly slowly.",
                    "label": 0
                },
                {
                    "sent": "So let's say we have some function G. Let's define from this Omega which is 8 to the N to some minus one one less.",
                    "label": 1
                },
                {
                    "sent": "It's the function with a bounded range and we can decompose J in terms of eigenvectors of the transition matrix.",
                    "label": 0
                },
                {
                    "sent": "And then we see what happens if we apply the transition matrix to this function.",
                    "label": 0
                },
                {
                    "sent": "So if we apply the teeth power of the transition matrix, what we get is that all the eigenvectors eigenvalues are raised to the 10th power, so that the highest the largest eigenvalue eigenvector corresponding to that is pushed up.",
                    "label": 0
                },
                {
                    "sent": "Everything else is pushed down.",
                    "label": 0
                },
                {
                    "sent": "Now if we apply this vector 1X, which is basically a vector with zeros everywhere except in the position corresponding to some point, XX is a point in Omega.",
                    "label": 0
                },
                {
                    "sent": "This is just.",
                    "label": 0
                },
                {
                    "sent": "We can write this where in terms of the eigenvectors value of the eigenvectors at position X on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "OK, so so this gives us some handle on what for a given point X what the value of the largest eigenvector that is in G might be.",
                    "label": 0
                },
                {
                    "sent": "But how do we actually?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Still evaluate this quantity so this One X transpose PT power of PG.",
                    "label": 0
                },
                {
                    "sent": "But if we think about it, if you look at this One X transpose and the power of P. This is actually just the distribution that you get on the space if you start at X and run the Markov chain 40 steps.",
                    "label": 0
                },
                {
                    "sent": "And if we have access to the Markov chain, we can actually run, do this and so we can for any given function G IF we have black box access to G, we can estimate this value by this value by just sampling.",
                    "label": 1
                },
                {
                    "sent": "And in particular, it means that we can get an approximate value of this top eigenvector in this, and by suitable subtractions later on, we can in fact all the eigenvectors that are in G. We can write them as some linear combinations of different powers of P applied to G. So this is what?",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For a second, of course, I'm cheating a bit here, right?",
                    "label": 0
                },
                {
                    "sent": "So we are hiding a lot of these things, so a lot of it depends on what the eigenvalues of the transition matrix actually look like.",
                    "label": 0
                },
                {
                    "sent": "So so we want the spectrum to show sharp drops.",
                    "label": 1
                },
                {
                    "sent": "Otherwise we can't really expect to separate the eigenvectors.",
                    "label": 0
                },
                {
                    "sent": "And so this is what we call this discrete spectrum, and it's hard to characterize when exactly you would have a discrete spectrum.",
                    "label": 0
                },
                {
                    "sent": "But it looks like if you have weakly correlated variables then one might have a discrete step spectrum.",
                    "label": 1
                },
                {
                    "sent": "The second point is of course that we have to find such a function.",
                    "label": 0
                },
                {
                    "sent": "Jesus.",
                    "label": 0
                },
                {
                    "sent": "So far I just said, let's assume we have black box access or some function G. We don't know where these functions would come from.",
                    "label": 0
                },
                {
                    "sent": "And this is also sort of difficult, but the reason why you would do this kind of free analysis at all is if you expect your target functions to have a good low degree X free expansion in this basis in some sense.",
                    "label": 0
                },
                {
                    "sent": "So, so we would expect that the functions from this class itself should be a reasonable basis as a starting point.",
                    "label": 0
                },
                {
                    "sent": "So I'll say a little bit more about this point, but these points later I want to show what?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The spectrum of so this is an easing model on a cycle at various values of temperature.",
                    "label": 0
                },
                {
                    "sent": "So beta equal to 0 means infinite temperature, and so this is just the uniform distribution, and indeed we get a very discrete spectrum with sharp drops everywhere.",
                    "label": 0
                },
                {
                    "sent": "And as we lower the temperature slightly we get something that still discrete and at some point of time it starts looking very continuous.",
                    "label": 0
                },
                {
                    "sent": "So we're in a very high temperature regime.",
                    "label": 0
                },
                {
                    "sent": "We would actually expect the spectrum of transition matrix for the easing model to actually be quite discreet, and this might be true for in many other Markov random fields as well.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me say what the learning algorithm now is.",
                    "label": 0
                },
                {
                    "sent": "It's it's actually just L1 regression algorithm of collide klivans Monster answer video.",
                    "label": 0
                },
                {
                    "sent": "So the input will be some basis functions.",
                    "label": 0
                },
                {
                    "sent": "And access to this Markov chain and some sample and all, we're going to try to do is take many powers of the transition matrix, apply them to these functions, and treat them as features.",
                    "label": 0
                },
                {
                    "sent": "And we're just trying to learn a linear function and fitted to the labels doing this and so for all of these functions we take many powers of the transition matrix, apply them to this G, and fit this up to and have some constraint on the total weight of this.",
                    "label": 0
                },
                {
                    "sent": "And then what I pointed out earlier is that we can show that if these functions satisfy some nice properties, then we can write these eigenvectors actually as linear combinations of powers of the transition matrix applied to this.",
                    "label": 0
                },
                {
                    "sent": "So in fact this if the function has a good expansion in the Fourier basis, this will fit it.",
                    "label": 0
                },
                {
                    "sent": "So you can come talk to me afterwards if you want some more details on this, but.",
                    "label": 0
                },
                {
                    "sent": "For that, and then the output is is is quite simple, so it's just, well, HX is a linear function, and if you want to binary prediction we just use random thresholding and this is what makes the prediction.",
                    "label": 0
                },
                {
                    "sent": "So it's really the standard algorithm you will use for agnostic learning, but using slightly different features, it's just not, it's not polynomials.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so, so here's the informal theorem.",
                    "label": 1
                },
                {
                    "sent": "So say that informal version of the theorem.",
                    "label": 0
                },
                {
                    "sent": "So if you have a class of function that's well approximated by eigenvectors corresponding to higher eigenvalues, and it happens that we have a discrete spectrum for the transition matrix and access to the useful selection of basis functions, then we can do agnostic learning for this function class F. OK, so.",
                    "label": 1
                },
                {
                    "sent": "So the first thing to notice that does this really generalize the uniform distribution case?",
                    "label": 0
                },
                {
                    "sent": "And it does in the sense that if you run it for the uniform distribution and used, let's say, these basis functions should be just conjunctions or disjunctions on a few variables, then you would get exactly the same guarantees as you would get by algorithm of linear, Montserrat Nissan.",
                    "label": 0
                },
                {
                    "sent": "The next question is why do we focus on eigenvectors corresponding to high eigenvalues?",
                    "label": 1
                },
                {
                    "sent": "Well, partly it is just because this part of the spectrum is easier to access.",
                    "label": 0
                },
                {
                    "sent": "It's really hard to get eigenvectors with low eigenvalues, but also that these are somehow stable, so so.",
                    "label": 1
                },
                {
                    "sent": "So what do I mean by stable?",
                    "label": 0
                },
                {
                    "sent": "If we if we actually think of the distribution being generated by the Markov chain and if we stop at some time T or some time T plus Delta T, the function value won't change on the point very often.",
                    "label": 0
                },
                {
                    "sent": "If for these eigenvectors which are.",
                    "label": 0
                },
                {
                    "sent": "Which are stable, but they will for if they're sort of low eigenvalue eigenvectors, and so in some sense this generalizes the notion of noise sensitivity, and This is why we're this part of the spectrum.",
                    "label": 0
                },
                {
                    "sent": "It makes sense to look at it.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me just conclude by some open questions.",
                    "label": 1
                },
                {
                    "sent": "So like the obvious question is, well first, can we characterize a simple enough Markov random field and the class of functions for which we can actually prove that?",
                    "label": 0
                },
                {
                    "sent": "This the functions in this class are well approximated by eigenvectors for high eigen values.",
                    "label": 0
                },
                {
                    "sent": "For this transition matrix.",
                    "label": 0
                },
                {
                    "sent": "So we show something in this direction.",
                    "label": 0
                },
                {
                    "sent": "So what do we show?",
                    "label": 0
                },
                {
                    "sent": "So if we have high temperature using models and let's I won't say what exactly those are.",
                    "label": 0
                },
                {
                    "sent": "And if you look at half spaces or linear separators then these functions actually do have a representation of in terms of eigenvectors, tigon values and we prove this by generalizing the notion of noise sensitivity.",
                    "label": 0
                },
                {
                    "sent": "And this is how we show that this is the case.",
                    "label": 1
                },
                {
                    "sent": "Second this week and ask that what actually happens if we get labeled examples from a Markov chain.",
                    "label": 0
                },
                {
                    "sent": "So right now we're assuming that we just can access the Markov chain for unlabeled examples, but we're getting ID examples as labels.",
                    "label": 0
                },
                {
                    "sent": "Can we do something?",
                    "label": 0
                },
                {
                    "sent": "It turns out and under some conditions is a very simple algorithm where you can learn hunters, but even this required some conditions.",
                    "label": 1
                },
                {
                    "sent": "So can we just just rapid mixing enough for learning hunters?",
                    "label": 1
                },
                {
                    "sent": "So we don't know the answer to this question.",
                    "label": 0
                },
                {
                    "sent": "And sort of the more generally, I think the interesting question would be can can we understand what kinds of Markov chains would actually have discrete spectrum?",
                    "label": 1
                },
                {
                    "sent": "This is so, so thanks very much questions.",
                    "label": 0
                }
            ]
        }
    }
}