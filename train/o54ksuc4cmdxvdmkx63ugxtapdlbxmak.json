{
    "id": "o54ksuc4cmdxvdmkx63ugxtapdlbxmak",
    "title": "Discovering Cyclic Causal Models by Independent Components Analysis",
    "info": {
        "author": [
            "Gustavo Lacerda, Carnegie Mellon University"
        ],
        "published": "Feb. 27, 2008",
        "recorded": "February 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/cmulls08_lacerda_dcc/",
    "segmentation": [
        [
            "Thank you, this is the first time I'm giving this talk, so if you have any questions please interrupt and ask.",
            "Some things may still be unclear, may not be explained very well.",
            "OK.",
            "So.",
            "Our goal is to discover causal models.",
            "What?"
        ],
        [
            "Kind of causal models.",
            "Will the framework that we work under is called structural equation models which was defined by Perl about.",
            "20 years ago.",
            "Um?",
            "So the idea is that you have a graphical model that.",
            "Tells you who depends on who.",
            "So in this case.",
            "X3.",
            "Only depends on X1 and X2 and X or only depends on X3.",
            "This means that if we were to manipulate the X3.",
            "X4 would.",
            "We would basically eliminate these dependencies so.",
            "So the graph looks like this once we control.",
            "For once we manipulate X3."
        ],
        [
            "Structural equation models can be acyclic, which is that.",
            "Most common kind of graphical model that you see.",
            "They can also be cyclic.",
            "Interpreting cyclic models is not always so straightforward.",
            "There can be many ways of interpreting them, but one common way is to interpret them as equilibrium of dynamical systems."
        ],
        [
            "So here's an example.",
            "Linear structure equation models.",
            "So in linear SCMS, the equations are linear for example.",
            "And you know, we can write down.",
            "Numbers next to the edges to tell us the coefficients.",
            "To say how strong the."
        ],
        [
            "Sciences.",
            "But the more interesting case in the case in which we have some randomness in these models.",
            "So this is what we work with this.",
            "Is the kind of model that we're interested in.",
            "It can be described by this matrix equation at the bottom.",
            "So B is basically a coefficient matrix.",
            "That encodes the values of all the coefficients.",
            "So it's basically just rewriting that system of equations in terms of 1 equation."
        ],
        [
            "If we solve for X.",
            "We can express.",
            "The observed variables directly in terms of the error terms.",
            "We call that a mixing matrix.",
            "How should we visualize the mixing matrix?"
        ],
        [
            "Well, you can think of it.",
            "As.",
            "It tells you how much of each noise term there is in each observed variable.",
            "So how much of E1 there is in X4?",
            "How much of E3 there is in next 4 home?"
        ],
        [
            "So.",
            "If we do that.",
            "Just work it out.",
            "So as you can see.",
            "E1 has no influence on X2.",
            "So that's zero.",
            "But it does have an influence on X3, so there's an edge between D1 and X3.",
            "Likewise, E3 has an edge 2X4.",
            "And but it does not have an edge to EX2 for example.",
            "Let's workout the weights.",
            "We define the model such that.",
            "All the.",
            "All these coefficients are one between the error term.",
            "And.",
            "Observed variable.",
            "So what's the coefficient from E1 to X3?",
            "Anyone?",
            "Should just be 1.2.",
            "Because this coefficient is 1, this is 1.2, so that's how much of a one there was going to be on this node.",
            "Likewise.",
            "But how much of each one?",
            "Is there an index for?",
            "There's 1.2 * -- 5, which is minus 6.",
            "So we can just look it out.",
            "Is this clear?"
        ],
        [
            "OK.",
            "So the question becomes.",
            "When we have just observational data from these kinds of models.",
            "What can you figure out about the structure?",
            "And until recently, the best we could do is identifying the separation equivalence class.",
            "This means, for example, that those two graphs cannot be distinguished.",
            "Likewise.",
            "If we have.",
            "These photographs these three, are indistinguishable because they are in the same D separation equivalence class.",
            "This one, on the other hand, could be distinguished, so sounds like a pretty serious limitation.",
            "If you're interested in."
        ],
        [
            "Who causes who?",
            "But it's an inherent limitation when you have Gaussian data.",
            "So when the error terms are Gaussian, these two distributions are identical.",
            "So there's just no way to tell them apart without doing an experiment."
        ],
        [
            "Now, what's independent components analysis?",
            "Let me give you a completely different problem.",
            "Suppose you have two sources of noise.",
            "And two.",
            "Receivers that are recording this noise.",
            "Each receiver is going to get a mixture.",
            "Of the two sources, a different mixture.",
            "You want to get back the original signals.",
            "What can you do?"
        ],
        [
            "If you look at the equation.",
            "You could plug in any a here, any mixing matrix and you're going to get a solution to that.",
            "All we have is X.",
            "All we have is the observed data.",
            "The microphone recordings.",
            "So what can you do?",
            "Well."
        ],
        [
            "Whenever you choose a name that implies a list of samples.",
            "Of the signals for any mixing matrix you can work back.",
            "To the signals.",
            "If we assume that the signals are independent.",
            "Sorry, I'm getting ahead of myself.",
            "An for each implied.",
            "Signals set of signals.",
            "We have a degree of independence between them.",
            "If we assume that they are independent.",
            "Then we should just maximize.",
            "Their independence by choosing the aid that maximizes that.",
            "So one way to do that is to measure their non gaussianity.",
            "It's just a theorem that.",
            "Maximally independent is the same thing as maximally non Gaussian.",
            "And if you want an intuition, just think of the central limit theorem.",
            "The more things mixed, the more Gaussian they become."
        ],
        [
            "Now one problem with ICA is that we don't know.",
            "Which signal is which?",
            "It just gives us two signals in no particular order.",
            "So we don't know.",
            "FS1 is Bob or Alex, or they're both male.",
            "I had to say.",
            "So.",
            "And as we will see later.",
            "When we apply ICA to structural equation models?",
            "It's not clear whether a coefficient is big.",
            "Because it has a lot of variance or because.",
            "It's related to a big.",
            "Coefficient between the observed variables."
        ],
        [
            "So OK. 2006 she means well published a paper.",
            "That solves this problem basically.",
            "That applies ICA to the discovery of structural equation models.",
            "What would happen if we generated some data for simulate?",
            "This kind of system.",
            "And when I say on it.",
            "Also from."
        ],
        [
            "I've told you.",
            "You'd expect to see.",
            "The mixtures.",
            "Basically the mixing matrix.",
            "How much of each error term there is in each observed variable?",
            "There's one little problem that I just mentioned I."
        ],
        [
            "He doesn't know this gaming, so really we will see something like this instead of one.",
            "Will see Two's maybe.",
            "Just for the sake of argument.",
            "And then we need to divide by two.",
            "For all the children of E1."
        ],
        [
            "And then we get.",
            "What we want.",
            "There's one more problem though, since I say doesn't know the order of the error terms, it doesn't know which East goes with which which axis.",
            "So it doesn't know how to match the East of the Axis.",
            "What we actually."
        ],
        [
            "Get this something like this.",
            "So we have a list of error terms.",
            "With no labels on them.",
            "And we don't know who mattress to home.",
            "Until.",
            "We do something.",
            "So what do we do?",
            "We tried to find the permutation of these guys.",
            "That will ensure.",
            "That every X has a vertical arrow above it.",
            "This is basically saying.",
            "That the variance.",
            "Of the error term.",
            "Of all the error terms is non 0.",
            "So.",
            "So once we have this, what we need to do is first find a permutation.",
            "Then we do the scaling.",
            "And there's a unique way to do this, because the model is a DAG.",
            "And lingam does.",
            "This Lingam assumes that the model is a dog, so it only searches for."
        ],
        [
            "Single permutation.",
            "So we get back the full model.",
            "The original model."
        ],
        [
            "So.",
            "Any questions so far?",
            "OK, yes.",
            "Are you making that legendary?",
            "We, we assume, causal sufficiency, which means that if there are any latent variables, they are not causes of more than one observed variable.",
            "; Erica right, exactly so that's how the independence of the error term follows from this assumption that.",
            "Of causal sufficiency.",
            "Right, this is actually the slide that was about to explain that.",
            "So when we assume called the sufficiency.",
            "We know that the error terms will be independent.",
            "So now these two models can be distinguished.",
            "Which we couldn't do before with just constraint based methods."
        ],
        [
            "So let me show you a picture.",
            "If X1 and X2 are not related in any way.",
            "We have something like this.",
            "You can see they're independent.",
            "In the case of a uniform distribution, it looks like this.",
            "Still independent.",
            "When X one is a cause of X2.",
            "And the error terms are Gaussian.",
            "We see something like this.",
            "When X2 is the cause of X1 in their terms of Gaussian, we see something like this, so it's the same shape.",
            "We can't tell the difference between these two.",
            "On the other hand.",
            "If the error terms are non Gaussian.",
            "In this case uniform.",
            "The distributions look different.",
            "So ICA will basically used this difference.",
            "Distributions."
        ],
        [
            "One more thing to note is that.",
            "Since we wrote down the X is in order compatible with the true DAG.",
            "There are not going to be any arrows pointing to the left.",
            "You can just imagine writing down the graph you know.",
            "Vertically top down.",
            "And this constraint is basically saying that no errors are going to propagate up.",
            "On the dag.",
            "But in general, ICA could.",
            "Return a left pointing arrow.",
            "Or more properly said.",
            "There is no way to permute the East such that there are no left pointing arrows.",
            "When we see that we know that this distribution is violating the assumption of basic liceity.",
            "So.",
            "What can you do?",
            "Well, then we'll just pretend it's not there.",
            "It will find some permutation and assume that anything pointing through the left is error.",
            "Just noise."
        ],
        [
            "So Lingam cannot discover cyclic models because cyclic models have mixing matrices that.",
            "Have left pointing arrows.",
            "So Lingam basically searches for a single permutation.",
            "Because that's what you have when the generating model is a DAG.",
            "However, if we search for any number of permutations.",
            "Then we can discover circle models.",
            "Very simple idea.",
            "That's what we did.",
            "Yes.",
            "And what we're doing on the way this is no, we find the ordering so Lingam finds the ordering by permuting them in such a way that it gets a lower triangular matrix.",
            "You just said that you have to have the eczema right order of the diagram.",
            "No, that's only.",
            "If you want to see that there are no left pointing arrows, then the X is have to be ordered that way.",
            "But it's just a visualization.",
            "OK. Is it clear?",
            "OK. Anymore questions.",
            "OK."
        ],
        [
            "So we call our approach link DG for directed graph.",
            "As a generalization of Dag.",
            "We dropped a cyclic.",
            "So when the data looks acyclic it works just like Lingam and returns a single model.",
            "When the data looks cyclic.",
            "Ling DG will find more than one permutation that is considered valid, meaning there will be more than one permutation where we have all the vertical arrows.",
            "So it's going to return the distribution equivalent set containing more than one model.",
            "I have an example in a couple of slides.",
            "Distribution equivalent, of course means that you can't do any better than that unless you have more assumptions or different kinds of data.",
            "So from purely observational data, this is the best we can do."
        ],
        [
            "The best anyone can do.",
            "So let's simulate.",
            "Where sampling the noise terms by sampling from a Gaussian and squaring a standard way to make non Gaussian distributions.",
            "We used 15,000 data points.",
            "And we test.",
            "So in the mixing matrix we will have to decide which of those are zero, which edges are not there.",
            "Yes, sample sort of from this model is simply sorry.",
            "How do you sample from this model?",
            "If it's cyclic, that's a good question.",
            "So well, intuitively you could think.",
            "Of.",
            "Having an infinite sum.",
            "So.",
            "For example, E2 on X2 is going to appear infinitely many times, but it's getting smaller and smaller.",
            "Because this cycle has a product of 0.6.",
            "Well, how do I actually sample from it?",
            "OK, so we have a little trick.",
            "Which basically we turn this into the reduced form into the.",
            "Mixing matrix form.",
            "Find.",
            "Sorry.",
            "Yes, I think you could say that.",
            "Except it's not in equilibrium because these are.",
            "You know, these are stochastic, so it's a distribution over equilibrium.",
            "So.",
            "So we have this problem of deciding which edges are zero.",
            "And we have.",
            "We basically have to hypothesis test.",
            "Is it plausible that a given error was a 0?",
            "Of course, I'm talking about this."
        ],
        [
            "I'm talking about this picture.",
            "How do we know that this is zero?",
            "In practice it will look like something 0.01 or something like that and we need some way of deciding whether it's 0 so we do some bootstrap sampling.",
            "And then we do a quantile test to see if."
        ],
        [
            "Zero is an outlier.",
            "If there was an outlier, then we.",
            "Then we put the edge there because that means.",
            "It's probably not 0.",
            "OK. Ready.",
            "So after running."
        ],
        [
            "In the integer we get.",
            "Two models.",
            "And they don't look exactly the same.",
            "You may notice that the direction.",
            "Of these reversed, the cycle is going this way.",
            "Here it's going that way.",
            "There.",
            "You may also notice that this edge isn't is now from X1 to X4.",
            "And here is from X1 to X2.",
            "You may also notice that only one of these is a stable model.",
            "If we look at the product of this cycle here.",
            "That's about 0.6.",
            "The product of this cycle.",
            "Is about 1.66.",
            "So if we assume that our model is stable, we know that this is the right one."
        ],
        [
            "So a question, a theoretical question you would want to ask is.",
            "When are we guaranteed?",
            "To have a unique stable model.",
            "And we have.",
            "A sufficient but not necessary."
        ],
        [
            "Mission.",
            "For that.",
            "So.",
            "If the cycles in the true model don't intersect.",
            "Then only one model will be stable.",
            "This follows from.",
            "This simple fact.",
            "When you have models that are simple cycles.",
            "And basically nothing else.",
            "The cycle products are inverses of each other.",
            "You know the candidates, so if we so basically we're going to have two models.",
            "Whenever you have a simple cycle and they're basically just reversing directions.",
            "And we have proven that the cycle product between them is just one over the other.",
            "This means that at least one of them will be greater than one in modulus.",
            "And thus unstable.",
            "Meaning that the error terms will not dissipate overtime.",
            "The more times it goes around the loop, the bigger it gets, or at least not any smaller.",
            "And since each cycle is independent.",
            "Once you have the right permutation, any other permutation.",
            "Will invert at least one cycle, giving you an unstable model, so that's our main result.",
            "I mean theoretical result."
        ],
        [
            "So I'm afraid of.",
            "Going too fast because.",
            "Because I'm almost running out of slides.",
            "Any questions so far?",
            "Yes.",
            "So there might be many many permutations, right?",
            "So we're going to talk about finding that.",
            "That's an interesting question.",
            "Yes, I can give you some of that.",
            "I didn't prepare any slides about it.",
            "So.",
            "OK, so the way.",
            "Lingum works the acyclic.",
            "Method the acyclic approach.",
            "It knows that there is only one correct permutation.",
            "So.",
            "It basically needs to find.",
            "So if we talk about this as a matrix.",
            "So.",
            "The problem is to find the row permutation.",
            "Of a matrix.",
            "Such that there are no zeros in the diagonal.",
            "So we have a matrix with a bunch of entries, Summer 0 summer not 0.",
            "So if there's only one, this is a bipartite matching problem, yes, exactly.",
            "But in your case, when it's set when it's cyclic, then there could be exponentially many actually worse than the truth, exclamation, factorial possibilities actually.",
            "In factorial, but if.",
            "Everything is non zero yes so so how do you search list all this possible permutations?",
            "And how do you find them?",
            "So we have.",
            "So this is one of the main.",
            "Things we needed to change in changing approaches and for discovering cyclic models instead of a cyclic.",
            "So what we do?",
            "As we basically do a hypothesis test.",
            "For each entry in the Matrix.",
            "To decide which of them are zeros?",
            "So.",
            "Just imagine you have zeros and non zeros like that.",
            "Once we've done these tests and decided who is a zero and who is not a 0.",
            "We solved the so called in rooks problem.",
            "Or more precisely, the constrained in rooks problem.",
            "The idea is that you would put a Rook.",
            "If you play chess, you would know what I'm talking about.",
            "The question is how many ways are there?",
            "Of putting rooks on the non zero entries.",
            "Such that no two rooks threaten each other.",
            "This would be a trivial problem if there were no zeros.",
            "You wouldn't know that it's just N factorial, but there are zeros.",
            "And if you have a lot of zeros, then that number is not going to be so big anymore.",
            "In the case of simple cycles, there's particularly only two ways of matching the of assigning the rooks.",
            "So once you have.",
            "These things you can just permute them so that they're all lying on the diagonal.",
            "And since we placed the rooks on the non zero entries, that means our diagonal is going to have no zeros.",
            "How easy is it to memory all this possible?",
            "That's why I'm asking what is the conversation?",
            "It depends on how many zeros who have.",
            "We haven't analyzed K. Let's say that you have key graphs in the end.",
            "Sorry, I let you depend on cake.",
            "Please help what is K in this case the number of possibilities that the number of matches that there exist.",
            "OK, so we have to know merit although the bipartite matching we do.",
            "Yeah so so this.",
            "So much music is.",
            "Yeah, that's what I called this in Rooks algorithm, which is just basically a depth first search.",
            "So if you I don't know if I want to go into detail here, maybe.",
            "OK. OK.",
            "I mean the just briefly.",
            "So the idea is if you assign.",
            "If you assign this entry to be a Rook.",
            "You know that nothing here can be a Rook.",
            "So that gives you a smaller matrix with which to find the next one.",
            "So you could choose this one.",
            "Or you could choose.",
            "This one, so basically you have a search tree and the 1st works just fine.",
            "Any other questions?",
            "Yes, could you explain how you hear about cycles works in the case for cycle two nodes?",
            "'cause I'm thinking about that.",
            "Oh sure, if you put the images with the same model but.",
            "It looks like a mistake number slide, so the graph would be the same, but the coefficients would be different."
        ],
        [
            "So.",
            "We have this result that says the cycle product.",
            "Is cycle products are inverted, so if the first one looks like?",
            "If you have a cycle product of say 2.",
            "In its alternative model.",
            "The cycle product is going to be.",
            "Half.",
            "So these are different models, although they correspond to the same graph.",
            "That answered the question.",
            "Why is this?",
            "Because the weights on the edges are different from the.",
            "Sorry, is this because the weights on the edges are different?",
            "Yes, yes it is.",
            "So what I'm writing here is just basically the product of the edges.",
            "Yes.",
            "Of course, if you had.",
            "This be one.",
            "Then you know if there's one one, then you would get one one as the alternative.",
            "But neither of them is stable and this is an exceptional situation that.",
            ".5 what happens is that it seems like it would be the same, but the cycle product.",
            "So if both of these edges are .5.",
            "Then the cycle product is .25.",
            "Right and in the alternative model, you're going to have two and two.",
            "For the edges.",
            "And the cycle product would be 4.",
            "I haven't proven this here, but it's in the paper.",
            "Anymore questions.",
            "OK."
        ],
        [
            "So.",
            "Now we have this question, what method should you use for discovering?",
            "Your structure, your linear structural equation models.",
            "And the answer depends on whether you know it's a DAG and whether the error terms are Gaussian or not Gaussian.",
            "So the.",
            "Oldways with Gaussians.",
            "Just basically testing for.",
            "Conditional independence ease.",
            "And all that gives you is the D separation equivalence class.",
            "Then 2006 Shimizu ET al came up with Lingam, which gives you a unique model.",
            "Which is a quite an impressive result.",
            "For the cyclic case.",
            "There's Richardson's cyclic causal discovery algorithm.",
            "It outputs a very large class of models that are not even covariance equivalent.",
            "It would be possible to narrow these by just computing the covariance matrix from the data, but in practice you have so many.",
            "Models that you don't try to do that.",
            "Finally, there's our new approach.",
            "Which.",
            "Does the best you can do in the cyclic case as well as in this cyclic case.",
            "Now another question.",
            "Is what about this line between Gaussian and non Gaussian?",
            "Is it really a sharp line?",
            "No.",
            "It's not a sharp line.",
            "You could, for example, have some Gaussian and some non Gaussian error terms.",
            "You could have some error terms that are very close to Gaussian.",
            "Or you could have too little data to actually get good results from ICA.",
            "ICA requires a lot of data.",
            "As you may have noticed.",
            "So there's a paper we've submitted to a UA I.",
            "Dealing with the acyclic case.",
            "And for the cyclic case, well.",
            "If anyone's interested in.",
            "In working on this stuff that would be good."
        ],
        [
            "So thank you.",
            "Anymore questions.",
            "Yes.",
            "That's sufficient for getting unique, stable solution, yes, but you actually have contact sample.",
            "That is, I do I do.",
            "I don't have it here.",
            "So I could just draw it.",
            "There is a graph that looks like this.",
            "In which you have 3.",
            "Possible models.",
            "It turns out that two of those are stable and one is unstable.",
            "But as you can see, these cycles are intersecting, it has they have nodes in common.",
            "Yes, experimental results for real world data.",
            "No, we only have simulated data so far.",
            "That's a good question.",
            "So we would need a lot of data points and we would need a system that's pretty linear.",
            "So I don't know.",
            "I wonder if Peter has any suggestions about that.",
            "I think we're gonna try it on.",
            "So.",
            "Non Gaussian should should be the least of the problems, because I think the world has lots of non gaussianity.",
            "Anymore, OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you, this is the first time I'm giving this talk, so if you have any questions please interrupt and ask.",
                    "label": 0
                },
                {
                    "sent": "Some things may still be unclear, may not be explained very well.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Our goal is to discover causal models.",
                    "label": 1
                },
                {
                    "sent": "What?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Kind of causal models.",
                    "label": 0
                },
                {
                    "sent": "Will the framework that we work under is called structural equation models which was defined by Perl about.",
                    "label": 1
                },
                {
                    "sent": "20 years ago.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So the idea is that you have a graphical model that.",
                    "label": 0
                },
                {
                    "sent": "Tells you who depends on who.",
                    "label": 0
                },
                {
                    "sent": "So in this case.",
                    "label": 0
                },
                {
                    "sent": "X3.",
                    "label": 0
                },
                {
                    "sent": "Only depends on X1 and X2 and X or only depends on X3.",
                    "label": 0
                },
                {
                    "sent": "This means that if we were to manipulate the X3.",
                    "label": 0
                },
                {
                    "sent": "X4 would.",
                    "label": 0
                },
                {
                    "sent": "We would basically eliminate these dependencies so.",
                    "label": 0
                },
                {
                    "sent": "So the graph looks like this once we control.",
                    "label": 0
                },
                {
                    "sent": "For once we manipulate X3.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Structural equation models can be acyclic, which is that.",
                    "label": 1
                },
                {
                    "sent": "Most common kind of graphical model that you see.",
                    "label": 0
                },
                {
                    "sent": "They can also be cyclic.",
                    "label": 0
                },
                {
                    "sent": "Interpreting cyclic models is not always so straightforward.",
                    "label": 0
                },
                {
                    "sent": "There can be many ways of interpreting them, but one common way is to interpret them as equilibrium of dynamical systems.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "Linear structure equation models.",
                    "label": 0
                },
                {
                    "sent": "So in linear SCMS, the equations are linear for example.",
                    "label": 1
                },
                {
                    "sent": "And you know, we can write down.",
                    "label": 1
                },
                {
                    "sent": "Numbers next to the edges to tell us the coefficients.",
                    "label": 0
                },
                {
                    "sent": "To say how strong the.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sciences.",
                    "label": 0
                },
                {
                    "sent": "But the more interesting case in the case in which we have some randomness in these models.",
                    "label": 0
                },
                {
                    "sent": "So this is what we work with this.",
                    "label": 0
                },
                {
                    "sent": "Is the kind of model that we're interested in.",
                    "label": 0
                },
                {
                    "sent": "It can be described by this matrix equation at the bottom.",
                    "label": 0
                },
                {
                    "sent": "So B is basically a coefficient matrix.",
                    "label": 0
                },
                {
                    "sent": "That encodes the values of all the coefficients.",
                    "label": 0
                },
                {
                    "sent": "So it's basically just rewriting that system of equations in terms of 1 equation.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If we solve for X.",
                    "label": 1
                },
                {
                    "sent": "We can express.",
                    "label": 0
                },
                {
                    "sent": "The observed variables directly in terms of the error terms.",
                    "label": 0
                },
                {
                    "sent": "We call that a mixing matrix.",
                    "label": 0
                },
                {
                    "sent": "How should we visualize the mixing matrix?",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, you can think of it.",
                    "label": 0
                },
                {
                    "sent": "As.",
                    "label": 0
                },
                {
                    "sent": "It tells you how much of each noise term there is in each observed variable.",
                    "label": 0
                },
                {
                    "sent": "So how much of E1 there is in X4?",
                    "label": 0
                },
                {
                    "sent": "How much of E3 there is in next 4 home?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If we do that.",
                    "label": 0
                },
                {
                    "sent": "Just work it out.",
                    "label": 0
                },
                {
                    "sent": "So as you can see.",
                    "label": 0
                },
                {
                    "sent": "E1 has no influence on X2.",
                    "label": 0
                },
                {
                    "sent": "So that's zero.",
                    "label": 0
                },
                {
                    "sent": "But it does have an influence on X3, so there's an edge between D1 and X3.",
                    "label": 0
                },
                {
                    "sent": "Likewise, E3 has an edge 2X4.",
                    "label": 0
                },
                {
                    "sent": "And but it does not have an edge to EX2 for example.",
                    "label": 0
                },
                {
                    "sent": "Let's workout the weights.",
                    "label": 0
                },
                {
                    "sent": "We define the model such that.",
                    "label": 0
                },
                {
                    "sent": "All the.",
                    "label": 0
                },
                {
                    "sent": "All these coefficients are one between the error term.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Observed variable.",
                    "label": 0
                },
                {
                    "sent": "So what's the coefficient from E1 to X3?",
                    "label": 0
                },
                {
                    "sent": "Anyone?",
                    "label": 0
                },
                {
                    "sent": "Should just be 1.2.",
                    "label": 0
                },
                {
                    "sent": "Because this coefficient is 1, this is 1.2, so that's how much of a one there was going to be on this node.",
                    "label": 0
                },
                {
                    "sent": "Likewise.",
                    "label": 0
                },
                {
                    "sent": "But how much of each one?",
                    "label": 0
                },
                {
                    "sent": "Is there an index for?",
                    "label": 0
                },
                {
                    "sent": "There's 1.2 * -- 5, which is minus 6.",
                    "label": 0
                },
                {
                    "sent": "So we can just look it out.",
                    "label": 0
                },
                {
                    "sent": "Is this clear?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the question becomes.",
                    "label": 0
                },
                {
                    "sent": "When we have just observational data from these kinds of models.",
                    "label": 0
                },
                {
                    "sent": "What can you figure out about the structure?",
                    "label": 0
                },
                {
                    "sent": "And until recently, the best we could do is identifying the separation equivalence class.",
                    "label": 1
                },
                {
                    "sent": "This means, for example, that those two graphs cannot be distinguished.",
                    "label": 0
                },
                {
                    "sent": "Likewise.",
                    "label": 0
                },
                {
                    "sent": "If we have.",
                    "label": 0
                },
                {
                    "sent": "These photographs these three, are indistinguishable because they are in the same D separation equivalence class.",
                    "label": 0
                },
                {
                    "sent": "This one, on the other hand, could be distinguished, so sounds like a pretty serious limitation.",
                    "label": 0
                },
                {
                    "sent": "If you're interested in.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Who causes who?",
                    "label": 0
                },
                {
                    "sent": "But it's an inherent limitation when you have Gaussian data.",
                    "label": 0
                },
                {
                    "sent": "So when the error terms are Gaussian, these two distributions are identical.",
                    "label": 1
                },
                {
                    "sent": "So there's just no way to tell them apart without doing an experiment.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, what's independent components analysis?",
                    "label": 1
                },
                {
                    "sent": "Let me give you a completely different problem.",
                    "label": 0
                },
                {
                    "sent": "Suppose you have two sources of noise.",
                    "label": 0
                },
                {
                    "sent": "And two.",
                    "label": 0
                },
                {
                    "sent": "Receivers that are recording this noise.",
                    "label": 0
                },
                {
                    "sent": "Each receiver is going to get a mixture.",
                    "label": 0
                },
                {
                    "sent": "Of the two sources, a different mixture.",
                    "label": 0
                },
                {
                    "sent": "You want to get back the original signals.",
                    "label": 1
                },
                {
                    "sent": "What can you do?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you look at the equation.",
                    "label": 0
                },
                {
                    "sent": "You could plug in any a here, any mixing matrix and you're going to get a solution to that.",
                    "label": 0
                },
                {
                    "sent": "All we have is X.",
                    "label": 0
                },
                {
                    "sent": "All we have is the observed data.",
                    "label": 0
                },
                {
                    "sent": "The microphone recordings.",
                    "label": 0
                },
                {
                    "sent": "So what can you do?",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Whenever you choose a name that implies a list of samples.",
                    "label": 1
                },
                {
                    "sent": "Of the signals for any mixing matrix you can work back.",
                    "label": 0
                },
                {
                    "sent": "To the signals.",
                    "label": 0
                },
                {
                    "sent": "If we assume that the signals are independent.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I'm getting ahead of myself.",
                    "label": 0
                },
                {
                    "sent": "An for each implied.",
                    "label": 0
                },
                {
                    "sent": "Signals set of signals.",
                    "label": 1
                },
                {
                    "sent": "We have a degree of independence between them.",
                    "label": 0
                },
                {
                    "sent": "If we assume that they are independent.",
                    "label": 0
                },
                {
                    "sent": "Then we should just maximize.",
                    "label": 0
                },
                {
                    "sent": "Their independence by choosing the aid that maximizes that.",
                    "label": 0
                },
                {
                    "sent": "So one way to do that is to measure their non gaussianity.",
                    "label": 0
                },
                {
                    "sent": "It's just a theorem that.",
                    "label": 1
                },
                {
                    "sent": "Maximally independent is the same thing as maximally non Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And if you want an intuition, just think of the central limit theorem.",
                    "label": 0
                },
                {
                    "sent": "The more things mixed, the more Gaussian they become.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now one problem with ICA is that we don't know.",
                    "label": 1
                },
                {
                    "sent": "Which signal is which?",
                    "label": 0
                },
                {
                    "sent": "It just gives us two signals in no particular order.",
                    "label": 0
                },
                {
                    "sent": "So we don't know.",
                    "label": 1
                },
                {
                    "sent": "FS1 is Bob or Alex, or they're both male.",
                    "label": 0
                },
                {
                    "sent": "I had to say.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And as we will see later.",
                    "label": 0
                },
                {
                    "sent": "When we apply ICA to structural equation models?",
                    "label": 0
                },
                {
                    "sent": "It's not clear whether a coefficient is big.",
                    "label": 0
                },
                {
                    "sent": "Because it has a lot of variance or because.",
                    "label": 0
                },
                {
                    "sent": "It's related to a big.",
                    "label": 0
                },
                {
                    "sent": "Coefficient between the observed variables.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK. 2006 she means well published a paper.",
                    "label": 0
                },
                {
                    "sent": "That solves this problem basically.",
                    "label": 0
                },
                {
                    "sent": "That applies ICA to the discovery of structural equation models.",
                    "label": 0
                },
                {
                    "sent": "What would happen if we generated some data for simulate?",
                    "label": 0
                },
                {
                    "sent": "This kind of system.",
                    "label": 0
                },
                {
                    "sent": "And when I say on it.",
                    "label": 0
                },
                {
                    "sent": "Also from.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've told you.",
                    "label": 0
                },
                {
                    "sent": "You'd expect to see.",
                    "label": 0
                },
                {
                    "sent": "The mixtures.",
                    "label": 0
                },
                {
                    "sent": "Basically the mixing matrix.",
                    "label": 0
                },
                {
                    "sent": "How much of each error term there is in each observed variable?",
                    "label": 0
                },
                {
                    "sent": "There's one little problem that I just mentioned I.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "He doesn't know this gaming, so really we will see something like this instead of one.",
                    "label": 1
                },
                {
                    "sent": "Will see Two's maybe.",
                    "label": 0
                },
                {
                    "sent": "Just for the sake of argument.",
                    "label": 1
                },
                {
                    "sent": "And then we need to divide by two.",
                    "label": 0
                },
                {
                    "sent": "For all the children of E1.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we get.",
                    "label": 0
                },
                {
                    "sent": "What we want.",
                    "label": 0
                },
                {
                    "sent": "There's one more problem though, since I say doesn't know the order of the error terms, it doesn't know which East goes with which which axis.",
                    "label": 1
                },
                {
                    "sent": "So it doesn't know how to match the East of the Axis.",
                    "label": 0
                },
                {
                    "sent": "What we actually.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Get this something like this.",
                    "label": 1
                },
                {
                    "sent": "So we have a list of error terms.",
                    "label": 0
                },
                {
                    "sent": "With no labels on them.",
                    "label": 0
                },
                {
                    "sent": "And we don't know who mattress to home.",
                    "label": 0
                },
                {
                    "sent": "Until.",
                    "label": 0
                },
                {
                    "sent": "We do something.",
                    "label": 0
                },
                {
                    "sent": "So what do we do?",
                    "label": 0
                },
                {
                    "sent": "We tried to find the permutation of these guys.",
                    "label": 1
                },
                {
                    "sent": "That will ensure.",
                    "label": 0
                },
                {
                    "sent": "That every X has a vertical arrow above it.",
                    "label": 0
                },
                {
                    "sent": "This is basically saying.",
                    "label": 0
                },
                {
                    "sent": "That the variance.",
                    "label": 0
                },
                {
                    "sent": "Of the error term.",
                    "label": 1
                },
                {
                    "sent": "Of all the error terms is non 0.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So once we have this, what we need to do is first find a permutation.",
                    "label": 1
                },
                {
                    "sent": "Then we do the scaling.",
                    "label": 0
                },
                {
                    "sent": "And there's a unique way to do this, because the model is a DAG.",
                    "label": 1
                },
                {
                    "sent": "And lingam does.",
                    "label": 0
                },
                {
                    "sent": "This Lingam assumes that the model is a dog, so it only searches for.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Single permutation.",
                    "label": 0
                },
                {
                    "sent": "So we get back the full model.",
                    "label": 1
                },
                {
                    "sent": "The original model.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Any questions so far?",
                    "label": 0
                },
                {
                    "sent": "OK, yes.",
                    "label": 0
                },
                {
                    "sent": "Are you making that legendary?",
                    "label": 0
                },
                {
                    "sent": "We, we assume, causal sufficiency, which means that if there are any latent variables, they are not causes of more than one observed variable.",
                    "label": 1
                },
                {
                    "sent": "; Erica right, exactly so that's how the independence of the error term follows from this assumption that.",
                    "label": 0
                },
                {
                    "sent": "Of causal sufficiency.",
                    "label": 0
                },
                {
                    "sent": "Right, this is actually the slide that was about to explain that.",
                    "label": 1
                },
                {
                    "sent": "So when we assume called the sufficiency.",
                    "label": 1
                },
                {
                    "sent": "We know that the error terms will be independent.",
                    "label": 0
                },
                {
                    "sent": "So now these two models can be distinguished.",
                    "label": 0
                },
                {
                    "sent": "Which we couldn't do before with just constraint based methods.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me show you a picture.",
                    "label": 0
                },
                {
                    "sent": "If X1 and X2 are not related in any way.",
                    "label": 0
                },
                {
                    "sent": "We have something like this.",
                    "label": 0
                },
                {
                    "sent": "You can see they're independent.",
                    "label": 0
                },
                {
                    "sent": "In the case of a uniform distribution, it looks like this.",
                    "label": 0
                },
                {
                    "sent": "Still independent.",
                    "label": 0
                },
                {
                    "sent": "When X one is a cause of X2.",
                    "label": 0
                },
                {
                    "sent": "And the error terms are Gaussian.",
                    "label": 0
                },
                {
                    "sent": "We see something like this.",
                    "label": 0
                },
                {
                    "sent": "When X2 is the cause of X1 in their terms of Gaussian, we see something like this, so it's the same shape.",
                    "label": 0
                },
                {
                    "sent": "We can't tell the difference between these two.",
                    "label": 0
                },
                {
                    "sent": "On the other hand.",
                    "label": 0
                },
                {
                    "sent": "If the error terms are non Gaussian.",
                    "label": 0
                },
                {
                    "sent": "In this case uniform.",
                    "label": 0
                },
                {
                    "sent": "The distributions look different.",
                    "label": 0
                },
                {
                    "sent": "So ICA will basically used this difference.",
                    "label": 0
                },
                {
                    "sent": "Distributions.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One more thing to note is that.",
                    "label": 0
                },
                {
                    "sent": "Since we wrote down the X is in order compatible with the true DAG.",
                    "label": 1
                },
                {
                    "sent": "There are not going to be any arrows pointing to the left.",
                    "label": 0
                },
                {
                    "sent": "You can just imagine writing down the graph you know.",
                    "label": 0
                },
                {
                    "sent": "Vertically top down.",
                    "label": 0
                },
                {
                    "sent": "And this constraint is basically saying that no errors are going to propagate up.",
                    "label": 0
                },
                {
                    "sent": "On the dag.",
                    "label": 0
                },
                {
                    "sent": "But in general, ICA could.",
                    "label": 1
                },
                {
                    "sent": "Return a left pointing arrow.",
                    "label": 0
                },
                {
                    "sent": "Or more properly said.",
                    "label": 1
                },
                {
                    "sent": "There is no way to permute the East such that there are no left pointing arrows.",
                    "label": 0
                },
                {
                    "sent": "When we see that we know that this distribution is violating the assumption of basic liceity.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What can you do?",
                    "label": 0
                },
                {
                    "sent": "Well, then we'll just pretend it's not there.",
                    "label": 0
                },
                {
                    "sent": "It will find some permutation and assume that anything pointing through the left is error.",
                    "label": 0
                },
                {
                    "sent": "Just noise.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Lingam cannot discover cyclic models because cyclic models have mixing matrices that.",
                    "label": 1
                },
                {
                    "sent": "Have left pointing arrows.",
                    "label": 1
                },
                {
                    "sent": "So Lingam basically searches for a single permutation.",
                    "label": 0
                },
                {
                    "sent": "Because that's what you have when the generating model is a DAG.",
                    "label": 1
                },
                {
                    "sent": "However, if we search for any number of permutations.",
                    "label": 1
                },
                {
                    "sent": "Then we can discover circle models.",
                    "label": 0
                },
                {
                    "sent": "Very simple idea.",
                    "label": 0
                },
                {
                    "sent": "That's what we did.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "And what we're doing on the way this is no, we find the ordering so Lingam finds the ordering by permuting them in such a way that it gets a lower triangular matrix.",
                    "label": 0
                },
                {
                    "sent": "You just said that you have to have the eczema right order of the diagram.",
                    "label": 0
                },
                {
                    "sent": "No, that's only.",
                    "label": 0
                },
                {
                    "sent": "If you want to see that there are no left pointing arrows, then the X is have to be ordered that way.",
                    "label": 0
                },
                {
                    "sent": "But it's just a visualization.",
                    "label": 0
                },
                {
                    "sent": "OK. Is it clear?",
                    "label": 0
                },
                {
                    "sent": "OK. Anymore questions.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we call our approach link DG for directed graph.",
                    "label": 0
                },
                {
                    "sent": "As a generalization of Dag.",
                    "label": 0
                },
                {
                    "sent": "We dropped a cyclic.",
                    "label": 0
                },
                {
                    "sent": "So when the data looks acyclic it works just like Lingam and returns a single model.",
                    "label": 1
                },
                {
                    "sent": "When the data looks cyclic.",
                    "label": 0
                },
                {
                    "sent": "Ling DG will find more than one permutation that is considered valid, meaning there will be more than one permutation where we have all the vertical arrows.",
                    "label": 0
                },
                {
                    "sent": "So it's going to return the distribution equivalent set containing more than one model.",
                    "label": 0
                },
                {
                    "sent": "I have an example in a couple of slides.",
                    "label": 0
                },
                {
                    "sent": "Distribution equivalent, of course means that you can't do any better than that unless you have more assumptions or different kinds of data.",
                    "label": 0
                },
                {
                    "sent": "So from purely observational data, this is the best we can do.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The best anyone can do.",
                    "label": 0
                },
                {
                    "sent": "So let's simulate.",
                    "label": 0
                },
                {
                    "sent": "Where sampling the noise terms by sampling from a Gaussian and squaring a standard way to make non Gaussian distributions.",
                    "label": 1
                },
                {
                    "sent": "We used 15,000 data points.",
                    "label": 0
                },
                {
                    "sent": "And we test.",
                    "label": 0
                },
                {
                    "sent": "So in the mixing matrix we will have to decide which of those are zero, which edges are not there.",
                    "label": 0
                },
                {
                    "sent": "Yes, sample sort of from this model is simply sorry.",
                    "label": 0
                },
                {
                    "sent": "How do you sample from this model?",
                    "label": 0
                },
                {
                    "sent": "If it's cyclic, that's a good question.",
                    "label": 0
                },
                {
                    "sent": "So well, intuitively you could think.",
                    "label": 0
                },
                {
                    "sent": "Of.",
                    "label": 0
                },
                {
                    "sent": "Having an infinite sum.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "For example, E2 on X2 is going to appear infinitely many times, but it's getting smaller and smaller.",
                    "label": 0
                },
                {
                    "sent": "Because this cycle has a product of 0.6.",
                    "label": 0
                },
                {
                    "sent": "Well, how do I actually sample from it?",
                    "label": 0
                },
                {
                    "sent": "OK, so we have a little trick.",
                    "label": 0
                },
                {
                    "sent": "Which basically we turn this into the reduced form into the.",
                    "label": 0
                },
                {
                    "sent": "Mixing matrix form.",
                    "label": 0
                },
                {
                    "sent": "Find.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Yes, I think you could say that.",
                    "label": 0
                },
                {
                    "sent": "Except it's not in equilibrium because these are.",
                    "label": 0
                },
                {
                    "sent": "You know, these are stochastic, so it's a distribution over equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So we have this problem of deciding which edges are zero.",
                    "label": 0
                },
                {
                    "sent": "And we have.",
                    "label": 0
                },
                {
                    "sent": "We basically have to hypothesis test.",
                    "label": 0
                },
                {
                    "sent": "Is it plausible that a given error was a 0?",
                    "label": 0
                },
                {
                    "sent": "Of course, I'm talking about this.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm talking about this picture.",
                    "label": 0
                },
                {
                    "sent": "How do we know that this is zero?",
                    "label": 0
                },
                {
                    "sent": "In practice it will look like something 0.01 or something like that and we need some way of deciding whether it's 0 so we do some bootstrap sampling.",
                    "label": 0
                },
                {
                    "sent": "And then we do a quantile test to see if.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Zero is an outlier.",
                    "label": 0
                },
                {
                    "sent": "If there was an outlier, then we.",
                    "label": 0
                },
                {
                    "sent": "Then we put the edge there because that means.",
                    "label": 0
                },
                {
                    "sent": "It's probably not 0.",
                    "label": 0
                },
                {
                    "sent": "OK. Ready.",
                    "label": 0
                },
                {
                    "sent": "So after running.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the integer we get.",
                    "label": 0
                },
                {
                    "sent": "Two models.",
                    "label": 0
                },
                {
                    "sent": "And they don't look exactly the same.",
                    "label": 0
                },
                {
                    "sent": "You may notice that the direction.",
                    "label": 0
                },
                {
                    "sent": "Of these reversed, the cycle is going this way.",
                    "label": 0
                },
                {
                    "sent": "Here it's going that way.",
                    "label": 0
                },
                {
                    "sent": "There.",
                    "label": 0
                },
                {
                    "sent": "You may also notice that this edge isn't is now from X1 to X4.",
                    "label": 0
                },
                {
                    "sent": "And here is from X1 to X2.",
                    "label": 0
                },
                {
                    "sent": "You may also notice that only one of these is a stable model.",
                    "label": 0
                },
                {
                    "sent": "If we look at the product of this cycle here.",
                    "label": 0
                },
                {
                    "sent": "That's about 0.6.",
                    "label": 0
                },
                {
                    "sent": "The product of this cycle.",
                    "label": 0
                },
                {
                    "sent": "Is about 1.66.",
                    "label": 0
                },
                {
                    "sent": "So if we assume that our model is stable, we know that this is the right one.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a question, a theoretical question you would want to ask is.",
                    "label": 0
                },
                {
                    "sent": "When are we guaranteed?",
                    "label": 0
                },
                {
                    "sent": "To have a unique stable model.",
                    "label": 1
                },
                {
                    "sent": "And we have.",
                    "label": 0
                },
                {
                    "sent": "A sufficient but not necessary.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mission.",
                    "label": 0
                },
                {
                    "sent": "For that.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If the cycles in the true model don't intersect.",
                    "label": 1
                },
                {
                    "sent": "Then only one model will be stable.",
                    "label": 1
                },
                {
                    "sent": "This follows from.",
                    "label": 0
                },
                {
                    "sent": "This simple fact.",
                    "label": 0
                },
                {
                    "sent": "When you have models that are simple cycles.",
                    "label": 0
                },
                {
                    "sent": "And basically nothing else.",
                    "label": 0
                },
                {
                    "sent": "The cycle products are inverses of each other.",
                    "label": 0
                },
                {
                    "sent": "You know the candidates, so if we so basically we're going to have two models.",
                    "label": 0
                },
                {
                    "sent": "Whenever you have a simple cycle and they're basically just reversing directions.",
                    "label": 1
                },
                {
                    "sent": "And we have proven that the cycle product between them is just one over the other.",
                    "label": 0
                },
                {
                    "sent": "This means that at least one of them will be greater than one in modulus.",
                    "label": 0
                },
                {
                    "sent": "And thus unstable.",
                    "label": 1
                },
                {
                    "sent": "Meaning that the error terms will not dissipate overtime.",
                    "label": 0
                },
                {
                    "sent": "The more times it goes around the loop, the bigger it gets, or at least not any smaller.",
                    "label": 0
                },
                {
                    "sent": "And since each cycle is independent.",
                    "label": 0
                },
                {
                    "sent": "Once you have the right permutation, any other permutation.",
                    "label": 0
                },
                {
                    "sent": "Will invert at least one cycle, giving you an unstable model, so that's our main result.",
                    "label": 1
                },
                {
                    "sent": "I mean theoretical result.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm afraid of.",
                    "label": 0
                },
                {
                    "sent": "Going too fast because.",
                    "label": 0
                },
                {
                    "sent": "Because I'm almost running out of slides.",
                    "label": 0
                },
                {
                    "sent": "Any questions so far?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So there might be many many permutations, right?",
                    "label": 0
                },
                {
                    "sent": "So we're going to talk about finding that.",
                    "label": 0
                },
                {
                    "sent": "That's an interesting question.",
                    "label": 0
                },
                {
                    "sent": "Yes, I can give you some of that.",
                    "label": 0
                },
                {
                    "sent": "I didn't prepare any slides about it.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, so the way.",
                    "label": 0
                },
                {
                    "sent": "Lingum works the acyclic.",
                    "label": 0
                },
                {
                    "sent": "Method the acyclic approach.",
                    "label": 0
                },
                {
                    "sent": "It knows that there is only one correct permutation.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It basically needs to find.",
                    "label": 0
                },
                {
                    "sent": "So if we talk about this as a matrix.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The problem is to find the row permutation.",
                    "label": 0
                },
                {
                    "sent": "Of a matrix.",
                    "label": 0
                },
                {
                    "sent": "Such that there are no zeros in the diagonal.",
                    "label": 0
                },
                {
                    "sent": "So we have a matrix with a bunch of entries, Summer 0 summer not 0.",
                    "label": 0
                },
                {
                    "sent": "So if there's only one, this is a bipartite matching problem, yes, exactly.",
                    "label": 0
                },
                {
                    "sent": "But in your case, when it's set when it's cyclic, then there could be exponentially many actually worse than the truth, exclamation, factorial possibilities actually.",
                    "label": 0
                },
                {
                    "sent": "In factorial, but if.",
                    "label": 0
                },
                {
                    "sent": "Everything is non zero yes so so how do you search list all this possible permutations?",
                    "label": 0
                },
                {
                    "sent": "And how do you find them?",
                    "label": 0
                },
                {
                    "sent": "So we have.",
                    "label": 0
                },
                {
                    "sent": "So this is one of the main.",
                    "label": 0
                },
                {
                    "sent": "Things we needed to change in changing approaches and for discovering cyclic models instead of a cyclic.",
                    "label": 0
                },
                {
                    "sent": "So what we do?",
                    "label": 0
                },
                {
                    "sent": "As we basically do a hypothesis test.",
                    "label": 0
                },
                {
                    "sent": "For each entry in the Matrix.",
                    "label": 0
                },
                {
                    "sent": "To decide which of them are zeros?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Just imagine you have zeros and non zeros like that.",
                    "label": 0
                },
                {
                    "sent": "Once we've done these tests and decided who is a zero and who is not a 0.",
                    "label": 0
                },
                {
                    "sent": "We solved the so called in rooks problem.",
                    "label": 0
                },
                {
                    "sent": "Or more precisely, the constrained in rooks problem.",
                    "label": 0
                },
                {
                    "sent": "The idea is that you would put a Rook.",
                    "label": 0
                },
                {
                    "sent": "If you play chess, you would know what I'm talking about.",
                    "label": 0
                },
                {
                    "sent": "The question is how many ways are there?",
                    "label": 0
                },
                {
                    "sent": "Of putting rooks on the non zero entries.",
                    "label": 0
                },
                {
                    "sent": "Such that no two rooks threaten each other.",
                    "label": 0
                },
                {
                    "sent": "This would be a trivial problem if there were no zeros.",
                    "label": 0
                },
                {
                    "sent": "You wouldn't know that it's just N factorial, but there are zeros.",
                    "label": 0
                },
                {
                    "sent": "And if you have a lot of zeros, then that number is not going to be so big anymore.",
                    "label": 0
                },
                {
                    "sent": "In the case of simple cycles, there's particularly only two ways of matching the of assigning the rooks.",
                    "label": 0
                },
                {
                    "sent": "So once you have.",
                    "label": 0
                },
                {
                    "sent": "These things you can just permute them so that they're all lying on the diagonal.",
                    "label": 0
                },
                {
                    "sent": "And since we placed the rooks on the non zero entries, that means our diagonal is going to have no zeros.",
                    "label": 0
                },
                {
                    "sent": "How easy is it to memory all this possible?",
                    "label": 0
                },
                {
                    "sent": "That's why I'm asking what is the conversation?",
                    "label": 0
                },
                {
                    "sent": "It depends on how many zeros who have.",
                    "label": 0
                },
                {
                    "sent": "We haven't analyzed K. Let's say that you have key graphs in the end.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I let you depend on cake.",
                    "label": 0
                },
                {
                    "sent": "Please help what is K in this case the number of possibilities that the number of matches that there exist.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have to know merit although the bipartite matching we do.",
                    "label": 0
                },
                {
                    "sent": "Yeah so so this.",
                    "label": 0
                },
                {
                    "sent": "So much music is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's what I called this in Rooks algorithm, which is just basically a depth first search.",
                    "label": 0
                },
                {
                    "sent": "So if you I don't know if I want to go into detail here, maybe.",
                    "label": 0
                },
                {
                    "sent": "OK. OK.",
                    "label": 0
                },
                {
                    "sent": "I mean the just briefly.",
                    "label": 0
                },
                {
                    "sent": "So the idea is if you assign.",
                    "label": 0
                },
                {
                    "sent": "If you assign this entry to be a Rook.",
                    "label": 0
                },
                {
                    "sent": "You know that nothing here can be a Rook.",
                    "label": 0
                },
                {
                    "sent": "So that gives you a smaller matrix with which to find the next one.",
                    "label": 0
                },
                {
                    "sent": "So you could choose this one.",
                    "label": 0
                },
                {
                    "sent": "Or you could choose.",
                    "label": 0
                },
                {
                    "sent": "This one, so basically you have a search tree and the 1st works just fine.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "Yes, could you explain how you hear about cycles works in the case for cycle two nodes?",
                    "label": 0
                },
                {
                    "sent": "'cause I'm thinking about that.",
                    "label": 0
                },
                {
                    "sent": "Oh sure, if you put the images with the same model but.",
                    "label": 0
                },
                {
                    "sent": "It looks like a mistake number slide, so the graph would be the same, but the coefficients would be different.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We have this result that says the cycle product.",
                    "label": 0
                },
                {
                    "sent": "Is cycle products are inverted, so if the first one looks like?",
                    "label": 1
                },
                {
                    "sent": "If you have a cycle product of say 2.",
                    "label": 0
                },
                {
                    "sent": "In its alternative model.",
                    "label": 0
                },
                {
                    "sent": "The cycle product is going to be.",
                    "label": 0
                },
                {
                    "sent": "Half.",
                    "label": 0
                },
                {
                    "sent": "So these are different models, although they correspond to the same graph.",
                    "label": 0
                },
                {
                    "sent": "That answered the question.",
                    "label": 0
                },
                {
                    "sent": "Why is this?",
                    "label": 0
                },
                {
                    "sent": "Because the weights on the edges are different from the.",
                    "label": 0
                },
                {
                    "sent": "Sorry, is this because the weights on the edges are different?",
                    "label": 0
                },
                {
                    "sent": "Yes, yes it is.",
                    "label": 0
                },
                {
                    "sent": "So what I'm writing here is just basically the product of the edges.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you had.",
                    "label": 0
                },
                {
                    "sent": "This be one.",
                    "label": 0
                },
                {
                    "sent": "Then you know if there's one one, then you would get one one as the alternative.",
                    "label": 1
                },
                {
                    "sent": "But neither of them is stable and this is an exceptional situation that.",
                    "label": 0
                },
                {
                    "sent": ".5 what happens is that it seems like it would be the same, but the cycle product.",
                    "label": 0
                },
                {
                    "sent": "So if both of these edges are .5.",
                    "label": 0
                },
                {
                    "sent": "Then the cycle product is .25.",
                    "label": 0
                },
                {
                    "sent": "Right and in the alternative model, you're going to have two and two.",
                    "label": 0
                },
                {
                    "sent": "For the edges.",
                    "label": 0
                },
                {
                    "sent": "And the cycle product would be 4.",
                    "label": 0
                },
                {
                    "sent": "I haven't proven this here, but it's in the paper.",
                    "label": 0
                },
                {
                    "sent": "Anymore questions.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now we have this question, what method should you use for discovering?",
                    "label": 0
                },
                {
                    "sent": "Your structure, your linear structural equation models.",
                    "label": 0
                },
                {
                    "sent": "And the answer depends on whether you know it's a DAG and whether the error terms are Gaussian or not Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "Oldways with Gaussians.",
                    "label": 0
                },
                {
                    "sent": "Just basically testing for.",
                    "label": 0
                },
                {
                    "sent": "Conditional independence ease.",
                    "label": 0
                },
                {
                    "sent": "And all that gives you is the D separation equivalence class.",
                    "label": 1
                },
                {
                    "sent": "Then 2006 Shimizu ET al came up with Lingam, which gives you a unique model.",
                    "label": 0
                },
                {
                    "sent": "Which is a quite an impressive result.",
                    "label": 0
                },
                {
                    "sent": "For the cyclic case.",
                    "label": 0
                },
                {
                    "sent": "There's Richardson's cyclic causal discovery algorithm.",
                    "label": 0
                },
                {
                    "sent": "It outputs a very large class of models that are not even covariance equivalent.",
                    "label": 1
                },
                {
                    "sent": "It would be possible to narrow these by just computing the covariance matrix from the data, but in practice you have so many.",
                    "label": 0
                },
                {
                    "sent": "Models that you don't try to do that.",
                    "label": 0
                },
                {
                    "sent": "Finally, there's our new approach.",
                    "label": 0
                },
                {
                    "sent": "Which.",
                    "label": 0
                },
                {
                    "sent": "Does the best you can do in the cyclic case as well as in this cyclic case.",
                    "label": 0
                },
                {
                    "sent": "Now another question.",
                    "label": 0
                },
                {
                    "sent": "Is what about this line between Gaussian and non Gaussian?",
                    "label": 0
                },
                {
                    "sent": "Is it really a sharp line?",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "It's not a sharp line.",
                    "label": 0
                },
                {
                    "sent": "You could, for example, have some Gaussian and some non Gaussian error terms.",
                    "label": 0
                },
                {
                    "sent": "You could have some error terms that are very close to Gaussian.",
                    "label": 1
                },
                {
                    "sent": "Or you could have too little data to actually get good results from ICA.",
                    "label": 0
                },
                {
                    "sent": "ICA requires a lot of data.",
                    "label": 0
                },
                {
                    "sent": "As you may have noticed.",
                    "label": 0
                },
                {
                    "sent": "So there's a paper we've submitted to a UA I.",
                    "label": 0
                },
                {
                    "sent": "Dealing with the acyclic case.",
                    "label": 0
                },
                {
                    "sent": "And for the cyclic case, well.",
                    "label": 0
                },
                {
                    "sent": "If anyone's interested in.",
                    "label": 0
                },
                {
                    "sent": "In working on this stuff that would be good.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thank you.",
                    "label": 0
                },
                {
                    "sent": "Anymore questions.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "That's sufficient for getting unique, stable solution, yes, but you actually have contact sample.",
                    "label": 0
                },
                {
                    "sent": "That is, I do I do.",
                    "label": 0
                },
                {
                    "sent": "I don't have it here.",
                    "label": 0
                },
                {
                    "sent": "So I could just draw it.",
                    "label": 0
                },
                {
                    "sent": "There is a graph that looks like this.",
                    "label": 0
                },
                {
                    "sent": "In which you have 3.",
                    "label": 0
                },
                {
                    "sent": "Possible models.",
                    "label": 0
                },
                {
                    "sent": "It turns out that two of those are stable and one is unstable.",
                    "label": 0
                },
                {
                    "sent": "But as you can see, these cycles are intersecting, it has they have nodes in common.",
                    "label": 0
                },
                {
                    "sent": "Yes, experimental results for real world data.",
                    "label": 0
                },
                {
                    "sent": "No, we only have simulated data so far.",
                    "label": 0
                },
                {
                    "sent": "That's a good question.",
                    "label": 0
                },
                {
                    "sent": "So we would need a lot of data points and we would need a system that's pretty linear.",
                    "label": 0
                },
                {
                    "sent": "So I don't know.",
                    "label": 0
                },
                {
                    "sent": "I wonder if Peter has any suggestions about that.",
                    "label": 0
                },
                {
                    "sent": "I think we're gonna try it on.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Non Gaussian should should be the least of the problems, because I think the world has lots of non gaussianity.",
                    "label": 0
                },
                {
                    "sent": "Anymore, OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}